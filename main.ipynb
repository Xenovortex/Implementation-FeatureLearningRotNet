{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from functionalities import dataloader as dl\n",
    "from functionalities import evaluater as ev\n",
    "from functionalities import filemanager as fm\n",
    "from functionalities import trainer as tr\n",
    "from functionalities import plot as p\n",
    "from architecture import RotNet as RN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset, testset, classes = dl.load_cifar(\"./datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, validloader, testloader = dl.make_dataloaders(trainset, testset, 0, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Loss Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RotNet for Rotation Task and Classifiers on Feature Maps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set rot classes\n",
    "rot_classes = ['original', '90 rotation', '180 rotation', '270 rotation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Block RotNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "net_block3 = RN.RotNet(num_classes=4, num_conv_block=3, add_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.131\n",
      "[1, 120] loss: 0.976\n",
      "[1, 180] loss: 0.907\n",
      "[1, 240] loss: 0.849\n",
      "[1, 300] loss: 0.791\n",
      "[1, 360] loss: 0.766\n",
      "Epoch: 1 -> Loss: 0.680784225464\n",
      "Epoch: 1 -> Test Accuracy: 69.8975\n",
      "[2, 60] loss: 0.699\n",
      "[2, 120] loss: 0.683\n",
      "[2, 180] loss: 0.672\n",
      "[2, 240] loss: 0.659\n",
      "[2, 300] loss: 0.638\n",
      "[2, 360] loss: 0.626\n",
      "Epoch: 2 -> Loss: 0.737947106361\n",
      "Epoch: 2 -> Test Accuracy: 75.53\n",
      "[3, 60] loss: 0.608\n",
      "[3, 120] loss: 0.595\n",
      "[3, 180] loss: 0.579\n",
      "[3, 240] loss: 0.557\n",
      "[3, 300] loss: 0.571\n",
      "[3, 360] loss: 0.547\n",
      "Epoch: 3 -> Loss: 0.533422529697\n",
      "Epoch: 3 -> Test Accuracy: 77.88\n",
      "[4, 60] loss: 0.527\n",
      "[4, 120] loss: 0.535\n",
      "[4, 180] loss: 0.514\n",
      "[4, 240] loss: 0.510\n",
      "[4, 300] loss: 0.519\n",
      "[4, 360] loss: 0.513\n",
      "Epoch: 4 -> Loss: 0.522677898407\n",
      "Epoch: 4 -> Test Accuracy: 80.2525\n",
      "[5, 60] loss: 0.492\n",
      "[5, 120] loss: 0.486\n",
      "[5, 180] loss: 0.503\n",
      "[5, 240] loss: 0.487\n",
      "[5, 300] loss: 0.486\n",
      "[5, 360] loss: 0.464\n",
      "Epoch: 5 -> Loss: 0.504644989967\n",
      "Epoch: 5 -> Test Accuracy: 80.67\n",
      "[6, 60] loss: 0.462\n",
      "[6, 120] loss: 0.472\n",
      "[6, 180] loss: 0.450\n",
      "[6, 240] loss: 0.462\n",
      "[6, 300] loss: 0.464\n",
      "[6, 360] loss: 0.456\n",
      "Epoch: 6 -> Loss: 0.686868667603\n",
      "Epoch: 6 -> Test Accuracy: 82.02\n",
      "[7, 60] loss: 0.437\n",
      "[7, 120] loss: 0.433\n",
      "[7, 180] loss: 0.445\n",
      "[7, 240] loss: 0.448\n",
      "[7, 300] loss: 0.437\n",
      "[7, 360] loss: 0.431\n",
      "Epoch: 7 -> Loss: 0.490416586399\n",
      "Epoch: 7 -> Test Accuracy: 83.1925\n",
      "[8, 60] loss: 0.424\n",
      "[8, 120] loss: 0.422\n",
      "[8, 180] loss: 0.424\n",
      "[8, 240] loss: 0.421\n",
      "[8, 300] loss: 0.430\n",
      "[8, 360] loss: 0.428\n",
      "Epoch: 8 -> Loss: 0.553188621998\n",
      "Epoch: 8 -> Test Accuracy: 83.96\n",
      "[9, 60] loss: 0.406\n",
      "[9, 120] loss: 0.398\n",
      "[9, 180] loss: 0.418\n",
      "[9, 240] loss: 0.418\n",
      "[9, 300] loss: 0.414\n",
      "[9, 360] loss: 0.397\n",
      "Epoch: 9 -> Loss: 0.507232546806\n",
      "Epoch: 9 -> Test Accuracy: 83.215\n",
      "[10, 60] loss: 0.395\n",
      "[10, 120] loss: 0.401\n",
      "[10, 180] loss: 0.384\n",
      "[10, 240] loss: 0.397\n",
      "[10, 300] loss: 0.415\n",
      "[10, 360] loss: 0.401\n",
      "Epoch: 10 -> Loss: 0.604861021042\n",
      "Epoch: 10 -> Test Accuracy: 84.5325\n",
      "[11, 60] loss: 0.387\n",
      "[11, 120] loss: 0.394\n",
      "[11, 180] loss: 0.394\n",
      "[11, 240] loss: 0.400\n",
      "[11, 300] loss: 0.394\n",
      "[11, 360] loss: 0.383\n",
      "Epoch: 11 -> Loss: 0.423508107662\n",
      "Epoch: 11 -> Test Accuracy: 83.875\n",
      "[12, 60] loss: 0.379\n",
      "[12, 120] loss: 0.381\n",
      "[12, 180] loss: 0.379\n",
      "[12, 240] loss: 0.389\n",
      "[12, 300] loss: 0.379\n",
      "[12, 360] loss: 0.393\n",
      "Epoch: 12 -> Loss: 0.480721771717\n",
      "Epoch: 12 -> Test Accuracy: 84.8025\n",
      "[13, 60] loss: 0.364\n",
      "[13, 120] loss: 0.369\n",
      "[13, 180] loss: 0.391\n",
      "[13, 240] loss: 0.375\n",
      "[13, 300] loss: 0.369\n",
      "[13, 360] loss: 0.383\n",
      "Epoch: 13 -> Loss: 0.347966581583\n",
      "Epoch: 13 -> Test Accuracy: 84.84\n",
      "[14, 60] loss: 0.359\n",
      "[14, 120] loss: 0.366\n",
      "[14, 180] loss: 0.374\n",
      "[14, 240] loss: 0.367\n",
      "[14, 300] loss: 0.372\n",
      "[14, 360] loss: 0.363\n",
      "Epoch: 14 -> Loss: 0.288730978966\n",
      "Epoch: 14 -> Test Accuracy: 84.1175\n",
      "[15, 60] loss: 0.352\n",
      "[15, 120] loss: 0.357\n",
      "[15, 180] loss: 0.353\n",
      "[15, 240] loss: 0.380\n",
      "[15, 300] loss: 0.365\n",
      "[15, 360] loss: 0.362\n",
      "Epoch: 15 -> Loss: 0.427661657333\n",
      "Epoch: 15 -> Test Accuracy: 84.1675\n",
      "[16, 60] loss: 0.346\n",
      "[16, 120] loss: 0.362\n",
      "[16, 180] loss: 0.364\n",
      "[16, 240] loss: 0.353\n",
      "[16, 300] loss: 0.362\n",
      "[16, 360] loss: 0.359\n",
      "Epoch: 16 -> Loss: 0.345564126968\n",
      "Epoch: 16 -> Test Accuracy: 85.19\n",
      "[17, 60] loss: 0.341\n",
      "[17, 120] loss: 0.346\n",
      "[17, 180] loss: 0.354\n",
      "[17, 240] loss: 0.355\n",
      "[17, 300] loss: 0.373\n",
      "[17, 360] loss: 0.366\n",
      "Epoch: 17 -> Loss: 0.327844202518\n",
      "Epoch: 17 -> Test Accuracy: 85.03\n",
      "[18, 60] loss: 0.339\n",
      "[18, 120] loss: 0.344\n",
      "[18, 180] loss: 0.340\n",
      "[18, 240] loss: 0.350\n",
      "[18, 300] loss: 0.368\n",
      "[18, 360] loss: 0.368\n",
      "Epoch: 18 -> Loss: 0.337501138449\n",
      "Epoch: 18 -> Test Accuracy: 85.5825\n",
      "[19, 60] loss: 0.332\n",
      "[19, 120] loss: 0.345\n",
      "[19, 180] loss: 0.355\n",
      "[19, 240] loss: 0.342\n",
      "[19, 300] loss: 0.350\n",
      "[19, 360] loss: 0.344\n",
      "Epoch: 19 -> Loss: 0.247544571757\n",
      "Epoch: 19 -> Test Accuracy: 85.9075\n",
      "[20, 60] loss: 0.326\n",
      "[20, 120] loss: 0.342\n",
      "[20, 180] loss: 0.346\n",
      "[20, 240] loss: 0.343\n",
      "[20, 300] loss: 0.346\n",
      "[20, 360] loss: 0.347\n",
      "Epoch: 20 -> Loss: 0.249266415834\n",
      "Epoch: 20 -> Test Accuracy: 85.0625\n",
      "[21, 60] loss: 0.331\n",
      "[21, 120] loss: 0.344\n",
      "[21, 180] loss: 0.340\n",
      "[21, 240] loss: 0.351\n",
      "[21, 300] loss: 0.340\n",
      "[21, 360] loss: 0.338\n",
      "Epoch: 21 -> Loss: 0.35905867815\n",
      "Epoch: 21 -> Test Accuracy: 86.1825\n",
      "[22, 60] loss: 0.321\n",
      "[22, 120] loss: 0.331\n",
      "[22, 180] loss: 0.336\n",
      "[22, 240] loss: 0.356\n",
      "[22, 300] loss: 0.338\n",
      "[22, 360] loss: 0.336\n",
      "Epoch: 22 -> Loss: 0.357327342033\n",
      "Epoch: 22 -> Test Accuracy: 86.455\n",
      "[23, 60] loss: 0.324\n",
      "[23, 120] loss: 0.339\n",
      "[23, 180] loss: 0.333\n",
      "[23, 240] loss: 0.330\n",
      "[23, 300] loss: 0.343\n",
      "[23, 360] loss: 0.351\n",
      "Epoch: 23 -> Loss: 0.312273919582\n",
      "Epoch: 23 -> Test Accuracy: 85.96\n",
      "[24, 60] loss: 0.319\n",
      "[24, 120] loss: 0.330\n",
      "[24, 180] loss: 0.336\n",
      "[24, 240] loss: 0.341\n",
      "[24, 300] loss: 0.331\n",
      "[24, 360] loss: 0.332\n",
      "Epoch: 24 -> Loss: 0.337024748325\n",
      "Epoch: 24 -> Test Accuracy: 84.885\n",
      "[25, 60] loss: 0.322\n",
      "[25, 120] loss: 0.332\n",
      "[25, 180] loss: 0.331\n",
      "[25, 240] loss: 0.323\n",
      "[25, 300] loss: 0.342\n",
      "[25, 360] loss: 0.325\n",
      "Epoch: 25 -> Loss: 0.367140382528\n",
      "Epoch: 25 -> Test Accuracy: 86.985\n",
      "[26, 60] loss: 0.312\n",
      "[26, 120] loss: 0.342\n",
      "[26, 180] loss: 0.336\n",
      "[26, 240] loss: 0.318\n",
      "[26, 300] loss: 0.321\n",
      "[26, 360] loss: 0.338\n",
      "Epoch: 26 -> Loss: 0.253477871418\n",
      "Epoch: 26 -> Test Accuracy: 86.5925\n",
      "[27, 60] loss: 0.312\n",
      "[27, 120] loss: 0.325\n",
      "[27, 180] loss: 0.316\n",
      "[27, 240] loss: 0.334\n",
      "[27, 300] loss: 0.320\n",
      "[27, 360] loss: 0.334\n",
      "Epoch: 27 -> Loss: 0.378106564283\n",
      "Epoch: 27 -> Test Accuracy: 86.01\n",
      "[28, 60] loss: 0.322\n",
      "[28, 120] loss: 0.313\n",
      "[28, 180] loss: 0.324\n",
      "[28, 240] loss: 0.332\n",
      "[28, 300] loss: 0.322\n",
      "[28, 360] loss: 0.335\n",
      "Epoch: 28 -> Loss: 0.339754790068\n",
      "Epoch: 28 -> Test Accuracy: 85.335\n",
      "[29, 60] loss: 0.312\n",
      "[29, 120] loss: 0.319\n",
      "[29, 180] loss: 0.314\n",
      "[29, 240] loss: 0.321\n",
      "[29, 300] loss: 0.311\n",
      "[29, 360] loss: 0.360\n",
      "Epoch: 29 -> Loss: 0.333819776773\n",
      "Epoch: 29 -> Test Accuracy: 86.7\n",
      "[30, 60] loss: 0.301\n",
      "[30, 120] loss: 0.317\n",
      "[30, 180] loss: 0.328\n",
      "[30, 240] loss: 0.313\n",
      "[30, 300] loss: 0.330\n",
      "[30, 360] loss: 0.323\n",
      "Epoch: 30 -> Loss: 0.36256891489\n",
      "Epoch: 30 -> Test Accuracy: 86.6425\n",
      "[31, 60] loss: 0.317\n",
      "[31, 120] loss: 0.311\n",
      "[31, 180] loss: 0.319\n",
      "[31, 240] loss: 0.328\n",
      "[31, 300] loss: 0.325\n",
      "[31, 360] loss: 0.320\n",
      "Epoch: 31 -> Loss: 0.251239985228\n",
      "Epoch: 31 -> Test Accuracy: 87.04\n",
      "[32, 60] loss: 0.300\n",
      "[32, 120] loss: 0.321\n",
      "[32, 180] loss: 0.322\n",
      "[32, 240] loss: 0.328\n",
      "[32, 300] loss: 0.306\n",
      "[32, 360] loss: 0.324\n",
      "Epoch: 32 -> Loss: 0.334061086178\n",
      "Epoch: 32 -> Test Accuracy: 86.39\n",
      "[33, 60] loss: 0.304\n",
      "[33, 120] loss: 0.311\n",
      "[33, 180] loss: 0.318\n",
      "[33, 240] loss: 0.323\n",
      "[33, 300] loss: 0.322\n",
      "[33, 360] loss: 0.332\n",
      "Epoch: 33 -> Loss: 0.217529252172\n",
      "Epoch: 33 -> Test Accuracy: 87.0375\n",
      "[34, 60] loss: 0.305\n",
      "[34, 120] loss: 0.314\n",
      "[34, 180] loss: 0.313\n",
      "[34, 240] loss: 0.332\n",
      "[34, 300] loss: 0.310\n",
      "[34, 360] loss: 0.322\n",
      "Epoch: 34 -> Loss: 0.252018988132\n",
      "Epoch: 34 -> Test Accuracy: 86.9325\n",
      "[35, 60] loss: 0.303\n",
      "[35, 120] loss: 0.314\n",
      "[35, 180] loss: 0.299\n",
      "[35, 240] loss: 0.327\n",
      "[35, 300] loss: 0.319\n",
      "[35, 360] loss: 0.317\n",
      "Epoch: 35 -> Loss: 0.302196979523\n",
      "Epoch: 35 -> Test Accuracy: 86.3425\n",
      "[36, 60] loss: 0.307\n",
      "[36, 120] loss: 0.321\n",
      "[36, 180] loss: 0.316\n",
      "[36, 240] loss: 0.316\n",
      "[36, 300] loss: 0.333\n",
      "[36, 360] loss: 0.303\n",
      "Epoch: 36 -> Loss: 0.31414026022\n",
      "Epoch: 36 -> Test Accuracy: 86.255\n",
      "[37, 60] loss: 0.299\n",
      "[37, 120] loss: 0.317\n",
      "[37, 180] loss: 0.316\n",
      "[37, 240] loss: 0.310\n",
      "[37, 300] loss: 0.311\n",
      "[37, 360] loss: 0.314\n",
      "Epoch: 37 -> Loss: 0.367029428482\n",
      "Epoch: 37 -> Test Accuracy: 86.2375\n",
      "[38, 60] loss: 0.309\n",
      "[38, 120] loss: 0.301\n",
      "[38, 180] loss: 0.311\n",
      "[38, 240] loss: 0.298\n",
      "[38, 300] loss: 0.318\n",
      "[38, 360] loss: 0.330\n",
      "Epoch: 38 -> Loss: 0.299027621746\n",
      "Epoch: 38 -> Test Accuracy: 86.9875\n",
      "[39, 60] loss: 0.305\n",
      "[39, 120] loss: 0.302\n",
      "[39, 180] loss: 0.306\n",
      "[39, 240] loss: 0.304\n",
      "[39, 300] loss: 0.322\n",
      "[39, 360] loss: 0.325\n",
      "Epoch: 39 -> Loss: 0.314734816551\n",
      "Epoch: 39 -> Test Accuracy: 87.3675\n",
      "[40, 60] loss: 0.315\n",
      "[40, 120] loss: 0.293\n",
      "[40, 180] loss: 0.313\n",
      "[40, 240] loss: 0.303\n",
      "[40, 300] loss: 0.313\n",
      "[40, 360] loss: 0.311\n",
      "Epoch: 40 -> Loss: 0.36648273468\n",
      "Epoch: 40 -> Test Accuracy: 86.3725\n",
      "[41, 60] loss: 0.294\n",
      "[41, 120] loss: 0.302\n",
      "[41, 180] loss: 0.305\n",
      "[41, 240] loss: 0.317\n",
      "[41, 300] loss: 0.317\n",
      "[41, 360] loss: 0.323\n",
      "Epoch: 41 -> Loss: 0.264878213406\n",
      "Epoch: 41 -> Test Accuracy: 86.8\n",
      "[42, 60] loss: 0.316\n",
      "[42, 120] loss: 0.306\n",
      "[42, 180] loss: 0.298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 240] loss: 0.310\n",
      "[42, 300] loss: 0.320\n",
      "[42, 360] loss: 0.303\n",
      "Epoch: 42 -> Loss: 0.324565410614\n",
      "Epoch: 42 -> Test Accuracy: 86.6675\n",
      "[43, 60] loss: 0.300\n",
      "[43, 120] loss: 0.299\n",
      "[43, 180] loss: 0.306\n",
      "[43, 240] loss: 0.317\n",
      "[43, 300] loss: 0.308\n",
      "[43, 360] loss: 0.325\n",
      "Epoch: 43 -> Loss: 0.44145283103\n",
      "Epoch: 43 -> Test Accuracy: 87.7575\n",
      "[44, 60] loss: 0.302\n",
      "[44, 120] loss: 0.300\n",
      "[44, 180] loss: 0.304\n",
      "[44, 240] loss: 0.310\n",
      "[44, 300] loss: 0.315\n",
      "[44, 360] loss: 0.323\n",
      "Epoch: 44 -> Loss: 0.278142631054\n",
      "Epoch: 44 -> Test Accuracy: 86.5475\n",
      "[45, 60] loss: 0.295\n",
      "[45, 120] loss: 0.288\n",
      "[45, 180] loss: 0.320\n",
      "[45, 240] loss: 0.310\n",
      "[45, 300] loss: 0.307\n",
      "[45, 360] loss: 0.303\n",
      "Epoch: 45 -> Loss: 0.273495495319\n",
      "Epoch: 45 -> Test Accuracy: 86.545\n",
      "[46, 60] loss: 0.298\n",
      "[46, 120] loss: 0.302\n",
      "[46, 180] loss: 0.308\n",
      "[46, 240] loss: 0.322\n",
      "[46, 300] loss: 0.309\n",
      "[46, 360] loss: 0.310\n",
      "Epoch: 46 -> Loss: 0.282479614019\n",
      "Epoch: 46 -> Test Accuracy: 86.7825\n",
      "[47, 60] loss: 0.296\n",
      "[47, 120] loss: 0.293\n",
      "[47, 180] loss: 0.307\n",
      "[47, 240] loss: 0.290\n",
      "[47, 300] loss: 0.311\n",
      "[47, 360] loss: 0.314\n",
      "Epoch: 47 -> Loss: 0.389905512333\n",
      "Epoch: 47 -> Test Accuracy: 85.595\n",
      "[48, 60] loss: 0.289\n",
      "[48, 120] loss: 0.313\n",
      "[48, 180] loss: 0.303\n",
      "[48, 240] loss: 0.304\n",
      "[48, 300] loss: 0.307\n",
      "[48, 360] loss: 0.315\n",
      "Epoch: 48 -> Loss: 0.234692662954\n",
      "Epoch: 48 -> Test Accuracy: 86.9425\n",
      "[49, 60] loss: 0.280\n",
      "[49, 120] loss: 0.297\n",
      "[49, 180] loss: 0.310\n",
      "[49, 240] loss: 0.319\n",
      "[49, 300] loss: 0.302\n",
      "[49, 360] loss: 0.311\n",
      "Epoch: 49 -> Loss: 0.283383756876\n",
      "Epoch: 49 -> Test Accuracy: 85.935\n",
      "[50, 60] loss: 0.308\n",
      "[50, 120] loss: 0.305\n",
      "[50, 180] loss: 0.300\n",
      "[50, 240] loss: 0.312\n",
      "[50, 300] loss: 0.300\n",
      "[50, 360] loss: 0.302\n",
      "Epoch: 50 -> Loss: 0.30039536953\n",
      "Epoch: 50 -> Test Accuracy: 85.67\n",
      "[51, 60] loss: 0.283\n",
      "[51, 120] loss: 0.291\n",
      "[51, 180] loss: 0.307\n",
      "[51, 240] loss: 0.308\n",
      "[51, 300] loss: 0.307\n",
      "[51, 360] loss: 0.307\n",
      "Epoch: 51 -> Loss: 0.339302152395\n",
      "Epoch: 51 -> Test Accuracy: 86.7925\n",
      "[52, 60] loss: 0.286\n",
      "[52, 120] loss: 0.300\n",
      "[52, 180] loss: 0.319\n",
      "[52, 240] loss: 0.298\n",
      "[52, 300] loss: 0.302\n",
      "[52, 360] loss: 0.299\n",
      "Epoch: 52 -> Loss: 0.280481874943\n",
      "Epoch: 52 -> Test Accuracy: 86.695\n",
      "[53, 60] loss: 0.291\n",
      "[53, 120] loss: 0.302\n",
      "[53, 180] loss: 0.304\n",
      "[53, 240] loss: 0.310\n",
      "[53, 300] loss: 0.304\n",
      "[53, 360] loss: 0.300\n",
      "Epoch: 53 -> Loss: 0.247449919581\n",
      "Epoch: 53 -> Test Accuracy: 86.46\n",
      "[54, 60] loss: 0.300\n",
      "[54, 120] loss: 0.302\n",
      "[54, 180] loss: 0.303\n",
      "[54, 240] loss: 0.295\n",
      "[54, 300] loss: 0.304\n",
      "[54, 360] loss: 0.309\n",
      "Epoch: 54 -> Loss: 0.283528625965\n",
      "Epoch: 54 -> Test Accuracy: 86.6175\n",
      "[55, 60] loss: 0.279\n",
      "[55, 120] loss: 0.304\n",
      "[55, 180] loss: 0.308\n",
      "[55, 240] loss: 0.290\n",
      "[55, 300] loss: 0.313\n",
      "[55, 360] loss: 0.304\n",
      "Epoch: 55 -> Loss: 0.39961463213\n",
      "Epoch: 55 -> Test Accuracy: 86.1525\n",
      "[56, 60] loss: 0.294\n",
      "[56, 120] loss: 0.295\n",
      "[56, 180] loss: 0.304\n",
      "[56, 240] loss: 0.303\n",
      "[56, 300] loss: 0.300\n",
      "[56, 360] loss: 0.293\n",
      "Epoch: 56 -> Loss: 0.370287895203\n",
      "Epoch: 56 -> Test Accuracy: 87.07\n",
      "[57, 60] loss: 0.298\n",
      "[57, 120] loss: 0.297\n",
      "[57, 180] loss: 0.308\n",
      "[57, 240] loss: 0.306\n",
      "[57, 300] loss: 0.295\n",
      "[57, 360] loss: 0.299\n",
      "Epoch: 57 -> Loss: 0.381079703569\n",
      "Epoch: 57 -> Test Accuracy: 87.93\n",
      "[58, 60] loss: 0.277\n",
      "[58, 120] loss: 0.288\n",
      "[58, 180] loss: 0.301\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "rot_block3_loss_log, rot_block3_valid_accuracy_log, rot_block3_test_accuracy_log, rot_block3_max_accuracy, \\\n",
    "rot_block3_best_epoch = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], [60, 120, 160, 200], 0.9, 5e-4, net_block3, \n",
    "                                             criterion, trainloader, None, testloader, rot=['90', '180', '270'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train NonLinearClassifiers on feature map of net_3block\n",
    "block3_loss_log, block3_valid_accuracy_log, block3_test_accuracy_log, block3_max_accuracy, block3_best_epoch = \\\n",
    "tr.train_all_blocks(3, 10, [0.1, 0.02, 0.004, 0.0008], [20, 40, 45, 100], 0.9, 5e-4, net_block3, criterion, trainloader,\n",
    "                    None, testloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train ConvClassifiers on feature map of net_3block\n",
    "conv_block3_loss_log, conv_block3_valid_accuracy_log, conv_block3_test_accuracy_log, conv_block3_max_accuracy, \\\n",
    "conv_block3_best_epoch = tr.train_all_blocks(3, 10, [0.1, 0.02, 0.004, 0.0008], [35, 70, 85, 100], 0.9, 5e-4, net_block3, \n",
    "                                            criterion, trainloader, None, testloader, use_ConvClassifier=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename files\n",
    "fm.add_block_to_name(3, [100, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Block RotNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "net_block4 = RN.RotNet(num_classes=4, num_conv_block=4, add_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.135\n",
      "[1, 120] loss: 0.994\n",
      "[1, 180] loss: 0.928\n",
      "[1, 240] loss: 0.863\n",
      "[1, 300] loss: 0.821\n",
      "[1, 360] loss: 0.801\n",
      "Epoch: 1 -> Loss: 0.695880711079\n",
      "Epoch: 1 -> Test Accuracy: 67.845\n",
      "[2, 60] loss: 0.750\n",
      "[2, 120] loss: 0.740\n",
      "[2, 180] loss: 0.708\n",
      "[2, 240] loss: 0.680\n",
      "[2, 300] loss: 0.679\n",
      "[2, 360] loss: 0.630\n",
      "Epoch: 2 -> Loss: 0.624272525311\n",
      "Epoch: 2 -> Test Accuracy: 73.69\n",
      "[3, 60] loss: 0.605\n",
      "[3, 120] loss: 0.616\n",
      "[3, 180] loss: 0.610\n",
      "[3, 240] loss: 0.589\n",
      "[3, 300] loss: 0.596\n",
      "[3, 360] loss: 0.569\n",
      "Epoch: 3 -> Loss: 0.525554418564\n",
      "Epoch: 3 -> Test Accuracy: 77.6975\n",
      "[4, 60] loss: 0.557\n",
      "[4, 120] loss: 0.540\n",
      "[4, 180] loss: 0.556\n",
      "[4, 240] loss: 0.546\n",
      "[4, 300] loss: 0.524\n",
      "[4, 360] loss: 0.518\n",
      "Epoch: 4 -> Loss: 0.727146923542\n",
      "Epoch: 4 -> Test Accuracy: 79.8675\n",
      "[5, 60] loss: 0.497\n",
      "[5, 120] loss: 0.490\n",
      "[5, 180] loss: 0.507\n",
      "[5, 240] loss: 0.492\n",
      "[5, 300] loss: 0.498\n",
      "[5, 360] loss: 0.503\n",
      "Epoch: 5 -> Loss: 0.511142671108\n",
      "Epoch: 5 -> Test Accuracy: 81.56\n",
      "[6, 60] loss: 0.483\n",
      "[6, 120] loss: 0.485\n",
      "[6, 180] loss: 0.462\n",
      "[6, 240] loss: 0.477\n",
      "[6, 300] loss: 0.466\n",
      "[6, 360] loss: 0.464\n",
      "Epoch: 6 -> Loss: 0.326499342918\n",
      "Epoch: 6 -> Test Accuracy: 82.465\n",
      "[7, 60] loss: 0.447\n",
      "[7, 120] loss: 0.455\n",
      "[7, 180] loss: 0.444\n",
      "[7, 240] loss: 0.468\n",
      "[7, 300] loss: 0.452\n",
      "[7, 360] loss: 0.449\n",
      "Epoch: 7 -> Loss: 0.455152750015\n",
      "Epoch: 7 -> Test Accuracy: 82.095\n",
      "[8, 60] loss: 0.434\n",
      "[8, 120] loss: 0.448\n",
      "[8, 180] loss: 0.430\n",
      "[8, 240] loss: 0.442\n",
      "[8, 300] loss: 0.424\n",
      "[8, 360] loss: 0.437\n",
      "Epoch: 8 -> Loss: 0.468420416117\n",
      "Epoch: 8 -> Test Accuracy: 82.9425\n",
      "[9, 60] loss: 0.415\n",
      "[9, 120] loss: 0.434\n",
      "[9, 180] loss: 0.416\n",
      "[9, 240] loss: 0.426\n",
      "[9, 300] loss: 0.421\n",
      "[9, 360] loss: 0.419\n",
      "Epoch: 9 -> Loss: 0.435953140259\n",
      "Epoch: 9 -> Test Accuracy: 82.76\n",
      "[10, 60] loss: 0.404\n",
      "[10, 120] loss: 0.399\n",
      "[10, 180] loss: 0.414\n",
      "[10, 240] loss: 0.402\n",
      "[10, 300] loss: 0.415\n",
      "[10, 360] loss: 0.419\n",
      "Epoch: 10 -> Loss: 0.378109037876\n",
      "Epoch: 10 -> Test Accuracy: 83.9925\n",
      "[11, 60] loss: 0.390\n",
      "[11, 120] loss: 0.397\n",
      "[11, 180] loss: 0.402\n",
      "[11, 240] loss: 0.394\n",
      "[11, 300] loss: 0.397\n",
      "[11, 360] loss: 0.401\n",
      "Epoch: 11 -> Loss: 0.48371720314\n",
      "Epoch: 11 -> Test Accuracy: 84.105\n",
      "[12, 60] loss: 0.383\n",
      "[12, 120] loss: 0.380\n",
      "[12, 180] loss: 0.395\n",
      "[12, 240] loss: 0.393\n",
      "[12, 300] loss: 0.397\n",
      "[12, 360] loss: 0.390\n",
      "Epoch: 12 -> Loss: 0.369051873684\n",
      "Epoch: 12 -> Test Accuracy: 84.37\n",
      "[13, 60] loss: 0.375\n",
      "[13, 120] loss: 0.380\n",
      "[13, 180] loss: 0.393\n",
      "[13, 240] loss: 0.386\n",
      "[13, 300] loss: 0.388\n",
      "[13, 360] loss: 0.380\n",
      "Epoch: 13 -> Loss: 0.434260457754\n",
      "Epoch: 13 -> Test Accuracy: 84.0925\n",
      "[14, 60] loss: 0.370\n",
      "[14, 120] loss: 0.376\n",
      "[14, 180] loss: 0.382\n",
      "[14, 240] loss: 0.365\n",
      "[14, 300] loss: 0.382\n",
      "[14, 360] loss: 0.374\n",
      "Epoch: 14 -> Loss: 0.338451862335\n",
      "Epoch: 14 -> Test Accuracy: 83.655\n",
      "[15, 60] loss: 0.360\n",
      "[15, 120] loss: 0.376\n",
      "[15, 180] loss: 0.363\n",
      "[15, 240] loss: 0.372\n",
      "[15, 300] loss: 0.362\n",
      "[15, 360] loss: 0.377\n",
      "Epoch: 15 -> Loss: 0.412696033716\n",
      "Epoch: 15 -> Test Accuracy: 84.8225\n",
      "[16, 60] loss: 0.347\n",
      "[16, 120] loss: 0.364\n",
      "[16, 180] loss: 0.366\n",
      "[16, 240] loss: 0.369\n",
      "[16, 300] loss: 0.351\n",
      "[16, 360] loss: 0.384\n",
      "Epoch: 16 -> Loss: 0.360315650702\n",
      "Epoch: 16 -> Test Accuracy: 84.0675\n",
      "[17, 60] loss: 0.353\n",
      "[17, 120] loss: 0.348\n",
      "[17, 180] loss: 0.361\n",
      "[17, 240] loss: 0.357\n",
      "[17, 300] loss: 0.367\n",
      "[17, 360] loss: 0.362\n",
      "Epoch: 17 -> Loss: 0.332892596722\n",
      "Epoch: 17 -> Test Accuracy: 85.17\n",
      "[18, 60] loss: 0.345\n",
      "[18, 120] loss: 0.356\n",
      "[18, 180] loss: 0.353\n",
      "[18, 240] loss: 0.350\n",
      "[18, 300] loss: 0.344\n",
      "[18, 360] loss: 0.354\n",
      "Epoch: 18 -> Loss: 0.362794071436\n",
      "Epoch: 18 -> Test Accuracy: 85.26\n",
      "[19, 60] loss: 0.335\n",
      "[19, 120] loss: 0.347\n",
      "[19, 180] loss: 0.352\n",
      "[19, 240] loss: 0.353\n",
      "[19, 300] loss: 0.344\n",
      "[19, 360] loss: 0.361\n",
      "Epoch: 19 -> Loss: 0.307477176189\n",
      "Epoch: 19 -> Test Accuracy: 85.145\n",
      "[20, 60] loss: 0.339\n",
      "[20, 120] loss: 0.341\n",
      "[20, 180] loss: 0.340\n",
      "[20, 240] loss: 0.361\n",
      "[20, 300] loss: 0.351\n",
      "[20, 360] loss: 0.350\n",
      "Epoch: 20 -> Loss: 0.345066606998\n",
      "Epoch: 20 -> Test Accuracy: 85.6025\n",
      "[21, 60] loss: 0.334\n",
      "[21, 120] loss: 0.354\n",
      "[21, 180] loss: 0.341\n",
      "[21, 240] loss: 0.329\n",
      "[21, 300] loss: 0.353\n",
      "[21, 360] loss: 0.347\n",
      "Epoch: 21 -> Loss: 0.228520154953\n",
      "Epoch: 21 -> Test Accuracy: 85.6\n",
      "[22, 60] loss: 0.338\n",
      "[22, 120] loss: 0.335\n",
      "[22, 180] loss: 0.336\n",
      "[22, 240] loss: 0.351\n",
      "[22, 300] loss: 0.336\n",
      "[22, 360] loss: 0.347\n",
      "Epoch: 22 -> Loss: 0.31521320343\n",
      "Epoch: 22 -> Test Accuracy: 83.7775\n",
      "[23, 60] loss: 0.337\n",
      "[23, 120] loss: 0.338\n",
      "[23, 180] loss: 0.345\n",
      "[23, 240] loss: 0.328\n",
      "[23, 300] loss: 0.335\n",
      "[23, 360] loss: 0.345\n",
      "Epoch: 23 -> Loss: 0.262852013111\n",
      "Epoch: 23 -> Test Accuracy: 85.7125\n",
      "[24, 60] loss: 0.329\n",
      "[24, 120] loss: 0.334\n",
      "[24, 180] loss: 0.327\n",
      "[24, 240] loss: 0.346\n",
      "[24, 300] loss: 0.337\n",
      "[24, 360] loss: 0.337\n",
      "Epoch: 24 -> Loss: 0.274355739355\n",
      "Epoch: 24 -> Test Accuracy: 86.995\n",
      "[25, 60] loss: 0.315\n",
      "[25, 120] loss: 0.343\n",
      "[25, 180] loss: 0.325\n",
      "[25, 240] loss: 0.324\n",
      "[25, 300] loss: 0.342\n",
      "[25, 360] loss: 0.333\n",
      "Epoch: 25 -> Loss: 0.270978271961\n",
      "Epoch: 25 -> Test Accuracy: 85.99\n",
      "[26, 60] loss: 0.322\n",
      "[26, 120] loss: 0.337\n",
      "[26, 180] loss: 0.328\n",
      "[26, 240] loss: 0.338\n",
      "[26, 300] loss: 0.333\n",
      "[26, 360] loss: 0.331\n",
      "Epoch: 26 -> Loss: 0.296570003033\n",
      "Epoch: 26 -> Test Accuracy: 86.6525\n",
      "[27, 60] loss: 0.324\n",
      "[27, 120] loss: 0.336\n",
      "[27, 180] loss: 0.322\n",
      "[27, 240] loss: 0.320\n",
      "[27, 300] loss: 0.336\n",
      "[27, 360] loss: 0.335\n",
      "Epoch: 27 -> Loss: 0.35425901413\n",
      "Epoch: 27 -> Test Accuracy: 85.0575\n",
      "[28, 60] loss: 0.308\n",
      "[28, 120] loss: 0.328\n",
      "[28, 180] loss: 0.337\n",
      "[28, 240] loss: 0.329\n",
      "[28, 300] loss: 0.321\n",
      "[28, 360] loss: 0.335\n",
      "Epoch: 28 -> Loss: 0.452170759439\n",
      "Epoch: 28 -> Test Accuracy: 86.58\n",
      "[29, 60] loss: 0.314\n",
      "[29, 120] loss: 0.323\n",
      "[29, 180] loss: 0.299\n",
      "[29, 240] loss: 0.337\n",
      "[29, 300] loss: 0.334\n",
      "[29, 360] loss: 0.327\n",
      "Epoch: 29 -> Loss: 0.351872295141\n",
      "Epoch: 29 -> Test Accuracy: 86.575\n",
      "[30, 60] loss: 0.303\n",
      "[30, 120] loss: 0.317\n",
      "[30, 180] loss: 0.341\n",
      "[30, 240] loss: 0.318\n",
      "[30, 300] loss: 0.326\n",
      "[30, 360] loss: 0.325\n",
      "Epoch: 30 -> Loss: 0.346842229366\n",
      "Epoch: 30 -> Test Accuracy: 86.25\n",
      "[31, 60] loss: 0.302\n",
      "[31, 120] loss: 0.313\n",
      "[31, 180] loss: 0.331\n",
      "[31, 240] loss: 0.335\n",
      "[31, 300] loss: 0.322\n",
      "[31, 360] loss: 0.323\n",
      "Epoch: 31 -> Loss: 0.37765288353\n",
      "Epoch: 31 -> Test Accuracy: 86.225\n",
      "[32, 60] loss: 0.320\n",
      "[32, 120] loss: 0.316\n",
      "[32, 180] loss: 0.335\n",
      "[32, 240] loss: 0.316\n",
      "[32, 300] loss: 0.319\n",
      "[32, 360] loss: 0.328\n",
      "Epoch: 32 -> Loss: 0.320212423801\n",
      "Epoch: 32 -> Test Accuracy: 86.585\n",
      "[33, 60] loss: 0.321\n",
      "[33, 120] loss: 0.314\n",
      "[33, 180] loss: 0.325\n",
      "[33, 240] loss: 0.307\n",
      "[33, 300] loss: 0.313\n",
      "[33, 360] loss: 0.324\n",
      "Epoch: 33 -> Loss: 0.422154098749\n",
      "Epoch: 33 -> Test Accuracy: 86.46\n",
      "[34, 60] loss: 0.306\n",
      "[34, 120] loss: 0.311\n",
      "[34, 180] loss: 0.314\n",
      "[34, 240] loss: 0.328\n",
      "[34, 300] loss: 0.312\n",
      "[34, 360] loss: 0.331\n",
      "Epoch: 34 -> Loss: 0.2321177423\n",
      "Epoch: 34 -> Test Accuracy: 87.0575\n",
      "[35, 60] loss: 0.308\n",
      "[35, 120] loss: 0.316\n",
      "[35, 180] loss: 0.323\n",
      "[35, 240] loss: 0.309\n",
      "[35, 300] loss: 0.314\n",
      "[35, 360] loss: 0.319\n",
      "Epoch: 35 -> Loss: 0.256613016129\n",
      "Epoch: 35 -> Test Accuracy: 86.805\n",
      "[36, 60] loss: 0.297\n",
      "[36, 120] loss: 0.309\n",
      "[36, 180] loss: 0.318\n",
      "[36, 240] loss: 0.323\n",
      "[36, 300] loss: 0.318\n",
      "[36, 360] loss: 0.314\n",
      "Epoch: 36 -> Loss: 0.39465624094\n",
      "Epoch: 36 -> Test Accuracy: 86.105\n",
      "[37, 60] loss: 0.304\n",
      "[37, 120] loss: 0.314\n",
      "[37, 180] loss: 0.317\n",
      "[37, 240] loss: 0.311\n",
      "[37, 300] loss: 0.310\n",
      "[37, 360] loss: 0.324\n",
      "Epoch: 37 -> Loss: 0.453603923321\n",
      "Epoch: 37 -> Test Accuracy: 86.6375\n",
      "[38, 60] loss: 0.303\n",
      "[38, 120] loss: 0.316\n",
      "[38, 180] loss: 0.322\n",
      "[38, 240] loss: 0.306\n",
      "[38, 300] loss: 0.309\n",
      "[38, 360] loss: 0.311\n",
      "Epoch: 38 -> Loss: 0.408038198948\n",
      "Epoch: 38 -> Test Accuracy: 85.605\n",
      "[39, 60] loss: 0.306\n",
      "[39, 120] loss: 0.310\n",
      "[39, 180] loss: 0.311\n",
      "[39, 240] loss: 0.308\n",
      "[39, 300] loss: 0.318\n",
      "[39, 360] loss: 0.315\n",
      "Epoch: 39 -> Loss: 0.313579142094\n",
      "Epoch: 39 -> Test Accuracy: 86.7575\n",
      "[40, 60] loss: 0.305\n",
      "[40, 120] loss: 0.315\n",
      "[40, 180] loss: 0.312\n",
      "[40, 240] loss: 0.301\n",
      "[40, 300] loss: 0.320\n",
      "[40, 360] loss: 0.319\n",
      "Epoch: 40 -> Loss: 0.353031694889\n",
      "Epoch: 40 -> Test Accuracy: 86.495\n",
      "[41, 60] loss: 0.293\n",
      "[41, 120] loss: 0.312\n",
      "[41, 180] loss: 0.310\n",
      "[41, 240] loss: 0.297\n",
      "[41, 300] loss: 0.315\n",
      "[41, 360] loss: 0.317\n",
      "Epoch: 41 -> Loss: 0.355686336756\n",
      "Epoch: 41 -> Test Accuracy: 87.1025\n",
      "[42, 60] loss: 0.291\n",
      "[42, 120] loss: 0.296\n",
      "[42, 180] loss: 0.329\n",
      "[42, 240] loss: 0.312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 300] loss: 0.309\n",
      "[42, 360] loss: 0.312\n",
      "Epoch: 42 -> Loss: 0.231715485454\n",
      "Epoch: 42 -> Test Accuracy: 87.18\n",
      "[43, 60] loss: 0.307\n",
      "[43, 120] loss: 0.304\n",
      "[43, 180] loss: 0.313\n",
      "[43, 240] loss: 0.315\n",
      "[43, 300] loss: 0.305\n",
      "[43, 360] loss: 0.305\n",
      "Epoch: 43 -> Loss: 0.375260204077\n",
      "Epoch: 43 -> Test Accuracy: 86.04\n",
      "[44, 60] loss: 0.310\n",
      "[44, 120] loss: 0.303\n",
      "[44, 180] loss: 0.303\n",
      "[44, 240] loss: 0.309\n",
      "[44, 300] loss: 0.321\n",
      "[44, 360] loss: 0.307\n",
      "Epoch: 44 -> Loss: 0.373315036297\n",
      "Epoch: 44 -> Test Accuracy: 86.4325\n",
      "[45, 60] loss: 0.301\n",
      "[45, 120] loss: 0.315\n",
      "[45, 180] loss: 0.308\n",
      "[45, 240] loss: 0.297\n",
      "[45, 300] loss: 0.306\n",
      "[45, 360] loss: 0.318\n",
      "Epoch: 45 -> Loss: 0.360315144062\n",
      "Epoch: 45 -> Test Accuracy: 86.62\n",
      "[46, 60] loss: 0.298\n",
      "[46, 120] loss: 0.300\n",
      "[46, 180] loss: 0.315\n",
      "[46, 240] loss: 0.304\n",
      "[46, 300] loss: 0.308\n",
      "[46, 360] loss: 0.306\n",
      "Epoch: 46 -> Loss: 0.281904876232\n",
      "Epoch: 46 -> Test Accuracy: 86.3025\n",
      "[47, 60] loss: 0.303\n",
      "[47, 120] loss: 0.308\n",
      "[47, 180] loss: 0.303\n",
      "[47, 240] loss: 0.300\n",
      "[47, 300] loss: 0.312\n",
      "[47, 360] loss: 0.303\n",
      "Epoch: 47 -> Loss: 0.295614421368\n",
      "Epoch: 47 -> Test Accuracy: 86.2\n",
      "[48, 60] loss: 0.296\n",
      "[48, 120] loss: 0.301\n",
      "[48, 180] loss: 0.297\n",
      "[48, 240] loss: 0.316\n",
      "[48, 300] loss: 0.308\n",
      "[48, 360] loss: 0.314\n",
      "Epoch: 48 -> Loss: 0.261360526085\n",
      "Epoch: 48 -> Test Accuracy: 85.4725\n",
      "[49, 60] loss: 0.292\n",
      "[49, 120] loss: 0.306\n",
      "[49, 180] loss: 0.323\n",
      "[49, 240] loss: 0.318\n",
      "[49, 300] loss: 0.311\n",
      "[49, 360] loss: 0.299\n",
      "Epoch: 49 -> Loss: 0.271177113056\n",
      "Epoch: 49 -> Test Accuracy: 86.945\n",
      "[50, 60] loss: 0.289\n",
      "[50, 120] loss: 0.287\n",
      "[50, 180] loss: 0.308\n",
      "[50, 240] loss: 0.312\n",
      "[50, 300] loss: 0.301\n",
      "[50, 360] loss: 0.312\n",
      "Epoch: 50 -> Loss: 0.33122587204\n",
      "Epoch: 50 -> Test Accuracy: 86.765\n",
      "[51, 60] loss: 0.297\n",
      "[51, 120] loss: 0.296\n",
      "[51, 180] loss: 0.303\n",
      "[51, 240] loss: 0.319\n",
      "[51, 300] loss: 0.303\n",
      "[51, 360] loss: 0.298\n",
      "Epoch: 51 -> Loss: 0.439655780792\n",
      "Epoch: 51 -> Test Accuracy: 85.98\n",
      "[52, 60] loss: 0.293\n",
      "[52, 120] loss: 0.299\n",
      "[52, 180] loss: 0.302\n",
      "[52, 240] loss: 0.295\n",
      "[52, 300] loss: 0.309\n",
      "[52, 360] loss: 0.312\n",
      "Epoch: 52 -> Loss: 0.294715940952\n",
      "Epoch: 52 -> Test Accuracy: 86.6375\n",
      "[53, 60] loss: 0.288\n",
      "[53, 120] loss: 0.291\n",
      "[53, 180] loss: 0.292\n",
      "[53, 240] loss: 0.313\n",
      "[53, 300] loss: 0.309\n",
      "[53, 360] loss: 0.309\n",
      "Epoch: 53 -> Loss: 0.286694973707\n",
      "Epoch: 53 -> Test Accuracy: 86.715\n",
      "[54, 60] loss: 0.289\n",
      "[54, 120] loss: 0.304\n",
      "[54, 180] loss: 0.309\n",
      "[54, 240] loss: 0.313\n",
      "[54, 300] loss: 0.288\n",
      "[54, 360] loss: 0.311\n",
      "Epoch: 54 -> Loss: 0.20824277401\n",
      "Epoch: 54 -> Test Accuracy: 86.13\n",
      "[55, 60] loss: 0.286\n",
      "[55, 120] loss: 0.300\n",
      "[55, 180] loss: 0.305\n",
      "[55, 240] loss: 0.299\n",
      "[55, 300] loss: 0.309\n",
      "[55, 360] loss: 0.311\n",
      "Epoch: 55 -> Loss: 0.312124401331\n",
      "Epoch: 55 -> Test Accuracy: 86.8725\n",
      "[56, 60] loss: 0.304\n",
      "[56, 120] loss: 0.281\n",
      "[56, 180] loss: 0.303\n",
      "[56, 240] loss: 0.292\n",
      "[56, 300] loss: 0.309\n",
      "[56, 360] loss: 0.302\n",
      "Epoch: 56 -> Loss: 0.36397460103\n",
      "Epoch: 56 -> Test Accuracy: 86.06\n",
      "[57, 60] loss: 0.305\n",
      "[57, 120] loss: 0.285\n",
      "[57, 180] loss: 0.297\n",
      "[57, 240] loss: 0.303\n",
      "[57, 300] loss: 0.306\n",
      "[57, 360] loss: 0.323\n",
      "Epoch: 57 -> Loss: 0.317247629166\n",
      "Epoch: 57 -> Test Accuracy: 87.3325\n",
      "[58, 60] loss: 0.280\n",
      "[58, 120] loss: 0.296\n",
      "[58, 180] loss: 0.296\n",
      "[58, 240] loss: 0.300\n",
      "[58, 300] loss: 0.312\n",
      "[58, 360] loss: 0.300\n",
      "Epoch: 58 -> Loss: 0.273131251335\n",
      "Epoch: 58 -> Test Accuracy: 87.0725\n",
      "[59, 60] loss: 0.288\n",
      "[59, 120] loss: 0.300\n",
      "[59, 180] loss: 0.296\n",
      "[59, 240] loss: 0.294\n",
      "[59, 300] loss: 0.286\n",
      "[59, 360] loss: 0.317\n",
      "Epoch: 59 -> Loss: 0.333387941122\n",
      "Epoch: 59 -> Test Accuracy: 86.1925\n",
      "[60, 60] loss: 0.303\n",
      "[60, 120] loss: 0.288\n",
      "[60, 180] loss: 0.295\n",
      "[60, 240] loss: 0.307\n",
      "[60, 300] loss: 0.298\n",
      "[60, 360] loss: 0.314\n",
      "Epoch: 60 -> Loss: 0.346051424742\n",
      "Epoch: 60 -> Test Accuracy: 87.6775\n",
      "[61, 60] loss: 0.222\n",
      "[61, 120] loss: 0.193\n",
      "[61, 180] loss: 0.190\n",
      "[61, 240] loss: 0.191\n",
      "[61, 300] loss: 0.178\n",
      "[61, 360] loss: 0.175\n",
      "Epoch: 61 -> Loss: 0.161712318659\n",
      "Epoch: 61 -> Test Accuracy: 90.9125\n",
      "[62, 60] loss: 0.164\n",
      "[62, 120] loss: 0.166\n",
      "[62, 180] loss: 0.175\n",
      "[62, 240] loss: 0.158\n",
      "[62, 300] loss: 0.160\n",
      "[62, 360] loss: 0.163\n",
      "Epoch: 62 -> Loss: 0.192591071129\n",
      "Epoch: 62 -> Test Accuracy: 91.005\n",
      "[63, 60] loss: 0.149\n",
      "[63, 120] loss: 0.150\n",
      "[63, 180] loss: 0.158\n",
      "[63, 240] loss: 0.157\n",
      "[63, 300] loss: 0.166\n",
      "[63, 360] loss: 0.158\n",
      "Epoch: 63 -> Loss: 0.183241561055\n",
      "Epoch: 63 -> Test Accuracy: 90.75\n",
      "[64, 60] loss: 0.148\n",
      "[64, 120] loss: 0.142\n",
      "[64, 180] loss: 0.153\n",
      "[64, 240] loss: 0.148\n",
      "[64, 300] loss: 0.158\n",
      "[64, 360] loss: 0.153\n",
      "Epoch: 64 -> Loss: 0.106767296791\n",
      "Epoch: 64 -> Test Accuracy: 91.305\n",
      "[65, 60] loss: 0.137\n",
      "[65, 120] loss: 0.139\n",
      "[65, 180] loss: 0.149\n",
      "[65, 240] loss: 0.151\n",
      "[65, 300] loss: 0.145\n",
      "[65, 360] loss: 0.149\n",
      "Epoch: 65 -> Loss: 0.154582515359\n",
      "Epoch: 65 -> Test Accuracy: 90.345\n",
      "[66, 60] loss: 0.143\n",
      "[66, 120] loss: 0.136\n",
      "[66, 180] loss: 0.144\n",
      "[66, 240] loss: 0.154\n",
      "[66, 300] loss: 0.144\n",
      "[66, 360] loss: 0.148\n",
      "Epoch: 66 -> Loss: 0.182747811079\n",
      "Epoch: 66 -> Test Accuracy: 90.82\n",
      "[67, 60] loss: 0.140\n",
      "[67, 120] loss: 0.139\n",
      "[67, 180] loss: 0.139\n",
      "[67, 240] loss: 0.145\n",
      "[67, 300] loss: 0.140\n",
      "[67, 360] loss: 0.150\n",
      "Epoch: 67 -> Loss: 0.153778672218\n",
      "Epoch: 67 -> Test Accuracy: 90.34\n",
      "[68, 60] loss: 0.140\n",
      "[68, 120] loss: 0.135\n",
      "[68, 180] loss: 0.143\n",
      "[68, 240] loss: 0.149\n",
      "[68, 300] loss: 0.153\n",
      "[68, 360] loss: 0.148\n",
      "Epoch: 68 -> Loss: 0.061506383121\n",
      "Epoch: 68 -> Test Accuracy: 91.085\n",
      "[69, 60] loss: 0.133\n",
      "[69, 120] loss: 0.131\n",
      "[69, 180] loss: 0.146\n",
      "[69, 240] loss: 0.142\n",
      "[69, 300] loss: 0.140\n",
      "[69, 360] loss: 0.157\n",
      "Epoch: 69 -> Loss: 0.222689345479\n",
      "Epoch: 69 -> Test Accuracy: 90.145\n",
      "[70, 60] loss: 0.128\n",
      "[70, 120] loss: 0.135\n",
      "[70, 180] loss: 0.146\n",
      "[70, 240] loss: 0.150\n",
      "[70, 300] loss: 0.151\n",
      "[70, 360] loss: 0.145\n",
      "Epoch: 70 -> Loss: 0.0849896520376\n",
      "Epoch: 70 -> Test Accuracy: 90.5775\n",
      "[71, 60] loss: 0.132\n",
      "[71, 120] loss: 0.133\n",
      "[71, 180] loss: 0.144\n",
      "[71, 240] loss: 0.151\n",
      "[71, 300] loss: 0.156\n",
      "[71, 360] loss: 0.144\n",
      "Epoch: 71 -> Loss: 0.130873352289\n",
      "Epoch: 71 -> Test Accuracy: 90.37\n",
      "[72, 60] loss: 0.139\n",
      "[72, 120] loss: 0.139\n",
      "[72, 180] loss: 0.140\n",
      "[72, 240] loss: 0.150\n",
      "[72, 300] loss: 0.147\n",
      "[72, 360] loss: 0.151\n",
      "Epoch: 72 -> Loss: 0.174063414335\n",
      "Epoch: 72 -> Test Accuracy: 90.59\n",
      "[73, 60] loss: 0.131\n",
      "[73, 120] loss: 0.141\n",
      "[73, 180] loss: 0.147\n",
      "[73, 240] loss: 0.155\n",
      "[73, 300] loss: 0.152\n",
      "[73, 360] loss: 0.142\n",
      "Epoch: 73 -> Loss: 0.155378773808\n",
      "Epoch: 73 -> Test Accuracy: 90.735\n",
      "[74, 60] loss: 0.134\n",
      "[74, 120] loss: 0.136\n",
      "[74, 180] loss: 0.147\n",
      "[74, 240] loss: 0.149\n",
      "[74, 300] loss: 0.150\n",
      "[74, 360] loss: 0.147\n",
      "Epoch: 74 -> Loss: 0.175812885165\n",
      "Epoch: 74 -> Test Accuracy: 89.695\n",
      "[75, 60] loss: 0.139\n",
      "[75, 120] loss: 0.150\n",
      "[75, 180] loss: 0.145\n",
      "[75, 240] loss: 0.154\n",
      "[75, 300] loss: 0.143\n",
      "[75, 360] loss: 0.148\n",
      "Epoch: 75 -> Loss: 0.1407122612\n",
      "Epoch: 75 -> Test Accuracy: 90.505\n",
      "[76, 60] loss: 0.130\n",
      "[76, 120] loss: 0.148\n",
      "[76, 180] loss: 0.147\n",
      "[76, 240] loss: 0.143\n",
      "[76, 300] loss: 0.152\n",
      "[76, 360] loss: 0.152\n",
      "Epoch: 76 -> Loss: 0.179979801178\n",
      "Epoch: 76 -> Test Accuracy: 90.2\n",
      "[77, 60] loss: 0.143\n",
      "[77, 120] loss: 0.137\n",
      "[77, 180] loss: 0.135\n",
      "[77, 240] loss: 0.148\n",
      "[77, 300] loss: 0.156\n",
      "[77, 360] loss: 0.150\n",
      "Epoch: 77 -> Loss: 0.245532184839\n",
      "Epoch: 77 -> Test Accuracy: 90.635\n",
      "[78, 60] loss: 0.139\n",
      "[78, 120] loss: 0.144\n",
      "[78, 180] loss: 0.135\n",
      "[78, 240] loss: 0.145\n",
      "[78, 300] loss: 0.139\n",
      "[78, 360] loss: 0.156\n",
      "Epoch: 78 -> Loss: 0.291426569223\n",
      "Epoch: 78 -> Test Accuracy: 89.975\n",
      "[79, 60] loss: 0.138\n",
      "[79, 120] loss: 0.134\n",
      "[79, 180] loss: 0.147\n",
      "[79, 240] loss: 0.148\n",
      "[79, 300] loss: 0.149\n",
      "[79, 360] loss: 0.145\n",
      "Epoch: 79 -> Loss: 0.130543172359\n",
      "Epoch: 79 -> Test Accuracy: 89.5775\n",
      "[80, 60] loss: 0.132\n",
      "[80, 120] loss: 0.133\n",
      "[80, 180] loss: 0.156\n",
      "[80, 240] loss: 0.144\n",
      "[80, 300] loss: 0.147\n",
      "[80, 360] loss: 0.154\n",
      "Epoch: 80 -> Loss: 0.109758213162\n",
      "Epoch: 80 -> Test Accuracy: 89.8975\n",
      "[81, 60] loss: 0.135\n",
      "[81, 120] loss: 0.144\n",
      "[81, 180] loss: 0.144\n",
      "[81, 240] loss: 0.144\n",
      "[81, 300] loss: 0.144\n",
      "[81, 360] loss: 0.155\n",
      "Epoch: 81 -> Loss: 0.181555747986\n",
      "Epoch: 81 -> Test Accuracy: 89.9625\n",
      "[82, 60] loss: 0.142\n",
      "[82, 120] loss: 0.133\n",
      "[82, 180] loss: 0.145\n",
      "[82, 240] loss: 0.148\n",
      "[82, 300] loss: 0.145\n",
      "[82, 360] loss: 0.148\n",
      "Epoch: 82 -> Loss: 0.192878499627\n",
      "Epoch: 82 -> Test Accuracy: 90.11\n",
      "[83, 60] loss: 0.135\n",
      "[83, 120] loss: 0.132\n",
      "[83, 180] loss: 0.143\n",
      "[83, 240] loss: 0.140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83, 300] loss: 0.152\n",
      "[83, 360] loss: 0.150\n",
      "Epoch: 83 -> Loss: 0.149241298437\n",
      "Epoch: 83 -> Test Accuracy: 90.4325\n",
      "[84, 60] loss: 0.139\n",
      "[84, 120] loss: 0.136\n",
      "[84, 180] loss: 0.147\n",
      "[84, 240] loss: 0.147\n",
      "[84, 300] loss: 0.146\n",
      "[84, 360] loss: 0.151\n",
      "Epoch: 84 -> Loss: 0.138423159719\n",
      "Epoch: 84 -> Test Accuracy: 90.105\n",
      "[85, 60] loss: 0.134\n",
      "[85, 120] loss: 0.144\n",
      "[85, 180] loss: 0.138\n",
      "[85, 240] loss: 0.148\n",
      "[85, 300] loss: 0.135\n",
      "[85, 360] loss: 0.151\n",
      "Epoch: 85 -> Loss: 0.175467908382\n",
      "Epoch: 85 -> Test Accuracy: 90.2325\n",
      "[86, 60] loss: 0.134\n",
      "[86, 120] loss: 0.141\n",
      "[86, 180] loss: 0.145\n",
      "[86, 240] loss: 0.142\n",
      "[86, 300] loss: 0.144\n",
      "[86, 360] loss: 0.157\n",
      "Epoch: 86 -> Loss: 0.112452127039\n",
      "Epoch: 86 -> Test Accuracy: 90.095\n",
      "[87, 60] loss: 0.131\n",
      "[87, 120] loss: 0.136\n",
      "[87, 180] loss: 0.150\n",
      "[87, 240] loss: 0.140\n",
      "[87, 300] loss: 0.148\n",
      "[87, 360] loss: 0.146\n",
      "Epoch: 87 -> Loss: 0.0645577311516\n",
      "Epoch: 87 -> Test Accuracy: 90.24\n",
      "[88, 60] loss: 0.132\n",
      "[88, 120] loss: 0.135\n",
      "[88, 180] loss: 0.154\n",
      "[88, 240] loss: 0.146\n",
      "[88, 300] loss: 0.150\n",
      "[88, 360] loss: 0.145\n",
      "Epoch: 88 -> Loss: 0.131883531809\n",
      "Epoch: 88 -> Test Accuracy: 89.97\n",
      "[89, 60] loss: 0.133\n",
      "[89, 120] loss: 0.130\n",
      "[89, 180] loss: 0.143\n",
      "[89, 240] loss: 0.149\n",
      "[89, 300] loss: 0.137\n",
      "[89, 360] loss: 0.148\n",
      "Epoch: 89 -> Loss: 0.117345198989\n",
      "Epoch: 89 -> Test Accuracy: 90.375\n",
      "[90, 60] loss: 0.128\n",
      "[90, 120] loss: 0.133\n",
      "[90, 180] loss: 0.142\n",
      "[90, 240] loss: 0.143\n",
      "[90, 300] loss: 0.148\n",
      "[90, 360] loss: 0.148\n",
      "Epoch: 90 -> Loss: 0.178715616465\n",
      "Epoch: 90 -> Test Accuracy: 90.505\n",
      "[91, 60] loss: 0.130\n",
      "[91, 120] loss: 0.132\n",
      "[91, 180] loss: 0.148\n",
      "[91, 240] loss: 0.134\n",
      "[91, 300] loss: 0.147\n",
      "[91, 360] loss: 0.142\n",
      "Epoch: 91 -> Loss: 0.190542846918\n",
      "Epoch: 91 -> Test Accuracy: 90.165\n",
      "[92, 60] loss: 0.129\n",
      "[92, 120] loss: 0.139\n",
      "[92, 180] loss: 0.142\n",
      "[92, 240] loss: 0.141\n",
      "[92, 300] loss: 0.142\n",
      "[92, 360] loss: 0.143\n",
      "Epoch: 92 -> Loss: 0.145902186632\n",
      "Epoch: 92 -> Test Accuracy: 90.68\n",
      "[93, 60] loss: 0.131\n",
      "[93, 120] loss: 0.132\n",
      "[93, 180] loss: 0.138\n",
      "[93, 240] loss: 0.147\n",
      "[93, 300] loss: 0.137\n",
      "[93, 360] loss: 0.150\n",
      "Epoch: 93 -> Loss: 0.0823304057121\n",
      "Epoch: 93 -> Test Accuracy: 90.2675\n",
      "[94, 60] loss: 0.125\n",
      "[94, 120] loss: 0.137\n",
      "[94, 180] loss: 0.136\n",
      "[94, 240] loss: 0.140\n",
      "[94, 300] loss: 0.144\n",
      "[94, 360] loss: 0.143\n",
      "Epoch: 94 -> Loss: 0.0809862017632\n",
      "Epoch: 94 -> Test Accuracy: 90.2125\n",
      "[95, 60] loss: 0.131\n",
      "[95, 120] loss: 0.131\n",
      "[95, 180] loss: 0.144\n",
      "[95, 240] loss: 0.135\n",
      "[95, 300] loss: 0.148\n",
      "[95, 360] loss: 0.146\n",
      "Epoch: 95 -> Loss: 0.118455789983\n",
      "Epoch: 95 -> Test Accuracy: 90.275\n",
      "[96, 60] loss: 0.133\n",
      "[96, 120] loss: 0.130\n",
      "[96, 180] loss: 0.146\n",
      "[96, 240] loss: 0.137\n",
      "[96, 300] loss: 0.140\n",
      "[96, 360] loss: 0.142\n",
      "Epoch: 96 -> Loss: 0.0918963328004\n",
      "Epoch: 96 -> Test Accuracy: 90.2925\n",
      "[97, 60] loss: 0.117\n",
      "[97, 120] loss: 0.136\n",
      "[97, 180] loss: 0.141\n",
      "[97, 240] loss: 0.135\n",
      "[97, 300] loss: 0.145\n",
      "[97, 360] loss: 0.146\n",
      "Epoch: 97 -> Loss: 0.117722533643\n",
      "Epoch: 97 -> Test Accuracy: 89.895\n",
      "[98, 60] loss: 0.125\n",
      "[98, 120] loss: 0.135\n",
      "[98, 180] loss: 0.132\n",
      "[98, 240] loss: 0.144\n",
      "[98, 300] loss: 0.142\n",
      "[98, 360] loss: 0.141\n",
      "Epoch: 98 -> Loss: 0.18538479507\n",
      "Epoch: 98 -> Test Accuracy: 90.3875\n",
      "[99, 60] loss: 0.130\n",
      "[99, 120] loss: 0.133\n",
      "[99, 180] loss: 0.138\n",
      "[99, 240] loss: 0.144\n",
      "[99, 300] loss: 0.140\n",
      "[99, 360] loss: 0.137\n",
      "Epoch: 99 -> Loss: 0.128938630223\n",
      "Epoch: 99 -> Test Accuracy: 89.915\n",
      "[100, 60] loss: 0.131\n",
      "[100, 120] loss: 0.133\n",
      "[100, 180] loss: 0.137\n",
      "[100, 240] loss: 0.133\n",
      "[100, 300] loss: 0.145\n",
      "[100, 360] loss: 0.145\n",
      "Epoch: 100 -> Loss: 0.18970964849\n",
      "Epoch: 100 -> Test Accuracy: 89.8975\n",
      "[101, 60] loss: 0.121\n",
      "[101, 120] loss: 0.135\n",
      "[101, 180] loss: 0.138\n",
      "[101, 240] loss: 0.134\n",
      "[101, 300] loss: 0.148\n",
      "[101, 360] loss: 0.145\n",
      "Epoch: 101 -> Loss: 0.108142279088\n",
      "Epoch: 101 -> Test Accuracy: 89.9275\n",
      "[102, 60] loss: 0.130\n",
      "[102, 120] loss: 0.131\n",
      "[102, 180] loss: 0.140\n",
      "[102, 240] loss: 0.142\n",
      "[102, 300] loss: 0.133\n",
      "[102, 360] loss: 0.140\n",
      "Epoch: 102 -> Loss: 0.0893251076341\n",
      "Epoch: 102 -> Test Accuracy: 90.1\n",
      "[103, 60] loss: 0.128\n",
      "[103, 120] loss: 0.132\n",
      "[103, 180] loss: 0.133\n",
      "[103, 240] loss: 0.133\n",
      "[103, 300] loss: 0.139\n",
      "[103, 360] loss: 0.148\n",
      "Epoch: 103 -> Loss: 0.136608690023\n",
      "Epoch: 103 -> Test Accuracy: 90.59\n",
      "[104, 60] loss: 0.134\n",
      "[104, 120] loss: 0.138\n",
      "[104, 180] loss: 0.130\n",
      "[104, 240] loss: 0.139\n",
      "[104, 300] loss: 0.142\n",
      "[104, 360] loss: 0.140\n",
      "Epoch: 104 -> Loss: 0.124764300883\n",
      "Epoch: 104 -> Test Accuracy: 90.47\n",
      "[105, 60] loss: 0.119\n",
      "[105, 120] loss: 0.126\n",
      "[105, 180] loss: 0.138\n",
      "[105, 240] loss: 0.138\n",
      "[105, 300] loss: 0.140\n",
      "[105, 360] loss: 0.134\n",
      "Epoch: 105 -> Loss: 0.185598760843\n",
      "Epoch: 105 -> Test Accuracy: 90.085\n",
      "[106, 60] loss: 0.125\n",
      "[106, 120] loss: 0.126\n",
      "[106, 180] loss: 0.139\n",
      "[106, 240] loss: 0.136\n",
      "[106, 300] loss: 0.139\n",
      "[106, 360] loss: 0.142\n",
      "Epoch: 106 -> Loss: 0.220004484057\n",
      "Epoch: 106 -> Test Accuracy: 90.22\n",
      "[107, 60] loss: 0.128\n",
      "[107, 120] loss: 0.126\n",
      "[107, 180] loss: 0.131\n",
      "[107, 240] loss: 0.139\n",
      "[107, 300] loss: 0.136\n",
      "[107, 360] loss: 0.144\n",
      "Epoch: 107 -> Loss: 0.118046499789\n",
      "Epoch: 107 -> Test Accuracy: 90.43\n",
      "[108, 60] loss: 0.133\n",
      "[108, 120] loss: 0.123\n",
      "[108, 180] loss: 0.133\n",
      "[108, 240] loss: 0.126\n",
      "[108, 300] loss: 0.142\n",
      "[108, 360] loss: 0.139\n",
      "Epoch: 108 -> Loss: 0.0912118330598\n",
      "Epoch: 108 -> Test Accuracy: 90.035\n",
      "[109, 60] loss: 0.131\n",
      "[109, 120] loss: 0.129\n",
      "[109, 180] loss: 0.139\n",
      "[109, 240] loss: 0.138\n",
      "[109, 300] loss: 0.126\n",
      "[109, 360] loss: 0.135\n",
      "Epoch: 109 -> Loss: 0.092477209866\n",
      "Epoch: 109 -> Test Accuracy: 90.155\n",
      "[110, 60] loss: 0.119\n",
      "[110, 120] loss: 0.129\n",
      "[110, 180] loss: 0.131\n",
      "[110, 240] loss: 0.136\n",
      "[110, 300] loss: 0.136\n",
      "[110, 360] loss: 0.143\n",
      "Epoch: 110 -> Loss: 0.0841803774238\n",
      "Epoch: 110 -> Test Accuracy: 90.415\n",
      "[111, 60] loss: 0.121\n",
      "[111, 120] loss: 0.127\n",
      "[111, 180] loss: 0.126\n",
      "[111, 240] loss: 0.137\n",
      "[111, 300] loss: 0.137\n",
      "[111, 360] loss: 0.142\n",
      "Epoch: 111 -> Loss: 0.133289575577\n",
      "Epoch: 111 -> Test Accuracy: 89.66\n",
      "[112, 60] loss: 0.119\n",
      "[112, 120] loss: 0.126\n",
      "[112, 180] loss: 0.126\n",
      "[112, 240] loss: 0.134\n",
      "[112, 300] loss: 0.139\n",
      "[112, 360] loss: 0.145\n",
      "Epoch: 112 -> Loss: 0.129071906209\n",
      "Epoch: 112 -> Test Accuracy: 90.175\n",
      "[113, 60] loss: 0.118\n",
      "[113, 120] loss: 0.124\n",
      "[113, 180] loss: 0.135\n",
      "[113, 240] loss: 0.128\n",
      "[113, 300] loss: 0.141\n",
      "[113, 360] loss: 0.138\n",
      "Epoch: 113 -> Loss: 0.117433905602\n",
      "Epoch: 113 -> Test Accuracy: 90.3525\n",
      "[114, 60] loss: 0.113\n",
      "[114, 120] loss: 0.124\n",
      "[114, 180] loss: 0.133\n",
      "[114, 240] loss: 0.144\n",
      "[114, 300] loss: 0.132\n",
      "[114, 360] loss: 0.135\n",
      "Epoch: 114 -> Loss: 0.142304390669\n",
      "Epoch: 114 -> Test Accuracy: 90.2475\n",
      "[115, 60] loss: 0.122\n",
      "[115, 120] loss: 0.124\n",
      "[115, 180] loss: 0.131\n",
      "[115, 240] loss: 0.140\n",
      "[115, 300] loss: 0.135\n",
      "[115, 360] loss: 0.136\n",
      "Epoch: 115 -> Loss: 0.130813017488\n",
      "Epoch: 115 -> Test Accuracy: 90.39\n",
      "[116, 60] loss: 0.130\n",
      "[116, 120] loss: 0.124\n",
      "[116, 180] loss: 0.131\n",
      "[116, 240] loss: 0.132\n",
      "[116, 300] loss: 0.138\n",
      "[116, 360] loss: 0.136\n",
      "Epoch: 116 -> Loss: 0.129043132067\n",
      "Epoch: 116 -> Test Accuracy: 90.2725\n",
      "[117, 60] loss: 0.130\n",
      "[117, 120] loss: 0.127\n",
      "[117, 180] loss: 0.127\n",
      "[117, 240] loss: 0.136\n",
      "[117, 300] loss: 0.136\n",
      "[117, 360] loss: 0.134\n",
      "Epoch: 117 -> Loss: 0.107642792165\n",
      "Epoch: 117 -> Test Accuracy: 89.9975\n",
      "[118, 60] loss: 0.120\n",
      "[118, 120] loss: 0.123\n",
      "[118, 180] loss: 0.137\n",
      "[118, 240] loss: 0.133\n",
      "[118, 300] loss: 0.142\n",
      "[118, 360] loss: 0.134\n",
      "Epoch: 118 -> Loss: 0.177022561431\n",
      "Epoch: 118 -> Test Accuracy: 90.2775\n",
      "[119, 60] loss: 0.124\n",
      "[119, 120] loss: 0.119\n",
      "[119, 180] loss: 0.129\n",
      "[119, 240] loss: 0.136\n",
      "[119, 300] loss: 0.132\n",
      "[119, 360] loss: 0.136\n",
      "Epoch: 119 -> Loss: 0.14112944901\n",
      "Epoch: 119 -> Test Accuracy: 89.7725\n",
      "[120, 60] loss: 0.120\n",
      "[120, 120] loss: 0.126\n",
      "[120, 180] loss: 0.132\n",
      "[120, 240] loss: 0.130\n",
      "[120, 300] loss: 0.134\n",
      "[120, 360] loss: 0.135\n",
      "Epoch: 120 -> Loss: 0.20968362689\n",
      "Epoch: 120 -> Test Accuracy: 89.9975\n",
      "[121, 60] loss: 0.093\n",
      "[121, 120] loss: 0.079\n",
      "[121, 180] loss: 0.074\n",
      "[121, 240] loss: 0.065\n",
      "[121, 300] loss: 0.066\n",
      "[121, 360] loss: 0.066\n",
      "Epoch: 121 -> Loss: 0.0816760584712\n",
      "Epoch: 121 -> Test Accuracy: 91.965\n",
      "[122, 60] loss: 0.053\n",
      "[122, 120] loss: 0.055\n",
      "[122, 180] loss: 0.056\n",
      "[122, 240] loss: 0.058\n",
      "[122, 300] loss: 0.052\n",
      "[122, 360] loss: 0.050\n",
      "Epoch: 122 -> Loss: 0.0504306778312\n",
      "Epoch: 122 -> Test Accuracy: 92.3675\n",
      "[123, 60] loss: 0.044\n",
      "[123, 120] loss: 0.047\n",
      "[123, 180] loss: 0.046\n",
      "[123, 240] loss: 0.049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123, 300] loss: 0.049\n",
      "[123, 360] loss: 0.049\n",
      "Epoch: 123 -> Loss: 0.0210487823933\n",
      "Epoch: 123 -> Test Accuracy: 92.2425\n",
      "[124, 60] loss: 0.043\n",
      "[124, 120] loss: 0.041\n",
      "[124, 180] loss: 0.042\n",
      "[124, 240] loss: 0.045\n",
      "[124, 300] loss: 0.044\n",
      "[124, 360] loss: 0.044\n",
      "Epoch: 124 -> Loss: 0.0389811620116\n",
      "Epoch: 124 -> Test Accuracy: 92.1275\n",
      "[125, 60] loss: 0.039\n",
      "[125, 120] loss: 0.041\n",
      "[125, 180] loss: 0.043\n",
      "[125, 240] loss: 0.039\n",
      "[125, 300] loss: 0.036\n",
      "[125, 360] loss: 0.041\n",
      "Epoch: 125 -> Loss: 0.0401941128075\n",
      "Epoch: 125 -> Test Accuracy: 92.395\n",
      "[126, 60] loss: 0.034\n",
      "[126, 120] loss: 0.036\n",
      "[126, 180] loss: 0.036\n",
      "[126, 240] loss: 0.040\n",
      "[126, 300] loss: 0.038\n",
      "[126, 360] loss: 0.042\n",
      "Epoch: 126 -> Loss: 0.0298605710268\n",
      "Epoch: 126 -> Test Accuracy: 92.1875\n",
      "[127, 60] loss: 0.036\n",
      "[127, 120] loss: 0.034\n",
      "[127, 180] loss: 0.033\n",
      "[127, 240] loss: 0.037\n",
      "[127, 300] loss: 0.034\n",
      "[127, 360] loss: 0.037\n",
      "Epoch: 127 -> Loss: 0.0408853441477\n",
      "Epoch: 127 -> Test Accuracy: 92.145\n",
      "[128, 60] loss: 0.033\n",
      "[128, 120] loss: 0.031\n",
      "[128, 180] loss: 0.035\n",
      "[128, 240] loss: 0.034\n",
      "[128, 300] loss: 0.034\n",
      "[128, 360] loss: 0.036\n",
      "Epoch: 128 -> Loss: 0.0231522209942\n",
      "Epoch: 128 -> Test Accuracy: 92.1575\n",
      "[129, 60] loss: 0.028\n",
      "[129, 120] loss: 0.029\n",
      "[129, 180] loss: 0.031\n",
      "[129, 240] loss: 0.035\n",
      "[129, 300] loss: 0.032\n",
      "[129, 360] loss: 0.030\n",
      "Epoch: 129 -> Loss: 0.0832593217492\n",
      "Epoch: 129 -> Test Accuracy: 92.265\n",
      "[130, 60] loss: 0.030\n",
      "[130, 120] loss: 0.029\n",
      "[130, 180] loss: 0.029\n",
      "[130, 240] loss: 0.031\n",
      "[130, 300] loss: 0.031\n",
      "[130, 360] loss: 0.033\n",
      "Epoch: 130 -> Loss: 0.0125324632972\n",
      "Epoch: 130 -> Test Accuracy: 92.08\n",
      "[131, 60] loss: 0.029\n",
      "[131, 120] loss: 0.031\n",
      "[131, 180] loss: 0.027\n",
      "[131, 240] loss: 0.030\n",
      "[131, 300] loss: 0.031\n",
      "[131, 360] loss: 0.029\n",
      "Epoch: 131 -> Loss: 0.016810208559\n",
      "Epoch: 131 -> Test Accuracy: 92.015\n",
      "[132, 60] loss: 0.028\n",
      "[132, 120] loss: 0.029\n",
      "[132, 180] loss: 0.033\n",
      "[132, 240] loss: 0.029\n",
      "[132, 300] loss: 0.028\n",
      "[132, 360] loss: 0.029\n",
      "Epoch: 132 -> Loss: 0.0253945142031\n",
      "Epoch: 132 -> Test Accuracy: 92.02\n",
      "[133, 60] loss: 0.029\n",
      "[133, 120] loss: 0.030\n",
      "[133, 180] loss: 0.032\n",
      "[133, 240] loss: 0.028\n",
      "[133, 300] loss: 0.027\n",
      "[133, 360] loss: 0.028\n",
      "Epoch: 133 -> Loss: 0.0169553905725\n",
      "Epoch: 133 -> Test Accuracy: 92.14\n",
      "[134, 60] loss: 0.027\n",
      "[134, 120] loss: 0.028\n",
      "[134, 180] loss: 0.028\n",
      "[134, 240] loss: 0.028\n",
      "[134, 300] loss: 0.029\n",
      "[134, 360] loss: 0.030\n",
      "Epoch: 134 -> Loss: 0.0231958441436\n",
      "Epoch: 134 -> Test Accuracy: 91.88\n",
      "[135, 60] loss: 0.024\n",
      "[135, 120] loss: 0.025\n",
      "[135, 180] loss: 0.029\n",
      "[135, 240] loss: 0.028\n",
      "[135, 300] loss: 0.027\n",
      "[135, 360] loss: 0.026\n",
      "Epoch: 135 -> Loss: 0.0205060616136\n",
      "Epoch: 135 -> Test Accuracy: 92.2875\n",
      "[136, 60] loss: 0.026\n",
      "[136, 120] loss: 0.024\n",
      "[136, 180] loss: 0.025\n",
      "[136, 240] loss: 0.025\n",
      "[136, 300] loss: 0.024\n",
      "[136, 360] loss: 0.027\n",
      "Epoch: 136 -> Loss: 0.0282891504467\n",
      "Epoch: 136 -> Test Accuracy: 91.8775\n",
      "[137, 60] loss: 0.026\n",
      "[137, 120] loss: 0.027\n",
      "[137, 180] loss: 0.026\n",
      "[137, 240] loss: 0.026\n",
      "[137, 300] loss: 0.027\n",
      "[137, 360] loss: 0.027\n",
      "Epoch: 137 -> Loss: 0.0227413084358\n",
      "Epoch: 137 -> Test Accuracy: 91.96\n",
      "[138, 60] loss: 0.026\n",
      "[138, 120] loss: 0.023\n",
      "[138, 180] loss: 0.026\n",
      "[138, 240] loss: 0.027\n",
      "[138, 300] loss: 0.028\n",
      "[138, 360] loss: 0.027\n",
      "Epoch: 138 -> Loss: 0.0458083450794\n",
      "Epoch: 138 -> Test Accuracy: 91.805\n",
      "[139, 60] loss: 0.026\n",
      "[139, 120] loss: 0.027\n",
      "[139, 180] loss: 0.027\n",
      "[139, 240] loss: 0.028\n",
      "[139, 300] loss: 0.026\n",
      "[139, 360] loss: 0.025\n",
      "Epoch: 139 -> Loss: 0.0280622653663\n",
      "Epoch: 139 -> Test Accuracy: 91.9075\n",
      "[140, 60] loss: 0.022\n",
      "[140, 120] loss: 0.021\n",
      "[140, 180] loss: 0.023\n",
      "[140, 240] loss: 0.025\n",
      "[140, 300] loss: 0.025\n",
      "[140, 360] loss: 0.025\n",
      "Epoch: 140 -> Loss: 0.0158074591309\n",
      "Epoch: 140 -> Test Accuracy: 92.1025\n",
      "[141, 60] loss: 0.022\n",
      "[141, 120] loss: 0.021\n",
      "[141, 180] loss: 0.024\n",
      "[141, 240] loss: 0.023\n",
      "[141, 300] loss: 0.026\n",
      "[141, 360] loss: 0.026\n",
      "Epoch: 141 -> Loss: 0.0368380323052\n",
      "Epoch: 141 -> Test Accuracy: 91.9775\n",
      "[142, 60] loss: 0.025\n",
      "[142, 120] loss: 0.020\n",
      "[142, 180] loss: 0.025\n",
      "[142, 240] loss: 0.026\n",
      "[142, 300] loss: 0.027\n",
      "[142, 360] loss: 0.025\n",
      "Epoch: 142 -> Loss: 0.0190944671631\n",
      "Epoch: 142 -> Test Accuracy: 91.865\n",
      "[143, 60] loss: 0.024\n",
      "[143, 120] loss: 0.023\n",
      "[143, 180] loss: 0.026\n",
      "[143, 240] loss: 0.025\n",
      "[143, 300] loss: 0.025\n",
      "[143, 360] loss: 0.023\n",
      "Epoch: 143 -> Loss: 0.0278250221163\n",
      "Epoch: 143 -> Test Accuracy: 92.1575\n",
      "[144, 60] loss: 0.023\n",
      "[144, 120] loss: 0.023\n",
      "[144, 180] loss: 0.023\n",
      "[144, 240] loss: 0.024\n",
      "[144, 300] loss: 0.025\n",
      "[144, 360] loss: 0.028\n",
      "Epoch: 144 -> Loss: 0.00972497276962\n",
      "Epoch: 144 -> Test Accuracy: 91.645\n",
      "[145, 60] loss: 0.025\n",
      "[145, 120] loss: 0.021\n",
      "[145, 180] loss: 0.024\n",
      "[145, 240] loss: 0.027\n",
      "[145, 300] loss: 0.024\n",
      "[145, 360] loss: 0.027\n",
      "Epoch: 145 -> Loss: 0.0353500656784\n",
      "Epoch: 145 -> Test Accuracy: 91.875\n",
      "[146, 60] loss: 0.024\n",
      "[146, 120] loss: 0.025\n",
      "[146, 180] loss: 0.024\n",
      "[146, 240] loss: 0.023\n",
      "[146, 300] loss: 0.024\n",
      "[146, 360] loss: 0.027\n",
      "Epoch: 146 -> Loss: 0.0264436956495\n",
      "Epoch: 146 -> Test Accuracy: 91.8025\n",
      "[147, 60] loss: 0.022\n",
      "[147, 120] loss: 0.022\n",
      "[147, 180] loss: 0.025\n",
      "[147, 240] loss: 0.026\n",
      "[147, 300] loss: 0.025\n",
      "[147, 360] loss: 0.026\n",
      "Epoch: 147 -> Loss: 0.0188651252538\n",
      "Epoch: 147 -> Test Accuracy: 91.9625\n",
      "[148, 60] loss: 0.019\n",
      "[148, 120] loss: 0.024\n",
      "[148, 180] loss: 0.023\n",
      "[148, 240] loss: 0.027\n",
      "[148, 300] loss: 0.026\n",
      "[148, 360] loss: 0.028\n",
      "Epoch: 148 -> Loss: 0.0198845528066\n",
      "Epoch: 148 -> Test Accuracy: 92.155\n",
      "[149, 60] loss: 0.024\n",
      "[149, 120] loss: 0.024\n",
      "[149, 180] loss: 0.022\n",
      "[149, 240] loss: 0.024\n",
      "[149, 300] loss: 0.027\n",
      "[149, 360] loss: 0.026\n",
      "Epoch: 149 -> Loss: 0.00391420489177\n",
      "Epoch: 149 -> Test Accuracy: 91.8925\n",
      "[150, 60] loss: 0.022\n",
      "[150, 120] loss: 0.024\n",
      "[150, 180] loss: 0.024\n",
      "[150, 240] loss: 0.027\n",
      "[150, 300] loss: 0.025\n",
      "[150, 360] loss: 0.025\n",
      "Epoch: 150 -> Loss: 0.0220097228885\n",
      "Epoch: 150 -> Test Accuracy: 91.845\n",
      "[151, 60] loss: 0.024\n",
      "[151, 120] loss: 0.022\n",
      "[151, 180] loss: 0.026\n",
      "[151, 240] loss: 0.025\n",
      "[151, 300] loss: 0.028\n",
      "[151, 360] loss: 0.026\n",
      "Epoch: 151 -> Loss: 0.053466014564\n",
      "Epoch: 151 -> Test Accuracy: 91.925\n",
      "[152, 60] loss: 0.024\n",
      "[152, 120] loss: 0.021\n",
      "[152, 180] loss: 0.022\n",
      "[152, 240] loss: 0.022\n",
      "[152, 300] loss: 0.025\n",
      "[152, 360] loss: 0.030\n",
      "Epoch: 152 -> Loss: 0.0168374273926\n",
      "Epoch: 152 -> Test Accuracy: 91.4225\n",
      "[153, 60] loss: 0.023\n",
      "[153, 120] loss: 0.021\n",
      "[153, 180] loss: 0.026\n",
      "[153, 240] loss: 0.025\n",
      "[153, 300] loss: 0.025\n",
      "[153, 360] loss: 0.027\n",
      "Epoch: 153 -> Loss: 0.0135332075879\n",
      "Epoch: 153 -> Test Accuracy: 91.7175\n",
      "[154, 60] loss: 0.023\n",
      "[154, 120] loss: 0.023\n",
      "[154, 180] loss: 0.024\n",
      "[154, 240] loss: 0.024\n",
      "[154, 300] loss: 0.024\n",
      "[154, 360] loss: 0.025\n",
      "Epoch: 154 -> Loss: 0.0130774173886\n",
      "Epoch: 154 -> Test Accuracy: 91.8175\n",
      "[155, 60] loss: 0.024\n",
      "[155, 120] loss: 0.023\n",
      "[155, 180] loss: 0.024\n",
      "[155, 240] loss: 0.023\n",
      "[155, 300] loss: 0.026\n",
      "[155, 360] loss: 0.025\n",
      "Epoch: 155 -> Loss: 0.0193723458797\n",
      "Epoch: 155 -> Test Accuracy: 91.765\n",
      "[156, 60] loss: 0.023\n",
      "[156, 120] loss: 0.024\n",
      "[156, 180] loss: 0.026\n",
      "[156, 240] loss: 0.026\n",
      "[156, 300] loss: 0.025\n",
      "[156, 360] loss: 0.028\n",
      "Epoch: 156 -> Loss: 0.0366167500615\n",
      "Epoch: 156 -> Test Accuracy: 91.815\n",
      "[157, 60] loss: 0.027\n",
      "[157, 120] loss: 0.025\n",
      "[157, 180] loss: 0.026\n",
      "[157, 240] loss: 0.025\n",
      "[157, 300] loss: 0.029\n",
      "[157, 360] loss: 0.025\n",
      "Epoch: 157 -> Loss: 0.0179907325655\n",
      "Epoch: 157 -> Test Accuracy: 91.96\n",
      "[158, 60] loss: 0.023\n",
      "[158, 120] loss: 0.022\n",
      "[158, 180] loss: 0.026\n",
      "[158, 240] loss: 0.026\n",
      "[158, 300] loss: 0.023\n",
      "[158, 360] loss: 0.026\n",
      "Epoch: 158 -> Loss: 0.0472861751914\n",
      "Epoch: 158 -> Test Accuracy: 91.705\n",
      "[159, 60] loss: 0.026\n",
      "[159, 120] loss: 0.024\n",
      "[159, 180] loss: 0.025\n",
      "[159, 240] loss: 0.027\n",
      "[159, 300] loss: 0.027\n",
      "[159, 360] loss: 0.030\n",
      "Epoch: 159 -> Loss: 0.0235533826053\n",
      "Epoch: 159 -> Test Accuracy: 91.6475\n",
      "[160, 60] loss: 0.026\n",
      "[160, 120] loss: 0.021\n",
      "[160, 180] loss: 0.025\n",
      "[160, 240] loss: 0.025\n",
      "[160, 300] loss: 0.029\n",
      "[160, 360] loss: 0.030\n",
      "Epoch: 160 -> Loss: 0.0388008765876\n",
      "Epoch: 160 -> Test Accuracy: 91.76\n",
      "[161, 60] loss: 0.020\n",
      "[161, 120] loss: 0.017\n",
      "[161, 180] loss: 0.018\n",
      "[161, 240] loss: 0.016\n",
      "[161, 300] loss: 0.014\n",
      "[161, 360] loss: 0.014\n",
      "Epoch: 161 -> Loss: 0.0230733081698\n",
      "Epoch: 161 -> Test Accuracy: 92.27\n",
      "[162, 60] loss: 0.013\n",
      "[162, 120] loss: 0.013\n",
      "[162, 180] loss: 0.013\n",
      "[162, 240] loss: 0.012\n",
      "[162, 300] loss: 0.011\n",
      "[162, 360] loss: 0.011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 162 -> Loss: 0.00509799784049\n",
      "Epoch: 162 -> Test Accuracy: 92.2875\n",
      "[163, 60] loss: 0.011\n",
      "[163, 120] loss: 0.011\n",
      "[163, 180] loss: 0.010\n",
      "[163, 240] loss: 0.011\n",
      "[163, 300] loss: 0.010\n",
      "[163, 360] loss: 0.010\n",
      "Epoch: 163 -> Loss: 0.00899147894233\n",
      "Epoch: 163 -> Test Accuracy: 92.28\n",
      "[164, 60] loss: 0.010\n",
      "[164, 120] loss: 0.009\n",
      "[164, 180] loss: 0.010\n",
      "[164, 240] loss: 0.010\n",
      "[164, 300] loss: 0.010\n",
      "[164, 360] loss: 0.010\n",
      "Epoch: 164 -> Loss: 0.00555024761707\n",
      "Epoch: 164 -> Test Accuracy: 92.305\n",
      "[165, 60] loss: 0.009\n",
      "[165, 120] loss: 0.010\n",
      "[165, 180] loss: 0.010\n",
      "[165, 240] loss: 0.010\n",
      "[165, 300] loss: 0.009\n",
      "[165, 360] loss: 0.009\n",
      "Epoch: 165 -> Loss: 0.00905185192823\n",
      "Epoch: 165 -> Test Accuracy: 92.3125\n",
      "[166, 60] loss: 0.009\n",
      "[166, 120] loss: 0.009\n",
      "[166, 180] loss: 0.009\n",
      "[166, 240] loss: 0.009\n",
      "[166, 300] loss: 0.008\n",
      "[166, 360] loss: 0.008\n",
      "Epoch: 166 -> Loss: 0.00991501379758\n",
      "Epoch: 166 -> Test Accuracy: 92.4075\n",
      "[167, 60] loss: 0.008\n",
      "[167, 120] loss: 0.009\n",
      "[167, 180] loss: 0.009\n",
      "[167, 240] loss: 0.009\n",
      "[167, 300] loss: 0.009\n",
      "[167, 360] loss: 0.009\n",
      "Epoch: 167 -> Loss: 0.00669632572681\n",
      "Epoch: 167 -> Test Accuracy: 92.3325\n",
      "[168, 60] loss: 0.008\n",
      "[168, 120] loss: 0.008\n",
      "[168, 180] loss: 0.008\n",
      "[168, 240] loss: 0.008\n",
      "[168, 300] loss: 0.008\n",
      "[168, 360] loss: 0.008\n",
      "Epoch: 168 -> Loss: 0.00294311204925\n",
      "Epoch: 168 -> Test Accuracy: 92.4225\n",
      "[169, 60] loss: 0.007\n",
      "[169, 120] loss: 0.008\n",
      "[169, 180] loss: 0.007\n",
      "[169, 240] loss: 0.008\n",
      "[169, 300] loss: 0.008\n",
      "[169, 360] loss: 0.009\n",
      "Epoch: 169 -> Loss: 0.00293462793343\n",
      "Epoch: 169 -> Test Accuracy: 92.4025\n",
      "[170, 60] loss: 0.008\n",
      "[170, 120] loss: 0.008\n",
      "[170, 180] loss: 0.008\n",
      "[170, 240] loss: 0.008\n",
      "[170, 300] loss: 0.008\n",
      "[170, 360] loss: 0.007\n",
      "Epoch: 170 -> Loss: 0.00631618406624\n",
      "Epoch: 170 -> Test Accuracy: 92.3875\n",
      "[171, 60] loss: 0.007\n",
      "[171, 120] loss: 0.007\n",
      "[171, 180] loss: 0.008\n",
      "[171, 240] loss: 0.009\n",
      "[171, 300] loss: 0.007\n",
      "[171, 360] loss: 0.008\n",
      "Epoch: 171 -> Loss: 0.00727566797286\n",
      "Epoch: 171 -> Test Accuracy: 92.4725\n",
      "[172, 60] loss: 0.007\n",
      "[172, 120] loss: 0.007\n",
      "[172, 180] loss: 0.006\n",
      "[172, 240] loss: 0.008\n",
      "[172, 300] loss: 0.008\n",
      "[172, 360] loss: 0.008\n",
      "Epoch: 172 -> Loss: 0.00735081639141\n",
      "Epoch: 172 -> Test Accuracy: 92.4125\n",
      "[173, 60] loss: 0.006\n",
      "[173, 120] loss: 0.007\n",
      "[173, 180] loss: 0.008\n",
      "[173, 240] loss: 0.007\n",
      "[173, 300] loss: 0.007\n",
      "[173, 360] loss: 0.007\n",
      "Epoch: 173 -> Loss: 0.00349995004945\n",
      "Epoch: 173 -> Test Accuracy: 92.41\n",
      "[174, 60] loss: 0.008\n",
      "[174, 120] loss: 0.007\n",
      "[174, 180] loss: 0.007\n",
      "[174, 240] loss: 0.007\n",
      "[174, 300] loss: 0.007\n",
      "[174, 360] loss: 0.006\n",
      "Epoch: 174 -> Loss: 0.00565226562321\n",
      "Epoch: 174 -> Test Accuracy: 92.475\n",
      "[175, 60] loss: 0.007\n",
      "[175, 120] loss: 0.007\n",
      "[175, 180] loss: 0.007\n",
      "[175, 240] loss: 0.007\n",
      "[175, 300] loss: 0.007\n",
      "[175, 360] loss: 0.007\n",
      "Epoch: 175 -> Loss: 0.0116137359291\n",
      "Epoch: 175 -> Test Accuracy: 92.3775\n",
      "[176, 60] loss: 0.006\n",
      "[176, 120] loss: 0.007\n",
      "[176, 180] loss: 0.007\n",
      "[176, 240] loss: 0.006\n",
      "[176, 300] loss: 0.007\n",
      "[176, 360] loss: 0.008\n",
      "Epoch: 176 -> Loss: 0.00655034929514\n",
      "Epoch: 176 -> Test Accuracy: 92.38\n",
      "[177, 60] loss: 0.007\n",
      "[177, 120] loss: 0.007\n",
      "[177, 180] loss: 0.007\n",
      "[177, 240] loss: 0.006\n",
      "[177, 300] loss: 0.007\n",
      "[177, 360] loss: 0.007\n",
      "Epoch: 177 -> Loss: 0.004984265659\n",
      "Epoch: 177 -> Test Accuracy: 92.38\n",
      "[178, 60] loss: 0.007\n",
      "[178, 120] loss: 0.007\n",
      "[178, 180] loss: 0.006\n",
      "[178, 240] loss: 0.006\n",
      "[178, 300] loss: 0.007\n",
      "[178, 360] loss: 0.007\n",
      "Epoch: 178 -> Loss: 0.0067149004899\n",
      "Epoch: 178 -> Test Accuracy: 92.385\n",
      "[179, 60] loss: 0.007\n",
      "[179, 120] loss: 0.006\n",
      "[179, 180] loss: 0.006\n",
      "[179, 240] loss: 0.006\n",
      "[179, 300] loss: 0.007\n",
      "[179, 360] loss: 0.007\n",
      "Epoch: 179 -> Loss: 0.00410048197955\n",
      "Epoch: 179 -> Test Accuracy: 92.3475\n",
      "[180, 60] loss: 0.006\n",
      "[180, 120] loss: 0.006\n",
      "[180, 180] loss: 0.006\n",
      "[180, 240] loss: 0.007\n",
      "[180, 300] loss: 0.005\n",
      "[180, 360] loss: 0.007\n",
      "Epoch: 180 -> Loss: 0.0031103156507\n",
      "Epoch: 180 -> Test Accuracy: 92.3975\n",
      "[181, 60] loss: 0.006\n",
      "[181, 120] loss: 0.007\n",
      "[181, 180] loss: 0.006\n",
      "[181, 240] loss: 0.006\n",
      "[181, 300] loss: 0.006\n",
      "[181, 360] loss: 0.007\n",
      "Epoch: 181 -> Loss: 0.00277294591069\n",
      "Epoch: 181 -> Test Accuracy: 92.3625\n",
      "[182, 60] loss: 0.006\n",
      "[182, 120] loss: 0.007\n",
      "[182, 180] loss: 0.006\n",
      "[182, 240] loss: 0.006\n",
      "[182, 300] loss: 0.006\n",
      "[182, 360] loss: 0.006\n",
      "Epoch: 182 -> Loss: 0.00907402671874\n",
      "Epoch: 182 -> Test Accuracy: 92.405\n",
      "[183, 60] loss: 0.006\n",
      "[183, 120] loss: 0.006\n",
      "[183, 180] loss: 0.006\n",
      "[183, 240] loss: 0.006\n",
      "[183, 300] loss: 0.006\n",
      "[183, 360] loss: 0.006\n",
      "Epoch: 183 -> Loss: 0.00288084149361\n",
      "Epoch: 183 -> Test Accuracy: 92.335\n",
      "[184, 60] loss: 0.005\n",
      "[184, 120] loss: 0.006\n",
      "[184, 180] loss: 0.006\n",
      "[184, 240] loss: 0.006\n",
      "[184, 300] loss: 0.006\n",
      "[184, 360] loss: 0.006\n",
      "Epoch: 184 -> Loss: 0.00355834444053\n",
      "Epoch: 184 -> Test Accuracy: 92.4525\n",
      "[185, 60] loss: 0.006\n",
      "[185, 120] loss: 0.007\n",
      "[185, 180] loss: 0.006\n",
      "[185, 240] loss: 0.006\n",
      "[185, 300] loss: 0.006\n",
      "[185, 360] loss: 0.006\n",
      "Epoch: 185 -> Loss: 0.00361480889842\n",
      "Epoch: 185 -> Test Accuracy: 92.385\n",
      "[186, 60] loss: 0.006\n",
      "[186, 120] loss: 0.006\n",
      "[186, 180] loss: 0.007\n",
      "[186, 240] loss: 0.006\n",
      "[186, 300] loss: 0.006\n",
      "[186, 360] loss: 0.007\n",
      "Epoch: 186 -> Loss: 0.00583706563339\n",
      "Epoch: 186 -> Test Accuracy: 92.345\n",
      "[187, 60] loss: 0.005\n",
      "[187, 120] loss: 0.006\n",
      "[187, 180] loss: 0.005\n",
      "[187, 240] loss: 0.006\n",
      "[187, 300] loss: 0.006\n",
      "[187, 360] loss: 0.006\n",
      "Epoch: 187 -> Loss: 0.0039578191936\n",
      "Epoch: 187 -> Test Accuracy: 92.375\n",
      "[188, 60] loss: 0.006\n",
      "[188, 120] loss: 0.006\n",
      "[188, 180] loss: 0.006\n",
      "[188, 240] loss: 0.006\n",
      "[188, 300] loss: 0.006\n",
      "[188, 360] loss: 0.006\n",
      "Epoch: 188 -> Loss: 0.00154573621694\n",
      "Epoch: 188 -> Test Accuracy: 92.3375\n",
      "[189, 60] loss: 0.006\n",
      "[189, 120] loss: 0.005\n",
      "[189, 180] loss: 0.006\n",
      "[189, 240] loss: 0.006\n",
      "[189, 300] loss: 0.006\n",
      "[189, 360] loss: 0.006\n",
      "Epoch: 189 -> Loss: 0.00387769867666\n",
      "Epoch: 189 -> Test Accuracy: 92.3925\n",
      "[190, 60] loss: 0.005\n",
      "[190, 120] loss: 0.006\n",
      "[190, 180] loss: 0.005\n",
      "[190, 240] loss: 0.006\n",
      "[190, 300] loss: 0.006\n",
      "[190, 360] loss: 0.006\n",
      "Epoch: 190 -> Loss: 0.0031169608701\n",
      "Epoch: 190 -> Test Accuracy: 92.43\n",
      "[191, 60] loss: 0.006\n",
      "[191, 120] loss: 0.005\n",
      "[191, 180] loss: 0.005\n",
      "[191, 240] loss: 0.005\n",
      "[191, 300] loss: 0.005\n",
      "[191, 360] loss: 0.006\n",
      "Epoch: 191 -> Loss: 0.00513067469001\n",
      "Epoch: 191 -> Test Accuracy: 92.3825\n",
      "[192, 60] loss: 0.005\n",
      "[192, 120] loss: 0.006\n",
      "[192, 180] loss: 0.005\n",
      "[192, 240] loss: 0.006\n",
      "[192, 300] loss: 0.006\n",
      "[192, 360] loss: 0.006\n",
      "Epoch: 192 -> Loss: 0.00460846256465\n",
      "Epoch: 192 -> Test Accuracy: 92.3475\n",
      "[193, 60] loss: 0.005\n",
      "[193, 120] loss: 0.006\n",
      "[193, 180] loss: 0.005\n",
      "[193, 240] loss: 0.005\n",
      "[193, 300] loss: 0.005\n",
      "[193, 360] loss: 0.005\n",
      "Epoch: 193 -> Loss: 0.00331775401719\n",
      "Epoch: 193 -> Test Accuracy: 92.355\n",
      "[194, 60] loss: 0.005\n",
      "[194, 120] loss: 0.005\n",
      "[194, 180] loss: 0.007\n",
      "[194, 240] loss: 0.006\n",
      "[194, 300] loss: 0.005\n",
      "[194, 360] loss: 0.005\n",
      "Epoch: 194 -> Loss: 0.00655183335766\n",
      "Epoch: 194 -> Test Accuracy: 92.3675\n",
      "[195, 60] loss: 0.005\n",
      "[195, 120] loss: 0.005\n",
      "[195, 180] loss: 0.006\n",
      "[195, 240] loss: 0.006\n",
      "[195, 300] loss: 0.006\n",
      "[195, 360] loss: 0.006\n",
      "Epoch: 195 -> Loss: 0.00250746379606\n",
      "Epoch: 195 -> Test Accuracy: 92.3725\n",
      "[196, 60] loss: 0.006\n",
      "[196, 120] loss: 0.006\n",
      "[196, 180] loss: 0.006\n",
      "[196, 240] loss: 0.007\n",
      "[196, 300] loss: 0.006\n",
      "[196, 360] loss: 0.006\n",
      "Epoch: 196 -> Loss: 0.00631155911833\n",
      "Epoch: 196 -> Test Accuracy: 92.395\n",
      "[197, 60] loss: 0.005\n",
      "[197, 120] loss: 0.005\n",
      "[197, 180] loss: 0.005\n",
      "[197, 240] loss: 0.005\n",
      "[197, 300] loss: 0.005\n",
      "[197, 360] loss: 0.005\n",
      "Epoch: 197 -> Loss: 0.00528618693352\n",
      "Epoch: 197 -> Test Accuracy: 92.37\n",
      "[198, 60] loss: 0.005\n",
      "[198, 120] loss: 0.005\n",
      "[198, 180] loss: 0.005\n",
      "[198, 240] loss: 0.005\n",
      "[198, 300] loss: 0.005\n",
      "[198, 360] loss: 0.005\n",
      "Epoch: 198 -> Loss: 0.0140777807683\n",
      "Epoch: 198 -> Test Accuracy: 92.3975\n",
      "[199, 60] loss: 0.005\n",
      "[199, 120] loss: 0.005\n",
      "[199, 180] loss: 0.006\n",
      "[199, 240] loss: 0.005\n",
      "[199, 300] loss: 0.005\n",
      "[199, 360] loss: 0.005\n",
      "Epoch: 199 -> Loss: 0.00414127483964\n",
      "Epoch: 199 -> Test Accuracy: 92.3275\n",
      "[200, 60] loss: 0.004\n",
      "[200, 120] loss: 0.005\n",
      "[200, 180] loss: 0.005\n",
      "[200, 240] loss: 0.006\n",
      "[200, 300] loss: 0.006\n",
      "[200, 360] loss: 0.005\n",
      "Epoch: 200 -> Loss: 0.0148299755529\n",
      "Epoch: 200 -> Test Accuracy: 92.3775\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "rot_block4_loss_log, rot_block4_valid_accuracy_log, rot_block4_test_accuracy_log, rot_block4_max_accuracy, \\\n",
    "rot_block4_best_epoch = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], [60, 120, 160, 200], 0.9, 5e-4, net_block4, \n",
    "                                             criterion, trainloader, None, testloader, rot=['90', '180', '270'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 2.207\n",
      "[1, 120] loss: 1.244\n",
      "[1, 180] loss: 1.155\n",
      "[1, 240] loss: 1.083\n",
      "[1, 300] loss: 1.024\n",
      "[1, 360] loss: 0.976\n",
      "Epoch: 1 -> Loss: 1.00132513046\n",
      "Epoch: 1 -> Test Accuracy: 67.56\n",
      "[2, 60] loss: 0.968\n",
      "[2, 120] loss: 0.921\n",
      "[2, 180] loss: 0.895\n",
      "[2, 240] loss: 0.875\n",
      "[2, 300] loss: 0.872\n",
      "[2, 360] loss: 0.842\n",
      "Epoch: 2 -> Loss: 0.871394813061\n",
      "Epoch: 2 -> Test Accuracy: 71.67\n",
      "[3, 60] loss: 0.833\n",
      "[3, 120] loss: 0.823\n",
      "[3, 180] loss: 0.795\n",
      "[3, 240] loss: 0.812\n",
      "[3, 300] loss: 0.828\n",
      "[3, 360] loss: 0.786\n",
      "Epoch: 3 -> Loss: 0.851732552052\n",
      "Epoch: 3 -> Test Accuracy: 73.66\n",
      "[4, 60] loss: 0.765\n",
      "[4, 120] loss: 0.757\n",
      "[4, 180] loss: 0.785\n",
      "[4, 240] loss: 0.752\n",
      "[4, 300] loss: 0.747\n",
      "[4, 360] loss: 0.751\n",
      "Epoch: 4 -> Loss: 0.77848637104\n",
      "Epoch: 4 -> Test Accuracy: 75.1\n",
      "[5, 60] loss: 0.727\n",
      "[5, 120] loss: 0.724\n",
      "[5, 180] loss: 0.731\n",
      "[5, 240] loss: 0.734\n",
      "[5, 300] loss: 0.712\n",
      "[5, 360] loss: 0.718\n",
      "Epoch: 5 -> Loss: 0.792627334595\n",
      "Epoch: 5 -> Test Accuracy: 75.23\n",
      "[6, 60] loss: 0.690\n",
      "[6, 120] loss: 0.696\n",
      "[6, 180] loss: 0.710\n",
      "[6, 240] loss: 0.692\n",
      "[6, 300] loss: 0.714\n",
      "[6, 360] loss: 0.710\n",
      "Epoch: 6 -> Loss: 0.584211051464\n",
      "Epoch: 6 -> Test Accuracy: 75.91\n",
      "[7, 60] loss: 0.659\n",
      "[7, 120] loss: 0.695\n",
      "[7, 180] loss: 0.691\n",
      "[7, 240] loss: 0.688\n",
      "[7, 300] loss: 0.672\n",
      "[7, 360] loss: 0.687\n",
      "Epoch: 7 -> Loss: 0.634452879429\n",
      "Epoch: 7 -> Test Accuracy: 77.26\n",
      "[8, 60] loss: 0.641\n",
      "[8, 120] loss: 0.657\n",
      "[8, 180] loss: 0.691\n",
      "[8, 240] loss: 0.662\n",
      "[8, 300] loss: 0.677\n",
      "[8, 360] loss: 0.656\n",
      "Epoch: 8 -> Loss: 0.726947128773\n",
      "Epoch: 8 -> Test Accuracy: 77.03\n",
      "[9, 60] loss: 0.642\n",
      "[9, 120] loss: 0.655\n",
      "[9, 180] loss: 0.669\n",
      "[9, 240] loss: 0.663\n",
      "[9, 300] loss: 0.662\n",
      "[9, 360] loss: 0.665\n",
      "Epoch: 9 -> Loss: 0.682752370834\n",
      "Epoch: 9 -> Test Accuracy: 77.06\n",
      "[10, 60] loss: 0.645\n",
      "[10, 120] loss: 0.645\n",
      "[10, 180] loss: 0.643\n",
      "[10, 240] loss: 0.660\n",
      "[10, 300] loss: 0.645\n",
      "[10, 360] loss: 0.678\n",
      "Epoch: 10 -> Loss: 0.439636796713\n",
      "Epoch: 10 -> Test Accuracy: 77.76\n",
      "[11, 60] loss: 0.620\n",
      "[11, 120] loss: 0.631\n",
      "[11, 180] loss: 0.645\n",
      "[11, 240] loss: 0.667\n",
      "[11, 300] loss: 0.625\n",
      "[11, 360] loss: 0.640\n",
      "Epoch: 11 -> Loss: 0.678311228752\n",
      "Epoch: 11 -> Test Accuracy: 76.88\n",
      "[12, 60] loss: 0.627\n",
      "[12, 120] loss: 0.630\n",
      "[12, 180] loss: 0.648\n",
      "[12, 240] loss: 0.628\n",
      "[12, 300] loss: 0.636\n",
      "[12, 360] loss: 0.654\n",
      "Epoch: 12 -> Loss: 0.691946089268\n",
      "Epoch: 12 -> Test Accuracy: 77.78\n",
      "[13, 60] loss: 0.611\n",
      "[13, 120] loss: 0.620\n",
      "[13, 180] loss: 0.635\n",
      "[13, 240] loss: 0.637\n",
      "[13, 300] loss: 0.642\n",
      "[13, 360] loss: 0.622\n",
      "Epoch: 13 -> Loss: 0.695531368256\n",
      "Epoch: 13 -> Test Accuracy: 77.82\n",
      "[14, 60] loss: 0.616\n",
      "[14, 120] loss: 0.625\n",
      "[14, 180] loss: 0.627\n",
      "[14, 240] loss: 0.625\n",
      "[14, 300] loss: 0.612\n",
      "[14, 360] loss: 0.630\n",
      "Epoch: 14 -> Loss: 0.591149926186\n",
      "Epoch: 14 -> Test Accuracy: 77.61\n",
      "[15, 60] loss: 0.605\n",
      "[15, 120] loss: 0.631\n",
      "[15, 180] loss: 0.619\n",
      "[15, 240] loss: 0.619\n",
      "[15, 300] loss: 0.625\n",
      "[15, 360] loss: 0.611\n",
      "Epoch: 15 -> Loss: 0.697739601135\n",
      "Epoch: 15 -> Test Accuracy: 77.79\n",
      "[16, 60] loss: 0.591\n",
      "[16, 120] loss: 0.575\n",
      "[16, 180] loss: 0.619\n",
      "[16, 240] loss: 0.602\n",
      "[16, 300] loss: 0.624\n",
      "[16, 360] loss: 0.623\n",
      "Epoch: 16 -> Loss: 0.58583676815\n",
      "Epoch: 16 -> Test Accuracy: 78.3\n",
      "[17, 60] loss: 0.603\n",
      "[17, 120] loss: 0.607\n",
      "[17, 180] loss: 0.595\n",
      "[17, 240] loss: 0.621\n",
      "[17, 300] loss: 0.622\n",
      "[17, 360] loss: 0.614\n",
      "Epoch: 17 -> Loss: 0.536822319031\n",
      "Epoch: 17 -> Test Accuracy: 78.25\n",
      "[18, 60] loss: 0.593\n",
      "[18, 120] loss: 0.592\n",
      "[18, 180] loss: 0.604\n",
      "[18, 240] loss: 0.622\n",
      "[18, 300] loss: 0.621\n",
      "[18, 360] loss: 0.617\n",
      "Epoch: 18 -> Loss: 0.672292649746\n",
      "Epoch: 18 -> Test Accuracy: 78.51\n",
      "[19, 60] loss: 0.590\n",
      "[19, 120] loss: 0.580\n",
      "[19, 180] loss: 0.612\n",
      "[19, 240] loss: 0.622\n",
      "[19, 300] loss: 0.596\n",
      "[19, 360] loss: 0.641\n",
      "Epoch: 19 -> Loss: 0.604664683342\n",
      "Epoch: 19 -> Test Accuracy: 78.85\n",
      "[20, 60] loss: 0.589\n",
      "[20, 120] loss: 0.600\n",
      "[20, 180] loss: 0.611\n",
      "[20, 240] loss: 0.594\n",
      "[20, 300] loss: 0.602\n",
      "[20, 360] loss: 0.622\n",
      "Epoch: 20 -> Loss: 0.677829146385\n",
      "Epoch: 20 -> Test Accuracy: 78.55\n",
      "[21, 60] loss: 0.553\n",
      "[21, 120] loss: 0.522\n",
      "[21, 180] loss: 0.507\n",
      "[21, 240] loss: 0.504\n",
      "[21, 300] loss: 0.498\n",
      "[21, 360] loss: 0.496\n",
      "Epoch: 21 -> Loss: 0.556253373623\n",
      "Epoch: 21 -> Test Accuracy: 80.76\n",
      "[22, 60] loss: 0.497\n",
      "[22, 120] loss: 0.475\n",
      "[22, 180] loss: 0.475\n",
      "[22, 240] loss: 0.458\n",
      "[22, 300] loss: 0.467\n",
      "[22, 360] loss: 0.466\n",
      "Epoch: 22 -> Loss: 0.634680509567\n",
      "Epoch: 22 -> Test Accuracy: 81.58\n",
      "[23, 60] loss: 0.441\n",
      "[23, 120] loss: 0.467\n",
      "[23, 180] loss: 0.466\n",
      "[23, 240] loss: 0.453\n",
      "[23, 300] loss: 0.444\n",
      "[23, 360] loss: 0.443\n",
      "Epoch: 23 -> Loss: 0.433705955744\n",
      "Epoch: 23 -> Test Accuracy: 81.77\n",
      "[24, 60] loss: 0.407\n",
      "[24, 120] loss: 0.445\n",
      "[24, 180] loss: 0.444\n",
      "[24, 240] loss: 0.430\n",
      "[24, 300] loss: 0.450\n",
      "[24, 360] loss: 0.440\n",
      "Epoch: 24 -> Loss: 0.498894125223\n",
      "Epoch: 24 -> Test Accuracy: 81.97\n",
      "[25, 60] loss: 0.432\n",
      "[25, 120] loss: 0.412\n",
      "[25, 180] loss: 0.451\n",
      "[25, 240] loss: 0.418\n",
      "[25, 300] loss: 0.418\n",
      "[25, 360] loss: 0.427\n",
      "Epoch: 25 -> Loss: 0.366900086403\n",
      "Epoch: 25 -> Test Accuracy: 81.41\n",
      "[26, 60] loss: 0.407\n",
      "[26, 120] loss: 0.426\n",
      "[26, 180] loss: 0.441\n",
      "[26, 240] loss: 0.436\n",
      "[26, 300] loss: 0.419\n",
      "[26, 360] loss: 0.409\n",
      "Epoch: 26 -> Loss: 0.464114427567\n",
      "Epoch: 26 -> Test Accuracy: 82.24\n",
      "[27, 60] loss: 0.407\n",
      "[27, 120] loss: 0.437\n",
      "[27, 180] loss: 0.409\n",
      "[27, 240] loss: 0.427\n",
      "[27, 300] loss: 0.408\n",
      "[27, 360] loss: 0.414\n",
      "Epoch: 27 -> Loss: 0.383529603481\n",
      "Epoch: 27 -> Test Accuracy: 82.21\n",
      "[28, 60] loss: 0.390\n",
      "[28, 120] loss: 0.416\n",
      "[28, 180] loss: 0.411\n",
      "[28, 240] loss: 0.404\n",
      "[28, 300] loss: 0.413\n",
      "[28, 360] loss: 0.416\n",
      "Epoch: 28 -> Loss: 0.731624186039\n",
      "Epoch: 28 -> Test Accuracy: 81.91\n",
      "[29, 60] loss: 0.397\n",
      "[29, 120] loss: 0.410\n",
      "[29, 180] loss: 0.412\n",
      "[29, 240] loss: 0.425\n",
      "[29, 300] loss: 0.405\n",
      "[29, 360] loss: 0.403\n",
      "Epoch: 29 -> Loss: 0.417862594128\n",
      "Epoch: 29 -> Test Accuracy: 81.81\n",
      "[30, 60] loss: 0.414\n",
      "[30, 120] loss: 0.398\n",
      "[30, 180] loss: 0.410\n",
      "[30, 240] loss: 0.412\n",
      "[30, 300] loss: 0.427\n",
      "[30, 360] loss: 0.399\n",
      "Epoch: 30 -> Loss: 0.437102228403\n",
      "Epoch: 30 -> Test Accuracy: 81.77\n",
      "[31, 60] loss: 0.386\n",
      "[31, 120] loss: 0.395\n",
      "[31, 180] loss: 0.407\n",
      "[31, 240] loss: 0.414\n",
      "[31, 300] loss: 0.397\n",
      "[31, 360] loss: 0.417\n",
      "Epoch: 31 -> Loss: 0.495404779911\n",
      "Epoch: 31 -> Test Accuracy: 81.85\n",
      "[32, 60] loss: 0.392\n",
      "[32, 120] loss: 0.399\n",
      "[32, 180] loss: 0.391\n",
      "[32, 240] loss: 0.410\n",
      "[32, 300] loss: 0.411\n",
      "[32, 360] loss: 0.408\n",
      "Epoch: 32 -> Loss: 0.386761665344\n",
      "Epoch: 32 -> Test Accuracy: 81.59\n",
      "[33, 60] loss: 0.383\n",
      "[33, 120] loss: 0.394\n",
      "[33, 180] loss: 0.397\n",
      "[33, 240] loss: 0.412\n",
      "[33, 300] loss: 0.400\n",
      "[33, 360] loss: 0.412\n",
      "Epoch: 33 -> Loss: 0.578221201897\n",
      "Epoch: 33 -> Test Accuracy: 82.01\n",
      "[34, 60] loss: 0.388\n",
      "[34, 120] loss: 0.381\n",
      "[34, 180] loss: 0.397\n",
      "[34, 240] loss: 0.392\n",
      "[34, 300] loss: 0.414\n",
      "[34, 360] loss: 0.414\n",
      "Epoch: 34 -> Loss: 0.37862688303\n",
      "Epoch: 34 -> Test Accuracy: 81.36\n",
      "[35, 60] loss: 0.391\n",
      "[35, 120] loss: 0.402\n",
      "[35, 180] loss: 0.377\n",
      "[35, 240] loss: 0.390\n",
      "[35, 300] loss: 0.392\n",
      "[35, 360] loss: 0.404\n",
      "Epoch: 35 -> Loss: 0.321468770504\n",
      "Epoch: 35 -> Test Accuracy: 82.19\n",
      "[36, 60] loss: 0.378\n",
      "[36, 120] loss: 0.383\n",
      "[36, 180] loss: 0.392\n",
      "[36, 240] loss: 0.406\n",
      "[36, 300] loss: 0.411\n",
      "[36, 360] loss: 0.398\n",
      "Epoch: 36 -> Loss: 0.343757629395\n",
      "Epoch: 36 -> Test Accuracy: 82.14\n",
      "[37, 60] loss: 0.389\n",
      "[37, 120] loss: 0.394\n",
      "[37, 180] loss: 0.389\n",
      "[37, 240] loss: 0.395\n",
      "[37, 300] loss: 0.400\n",
      "[37, 360] loss: 0.405\n",
      "Epoch: 37 -> Loss: 0.352990269661\n",
      "Epoch: 37 -> Test Accuracy: 81.86\n",
      "[38, 60] loss: 0.384\n",
      "[38, 120] loss: 0.388\n",
      "[38, 180] loss: 0.382\n",
      "[38, 240] loss: 0.402\n",
      "[38, 300] loss: 0.391\n",
      "[38, 360] loss: 0.427\n",
      "Epoch: 38 -> Loss: 0.353338479996\n",
      "Epoch: 38 -> Test Accuracy: 81.66\n",
      "[39, 60] loss: 0.389\n",
      "[39, 120] loss: 0.382\n",
      "[39, 180] loss: 0.383\n",
      "[39, 240] loss: 0.381\n",
      "[39, 300] loss: 0.409\n",
      "[39, 360] loss: 0.401\n",
      "Epoch: 39 -> Loss: 0.377798765898\n",
      "Epoch: 39 -> Test Accuracy: 82.23\n",
      "[40, 60] loss: 0.384\n",
      "[40, 120] loss: 0.389\n",
      "[40, 180] loss: 0.407\n",
      "[40, 240] loss: 0.397\n",
      "[40, 300] loss: 0.375\n",
      "[40, 360] loss: 0.403\n",
      "Epoch: 40 -> Loss: 0.410082817078\n",
      "Epoch: 40 -> Test Accuracy: 82.01\n",
      "[41, 60] loss: 0.375\n",
      "[41, 120] loss: 0.358\n",
      "[41, 180] loss: 0.352\n",
      "[41, 240] loss: 0.343\n",
      "[41, 300] loss: 0.341\n",
      "[41, 360] loss: 0.334\n",
      "Epoch: 41 -> Loss: 0.342916488647\n",
      "Epoch: 41 -> Test Accuracy: 83.01\n",
      "[42, 60] loss: 0.332\n",
      "[42, 120] loss: 0.347\n",
      "[42, 180] loss: 0.325\n",
      "[42, 240] loss: 0.330\n",
      "[42, 300] loss: 0.322\n",
      "[42, 360] loss: 0.318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.203508093953\n",
      "Epoch: 42 -> Test Accuracy: 83.2\n",
      "[43, 60] loss: 0.306\n",
      "[43, 120] loss: 0.330\n",
      "[43, 180] loss: 0.324\n",
      "[43, 240] loss: 0.323\n",
      "[43, 300] loss: 0.318\n",
      "[43, 360] loss: 0.308\n",
      "Epoch: 43 -> Loss: 0.395796865225\n",
      "Epoch: 43 -> Test Accuracy: 83.36\n",
      "[44, 60] loss: 0.295\n",
      "[44, 120] loss: 0.296\n",
      "[44, 180] loss: 0.325\n",
      "[44, 240] loss: 0.307\n",
      "[44, 300] loss: 0.294\n",
      "[44, 360] loss: 0.318\n",
      "Epoch: 44 -> Loss: 0.546502292156\n",
      "Epoch: 44 -> Test Accuracy: 83.57\n",
      "[45, 60] loss: 0.282\n",
      "[45, 120] loss: 0.287\n",
      "[45, 180] loss: 0.305\n",
      "[45, 240] loss: 0.301\n",
      "[45, 300] loss: 0.316\n",
      "[45, 360] loss: 0.295\n",
      "Epoch: 45 -> Loss: 0.281921863556\n",
      "Epoch: 45 -> Test Accuracy: 83.41\n",
      "[46, 60] loss: 0.287\n",
      "[46, 120] loss: 0.290\n",
      "[46, 180] loss: 0.283\n",
      "[46, 240] loss: 0.300\n",
      "[46, 300] loss: 0.282\n",
      "[46, 360] loss: 0.289\n",
      "Epoch: 46 -> Loss: 0.549962162971\n",
      "Epoch: 46 -> Test Accuracy: 83.56\n",
      "[47, 60] loss: 0.301\n",
      "[47, 120] loss: 0.268\n",
      "[47, 180] loss: 0.277\n",
      "[47, 240] loss: 0.269\n",
      "[47, 300] loss: 0.288\n",
      "[47, 360] loss: 0.301\n",
      "Epoch: 47 -> Loss: 0.354379713535\n",
      "Epoch: 47 -> Test Accuracy: 83.55\n",
      "[48, 60] loss: 0.291\n",
      "[48, 120] loss: 0.286\n",
      "[48, 180] loss: 0.279\n",
      "[48, 240] loss: 0.293\n",
      "[48, 300] loss: 0.284\n",
      "[48, 360] loss: 0.291\n",
      "Epoch: 48 -> Loss: 0.253436893225\n",
      "Epoch: 48 -> Test Accuracy: 83.64\n",
      "[49, 60] loss: 0.280\n",
      "[49, 120] loss: 0.282\n",
      "[49, 180] loss: 0.285\n",
      "[49, 240] loss: 0.283\n",
      "[49, 300] loss: 0.280\n",
      "[49, 360] loss: 0.272\n",
      "Epoch: 49 -> Loss: 0.350082695484\n",
      "Epoch: 49 -> Test Accuracy: 83.46\n",
      "[50, 60] loss: 0.279\n",
      "[50, 120] loss: 0.271\n",
      "[50, 180] loss: 0.292\n",
      "[50, 240] loss: 0.290\n",
      "[50, 300] loss: 0.289\n",
      "[50, 360] loss: 0.277\n",
      "Epoch: 50 -> Loss: 0.302632629871\n",
      "Epoch: 50 -> Test Accuracy: 83.56\n",
      "[51, 60] loss: 0.282\n",
      "[51, 120] loss: 0.262\n",
      "[51, 180] loss: 0.280\n",
      "[51, 240] loss: 0.282\n",
      "[51, 300] loss: 0.289\n",
      "[51, 360] loss: 0.278\n",
      "Epoch: 51 -> Loss: 0.345802277327\n",
      "Epoch: 51 -> Test Accuracy: 83.52\n",
      "[52, 60] loss: 0.263\n",
      "[52, 120] loss: 0.277\n",
      "[52, 180] loss: 0.268\n",
      "[52, 240] loss: 0.287\n",
      "[52, 300] loss: 0.275\n",
      "[52, 360] loss: 0.273\n",
      "Epoch: 52 -> Loss: 0.147413417697\n",
      "Epoch: 52 -> Test Accuracy: 83.6\n",
      "[53, 60] loss: 0.277\n",
      "[53, 120] loss: 0.283\n",
      "[53, 180] loss: 0.274\n",
      "[53, 240] loss: 0.283\n",
      "[53, 300] loss: 0.269\n",
      "[53, 360] loss: 0.264\n",
      "Epoch: 53 -> Loss: 0.269530415535\n",
      "Epoch: 53 -> Test Accuracy: 83.55\n",
      "[54, 60] loss: 0.265\n",
      "[54, 120] loss: 0.290\n",
      "[54, 180] loss: 0.281\n",
      "[54, 240] loss: 0.263\n",
      "[54, 300] loss: 0.280\n",
      "[54, 360] loss: 0.267\n",
      "Epoch: 54 -> Loss: 0.291301369667\n",
      "Epoch: 54 -> Test Accuracy: 83.71\n",
      "[55, 60] loss: 0.267\n",
      "[55, 120] loss: 0.278\n",
      "[55, 180] loss: 0.285\n",
      "[55, 240] loss: 0.267\n",
      "[55, 300] loss: 0.276\n",
      "[55, 360] loss: 0.278\n",
      "Epoch: 55 -> Loss: 0.206594899297\n",
      "Epoch: 55 -> Test Accuracy: 83.69\n",
      "[56, 60] loss: 0.269\n",
      "[56, 120] loss: 0.274\n",
      "[56, 180] loss: 0.294\n",
      "[56, 240] loss: 0.271\n",
      "[56, 300] loss: 0.272\n",
      "[56, 360] loss: 0.274\n",
      "Epoch: 56 -> Loss: 0.275197327137\n",
      "Epoch: 56 -> Test Accuracy: 83.65\n",
      "[57, 60] loss: 0.260\n",
      "[57, 120] loss: 0.268\n",
      "[57, 180] loss: 0.280\n",
      "[57, 240] loss: 0.265\n",
      "[57, 300] loss: 0.272\n",
      "[57, 360] loss: 0.285\n",
      "Epoch: 57 -> Loss: 0.211149215698\n",
      "Epoch: 57 -> Test Accuracy: 83.67\n",
      "[58, 60] loss: 0.272\n",
      "[58, 120] loss: 0.270\n",
      "[58, 180] loss: 0.269\n",
      "[58, 240] loss: 0.281\n",
      "[58, 300] loss: 0.261\n",
      "[58, 360] loss: 0.265\n",
      "Epoch: 58 -> Loss: 0.301922231913\n",
      "Epoch: 58 -> Test Accuracy: 83.59\n",
      "[59, 60] loss: 0.262\n",
      "[59, 120] loss: 0.260\n",
      "[59, 180] loss: 0.275\n",
      "[59, 240] loss: 0.274\n",
      "[59, 300] loss: 0.272\n",
      "[59, 360] loss: 0.269\n",
      "Epoch: 59 -> Loss: 0.298968076706\n",
      "Epoch: 59 -> Test Accuracy: 83.64\n",
      "[60, 60] loss: 0.261\n",
      "[60, 120] loss: 0.272\n",
      "[60, 180] loss: 0.275\n",
      "[60, 240] loss: 0.271\n",
      "[60, 300] loss: 0.263\n",
      "[60, 360] loss: 0.263\n",
      "Epoch: 60 -> Loss: 0.262776732445\n",
      "Epoch: 60 -> Test Accuracy: 83.61\n",
      "[61, 60] loss: 0.263\n",
      "[61, 120] loss: 0.263\n",
      "[61, 180] loss: 0.272\n",
      "[61, 240] loss: 0.260\n",
      "[61, 300] loss: 0.255\n",
      "[61, 360] loss: 0.263\n",
      "Epoch: 61 -> Loss: 0.159373417497\n",
      "Epoch: 61 -> Test Accuracy: 83.44\n",
      "[62, 60] loss: 0.257\n",
      "[62, 120] loss: 0.256\n",
      "[62, 180] loss: 0.266\n",
      "[62, 240] loss: 0.280\n",
      "[62, 300] loss: 0.251\n",
      "[62, 360] loss: 0.280\n",
      "Epoch: 62 -> Loss: 0.213886171579\n",
      "Epoch: 62 -> Test Accuracy: 83.59\n",
      "[63, 60] loss: 0.256\n",
      "[63, 120] loss: 0.272\n",
      "[63, 180] loss: 0.269\n",
      "[63, 240] loss: 0.262\n",
      "[63, 300] loss: 0.266\n",
      "[63, 360] loss: 0.269\n",
      "Epoch: 63 -> Loss: 0.286275267601\n",
      "Epoch: 63 -> Test Accuracy: 83.68\n",
      "[64, 60] loss: 0.252\n",
      "[64, 120] loss: 0.261\n",
      "[64, 180] loss: 0.251\n",
      "[64, 240] loss: 0.263\n",
      "[64, 300] loss: 0.273\n",
      "[64, 360] loss: 0.265\n",
      "Epoch: 64 -> Loss: 0.318299114704\n",
      "Epoch: 64 -> Test Accuracy: 83.7\n",
      "[65, 60] loss: 0.255\n",
      "[65, 120] loss: 0.267\n",
      "[65, 180] loss: 0.262\n",
      "[65, 240] loss: 0.273\n",
      "[65, 300] loss: 0.263\n",
      "[65, 360] loss: 0.268\n",
      "Epoch: 65 -> Loss: 0.18624971807\n",
      "Epoch: 65 -> Test Accuracy: 83.65\n",
      "[66, 60] loss: 0.267\n",
      "[66, 120] loss: 0.268\n",
      "[66, 180] loss: 0.245\n",
      "[66, 240] loss: 0.251\n",
      "[66, 300] loss: 0.261\n",
      "[66, 360] loss: 0.268\n",
      "Epoch: 66 -> Loss: 0.154118046165\n",
      "Epoch: 66 -> Test Accuracy: 83.63\n",
      "[67, 60] loss: 0.254\n",
      "[67, 120] loss: 0.260\n",
      "[67, 180] loss: 0.261\n",
      "[67, 240] loss: 0.270\n",
      "[67, 300] loss: 0.267\n",
      "[67, 360] loss: 0.252\n",
      "Epoch: 67 -> Loss: 0.404220432043\n",
      "Epoch: 67 -> Test Accuracy: 83.66\n",
      "[68, 60] loss: 0.268\n",
      "[68, 120] loss: 0.259\n",
      "[68, 180] loss: 0.257\n",
      "[68, 240] loss: 0.253\n",
      "[68, 300] loss: 0.250\n",
      "[68, 360] loss: 0.249\n",
      "Epoch: 68 -> Loss: 0.247941821814\n",
      "Epoch: 68 -> Test Accuracy: 83.59\n",
      "[69, 60] loss: 0.268\n",
      "[69, 120] loss: 0.255\n",
      "[69, 180] loss: 0.249\n",
      "[69, 240] loss: 0.255\n",
      "[69, 300] loss: 0.257\n",
      "[69, 360] loss: 0.255\n",
      "Epoch: 69 -> Loss: 0.230115368962\n",
      "Epoch: 69 -> Test Accuracy: 83.71\n",
      "[70, 60] loss: 0.256\n",
      "[70, 120] loss: 0.251\n",
      "[70, 180] loss: 0.246\n",
      "[70, 240] loss: 0.257\n",
      "[70, 300] loss: 0.266\n",
      "[70, 360] loss: 0.255\n",
      "Epoch: 70 -> Loss: 0.331393420696\n",
      "Epoch: 70 -> Test Accuracy: 83.72\n",
      "[71, 60] loss: 0.252\n",
      "[71, 120] loss: 0.249\n",
      "[71, 180] loss: 0.256\n",
      "[71, 240] loss: 0.256\n",
      "[71, 300] loss: 0.258\n",
      "[71, 360] loss: 0.241\n",
      "Epoch: 71 -> Loss: 0.264885872602\n",
      "Epoch: 71 -> Test Accuracy: 83.66\n",
      "[72, 60] loss: 0.254\n",
      "[72, 120] loss: 0.242\n",
      "[72, 180] loss: 0.253\n",
      "[72, 240] loss: 0.260\n",
      "[72, 300] loss: 0.242\n",
      "[72, 360] loss: 0.259\n",
      "Epoch: 72 -> Loss: 0.294948756695\n",
      "Epoch: 72 -> Test Accuracy: 83.63\n",
      "[73, 60] loss: 0.252\n",
      "[73, 120] loss: 0.255\n",
      "[73, 180] loss: 0.250\n",
      "[73, 240] loss: 0.252\n",
      "[73, 300] loss: 0.262\n",
      "[73, 360] loss: 0.262\n",
      "Epoch: 73 -> Loss: 0.334350407124\n",
      "Epoch: 73 -> Test Accuracy: 83.67\n",
      "[74, 60] loss: 0.252\n",
      "[74, 120] loss: 0.247\n",
      "[74, 180] loss: 0.257\n",
      "[74, 240] loss: 0.258\n",
      "[74, 300] loss: 0.246\n",
      "[74, 360] loss: 0.243\n",
      "Epoch: 74 -> Loss: 0.419766277075\n",
      "Epoch: 74 -> Test Accuracy: 83.76\n",
      "[75, 60] loss: 0.245\n",
      "[75, 120] loss: 0.245\n",
      "[75, 180] loss: 0.240\n",
      "[75, 240] loss: 0.240\n",
      "[75, 300] loss: 0.246\n",
      "[75, 360] loss: 0.251\n",
      "Epoch: 75 -> Loss: 0.208842560649\n",
      "Epoch: 75 -> Test Accuracy: 83.55\n",
      "[76, 60] loss: 0.253\n",
      "[76, 120] loss: 0.243\n",
      "[76, 180] loss: 0.250\n",
      "[76, 240] loss: 0.248\n",
      "[76, 300] loss: 0.255\n",
      "[76, 360] loss: 0.248\n",
      "Epoch: 76 -> Loss: 0.193769127131\n",
      "Epoch: 76 -> Test Accuracy: 83.52\n",
      "[77, 60] loss: 0.241\n",
      "[77, 120] loss: 0.241\n",
      "[77, 180] loss: 0.257\n",
      "[77, 240] loss: 0.248\n",
      "[77, 300] loss: 0.262\n",
      "[77, 360] loss: 0.252\n",
      "Epoch: 77 -> Loss: 0.189796313643\n",
      "Epoch: 77 -> Test Accuracy: 83.53\n",
      "[78, 60] loss: 0.253\n",
      "[78, 120] loss: 0.249\n",
      "[78, 180] loss: 0.240\n",
      "[78, 240] loss: 0.253\n",
      "[78, 300] loss: 0.241\n",
      "[78, 360] loss: 0.255\n",
      "Epoch: 78 -> Loss: 0.238433808088\n",
      "Epoch: 78 -> Test Accuracy: 83.56\n",
      "[79, 60] loss: 0.259\n",
      "[79, 120] loss: 0.238\n",
      "[79, 180] loss: 0.251\n",
      "[79, 240] loss: 0.255\n",
      "[79, 300] loss: 0.251\n",
      "[79, 360] loss: 0.233\n",
      "Epoch: 79 -> Loss: 0.182664766908\n",
      "Epoch: 79 -> Test Accuracy: 83.55\n",
      "[80, 60] loss: 0.248\n",
      "[80, 120] loss: 0.255\n",
      "[80, 180] loss: 0.247\n",
      "[80, 240] loss: 0.254\n",
      "[80, 300] loss: 0.248\n",
      "[80, 360] loss: 0.233\n",
      "Epoch: 80 -> Loss: 0.273757606745\n",
      "Epoch: 80 -> Test Accuracy: 83.59\n",
      "[81, 60] loss: 0.248\n",
      "[81, 120] loss: 0.244\n",
      "[81, 180] loss: 0.244\n",
      "[81, 240] loss: 0.247\n",
      "[81, 300] loss: 0.255\n",
      "[81, 360] loss: 0.237\n",
      "Epoch: 81 -> Loss: 0.308219820261\n",
      "Epoch: 81 -> Test Accuracy: 83.65\n",
      "[82, 60] loss: 0.226\n",
      "[82, 120] loss: 0.236\n",
      "[82, 180] loss: 0.249\n",
      "[82, 240] loss: 0.248\n",
      "[82, 300] loss: 0.247\n",
      "[82, 360] loss: 0.250\n",
      "Epoch: 82 -> Loss: 0.21916885674\n",
      "Epoch: 82 -> Test Accuracy: 83.69\n",
      "[83, 60] loss: 0.244\n",
      "[83, 120] loss: 0.251\n",
      "[83, 180] loss: 0.244\n",
      "[83, 240] loss: 0.247\n",
      "[83, 300] loss: 0.248\n",
      "[83, 360] loss: 0.237\n",
      "Epoch: 83 -> Loss: 0.252726972103\n",
      "Epoch: 83 -> Test Accuracy: 83.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.247\n",
      "[84, 120] loss: 0.243\n",
      "[84, 180] loss: 0.246\n",
      "[84, 240] loss: 0.244\n",
      "[84, 300] loss: 0.241\n",
      "[84, 360] loss: 0.248\n",
      "Epoch: 84 -> Loss: 0.164974316955\n",
      "Epoch: 84 -> Test Accuracy: 83.53\n",
      "[85, 60] loss: 0.224\n",
      "[85, 120] loss: 0.234\n",
      "[85, 180] loss: 0.258\n",
      "[85, 240] loss: 0.237\n",
      "[85, 300] loss: 0.241\n",
      "[85, 360] loss: 0.253\n",
      "Epoch: 85 -> Loss: 0.20973174274\n",
      "Epoch: 85 -> Test Accuracy: 83.57\n",
      "[86, 60] loss: 0.245\n",
      "[86, 120] loss: 0.242\n",
      "[86, 180] loss: 0.243\n",
      "[86, 240] loss: 0.246\n",
      "[86, 300] loss: 0.227\n",
      "[86, 360] loss: 0.238\n",
      "Epoch: 86 -> Loss: 0.342697739601\n",
      "Epoch: 86 -> Test Accuracy: 83.69\n",
      "[87, 60] loss: 0.238\n",
      "[87, 120] loss: 0.239\n",
      "[87, 180] loss: 0.251\n",
      "[87, 240] loss: 0.240\n",
      "[87, 300] loss: 0.246\n",
      "[87, 360] loss: 0.236\n",
      "Epoch: 87 -> Loss: 0.112039014697\n",
      "Epoch: 87 -> Test Accuracy: 83.43\n",
      "[88, 60] loss: 0.234\n",
      "[88, 120] loss: 0.240\n",
      "[88, 180] loss: 0.234\n",
      "[88, 240] loss: 0.227\n",
      "[88, 300] loss: 0.237\n",
      "[88, 360] loss: 0.238\n",
      "Epoch: 88 -> Loss: 0.327898234129\n",
      "Epoch: 88 -> Test Accuracy: 83.54\n",
      "[89, 60] loss: 0.246\n",
      "[89, 120] loss: 0.234\n",
      "[89, 180] loss: 0.228\n",
      "[89, 240] loss: 0.249\n",
      "[89, 300] loss: 0.237\n",
      "[89, 360] loss: 0.231\n",
      "Epoch: 89 -> Loss: 0.172284632921\n",
      "Epoch: 89 -> Test Accuracy: 83.53\n",
      "[90, 60] loss: 0.240\n",
      "[90, 120] loss: 0.251\n",
      "[90, 180] loss: 0.238\n",
      "[90, 240] loss: 0.240\n",
      "[90, 300] loss: 0.236\n",
      "[90, 360] loss: 0.237\n",
      "Epoch: 90 -> Loss: 0.108659207821\n",
      "Epoch: 90 -> Test Accuracy: 83.5\n",
      "[91, 60] loss: 0.223\n",
      "[91, 120] loss: 0.239\n",
      "[91, 180] loss: 0.229\n",
      "[91, 240] loss: 0.247\n",
      "[91, 300] loss: 0.239\n",
      "[91, 360] loss: 0.234\n",
      "Epoch: 91 -> Loss: 0.248663112521\n",
      "Epoch: 91 -> Test Accuracy: 83.6\n",
      "[92, 60] loss: 0.234\n",
      "[92, 120] loss: 0.245\n",
      "[92, 180] loss: 0.235\n",
      "[92, 240] loss: 0.238\n",
      "[92, 300] loss: 0.236\n",
      "[92, 360] loss: 0.257\n",
      "Epoch: 92 -> Loss: 0.224251657724\n",
      "Epoch: 92 -> Test Accuracy: 83.49\n",
      "[93, 60] loss: 0.224\n",
      "[93, 120] loss: 0.236\n",
      "[93, 180] loss: 0.226\n",
      "[93, 240] loss: 0.240\n",
      "[93, 300] loss: 0.240\n",
      "[93, 360] loss: 0.239\n",
      "Epoch: 93 -> Loss: 0.123657979071\n",
      "Epoch: 93 -> Test Accuracy: 83.64\n",
      "[94, 60] loss: 0.231\n",
      "[94, 120] loss: 0.231\n",
      "[94, 180] loss: 0.234\n",
      "[94, 240] loss: 0.233\n",
      "[94, 300] loss: 0.234\n",
      "[94, 360] loss: 0.232\n",
      "Epoch: 94 -> Loss: 0.255199015141\n",
      "Epoch: 94 -> Test Accuracy: 83.62\n",
      "[95, 60] loss: 0.233\n",
      "[95, 120] loss: 0.227\n",
      "[95, 180] loss: 0.229\n",
      "[95, 240] loss: 0.235\n",
      "[95, 300] loss: 0.240\n",
      "[95, 360] loss: 0.236\n",
      "Epoch: 95 -> Loss: 0.332764416933\n",
      "Epoch: 95 -> Test Accuracy: 83.56\n",
      "[96, 60] loss: 0.236\n",
      "[96, 120] loss: 0.237\n",
      "[96, 180] loss: 0.235\n",
      "[96, 240] loss: 0.240\n",
      "[96, 300] loss: 0.239\n",
      "[96, 360] loss: 0.235\n",
      "Epoch: 96 -> Loss: 0.297603130341\n",
      "Epoch: 96 -> Test Accuracy: 83.62\n",
      "[97, 60] loss: 0.233\n",
      "[97, 120] loss: 0.229\n",
      "[97, 180] loss: 0.225\n",
      "[97, 240] loss: 0.232\n",
      "[97, 300] loss: 0.225\n",
      "[97, 360] loss: 0.226\n",
      "Epoch: 97 -> Loss: 0.192263692617\n",
      "Epoch: 97 -> Test Accuracy: 83.36\n",
      "[98, 60] loss: 0.232\n",
      "[98, 120] loss: 0.224\n",
      "[98, 180] loss: 0.229\n",
      "[98, 240] loss: 0.224\n",
      "[98, 300] loss: 0.231\n",
      "[98, 360] loss: 0.242\n",
      "Epoch: 98 -> Loss: 0.123955965042\n",
      "Epoch: 98 -> Test Accuracy: 83.35\n",
      "[99, 60] loss: 0.224\n",
      "[99, 120] loss: 0.228\n",
      "[99, 180] loss: 0.238\n",
      "[99, 240] loss: 0.223\n",
      "[99, 300] loss: 0.228\n",
      "[99, 360] loss: 0.235\n",
      "Epoch: 99 -> Loss: 0.238090470433\n",
      "Epoch: 99 -> Test Accuracy: 83.45\n",
      "[100, 60] loss: 0.223\n",
      "[100, 120] loss: 0.230\n",
      "[100, 180] loss: 0.217\n",
      "[100, 240] loss: 0.227\n",
      "[100, 300] loss: 0.229\n",
      "[100, 360] loss: 0.244\n",
      "Epoch: 100 -> Loss: 0.401184856892\n",
      "Epoch: 100 -> Test Accuracy: 83.36\n",
      "Finished Training\n",
      "[1, 60] loss: 1.720\n",
      "[1, 120] loss: 0.820\n",
      "[1, 180] loss: 0.780\n",
      "[1, 240] loss: 0.698\n",
      "[1, 300] loss: 0.681\n",
      "[1, 360] loss: 0.681\n",
      "Epoch: 1 -> Loss: 0.668790817261\n",
      "Epoch: 1 -> Test Accuracy: 78.39\n",
      "[2, 60] loss: 0.611\n",
      "[2, 120] loss: 0.599\n",
      "[2, 180] loss: 0.575\n",
      "[2, 240] loss: 0.575\n",
      "[2, 300] loss: 0.559\n",
      "[2, 360] loss: 0.557\n",
      "Epoch: 2 -> Loss: 0.518618702888\n",
      "Epoch: 2 -> Test Accuracy: 80.48\n",
      "[3, 60] loss: 0.517\n",
      "[3, 120] loss: 0.538\n",
      "[3, 180] loss: 0.529\n",
      "[3, 240] loss: 0.515\n",
      "[3, 300] loss: 0.518\n",
      "[3, 360] loss: 0.501\n",
      "Epoch: 3 -> Loss: 0.54284965992\n",
      "Epoch: 3 -> Test Accuracy: 81.61\n",
      "[4, 60] loss: 0.480\n",
      "[4, 120] loss: 0.481\n",
      "[4, 180] loss: 0.492\n",
      "[4, 240] loss: 0.480\n",
      "[4, 300] loss: 0.491\n",
      "[4, 360] loss: 0.463\n",
      "Epoch: 4 -> Loss: 0.436032831669\n",
      "Epoch: 4 -> Test Accuracy: 82.47\n",
      "[5, 60] loss: 0.449\n",
      "[5, 120] loss: 0.455\n",
      "[5, 180] loss: 0.454\n",
      "[5, 240] loss: 0.452\n",
      "[5, 300] loss: 0.460\n",
      "[5, 360] loss: 0.468\n",
      "Epoch: 5 -> Loss: 0.552439272404\n",
      "Epoch: 5 -> Test Accuracy: 82.08\n",
      "[6, 60] loss: 0.439\n",
      "[6, 120] loss: 0.451\n",
      "[6, 180] loss: 0.440\n",
      "[6, 240] loss: 0.426\n",
      "[6, 300] loss: 0.451\n",
      "[6, 360] loss: 0.450\n",
      "Epoch: 6 -> Loss: 0.41356959939\n",
      "Epoch: 6 -> Test Accuracy: 83.19\n",
      "[7, 60] loss: 0.406\n",
      "[7, 120] loss: 0.425\n",
      "[7, 180] loss: 0.437\n",
      "[7, 240] loss: 0.439\n",
      "[7, 300] loss: 0.438\n",
      "[7, 360] loss: 0.404\n",
      "Epoch: 7 -> Loss: 0.432373613119\n",
      "Epoch: 7 -> Test Accuracy: 83.21\n",
      "[8, 60] loss: 0.402\n",
      "[8, 120] loss: 0.403\n",
      "[8, 180] loss: 0.422\n",
      "[8, 240] loss: 0.425\n",
      "[8, 300] loss: 0.431\n",
      "[8, 360] loss: 0.421\n",
      "Epoch: 8 -> Loss: 0.465481936932\n",
      "Epoch: 8 -> Test Accuracy: 83.2\n",
      "[9, 60] loss: 0.401\n",
      "[9, 120] loss: 0.394\n",
      "[9, 180] loss: 0.400\n",
      "[9, 240] loss: 0.429\n",
      "[9, 300] loss: 0.419\n",
      "[9, 360] loss: 0.439\n",
      "Epoch: 9 -> Loss: 0.569434762001\n",
      "Epoch: 9 -> Test Accuracy: 83.4\n",
      "[10, 60] loss: 0.394\n",
      "[10, 120] loss: 0.405\n",
      "[10, 180] loss: 0.398\n",
      "[10, 240] loss: 0.413\n",
      "[10, 300] loss: 0.428\n",
      "[10, 360] loss: 0.424\n",
      "Epoch: 10 -> Loss: 0.45695194602\n",
      "Epoch: 10 -> Test Accuracy: 83.6\n",
      "[11, 60] loss: 0.392\n",
      "[11, 120] loss: 0.393\n",
      "[11, 180] loss: 0.376\n",
      "[11, 240] loss: 0.403\n",
      "[11, 300] loss: 0.404\n",
      "[11, 360] loss: 0.403\n",
      "Epoch: 11 -> Loss: 0.397065788507\n",
      "Epoch: 11 -> Test Accuracy: 83.44\n",
      "[12, 60] loss: 0.376\n",
      "[12, 120] loss: 0.379\n",
      "[12, 180] loss: 0.383\n",
      "[12, 240] loss: 0.394\n",
      "[12, 300] loss: 0.395\n",
      "[12, 360] loss: 0.416\n",
      "Epoch: 12 -> Loss: 0.470592498779\n",
      "Epoch: 12 -> Test Accuracy: 83.24\n",
      "[13, 60] loss: 0.367\n",
      "[13, 120] loss: 0.391\n",
      "[13, 180] loss: 0.387\n",
      "[13, 240] loss: 0.397\n",
      "[13, 300] loss: 0.385\n",
      "[13, 360] loss: 0.406\n",
      "Epoch: 13 -> Loss: 0.490119278431\n",
      "Epoch: 13 -> Test Accuracy: 83.81\n",
      "[14, 60] loss: 0.377\n",
      "[14, 120] loss: 0.371\n",
      "[14, 180] loss: 0.378\n",
      "[14, 240] loss: 0.363\n",
      "[14, 300] loss: 0.383\n",
      "[14, 360] loss: 0.409\n",
      "Epoch: 14 -> Loss: 0.412298381329\n",
      "Epoch: 14 -> Test Accuracy: 83.9\n",
      "[15, 60] loss: 0.359\n",
      "[15, 120] loss: 0.359\n",
      "[15, 180] loss: 0.380\n",
      "[15, 240] loss: 0.386\n",
      "[15, 300] loss: 0.394\n",
      "[15, 360] loss: 0.399\n",
      "Epoch: 15 -> Loss: 0.289295613766\n",
      "Epoch: 15 -> Test Accuracy: 84.08\n",
      "[16, 60] loss: 0.361\n",
      "[16, 120] loss: 0.372\n",
      "[16, 180] loss: 0.378\n",
      "[16, 240] loss: 0.410\n",
      "[16, 300] loss: 0.381\n",
      "[16, 360] loss: 0.402\n",
      "Epoch: 16 -> Loss: 0.263494968414\n",
      "Epoch: 16 -> Test Accuracy: 84.59\n",
      "[17, 60] loss: 0.368\n",
      "[17, 120] loss: 0.363\n",
      "[17, 180] loss: 0.390\n",
      "[17, 240] loss: 0.386\n",
      "[17, 300] loss: 0.369\n",
      "[17, 360] loss: 0.383\n",
      "Epoch: 17 -> Loss: 0.46472248435\n",
      "Epoch: 17 -> Test Accuracy: 83.69\n",
      "[18, 60] loss: 0.352\n",
      "[18, 120] loss: 0.371\n",
      "[18, 180] loss: 0.371\n",
      "[18, 240] loss: 0.392\n",
      "[18, 300] loss: 0.381\n",
      "[18, 360] loss: 0.390\n",
      "Epoch: 18 -> Loss: 0.314830452204\n",
      "Epoch: 18 -> Test Accuracy: 84.28\n",
      "[19, 60] loss: 0.353\n",
      "[19, 120] loss: 0.370\n",
      "[19, 180] loss: 0.367\n",
      "[19, 240] loss: 0.378\n",
      "[19, 300] loss: 0.379\n",
      "[19, 360] loss: 0.374\n",
      "Epoch: 19 -> Loss: 0.356158852577\n",
      "Epoch: 19 -> Test Accuracy: 83.99\n",
      "[20, 60] loss: 0.366\n",
      "[20, 120] loss: 0.348\n",
      "[20, 180] loss: 0.368\n",
      "[20, 240] loss: 0.379\n",
      "[20, 300] loss: 0.380\n",
      "[20, 360] loss: 0.376\n",
      "Epoch: 20 -> Loss: 0.359889298677\n",
      "Epoch: 20 -> Test Accuracy: 84.19\n",
      "[21, 60] loss: 0.341\n",
      "[21, 120] loss: 0.305\n",
      "[21, 180] loss: 0.310\n",
      "[21, 240] loss: 0.271\n",
      "[21, 300] loss: 0.297\n",
      "[21, 360] loss: 0.285\n",
      "Epoch: 21 -> Loss: 0.337404251099\n",
      "Epoch: 21 -> Test Accuracy: 85.82\n",
      "[22, 60] loss: 0.277\n",
      "[22, 120] loss: 0.264\n",
      "[22, 180] loss: 0.267\n",
      "[22, 240] loss: 0.265\n",
      "[22, 300] loss: 0.265\n",
      "[22, 360] loss: 0.264\n",
      "Epoch: 22 -> Loss: 0.332636833191\n",
      "Epoch: 22 -> Test Accuracy: 86.11\n",
      "[23, 60] loss: 0.238\n",
      "[23, 120] loss: 0.245\n",
      "[23, 180] loss: 0.250\n",
      "[23, 240] loss: 0.259\n",
      "[23, 300] loss: 0.257\n",
      "[23, 360] loss: 0.251\n",
      "Epoch: 23 -> Loss: 0.27460205555\n",
      "Epoch: 23 -> Test Accuracy: 86.57\n",
      "[24, 60] loss: 0.229\n",
      "[24, 120] loss: 0.233\n",
      "[24, 180] loss: 0.238\n",
      "[24, 240] loss: 0.237\n",
      "[24, 300] loss: 0.238\n",
      "[24, 360] loss: 0.226\n",
      "Epoch: 24 -> Loss: 0.375533878803\n",
      "Epoch: 24 -> Test Accuracy: 86.75\n",
      "[25, 60] loss: 0.219\n",
      "[25, 120] loss: 0.212\n",
      "[25, 180] loss: 0.237\n",
      "[25, 240] loss: 0.213\n",
      "[25, 300] loss: 0.233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 360] loss: 0.232\n",
      "Epoch: 25 -> Loss: 0.33040446043\n",
      "Epoch: 25 -> Test Accuracy: 86.19\n",
      "[26, 60] loss: 0.209\n",
      "[26, 120] loss: 0.224\n",
      "[26, 180] loss: 0.228\n",
      "[26, 240] loss: 0.219\n",
      "[26, 300] loss: 0.226\n",
      "[26, 360] loss: 0.225\n",
      "Epoch: 26 -> Loss: 0.15293392539\n",
      "Epoch: 26 -> Test Accuracy: 86.11\n",
      "[27, 60] loss: 0.217\n",
      "[27, 120] loss: 0.207\n",
      "[27, 180] loss: 0.206\n",
      "[27, 240] loss: 0.210\n",
      "[27, 300] loss: 0.231\n",
      "[27, 360] loss: 0.211\n",
      "Epoch: 27 -> Loss: 0.372671753168\n",
      "Epoch: 27 -> Test Accuracy: 85.95\n",
      "[28, 60] loss: 0.204\n",
      "[28, 120] loss: 0.209\n",
      "[28, 180] loss: 0.207\n",
      "[28, 240] loss: 0.223\n",
      "[28, 300] loss: 0.224\n",
      "[28, 360] loss: 0.205\n",
      "Epoch: 28 -> Loss: 0.217478230596\n",
      "Epoch: 28 -> Test Accuracy: 86.57\n",
      "[29, 60] loss: 0.196\n",
      "[29, 120] loss: 0.206\n",
      "[29, 180] loss: 0.206\n",
      "[29, 240] loss: 0.204\n",
      "[29, 300] loss: 0.215\n",
      "[29, 360] loss: 0.222\n",
      "Epoch: 29 -> Loss: 0.268197536469\n",
      "Epoch: 29 -> Test Accuracy: 86.48\n",
      "[30, 60] loss: 0.199\n",
      "[30, 120] loss: 0.210\n",
      "[30, 180] loss: 0.204\n",
      "[30, 240] loss: 0.214\n",
      "[30, 300] loss: 0.209\n",
      "[30, 360] loss: 0.210\n",
      "Epoch: 30 -> Loss: 0.251915186644\n",
      "Epoch: 30 -> Test Accuracy: 85.81\n",
      "[31, 60] loss: 0.195\n",
      "[31, 120] loss: 0.195\n",
      "[31, 180] loss: 0.200\n",
      "[31, 240] loss: 0.209\n",
      "[31, 300] loss: 0.207\n",
      "[31, 360] loss: 0.219\n",
      "Epoch: 31 -> Loss: 0.21470245719\n",
      "Epoch: 31 -> Test Accuracy: 85.82\n",
      "[32, 60] loss: 0.196\n",
      "[32, 120] loss: 0.190\n",
      "[32, 180] loss: 0.195\n",
      "[32, 240] loss: 0.207\n",
      "[32, 300] loss: 0.204\n",
      "[32, 360] loss: 0.216\n",
      "Epoch: 32 -> Loss: 0.206786602736\n",
      "Epoch: 32 -> Test Accuracy: 86.33\n",
      "[33, 60] loss: 0.201\n",
      "[33, 120] loss: 0.192\n",
      "[33, 180] loss: 0.191\n",
      "[33, 240] loss: 0.202\n",
      "[33, 300] loss: 0.207\n",
      "[33, 360] loss: 0.206\n",
      "Epoch: 33 -> Loss: 0.293103009462\n",
      "Epoch: 33 -> Test Accuracy: 85.96\n",
      "[34, 60] loss: 0.193\n",
      "[34, 120] loss: 0.190\n",
      "[34, 180] loss: 0.204\n",
      "[34, 240] loss: 0.190\n",
      "[34, 300] loss: 0.198\n",
      "[34, 360] loss: 0.215\n",
      "Epoch: 34 -> Loss: 0.196565166116\n",
      "Epoch: 34 -> Test Accuracy: 86.15\n",
      "[35, 60] loss: 0.190\n",
      "[35, 120] loss: 0.194\n",
      "[35, 180] loss: 0.197\n",
      "[35, 240] loss: 0.188\n",
      "[35, 300] loss: 0.204\n",
      "[35, 360] loss: 0.199\n",
      "Epoch: 35 -> Loss: 0.145626544952\n",
      "Epoch: 35 -> Test Accuracy: 85.85\n",
      "[36, 60] loss: 0.199\n",
      "[36, 120] loss: 0.188\n",
      "[36, 180] loss: 0.190\n",
      "[36, 240] loss: 0.195\n",
      "[36, 300] loss: 0.203\n",
      "[36, 360] loss: 0.202\n",
      "Epoch: 36 -> Loss: 0.183900505304\n",
      "Epoch: 36 -> Test Accuracy: 86.1\n",
      "[37, 60] loss: 0.191\n",
      "[37, 120] loss: 0.190\n",
      "[37, 180] loss: 0.206\n",
      "[37, 240] loss: 0.189\n",
      "[37, 300] loss: 0.209\n",
      "[37, 360] loss: 0.207\n",
      "Epoch: 37 -> Loss: 0.19815865159\n",
      "Epoch: 37 -> Test Accuracy: 85.88\n",
      "[38, 60] loss: 0.193\n",
      "[38, 120] loss: 0.188\n",
      "[38, 180] loss: 0.206\n",
      "[38, 240] loss: 0.196\n",
      "[38, 300] loss: 0.197\n",
      "[38, 360] loss: 0.210\n",
      "Epoch: 38 -> Loss: 0.234115988016\n",
      "Epoch: 38 -> Test Accuracy: 86.12\n",
      "[39, 60] loss: 0.187\n",
      "[39, 120] loss: 0.185\n",
      "[39, 180] loss: 0.200\n",
      "[39, 240] loss: 0.210\n",
      "[39, 300] loss: 0.197\n",
      "[39, 360] loss: 0.206\n",
      "Epoch: 39 -> Loss: 0.35375803709\n",
      "Epoch: 39 -> Test Accuracy: 85.66\n",
      "[40, 60] loss: 0.197\n",
      "[40, 120] loss: 0.188\n",
      "[40, 180] loss: 0.194\n",
      "[40, 240] loss: 0.194\n",
      "[40, 300] loss: 0.206\n",
      "[40, 360] loss: 0.208\n",
      "Epoch: 40 -> Loss: 0.182641029358\n",
      "Epoch: 40 -> Test Accuracy: 85.94\n",
      "[41, 60] loss: 0.174\n",
      "[41, 120] loss: 0.168\n",
      "[41, 180] loss: 0.164\n",
      "[41, 240] loss: 0.143\n",
      "[41, 300] loss: 0.159\n",
      "[41, 360] loss: 0.166\n",
      "Epoch: 41 -> Loss: 0.250245988369\n",
      "Epoch: 41 -> Test Accuracy: 86.4\n",
      "[42, 60] loss: 0.148\n",
      "[42, 120] loss: 0.149\n",
      "[42, 180] loss: 0.149\n",
      "[42, 240] loss: 0.148\n",
      "[42, 300] loss: 0.149\n",
      "[42, 360] loss: 0.142\n",
      "Epoch: 42 -> Loss: 0.118372321129\n",
      "Epoch: 42 -> Test Accuracy: 86.48\n",
      "[43, 60] loss: 0.141\n",
      "[43, 120] loss: 0.136\n",
      "[43, 180] loss: 0.139\n",
      "[43, 240] loss: 0.134\n",
      "[43, 300] loss: 0.141\n",
      "[43, 360] loss: 0.142\n",
      "Epoch: 43 -> Loss: 0.0729807913303\n",
      "Epoch: 43 -> Test Accuracy: 86.52\n",
      "[44, 60] loss: 0.131\n",
      "[44, 120] loss: 0.130\n",
      "[44, 180] loss: 0.140\n",
      "[44, 240] loss: 0.135\n",
      "[44, 300] loss: 0.135\n",
      "[44, 360] loss: 0.130\n",
      "Epoch: 44 -> Loss: 0.127387747169\n",
      "Epoch: 44 -> Test Accuracy: 86.51\n",
      "[45, 60] loss: 0.123\n",
      "[45, 120] loss: 0.130\n",
      "[45, 180] loss: 0.130\n",
      "[45, 240] loss: 0.125\n",
      "[45, 300] loss: 0.131\n",
      "[45, 360] loss: 0.123\n",
      "Epoch: 45 -> Loss: 0.120789982378\n",
      "Epoch: 45 -> Test Accuracy: 86.94\n",
      "[46, 60] loss: 0.121\n",
      "[46, 120] loss: 0.121\n",
      "[46, 180] loss: 0.121\n",
      "[46, 240] loss: 0.120\n",
      "[46, 300] loss: 0.123\n",
      "[46, 360] loss: 0.123\n",
      "Epoch: 46 -> Loss: 0.149049848318\n",
      "Epoch: 46 -> Test Accuracy: 86.94\n",
      "[47, 60] loss: 0.117\n",
      "[47, 120] loss: 0.121\n",
      "[47, 180] loss: 0.118\n",
      "[47, 240] loss: 0.114\n",
      "[47, 300] loss: 0.125\n",
      "[47, 360] loss: 0.112\n",
      "Epoch: 47 -> Loss: 0.0805044844747\n",
      "Epoch: 47 -> Test Accuracy: 86.93\n",
      "[48, 60] loss: 0.119\n",
      "[48, 120] loss: 0.118\n",
      "[48, 180] loss: 0.112\n",
      "[48, 240] loss: 0.108\n",
      "[48, 300] loss: 0.121\n",
      "[48, 360] loss: 0.121\n",
      "Epoch: 48 -> Loss: 0.156961172819\n",
      "Epoch: 48 -> Test Accuracy: 86.88\n",
      "[49, 60] loss: 0.109\n",
      "[49, 120] loss: 0.119\n",
      "[49, 180] loss: 0.112\n",
      "[49, 240] loss: 0.112\n",
      "[49, 300] loss: 0.117\n",
      "[49, 360] loss: 0.121\n",
      "Epoch: 49 -> Loss: 0.0993171557784\n",
      "Epoch: 49 -> Test Accuracy: 86.85\n",
      "[50, 60] loss: 0.111\n",
      "[50, 120] loss: 0.113\n",
      "[50, 180] loss: 0.108\n",
      "[50, 240] loss: 0.117\n",
      "[50, 300] loss: 0.119\n",
      "[50, 360] loss: 0.115\n",
      "Epoch: 50 -> Loss: 0.147161975503\n",
      "Epoch: 50 -> Test Accuracy: 86.94\n",
      "[51, 60] loss: 0.111\n",
      "[51, 120] loss: 0.109\n",
      "[51, 180] loss: 0.117\n",
      "[51, 240] loss: 0.119\n",
      "[51, 300] loss: 0.109\n",
      "[51, 360] loss: 0.114\n",
      "Epoch: 51 -> Loss: 0.175433307886\n",
      "Epoch: 51 -> Test Accuracy: 86.91\n",
      "[52, 60] loss: 0.111\n",
      "[52, 120] loss: 0.104\n",
      "[52, 180] loss: 0.111\n",
      "[52, 240] loss: 0.115\n",
      "[52, 300] loss: 0.117\n",
      "[52, 360] loss: 0.110\n",
      "Epoch: 52 -> Loss: 0.0737187415361\n",
      "Epoch: 52 -> Test Accuracy: 86.9\n",
      "[53, 60] loss: 0.103\n",
      "[53, 120] loss: 0.110\n",
      "[53, 180] loss: 0.115\n",
      "[53, 240] loss: 0.109\n",
      "[53, 300] loss: 0.114\n",
      "[53, 360] loss: 0.101\n",
      "Epoch: 53 -> Loss: 0.0974029749632\n",
      "Epoch: 53 -> Test Accuracy: 86.92\n",
      "[54, 60] loss: 0.108\n",
      "[54, 120] loss: 0.110\n",
      "[54, 180] loss: 0.102\n",
      "[54, 240] loss: 0.108\n",
      "[54, 300] loss: 0.107\n",
      "[54, 360] loss: 0.113\n",
      "Epoch: 54 -> Loss: 0.163277611136\n",
      "Epoch: 54 -> Test Accuracy: 86.94\n",
      "[55, 60] loss: 0.105\n",
      "[55, 120] loss: 0.097\n",
      "[55, 180] loss: 0.105\n",
      "[55, 240] loss: 0.108\n",
      "[55, 300] loss: 0.106\n",
      "[55, 360] loss: 0.118\n",
      "Epoch: 55 -> Loss: 0.164786726236\n",
      "Epoch: 55 -> Test Accuracy: 86.9\n",
      "[56, 60] loss: 0.109\n",
      "[56, 120] loss: 0.107\n",
      "[56, 180] loss: 0.104\n",
      "[56, 240] loss: 0.103\n",
      "[56, 300] loss: 0.110\n",
      "[56, 360] loss: 0.107\n",
      "Epoch: 56 -> Loss: 0.225197508931\n",
      "Epoch: 56 -> Test Accuracy: 86.96\n",
      "[57, 60] loss: 0.108\n",
      "[57, 120] loss: 0.108\n",
      "[57, 180] loss: 0.106\n",
      "[57, 240] loss: 0.100\n",
      "[57, 300] loss: 0.108\n",
      "[57, 360] loss: 0.112\n",
      "Epoch: 57 -> Loss: 0.116636052728\n",
      "Epoch: 57 -> Test Accuracy: 86.96\n",
      "[58, 60] loss: 0.105\n",
      "[58, 120] loss: 0.108\n",
      "[58, 180] loss: 0.099\n",
      "[58, 240] loss: 0.100\n",
      "[58, 300] loss: 0.104\n",
      "[58, 360] loss: 0.108\n",
      "Epoch: 58 -> Loss: 0.0597328729928\n",
      "Epoch: 58 -> Test Accuracy: 86.89\n",
      "[59, 60] loss: 0.104\n",
      "[59, 120] loss: 0.100\n",
      "[59, 180] loss: 0.101\n",
      "[59, 240] loss: 0.109\n",
      "[59, 300] loss: 0.097\n",
      "[59, 360] loss: 0.097\n",
      "Epoch: 59 -> Loss: 0.165486171842\n",
      "Epoch: 59 -> Test Accuracy: 86.93\n",
      "[60, 60] loss: 0.100\n",
      "[60, 120] loss: 0.109\n",
      "[60, 180] loss: 0.101\n",
      "[60, 240] loss: 0.101\n",
      "[60, 300] loss: 0.100\n",
      "[60, 360] loss: 0.103\n",
      "Epoch: 60 -> Loss: 0.0867592468858\n",
      "Epoch: 60 -> Test Accuracy: 86.97\n",
      "[61, 60] loss: 0.110\n",
      "[61, 120] loss: 0.104\n",
      "[61, 180] loss: 0.100\n",
      "[61, 240] loss: 0.103\n",
      "[61, 300] loss: 0.102\n",
      "[61, 360] loss: 0.094\n",
      "Epoch: 61 -> Loss: 0.113060951233\n",
      "Epoch: 61 -> Test Accuracy: 86.86\n",
      "[62, 60] loss: 0.100\n",
      "[62, 120] loss: 0.094\n",
      "[62, 180] loss: 0.090\n",
      "[62, 240] loss: 0.099\n",
      "[62, 300] loss: 0.109\n",
      "[62, 360] loss: 0.105\n",
      "Epoch: 62 -> Loss: 0.169707641006\n",
      "Epoch: 62 -> Test Accuracy: 86.95\n",
      "[63, 60] loss: 0.104\n",
      "[63, 120] loss: 0.096\n",
      "[63, 180] loss: 0.103\n",
      "[63, 240] loss: 0.092\n",
      "[63, 300] loss: 0.101\n",
      "[63, 360] loss: 0.101\n",
      "Epoch: 63 -> Loss: 0.10827896744\n",
      "Epoch: 63 -> Test Accuracy: 86.94\n",
      "[64, 60] loss: 0.088\n",
      "[64, 120] loss: 0.095\n",
      "[64, 180] loss: 0.096\n",
      "[64, 240] loss: 0.100\n",
      "[64, 300] loss: 0.106\n",
      "[64, 360] loss: 0.104\n",
      "Epoch: 64 -> Loss: 0.140646874905\n",
      "Epoch: 64 -> Test Accuracy: 86.86\n",
      "[65, 60] loss: 0.095\n",
      "[65, 120] loss: 0.091\n",
      "[65, 180] loss: 0.100\n",
      "[65, 240] loss: 0.095\n",
      "[65, 300] loss: 0.100\n",
      "[65, 360] loss: 0.103\n",
      "Epoch: 65 -> Loss: 0.0604255385697\n",
      "Epoch: 65 -> Test Accuracy: 86.89\n",
      "[66, 60] loss: 0.094\n",
      "[66, 120] loss: 0.094\n",
      "[66, 180] loss: 0.091\n",
      "[66, 240] loss: 0.101\n",
      "[66, 300] loss: 0.105\n",
      "[66, 360] loss: 0.092\n",
      "Epoch: 66 -> Loss: 0.116152822971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Test Accuracy: 86.96\n",
      "[67, 60] loss: 0.101\n",
      "[67, 120] loss: 0.093\n",
      "[67, 180] loss: 0.096\n",
      "[67, 240] loss: 0.101\n",
      "[67, 300] loss: 0.099\n",
      "[67, 360] loss: 0.096\n",
      "Epoch: 67 -> Loss: 0.0800305232406\n",
      "Epoch: 67 -> Test Accuracy: 86.83\n",
      "[68, 60] loss: 0.097\n",
      "[68, 120] loss: 0.093\n",
      "[68, 180] loss: 0.092\n",
      "[68, 240] loss: 0.096\n",
      "[68, 300] loss: 0.094\n",
      "[68, 360] loss: 0.097\n",
      "Epoch: 68 -> Loss: 0.0585989542305\n",
      "Epoch: 68 -> Test Accuracy: 86.92\n",
      "[69, 60] loss: 0.099\n",
      "[69, 120] loss: 0.095\n",
      "[69, 180] loss: 0.093\n",
      "[69, 240] loss: 0.104\n",
      "[69, 300] loss: 0.092\n",
      "[69, 360] loss: 0.089\n",
      "Epoch: 69 -> Loss: 0.0422497317195\n",
      "Epoch: 69 -> Test Accuracy: 86.91\n",
      "[70, 60] loss: 0.093\n",
      "[70, 120] loss: 0.094\n",
      "[70, 180] loss: 0.093\n",
      "[70, 240] loss: 0.097\n",
      "[70, 300] loss: 0.105\n",
      "[70, 360] loss: 0.090\n",
      "Epoch: 70 -> Loss: 0.0596608109772\n",
      "Epoch: 70 -> Test Accuracy: 86.85\n",
      "[71, 60] loss: 0.102\n",
      "[71, 120] loss: 0.097\n",
      "[71, 180] loss: 0.095\n",
      "[71, 240] loss: 0.093\n",
      "[71, 300] loss: 0.091\n",
      "[71, 360] loss: 0.086\n",
      "Epoch: 71 -> Loss: 0.0471122190356\n",
      "Epoch: 71 -> Test Accuracy: 86.97\n",
      "[72, 60] loss: 0.088\n",
      "[72, 120] loss: 0.089\n",
      "[72, 180] loss: 0.087\n",
      "[72, 240] loss: 0.090\n",
      "[72, 300] loss: 0.091\n",
      "[72, 360] loss: 0.100\n",
      "Epoch: 72 -> Loss: 0.090664640069\n",
      "Epoch: 72 -> Test Accuracy: 86.93\n",
      "[73, 60] loss: 0.093\n",
      "[73, 120] loss: 0.095\n",
      "[73, 180] loss: 0.088\n",
      "[73, 240] loss: 0.093\n",
      "[73, 300] loss: 0.084\n",
      "[73, 360] loss: 0.097\n",
      "Epoch: 73 -> Loss: 0.153961747885\n",
      "Epoch: 73 -> Test Accuracy: 86.98\n",
      "[74, 60] loss: 0.088\n",
      "[74, 120] loss: 0.094\n",
      "[74, 180] loss: 0.097\n",
      "[74, 240] loss: 0.093\n",
      "[74, 300] loss: 0.092\n",
      "[74, 360] loss: 0.088\n",
      "Epoch: 74 -> Loss: 0.0356141850352\n",
      "Epoch: 74 -> Test Accuracy: 86.85\n",
      "[75, 60] loss: 0.094\n",
      "[75, 120] loss: 0.093\n",
      "[75, 180] loss: 0.088\n",
      "[75, 240] loss: 0.085\n",
      "[75, 300] loss: 0.094\n",
      "[75, 360] loss: 0.091\n",
      "Epoch: 75 -> Loss: 0.0494329631329\n",
      "Epoch: 75 -> Test Accuracy: 86.82\n",
      "[76, 60] loss: 0.093\n",
      "[76, 120] loss: 0.091\n",
      "[76, 180] loss: 0.093\n",
      "[76, 240] loss: 0.087\n",
      "[76, 300] loss: 0.090\n",
      "[76, 360] loss: 0.093\n",
      "Epoch: 76 -> Loss: 0.173744827509\n",
      "Epoch: 76 -> Test Accuracy: 86.79\n",
      "[77, 60] loss: 0.087\n",
      "[77, 120] loss: 0.094\n",
      "[77, 180] loss: 0.089\n",
      "[77, 240] loss: 0.089\n",
      "[77, 300] loss: 0.085\n",
      "[77, 360] loss: 0.094\n",
      "Epoch: 77 -> Loss: 0.0665050074458\n",
      "Epoch: 77 -> Test Accuracy: 86.87\n",
      "[78, 60] loss: 0.094\n",
      "[78, 120] loss: 0.088\n",
      "[78, 180] loss: 0.081\n",
      "[78, 240] loss: 0.090\n",
      "[78, 300] loss: 0.097\n",
      "[78, 360] loss: 0.090\n",
      "Epoch: 78 -> Loss: 0.0980572402477\n",
      "Epoch: 78 -> Test Accuracy: 86.79\n",
      "[79, 60] loss: 0.090\n",
      "[79, 120] loss: 0.079\n",
      "[79, 180] loss: 0.085\n",
      "[79, 240] loss: 0.090\n",
      "[79, 300] loss: 0.087\n",
      "[79, 360] loss: 0.097\n",
      "Epoch: 79 -> Loss: 0.126461476088\n",
      "Epoch: 79 -> Test Accuracy: 86.77\n",
      "[80, 60] loss: 0.086\n",
      "[80, 120] loss: 0.089\n",
      "[80, 180] loss: 0.089\n",
      "[80, 240] loss: 0.085\n",
      "[80, 300] loss: 0.090\n",
      "[80, 360] loss: 0.083\n",
      "Epoch: 80 -> Loss: 0.0966233387589\n",
      "Epoch: 80 -> Test Accuracy: 86.78\n",
      "[81, 60] loss: 0.088\n",
      "[81, 120] loss: 0.082\n",
      "[81, 180] loss: 0.086\n",
      "[81, 240] loss: 0.087\n",
      "[81, 300] loss: 0.079\n",
      "[81, 360] loss: 0.089\n",
      "Epoch: 81 -> Loss: 0.0879682600498\n",
      "Epoch: 81 -> Test Accuracy: 86.73\n",
      "[82, 60] loss: 0.090\n",
      "[82, 120] loss: 0.080\n",
      "[82, 180] loss: 0.086\n",
      "[82, 240] loss: 0.090\n",
      "[82, 300] loss: 0.088\n",
      "[82, 360] loss: 0.094\n",
      "Epoch: 82 -> Loss: 0.0821733027697\n",
      "Epoch: 82 -> Test Accuracy: 86.7\n",
      "[83, 60] loss: 0.081\n",
      "[83, 120] loss: 0.095\n",
      "[83, 180] loss: 0.090\n",
      "[83, 240] loss: 0.080\n",
      "[83, 300] loss: 0.087\n",
      "[83, 360] loss: 0.089\n",
      "Epoch: 83 -> Loss: 0.111677847803\n",
      "Epoch: 83 -> Test Accuracy: 86.76\n",
      "[84, 60] loss: 0.091\n",
      "[84, 120] loss: 0.083\n",
      "[84, 180] loss: 0.083\n",
      "[84, 240] loss: 0.088\n",
      "[84, 300] loss: 0.083\n",
      "[84, 360] loss: 0.078\n",
      "Epoch: 84 -> Loss: 0.101370356977\n",
      "Epoch: 84 -> Test Accuracy: 86.85\n",
      "[85, 60] loss: 0.085\n",
      "[85, 120] loss: 0.083\n",
      "[85, 180] loss: 0.083\n",
      "[85, 240] loss: 0.083\n",
      "[85, 300] loss: 0.083\n",
      "[85, 360] loss: 0.081\n",
      "Epoch: 85 -> Loss: 0.14815326035\n",
      "Epoch: 85 -> Test Accuracy: 86.89\n",
      "[86, 60] loss: 0.084\n",
      "[86, 120] loss: 0.076\n",
      "[86, 180] loss: 0.083\n",
      "[86, 240] loss: 0.082\n",
      "[86, 300] loss: 0.086\n",
      "[86, 360] loss: 0.087\n",
      "Epoch: 86 -> Loss: 0.0750930160284\n",
      "Epoch: 86 -> Test Accuracy: 86.88\n",
      "[87, 60] loss: 0.083\n",
      "[87, 120] loss: 0.085\n",
      "[87, 180] loss: 0.086\n",
      "[87, 240] loss: 0.083\n",
      "[87, 300] loss: 0.080\n",
      "[87, 360] loss: 0.084\n",
      "Epoch: 87 -> Loss: 0.182400152087\n",
      "Epoch: 87 -> Test Accuracy: 86.81\n",
      "[88, 60] loss: 0.081\n",
      "[88, 120] loss: 0.083\n",
      "[88, 180] loss: 0.085\n",
      "[88, 240] loss: 0.081\n",
      "[88, 300] loss: 0.085\n",
      "[88, 360] loss: 0.085\n",
      "Epoch: 88 -> Loss: 0.177525401115\n",
      "Epoch: 88 -> Test Accuracy: 86.85\n",
      "[89, 60] loss: 0.078\n",
      "[89, 120] loss: 0.080\n",
      "[89, 180] loss: 0.084\n",
      "[89, 240] loss: 0.083\n",
      "[89, 300] loss: 0.083\n",
      "[89, 360] loss: 0.078\n",
      "Epoch: 89 -> Loss: 0.125337600708\n",
      "Epoch: 89 -> Test Accuracy: 87.06\n",
      "[90, 60] loss: 0.086\n",
      "[90, 120] loss: 0.075\n",
      "[90, 180] loss: 0.084\n",
      "[90, 240] loss: 0.078\n",
      "[90, 300] loss: 0.082\n",
      "[90, 360] loss: 0.085\n",
      "Epoch: 90 -> Loss: 0.0672893673182\n",
      "Epoch: 90 -> Test Accuracy: 86.96\n",
      "[91, 60] loss: 0.083\n",
      "[91, 120] loss: 0.079\n",
      "[91, 180] loss: 0.084\n",
      "[91, 240] loss: 0.086\n",
      "[91, 300] loss: 0.082\n",
      "[91, 360] loss: 0.081\n",
      "Epoch: 91 -> Loss: 0.158251091838\n",
      "Epoch: 91 -> Test Accuracy: 86.92\n",
      "[92, 60] loss: 0.078\n",
      "[92, 120] loss: 0.085\n",
      "[92, 180] loss: 0.072\n",
      "[92, 240] loss: 0.083\n",
      "[92, 300] loss: 0.081\n",
      "[92, 360] loss: 0.083\n",
      "Epoch: 92 -> Loss: 0.111176706851\n",
      "Epoch: 92 -> Test Accuracy: 86.89\n",
      "[93, 60] loss: 0.079\n",
      "[93, 120] loss: 0.078\n",
      "[93, 180] loss: 0.082\n",
      "[93, 240] loss: 0.079\n",
      "[93, 300] loss: 0.079\n",
      "[93, 360] loss: 0.082\n",
      "Epoch: 93 -> Loss: 0.0998524054885\n",
      "Epoch: 93 -> Test Accuracy: 86.91\n",
      "[94, 60] loss: 0.083\n",
      "[94, 120] loss: 0.073\n",
      "[94, 180] loss: 0.074\n",
      "[94, 240] loss: 0.080\n",
      "[94, 300] loss: 0.076\n",
      "[94, 360] loss: 0.079\n",
      "Epoch: 94 -> Loss: 0.17230515182\n",
      "Epoch: 94 -> Test Accuracy: 86.93\n",
      "[95, 60] loss: 0.081\n",
      "[95, 120] loss: 0.078\n",
      "[95, 180] loss: 0.073\n",
      "[95, 240] loss: 0.080\n",
      "[95, 300] loss: 0.085\n",
      "[95, 360] loss: 0.080\n",
      "Epoch: 95 -> Loss: 0.0896008387208\n",
      "Epoch: 95 -> Test Accuracy: 86.98\n",
      "[96, 60] loss: 0.071\n",
      "[96, 120] loss: 0.073\n",
      "[96, 180] loss: 0.080\n",
      "[96, 240] loss: 0.077\n",
      "[96, 300] loss: 0.078\n",
      "[96, 360] loss: 0.081\n",
      "Epoch: 96 -> Loss: 0.0917995423079\n",
      "Epoch: 96 -> Test Accuracy: 86.93\n",
      "[97, 60] loss: 0.073\n",
      "[97, 120] loss: 0.083\n",
      "[97, 180] loss: 0.078\n",
      "[97, 240] loss: 0.082\n",
      "[97, 300] loss: 0.078\n",
      "[97, 360] loss: 0.071\n",
      "Epoch: 97 -> Loss: 0.154732629657\n",
      "Epoch: 97 -> Test Accuracy: 86.91\n",
      "[98, 60] loss: 0.073\n",
      "[98, 120] loss: 0.075\n",
      "[98, 180] loss: 0.080\n",
      "[98, 240] loss: 0.080\n",
      "[98, 300] loss: 0.079\n",
      "[98, 360] loss: 0.076\n",
      "Epoch: 98 -> Loss: 0.0702789127827\n",
      "Epoch: 98 -> Test Accuracy: 86.78\n",
      "[99, 60] loss: 0.075\n",
      "[99, 120] loss: 0.074\n",
      "[99, 180] loss: 0.080\n",
      "[99, 240] loss: 0.079\n",
      "[99, 300] loss: 0.079\n",
      "[99, 360] loss: 0.074\n",
      "Epoch: 99 -> Loss: 0.0545277781785\n",
      "Epoch: 99 -> Test Accuracy: 86.87\n",
      "[100, 60] loss: 0.075\n",
      "[100, 120] loss: 0.076\n",
      "[100, 180] loss: 0.074\n",
      "[100, 240] loss: 0.073\n",
      "[100, 300] loss: 0.078\n",
      "[100, 360] loss: 0.077\n",
      "Epoch: 100 -> Loss: 0.0340824536979\n",
      "Epoch: 100 -> Test Accuracy: 86.91\n",
      "Finished Training\n",
      "[1, 60] loss: 1.711\n",
      "[1, 120] loss: 0.887\n",
      "[1, 180] loss: 0.847\n",
      "[1, 240] loss: 0.785\n",
      "[1, 300] loss: 0.757\n",
      "[1, 360] loss: 0.746\n",
      "Epoch: 1 -> Loss: 0.704611420631\n",
      "Epoch: 1 -> Test Accuracy: 73.0\n",
      "[2, 60] loss: 0.686\n",
      "[2, 120] loss: 0.696\n",
      "[2, 180] loss: 0.692\n",
      "[2, 240] loss: 0.670\n",
      "[2, 300] loss: 0.665\n",
      "[2, 360] loss: 0.634\n",
      "Epoch: 2 -> Loss: 0.508521437645\n",
      "Epoch: 2 -> Test Accuracy: 74.77\n",
      "[3, 60] loss: 0.622\n",
      "[3, 120] loss: 0.634\n",
      "[3, 180] loss: 0.634\n",
      "[3, 240] loss: 0.629\n",
      "[3, 300] loss: 0.630\n",
      "[3, 360] loss: 0.631\n",
      "Epoch: 3 -> Loss: 0.670765042305\n",
      "Epoch: 3 -> Test Accuracy: 76.87\n",
      "[4, 60] loss: 0.578\n",
      "[4, 120] loss: 0.589\n",
      "[4, 180] loss: 0.605\n",
      "[4, 240] loss: 0.604\n",
      "[4, 300] loss: 0.595\n",
      "[4, 360] loss: 0.581\n",
      "Epoch: 4 -> Loss: 0.692450881004\n",
      "Epoch: 4 -> Test Accuracy: 77.2\n",
      "[5, 60] loss: 0.562\n",
      "[5, 120] loss: 0.585\n",
      "[5, 180] loss: 0.584\n",
      "[5, 240] loss: 0.594\n",
      "[5, 300] loss: 0.564\n",
      "[5, 360] loss: 0.585\n",
      "Epoch: 5 -> Loss: 0.555822610855\n",
      "Epoch: 5 -> Test Accuracy: 77.95\n",
      "[6, 60] loss: 0.554\n",
      "[6, 120] loss: 0.550\n",
      "[6, 180] loss: 0.552\n",
      "[6, 240] loss: 0.569\n",
      "[6, 300] loss: 0.558\n",
      "[6, 360] loss: 0.580\n",
      "Epoch: 6 -> Loss: 0.553102135658\n",
      "Epoch: 6 -> Test Accuracy: 78.01\n",
      "[7, 60] loss: 0.540\n",
      "[7, 120] loss: 0.532\n",
      "[7, 180] loss: 0.545\n",
      "[7, 240] loss: 0.542\n",
      "[7, 300] loss: 0.526\n",
      "[7, 360] loss: 0.578\n",
      "Epoch: 7 -> Loss: 0.564718782902\n",
      "Epoch: 7 -> Test Accuracy: 78.2\n",
      "[8, 60] loss: 0.526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 120] loss: 0.535\n",
      "[8, 180] loss: 0.549\n",
      "[8, 240] loss: 0.547\n",
      "[8, 300] loss: 0.530\n",
      "[8, 360] loss: 0.540\n",
      "Epoch: 8 -> Loss: 0.629955351353\n",
      "Epoch: 8 -> Test Accuracy: 78.15\n",
      "[9, 60] loss: 0.517\n",
      "[9, 120] loss: 0.538\n",
      "[9, 180] loss: 0.555\n",
      "[9, 240] loss: 0.547\n",
      "[9, 300] loss: 0.551\n",
      "[9, 360] loss: 0.536\n",
      "Epoch: 9 -> Loss: 0.469167232513\n",
      "Epoch: 9 -> Test Accuracy: 78.53\n",
      "[10, 60] loss: 0.514\n",
      "[10, 120] loss: 0.522\n",
      "[10, 180] loss: 0.519\n",
      "[10, 240] loss: 0.519\n",
      "[10, 300] loss: 0.545\n",
      "[10, 360] loss: 0.535\n",
      "Epoch: 10 -> Loss: 0.575849473476\n",
      "Epoch: 10 -> Test Accuracy: 77.9\n",
      "[11, 60] loss: 0.505\n",
      "[11, 120] loss: 0.541\n",
      "[11, 180] loss: 0.522\n",
      "[11, 240] loss: 0.525\n",
      "[11, 300] loss: 0.546\n",
      "[11, 360] loss: 0.531\n",
      "Epoch: 11 -> Loss: 0.402602910995\n",
      "Epoch: 11 -> Test Accuracy: 78.18\n",
      "[12, 60] loss: 0.532\n",
      "[12, 120] loss: 0.503\n",
      "[12, 180] loss: 0.517\n",
      "[12, 240] loss: 0.519\n",
      "[12, 300] loss: 0.533\n",
      "[12, 360] loss: 0.522\n",
      "Epoch: 12 -> Loss: 0.602007329464\n",
      "Epoch: 12 -> Test Accuracy: 78.39\n",
      "[13, 60] loss: 0.507\n",
      "[13, 120] loss: 0.508\n",
      "[13, 180] loss: 0.533\n",
      "[13, 240] loss: 0.524\n",
      "[13, 300] loss: 0.514\n",
      "[13, 360] loss: 0.517\n",
      "Epoch: 13 -> Loss: 0.497827470303\n",
      "Epoch: 13 -> Test Accuracy: 79.08\n",
      "[14, 60] loss: 0.496\n",
      "[14, 120] loss: 0.508\n",
      "[14, 180] loss: 0.514\n",
      "[14, 240] loss: 0.535\n",
      "[14, 300] loss: 0.537\n",
      "[14, 360] loss: 0.519\n",
      "Epoch: 14 -> Loss: 0.623694419861\n",
      "Epoch: 14 -> Test Accuracy: 78.94\n",
      "[15, 60] loss: 0.505\n",
      "[15, 120] loss: 0.509\n",
      "[15, 180] loss: 0.530\n",
      "[15, 240] loss: 0.521\n",
      "[15, 300] loss: 0.535\n",
      "[15, 360] loss: 0.507\n",
      "Epoch: 15 -> Loss: 0.531161904335\n",
      "Epoch: 15 -> Test Accuracy: 78.72\n",
      "[16, 60] loss: 0.501\n",
      "[16, 120] loss: 0.506\n",
      "[16, 180] loss: 0.513\n",
      "[16, 240] loss: 0.509\n",
      "[16, 300] loss: 0.522\n",
      "[16, 360] loss: 0.511\n",
      "Epoch: 16 -> Loss: 0.396679073572\n",
      "Epoch: 16 -> Test Accuracy: 78.72\n",
      "[17, 60] loss: 0.470\n",
      "[17, 120] loss: 0.521\n",
      "[17, 180] loss: 0.508\n",
      "[17, 240] loss: 0.523\n",
      "[17, 300] loss: 0.519\n",
      "[17, 360] loss: 0.520\n",
      "Epoch: 17 -> Loss: 0.501190543175\n",
      "Epoch: 17 -> Test Accuracy: 79.15\n",
      "[18, 60] loss: 0.496\n",
      "[18, 120] loss: 0.485\n",
      "[18, 180] loss: 0.532\n",
      "[18, 240] loss: 0.516\n",
      "[18, 300] loss: 0.513\n",
      "[18, 360] loss: 0.508\n",
      "Epoch: 18 -> Loss: 0.468975454569\n",
      "Epoch: 18 -> Test Accuracy: 78.75\n",
      "[19, 60] loss: 0.485\n",
      "[19, 120] loss: 0.496\n",
      "[19, 180] loss: 0.502\n",
      "[19, 240] loss: 0.503\n",
      "[19, 300] loss: 0.501\n",
      "[19, 360] loss: 0.511\n",
      "Epoch: 19 -> Loss: 0.469917356968\n",
      "Epoch: 19 -> Test Accuracy: 78.91\n",
      "[20, 60] loss: 0.504\n",
      "[20, 120] loss: 0.497\n",
      "[20, 180] loss: 0.514\n",
      "[20, 240] loss: 0.516\n",
      "[20, 300] loss: 0.522\n",
      "[20, 360] loss: 0.514\n",
      "Epoch: 20 -> Loss: 0.520251214504\n",
      "Epoch: 20 -> Test Accuracy: 79.05\n",
      "[21, 60] loss: 0.456\n",
      "[21, 120] loss: 0.456\n",
      "[21, 180] loss: 0.449\n",
      "[21, 240] loss: 0.444\n",
      "[21, 300] loss: 0.440\n",
      "[21, 360] loss: 0.424\n",
      "Epoch: 21 -> Loss: 0.416618585587\n",
      "Epoch: 21 -> Test Accuracy: 80.86\n",
      "[22, 60] loss: 0.420\n",
      "[22, 120] loss: 0.401\n",
      "[22, 180] loss: 0.406\n",
      "[22, 240] loss: 0.393\n",
      "[22, 300] loss: 0.411\n",
      "[22, 360] loss: 0.410\n",
      "Epoch: 22 -> Loss: 0.45125746727\n",
      "Epoch: 22 -> Test Accuracy: 81.65\n",
      "[23, 60] loss: 0.402\n",
      "[23, 120] loss: 0.393\n",
      "[23, 180] loss: 0.408\n",
      "[23, 240] loss: 0.393\n",
      "[23, 300] loss: 0.394\n",
      "[23, 360] loss: 0.398\n",
      "Epoch: 23 -> Loss: 0.265120059252\n",
      "Epoch: 23 -> Test Accuracy: 81.19\n",
      "[24, 60] loss: 0.387\n",
      "[24, 120] loss: 0.387\n",
      "[24, 180] loss: 0.385\n",
      "[24, 240] loss: 0.390\n",
      "[24, 300] loss: 0.382\n",
      "[24, 360] loss: 0.383\n",
      "Epoch: 24 -> Loss: 0.404354989529\n",
      "Epoch: 24 -> Test Accuracy: 81.49\n",
      "[25, 60] loss: 0.371\n",
      "[25, 120] loss: 0.387\n",
      "[25, 180] loss: 0.387\n",
      "[25, 240] loss: 0.372\n",
      "[25, 300] loss: 0.374\n",
      "[25, 360] loss: 0.369\n",
      "Epoch: 25 -> Loss: 0.258071839809\n",
      "Epoch: 25 -> Test Accuracy: 81.49\n",
      "[26, 60] loss: 0.363\n",
      "[26, 120] loss: 0.382\n",
      "[26, 180] loss: 0.366\n",
      "[26, 240] loss: 0.359\n",
      "[26, 300] loss: 0.378\n",
      "[26, 360] loss: 0.392\n",
      "Epoch: 26 -> Loss: 0.406642526388\n",
      "Epoch: 26 -> Test Accuracy: 81.57\n",
      "[27, 60] loss: 0.365\n",
      "[27, 120] loss: 0.362\n",
      "[27, 180] loss: 0.350\n",
      "[27, 240] loss: 0.378\n",
      "[27, 300] loss: 0.381\n",
      "[27, 360] loss: 0.368\n",
      "Epoch: 27 -> Loss: 0.425704956055\n",
      "Epoch: 27 -> Test Accuracy: 81.56\n",
      "[28, 60] loss: 0.352\n",
      "[28, 120] loss: 0.363\n",
      "[28, 180] loss: 0.373\n",
      "[28, 240] loss: 0.372\n",
      "[28, 300] loss: 0.363\n",
      "[28, 360] loss: 0.375\n",
      "Epoch: 28 -> Loss: 0.32679566741\n",
      "Epoch: 28 -> Test Accuracy: 81.53\n",
      "[29, 60] loss: 0.348\n",
      "[29, 120] loss: 0.354\n",
      "[29, 180] loss: 0.368\n",
      "[29, 240] loss: 0.347\n",
      "[29, 300] loss: 0.366\n",
      "[29, 360] loss: 0.377\n",
      "Epoch: 29 -> Loss: 0.255319327116\n",
      "Epoch: 29 -> Test Accuracy: 81.26\n",
      "[30, 60] loss: 0.360\n",
      "[30, 120] loss: 0.340\n",
      "[30, 180] loss: 0.373\n",
      "[30, 240] loss: 0.363\n",
      "[30, 300] loss: 0.367\n",
      "[30, 360] loss: 0.362\n",
      "Epoch: 30 -> Loss: 0.390402972698\n",
      "Epoch: 30 -> Test Accuracy: 81.32\n",
      "[31, 60] loss: 0.344\n",
      "[31, 120] loss: 0.368\n",
      "[31, 180] loss: 0.348\n",
      "[31, 240] loss: 0.351\n",
      "[31, 300] loss: 0.346\n",
      "[31, 360] loss: 0.366\n",
      "Epoch: 31 -> Loss: 0.237546354532\n",
      "Epoch: 31 -> Test Accuracy: 80.96\n",
      "[32, 60] loss: 0.348\n",
      "[32, 120] loss: 0.342\n",
      "[32, 180] loss: 0.361\n",
      "[32, 240] loss: 0.363\n",
      "[32, 300] loss: 0.347\n",
      "[32, 360] loss: 0.373\n",
      "Epoch: 32 -> Loss: 0.380141586065\n",
      "Epoch: 32 -> Test Accuracy: 81.24\n",
      "[33, 60] loss: 0.335\n",
      "[33, 120] loss: 0.338\n",
      "[33, 180] loss: 0.356\n",
      "[33, 240] loss: 0.368\n",
      "[33, 300] loss: 0.369\n",
      "[33, 360] loss: 0.371\n",
      "Epoch: 33 -> Loss: 0.459288060665\n",
      "Epoch: 33 -> Test Accuracy: 80.91\n",
      "[34, 60] loss: 0.328\n",
      "[34, 120] loss: 0.350\n",
      "[34, 180] loss: 0.347\n",
      "[34, 240] loss: 0.351\n",
      "[34, 300] loss: 0.354\n",
      "[34, 360] loss: 0.364\n",
      "Epoch: 34 -> Loss: 0.476556777954\n",
      "Epoch: 34 -> Test Accuracy: 81.22\n",
      "[35, 60] loss: 0.337\n",
      "[35, 120] loss: 0.362\n",
      "[35, 180] loss: 0.353\n",
      "[35, 240] loss: 0.361\n",
      "[35, 300] loss: 0.334\n",
      "[35, 360] loss: 0.360\n",
      "Epoch: 35 -> Loss: 0.262681722641\n",
      "Epoch: 35 -> Test Accuracy: 81.34\n",
      "[36, 60] loss: 0.345\n",
      "[36, 120] loss: 0.343\n",
      "[36, 180] loss: 0.339\n",
      "[36, 240] loss: 0.351\n",
      "[36, 300] loss: 0.353\n",
      "[36, 360] loss: 0.359\n",
      "Epoch: 36 -> Loss: 0.340848386288\n",
      "Epoch: 36 -> Test Accuracy: 80.5\n",
      "[37, 60] loss: 0.353\n",
      "[37, 120] loss: 0.338\n",
      "[37, 180] loss: 0.332\n",
      "[37, 240] loss: 0.341\n",
      "[37, 300] loss: 0.348\n",
      "[37, 360] loss: 0.357\n",
      "Epoch: 37 -> Loss: 0.329113811255\n",
      "Epoch: 37 -> Test Accuracy: 80.33\n",
      "[38, 60] loss: 0.333\n",
      "[38, 120] loss: 0.337\n",
      "[38, 180] loss: 0.344\n",
      "[38, 240] loss: 0.354\n",
      "[38, 300] loss: 0.347\n",
      "[38, 360] loss: 0.354\n",
      "Epoch: 38 -> Loss: 0.274360656738\n",
      "Epoch: 38 -> Test Accuracy: 80.4\n",
      "[39, 60] loss: 0.341\n",
      "[39, 120] loss: 0.336\n",
      "[39, 180] loss: 0.342\n",
      "[39, 240] loss: 0.345\n",
      "[39, 300] loss: 0.346\n",
      "[39, 360] loss: 0.356\n",
      "Epoch: 39 -> Loss: 0.559508919716\n",
      "Epoch: 39 -> Test Accuracy: 80.5\n",
      "[40, 60] loss: 0.333\n",
      "[40, 120] loss: 0.342\n",
      "[40, 180] loss: 0.330\n",
      "[40, 240] loss: 0.343\n",
      "[40, 300] loss: 0.346\n",
      "[40, 360] loss: 0.353\n",
      "Epoch: 40 -> Loss: 0.567996561527\n",
      "Epoch: 40 -> Test Accuracy: 80.66\n",
      "[41, 60] loss: 0.318\n",
      "[41, 120] loss: 0.305\n",
      "[41, 180] loss: 0.308\n",
      "[41, 240] loss: 0.312\n",
      "[41, 300] loss: 0.305\n",
      "[41, 360] loss: 0.287\n",
      "Epoch: 41 -> Loss: 0.374767065048\n",
      "Epoch: 41 -> Test Accuracy: 81.96\n",
      "[42, 60] loss: 0.296\n",
      "[42, 120] loss: 0.297\n",
      "[42, 180] loss: 0.308\n",
      "[42, 240] loss: 0.293\n",
      "[42, 300] loss: 0.288\n",
      "[42, 360] loss: 0.300\n",
      "Epoch: 42 -> Loss: 0.300914227962\n",
      "Epoch: 42 -> Test Accuracy: 82.28\n",
      "[43, 60] loss: 0.269\n",
      "[43, 120] loss: 0.285\n",
      "[43, 180] loss: 0.289\n",
      "[43, 240] loss: 0.285\n",
      "[43, 300] loss: 0.275\n",
      "[43, 360] loss: 0.287\n",
      "Epoch: 43 -> Loss: 0.325897037983\n",
      "Epoch: 43 -> Test Accuracy: 82.12\n",
      "[44, 60] loss: 0.281\n",
      "[44, 120] loss: 0.262\n",
      "[44, 180] loss: 0.285\n",
      "[44, 240] loss: 0.283\n",
      "[44, 300] loss: 0.269\n",
      "[44, 360] loss: 0.275\n",
      "Epoch: 44 -> Loss: 0.184945017099\n",
      "Epoch: 44 -> Test Accuracy: 82.13\n",
      "[45, 60] loss: 0.266\n",
      "[45, 120] loss: 0.270\n",
      "[45, 180] loss: 0.263\n",
      "[45, 240] loss: 0.273\n",
      "[45, 300] loss: 0.265\n",
      "[45, 360] loss: 0.278\n",
      "Epoch: 45 -> Loss: 0.390075832605\n",
      "Epoch: 45 -> Test Accuracy: 82.07\n",
      "[46, 60] loss: 0.265\n",
      "[46, 120] loss: 0.258\n",
      "[46, 180] loss: 0.266\n",
      "[46, 240] loss: 0.264\n",
      "[46, 300] loss: 0.267\n",
      "[46, 360] loss: 0.263\n",
      "Epoch: 46 -> Loss: 0.18297226727\n",
      "Epoch: 46 -> Test Accuracy: 82.43\n",
      "[47, 60] loss: 0.252\n",
      "[47, 120] loss: 0.264\n",
      "[47, 180] loss: 0.259\n",
      "[47, 240] loss: 0.250\n",
      "[47, 300] loss: 0.265\n",
      "[47, 360] loss: 0.256\n",
      "Epoch: 47 -> Loss: 0.283121287823\n",
      "Epoch: 47 -> Test Accuracy: 82.41\n",
      "[48, 60] loss: 0.258\n",
      "[48, 120] loss: 0.253\n",
      "[48, 180] loss: 0.267\n",
      "[48, 240] loss: 0.267\n",
      "[48, 300] loss: 0.247\n",
      "[48, 360] loss: 0.265\n",
      "Epoch: 48 -> Loss: 0.210622280836\n",
      "Epoch: 48 -> Test Accuracy: 82.45\n",
      "[49, 60] loss: 0.251\n",
      "[49, 120] loss: 0.253\n",
      "[49, 180] loss: 0.261\n",
      "[49, 240] loss: 0.258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 300] loss: 0.252\n",
      "[49, 360] loss: 0.243\n",
      "Epoch: 49 -> Loss: 0.317566245794\n",
      "Epoch: 49 -> Test Accuracy: 82.44\n",
      "[50, 60] loss: 0.242\n",
      "[50, 120] loss: 0.249\n",
      "[50, 180] loss: 0.256\n",
      "[50, 240] loss: 0.254\n",
      "[50, 300] loss: 0.247\n",
      "[50, 360] loss: 0.244\n",
      "Epoch: 50 -> Loss: 0.347239792347\n",
      "Epoch: 50 -> Test Accuracy: 82.47\n",
      "[51, 60] loss: 0.250\n",
      "[51, 120] loss: 0.252\n",
      "[51, 180] loss: 0.246\n",
      "[51, 240] loss: 0.242\n",
      "[51, 300] loss: 0.244\n",
      "[51, 360] loss: 0.249\n",
      "Epoch: 51 -> Loss: 0.214523434639\n",
      "Epoch: 51 -> Test Accuracy: 82.34\n",
      "[52, 60] loss: 0.244\n",
      "[52, 120] loss: 0.245\n",
      "[52, 180] loss: 0.247\n",
      "[52, 240] loss: 0.256\n",
      "[52, 300] loss: 0.245\n",
      "[52, 360] loss: 0.250\n",
      "Epoch: 52 -> Loss: 0.208851456642\n",
      "Epoch: 52 -> Test Accuracy: 82.47\n",
      "[53, 60] loss: 0.259\n",
      "[53, 120] loss: 0.240\n",
      "[53, 180] loss: 0.261\n",
      "[53, 240] loss: 0.238\n",
      "[53, 300] loss: 0.245\n",
      "[53, 360] loss: 0.247\n",
      "Epoch: 53 -> Loss: 0.315613150597\n",
      "Epoch: 53 -> Test Accuracy: 82.56\n",
      "[54, 60] loss: 0.257\n",
      "[54, 120] loss: 0.243\n",
      "[54, 180] loss: 0.251\n",
      "[54, 240] loss: 0.240\n",
      "[54, 300] loss: 0.254\n",
      "[54, 360] loss: 0.234\n",
      "Epoch: 54 -> Loss: 0.399176180363\n",
      "Epoch: 54 -> Test Accuracy: 82.41\n",
      "[55, 60] loss: 0.245\n",
      "[55, 120] loss: 0.239\n",
      "[55, 180] loss: 0.244\n",
      "[55, 240] loss: 0.254\n",
      "[55, 300] loss: 0.242\n",
      "[55, 360] loss: 0.251\n",
      "Epoch: 55 -> Loss: 0.299975574017\n",
      "Epoch: 55 -> Test Accuracy: 82.51\n",
      "[56, 60] loss: 0.247\n",
      "[56, 120] loss: 0.238\n",
      "[56, 180] loss: 0.252\n",
      "[56, 240] loss: 0.251\n",
      "[56, 300] loss: 0.237\n",
      "[56, 360] loss: 0.243\n",
      "Epoch: 56 -> Loss: 0.325543344021\n",
      "Epoch: 56 -> Test Accuracy: 82.36\n",
      "[57, 60] loss: 0.254\n",
      "[57, 120] loss: 0.242\n",
      "[57, 180] loss: 0.254\n",
      "[57, 240] loss: 0.237\n",
      "[57, 300] loss: 0.249\n",
      "[57, 360] loss: 0.237\n",
      "Epoch: 57 -> Loss: 0.367322772741\n",
      "Epoch: 57 -> Test Accuracy: 82.33\n",
      "[58, 60] loss: 0.236\n",
      "[58, 120] loss: 0.230\n",
      "[58, 180] loss: 0.255\n",
      "[58, 240] loss: 0.247\n",
      "[58, 300] loss: 0.242\n",
      "[58, 360] loss: 0.243\n",
      "Epoch: 58 -> Loss: 0.2990642488\n",
      "Epoch: 58 -> Test Accuracy: 82.35\n",
      "[59, 60] loss: 0.246\n",
      "[59, 120] loss: 0.236\n",
      "[59, 180] loss: 0.247\n",
      "[59, 240] loss: 0.244\n",
      "[59, 300] loss: 0.248\n",
      "[59, 360] loss: 0.239\n",
      "Epoch: 59 -> Loss: 0.202575370669\n",
      "Epoch: 59 -> Test Accuracy: 82.52\n",
      "[60, 60] loss: 0.242\n",
      "[60, 120] loss: 0.237\n",
      "[60, 180] loss: 0.239\n",
      "[60, 240] loss: 0.229\n",
      "[60, 300] loss: 0.245\n",
      "[60, 360] loss: 0.227\n",
      "Epoch: 60 -> Loss: 0.166762962937\n",
      "Epoch: 60 -> Test Accuracy: 82.49\n",
      "[61, 60] loss: 0.235\n",
      "[61, 120] loss: 0.236\n",
      "[61, 180] loss: 0.231\n",
      "[61, 240] loss: 0.232\n",
      "[61, 300] loss: 0.235\n",
      "[61, 360] loss: 0.238\n",
      "Epoch: 61 -> Loss: 0.282093524933\n",
      "Epoch: 61 -> Test Accuracy: 82.5\n",
      "[62, 60] loss: 0.242\n",
      "[62, 120] loss: 0.245\n",
      "[62, 180] loss: 0.246\n",
      "[62, 240] loss: 0.234\n",
      "[62, 300] loss: 0.231\n",
      "[62, 360] loss: 0.245\n",
      "Epoch: 62 -> Loss: 0.180913999677\n",
      "Epoch: 62 -> Test Accuracy: 82.46\n",
      "[63, 60] loss: 0.230\n",
      "[63, 120] loss: 0.242\n",
      "[63, 180] loss: 0.234\n",
      "[63, 240] loss: 0.230\n",
      "[63, 300] loss: 0.240\n",
      "[63, 360] loss: 0.240\n",
      "Epoch: 63 -> Loss: 0.243596225977\n",
      "Epoch: 63 -> Test Accuracy: 82.46\n",
      "[64, 60] loss: 0.229\n",
      "[64, 120] loss: 0.247\n",
      "[64, 180] loss: 0.248\n",
      "[64, 240] loss: 0.234\n",
      "[64, 300] loss: 0.232\n",
      "[64, 360] loss: 0.238\n",
      "Epoch: 64 -> Loss: 0.140313714743\n",
      "Epoch: 64 -> Test Accuracy: 82.56\n",
      "[65, 60] loss: 0.226\n",
      "[65, 120] loss: 0.236\n",
      "[65, 180] loss: 0.248\n",
      "[65, 240] loss: 0.238\n",
      "[65, 300] loss: 0.237\n",
      "[65, 360] loss: 0.239\n",
      "Epoch: 65 -> Loss: 0.383917987347\n",
      "Epoch: 65 -> Test Accuracy: 82.46\n",
      "[66, 60] loss: 0.242\n",
      "[66, 120] loss: 0.223\n",
      "[66, 180] loss: 0.243\n",
      "[66, 240] loss: 0.237\n",
      "[66, 300] loss: 0.227\n",
      "[66, 360] loss: 0.247\n",
      "Epoch: 66 -> Loss: 0.272114783525\n",
      "Epoch: 66 -> Test Accuracy: 82.58\n",
      "[67, 60] loss: 0.235\n",
      "[67, 120] loss: 0.224\n",
      "[67, 180] loss: 0.224\n",
      "[67, 240] loss: 0.225\n",
      "[67, 300] loss: 0.232\n",
      "[67, 360] loss: 0.233\n",
      "Epoch: 67 -> Loss: 0.234276771545\n",
      "Epoch: 67 -> Test Accuracy: 82.44\n",
      "[68, 60] loss: 0.225\n",
      "[68, 120] loss: 0.240\n",
      "[68, 180] loss: 0.234\n",
      "[68, 240] loss: 0.232\n",
      "[68, 300] loss: 0.227\n",
      "[68, 360] loss: 0.224\n",
      "Epoch: 68 -> Loss: 0.227754354477\n",
      "Epoch: 68 -> Test Accuracy: 82.54\n",
      "[69, 60] loss: 0.239\n",
      "[69, 120] loss: 0.230\n",
      "[69, 180] loss: 0.234\n",
      "[69, 240] loss: 0.216\n",
      "[69, 300] loss: 0.238\n",
      "[69, 360] loss: 0.241\n",
      "Epoch: 69 -> Loss: 0.249202415347\n",
      "Epoch: 69 -> Test Accuracy: 82.48\n",
      "[70, 60] loss: 0.246\n",
      "[70, 120] loss: 0.230\n",
      "[70, 180] loss: 0.227\n",
      "[70, 240] loss: 0.222\n",
      "[70, 300] loss: 0.232\n",
      "[70, 360] loss: 0.232\n",
      "Epoch: 70 -> Loss: 0.203882336617\n",
      "Epoch: 70 -> Test Accuracy: 82.43\n",
      "[71, 60] loss: 0.228\n",
      "[71, 120] loss: 0.219\n",
      "[71, 180] loss: 0.232\n",
      "[71, 240] loss: 0.230\n",
      "[71, 300] loss: 0.230\n",
      "[71, 360] loss: 0.235\n",
      "Epoch: 71 -> Loss: 0.339438825846\n",
      "Epoch: 71 -> Test Accuracy: 82.23\n",
      "[72, 60] loss: 0.225\n",
      "[72, 120] loss: 0.232\n",
      "[72, 180] loss: 0.226\n",
      "[72, 240] loss: 0.231\n",
      "[72, 300] loss: 0.233\n",
      "[72, 360] loss: 0.226\n",
      "Epoch: 72 -> Loss: 0.500967860222\n",
      "Epoch: 72 -> Test Accuracy: 82.23\n",
      "[73, 60] loss: 0.225\n",
      "[73, 120] loss: 0.227\n",
      "[73, 180] loss: 0.231\n",
      "[73, 240] loss: 0.221\n",
      "[73, 300] loss: 0.222\n",
      "[73, 360] loss: 0.217\n",
      "Epoch: 73 -> Loss: 0.271007835865\n",
      "Epoch: 73 -> Test Accuracy: 82.42\n",
      "[74, 60] loss: 0.240\n",
      "[74, 120] loss: 0.230\n",
      "[74, 180] loss: 0.231\n",
      "[74, 240] loss: 0.221\n",
      "[74, 300] loss: 0.222\n",
      "[74, 360] loss: 0.227\n",
      "Epoch: 74 -> Loss: 0.176378875971\n",
      "Epoch: 74 -> Test Accuracy: 82.29\n",
      "[75, 60] loss: 0.225\n",
      "[75, 120] loss: 0.242\n",
      "[75, 180] loss: 0.221\n",
      "[75, 240] loss: 0.220\n",
      "[75, 300] loss: 0.223\n",
      "[75, 360] loss: 0.223\n",
      "Epoch: 75 -> Loss: 0.274955838919\n",
      "Epoch: 75 -> Test Accuracy: 82.35\n",
      "[76, 60] loss: 0.215\n",
      "[76, 120] loss: 0.239\n",
      "[76, 180] loss: 0.229\n",
      "[76, 240] loss: 0.217\n",
      "[76, 300] loss: 0.214\n",
      "[76, 360] loss: 0.230\n",
      "Epoch: 76 -> Loss: 0.278411269188\n",
      "Epoch: 76 -> Test Accuracy: 82.42\n",
      "[77, 60] loss: 0.230\n",
      "[77, 120] loss: 0.218\n",
      "[77, 180] loss: 0.223\n",
      "[77, 240] loss: 0.217\n",
      "[77, 300] loss: 0.232\n",
      "[77, 360] loss: 0.218\n",
      "Epoch: 77 -> Loss: 0.358446806669\n",
      "Epoch: 77 -> Test Accuracy: 82.3\n",
      "[78, 60] loss: 0.221\n",
      "[78, 120] loss: 0.226\n",
      "[78, 180] loss: 0.223\n",
      "[78, 240] loss: 0.231\n",
      "[78, 300] loss: 0.220\n",
      "[78, 360] loss: 0.218\n",
      "Epoch: 78 -> Loss: 0.21603640914\n",
      "Epoch: 78 -> Test Accuracy: 82.52\n",
      "[79, 60] loss: 0.224\n",
      "[79, 120] loss: 0.230\n",
      "[79, 180] loss: 0.217\n",
      "[79, 240] loss: 0.217\n",
      "[79, 300] loss: 0.216\n",
      "[79, 360] loss: 0.216\n",
      "Epoch: 79 -> Loss: 0.160862535238\n",
      "Epoch: 79 -> Test Accuracy: 82.33\n",
      "[80, 60] loss: 0.221\n",
      "[80, 120] loss: 0.216\n",
      "[80, 180] loss: 0.222\n",
      "[80, 240] loss: 0.231\n",
      "[80, 300] loss: 0.210\n",
      "[80, 360] loss: 0.215\n",
      "Epoch: 80 -> Loss: 0.285882174969\n",
      "Epoch: 80 -> Test Accuracy: 82.26\n",
      "[81, 60] loss: 0.226\n",
      "[81, 120] loss: 0.215\n",
      "[81, 180] loss: 0.225\n",
      "[81, 240] loss: 0.221\n",
      "[81, 300] loss: 0.210\n",
      "[81, 360] loss: 0.222\n",
      "Epoch: 81 -> Loss: 0.270557552576\n",
      "Epoch: 81 -> Test Accuracy: 82.35\n",
      "[82, 60] loss: 0.216\n",
      "[82, 120] loss: 0.212\n",
      "[82, 180] loss: 0.219\n",
      "[82, 240] loss: 0.220\n",
      "[82, 300] loss: 0.232\n",
      "[82, 360] loss: 0.219\n",
      "Epoch: 82 -> Loss: 0.331027448177\n",
      "Epoch: 82 -> Test Accuracy: 82.37\n",
      "[83, 60] loss: 0.214\n",
      "[83, 120] loss: 0.221\n",
      "[83, 180] loss: 0.219\n",
      "[83, 240] loss: 0.213\n",
      "[83, 300] loss: 0.224\n",
      "[83, 360] loss: 0.212\n",
      "Epoch: 83 -> Loss: 0.205770403147\n",
      "Epoch: 83 -> Test Accuracy: 82.43\n",
      "[84, 60] loss: 0.216\n",
      "[84, 120] loss: 0.215\n",
      "[84, 180] loss: 0.215\n",
      "[84, 240] loss: 0.218\n",
      "[84, 300] loss: 0.217\n",
      "[84, 360] loss: 0.216\n",
      "Epoch: 84 -> Loss: 0.32675921917\n",
      "Epoch: 84 -> Test Accuracy: 82.4\n",
      "[85, 60] loss: 0.204\n",
      "[85, 120] loss: 0.216\n",
      "[85, 180] loss: 0.212\n",
      "[85, 240] loss: 0.217\n",
      "[85, 300] loss: 0.215\n",
      "[85, 360] loss: 0.206\n",
      "Epoch: 85 -> Loss: 0.27619856596\n",
      "Epoch: 85 -> Test Accuracy: 82.22\n",
      "[86, 60] loss: 0.220\n",
      "[86, 120] loss: 0.203\n",
      "[86, 180] loss: 0.217\n",
      "[86, 240] loss: 0.228\n",
      "[86, 300] loss: 0.214\n",
      "[86, 360] loss: 0.209\n",
      "Epoch: 86 -> Loss: 0.140449523926\n",
      "Epoch: 86 -> Test Accuracy: 82.18\n",
      "[87, 60] loss: 0.215\n",
      "[87, 120] loss: 0.221\n",
      "[87, 180] loss: 0.204\n",
      "[87, 240] loss: 0.208\n",
      "[87, 300] loss: 0.216\n",
      "[87, 360] loss: 0.210\n",
      "Epoch: 87 -> Loss: 0.311237633228\n",
      "Epoch: 87 -> Test Accuracy: 82.23\n",
      "[88, 60] loss: 0.224\n",
      "[88, 120] loss: 0.219\n",
      "[88, 180] loss: 0.210\n",
      "[88, 240] loss: 0.216\n",
      "[88, 300] loss: 0.205\n",
      "[88, 360] loss: 0.207\n",
      "Epoch: 88 -> Loss: 0.307638555765\n",
      "Epoch: 88 -> Test Accuracy: 82.38\n",
      "[89, 60] loss: 0.210\n",
      "[89, 120] loss: 0.216\n",
      "[89, 180] loss: 0.219\n",
      "[89, 240] loss: 0.206\n",
      "[89, 300] loss: 0.205\n",
      "[89, 360] loss: 0.204\n",
      "Epoch: 89 -> Loss: 0.24717721343\n",
      "Epoch: 89 -> Test Accuracy: 82.24\n",
      "[90, 60] loss: 0.211\n",
      "[90, 120] loss: 0.202\n",
      "[90, 180] loss: 0.201\n",
      "[90, 240] loss: 0.221\n",
      "[90, 300] loss: 0.201\n",
      "[90, 360] loss: 0.222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 -> Loss: 0.17134359479\n",
      "Epoch: 90 -> Test Accuracy: 82.41\n",
      "[91, 60] loss: 0.206\n",
      "[91, 120] loss: 0.205\n",
      "[91, 180] loss: 0.213\n",
      "[91, 240] loss: 0.213\n",
      "[91, 300] loss: 0.217\n",
      "[91, 360] loss: 0.215\n",
      "Epoch: 91 -> Loss: 0.0965504646301\n",
      "Epoch: 91 -> Test Accuracy: 82.35\n",
      "[92, 60] loss: 0.211\n",
      "[92, 120] loss: 0.204\n",
      "[92, 180] loss: 0.206\n",
      "[92, 240] loss: 0.206\n",
      "[92, 300] loss: 0.213\n",
      "[92, 360] loss: 0.197\n",
      "Epoch: 92 -> Loss: 0.122842535377\n",
      "Epoch: 92 -> Test Accuracy: 82.24\n",
      "[93, 60] loss: 0.205\n",
      "[93, 120] loss: 0.209\n",
      "[93, 180] loss: 0.212\n",
      "[93, 240] loss: 0.210\n",
      "[93, 300] loss: 0.207\n",
      "[93, 360] loss: 0.204\n",
      "Epoch: 93 -> Loss: 0.231962129474\n",
      "Epoch: 93 -> Test Accuracy: 82.19\n",
      "[94, 60] loss: 0.210\n",
      "[94, 120] loss: 0.205\n",
      "[94, 180] loss: 0.203\n",
      "[94, 240] loss: 0.218\n",
      "[94, 300] loss: 0.206\n",
      "[94, 360] loss: 0.209\n",
      "Epoch: 94 -> Loss: 0.205901548266\n",
      "Epoch: 94 -> Test Accuracy: 82.18\n",
      "[95, 60] loss: 0.198\n",
      "[95, 120] loss: 0.201\n",
      "[95, 180] loss: 0.194\n",
      "[95, 240] loss: 0.218\n",
      "[95, 300] loss: 0.213\n",
      "[95, 360] loss: 0.207\n",
      "Epoch: 95 -> Loss: 0.275548547506\n",
      "Epoch: 95 -> Test Accuracy: 82.13\n",
      "[96, 60] loss: 0.212\n",
      "[96, 120] loss: 0.210\n",
      "[96, 180] loss: 0.216\n",
      "[96, 240] loss: 0.208\n",
      "[96, 300] loss: 0.206\n",
      "[96, 360] loss: 0.211\n",
      "Epoch: 96 -> Loss: 0.214099645615\n",
      "Epoch: 96 -> Test Accuracy: 82.17\n",
      "[97, 60] loss: 0.198\n",
      "[97, 120] loss: 0.205\n",
      "[97, 180] loss: 0.207\n",
      "[97, 240] loss: 0.210\n",
      "[97, 300] loss: 0.200\n",
      "[97, 360] loss: 0.210\n",
      "Epoch: 97 -> Loss: 0.266627699137\n",
      "Epoch: 97 -> Test Accuracy: 82.1\n",
      "[98, 60] loss: 0.203\n",
      "[98, 120] loss: 0.217\n",
      "[98, 180] loss: 0.200\n",
      "[98, 240] loss: 0.205\n",
      "[98, 300] loss: 0.202\n",
      "[98, 360] loss: 0.214\n",
      "Epoch: 98 -> Loss: 0.207354903221\n",
      "Epoch: 98 -> Test Accuracy: 82.31\n",
      "[99, 60] loss: 0.212\n",
      "[99, 120] loss: 0.196\n",
      "[99, 180] loss: 0.205\n",
      "[99, 240] loss: 0.199\n",
      "[99, 300] loss: 0.212\n",
      "[99, 360] loss: 0.199\n",
      "Epoch: 99 -> Loss: 0.2049266994\n",
      "Epoch: 99 -> Test Accuracy: 82.24\n",
      "[100, 60] loss: 0.202\n",
      "[100, 120] loss: 0.201\n",
      "[100, 180] loss: 0.196\n",
      "[100, 240] loss: 0.197\n",
      "[100, 300] loss: 0.207\n",
      "[100, 360] loss: 0.205\n",
      "Epoch: 100 -> Loss: 0.271165549755\n",
      "Epoch: 100 -> Test Accuracy: 82.11\n",
      "Finished Training\n",
      "[1, 60] loss: 2.778\n",
      "[1, 120] loss: 2.006\n",
      "[1, 180] loss: 1.948\n",
      "[1, 240] loss: 1.925\n",
      "[1, 300] loss: 1.885\n",
      "[1, 360] loss: 1.858\n",
      "Epoch: 1 -> Loss: 1.88053262234\n",
      "Epoch: 1 -> Test Accuracy: 31.07\n",
      "[2, 60] loss: 1.833\n",
      "[2, 120] loss: 1.847\n",
      "[2, 180] loss: 1.819\n",
      "[2, 240] loss: 1.818\n",
      "[2, 300] loss: 1.824\n",
      "[2, 360] loss: 1.791\n",
      "Epoch: 2 -> Loss: 1.69867193699\n",
      "Epoch: 2 -> Test Accuracy: 33.51\n",
      "[3, 60] loss: 1.775\n",
      "[3, 120] loss: 1.789\n",
      "[3, 180] loss: 1.775\n",
      "[3, 240] loss: 1.777\n",
      "[3, 300] loss: 1.763\n",
      "[3, 360] loss: 1.758\n",
      "Epoch: 3 -> Loss: 1.8226287365\n",
      "Epoch: 3 -> Test Accuracy: 34.59\n",
      "[4, 60] loss: 1.751\n",
      "[4, 120] loss: 1.737\n",
      "[4, 180] loss: 1.769\n",
      "[4, 240] loss: 1.753\n",
      "[4, 300] loss: 1.744\n",
      "[4, 360] loss: 1.726\n",
      "Epoch: 4 -> Loss: 1.93968200684\n",
      "Epoch: 4 -> Test Accuracy: 34.48\n",
      "[5, 60] loss: 1.710\n",
      "[5, 120] loss: 1.743\n",
      "[5, 180] loss: 1.729\n",
      "[5, 240] loss: 1.716\n",
      "[5, 300] loss: 1.715\n",
      "[5, 360] loss: 1.736\n",
      "Epoch: 5 -> Loss: 1.76070332527\n",
      "Epoch: 5 -> Test Accuracy: 35.53\n",
      "[6, 60] loss: 1.733\n",
      "[6, 120] loss: 1.721\n",
      "[6, 180] loss: 1.702\n",
      "[6, 240] loss: 1.729\n",
      "[6, 300] loss: 1.728\n",
      "[6, 360] loss: 1.707\n",
      "Epoch: 6 -> Loss: 1.91199910641\n",
      "Epoch: 6 -> Test Accuracy: 35.54\n",
      "[7, 60] loss: 1.698\n",
      "[7, 120] loss: 1.707\n",
      "[7, 180] loss: 1.703\n",
      "[7, 240] loss: 1.696\n",
      "[7, 300] loss: 1.720\n",
      "[7, 360] loss: 1.696\n",
      "Epoch: 7 -> Loss: 1.74721312523\n",
      "Epoch: 7 -> Test Accuracy: 35.64\n",
      "[8, 60] loss: 1.687\n",
      "[8, 120] loss: 1.703\n",
      "[8, 180] loss: 1.700\n",
      "[8, 240] loss: 1.678\n",
      "[8, 300] loss: 1.706\n",
      "[8, 360] loss: 1.695\n",
      "Epoch: 8 -> Loss: 1.86428773403\n",
      "Epoch: 8 -> Test Accuracy: 36.19\n",
      "[9, 60] loss: 1.697\n",
      "[9, 120] loss: 1.688\n",
      "[9, 180] loss: 1.698\n",
      "[9, 240] loss: 1.711\n",
      "[9, 300] loss: 1.668\n",
      "[9, 360] loss: 1.692\n",
      "Epoch: 9 -> Loss: 1.64708256721\n",
      "Epoch: 9 -> Test Accuracy: 36.51\n",
      "[10, 60] loss: 1.693\n",
      "[10, 120] loss: 1.682\n",
      "[10, 180] loss: 1.677\n",
      "[10, 240] loss: 1.670\n",
      "[10, 300] loss: 1.703\n",
      "[10, 360] loss: 1.703\n",
      "Epoch: 10 -> Loss: 1.58855688572\n",
      "Epoch: 10 -> Test Accuracy: 37.49\n",
      "[11, 60] loss: 1.672\n",
      "[11, 120] loss: 1.688\n",
      "[11, 180] loss: 1.690\n",
      "[11, 240] loss: 1.691\n",
      "[11, 300] loss: 1.685\n",
      "[11, 360] loss: 1.676\n",
      "Epoch: 11 -> Loss: 1.58510625362\n",
      "Epoch: 11 -> Test Accuracy: 36.76\n",
      "[12, 60] loss: 1.667\n",
      "[12, 120] loss: 1.661\n",
      "[12, 180] loss: 1.690\n",
      "[12, 240] loss: 1.705\n",
      "[12, 300] loss: 1.683\n",
      "[12, 360] loss: 1.692\n",
      "Epoch: 12 -> Loss: 1.91417431831\n",
      "Epoch: 12 -> Test Accuracy: 37.16\n",
      "[13, 60] loss: 1.683\n",
      "[13, 120] loss: 1.667\n",
      "[13, 180] loss: 1.676\n",
      "[13, 240] loss: 1.672\n",
      "[13, 300] loss: 1.660\n",
      "[13, 360] loss: 1.690\n",
      "Epoch: 13 -> Loss: 1.57052981853\n",
      "Epoch: 13 -> Test Accuracy: 35.89\n",
      "[14, 60] loss: 1.666\n",
      "[14, 120] loss: 1.687\n",
      "[14, 180] loss: 1.690\n",
      "[14, 240] loss: 1.668\n",
      "[14, 300] loss: 1.683\n",
      "[14, 360] loss: 1.672\n",
      "Epoch: 14 -> Loss: 1.69853758812\n",
      "Epoch: 14 -> Test Accuracy: 36.95\n",
      "[15, 60] loss: 1.665\n",
      "[15, 120] loss: 1.661\n",
      "[15, 180] loss: 1.684\n",
      "[15, 240] loss: 1.679\n",
      "[15, 300] loss: 1.668\n",
      "[15, 360] loss: 1.666\n",
      "Epoch: 15 -> Loss: 1.5666000843\n",
      "Epoch: 15 -> Test Accuracy: 36.74\n",
      "[16, 60] loss: 1.673\n",
      "[16, 120] loss: 1.664\n",
      "[16, 180] loss: 1.690\n",
      "[16, 240] loss: 1.675\n",
      "[16, 300] loss: 1.668\n",
      "[16, 360] loss: 1.673\n",
      "Epoch: 16 -> Loss: 1.59770357609\n",
      "Epoch: 16 -> Test Accuracy: 37.21\n",
      "[17, 60] loss: 1.644\n",
      "[17, 120] loss: 1.673\n",
      "[17, 180] loss: 1.672\n",
      "[17, 240] loss: 1.680\n",
      "[17, 300] loss: 1.687\n",
      "[17, 360] loss: 1.676\n",
      "Epoch: 17 -> Loss: 1.80427098274\n",
      "Epoch: 17 -> Test Accuracy: 36.46\n",
      "[18, 60] loss: 1.674\n",
      "[18, 120] loss: 1.655\n",
      "[18, 180] loss: 1.672\n",
      "[18, 240] loss: 1.670\n",
      "[18, 300] loss: 1.676\n",
      "[18, 360] loss: 1.659\n",
      "Epoch: 18 -> Loss: 1.63368105888\n",
      "Epoch: 18 -> Test Accuracy: 37.2\n",
      "[19, 60] loss: 1.670\n",
      "[19, 120] loss: 1.678\n",
      "[19, 180] loss: 1.685\n",
      "[19, 240] loss: 1.669\n",
      "[19, 300] loss: 1.660\n",
      "[19, 360] loss: 1.656\n",
      "Epoch: 19 -> Loss: 1.72614502907\n",
      "Epoch: 19 -> Test Accuracy: 37.35\n",
      "[20, 60] loss: 1.669\n",
      "[20, 120] loss: 1.661\n",
      "[20, 180] loss: 1.661\n",
      "[20, 240] loss: 1.646\n",
      "[20, 300] loss: 1.687\n",
      "[20, 360] loss: 1.675\n",
      "Epoch: 20 -> Loss: 1.77798819542\n",
      "Epoch: 20 -> Test Accuracy: 36.05\n",
      "[21, 60] loss: 1.640\n",
      "[21, 120] loss: 1.589\n",
      "[21, 180] loss: 1.586\n",
      "[21, 240] loss: 1.580\n",
      "[21, 300] loss: 1.572\n",
      "[21, 360] loss: 1.586\n",
      "Epoch: 21 -> Loss: 1.57669973373\n",
      "Epoch: 21 -> Test Accuracy: 39.59\n",
      "[22, 60] loss: 1.572\n",
      "[22, 120] loss: 1.570\n",
      "[22, 180] loss: 1.556\n",
      "[22, 240] loss: 1.569\n",
      "[22, 300] loss: 1.571\n",
      "[22, 360] loss: 1.564\n",
      "Epoch: 22 -> Loss: 1.51961004734\n",
      "Epoch: 22 -> Test Accuracy: 40.11\n",
      "[23, 60] loss: 1.549\n",
      "[23, 120] loss: 1.570\n",
      "[23, 180] loss: 1.555\n",
      "[23, 240] loss: 1.557\n",
      "[23, 300] loss: 1.538\n",
      "[23, 360] loss: 1.571\n",
      "Epoch: 23 -> Loss: 1.52355194092\n",
      "Epoch: 23 -> Test Accuracy: 40.38\n",
      "[24, 60] loss: 1.531\n",
      "[24, 120] loss: 1.535\n",
      "[24, 180] loss: 1.538\n",
      "[24, 240] loss: 1.555\n",
      "[24, 300] loss: 1.568\n",
      "[24, 360] loss: 1.547\n",
      "Epoch: 24 -> Loss: 1.54698204994\n",
      "Epoch: 24 -> Test Accuracy: 39.94\n",
      "[25, 60] loss: 1.540\n",
      "[25, 120] loss: 1.537\n",
      "[25, 180] loss: 1.537\n",
      "[25, 240] loss: 1.544\n",
      "[25, 300] loss: 1.536\n",
      "[25, 360] loss: 1.529\n",
      "Epoch: 25 -> Loss: 1.54639744759\n",
      "Epoch: 25 -> Test Accuracy: 40.29\n",
      "[26, 60] loss: 1.532\n",
      "[26, 120] loss: 1.550\n",
      "[26, 180] loss: 1.556\n",
      "[26, 240] loss: 1.514\n",
      "[26, 300] loss: 1.549\n",
      "[26, 360] loss: 1.526\n",
      "Epoch: 26 -> Loss: 1.68379557133\n",
      "Epoch: 26 -> Test Accuracy: 40.04\n",
      "[27, 60] loss: 1.524\n",
      "[27, 120] loss: 1.548\n",
      "[27, 180] loss: 1.518\n",
      "[27, 240] loss: 1.546\n",
      "[27, 300] loss: 1.556\n",
      "[27, 360] loss: 1.533\n",
      "Epoch: 27 -> Loss: 1.59639799595\n",
      "Epoch: 27 -> Test Accuracy: 40.4\n",
      "[28, 60] loss: 1.520\n",
      "[28, 120] loss: 1.536\n",
      "[28, 180] loss: 1.567\n",
      "[28, 240] loss: 1.553\n",
      "[28, 300] loss: 1.533\n",
      "[28, 360] loss: 1.539\n",
      "Epoch: 28 -> Loss: 1.63576769829\n",
      "Epoch: 28 -> Test Accuracy: 40.76\n",
      "[29, 60] loss: 1.522\n",
      "[29, 120] loss: 1.528\n",
      "[29, 180] loss: 1.562\n",
      "[29, 240] loss: 1.549\n",
      "[29, 300] loss: 1.537\n",
      "[29, 360] loss: 1.560\n",
      "Epoch: 29 -> Loss: 1.32969725132\n",
      "Epoch: 29 -> Test Accuracy: 40.51\n",
      "[30, 60] loss: 1.540\n",
      "[30, 120] loss: 1.550\n",
      "[30, 180] loss: 1.525\n",
      "[30, 240] loss: 1.563\n",
      "[30, 300] loss: 1.537\n",
      "[30, 360] loss: 1.529\n",
      "Epoch: 30 -> Loss: 1.63883709908\n",
      "Epoch: 30 -> Test Accuracy: 40.35\n",
      "[31, 60] loss: 1.536\n",
      "[31, 120] loss: 1.536\n",
      "[31, 180] loss: 1.517\n",
      "[31, 240] loss: 1.555\n",
      "[31, 300] loss: 1.538\n",
      "[31, 360] loss: 1.528\n",
      "Epoch: 31 -> Loss: 1.57921719551\n",
      "Epoch: 31 -> Test Accuracy: 39.81\n",
      "[32, 60] loss: 1.533\n",
      "[32, 120] loss: 1.513\n",
      "[32, 180] loss: 1.527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 240] loss: 1.525\n",
      "[32, 300] loss: 1.546\n",
      "[32, 360] loss: 1.554\n",
      "Epoch: 32 -> Loss: 1.53451240063\n",
      "Epoch: 32 -> Test Accuracy: 40.83\n",
      "[33, 60] loss: 1.545\n",
      "[33, 120] loss: 1.521\n",
      "[33, 180] loss: 1.542\n",
      "[33, 240] loss: 1.540\n",
      "[33, 300] loss: 1.529\n",
      "[33, 360] loss: 1.529\n",
      "Epoch: 33 -> Loss: 1.59418988228\n",
      "Epoch: 33 -> Test Accuracy: 41.07\n",
      "[34, 60] loss: 1.526\n",
      "[34, 120] loss: 1.532\n",
      "[34, 180] loss: 1.517\n",
      "[34, 240] loss: 1.545\n",
      "[34, 300] loss: 1.525\n",
      "[34, 360] loss: 1.553\n",
      "Epoch: 34 -> Loss: 1.61489868164\n",
      "Epoch: 34 -> Test Accuracy: 40.3\n",
      "[35, 60] loss: 1.535\n",
      "[35, 120] loss: 1.527\n",
      "[35, 180] loss: 1.547\n",
      "[35, 240] loss: 1.518\n",
      "[35, 300] loss: 1.529\n",
      "[35, 360] loss: 1.514\n",
      "Epoch: 35 -> Loss: 1.49452698231\n",
      "Epoch: 35 -> Test Accuracy: 40.53\n",
      "[36, 60] loss: 1.506\n",
      "[36, 120] loss: 1.530\n",
      "[36, 180] loss: 1.545\n",
      "[36, 240] loss: 1.532\n",
      "[36, 300] loss: 1.547\n",
      "[36, 360] loss: 1.544\n",
      "Epoch: 36 -> Loss: 1.47451615334\n",
      "Epoch: 36 -> Test Accuracy: 39.38\n",
      "[37, 60] loss: 1.519\n",
      "[37, 120] loss: 1.527\n",
      "[37, 180] loss: 1.531\n",
      "[37, 240] loss: 1.522\n",
      "[37, 300] loss: 1.518\n",
      "[37, 360] loss: 1.527\n",
      "Epoch: 37 -> Loss: 1.53129124641\n",
      "Epoch: 37 -> Test Accuracy: 40.65\n",
      "[38, 60] loss: 1.517\n",
      "[38, 120] loss: 1.518\n",
      "[38, 180] loss: 1.534\n",
      "[38, 240] loss: 1.527\n",
      "[38, 300] loss: 1.528\n",
      "[38, 360] loss: 1.525\n",
      "Epoch: 38 -> Loss: 1.52182626724\n",
      "Epoch: 38 -> Test Accuracy: 40.08\n",
      "[39, 60] loss: 1.512\n",
      "[39, 120] loss: 1.524\n",
      "[39, 180] loss: 1.539\n",
      "[39, 240] loss: 1.524\n",
      "[39, 300] loss: 1.544\n",
      "[39, 360] loss: 1.524\n",
      "Epoch: 39 -> Loss: 1.76025748253\n",
      "Epoch: 39 -> Test Accuracy: 40.48\n",
      "[40, 60] loss: 1.520\n",
      "[40, 120] loss: 1.535\n",
      "[40, 180] loss: 1.526\n",
      "[40, 240] loss: 1.510\n",
      "[40, 300] loss: 1.525\n",
      "[40, 360] loss: 1.537\n",
      "Epoch: 40 -> Loss: 1.58574509621\n",
      "Epoch: 40 -> Test Accuracy: 40.7\n",
      "[41, 60] loss: 1.509\n",
      "[41, 120] loss: 1.489\n",
      "[41, 180] loss: 1.487\n",
      "[41, 240] loss: 1.471\n",
      "[41, 300] loss: 1.490\n",
      "[41, 360] loss: 1.477\n",
      "Epoch: 41 -> Loss: 1.51294291019\n",
      "Epoch: 41 -> Test Accuracy: 42.34\n",
      "[42, 60] loss: 1.479\n",
      "[42, 120] loss: 1.467\n",
      "[42, 180] loss: 1.460\n",
      "[42, 240] loss: 1.461\n",
      "[42, 300] loss: 1.480\n",
      "[42, 360] loss: 1.496\n",
      "Epoch: 42 -> Loss: 1.34982132912\n",
      "Epoch: 42 -> Test Accuracy: 42.15\n",
      "[43, 60] loss: 1.449\n",
      "[43, 120] loss: 1.468\n",
      "[43, 180] loss: 1.469\n",
      "[43, 240] loss: 1.462\n",
      "[43, 300] loss: 1.458\n",
      "[43, 360] loss: 1.453\n",
      "Epoch: 43 -> Loss: 1.51525425911\n",
      "Epoch: 43 -> Test Accuracy: 42.99\n",
      "[44, 60] loss: 1.447\n",
      "[44, 120] loss: 1.460\n",
      "[44, 180] loss: 1.463\n",
      "[44, 240] loss: 1.439\n",
      "[44, 300] loss: 1.475\n",
      "[44, 360] loss: 1.447\n",
      "Epoch: 44 -> Loss: 1.58201694489\n",
      "Epoch: 44 -> Test Accuracy: 42.99\n",
      "[45, 60] loss: 1.447\n",
      "[45, 120] loss: 1.442\n",
      "[45, 180] loss: 1.435\n",
      "[45, 240] loss: 1.456\n",
      "[45, 300] loss: 1.471\n",
      "[45, 360] loss: 1.447\n",
      "Epoch: 45 -> Loss: 1.61785066128\n",
      "Epoch: 45 -> Test Accuracy: 42.98\n",
      "[46, 60] loss: 1.437\n",
      "[46, 120] loss: 1.436\n",
      "[46, 180] loss: 1.452\n",
      "[46, 240] loss: 1.418\n",
      "[46, 300] loss: 1.430\n",
      "[46, 360] loss: 1.451\n",
      "Epoch: 46 -> Loss: 1.55582308769\n",
      "Epoch: 46 -> Test Accuracy: 42.62\n",
      "[47, 60] loss: 1.431\n",
      "[47, 120] loss: 1.436\n",
      "[47, 180] loss: 1.436\n",
      "[47, 240] loss: 1.437\n",
      "[47, 300] loss: 1.435\n",
      "[47, 360] loss: 1.431\n",
      "Epoch: 47 -> Loss: 1.56159329414\n",
      "Epoch: 47 -> Test Accuracy: 43.09\n",
      "[48, 60] loss: 1.413\n",
      "[48, 120] loss: 1.443\n",
      "[48, 180] loss: 1.429\n",
      "[48, 240] loss: 1.447\n",
      "[48, 300] loss: 1.420\n",
      "[48, 360] loss: 1.452\n",
      "Epoch: 48 -> Loss: 1.48917782307\n",
      "Epoch: 48 -> Test Accuracy: 43.03\n",
      "[49, 60] loss: 1.437\n",
      "[49, 120] loss: 1.426\n",
      "[49, 180] loss: 1.422\n",
      "[49, 240] loss: 1.435\n",
      "[49, 300] loss: 1.440\n",
      "[49, 360] loss: 1.427\n",
      "Epoch: 49 -> Loss: 1.39532530308\n",
      "Epoch: 49 -> Test Accuracy: 43.21\n",
      "[50, 60] loss: 1.409\n",
      "[50, 120] loss: 1.435\n",
      "[50, 180] loss: 1.455\n",
      "[50, 240] loss: 1.441\n",
      "[50, 300] loss: 1.423\n",
      "[50, 360] loss: 1.429\n",
      "Epoch: 50 -> Loss: 1.34483087063\n",
      "Epoch: 50 -> Test Accuracy: 42.97\n",
      "[51, 60] loss: 1.404\n",
      "[51, 120] loss: 1.439\n",
      "[51, 180] loss: 1.434\n",
      "[51, 240] loss: 1.426\n",
      "[51, 300] loss: 1.451\n",
      "[51, 360] loss: 1.423\n",
      "Epoch: 51 -> Loss: 1.62458729744\n",
      "Epoch: 51 -> Test Accuracy: 43.24\n",
      "[52, 60] loss: 1.443\n",
      "[52, 120] loss: 1.438\n",
      "[52, 180] loss: 1.416\n",
      "[52, 240] loss: 1.424\n",
      "[52, 300] loss: 1.428\n",
      "[52, 360] loss: 1.429\n",
      "Epoch: 52 -> Loss: 1.53166079521\n",
      "Epoch: 52 -> Test Accuracy: 43.25\n",
      "[53, 60] loss: 1.434\n",
      "[53, 120] loss: 1.405\n",
      "[53, 180] loss: 1.427\n",
      "[53, 240] loss: 1.422\n",
      "[53, 300] loss: 1.440\n",
      "[53, 360] loss: 1.438\n",
      "Epoch: 53 -> Loss: 1.3822593689\n",
      "Epoch: 53 -> Test Accuracy: 43.36\n",
      "[54, 60] loss: 1.422\n",
      "[54, 120] loss: 1.424\n",
      "[54, 180] loss: 1.426\n",
      "[54, 240] loss: 1.416\n",
      "[54, 300] loss: 1.440\n",
      "[54, 360] loss: 1.428\n",
      "Epoch: 54 -> Loss: 1.54542899132\n",
      "Epoch: 54 -> Test Accuracy: 43.22\n",
      "[55, 60] loss: 1.424\n",
      "[55, 120] loss: 1.410\n",
      "[55, 180] loss: 1.418\n",
      "[55, 240] loss: 1.431\n",
      "[55, 300] loss: 1.417\n",
      "[55, 360] loss: 1.445\n",
      "Epoch: 55 -> Loss: 1.46672785282\n",
      "Epoch: 55 -> Test Accuracy: 43.35\n",
      "[56, 60] loss: 1.437\n",
      "[56, 120] loss: 1.431\n",
      "[56, 180] loss: 1.432\n",
      "[56, 240] loss: 1.408\n",
      "[56, 300] loss: 1.393\n",
      "[56, 360] loss: 1.427\n",
      "Epoch: 56 -> Loss: 1.43031644821\n",
      "Epoch: 56 -> Test Accuracy: 43.55\n",
      "[57, 60] loss: 1.425\n",
      "[57, 120] loss: 1.426\n",
      "[57, 180] loss: 1.421\n",
      "[57, 240] loss: 1.416\n",
      "[57, 300] loss: 1.420\n",
      "[57, 360] loss: 1.421\n",
      "Epoch: 57 -> Loss: 1.37018609047\n",
      "Epoch: 57 -> Test Accuracy: 43.47\n",
      "[58, 60] loss: 1.406\n",
      "[58, 120] loss: 1.416\n",
      "[58, 180] loss: 1.428\n",
      "[58, 240] loss: 1.429\n",
      "[58, 300] loss: 1.432\n",
      "[58, 360] loss: 1.442\n",
      "Epoch: 58 -> Loss: 1.34061169624\n",
      "Epoch: 58 -> Test Accuracy: 43.39\n",
      "[59, 60] loss: 1.417\n",
      "[59, 120] loss: 1.406\n",
      "[59, 180] loss: 1.405\n",
      "[59, 240] loss: 1.427\n",
      "[59, 300] loss: 1.416\n",
      "[59, 360] loss: 1.437\n",
      "Epoch: 59 -> Loss: 1.38976216316\n",
      "Epoch: 59 -> Test Accuracy: 43.18\n",
      "[60, 60] loss: 1.429\n",
      "[60, 120] loss: 1.412\n",
      "[60, 180] loss: 1.427\n",
      "[60, 240] loss: 1.426\n",
      "[60, 300] loss: 1.413\n",
      "[60, 360] loss: 1.422\n",
      "Epoch: 60 -> Loss: 1.50026750565\n",
      "Epoch: 60 -> Test Accuracy: 43.45\n",
      "[61, 60] loss: 1.442\n",
      "[61, 120] loss: 1.409\n",
      "[61, 180] loss: 1.419\n",
      "[61, 240] loss: 1.410\n",
      "[61, 300] loss: 1.414\n",
      "[61, 360] loss: 1.412\n",
      "Epoch: 61 -> Loss: 1.66970002651\n",
      "Epoch: 61 -> Test Accuracy: 43.05\n",
      "[62, 60] loss: 1.427\n",
      "[62, 120] loss: 1.425\n",
      "[62, 180] loss: 1.417\n",
      "[62, 240] loss: 1.438\n",
      "[62, 300] loss: 1.418\n",
      "[62, 360] loss: 1.415\n",
      "Epoch: 62 -> Loss: 1.37892401218\n",
      "Epoch: 62 -> Test Accuracy: 43.52\n",
      "[63, 60] loss: 1.395\n",
      "[63, 120] loss: 1.415\n",
      "[63, 180] loss: 1.426\n",
      "[63, 240] loss: 1.411\n",
      "[63, 300] loss: 1.422\n",
      "[63, 360] loss: 1.430\n",
      "Epoch: 63 -> Loss: 1.41184568405\n",
      "Epoch: 63 -> Test Accuracy: 43.48\n",
      "[64, 60] loss: 1.433\n",
      "[64, 120] loss: 1.431\n",
      "[64, 180] loss: 1.426\n",
      "[64, 240] loss: 1.414\n",
      "[64, 300] loss: 1.407\n",
      "[64, 360] loss: 1.419\n",
      "Epoch: 64 -> Loss: 1.39488089085\n",
      "Epoch: 64 -> Test Accuracy: 43.96\n",
      "[65, 60] loss: 1.417\n",
      "[65, 120] loss: 1.416\n",
      "[65, 180] loss: 1.413\n",
      "[65, 240] loss: 1.422\n",
      "[65, 300] loss: 1.425\n",
      "[65, 360] loss: 1.404\n",
      "Epoch: 65 -> Loss: 1.47419381142\n",
      "Epoch: 65 -> Test Accuracy: 43.44\n",
      "[66, 60] loss: 1.412\n",
      "[66, 120] loss: 1.405\n",
      "[66, 180] loss: 1.426\n",
      "[66, 240] loss: 1.396\n",
      "[66, 300] loss: 1.404\n",
      "[66, 360] loss: 1.415\n",
      "Epoch: 66 -> Loss: 1.55342888832\n",
      "Epoch: 66 -> Test Accuracy: 43.73\n",
      "[67, 60] loss: 1.411\n",
      "[67, 120] loss: 1.405\n",
      "[67, 180] loss: 1.419\n",
      "[67, 240] loss: 1.413\n",
      "[67, 300] loss: 1.419\n",
      "[67, 360] loss: 1.426\n",
      "Epoch: 67 -> Loss: 1.36505889893\n",
      "Epoch: 67 -> Test Accuracy: 43.42\n",
      "[68, 60] loss: 1.408\n",
      "[68, 120] loss: 1.417\n",
      "[68, 180] loss: 1.418\n",
      "[68, 240] loss: 1.394\n",
      "[68, 300] loss: 1.426\n",
      "[68, 360] loss: 1.440\n",
      "Epoch: 68 -> Loss: 1.43642902374\n",
      "Epoch: 68 -> Test Accuracy: 43.65\n",
      "[69, 60] loss: 1.418\n",
      "[69, 120] loss: 1.415\n",
      "[69, 180] loss: 1.416\n",
      "[69, 240] loss: 1.415\n",
      "[69, 300] loss: 1.414\n",
      "[69, 360] loss: 1.432\n",
      "Epoch: 69 -> Loss: 1.2604227066\n",
      "Epoch: 69 -> Test Accuracy: 43.51\n",
      "[70, 60] loss: 1.431\n",
      "[70, 120] loss: 1.427\n",
      "[70, 180] loss: 1.410\n",
      "[70, 240] loss: 1.406\n",
      "[70, 300] loss: 1.415\n",
      "[70, 360] loss: 1.415\n",
      "Epoch: 70 -> Loss: 1.29814291\n",
      "Epoch: 70 -> Test Accuracy: 43.34\n",
      "[71, 60] loss: 1.427\n",
      "[71, 120] loss: 1.425\n",
      "[71, 180] loss: 1.420\n",
      "[71, 240] loss: 1.421\n",
      "[71, 300] loss: 1.401\n",
      "[71, 360] loss: 1.425\n",
      "Epoch: 71 -> Loss: 1.37363100052\n",
      "Epoch: 71 -> Test Accuracy: 43.67\n",
      "[72, 60] loss: 1.407\n",
      "[72, 120] loss: 1.415\n",
      "[72, 180] loss: 1.427\n",
      "[72, 240] loss: 1.411\n",
      "[72, 300] loss: 1.395\n",
      "[72, 360] loss: 1.412\n",
      "Epoch: 72 -> Loss: 1.35431599617\n",
      "Epoch: 72 -> Test Accuracy: 43.51\n",
      "[73, 60] loss: 1.432\n",
      "[73, 120] loss: 1.419\n",
      "[73, 180] loss: 1.406\n",
      "[73, 240] loss: 1.407\n",
      "[73, 300] loss: 1.403\n",
      "[73, 360] loss: 1.403\n",
      "Epoch: 73 -> Loss: 1.56190168858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 -> Test Accuracy: 43.66\n",
      "[74, 60] loss: 1.406\n",
      "[74, 120] loss: 1.408\n",
      "[74, 180] loss: 1.417\n",
      "[74, 240] loss: 1.409\n",
      "[74, 300] loss: 1.408\n",
      "[74, 360] loss: 1.408\n",
      "Epoch: 74 -> Loss: 1.45614135265\n",
      "Epoch: 74 -> Test Accuracy: 43.34\n",
      "[75, 60] loss: 1.406\n",
      "[75, 120] loss: 1.424\n",
      "[75, 180] loss: 1.405\n",
      "[75, 240] loss: 1.419\n",
      "[75, 300] loss: 1.413\n",
      "[75, 360] loss: 1.402\n",
      "Epoch: 75 -> Loss: 1.35360169411\n",
      "Epoch: 75 -> Test Accuracy: 43.56\n",
      "[76, 60] loss: 1.415\n",
      "[76, 120] loss: 1.396\n",
      "[76, 180] loss: 1.388\n",
      "[76, 240] loss: 1.406\n",
      "[76, 300] loss: 1.407\n",
      "[76, 360] loss: 1.430\n",
      "Epoch: 76 -> Loss: 1.68985807896\n",
      "Epoch: 76 -> Test Accuracy: 43.49\n",
      "[77, 60] loss: 1.417\n",
      "[77, 120] loss: 1.410\n",
      "[77, 180] loss: 1.399\n",
      "[77, 240] loss: 1.405\n",
      "[77, 300] loss: 1.395\n",
      "[77, 360] loss: 1.402\n",
      "Epoch: 77 -> Loss: 1.65382122993\n",
      "Epoch: 77 -> Test Accuracy: 43.63\n",
      "[78, 60] loss: 1.397\n",
      "[78, 120] loss: 1.425\n",
      "[78, 180] loss: 1.392\n",
      "[78, 240] loss: 1.414\n",
      "[78, 300] loss: 1.415\n",
      "[78, 360] loss: 1.410\n",
      "Epoch: 78 -> Loss: 1.41281616688\n",
      "Epoch: 78 -> Test Accuracy: 43.74\n",
      "[79, 60] loss: 1.411\n",
      "[79, 120] loss: 1.425\n",
      "[79, 180] loss: 1.390\n",
      "[79, 240] loss: 1.391\n",
      "[79, 300] loss: 1.416\n",
      "[79, 360] loss: 1.410\n",
      "Epoch: 79 -> Loss: 1.52867090702\n",
      "Epoch: 79 -> Test Accuracy: 43.92\n",
      "[80, 60] loss: 1.414\n",
      "[80, 120] loss: 1.388\n",
      "[80, 180] loss: 1.387\n",
      "[80, 240] loss: 1.410\n",
      "[80, 300] loss: 1.398\n",
      "[80, 360] loss: 1.409\n",
      "Epoch: 80 -> Loss: 1.41492807865\n",
      "Epoch: 80 -> Test Accuracy: 43.89\n",
      "[81, 60] loss: 1.430\n",
      "[81, 120] loss: 1.406\n",
      "[81, 180] loss: 1.412\n",
      "[81, 240] loss: 1.413\n",
      "[81, 300] loss: 1.390\n",
      "[81, 360] loss: 1.403\n",
      "Epoch: 81 -> Loss: 1.37318897247\n",
      "Epoch: 81 -> Test Accuracy: 43.88\n",
      "[82, 60] loss: 1.402\n",
      "[82, 120] loss: 1.403\n",
      "[82, 180] loss: 1.388\n",
      "[82, 240] loss: 1.419\n",
      "[82, 300] loss: 1.403\n",
      "[82, 360] loss: 1.414\n",
      "Epoch: 82 -> Loss: 1.26672124863\n",
      "Epoch: 82 -> Test Accuracy: 43.61\n",
      "[83, 60] loss: 1.420\n",
      "[83, 120] loss: 1.411\n",
      "[83, 180] loss: 1.407\n",
      "[83, 240] loss: 1.427\n",
      "[83, 300] loss: 1.403\n",
      "[83, 360] loss: 1.417\n",
      "Epoch: 83 -> Loss: 1.41158461571\n",
      "Epoch: 83 -> Test Accuracy: 43.75\n",
      "[84, 60] loss: 1.413\n",
      "[84, 120] loss: 1.408\n",
      "[84, 180] loss: 1.410\n",
      "[84, 240] loss: 1.412\n",
      "[84, 300] loss: 1.418\n",
      "[84, 360] loss: 1.404\n",
      "Epoch: 84 -> Loss: 1.39050137997\n",
      "Epoch: 84 -> Test Accuracy: 43.75\n",
      "[85, 60] loss: 1.405\n",
      "[85, 120] loss: 1.407\n",
      "[85, 180] loss: 1.386\n",
      "[85, 240] loss: 1.404\n",
      "[85, 300] loss: 1.407\n",
      "[85, 360] loss: 1.407\n",
      "Epoch: 85 -> Loss: 1.43419981003\n",
      "Epoch: 85 -> Test Accuracy: 43.54\n",
      "[86, 60] loss: 1.421\n",
      "[86, 120] loss: 1.408\n",
      "[86, 180] loss: 1.403\n",
      "[86, 240] loss: 1.404\n",
      "[86, 300] loss: 1.391\n",
      "[86, 360] loss: 1.413\n",
      "Epoch: 86 -> Loss: 1.50575780869\n",
      "Epoch: 86 -> Test Accuracy: 43.71\n",
      "[87, 60] loss: 1.399\n",
      "[87, 120] loss: 1.409\n",
      "[87, 180] loss: 1.394\n",
      "[87, 240] loss: 1.403\n",
      "[87, 300] loss: 1.407\n",
      "[87, 360] loss: 1.404\n",
      "Epoch: 87 -> Loss: 1.46825647354\n",
      "Epoch: 87 -> Test Accuracy: 43.91\n",
      "[88, 60] loss: 1.407\n",
      "[88, 120] loss: 1.393\n",
      "[88, 180] loss: 1.405\n",
      "[88, 240] loss: 1.399\n",
      "[88, 300] loss: 1.387\n",
      "[88, 360] loss: 1.405\n",
      "Epoch: 88 -> Loss: 1.36556279659\n",
      "Epoch: 88 -> Test Accuracy: 43.77\n",
      "[89, 60] loss: 1.406\n",
      "[89, 120] loss: 1.387\n",
      "[89, 180] loss: 1.386\n",
      "[89, 240] loss: 1.411\n",
      "[89, 300] loss: 1.403\n",
      "[89, 360] loss: 1.407\n",
      "Epoch: 89 -> Loss: 1.50116181374\n",
      "Epoch: 89 -> Test Accuracy: 43.58\n",
      "[90, 60] loss: 1.395\n",
      "[90, 120] loss: 1.399\n",
      "[90, 180] loss: 1.421\n",
      "[90, 240] loss: 1.404\n",
      "[90, 300] loss: 1.407\n",
      "[90, 360] loss: 1.394\n",
      "Epoch: 90 -> Loss: 1.26786255836\n",
      "Epoch: 90 -> Test Accuracy: 43.67\n",
      "[91, 60] loss: 1.382\n",
      "[91, 120] loss: 1.380\n",
      "[91, 180] loss: 1.422\n",
      "[91, 240] loss: 1.409\n",
      "[91, 300] loss: 1.388\n",
      "[91, 360] loss: 1.406\n",
      "Epoch: 91 -> Loss: 1.39460158348\n",
      "Epoch: 91 -> Test Accuracy: 43.68\n",
      "[92, 60] loss: 1.413\n",
      "[92, 120] loss: 1.391\n",
      "[92, 180] loss: 1.420\n",
      "[92, 240] loss: 1.399\n",
      "[92, 300] loss: 1.382\n",
      "[92, 360] loss: 1.395\n",
      "Epoch: 92 -> Loss: 1.53552651405\n",
      "Epoch: 92 -> Test Accuracy: 43.72\n",
      "[93, 60] loss: 1.396\n",
      "[93, 120] loss: 1.400\n",
      "[93, 180] loss: 1.411\n",
      "[93, 240] loss: 1.396\n",
      "[93, 300] loss: 1.382\n",
      "[93, 360] loss: 1.401\n",
      "Epoch: 93 -> Loss: 1.66086745262\n",
      "Epoch: 93 -> Test Accuracy: 43.69\n",
      "[94, 60] loss: 1.405\n",
      "[94, 120] loss: 1.428\n",
      "[94, 180] loss: 1.392\n",
      "[94, 240] loss: 1.409\n",
      "[94, 300] loss: 1.410\n",
      "[94, 360] loss: 1.394\n",
      "Epoch: 94 -> Loss: 1.30477297306\n",
      "Epoch: 94 -> Test Accuracy: 43.77\n",
      "[95, 60] loss: 1.413\n",
      "[95, 120] loss: 1.394\n",
      "[95, 180] loss: 1.422\n",
      "[95, 240] loss: 1.406\n",
      "[95, 300] loss: 1.385\n",
      "[95, 360] loss: 1.390\n",
      "Epoch: 95 -> Loss: 1.61090636253\n",
      "Epoch: 95 -> Test Accuracy: 43.92\n",
      "[96, 60] loss: 1.383\n",
      "[96, 120] loss: 1.404\n",
      "[96, 180] loss: 1.415\n",
      "[96, 240] loss: 1.399\n",
      "[96, 300] loss: 1.389\n",
      "[96, 360] loss: 1.392\n",
      "Epoch: 96 -> Loss: 1.46070921421\n",
      "Epoch: 96 -> Test Accuracy: 43.87\n",
      "[97, 60] loss: 1.412\n",
      "[97, 120] loss: 1.401\n",
      "[97, 180] loss: 1.400\n",
      "[97, 240] loss: 1.398\n",
      "[97, 300] loss: 1.394\n",
      "[97, 360] loss: 1.408\n",
      "Epoch: 97 -> Loss: 1.38854551315\n",
      "Epoch: 97 -> Test Accuracy: 43.66\n",
      "[98, 60] loss: 1.382\n",
      "[98, 120] loss: 1.422\n",
      "[98, 180] loss: 1.379\n",
      "[98, 240] loss: 1.401\n",
      "[98, 300] loss: 1.397\n",
      "[98, 360] loss: 1.383\n",
      "Epoch: 98 -> Loss: 1.21464574337\n",
      "Epoch: 98 -> Test Accuracy: 43.83\n",
      "[99, 60] loss: 1.394\n",
      "[99, 120] loss: 1.378\n",
      "[99, 180] loss: 1.393\n",
      "[99, 240] loss: 1.417\n",
      "[99, 300] loss: 1.406\n",
      "[99, 360] loss: 1.379\n",
      "Epoch: 99 -> Loss: 1.36778831482\n",
      "Epoch: 99 -> Test Accuracy: 43.85\n",
      "[100, 60] loss: 1.389\n",
      "[100, 120] loss: 1.406\n",
      "[100, 180] loss: 1.386\n",
      "[100, 240] loss: 1.378\n",
      "[100, 300] loss: 1.380\n",
      "[100, 360] loss: 1.403\n",
      "Epoch: 100 -> Loss: 1.44292724133\n",
      "Epoch: 100 -> Test Accuracy: 43.77\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train NonLinearClassifiers on feature map of net_3block\n",
    "block4_loss_log, block4_valid_accuracy_log, block4_test_accuracy_log, block4_max_accuracy, block4_best_epoch = \\\n",
    "tr.train_all_blocks(4, 10, [0.1, 0.02, 0.004, 0.0008], [20, 40, 45, 100], 0.9, 5e-4, net_block4, criterion, trainloader,\n",
    "                    None, testloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.394\n",
      "[1, 120] loss: 1.036\n",
      "[1, 180] loss: 0.958\n",
      "[1, 240] loss: 0.882\n",
      "[1, 300] loss: 0.837\n",
      "[1, 360] loss: 0.819\n",
      "Epoch: 1 -> Loss: 0.923454582691\n",
      "Epoch: 1 -> Test Accuracy: 70.08\n",
      "[2, 60] loss: 0.746\n",
      "[2, 120] loss: 0.763\n",
      "[2, 180] loss: 0.743\n",
      "[2, 240] loss: 0.708\n",
      "[2, 300] loss: 0.686\n",
      "[2, 360] loss: 0.699\n",
      "Epoch: 2 -> Loss: 0.579561471939\n",
      "Epoch: 2 -> Test Accuracy: 73.41\n",
      "[3, 60] loss: 0.651\n",
      "[3, 120] loss: 0.627\n",
      "[3, 180] loss: 0.629\n",
      "[3, 240] loss: 0.649\n",
      "[3, 300] loss: 0.632\n",
      "[3, 360] loss: 0.628\n",
      "Epoch: 3 -> Loss: 0.693818509579\n",
      "Epoch: 3 -> Test Accuracy: 75.34\n",
      "[4, 60] loss: 0.592\n",
      "[4, 120] loss: 0.584\n",
      "[4, 180] loss: 0.600\n",
      "[4, 240] loss: 0.577\n",
      "[4, 300] loss: 0.577\n",
      "[4, 360] loss: 0.581\n",
      "Epoch: 4 -> Loss: 0.685258567333\n",
      "Epoch: 4 -> Test Accuracy: 77.36\n",
      "[5, 60] loss: 0.536\n",
      "[5, 120] loss: 0.561\n",
      "[5, 180] loss: 0.561\n",
      "[5, 240] loss: 0.559\n",
      "[5, 300] loss: 0.553\n",
      "[5, 360] loss: 0.579\n",
      "Epoch: 5 -> Loss: 0.505276978016\n",
      "Epoch: 5 -> Test Accuracy: 77.56\n",
      "[6, 60] loss: 0.527\n",
      "[6, 120] loss: 0.520\n",
      "[6, 180] loss: 0.530\n",
      "[6, 240] loss: 0.542\n",
      "[6, 300] loss: 0.545\n",
      "[6, 360] loss: 0.535\n",
      "Epoch: 6 -> Loss: 0.489457905293\n",
      "Epoch: 6 -> Test Accuracy: 78.44\n",
      "[7, 60] loss: 0.479\n",
      "[7, 120] loss: 0.525\n",
      "[7, 180] loss: 0.529\n",
      "[7, 240] loss: 0.510\n",
      "[7, 300] loss: 0.518\n",
      "[7, 360] loss: 0.522\n",
      "Epoch: 7 -> Loss: 0.488961458206\n",
      "Epoch: 7 -> Test Accuracy: 78.58\n",
      "[8, 60] loss: 0.494\n",
      "[8, 120] loss: 0.492\n",
      "[8, 180] loss: 0.484\n",
      "[8, 240] loss: 0.510\n",
      "[8, 300] loss: 0.529\n",
      "[8, 360] loss: 0.509\n",
      "Epoch: 8 -> Loss: 0.619894206524\n",
      "Epoch: 8 -> Test Accuracy: 79.72\n",
      "[9, 60] loss: 0.484\n",
      "[9, 120] loss: 0.476\n",
      "[9, 180] loss: 0.495\n",
      "[9, 240] loss: 0.476\n",
      "[9, 300] loss: 0.487\n",
      "[9, 360] loss: 0.505\n",
      "Epoch: 9 -> Loss: 0.521310150623\n",
      "Epoch: 9 -> Test Accuracy: 79.77\n",
      "[10, 60] loss: 0.474\n",
      "[10, 120] loss: 0.473\n",
      "[10, 180] loss: 0.489\n",
      "[10, 240] loss: 0.504\n",
      "[10, 300] loss: 0.480\n",
      "[10, 360] loss: 0.475\n",
      "Epoch: 10 -> Loss: 0.62047368288\n",
      "Epoch: 10 -> Test Accuracy: 79.56\n",
      "[11, 60] loss: 0.452\n",
      "[11, 120] loss: 0.477\n",
      "[11, 180] loss: 0.486\n",
      "[11, 240] loss: 0.471\n",
      "[11, 300] loss: 0.459\n",
      "[11, 360] loss: 0.491\n",
      "Epoch: 11 -> Loss: 0.486270576715\n",
      "Epoch: 11 -> Test Accuracy: 80.8\n",
      "[12, 60] loss: 0.452\n",
      "[12, 120] loss: 0.458\n",
      "[12, 180] loss: 0.479\n",
      "[12, 240] loss: 0.457\n",
      "[12, 300] loss: 0.483\n",
      "[12, 360] loss: 0.476\n",
      "Epoch: 12 -> Loss: 0.644150018692\n",
      "Epoch: 12 -> Test Accuracy: 80.16\n",
      "[13, 60] loss: 0.444\n",
      "[13, 120] loss: 0.457\n",
      "[13, 180] loss: 0.462\n",
      "[13, 240] loss: 0.470\n",
      "[13, 300] loss: 0.465\n",
      "[13, 360] loss: 0.461\n",
      "Epoch: 13 -> Loss: 0.779539704323\n",
      "Epoch: 13 -> Test Accuracy: 79.23\n",
      "[14, 60] loss: 0.438\n",
      "[14, 120] loss: 0.440\n",
      "[14, 180] loss: 0.439\n",
      "[14, 240] loss: 0.488\n",
      "[14, 300] loss: 0.465\n",
      "[14, 360] loss: 0.457\n",
      "Epoch: 14 -> Loss: 0.401601403952\n",
      "Epoch: 14 -> Test Accuracy: 79.92\n",
      "[15, 60] loss: 0.439\n",
      "[15, 120] loss: 0.446\n",
      "[15, 180] loss: 0.446\n",
      "[15, 240] loss: 0.464\n",
      "[15, 300] loss: 0.467\n",
      "[15, 360] loss: 0.438\n",
      "Epoch: 15 -> Loss: 0.521831929684\n",
      "Epoch: 15 -> Test Accuracy: 81.34\n",
      "[16, 60] loss: 0.425\n",
      "[16, 120] loss: 0.425\n",
      "[16, 180] loss: 0.439\n",
      "[16, 240] loss: 0.453\n",
      "[16, 300] loss: 0.463\n",
      "[16, 360] loss: 0.456\n",
      "Epoch: 16 -> Loss: 0.401683270931\n",
      "Epoch: 16 -> Test Accuracy: 79.11\n",
      "[17, 60] loss: 0.429\n",
      "[17, 120] loss: 0.446\n",
      "[17, 180] loss: 0.449\n",
      "[17, 240] loss: 0.445\n",
      "[17, 300] loss: 0.443\n",
      "[17, 360] loss: 0.458\n",
      "Epoch: 17 -> Loss: 0.424320399761\n",
      "Epoch: 17 -> Test Accuracy: 80.55\n",
      "[18, 60] loss: 0.427\n",
      "[18, 120] loss: 0.421\n",
      "[18, 180] loss: 0.446\n",
      "[18, 240] loss: 0.445\n",
      "[18, 300] loss: 0.444\n",
      "[18, 360] loss: 0.459\n",
      "Epoch: 18 -> Loss: 0.37384468317\n",
      "Epoch: 18 -> Test Accuracy: 80.04\n",
      "[19, 60] loss: 0.425\n",
      "[19, 120] loss: 0.415\n",
      "[19, 180] loss: 0.452\n",
      "[19, 240] loss: 0.422\n",
      "[19, 300] loss: 0.468\n",
      "[19, 360] loss: 0.428\n",
      "Epoch: 19 -> Loss: 0.541272461414\n",
      "Epoch: 19 -> Test Accuracy: 79.72\n",
      "[20, 60] loss: 0.425\n",
      "[20, 120] loss: 0.416\n",
      "[20, 180] loss: 0.451\n",
      "[20, 240] loss: 0.440\n",
      "[20, 300] loss: 0.437\n",
      "[20, 360] loss: 0.444\n",
      "Epoch: 20 -> Loss: 0.375393718481\n",
      "Epoch: 20 -> Test Accuracy: 79.93\n",
      "[21, 60] loss: 0.415\n",
      "[21, 120] loss: 0.430\n",
      "[21, 180] loss: 0.432\n",
      "[21, 240] loss: 0.435\n",
      "[21, 300] loss: 0.440\n",
      "[21, 360] loss: 0.447\n",
      "Epoch: 21 -> Loss: 0.51179921627\n",
      "Epoch: 21 -> Test Accuracy: 81.28\n",
      "[22, 60] loss: 0.406\n",
      "[22, 120] loss: 0.440\n",
      "[22, 180] loss: 0.443\n",
      "[22, 240] loss: 0.427\n",
      "[22, 300] loss: 0.448\n",
      "[22, 360] loss: 0.426\n",
      "Epoch: 22 -> Loss: 0.578393638134\n",
      "Epoch: 22 -> Test Accuracy: 80.74\n",
      "[23, 60] loss: 0.422\n",
      "[23, 120] loss: 0.401\n",
      "[23, 180] loss: 0.454\n",
      "[23, 240] loss: 0.428\n",
      "[23, 300] loss: 0.448\n",
      "[23, 360] loss: 0.438\n",
      "Epoch: 23 -> Loss: 0.588028550148\n",
      "Epoch: 23 -> Test Accuracy: 79.8\n",
      "[24, 60] loss: 0.383\n",
      "[24, 120] loss: 0.422\n",
      "[24, 180] loss: 0.422\n",
      "[24, 240] loss: 0.424\n",
      "[24, 300] loss: 0.440\n",
      "[24, 360] loss: 0.432\n",
      "Epoch: 24 -> Loss: 0.493817746639\n",
      "Epoch: 24 -> Test Accuracy: 81.61\n",
      "[25, 60] loss: 0.401\n",
      "[25, 120] loss: 0.421\n",
      "[25, 180] loss: 0.450\n",
      "[25, 240] loss: 0.413\n",
      "[25, 300] loss: 0.425\n",
      "[25, 360] loss: 0.428\n",
      "Epoch: 25 -> Loss: 0.473677545786\n",
      "Epoch: 25 -> Test Accuracy: 80.91\n",
      "[26, 60] loss: 0.391\n",
      "[26, 120] loss: 0.422\n",
      "[26, 180] loss: 0.430\n",
      "[26, 240] loss: 0.428\n",
      "[26, 300] loss: 0.420\n",
      "[26, 360] loss: 0.463\n",
      "Epoch: 26 -> Loss: 0.389225065708\n",
      "Epoch: 26 -> Test Accuracy: 81.74\n",
      "[27, 60] loss: 0.418\n",
      "[27, 120] loss: 0.402\n",
      "[27, 180] loss: 0.394\n",
      "[27, 240] loss: 0.420\n",
      "[27, 300] loss: 0.431\n",
      "[27, 360] loss: 0.434\n",
      "Epoch: 27 -> Loss: 0.531800150871\n",
      "Epoch: 27 -> Test Accuracy: 81.52\n",
      "[28, 60] loss: 0.400\n",
      "[28, 120] loss: 0.427\n",
      "[28, 180] loss: 0.414\n",
      "[28, 240] loss: 0.434\n",
      "[28, 300] loss: 0.438\n",
      "[28, 360] loss: 0.426\n",
      "Epoch: 28 -> Loss: 0.589133858681\n",
      "Epoch: 28 -> Test Accuracy: 81.08\n",
      "[29, 60] loss: 0.383\n",
      "[29, 120] loss: 0.407\n",
      "[29, 180] loss: 0.405\n",
      "[29, 240] loss: 0.424\n",
      "[29, 300] loss: 0.431\n",
      "[29, 360] loss: 0.430\n",
      "Epoch: 29 -> Loss: 0.511840939522\n",
      "Epoch: 29 -> Test Accuracy: 81.1\n",
      "[30, 60] loss: 0.411\n",
      "[30, 120] loss: 0.409\n",
      "[30, 180] loss: 0.407\n",
      "[30, 240] loss: 0.418\n",
      "[30, 300] loss: 0.435\n",
      "[30, 360] loss: 0.439\n",
      "Epoch: 30 -> Loss: 0.249245852232\n",
      "Epoch: 30 -> Test Accuracy: 80.96\n",
      "[31, 60] loss: 0.398\n",
      "[31, 120] loss: 0.401\n",
      "[31, 180] loss: 0.400\n",
      "[31, 240] loss: 0.413\n",
      "[31, 300] loss: 0.434\n",
      "[31, 360] loss: 0.435\n",
      "Epoch: 31 -> Loss: 0.405907392502\n",
      "Epoch: 31 -> Test Accuracy: 81.38\n",
      "[32, 60] loss: 0.420\n",
      "[32, 120] loss: 0.397\n",
      "[32, 180] loss: 0.411\n",
      "[32, 240] loss: 0.417\n",
      "[32, 300] loss: 0.432\n",
      "[32, 360] loss: 0.416\n",
      "Epoch: 32 -> Loss: 0.509563803673\n",
      "Epoch: 32 -> Test Accuracy: 79.87\n",
      "[33, 60] loss: 0.403\n",
      "[33, 120] loss: 0.412\n",
      "[33, 180] loss: 0.422\n",
      "[33, 240] loss: 0.392\n",
      "[33, 300] loss: 0.415\n",
      "[33, 360] loss: 0.432\n",
      "Epoch: 33 -> Loss: 0.389994382858\n",
      "Epoch: 33 -> Test Accuracy: 81.09\n",
      "[34, 60] loss: 0.410\n",
      "[34, 120] loss: 0.396\n",
      "[34, 180] loss: 0.410\n",
      "[34, 240] loss: 0.409\n",
      "[34, 300] loss: 0.430\n",
      "[34, 360] loss: 0.417\n",
      "Epoch: 34 -> Loss: 0.287341117859\n",
      "Epoch: 34 -> Test Accuracy: 80.45\n",
      "[35, 60] loss: 0.389\n",
      "[35, 120] loss: 0.412\n",
      "[35, 180] loss: 0.424\n",
      "[35, 240] loss: 0.418\n",
      "[35, 300] loss: 0.427\n",
      "[35, 360] loss: 0.415\n",
      "Epoch: 35 -> Loss: 0.291394114494\n",
      "Epoch: 35 -> Test Accuracy: 81.19\n",
      "[36, 60] loss: 0.317\n",
      "[36, 120] loss: 0.302\n",
      "[36, 180] loss: 0.288\n",
      "[36, 240] loss: 0.287\n",
      "[36, 300] loss: 0.280\n",
      "[36, 360] loss: 0.270\n",
      "Epoch: 36 -> Loss: 0.277999222279\n",
      "Epoch: 36 -> Test Accuracy: 85.19\n",
      "[37, 60] loss: 0.247\n",
      "[37, 120] loss: 0.261\n",
      "[37, 180] loss: 0.253\n",
      "[37, 240] loss: 0.271\n",
      "[37, 300] loss: 0.264\n",
      "[37, 360] loss: 0.262\n",
      "Epoch: 37 -> Loss: 0.158485084772\n",
      "Epoch: 37 -> Test Accuracy: 85.47\n",
      "[38, 60] loss: 0.235\n",
      "[38, 120] loss: 0.247\n",
      "[38, 180] loss: 0.243\n",
      "[38, 240] loss: 0.257\n",
      "[38, 300] loss: 0.257\n",
      "[38, 360] loss: 0.248\n",
      "Epoch: 38 -> Loss: 0.2482778579\n",
      "Epoch: 38 -> Test Accuracy: 85.88\n",
      "[39, 60] loss: 0.232\n",
      "[39, 120] loss: 0.231\n",
      "[39, 180] loss: 0.233\n",
      "[39, 240] loss: 0.246\n",
      "[39, 300] loss: 0.238\n",
      "[39, 360] loss: 0.241\n",
      "Epoch: 39 -> Loss: 0.323215663433\n",
      "Epoch: 39 -> Test Accuracy: 85.63\n",
      "[40, 60] loss: 0.231\n",
      "[40, 120] loss: 0.227\n",
      "[40, 180] loss: 0.236\n",
      "[40, 240] loss: 0.234\n",
      "[40, 300] loss: 0.238\n",
      "[40, 360] loss: 0.239\n",
      "Epoch: 40 -> Loss: 0.213495820761\n",
      "Epoch: 40 -> Test Accuracy: 85.07\n",
      "[41, 60] loss: 0.220\n",
      "[41, 120] loss: 0.213\n",
      "[41, 180] loss: 0.228\n",
      "[41, 240] loss: 0.228\n",
      "[41, 300] loss: 0.239\n",
      "[41, 360] loss: 0.244\n",
      "Epoch: 41 -> Loss: 0.281728237867\n",
      "Epoch: 41 -> Test Accuracy: 85.41\n",
      "[42, 60] loss: 0.218\n",
      "[42, 120] loss: 0.222\n",
      "[42, 180] loss: 0.229\n",
      "[42, 240] loss: 0.230\n",
      "[42, 300] loss: 0.229\n",
      "[42, 360] loss: 0.234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.323784887791\n",
      "Epoch: 42 -> Test Accuracy: 85.36\n",
      "[43, 60] loss: 0.218\n",
      "[43, 120] loss: 0.217\n",
      "[43, 180] loss: 0.224\n",
      "[43, 240] loss: 0.222\n",
      "[43, 300] loss: 0.233\n",
      "[43, 360] loss: 0.244\n",
      "Epoch: 43 -> Loss: 0.371331512928\n",
      "Epoch: 43 -> Test Accuracy: 85.25\n",
      "[44, 60] loss: 0.206\n",
      "[44, 120] loss: 0.223\n",
      "[44, 180] loss: 0.231\n",
      "[44, 240] loss: 0.210\n",
      "[44, 300] loss: 0.234\n",
      "[44, 360] loss: 0.234\n",
      "Epoch: 44 -> Loss: 0.151928126812\n",
      "Epoch: 44 -> Test Accuracy: 85.12\n",
      "[45, 60] loss: 0.207\n",
      "[45, 120] loss: 0.221\n",
      "[45, 180] loss: 0.225\n",
      "[45, 240] loss: 0.227\n",
      "[45, 300] loss: 0.225\n",
      "[45, 360] loss: 0.249\n",
      "Epoch: 45 -> Loss: 0.221330314875\n",
      "Epoch: 45 -> Test Accuracy: 85.05\n",
      "[46, 60] loss: 0.215\n",
      "[46, 120] loss: 0.209\n",
      "[46, 180] loss: 0.217\n",
      "[46, 240] loss: 0.233\n",
      "[46, 300] loss: 0.233\n",
      "[46, 360] loss: 0.234\n",
      "Epoch: 46 -> Loss: 0.236365795135\n",
      "Epoch: 46 -> Test Accuracy: 84.76\n",
      "[47, 60] loss: 0.202\n",
      "[47, 120] loss: 0.215\n",
      "[47, 180] loss: 0.216\n",
      "[47, 240] loss: 0.230\n",
      "[47, 300] loss: 0.226\n",
      "[47, 360] loss: 0.235\n",
      "Epoch: 47 -> Loss: 0.306506931782\n",
      "Epoch: 47 -> Test Accuracy: 84.41\n",
      "[48, 60] loss: 0.213\n",
      "[48, 120] loss: 0.230\n",
      "[48, 180] loss: 0.220\n",
      "[48, 240] loss: 0.235\n",
      "[48, 300] loss: 0.229\n",
      "[48, 360] loss: 0.229\n",
      "Epoch: 48 -> Loss: 0.355921715498\n",
      "Epoch: 48 -> Test Accuracy: 85.26\n",
      "[49, 60] loss: 0.206\n",
      "[49, 120] loss: 0.217\n",
      "[49, 180] loss: 0.213\n",
      "[49, 240] loss: 0.237\n",
      "[49, 300] loss: 0.236\n",
      "[49, 360] loss: 0.243\n",
      "Epoch: 49 -> Loss: 0.159369468689\n",
      "Epoch: 49 -> Test Accuracy: 84.86\n",
      "[50, 60] loss: 0.217\n",
      "[50, 120] loss: 0.211\n",
      "[50, 180] loss: 0.232\n",
      "[50, 240] loss: 0.220\n",
      "[50, 300] loss: 0.239\n",
      "[50, 360] loss: 0.232\n",
      "Epoch: 50 -> Loss: 0.236751884222\n",
      "Epoch: 50 -> Test Accuracy: 85.17\n",
      "[51, 60] loss: 0.213\n",
      "[51, 120] loss: 0.230\n",
      "[51, 180] loss: 0.223\n",
      "[51, 240] loss: 0.217\n",
      "[51, 300] loss: 0.235\n",
      "[51, 360] loss: 0.225\n",
      "Epoch: 51 -> Loss: 0.257622927427\n",
      "Epoch: 51 -> Test Accuracy: 84.9\n",
      "[52, 60] loss: 0.209\n",
      "[52, 120] loss: 0.205\n",
      "[52, 180] loss: 0.221\n",
      "[52, 240] loss: 0.235\n",
      "[52, 300] loss: 0.232\n",
      "[52, 360] loss: 0.239\n",
      "Epoch: 52 -> Loss: 0.192789524794\n",
      "Epoch: 52 -> Test Accuracy: 84.75\n",
      "[53, 60] loss: 0.208\n",
      "[53, 120] loss: 0.228\n",
      "[53, 180] loss: 0.225\n",
      "[53, 240] loss: 0.227\n",
      "[53, 300] loss: 0.230\n",
      "[53, 360] loss: 0.224\n",
      "Epoch: 53 -> Loss: 0.171563431621\n",
      "Epoch: 53 -> Test Accuracy: 83.88\n",
      "[54, 60] loss: 0.211\n",
      "[54, 120] loss: 0.216\n",
      "[54, 180] loss: 0.212\n",
      "[54, 240] loss: 0.231\n",
      "[54, 300] loss: 0.230\n",
      "[54, 360] loss: 0.247\n",
      "Epoch: 54 -> Loss: 0.214097782969\n",
      "Epoch: 54 -> Test Accuracy: 84.63\n",
      "[55, 60] loss: 0.209\n",
      "[55, 120] loss: 0.210\n",
      "[55, 180] loss: 0.214\n",
      "[55, 240] loss: 0.218\n",
      "[55, 300] loss: 0.221\n",
      "[55, 360] loss: 0.236\n",
      "Epoch: 55 -> Loss: 0.235678464174\n",
      "Epoch: 55 -> Test Accuracy: 84.06\n",
      "[56, 60] loss: 0.204\n",
      "[56, 120] loss: 0.208\n",
      "[56, 180] loss: 0.203\n",
      "[56, 240] loss: 0.229\n",
      "[56, 300] loss: 0.236\n",
      "[56, 360] loss: 0.232\n",
      "Epoch: 56 -> Loss: 0.401964336634\n",
      "Epoch: 56 -> Test Accuracy: 84.66\n",
      "[57, 60] loss: 0.206\n",
      "[57, 120] loss: 0.214\n",
      "[57, 180] loss: 0.223\n",
      "[57, 240] loss: 0.214\n",
      "[57, 300] loss: 0.226\n",
      "[57, 360] loss: 0.232\n",
      "Epoch: 57 -> Loss: 0.265280812979\n",
      "Epoch: 57 -> Test Accuracy: 84.19\n",
      "[58, 60] loss: 0.199\n",
      "[58, 120] loss: 0.221\n",
      "[58, 180] loss: 0.225\n",
      "[58, 240] loss: 0.233\n",
      "[58, 300] loss: 0.222\n",
      "[58, 360] loss: 0.228\n",
      "Epoch: 58 -> Loss: 0.256299823523\n",
      "Epoch: 58 -> Test Accuracy: 84.07\n",
      "[59, 60] loss: 0.211\n",
      "[59, 120] loss: 0.213\n",
      "[59, 180] loss: 0.224\n",
      "[59, 240] loss: 0.225\n",
      "[59, 300] loss: 0.236\n",
      "[59, 360] loss: 0.218\n",
      "Epoch: 59 -> Loss: 0.313919186592\n",
      "Epoch: 59 -> Test Accuracy: 83.8\n",
      "[60, 60] loss: 0.203\n",
      "[60, 120] loss: 0.209\n",
      "[60, 180] loss: 0.213\n",
      "[60, 240] loss: 0.231\n",
      "[60, 300] loss: 0.223\n",
      "[60, 360] loss: 0.226\n",
      "Epoch: 60 -> Loss: 0.147210642695\n",
      "Epoch: 60 -> Test Accuracy: 83.62\n",
      "[61, 60] loss: 0.208\n",
      "[61, 120] loss: 0.197\n",
      "[61, 180] loss: 0.217\n",
      "[61, 240] loss: 0.227\n",
      "[61, 300] loss: 0.227\n",
      "[61, 360] loss: 0.227\n",
      "Epoch: 61 -> Loss: 0.242491215467\n",
      "Epoch: 61 -> Test Accuracy: 84.28\n",
      "[62, 60] loss: 0.207\n",
      "[62, 120] loss: 0.207\n",
      "[62, 180] loss: 0.216\n",
      "[62, 240] loss: 0.214\n",
      "[62, 300] loss: 0.226\n",
      "[62, 360] loss: 0.223\n",
      "Epoch: 62 -> Loss: 0.370260685682\n",
      "Epoch: 62 -> Test Accuracy: 83.88\n",
      "[63, 60] loss: 0.208\n",
      "[63, 120] loss: 0.205\n",
      "[63, 180] loss: 0.207\n",
      "[63, 240] loss: 0.227\n",
      "[63, 300] loss: 0.215\n",
      "[63, 360] loss: 0.245\n",
      "Epoch: 63 -> Loss: 0.318484604359\n",
      "Epoch: 63 -> Test Accuracy: 84.68\n",
      "[64, 60] loss: 0.208\n",
      "[64, 120] loss: 0.209\n",
      "[64, 180] loss: 0.222\n",
      "[64, 240] loss: 0.216\n",
      "[64, 300] loss: 0.218\n",
      "[64, 360] loss: 0.232\n",
      "Epoch: 64 -> Loss: 0.233302950859\n",
      "Epoch: 64 -> Test Accuracy: 83.73\n",
      "[65, 60] loss: 0.199\n",
      "[65, 120] loss: 0.210\n",
      "[65, 180] loss: 0.212\n",
      "[65, 240] loss: 0.210\n",
      "[65, 300] loss: 0.218\n",
      "[65, 360] loss: 0.230\n",
      "Epoch: 65 -> Loss: 0.25154030323\n",
      "Epoch: 65 -> Test Accuracy: 84.74\n",
      "[66, 60] loss: 0.204\n",
      "[66, 120] loss: 0.204\n",
      "[66, 180] loss: 0.209\n",
      "[66, 240] loss: 0.219\n",
      "[66, 300] loss: 0.227\n",
      "[66, 360] loss: 0.224\n",
      "Epoch: 66 -> Loss: 0.320568263531\n",
      "Epoch: 66 -> Test Accuracy: 84.27\n",
      "[67, 60] loss: 0.196\n",
      "[67, 120] loss: 0.189\n",
      "[67, 180] loss: 0.209\n",
      "[67, 240] loss: 0.223\n",
      "[67, 300] loss: 0.220\n",
      "[67, 360] loss: 0.218\n",
      "Epoch: 67 -> Loss: 0.195076435804\n",
      "Epoch: 67 -> Test Accuracy: 84.89\n",
      "[68, 60] loss: 0.191\n",
      "[68, 120] loss: 0.201\n",
      "[68, 180] loss: 0.223\n",
      "[68, 240] loss: 0.229\n",
      "[68, 300] loss: 0.229\n",
      "[68, 360] loss: 0.222\n",
      "Epoch: 68 -> Loss: 0.207546830177\n",
      "Epoch: 68 -> Test Accuracy: 84.38\n",
      "[69, 60] loss: 0.203\n",
      "[69, 120] loss: 0.200\n",
      "[69, 180] loss: 0.213\n",
      "[69, 240] loss: 0.219\n",
      "[69, 300] loss: 0.223\n",
      "[69, 360] loss: 0.212\n",
      "Epoch: 69 -> Loss: 0.221870660782\n",
      "Epoch: 69 -> Test Accuracy: 84.19\n",
      "[70, 60] loss: 0.190\n",
      "[70, 120] loss: 0.200\n",
      "[70, 180] loss: 0.213\n",
      "[70, 240] loss: 0.214\n",
      "[70, 300] loss: 0.220\n",
      "[70, 360] loss: 0.220\n",
      "Epoch: 70 -> Loss: 0.234991073608\n",
      "Epoch: 70 -> Test Accuracy: 84.66\n",
      "[71, 60] loss: 0.165\n",
      "[71, 120] loss: 0.155\n",
      "[71, 180] loss: 0.149\n",
      "[71, 240] loss: 0.144\n",
      "[71, 300] loss: 0.146\n",
      "[71, 360] loss: 0.137\n",
      "Epoch: 71 -> Loss: 0.212197139859\n",
      "Epoch: 71 -> Test Accuracy: 86.91\n",
      "[72, 60] loss: 0.132\n",
      "[72, 120] loss: 0.135\n",
      "[72, 180] loss: 0.128\n",
      "[72, 240] loss: 0.133\n",
      "[72, 300] loss: 0.137\n",
      "[72, 360] loss: 0.133\n",
      "Epoch: 72 -> Loss: 0.183058232069\n",
      "Epoch: 72 -> Test Accuracy: 86.81\n",
      "[73, 60] loss: 0.126\n",
      "[73, 120] loss: 0.118\n",
      "[73, 180] loss: 0.124\n",
      "[73, 240] loss: 0.124\n",
      "[73, 300] loss: 0.121\n",
      "[73, 360] loss: 0.122\n",
      "Epoch: 73 -> Loss: 0.197713762522\n",
      "Epoch: 73 -> Test Accuracy: 86.51\n",
      "[74, 60] loss: 0.121\n",
      "[74, 120] loss: 0.121\n",
      "[74, 180] loss: 0.128\n",
      "[74, 240] loss: 0.117\n",
      "[74, 300] loss: 0.119\n",
      "[74, 360] loss: 0.123\n",
      "Epoch: 74 -> Loss: 0.177908584476\n",
      "Epoch: 74 -> Test Accuracy: 86.73\n",
      "[75, 60] loss: 0.111\n",
      "[75, 120] loss: 0.114\n",
      "[75, 180] loss: 0.120\n",
      "[75, 240] loss: 0.118\n",
      "[75, 300] loss: 0.113\n",
      "[75, 360] loss: 0.125\n",
      "Epoch: 75 -> Loss: 0.110593222082\n",
      "Epoch: 75 -> Test Accuracy: 86.53\n",
      "[76, 60] loss: 0.107\n",
      "[76, 120] loss: 0.114\n",
      "[76, 180] loss: 0.109\n",
      "[76, 240] loss: 0.111\n",
      "[76, 300] loss: 0.118\n",
      "[76, 360] loss: 0.120\n",
      "Epoch: 76 -> Loss: 0.0951409116387\n",
      "Epoch: 76 -> Test Accuracy: 86.76\n",
      "[77, 60] loss: 0.103\n",
      "[77, 120] loss: 0.114\n",
      "[77, 180] loss: 0.109\n",
      "[77, 240] loss: 0.114\n",
      "[77, 300] loss: 0.110\n",
      "[77, 360] loss: 0.113\n",
      "Epoch: 77 -> Loss: 0.0653486400843\n",
      "Epoch: 77 -> Test Accuracy: 86.75\n",
      "[78, 60] loss: 0.101\n",
      "[78, 120] loss: 0.119\n",
      "[78, 180] loss: 0.108\n",
      "[78, 240] loss: 0.106\n",
      "[78, 300] loss: 0.109\n",
      "[78, 360] loss: 0.112\n",
      "Epoch: 78 -> Loss: 0.0727372989058\n",
      "Epoch: 78 -> Test Accuracy: 86.45\n",
      "[79, 60] loss: 0.095\n",
      "[79, 120] loss: 0.111\n",
      "[79, 180] loss: 0.104\n",
      "[79, 240] loss: 0.106\n",
      "[79, 300] loss: 0.108\n",
      "[79, 360] loss: 0.111\n",
      "Epoch: 79 -> Loss: 0.0991299375892\n",
      "Epoch: 79 -> Test Accuracy: 86.3\n",
      "[80, 60] loss: 0.102\n",
      "[80, 120] loss: 0.102\n",
      "[80, 180] loss: 0.109\n",
      "[80, 240] loss: 0.102\n",
      "[80, 300] loss: 0.105\n",
      "[80, 360] loss: 0.106\n",
      "Epoch: 80 -> Loss: 0.109188593924\n",
      "Epoch: 80 -> Test Accuracy: 86.54\n",
      "[81, 60] loss: 0.105\n",
      "[81, 120] loss: 0.108\n",
      "[81, 180] loss: 0.099\n",
      "[81, 240] loss: 0.103\n",
      "[81, 300] loss: 0.106\n",
      "[81, 360] loss: 0.103\n",
      "Epoch: 81 -> Loss: 0.11444131285\n",
      "Epoch: 81 -> Test Accuracy: 86.67\n",
      "[82, 60] loss: 0.096\n",
      "[82, 120] loss: 0.100\n",
      "[82, 180] loss: 0.105\n",
      "[82, 240] loss: 0.096\n",
      "[82, 300] loss: 0.108\n",
      "[82, 360] loss: 0.106\n",
      "Epoch: 82 -> Loss: 0.160700753331\n",
      "Epoch: 82 -> Test Accuracy: 86.74\n",
      "[83, 60] loss: 0.099\n",
      "[83, 120] loss: 0.102\n",
      "[83, 180] loss: 0.102\n",
      "[83, 240] loss: 0.101\n",
      "[83, 300] loss: 0.102\n",
      "[83, 360] loss: 0.100\n",
      "Epoch: 83 -> Loss: 0.154236286879\n",
      "Epoch: 83 -> Test Accuracy: 86.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.096\n",
      "[84, 120] loss: 0.095\n",
      "[84, 180] loss: 0.098\n",
      "[84, 240] loss: 0.097\n",
      "[84, 300] loss: 0.101\n",
      "[84, 360] loss: 0.102\n",
      "Epoch: 84 -> Loss: 0.101365730166\n",
      "Epoch: 84 -> Test Accuracy: 86.36\n",
      "[85, 60] loss: 0.098\n",
      "[85, 120] loss: 0.096\n",
      "[85, 180] loss: 0.100\n",
      "[85, 240] loss: 0.098\n",
      "[85, 300] loss: 0.100\n",
      "[85, 360] loss: 0.104\n",
      "Epoch: 85 -> Loss: 0.0720160901546\n",
      "Epoch: 85 -> Test Accuracy: 86.4\n",
      "[86, 60] loss: 0.085\n",
      "[86, 120] loss: 0.087\n",
      "[86, 180] loss: 0.092\n",
      "[86, 240] loss: 0.085\n",
      "[86, 300] loss: 0.085\n",
      "[86, 360] loss: 0.084\n",
      "Epoch: 86 -> Loss: 0.0520862042904\n",
      "Epoch: 86 -> Test Accuracy: 86.78\n",
      "[87, 60] loss: 0.083\n",
      "[87, 120] loss: 0.081\n",
      "[87, 180] loss: 0.088\n",
      "[87, 240] loss: 0.088\n",
      "[87, 300] loss: 0.085\n",
      "[87, 360] loss: 0.084\n",
      "Epoch: 87 -> Loss: 0.112230136991\n",
      "Epoch: 87 -> Test Accuracy: 86.78\n",
      "[88, 60] loss: 0.081\n",
      "[88, 120] loss: 0.091\n",
      "[88, 180] loss: 0.078\n",
      "[88, 240] loss: 0.080\n",
      "[88, 300] loss: 0.089\n",
      "[88, 360] loss: 0.079\n",
      "Epoch: 88 -> Loss: 0.0885019674897\n",
      "Epoch: 88 -> Test Accuracy: 86.87\n",
      "[89, 60] loss: 0.085\n",
      "[89, 120] loss: 0.083\n",
      "[89, 180] loss: 0.084\n",
      "[89, 240] loss: 0.086\n",
      "[89, 300] loss: 0.082\n",
      "[89, 360] loss: 0.085\n",
      "Epoch: 89 -> Loss: 0.0710821673274\n",
      "Epoch: 89 -> Test Accuracy: 86.8\n",
      "[90, 60] loss: 0.081\n",
      "[90, 120] loss: 0.082\n",
      "[90, 180] loss: 0.081\n",
      "[90, 240] loss: 0.080\n",
      "[90, 300] loss: 0.083\n",
      "[90, 360] loss: 0.081\n",
      "Epoch: 90 -> Loss: 0.0888706296682\n",
      "Epoch: 90 -> Test Accuracy: 86.89\n",
      "[91, 60] loss: 0.083\n",
      "[91, 120] loss: 0.080\n",
      "[91, 180] loss: 0.081\n",
      "[91, 240] loss: 0.080\n",
      "[91, 300] loss: 0.082\n",
      "[91, 360] loss: 0.082\n",
      "Epoch: 91 -> Loss: 0.0760119706392\n",
      "Epoch: 91 -> Test Accuracy: 86.82\n",
      "[92, 60] loss: 0.078\n",
      "[92, 120] loss: 0.078\n",
      "[92, 180] loss: 0.083\n",
      "[92, 240] loss: 0.088\n",
      "[92, 300] loss: 0.081\n",
      "[92, 360] loss: 0.081\n",
      "Epoch: 92 -> Loss: 0.0840346813202\n",
      "Epoch: 92 -> Test Accuracy: 86.58\n",
      "[93, 60] loss: 0.079\n",
      "[93, 120] loss: 0.078\n",
      "[93, 180] loss: 0.079\n",
      "[93, 240] loss: 0.080\n",
      "[93, 300] loss: 0.085\n",
      "[93, 360] loss: 0.080\n",
      "Epoch: 93 -> Loss: 0.058117646724\n",
      "Epoch: 93 -> Test Accuracy: 86.76\n",
      "[94, 60] loss: 0.081\n",
      "[94, 120] loss: 0.082\n",
      "[94, 180] loss: 0.080\n",
      "[94, 240] loss: 0.081\n",
      "[94, 300] loss: 0.079\n",
      "[94, 360] loss: 0.079\n",
      "Epoch: 94 -> Loss: 0.0838933736086\n",
      "Epoch: 94 -> Test Accuracy: 86.64\n",
      "[95, 60] loss: 0.077\n",
      "[95, 120] loss: 0.077\n",
      "[95, 180] loss: 0.075\n",
      "[95, 240] loss: 0.079\n",
      "[95, 300] loss: 0.082\n",
      "[95, 360] loss: 0.080\n",
      "Epoch: 95 -> Loss: 0.0909370854497\n",
      "Epoch: 95 -> Test Accuracy: 86.88\n",
      "[96, 60] loss: 0.077\n",
      "[96, 120] loss: 0.081\n",
      "[96, 180] loss: 0.078\n",
      "[96, 240] loss: 0.083\n",
      "[96, 300] loss: 0.080\n",
      "[96, 360] loss: 0.081\n",
      "Epoch: 96 -> Loss: 0.116033054888\n",
      "Epoch: 96 -> Test Accuracy: 86.69\n",
      "[97, 60] loss: 0.075\n",
      "[97, 120] loss: 0.080\n",
      "[97, 180] loss: 0.080\n",
      "[97, 240] loss: 0.079\n",
      "[97, 300] loss: 0.080\n",
      "[97, 360] loss: 0.079\n",
      "Epoch: 97 -> Loss: 0.0723071917892\n",
      "Epoch: 97 -> Test Accuracy: 86.68\n",
      "[98, 60] loss: 0.079\n",
      "[98, 120] loss: 0.085\n",
      "[98, 180] loss: 0.076\n",
      "[98, 240] loss: 0.075\n",
      "[98, 300] loss: 0.077\n",
      "[98, 360] loss: 0.077\n",
      "Epoch: 98 -> Loss: 0.0871164053679\n",
      "Epoch: 98 -> Test Accuracy: 86.71\n",
      "[99, 60] loss: 0.079\n",
      "[99, 120] loss: 0.081\n",
      "[99, 180] loss: 0.082\n",
      "[99, 240] loss: 0.074\n",
      "[99, 300] loss: 0.076\n",
      "[99, 360] loss: 0.079\n",
      "Epoch: 99 -> Loss: 0.0448883883655\n",
      "Epoch: 99 -> Test Accuracy: 86.9\n",
      "[100, 60] loss: 0.075\n",
      "[100, 120] loss: 0.082\n",
      "[100, 180] loss: 0.083\n",
      "[100, 240] loss: 0.081\n",
      "[100, 300] loss: 0.078\n",
      "[100, 360] loss: 0.077\n",
      "Epoch: 100 -> Loss: 0.0844805017114\n",
      "Epoch: 100 -> Test Accuracy: 86.84\n",
      "Finished Training\n",
      "[1, 60] loss: 0.940\n",
      "[1, 120] loss: 0.632\n",
      "[1, 180] loss: 0.574\n",
      "[1, 240] loss: 0.550\n",
      "[1, 300] loss: 0.512\n",
      "[1, 360] loss: 0.493\n",
      "Epoch: 1 -> Loss: 0.463818609715\n",
      "Epoch: 1 -> Test Accuracy: 80.51\n",
      "[2, 60] loss: 0.447\n",
      "[2, 120] loss: 0.432\n",
      "[2, 180] loss: 0.440\n",
      "[2, 240] loss: 0.434\n",
      "[2, 300] loss: 0.423\n",
      "[2, 360] loss: 0.454\n",
      "Epoch: 2 -> Loss: 0.398221999407\n",
      "Epoch: 2 -> Test Accuracy: 83.56\n",
      "[3, 60] loss: 0.390\n",
      "[3, 120] loss: 0.403\n",
      "[3, 180] loss: 0.392\n",
      "[3, 240] loss: 0.381\n",
      "[3, 300] loss: 0.390\n",
      "[3, 360] loss: 0.371\n",
      "Epoch: 3 -> Loss: 0.464728504419\n",
      "Epoch: 3 -> Test Accuracy: 82.96\n",
      "[4, 60] loss: 0.355\n",
      "[4, 120] loss: 0.348\n",
      "[4, 180] loss: 0.382\n",
      "[4, 240] loss: 0.372\n",
      "[4, 300] loss: 0.373\n",
      "[4, 360] loss: 0.349\n",
      "Epoch: 4 -> Loss: 0.29524320364\n",
      "Epoch: 4 -> Test Accuracy: 84.75\n",
      "[5, 60] loss: 0.339\n",
      "[5, 120] loss: 0.330\n",
      "[5, 180] loss: 0.349\n",
      "[5, 240] loss: 0.350\n",
      "[5, 300] loss: 0.367\n",
      "[5, 360] loss: 0.357\n",
      "Epoch: 5 -> Loss: 0.35385966301\n",
      "Epoch: 5 -> Test Accuracy: 84.51\n",
      "[6, 60] loss: 0.305\n",
      "[6, 120] loss: 0.324\n",
      "[6, 180] loss: 0.331\n",
      "[6, 240] loss: 0.344\n",
      "[6, 300] loss: 0.343\n",
      "[6, 360] loss: 0.356\n",
      "Epoch: 6 -> Loss: 0.206433728337\n",
      "Epoch: 6 -> Test Accuracy: 84.96\n",
      "[7, 60] loss: 0.305\n",
      "[7, 120] loss: 0.310\n",
      "[7, 180] loss: 0.329\n",
      "[7, 240] loss: 0.331\n",
      "[7, 300] loss: 0.326\n",
      "[7, 360] loss: 0.331\n",
      "Epoch: 7 -> Loss: 0.325640976429\n",
      "Epoch: 7 -> Test Accuracy: 84.76\n",
      "[8, 60] loss: 0.295\n",
      "[8, 120] loss: 0.302\n",
      "[8, 180] loss: 0.313\n",
      "[8, 240] loss: 0.322\n",
      "[8, 300] loss: 0.332\n",
      "[8, 360] loss: 0.320\n",
      "Epoch: 8 -> Loss: 0.38960185647\n",
      "Epoch: 8 -> Test Accuracy: 85.2\n",
      "[9, 60] loss: 0.284\n",
      "[9, 120] loss: 0.303\n",
      "[9, 180] loss: 0.299\n",
      "[9, 240] loss: 0.318\n",
      "[9, 300] loss: 0.319\n",
      "[9, 360] loss: 0.308\n",
      "Epoch: 9 -> Loss: 0.277150839567\n",
      "Epoch: 9 -> Test Accuracy: 85.14\n",
      "[10, 60] loss: 0.287\n",
      "[10, 120] loss: 0.298\n",
      "[10, 180] loss: 0.314\n",
      "[10, 240] loss: 0.310\n",
      "[10, 300] loss: 0.315\n",
      "[10, 360] loss: 0.322\n",
      "Epoch: 10 -> Loss: 0.198751315475\n",
      "Epoch: 10 -> Test Accuracy: 85.9\n",
      "[11, 60] loss: 0.287\n",
      "[11, 120] loss: 0.279\n",
      "[11, 180] loss: 0.294\n",
      "[11, 240] loss: 0.303\n",
      "[11, 300] loss: 0.303\n",
      "[11, 360] loss: 0.317\n",
      "Epoch: 11 -> Loss: 0.378007829189\n",
      "Epoch: 11 -> Test Accuracy: 85.25\n",
      "[12, 60] loss: 0.278\n",
      "[12, 120] loss: 0.277\n",
      "[12, 180] loss: 0.284\n",
      "[12, 240] loss: 0.307\n",
      "[12, 300] loss: 0.310\n",
      "[12, 360] loss: 0.305\n",
      "Epoch: 12 -> Loss: 0.316973030567\n",
      "Epoch: 12 -> Test Accuracy: 85.74\n",
      "[13, 60] loss: 0.256\n",
      "[13, 120] loss: 0.273\n",
      "[13, 180] loss: 0.285\n",
      "[13, 240] loss: 0.305\n",
      "[13, 300] loss: 0.308\n",
      "[13, 360] loss: 0.295\n",
      "Epoch: 13 -> Loss: 0.445106893778\n",
      "Epoch: 13 -> Test Accuracy: 85.88\n",
      "[14, 60] loss: 0.268\n",
      "[14, 120] loss: 0.273\n",
      "[14, 180] loss: 0.293\n",
      "[14, 240] loss: 0.299\n",
      "[14, 300] loss: 0.288\n",
      "[14, 360] loss: 0.305\n",
      "Epoch: 14 -> Loss: 0.157875269651\n",
      "Epoch: 14 -> Test Accuracy: 85.24\n",
      "[15, 60] loss: 0.265\n",
      "[15, 120] loss: 0.277\n",
      "[15, 180] loss: 0.284\n",
      "[15, 240] loss: 0.292\n",
      "[15, 300] loss: 0.299\n",
      "[15, 360] loss: 0.279\n",
      "Epoch: 15 -> Loss: 0.348362982273\n",
      "Epoch: 15 -> Test Accuracy: 84.85\n",
      "[16, 60] loss: 0.263\n",
      "[16, 120] loss: 0.267\n",
      "[16, 180] loss: 0.286\n",
      "[16, 240] loss: 0.282\n",
      "[16, 300] loss: 0.302\n",
      "[16, 360] loss: 0.298\n",
      "Epoch: 16 -> Loss: 0.167901203036\n",
      "Epoch: 16 -> Test Accuracy: 85.2\n",
      "[17, 60] loss: 0.269\n",
      "[17, 120] loss: 0.259\n",
      "[17, 180] loss: 0.275\n",
      "[17, 240] loss: 0.282\n",
      "[17, 300] loss: 0.294\n",
      "[17, 360] loss: 0.295\n",
      "Epoch: 17 -> Loss: 0.477360785007\n",
      "Epoch: 17 -> Test Accuracy: 85.5\n",
      "[18, 60] loss: 0.256\n",
      "[18, 120] loss: 0.280\n",
      "[18, 180] loss: 0.286\n",
      "[18, 240] loss: 0.285\n",
      "[18, 300] loss: 0.275\n",
      "[18, 360] loss: 0.294\n",
      "Epoch: 18 -> Loss: 0.237251237035\n",
      "Epoch: 18 -> Test Accuracy: 86.0\n",
      "[19, 60] loss: 0.253\n",
      "[19, 120] loss: 0.264\n",
      "[19, 180] loss: 0.262\n",
      "[19, 240] loss: 0.282\n",
      "[19, 300] loss: 0.280\n",
      "[19, 360] loss: 0.294\n",
      "Epoch: 19 -> Loss: 0.224746108055\n",
      "Epoch: 19 -> Test Accuracy: 85.36\n",
      "[20, 60] loss: 0.257\n",
      "[20, 120] loss: 0.264\n",
      "[20, 180] loss: 0.274\n",
      "[20, 240] loss: 0.277\n",
      "[20, 300] loss: 0.286\n",
      "[20, 360] loss: 0.284\n",
      "Epoch: 20 -> Loss: 0.234430149198\n",
      "Epoch: 20 -> Test Accuracy: 85.42\n",
      "[21, 60] loss: 0.252\n",
      "[21, 120] loss: 0.252\n",
      "[21, 180] loss: 0.264\n",
      "[21, 240] loss: 0.283\n",
      "[21, 300] loss: 0.285\n",
      "[21, 360] loss: 0.282\n",
      "Epoch: 21 -> Loss: 0.302761167288\n",
      "Epoch: 21 -> Test Accuracy: 86.23\n",
      "[22, 60] loss: 0.260\n",
      "[22, 120] loss: 0.259\n",
      "[22, 180] loss: 0.270\n",
      "[22, 240] loss: 0.276\n",
      "[22, 300] loss: 0.275\n",
      "[22, 360] loss: 0.294\n",
      "Epoch: 22 -> Loss: 0.357580959797\n",
      "Epoch: 22 -> Test Accuracy: 85.08\n",
      "[23, 60] loss: 0.252\n",
      "[23, 120] loss: 0.240\n",
      "[23, 180] loss: 0.254\n",
      "[23, 240] loss: 0.273\n",
      "[23, 300] loss: 0.289\n",
      "[23, 360] loss: 0.272\n",
      "Epoch: 23 -> Loss: 0.27123683691\n",
      "Epoch: 23 -> Test Accuracy: 85.0\n",
      "[24, 60] loss: 0.255\n",
      "[24, 120] loss: 0.255\n",
      "[24, 180] loss: 0.260\n",
      "[24, 240] loss: 0.277\n",
      "[24, 300] loss: 0.283\n",
      "[24, 360] loss: 0.270\n",
      "Epoch: 24 -> Loss: 0.415149599314\n",
      "Epoch: 24 -> Test Accuracy: 85.58\n",
      "[25, 60] loss: 0.238\n",
      "[25, 120] loss: 0.263\n",
      "[25, 180] loss: 0.256\n",
      "[25, 240] loss: 0.278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 300] loss: 0.300\n",
      "[25, 360] loss: 0.279\n",
      "Epoch: 25 -> Loss: 0.353267818689\n",
      "Epoch: 25 -> Test Accuracy: 86.47\n",
      "[26, 60] loss: 0.251\n",
      "[26, 120] loss: 0.250\n",
      "[26, 180] loss: 0.268\n",
      "[26, 240] loss: 0.274\n",
      "[26, 300] loss: 0.276\n",
      "[26, 360] loss: 0.278\n",
      "Epoch: 26 -> Loss: 0.277153521776\n",
      "Epoch: 26 -> Test Accuracy: 85.39\n",
      "[27, 60] loss: 0.249\n",
      "[27, 120] loss: 0.262\n",
      "[27, 180] loss: 0.260\n",
      "[27, 240] loss: 0.268\n",
      "[27, 300] loss: 0.283\n",
      "[27, 360] loss: 0.271\n",
      "Epoch: 27 -> Loss: 0.349256575108\n",
      "Epoch: 27 -> Test Accuracy: 85.31\n",
      "[28, 60] loss: 0.246\n",
      "[28, 120] loss: 0.246\n",
      "[28, 180] loss: 0.264\n",
      "[28, 240] loss: 0.271\n",
      "[28, 300] loss: 0.287\n",
      "[28, 360] loss: 0.269\n",
      "Epoch: 28 -> Loss: 0.388958781958\n",
      "Epoch: 28 -> Test Accuracy: 85.57\n",
      "[29, 60] loss: 0.249\n",
      "[29, 120] loss: 0.238\n",
      "[29, 180] loss: 0.258\n",
      "[29, 240] loss: 0.273\n",
      "[29, 300] loss: 0.263\n",
      "[29, 360] loss: 0.282\n",
      "Epoch: 29 -> Loss: 0.26197963953\n",
      "Epoch: 29 -> Test Accuracy: 85.53\n",
      "[30, 60] loss: 0.240\n",
      "[30, 120] loss: 0.257\n",
      "[30, 180] loss: 0.261\n",
      "[30, 240] loss: 0.274\n",
      "[30, 300] loss: 0.278\n",
      "[30, 360] loss: 0.279\n",
      "Epoch: 30 -> Loss: 0.265752702951\n",
      "Epoch: 30 -> Test Accuracy: 85.39\n",
      "[31, 60] loss: 0.248\n",
      "[31, 120] loss: 0.245\n",
      "[31, 180] loss: 0.270\n",
      "[31, 240] loss: 0.265\n",
      "[31, 300] loss: 0.275\n",
      "[31, 360] loss: 0.292\n",
      "Epoch: 31 -> Loss: 0.303811311722\n",
      "Epoch: 31 -> Test Accuracy: 85.13\n",
      "[32, 60] loss: 0.244\n",
      "[32, 120] loss: 0.251\n",
      "[32, 180] loss: 0.253\n",
      "[32, 240] loss: 0.250\n",
      "[32, 300] loss: 0.280\n",
      "[32, 360] loss: 0.292\n",
      "Epoch: 32 -> Loss: 0.324484199286\n",
      "Epoch: 32 -> Test Accuracy: 86.01\n",
      "[33, 60] loss: 0.239\n",
      "[33, 120] loss: 0.243\n",
      "[33, 180] loss: 0.257\n",
      "[33, 240] loss: 0.269\n",
      "[33, 300] loss: 0.277\n",
      "[33, 360] loss: 0.281\n",
      "Epoch: 33 -> Loss: 0.25650909543\n",
      "Epoch: 33 -> Test Accuracy: 85.66\n",
      "[34, 60] loss: 0.230\n",
      "[34, 120] loss: 0.259\n",
      "[34, 180] loss: 0.264\n",
      "[34, 240] loss: 0.270\n",
      "[34, 300] loss: 0.283\n",
      "[34, 360] loss: 0.264\n",
      "Epoch: 34 -> Loss: 0.208400294185\n",
      "Epoch: 34 -> Test Accuracy: 86.05\n",
      "[35, 60] loss: 0.237\n",
      "[35, 120] loss: 0.244\n",
      "[35, 180] loss: 0.261\n",
      "[35, 240] loss: 0.262\n",
      "[35, 300] loss: 0.268\n",
      "[35, 360] loss: 0.284\n",
      "Epoch: 35 -> Loss: 0.574324369431\n",
      "Epoch: 35 -> Test Accuracy: 86.0\n",
      "[36, 60] loss: 0.200\n",
      "[36, 120] loss: 0.189\n",
      "[36, 180] loss: 0.168\n",
      "[36, 240] loss: 0.177\n",
      "[36, 300] loss: 0.166\n",
      "[36, 360] loss: 0.160\n",
      "Epoch: 36 -> Loss: 0.213209629059\n",
      "Epoch: 36 -> Test Accuracy: 88.47\n",
      "[37, 60] loss: 0.144\n",
      "[37, 120] loss: 0.151\n",
      "[37, 180] loss: 0.140\n",
      "[37, 240] loss: 0.137\n",
      "[37, 300] loss: 0.139\n",
      "[37, 360] loss: 0.148\n",
      "Epoch: 37 -> Loss: 0.141361922026\n",
      "Epoch: 37 -> Test Accuracy: 88.22\n",
      "[38, 60] loss: 0.132\n",
      "[38, 120] loss: 0.132\n",
      "[38, 180] loss: 0.125\n",
      "[38, 240] loss: 0.138\n",
      "[38, 300] loss: 0.136\n",
      "[38, 360] loss: 0.136\n",
      "Epoch: 38 -> Loss: 0.177453607321\n",
      "Epoch: 38 -> Test Accuracy: 88.34\n",
      "[39, 60] loss: 0.125\n",
      "[39, 120] loss: 0.121\n",
      "[39, 180] loss: 0.120\n",
      "[39, 240] loss: 0.121\n",
      "[39, 300] loss: 0.130\n",
      "[39, 360] loss: 0.127\n",
      "Epoch: 39 -> Loss: 0.179087281227\n",
      "Epoch: 39 -> Test Accuracy: 88.51\n",
      "[40, 60] loss: 0.105\n",
      "[40, 120] loss: 0.124\n",
      "[40, 180] loss: 0.116\n",
      "[40, 240] loss: 0.113\n",
      "[40, 300] loss: 0.112\n",
      "[40, 360] loss: 0.125\n",
      "Epoch: 40 -> Loss: 0.0878138393164\n",
      "Epoch: 40 -> Test Accuracy: 88.18\n",
      "[41, 60] loss: 0.104\n",
      "[41, 120] loss: 0.117\n",
      "[41, 180] loss: 0.116\n",
      "[41, 240] loss: 0.119\n",
      "[41, 300] loss: 0.114\n",
      "[41, 360] loss: 0.112\n",
      "Epoch: 41 -> Loss: 0.164249405265\n",
      "Epoch: 41 -> Test Accuracy: 88.22\n",
      "[42, 60] loss: 0.100\n",
      "[42, 120] loss: 0.103\n",
      "[42, 180] loss: 0.107\n",
      "[42, 240] loss: 0.115\n",
      "[42, 300] loss: 0.119\n",
      "[42, 360] loss: 0.119\n",
      "Epoch: 42 -> Loss: 0.104909852147\n",
      "Epoch: 42 -> Test Accuracy: 88.89\n",
      "[43, 60] loss: 0.111\n",
      "[43, 120] loss: 0.106\n",
      "[43, 180] loss: 0.101\n",
      "[43, 240] loss: 0.113\n",
      "[43, 300] loss: 0.113\n",
      "[43, 360] loss: 0.120\n",
      "Epoch: 43 -> Loss: 0.170936107635\n",
      "Epoch: 43 -> Test Accuracy: 88.03\n",
      "[44, 60] loss: 0.102\n",
      "[44, 120] loss: 0.103\n",
      "[44, 180] loss: 0.110\n",
      "[44, 240] loss: 0.109\n",
      "[44, 300] loss: 0.110\n",
      "[44, 360] loss: 0.112\n",
      "Epoch: 44 -> Loss: 0.0454615876079\n",
      "Epoch: 44 -> Test Accuracy: 88.27\n",
      "[45, 60] loss: 0.097\n",
      "[45, 120] loss: 0.100\n",
      "[45, 180] loss: 0.108\n",
      "[45, 240] loss: 0.109\n",
      "[45, 300] loss: 0.120\n",
      "[45, 360] loss: 0.110\n",
      "Epoch: 45 -> Loss: 0.112169191241\n",
      "Epoch: 45 -> Test Accuracy: 87.71\n",
      "[46, 60] loss: 0.093\n",
      "[46, 120] loss: 0.098\n",
      "[46, 180] loss: 0.103\n",
      "[46, 240] loss: 0.099\n",
      "[46, 300] loss: 0.114\n",
      "[46, 360] loss: 0.123\n",
      "Epoch: 46 -> Loss: 0.0747150853276\n",
      "Epoch: 46 -> Test Accuracy: 88.24\n",
      "[47, 60] loss: 0.095\n",
      "[47, 120] loss: 0.100\n",
      "[47, 180] loss: 0.110\n",
      "[47, 240] loss: 0.104\n",
      "[47, 300] loss: 0.114\n",
      "[47, 360] loss: 0.116\n",
      "Epoch: 47 -> Loss: 0.172845721245\n",
      "Epoch: 47 -> Test Accuracy: 88.15\n",
      "[48, 60] loss: 0.102\n",
      "[48, 120] loss: 0.105\n",
      "[48, 180] loss: 0.104\n",
      "[48, 240] loss: 0.115\n",
      "[48, 300] loss: 0.115\n",
      "[48, 360] loss: 0.111\n",
      "Epoch: 48 -> Loss: 0.0347038805485\n",
      "Epoch: 48 -> Test Accuracy: 87.94\n",
      "[49, 60] loss: 0.093\n",
      "[49, 120] loss: 0.102\n",
      "[49, 180] loss: 0.102\n",
      "[49, 240] loss: 0.111\n",
      "[49, 300] loss: 0.110\n",
      "[49, 360] loss: 0.110\n",
      "Epoch: 49 -> Loss: 0.142517060041\n",
      "Epoch: 49 -> Test Accuracy: 87.36\n",
      "[50, 60] loss: 0.098\n",
      "[50, 120] loss: 0.103\n",
      "[50, 180] loss: 0.103\n",
      "[50, 240] loss: 0.110\n",
      "[50, 300] loss: 0.110\n",
      "[50, 360] loss: 0.119\n",
      "Epoch: 50 -> Loss: 0.14515247941\n",
      "Epoch: 50 -> Test Accuracy: 87.68\n",
      "[51, 60] loss: 0.101\n",
      "[51, 120] loss: 0.111\n",
      "[51, 180] loss: 0.104\n",
      "[51, 240] loss: 0.108\n",
      "[51, 300] loss: 0.112\n",
      "[51, 360] loss: 0.108\n",
      "Epoch: 51 -> Loss: 0.0892527326941\n",
      "Epoch: 51 -> Test Accuracy: 87.27\n",
      "[52, 60] loss: 0.093\n",
      "[52, 120] loss: 0.095\n",
      "[52, 180] loss: 0.101\n",
      "[52, 240] loss: 0.107\n",
      "[52, 300] loss: 0.120\n",
      "[52, 360] loss: 0.111\n",
      "Epoch: 52 -> Loss: 0.0890118032694\n",
      "Epoch: 52 -> Test Accuracy: 87.35\n",
      "[53, 60] loss: 0.101\n",
      "[53, 120] loss: 0.102\n",
      "[53, 180] loss: 0.096\n",
      "[53, 240] loss: 0.107\n",
      "[53, 300] loss: 0.115\n",
      "[53, 360] loss: 0.112\n",
      "Epoch: 53 -> Loss: 0.105330608785\n",
      "Epoch: 53 -> Test Accuracy: 87.39\n",
      "[54, 60] loss: 0.089\n",
      "[54, 120] loss: 0.101\n",
      "[54, 180] loss: 0.104\n",
      "[54, 240] loss: 0.104\n",
      "[54, 300] loss: 0.113\n",
      "[54, 360] loss: 0.126\n",
      "Epoch: 54 -> Loss: 0.0998519808054\n",
      "Epoch: 54 -> Test Accuracy: 87.45\n",
      "[55, 60] loss: 0.097\n",
      "[55, 120] loss: 0.094\n",
      "[55, 180] loss: 0.111\n",
      "[55, 240] loss: 0.101\n",
      "[55, 300] loss: 0.116\n",
      "[55, 360] loss: 0.111\n",
      "Epoch: 55 -> Loss: 0.0747781246901\n",
      "Epoch: 55 -> Test Accuracy: 87.61\n",
      "[56, 60] loss: 0.093\n",
      "[56, 120] loss: 0.096\n",
      "[56, 180] loss: 0.104\n",
      "[56, 240] loss: 0.115\n",
      "[56, 300] loss: 0.112\n",
      "[56, 360] loss: 0.131\n",
      "Epoch: 56 -> Loss: 0.131181523204\n",
      "Epoch: 56 -> Test Accuracy: 86.83\n",
      "[57, 60] loss: 0.099\n",
      "[57, 120] loss: 0.098\n",
      "[57, 180] loss: 0.111\n",
      "[57, 240] loss: 0.112\n",
      "[57, 300] loss: 0.107\n",
      "[57, 360] loss: 0.118\n",
      "Epoch: 57 -> Loss: 0.0841394364834\n",
      "Epoch: 57 -> Test Accuracy: 87.61\n",
      "[58, 60] loss: 0.095\n",
      "[58, 120] loss: 0.100\n",
      "[58, 180] loss: 0.108\n",
      "[58, 240] loss: 0.112\n",
      "[58, 300] loss: 0.111\n",
      "[58, 360] loss: 0.110\n",
      "Epoch: 58 -> Loss: 0.0604541711509\n",
      "Epoch: 58 -> Test Accuracy: 87.44\n",
      "[59, 60] loss: 0.100\n",
      "[59, 120] loss: 0.098\n",
      "[59, 180] loss: 0.103\n",
      "[59, 240] loss: 0.102\n",
      "[59, 300] loss: 0.104\n",
      "[59, 360] loss: 0.125\n",
      "Epoch: 59 -> Loss: 0.106396354735\n",
      "Epoch: 59 -> Test Accuracy: 87.37\n",
      "[60, 60] loss: 0.093\n",
      "[60, 120] loss: 0.106\n",
      "[60, 180] loss: 0.105\n",
      "[60, 240] loss: 0.100\n",
      "[60, 300] loss: 0.117\n",
      "[60, 360] loss: 0.118\n",
      "Epoch: 60 -> Loss: 0.143519252539\n",
      "Epoch: 60 -> Test Accuracy: 86.86\n",
      "[61, 60] loss: 0.095\n",
      "[61, 120] loss: 0.084\n",
      "[61, 180] loss: 0.108\n",
      "[61, 240] loss: 0.108\n",
      "[61, 300] loss: 0.112\n",
      "[61, 360] loss: 0.109\n",
      "Epoch: 61 -> Loss: 0.0791571959853\n",
      "Epoch: 61 -> Test Accuracy: 87.2\n",
      "[62, 60] loss: 0.098\n",
      "[62, 120] loss: 0.094\n",
      "[62, 180] loss: 0.103\n",
      "[62, 240] loss: 0.104\n",
      "[62, 300] loss: 0.114\n",
      "[62, 360] loss: 0.114\n",
      "Epoch: 62 -> Loss: 0.144332438707\n",
      "Epoch: 62 -> Test Accuracy: 87.42\n",
      "[63, 60] loss: 0.096\n",
      "[63, 120] loss: 0.103\n",
      "[63, 180] loss: 0.103\n",
      "[63, 240] loss: 0.102\n",
      "[63, 300] loss: 0.108\n",
      "[63, 360] loss: 0.112\n",
      "Epoch: 63 -> Loss: 0.0382519587874\n",
      "Epoch: 63 -> Test Accuracy: 87.38\n",
      "[64, 60] loss: 0.107\n",
      "[64, 120] loss: 0.094\n",
      "[64, 180] loss: 0.104\n",
      "[64, 240] loss: 0.110\n",
      "[64, 300] loss: 0.110\n",
      "[64, 360] loss: 0.106\n",
      "Epoch: 64 -> Loss: 0.087084248662\n",
      "Epoch: 64 -> Test Accuracy: 87.35\n",
      "[65, 60] loss: 0.094\n",
      "[65, 120] loss: 0.099\n",
      "[65, 180] loss: 0.099\n",
      "[65, 240] loss: 0.103\n",
      "[65, 300] loss: 0.104\n",
      "[65, 360] loss: 0.108\n",
      "Epoch: 65 -> Loss: 0.147875994444\n",
      "Epoch: 65 -> Test Accuracy: 87.31\n",
      "[66, 60] loss: 0.092\n",
      "[66, 120] loss: 0.090\n",
      "[66, 180] loss: 0.103\n",
      "[66, 240] loss: 0.102\n",
      "[66, 300] loss: 0.110\n",
      "[66, 360] loss: 0.115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Loss: 0.0585932023823\n",
      "Epoch: 66 -> Test Accuracy: 87.55\n",
      "[67, 60] loss: 0.094\n",
      "[67, 120] loss: 0.098\n",
      "[67, 180] loss: 0.100\n",
      "[67, 240] loss: 0.102\n",
      "[67, 300] loss: 0.108\n",
      "[67, 360] loss: 0.102\n",
      "Epoch: 67 -> Loss: 0.248552799225\n",
      "Epoch: 67 -> Test Accuracy: 87.21\n",
      "[68, 60] loss: 0.092\n",
      "[68, 120] loss: 0.092\n",
      "[68, 180] loss: 0.100\n",
      "[68, 240] loss: 0.108\n",
      "[68, 300] loss: 0.109\n",
      "[68, 360] loss: 0.119\n",
      "Epoch: 68 -> Loss: 0.105272315443\n",
      "Epoch: 68 -> Test Accuracy: 87.38\n",
      "[69, 60] loss: 0.099\n",
      "[69, 120] loss: 0.094\n",
      "[69, 180] loss: 0.104\n",
      "[69, 240] loss: 0.111\n",
      "[69, 300] loss: 0.109\n",
      "[69, 360] loss: 0.121\n",
      "Epoch: 69 -> Loss: 0.172455877066\n",
      "Epoch: 69 -> Test Accuracy: 87.11\n",
      "[70, 60] loss: 0.099\n",
      "[70, 120] loss: 0.100\n",
      "[70, 180] loss: 0.099\n",
      "[70, 240] loss: 0.101\n",
      "[70, 300] loss: 0.105\n",
      "[70, 360] loss: 0.114\n",
      "Epoch: 70 -> Loss: 0.241522461176\n",
      "Epoch: 70 -> Test Accuracy: 87.41\n",
      "[71, 60] loss: 0.086\n",
      "[71, 120] loss: 0.063\n",
      "[71, 180] loss: 0.064\n",
      "[71, 240] loss: 0.065\n",
      "[71, 300] loss: 0.060\n",
      "[71, 360] loss: 0.064\n",
      "Epoch: 71 -> Loss: 0.0356141999364\n",
      "Epoch: 71 -> Test Accuracy: 88.59\n",
      "[72, 60] loss: 0.051\n",
      "[72, 120] loss: 0.049\n",
      "[72, 180] loss: 0.053\n",
      "[72, 240] loss: 0.055\n",
      "[72, 300] loss: 0.058\n",
      "[72, 360] loss: 0.052\n",
      "Epoch: 72 -> Loss: 0.059558738023\n",
      "Epoch: 72 -> Test Accuracy: 88.67\n",
      "[73, 60] loss: 0.050\n",
      "[73, 120] loss: 0.050\n",
      "[73, 180] loss: 0.051\n",
      "[73, 240] loss: 0.047\n",
      "[73, 300] loss: 0.049\n",
      "[73, 360] loss: 0.048\n",
      "Epoch: 73 -> Loss: 0.0656321421266\n",
      "Epoch: 73 -> Test Accuracy: 88.64\n",
      "[74, 60] loss: 0.044\n",
      "[74, 120] loss: 0.045\n",
      "[74, 180] loss: 0.042\n",
      "[74, 240] loss: 0.044\n",
      "[74, 300] loss: 0.046\n",
      "[74, 360] loss: 0.044\n",
      "Epoch: 74 -> Loss: 0.0261993799359\n",
      "Epoch: 74 -> Test Accuracy: 88.79\n",
      "[75, 60] loss: 0.039\n",
      "[75, 120] loss: 0.043\n",
      "[75, 180] loss: 0.042\n",
      "[75, 240] loss: 0.043\n",
      "[75, 300] loss: 0.040\n",
      "[75, 360] loss: 0.042\n",
      "Epoch: 75 -> Loss: 0.037069644779\n",
      "Epoch: 75 -> Test Accuracy: 88.86\n",
      "[76, 60] loss: 0.036\n",
      "[76, 120] loss: 0.041\n",
      "[76, 180] loss: 0.042\n",
      "[76, 240] loss: 0.042\n",
      "[76, 300] loss: 0.037\n",
      "[76, 360] loss: 0.041\n",
      "Epoch: 76 -> Loss: 0.0502620637417\n",
      "Epoch: 76 -> Test Accuracy: 88.61\n",
      "[77, 60] loss: 0.039\n",
      "[77, 120] loss: 0.036\n",
      "[77, 180] loss: 0.037\n",
      "[77, 240] loss: 0.040\n",
      "[77, 300] loss: 0.044\n",
      "[77, 360] loss: 0.038\n",
      "Epoch: 77 -> Loss: 0.0595133975148\n",
      "Epoch: 77 -> Test Accuracy: 88.73\n",
      "[78, 60] loss: 0.038\n",
      "[78, 120] loss: 0.035\n",
      "[78, 180] loss: 0.040\n",
      "[78, 240] loss: 0.039\n",
      "[78, 300] loss: 0.038\n",
      "[78, 360] loss: 0.034\n",
      "Epoch: 78 -> Loss: 0.0208748634905\n",
      "Epoch: 78 -> Test Accuracy: 88.73\n",
      "[79, 60] loss: 0.038\n",
      "[79, 120] loss: 0.038\n",
      "[79, 180] loss: 0.037\n",
      "[79, 240] loss: 0.034\n",
      "[79, 300] loss: 0.039\n",
      "[79, 360] loss: 0.034\n",
      "Epoch: 79 -> Loss: 0.0311844050884\n",
      "Epoch: 79 -> Test Accuracy: 88.62\n",
      "[80, 60] loss: 0.034\n",
      "[80, 120] loss: 0.036\n",
      "[80, 180] loss: 0.033\n",
      "[80, 240] loss: 0.033\n",
      "[80, 300] loss: 0.036\n",
      "[80, 360] loss: 0.036\n",
      "Epoch: 80 -> Loss: 0.0348690226674\n",
      "Epoch: 80 -> Test Accuracy: 88.79\n",
      "[81, 60] loss: 0.030\n",
      "[81, 120] loss: 0.034\n",
      "[81, 180] loss: 0.034\n",
      "[81, 240] loss: 0.030\n",
      "[81, 300] loss: 0.036\n",
      "[81, 360] loss: 0.035\n",
      "Epoch: 81 -> Loss: 0.0219689253718\n",
      "Epoch: 81 -> Test Accuracy: 88.88\n",
      "[82, 60] loss: 0.033\n",
      "[82, 120] loss: 0.033\n",
      "[82, 180] loss: 0.028\n",
      "[82, 240] loss: 0.033\n",
      "[82, 300] loss: 0.034\n",
      "[82, 360] loss: 0.034\n",
      "Epoch: 82 -> Loss: 0.0619051381946\n",
      "Epoch: 82 -> Test Accuracy: 88.76\n",
      "[83, 60] loss: 0.034\n",
      "[83, 120] loss: 0.029\n",
      "[83, 180] loss: 0.035\n",
      "[83, 240] loss: 0.032\n",
      "[83, 300] loss: 0.033\n",
      "[83, 360] loss: 0.034\n",
      "Epoch: 83 -> Loss: 0.040428634733\n",
      "Epoch: 83 -> Test Accuracy: 88.77\n",
      "[84, 60] loss: 0.031\n",
      "[84, 120] loss: 0.031\n",
      "[84, 180] loss: 0.032\n",
      "[84, 240] loss: 0.032\n",
      "[84, 300] loss: 0.032\n",
      "[84, 360] loss: 0.034\n",
      "Epoch: 84 -> Loss: 0.0188203565776\n",
      "Epoch: 84 -> Test Accuracy: 88.64\n",
      "[85, 60] loss: 0.030\n",
      "[85, 120] loss: 0.030\n",
      "[85, 180] loss: 0.032\n",
      "[85, 240] loss: 0.030\n",
      "[85, 300] loss: 0.032\n",
      "[85, 360] loss: 0.030\n",
      "Epoch: 85 -> Loss: 0.0495106503367\n",
      "Epoch: 85 -> Test Accuracy: 88.63\n",
      "[86, 60] loss: 0.030\n",
      "[86, 120] loss: 0.029\n",
      "[86, 180] loss: 0.031\n",
      "[86, 240] loss: 0.027\n",
      "[86, 300] loss: 0.028\n",
      "[86, 360] loss: 0.027\n",
      "Epoch: 86 -> Loss: 0.0432722568512\n",
      "Epoch: 86 -> Test Accuracy: 88.8\n",
      "[87, 60] loss: 0.029\n",
      "[87, 120] loss: 0.031\n",
      "[87, 180] loss: 0.029\n",
      "[87, 240] loss: 0.029\n",
      "[87, 300] loss: 0.028\n",
      "[87, 360] loss: 0.029\n",
      "Epoch: 87 -> Loss: 0.018822144717\n",
      "Epoch: 87 -> Test Accuracy: 89.02\n",
      "[88, 60] loss: 0.025\n",
      "[88, 120] loss: 0.028\n",
      "[88, 180] loss: 0.029\n",
      "[88, 240] loss: 0.027\n",
      "[88, 300] loss: 0.027\n",
      "[88, 360] loss: 0.025\n",
      "Epoch: 88 -> Loss: 0.0868321284652\n",
      "Epoch: 88 -> Test Accuracy: 88.94\n",
      "[89, 60] loss: 0.028\n",
      "[89, 120] loss: 0.026\n",
      "[89, 180] loss: 0.028\n",
      "[89, 240] loss: 0.028\n",
      "[89, 300] loss: 0.027\n",
      "[89, 360] loss: 0.027\n",
      "Epoch: 89 -> Loss: 0.0319915488362\n",
      "Epoch: 89 -> Test Accuracy: 88.91\n",
      "[90, 60] loss: 0.027\n",
      "[90, 120] loss: 0.027\n",
      "[90, 180] loss: 0.026\n",
      "[90, 240] loss: 0.026\n",
      "[90, 300] loss: 0.024\n",
      "[90, 360] loss: 0.027\n",
      "Epoch: 90 -> Loss: 0.0171624366194\n",
      "Epoch: 90 -> Test Accuracy: 88.95\n",
      "[91, 60] loss: 0.024\n",
      "[91, 120] loss: 0.026\n",
      "[91, 180] loss: 0.028\n",
      "[91, 240] loss: 0.026\n",
      "[91, 300] loss: 0.026\n",
      "[91, 360] loss: 0.027\n",
      "Epoch: 91 -> Loss: 0.0305941645056\n",
      "Epoch: 91 -> Test Accuracy: 88.97\n",
      "[92, 60] loss: 0.026\n",
      "[92, 120] loss: 0.027\n",
      "[92, 180] loss: 0.027\n",
      "[92, 240] loss: 0.028\n",
      "[92, 300] loss: 0.026\n",
      "[92, 360] loss: 0.024\n",
      "Epoch: 92 -> Loss: 0.0695459470153\n",
      "Epoch: 92 -> Test Accuracy: 88.88\n",
      "[93, 60] loss: 0.028\n",
      "[93, 120] loss: 0.027\n",
      "[93, 180] loss: 0.027\n",
      "[93, 240] loss: 0.025\n",
      "[93, 300] loss: 0.024\n",
      "[93, 360] loss: 0.026\n",
      "Epoch: 93 -> Loss: 0.0403681211174\n",
      "Epoch: 93 -> Test Accuracy: 88.98\n",
      "[94, 60] loss: 0.025\n",
      "[94, 120] loss: 0.025\n",
      "[94, 180] loss: 0.025\n",
      "[94, 240] loss: 0.025\n",
      "[94, 300] loss: 0.027\n",
      "[94, 360] loss: 0.023\n",
      "Epoch: 94 -> Loss: 0.0550551041961\n",
      "Epoch: 94 -> Test Accuracy: 89.03\n",
      "[95, 60] loss: 0.026\n",
      "[95, 120] loss: 0.026\n",
      "[95, 180] loss: 0.025\n",
      "[95, 240] loss: 0.027\n",
      "[95, 300] loss: 0.025\n",
      "[95, 360] loss: 0.026\n",
      "Epoch: 95 -> Loss: 0.0289799869061\n",
      "Epoch: 95 -> Test Accuracy: 89.11\n",
      "[96, 60] loss: 0.025\n",
      "[96, 120] loss: 0.025\n",
      "[96, 180] loss: 0.025\n",
      "[96, 240] loss: 0.026\n",
      "[96, 300] loss: 0.026\n",
      "[96, 360] loss: 0.025\n",
      "Epoch: 96 -> Loss: 0.00854846835136\n",
      "Epoch: 96 -> Test Accuracy: 88.99\n",
      "[97, 60] loss: 0.025\n",
      "[97, 120] loss: 0.024\n",
      "[97, 180] loss: 0.026\n",
      "[97, 240] loss: 0.025\n",
      "[97, 300] loss: 0.027\n",
      "[97, 360] loss: 0.027\n",
      "Epoch: 97 -> Loss: 0.029043186456\n",
      "Epoch: 97 -> Test Accuracy: 89.0\n",
      "[98, 60] loss: 0.023\n",
      "[98, 120] loss: 0.023\n",
      "[98, 180] loss: 0.027\n",
      "[98, 240] loss: 0.025\n",
      "[98, 300] loss: 0.027\n",
      "[98, 360] loss: 0.024\n",
      "Epoch: 98 -> Loss: 0.0209736879915\n",
      "Epoch: 98 -> Test Accuracy: 88.92\n",
      "[99, 60] loss: 0.024\n",
      "[99, 120] loss: 0.025\n",
      "[99, 180] loss: 0.024\n",
      "[99, 240] loss: 0.025\n",
      "[99, 300] loss: 0.025\n",
      "[99, 360] loss: 0.025\n",
      "Epoch: 99 -> Loss: 0.0154507160187\n",
      "Epoch: 99 -> Test Accuracy: 89.01\n",
      "[100, 60] loss: 0.023\n",
      "[100, 120] loss: 0.024\n",
      "[100, 180] loss: 0.026\n",
      "[100, 240] loss: 0.026\n",
      "[100, 300] loss: 0.026\n",
      "[100, 360] loss: 0.026\n",
      "Epoch: 100 -> Loss: 0.0170792341232\n",
      "Epoch: 100 -> Test Accuracy: 88.89\n",
      "Finished Training\n",
      "[1, 60] loss: 0.934\n",
      "[1, 120] loss: 0.704\n",
      "[1, 180] loss: 0.652\n",
      "[1, 240] loss: 0.624\n",
      "[1, 300] loss: 0.605\n",
      "[1, 360] loss: 0.582\n",
      "Epoch: 1 -> Loss: 0.639884710312\n",
      "Epoch: 1 -> Test Accuracy: 75.81\n",
      "[2, 60] loss: 0.575\n",
      "[2, 120] loss: 0.576\n",
      "[2, 180] loss: 0.553\n",
      "[2, 240] loss: 0.547\n",
      "[2, 300] loss: 0.530\n",
      "[2, 360] loss: 0.510\n",
      "Epoch: 2 -> Loss: 0.547850012779\n",
      "Epoch: 2 -> Test Accuracy: 78.83\n",
      "[3, 60] loss: 0.504\n",
      "[3, 120] loss: 0.522\n",
      "[3, 180] loss: 0.511\n",
      "[3, 240] loss: 0.519\n",
      "[3, 300] loss: 0.520\n",
      "[3, 360] loss: 0.521\n",
      "Epoch: 3 -> Loss: 0.515331089497\n",
      "Epoch: 3 -> Test Accuracy: 78.99\n",
      "[4, 60] loss: 0.489\n",
      "[4, 120] loss: 0.487\n",
      "[4, 180] loss: 0.482\n",
      "[4, 240] loss: 0.494\n",
      "[4, 300] loss: 0.498\n",
      "[4, 360] loss: 0.498\n",
      "Epoch: 4 -> Loss: 0.479008585215\n",
      "Epoch: 4 -> Test Accuracy: 79.99\n",
      "[5, 60] loss: 0.451\n",
      "[5, 120] loss: 0.478\n",
      "[5, 180] loss: 0.467\n",
      "[5, 240] loss: 0.474\n",
      "[5, 300] loss: 0.484\n",
      "[5, 360] loss: 0.486\n",
      "Epoch: 5 -> Loss: 0.528380572796\n",
      "Epoch: 5 -> Test Accuracy: 79.76\n",
      "[6, 60] loss: 0.453\n",
      "[6, 120] loss: 0.468\n",
      "[6, 180] loss: 0.466\n",
      "[6, 240] loss: 0.470\n",
      "[6, 300] loss: 0.480\n",
      "[6, 360] loss: 0.474\n",
      "Epoch: 6 -> Loss: 0.393694460392\n",
      "Epoch: 6 -> Test Accuracy: 79.59\n",
      "[7, 60] loss: 0.460\n",
      "[7, 120] loss: 0.454\n",
      "[7, 180] loss: 0.469\n",
      "[7, 240] loss: 0.484\n",
      "[7, 300] loss: 0.460\n",
      "[7, 360] loss: 0.465\n",
      "Epoch: 7 -> Loss: 0.478564083576\n",
      "Epoch: 7 -> Test Accuracy: 79.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 60] loss: 0.453\n",
      "[8, 120] loss: 0.448\n",
      "[8, 180] loss: 0.469\n",
      "[8, 240] loss: 0.462\n",
      "[8, 300] loss: 0.461\n",
      "[8, 360] loss: 0.450\n",
      "Epoch: 8 -> Loss: 0.502809643745\n",
      "Epoch: 8 -> Test Accuracy: 79.84\n",
      "[9, 60] loss: 0.439\n",
      "[9, 120] loss: 0.447\n",
      "[9, 180] loss: 0.437\n",
      "[9, 240] loss: 0.460\n",
      "[9, 300] loss: 0.454\n",
      "[9, 360] loss: 0.460\n",
      "Epoch: 9 -> Loss: 0.408176988363\n",
      "Epoch: 9 -> Test Accuracy: 80.25\n",
      "[10, 60] loss: 0.432\n",
      "[10, 120] loss: 0.435\n",
      "[10, 180] loss: 0.446\n",
      "[10, 240] loss: 0.442\n",
      "[10, 300] loss: 0.475\n",
      "[10, 360] loss: 0.443\n",
      "Epoch: 10 -> Loss: 0.401498496532\n",
      "Epoch: 10 -> Test Accuracy: 80.11\n",
      "[11, 60] loss: 0.438\n",
      "[11, 120] loss: 0.451\n",
      "[11, 180] loss: 0.452\n",
      "[11, 240] loss: 0.432\n",
      "[11, 300] loss: 0.460\n",
      "[11, 360] loss: 0.459\n",
      "Epoch: 11 -> Loss: 0.670123100281\n",
      "Epoch: 11 -> Test Accuracy: 80.14\n",
      "[12, 60] loss: 0.423\n",
      "[12, 120] loss: 0.442\n",
      "[12, 180] loss: 0.430\n",
      "[12, 240] loss: 0.447\n",
      "[12, 300] loss: 0.447\n",
      "[12, 360] loss: 0.460\n",
      "Epoch: 12 -> Loss: 0.37512165308\n",
      "Epoch: 12 -> Test Accuracy: 80.89\n",
      "[13, 60] loss: 0.434\n",
      "[13, 120] loss: 0.433\n",
      "[13, 180] loss: 0.436\n",
      "[13, 240] loss: 0.437\n",
      "[13, 300] loss: 0.443\n",
      "[13, 360] loss: 0.440\n",
      "Epoch: 13 -> Loss: 0.344830453396\n",
      "Epoch: 13 -> Test Accuracy: 81.45\n",
      "[14, 60] loss: 0.434\n",
      "[14, 120] loss: 0.443\n",
      "[14, 180] loss: 0.439\n",
      "[14, 240] loss: 0.428\n",
      "[14, 300] loss: 0.430\n",
      "[14, 360] loss: 0.443\n",
      "Epoch: 14 -> Loss: 0.444436073303\n",
      "Epoch: 14 -> Test Accuracy: 80.58\n",
      "[15, 60] loss: 0.416\n",
      "[15, 120] loss: 0.441\n",
      "[15, 180] loss: 0.436\n",
      "[15, 240] loss: 0.443\n",
      "[15, 300] loss: 0.452\n",
      "[15, 360] loss: 0.426\n",
      "Epoch: 15 -> Loss: 0.600211024284\n",
      "Epoch: 15 -> Test Accuracy: 80.45\n",
      "[16, 60] loss: 0.418\n",
      "[16, 120] loss: 0.427\n",
      "[16, 180] loss: 0.421\n",
      "[16, 240] loss: 0.437\n",
      "[16, 300] loss: 0.448\n",
      "[16, 360] loss: 0.445\n",
      "Epoch: 16 -> Loss: 0.424493163824\n",
      "Epoch: 16 -> Test Accuracy: 80.8\n",
      "[17, 60] loss: 0.406\n",
      "[17, 120] loss: 0.435\n",
      "[17, 180] loss: 0.426\n",
      "[17, 240] loss: 0.424\n",
      "[17, 300] loss: 0.434\n",
      "[17, 360] loss: 0.451\n",
      "Epoch: 17 -> Loss: 0.319312781096\n",
      "Epoch: 17 -> Test Accuracy: 80.63\n",
      "[18, 60] loss: 0.411\n",
      "[18, 120] loss: 0.423\n",
      "[18, 180] loss: 0.417\n",
      "[18, 240] loss: 0.430\n",
      "[18, 300] loss: 0.436\n",
      "[18, 360] loss: 0.436\n",
      "Epoch: 18 -> Loss: 0.437712430954\n",
      "Epoch: 18 -> Test Accuracy: 81.14\n",
      "[19, 60] loss: 0.423\n",
      "[19, 120] loss: 0.432\n",
      "[19, 180] loss: 0.435\n",
      "[19, 240] loss: 0.442\n",
      "[19, 300] loss: 0.434\n",
      "[19, 360] loss: 0.427\n",
      "Epoch: 19 -> Loss: 0.553340196609\n",
      "Epoch: 19 -> Test Accuracy: 80.91\n",
      "[20, 60] loss: 0.414\n",
      "[20, 120] loss: 0.418\n",
      "[20, 180] loss: 0.418\n",
      "[20, 240] loss: 0.442\n",
      "[20, 300] loss: 0.439\n",
      "[20, 360] loss: 0.427\n",
      "Epoch: 20 -> Loss: 0.434405982494\n",
      "Epoch: 20 -> Test Accuracy: 81.78\n",
      "[21, 60] loss: 0.411\n",
      "[21, 120] loss: 0.419\n",
      "[21, 180] loss: 0.425\n",
      "[21, 240] loss: 0.433\n",
      "[21, 300] loss: 0.434\n",
      "[21, 360] loss: 0.435\n",
      "Epoch: 21 -> Loss: 0.445220053196\n",
      "Epoch: 21 -> Test Accuracy: 81.58\n",
      "[22, 60] loss: 0.443\n",
      "[22, 120] loss: 0.417\n",
      "[22, 180] loss: 0.427\n",
      "[22, 240] loss: 0.414\n",
      "[22, 300] loss: 0.427\n",
      "[22, 360] loss: 0.427\n",
      "Epoch: 22 -> Loss: 0.238223791122\n",
      "Epoch: 22 -> Test Accuracy: 80.52\n",
      "[23, 60] loss: 0.419\n",
      "[23, 120] loss: 0.428\n",
      "[23, 180] loss: 0.426\n",
      "[23, 240] loss: 0.417\n",
      "[23, 300] loss: 0.440\n",
      "[23, 360] loss: 0.418\n",
      "Epoch: 23 -> Loss: 0.23487444222\n",
      "Epoch: 23 -> Test Accuracy: 80.28\n",
      "[24, 60] loss: 0.405\n",
      "[24, 120] loss: 0.416\n",
      "[24, 180] loss: 0.427\n",
      "[24, 240] loss: 0.432\n",
      "[24, 300] loss: 0.428\n",
      "[24, 360] loss: 0.420\n",
      "Epoch: 24 -> Loss: 0.603229820728\n",
      "Epoch: 24 -> Test Accuracy: 80.44\n",
      "[25, 60] loss: 0.401\n",
      "[25, 120] loss: 0.409\n",
      "[25, 180] loss: 0.416\n",
      "[25, 240] loss: 0.445\n",
      "[25, 300] loss: 0.435\n",
      "[25, 360] loss: 0.412\n",
      "Epoch: 25 -> Loss: 0.380954802036\n",
      "Epoch: 25 -> Test Accuracy: 80.91\n",
      "[26, 60] loss: 0.393\n",
      "[26, 120] loss: 0.423\n",
      "[26, 180] loss: 0.420\n",
      "[26, 240] loss: 0.415\n",
      "[26, 300] loss: 0.421\n",
      "[26, 360] loss: 0.433\n",
      "Epoch: 26 -> Loss: 0.405666649342\n",
      "Epoch: 26 -> Test Accuracy: 80.61\n",
      "[27, 60] loss: 0.397\n",
      "[27, 120] loss: 0.419\n",
      "[27, 180] loss: 0.412\n",
      "[27, 240] loss: 0.407\n",
      "[27, 300] loss: 0.414\n",
      "[27, 360] loss: 0.427\n",
      "Epoch: 27 -> Loss: 0.386996209621\n",
      "Epoch: 27 -> Test Accuracy: 80.47\n",
      "[28, 60] loss: 0.413\n",
      "[28, 120] loss: 0.421\n",
      "[28, 180] loss: 0.400\n",
      "[28, 240] loss: 0.420\n",
      "[28, 300] loss: 0.407\n",
      "[28, 360] loss: 0.435\n",
      "Epoch: 28 -> Loss: 0.416726648808\n",
      "Epoch: 28 -> Test Accuracy: 80.45\n",
      "[29, 60] loss: 0.387\n",
      "[29, 120] loss: 0.430\n",
      "[29, 180] loss: 0.416\n",
      "[29, 240] loss: 0.422\n",
      "[29, 300] loss: 0.414\n",
      "[29, 360] loss: 0.412\n",
      "Epoch: 29 -> Loss: 0.564592003822\n",
      "Epoch: 29 -> Test Accuracy: 79.27\n",
      "[30, 60] loss: 0.418\n",
      "[30, 120] loss: 0.421\n",
      "[30, 180] loss: 0.426\n",
      "[30, 240] loss: 0.417\n",
      "[30, 300] loss: 0.426\n",
      "[30, 360] loss: 0.419\n",
      "Epoch: 30 -> Loss: 0.496313393116\n",
      "Epoch: 30 -> Test Accuracy: 80.79\n",
      "[31, 60] loss: 0.400\n",
      "[31, 120] loss: 0.407\n",
      "[31, 180] loss: 0.436\n",
      "[31, 240] loss: 0.434\n",
      "[31, 300] loss: 0.423\n",
      "[31, 360] loss: 0.415\n",
      "Epoch: 31 -> Loss: 0.436560809612\n",
      "Epoch: 31 -> Test Accuracy: 80.84\n",
      "[32, 60] loss: 0.397\n",
      "[32, 120] loss: 0.425\n",
      "[32, 180] loss: 0.406\n",
      "[32, 240] loss: 0.412\n",
      "[32, 300] loss: 0.422\n",
      "[32, 360] loss: 0.438\n",
      "Epoch: 32 -> Loss: 0.650264918804\n",
      "Epoch: 32 -> Test Accuracy: 80.88\n",
      "[33, 60] loss: 0.405\n",
      "[33, 120] loss: 0.395\n",
      "[33, 180] loss: 0.430\n",
      "[33, 240] loss: 0.409\n",
      "[33, 300] loss: 0.426\n",
      "[33, 360] loss: 0.422\n",
      "Epoch: 33 -> Loss: 0.380748927593\n",
      "Epoch: 33 -> Test Accuracy: 80.42\n",
      "[34, 60] loss: 0.407\n",
      "[34, 120] loss: 0.392\n",
      "[34, 180] loss: 0.420\n",
      "[34, 240] loss: 0.412\n",
      "[34, 300] loss: 0.437\n",
      "[34, 360] loss: 0.419\n",
      "Epoch: 34 -> Loss: 0.520315527916\n",
      "Epoch: 34 -> Test Accuracy: 81.03\n",
      "[35, 60] loss: 0.402\n",
      "[35, 120] loss: 0.406\n",
      "[35, 180] loss: 0.420\n",
      "[35, 240] loss: 0.417\n",
      "[35, 300] loss: 0.423\n",
      "[35, 360] loss: 0.426\n",
      "Epoch: 35 -> Loss: 0.365457624197\n",
      "Epoch: 35 -> Test Accuracy: 81.68\n",
      "[36, 60] loss: 0.360\n",
      "[36, 120] loss: 0.366\n",
      "[36, 180] loss: 0.342\n",
      "[36, 240] loss: 0.318\n",
      "[36, 300] loss: 0.327\n",
      "[36, 360] loss: 0.336\n",
      "Epoch: 36 -> Loss: 0.382669985294\n",
      "Epoch: 36 -> Test Accuracy: 83.74\n",
      "[37, 60] loss: 0.316\n",
      "[37, 120] loss: 0.320\n",
      "[37, 180] loss: 0.318\n",
      "[37, 240] loss: 0.307\n",
      "[37, 300] loss: 0.310\n",
      "[37, 360] loss: 0.312\n",
      "Epoch: 37 -> Loss: 0.202742666006\n",
      "Epoch: 37 -> Test Accuracy: 84.15\n",
      "[38, 60] loss: 0.304\n",
      "[38, 120] loss: 0.295\n",
      "[38, 180] loss: 0.292\n",
      "[38, 240] loss: 0.313\n",
      "[38, 300] loss: 0.313\n",
      "[38, 360] loss: 0.305\n",
      "Epoch: 38 -> Loss: 0.301402807236\n",
      "Epoch: 38 -> Test Accuracy: 83.91\n",
      "[39, 60] loss: 0.293\n",
      "[39, 120] loss: 0.289\n",
      "[39, 180] loss: 0.283\n",
      "[39, 240] loss: 0.309\n",
      "[39, 300] loss: 0.299\n",
      "[39, 360] loss: 0.298\n",
      "Epoch: 39 -> Loss: 0.317778229713\n",
      "Epoch: 39 -> Test Accuracy: 83.49\n",
      "[40, 60] loss: 0.287\n",
      "[40, 120] loss: 0.285\n",
      "[40, 180] loss: 0.301\n",
      "[40, 240] loss: 0.299\n",
      "[40, 300] loss: 0.288\n",
      "[40, 360] loss: 0.296\n",
      "Epoch: 40 -> Loss: 0.350103229284\n",
      "Epoch: 40 -> Test Accuracy: 84.01\n",
      "[41, 60] loss: 0.301\n",
      "[41, 120] loss: 0.293\n",
      "[41, 180] loss: 0.282\n",
      "[41, 240] loss: 0.285\n",
      "[41, 300] loss: 0.288\n",
      "[41, 360] loss: 0.289\n",
      "Epoch: 41 -> Loss: 0.282455295324\n",
      "Epoch: 41 -> Test Accuracy: 84.16\n",
      "[42, 60] loss: 0.268\n",
      "[42, 120] loss: 0.281\n",
      "[42, 180] loss: 0.273\n",
      "[42, 240] loss: 0.299\n",
      "[42, 300] loss: 0.287\n",
      "[42, 360] loss: 0.283\n",
      "Epoch: 42 -> Loss: 0.268324434757\n",
      "Epoch: 42 -> Test Accuracy: 83.56\n",
      "[43, 60] loss: 0.282\n",
      "[43, 120] loss: 0.286\n",
      "[43, 180] loss: 0.282\n",
      "[43, 240] loss: 0.291\n",
      "[43, 300] loss: 0.297\n",
      "[43, 360] loss: 0.291\n",
      "Epoch: 43 -> Loss: 0.37554949522\n",
      "Epoch: 43 -> Test Accuracy: 83.72\n",
      "[44, 60] loss: 0.264\n",
      "[44, 120] loss: 0.293\n",
      "[44, 180] loss: 0.295\n",
      "[44, 240] loss: 0.283\n",
      "[44, 300] loss: 0.287\n",
      "[44, 360] loss: 0.287\n",
      "Epoch: 44 -> Loss: 0.40296626091\n",
      "Epoch: 44 -> Test Accuracy: 83.39\n",
      "[45, 60] loss: 0.271\n",
      "[45, 120] loss: 0.270\n",
      "[45, 180] loss: 0.280\n",
      "[45, 240] loss: 0.291\n",
      "[45, 300] loss: 0.290\n",
      "[45, 360] loss: 0.287\n",
      "Epoch: 45 -> Loss: 0.41532382369\n",
      "Epoch: 45 -> Test Accuracy: 83.4\n",
      "[46, 60] loss: 0.269\n",
      "[46, 120] loss: 0.269\n",
      "[46, 180] loss: 0.278\n",
      "[46, 240] loss: 0.297\n",
      "[46, 300] loss: 0.296\n",
      "[46, 360] loss: 0.274\n",
      "Epoch: 46 -> Loss: 0.26539760828\n",
      "Epoch: 46 -> Test Accuracy: 83.04\n",
      "[47, 60] loss: 0.290\n",
      "[47, 120] loss: 0.282\n",
      "[47, 180] loss: 0.271\n",
      "[47, 240] loss: 0.271\n",
      "[47, 300] loss: 0.282\n",
      "[47, 360] loss: 0.276\n",
      "Epoch: 47 -> Loss: 0.266316503286\n",
      "Epoch: 47 -> Test Accuracy: 83.37\n",
      "[48, 60] loss: 0.268\n",
      "[48, 120] loss: 0.283\n",
      "[48, 180] loss: 0.273\n",
      "[48, 240] loss: 0.285\n",
      "[48, 300] loss: 0.290\n",
      "[48, 360] loss: 0.295\n",
      "Epoch: 48 -> Loss: 0.401303052902\n",
      "Epoch: 48 -> Test Accuracy: 82.97\n",
      "[49, 60] loss: 0.279\n",
      "[49, 120] loss: 0.277\n",
      "[49, 180] loss: 0.285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 240] loss: 0.275\n",
      "[49, 300] loss: 0.277\n",
      "[49, 360] loss: 0.278\n",
      "Epoch: 49 -> Loss: 0.392577946186\n",
      "Epoch: 49 -> Test Accuracy: 82.81\n",
      "[50, 60] loss: 0.272\n",
      "[50, 120] loss: 0.266\n",
      "[50, 180] loss: 0.273\n",
      "[50, 240] loss: 0.280\n",
      "[50, 300] loss: 0.277\n",
      "[50, 360] loss: 0.299\n",
      "Epoch: 50 -> Loss: 0.353411406279\n",
      "Epoch: 50 -> Test Accuracy: 83.17\n",
      "[51, 60] loss: 0.269\n",
      "[51, 120] loss: 0.263\n",
      "[51, 180] loss: 0.274\n",
      "[51, 240] loss: 0.280\n",
      "[51, 300] loss: 0.285\n",
      "[51, 360] loss: 0.269\n",
      "Epoch: 51 -> Loss: 0.214863657951\n",
      "Epoch: 51 -> Test Accuracy: 83.31\n",
      "[52, 60] loss: 0.255\n",
      "[52, 120] loss: 0.265\n",
      "[52, 180] loss: 0.279\n",
      "[52, 240] loss: 0.296\n",
      "[52, 300] loss: 0.289\n",
      "[52, 360] loss: 0.279\n",
      "Epoch: 52 -> Loss: 0.4449172616\n",
      "Epoch: 52 -> Test Accuracy: 82.86\n",
      "[53, 60] loss: 0.253\n",
      "[53, 120] loss: 0.274\n",
      "[53, 180] loss: 0.276\n",
      "[53, 240] loss: 0.278\n",
      "[53, 300] loss: 0.278\n",
      "[53, 360] loss: 0.292\n",
      "Epoch: 53 -> Loss: 0.380030691624\n",
      "Epoch: 53 -> Test Accuracy: 83.08\n",
      "[54, 60] loss: 0.264\n",
      "[54, 120] loss: 0.263\n",
      "[54, 180] loss: 0.284\n",
      "[54, 240] loss: 0.273\n",
      "[54, 300] loss: 0.287\n",
      "[54, 360] loss: 0.285\n",
      "Epoch: 54 -> Loss: 0.369022071362\n",
      "Epoch: 54 -> Test Accuracy: 82.72\n",
      "[55, 60] loss: 0.277\n",
      "[55, 120] loss: 0.268\n",
      "[55, 180] loss: 0.263\n",
      "[55, 240] loss: 0.281\n",
      "[55, 300] loss: 0.278\n",
      "[55, 360] loss: 0.271\n",
      "Epoch: 55 -> Loss: 0.305944293737\n",
      "Epoch: 55 -> Test Accuracy: 82.97\n",
      "[56, 60] loss: 0.240\n",
      "[56, 120] loss: 0.268\n",
      "[56, 180] loss: 0.266\n",
      "[56, 240] loss: 0.269\n",
      "[56, 300] loss: 0.284\n",
      "[56, 360] loss: 0.290\n",
      "Epoch: 56 -> Loss: 0.21729286015\n",
      "Epoch: 56 -> Test Accuracy: 82.89\n",
      "[57, 60] loss: 0.277\n",
      "[57, 120] loss: 0.263\n",
      "[57, 180] loss: 0.266\n",
      "[57, 240] loss: 0.267\n",
      "[57, 300] loss: 0.275\n",
      "[57, 360] loss: 0.274\n",
      "Epoch: 57 -> Loss: 0.233299925923\n",
      "Epoch: 57 -> Test Accuracy: 82.83\n",
      "[58, 60] loss: 0.262\n",
      "[58, 120] loss: 0.268\n",
      "[58, 180] loss: 0.274\n",
      "[58, 240] loss: 0.268\n",
      "[58, 300] loss: 0.264\n",
      "[58, 360] loss: 0.291\n",
      "Epoch: 58 -> Loss: 0.225833341479\n",
      "Epoch: 58 -> Test Accuracy: 83.53\n",
      "[59, 60] loss: 0.258\n",
      "[59, 120] loss: 0.276\n",
      "[59, 180] loss: 0.268\n",
      "[59, 240] loss: 0.258\n",
      "[59, 300] loss: 0.271\n",
      "[59, 360] loss: 0.282\n",
      "Epoch: 59 -> Loss: 0.118125602603\n",
      "Epoch: 59 -> Test Accuracy: 82.58\n",
      "[60, 60] loss: 0.250\n",
      "[60, 120] loss: 0.256\n",
      "[60, 180] loss: 0.259\n",
      "[60, 240] loss: 0.264\n",
      "[60, 300] loss: 0.284\n",
      "[60, 360] loss: 0.293\n",
      "Epoch: 60 -> Loss: 0.310302942991\n",
      "Epoch: 60 -> Test Accuracy: 83.29\n",
      "[61, 60] loss: 0.271\n",
      "[61, 120] loss: 0.256\n",
      "[61, 180] loss: 0.266\n",
      "[61, 240] loss: 0.264\n",
      "[61, 300] loss: 0.286\n",
      "[61, 360] loss: 0.281\n",
      "Epoch: 61 -> Loss: 0.189207240939\n",
      "Epoch: 61 -> Test Accuracy: 82.83\n",
      "[62, 60] loss: 0.263\n",
      "[62, 120] loss: 0.262\n",
      "[62, 180] loss: 0.265\n",
      "[62, 240] loss: 0.271\n",
      "[62, 300] loss: 0.262\n",
      "[62, 360] loss: 0.286\n",
      "Epoch: 62 -> Loss: 0.208173707128\n",
      "Epoch: 62 -> Test Accuracy: 82.89\n",
      "[63, 60] loss: 0.259\n",
      "[63, 120] loss: 0.262\n",
      "[63, 180] loss: 0.262\n",
      "[63, 240] loss: 0.271\n",
      "[63, 300] loss: 0.266\n",
      "[63, 360] loss: 0.275\n",
      "Epoch: 63 -> Loss: 0.337559938431\n",
      "Epoch: 63 -> Test Accuracy: 82.97\n",
      "[64, 60] loss: 0.262\n",
      "[64, 120] loss: 0.271\n",
      "[64, 180] loss: 0.266\n",
      "[64, 240] loss: 0.269\n",
      "[64, 300] loss: 0.264\n",
      "[64, 360] loss: 0.270\n",
      "Epoch: 64 -> Loss: 0.260224819183\n",
      "Epoch: 64 -> Test Accuracy: 82.9\n",
      "[65, 60] loss: 0.259\n",
      "[65, 120] loss: 0.254\n",
      "[65, 180] loss: 0.252\n",
      "[65, 240] loss: 0.273\n",
      "[65, 300] loss: 0.290\n",
      "[65, 360] loss: 0.273\n",
      "Epoch: 65 -> Loss: 0.368686288595\n",
      "Epoch: 65 -> Test Accuracy: 82.64\n",
      "[66, 60] loss: 0.257\n",
      "[66, 120] loss: 0.258\n",
      "[66, 180] loss: 0.264\n",
      "[66, 240] loss: 0.261\n",
      "[66, 300] loss: 0.280\n",
      "[66, 360] loss: 0.269\n",
      "Epoch: 66 -> Loss: 0.265360981226\n",
      "Epoch: 66 -> Test Accuracy: 82.89\n",
      "[67, 60] loss: 0.252\n",
      "[67, 120] loss: 0.260\n",
      "[67, 180] loss: 0.273\n",
      "[67, 240] loss: 0.277\n",
      "[67, 300] loss: 0.274\n",
      "[67, 360] loss: 0.274\n",
      "Epoch: 67 -> Loss: 0.297508090734\n",
      "Epoch: 67 -> Test Accuracy: 82.91\n",
      "[68, 60] loss: 0.239\n",
      "[68, 120] loss: 0.252\n",
      "[68, 180] loss: 0.261\n",
      "[68, 240] loss: 0.276\n",
      "[68, 300] loss: 0.272\n",
      "[68, 360] loss: 0.264\n",
      "Epoch: 68 -> Loss: 0.38144955039\n",
      "Epoch: 68 -> Test Accuracy: 82.95\n",
      "[69, 60] loss: 0.253\n",
      "[69, 120] loss: 0.243\n",
      "[69, 180] loss: 0.251\n",
      "[69, 240] loss: 0.267\n",
      "[69, 300] loss: 0.279\n",
      "[69, 360] loss: 0.270\n",
      "Epoch: 69 -> Loss: 0.366516828537\n",
      "Epoch: 69 -> Test Accuracy: 83.3\n",
      "[70, 60] loss: 0.261\n",
      "[70, 120] loss: 0.242\n",
      "[70, 180] loss: 0.271\n",
      "[70, 240] loss: 0.268\n",
      "[70, 300] loss: 0.257\n",
      "[70, 360] loss: 0.260\n",
      "Epoch: 70 -> Loss: 0.175772994757\n",
      "Epoch: 70 -> Test Accuracy: 83.06\n",
      "[71, 60] loss: 0.219\n",
      "[71, 120] loss: 0.220\n",
      "[71, 180] loss: 0.206\n",
      "[71, 240] loss: 0.205\n",
      "[71, 300] loss: 0.211\n",
      "[71, 360] loss: 0.202\n",
      "Epoch: 71 -> Loss: 0.118918910623\n",
      "Epoch: 71 -> Test Accuracy: 84.84\n",
      "[72, 60] loss: 0.193\n",
      "[72, 120] loss: 0.186\n",
      "[72, 180] loss: 0.190\n",
      "[72, 240] loss: 0.199\n",
      "[72, 300] loss: 0.180\n",
      "[72, 360] loss: 0.192\n",
      "Epoch: 72 -> Loss: 0.176102370024\n",
      "Epoch: 72 -> Test Accuracy: 84.85\n",
      "[73, 60] loss: 0.191\n",
      "[73, 120] loss: 0.178\n",
      "[73, 180] loss: 0.181\n",
      "[73, 240] loss: 0.184\n",
      "[73, 300] loss: 0.183\n",
      "[73, 360] loss: 0.189\n",
      "Epoch: 73 -> Loss: 0.109717868268\n",
      "Epoch: 73 -> Test Accuracy: 84.74\n",
      "[74, 60] loss: 0.178\n",
      "[74, 120] loss: 0.172\n",
      "[74, 180] loss: 0.178\n",
      "[74, 240] loss: 0.181\n",
      "[74, 300] loss: 0.178\n",
      "[74, 360] loss: 0.190\n",
      "Epoch: 74 -> Loss: 0.115622542799\n",
      "Epoch: 74 -> Test Accuracy: 84.7\n",
      "[75, 60] loss: 0.166\n",
      "[75, 120] loss: 0.179\n",
      "[75, 180] loss: 0.178\n",
      "[75, 240] loss: 0.171\n",
      "[75, 300] loss: 0.185\n",
      "[75, 360] loss: 0.176\n",
      "Epoch: 75 -> Loss: 0.155191987753\n",
      "Epoch: 75 -> Test Accuracy: 84.46\n",
      "[76, 60] loss: 0.156\n",
      "[76, 120] loss: 0.173\n",
      "[76, 180] loss: 0.183\n",
      "[76, 240] loss: 0.178\n",
      "[76, 300] loss: 0.174\n",
      "[76, 360] loss: 0.168\n",
      "Epoch: 76 -> Loss: 0.184469655156\n",
      "Epoch: 76 -> Test Accuracy: 84.38\n",
      "[77, 60] loss: 0.159\n",
      "[77, 120] loss: 0.170\n",
      "[77, 180] loss: 0.175\n",
      "[77, 240] loss: 0.164\n",
      "[77, 300] loss: 0.169\n",
      "[77, 360] loss: 0.177\n",
      "Epoch: 77 -> Loss: 0.155790299177\n",
      "Epoch: 77 -> Test Accuracy: 84.8\n",
      "[78, 60] loss: 0.168\n",
      "[78, 120] loss: 0.173\n",
      "[78, 180] loss: 0.165\n",
      "[78, 240] loss: 0.163\n",
      "[78, 300] loss: 0.174\n",
      "[78, 360] loss: 0.174\n",
      "Epoch: 78 -> Loss: 0.2357750386\n",
      "Epoch: 78 -> Test Accuracy: 84.43\n",
      "[79, 60] loss: 0.161\n",
      "[79, 120] loss: 0.150\n",
      "[79, 180] loss: 0.162\n",
      "[79, 240] loss: 0.173\n",
      "[79, 300] loss: 0.166\n",
      "[79, 360] loss: 0.175\n",
      "Epoch: 79 -> Loss: 0.193073183298\n",
      "Epoch: 79 -> Test Accuracy: 84.62\n",
      "[80, 60] loss: 0.154\n",
      "[80, 120] loss: 0.151\n",
      "[80, 180] loss: 0.165\n",
      "[80, 240] loss: 0.166\n",
      "[80, 300] loss: 0.158\n",
      "[80, 360] loss: 0.166\n",
      "Epoch: 80 -> Loss: 0.244321629405\n",
      "Epoch: 80 -> Test Accuracy: 84.2\n",
      "[81, 60] loss: 0.158\n",
      "[81, 120] loss: 0.154\n",
      "[81, 180] loss: 0.155\n",
      "[81, 240] loss: 0.153\n",
      "[81, 300] loss: 0.161\n",
      "[81, 360] loss: 0.170\n",
      "Epoch: 81 -> Loss: 0.238705068827\n",
      "Epoch: 81 -> Test Accuracy: 84.04\n",
      "[82, 60] loss: 0.154\n",
      "[82, 120] loss: 0.160\n",
      "[82, 180] loss: 0.159\n",
      "[82, 240] loss: 0.167\n",
      "[82, 300] loss: 0.162\n",
      "[82, 360] loss: 0.159\n",
      "Epoch: 82 -> Loss: 0.169666498899\n",
      "Epoch: 82 -> Test Accuracy: 84.24\n",
      "[83, 60] loss: 0.152\n",
      "[83, 120] loss: 0.158\n",
      "[83, 180] loss: 0.162\n",
      "[83, 240] loss: 0.158\n",
      "[83, 300] loss: 0.161\n",
      "[83, 360] loss: 0.161\n",
      "Epoch: 83 -> Loss: 0.30144071579\n",
      "Epoch: 83 -> Test Accuracy: 84.48\n",
      "[84, 60] loss: 0.149\n",
      "[84, 120] loss: 0.154\n",
      "[84, 180] loss: 0.153\n",
      "[84, 240] loss: 0.149\n",
      "[84, 300] loss: 0.160\n",
      "[84, 360] loss: 0.160\n",
      "Epoch: 84 -> Loss: 0.126848950982\n",
      "Epoch: 84 -> Test Accuracy: 84.36\n",
      "[85, 60] loss: 0.148\n",
      "[85, 120] loss: 0.153\n",
      "[85, 180] loss: 0.150\n",
      "[85, 240] loss: 0.161\n",
      "[85, 300] loss: 0.154\n",
      "[85, 360] loss: 0.152\n",
      "Epoch: 85 -> Loss: 0.147516280413\n",
      "Epoch: 85 -> Test Accuracy: 84.26\n",
      "[86, 60] loss: 0.147\n",
      "[86, 120] loss: 0.142\n",
      "[86, 180] loss: 0.128\n",
      "[86, 240] loss: 0.143\n",
      "[86, 300] loss: 0.133\n",
      "[86, 360] loss: 0.145\n",
      "Epoch: 86 -> Loss: 0.0681399554014\n",
      "Epoch: 86 -> Test Accuracy: 84.67\n",
      "[87, 60] loss: 0.143\n",
      "[87, 120] loss: 0.139\n",
      "[87, 180] loss: 0.130\n",
      "[87, 240] loss: 0.135\n",
      "[87, 300] loss: 0.131\n",
      "[87, 360] loss: 0.138\n",
      "Epoch: 87 -> Loss: 0.128202885389\n",
      "Epoch: 87 -> Test Accuracy: 84.65\n",
      "[88, 60] loss: 0.141\n",
      "[88, 120] loss: 0.130\n",
      "[88, 180] loss: 0.137\n",
      "[88, 240] loss: 0.133\n",
      "[88, 300] loss: 0.135\n",
      "[88, 360] loss: 0.137\n",
      "Epoch: 88 -> Loss: 0.248545214534\n",
      "Epoch: 88 -> Test Accuracy: 84.55\n",
      "[89, 60] loss: 0.132\n",
      "[89, 120] loss: 0.132\n",
      "[89, 180] loss: 0.133\n",
      "[89, 240] loss: 0.140\n",
      "[89, 300] loss: 0.127\n",
      "[89, 360] loss: 0.145\n",
      "Epoch: 89 -> Loss: 0.182018786669\n",
      "Epoch: 89 -> Test Accuracy: 84.55\n",
      "[90, 60] loss: 0.128\n",
      "[90, 120] loss: 0.135\n",
      "[90, 180] loss: 0.132\n",
      "[90, 240] loss: 0.130\n",
      "[90, 300] loss: 0.132\n",
      "[90, 360] loss: 0.132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 -> Loss: 0.153813287616\n",
      "Epoch: 90 -> Test Accuracy: 84.58\n",
      "[91, 60] loss: 0.134\n",
      "[91, 120] loss: 0.133\n",
      "[91, 180] loss: 0.134\n",
      "[91, 240] loss: 0.128\n",
      "[91, 300] loss: 0.135\n",
      "[91, 360] loss: 0.131\n",
      "Epoch: 91 -> Loss: 0.113681219518\n",
      "Epoch: 91 -> Test Accuracy: 84.67\n",
      "[92, 60] loss: 0.132\n",
      "[92, 120] loss: 0.133\n",
      "[92, 180] loss: 0.137\n",
      "[92, 240] loss: 0.128\n",
      "[92, 300] loss: 0.132\n",
      "[92, 360] loss: 0.133\n",
      "Epoch: 92 -> Loss: 0.144803076982\n",
      "Epoch: 92 -> Test Accuracy: 84.58\n",
      "[93, 60] loss: 0.131\n",
      "[93, 120] loss: 0.137\n",
      "[93, 180] loss: 0.128\n",
      "[93, 240] loss: 0.127\n",
      "[93, 300] loss: 0.124\n",
      "[93, 360] loss: 0.138\n",
      "Epoch: 93 -> Loss: 0.118097901344\n",
      "Epoch: 93 -> Test Accuracy: 84.35\n",
      "[94, 60] loss: 0.141\n",
      "[94, 120] loss: 0.130\n",
      "[94, 180] loss: 0.128\n",
      "[94, 240] loss: 0.130\n",
      "[94, 300] loss: 0.132\n",
      "[94, 360] loss: 0.127\n",
      "Epoch: 94 -> Loss: 0.111318983138\n",
      "Epoch: 94 -> Test Accuracy: 84.51\n",
      "[95, 60] loss: 0.123\n",
      "[95, 120] loss: 0.125\n",
      "[95, 180] loss: 0.134\n",
      "[95, 240] loss: 0.127\n",
      "[95, 300] loss: 0.133\n",
      "[95, 360] loss: 0.128\n",
      "Epoch: 95 -> Loss: 0.165491446853\n",
      "Epoch: 95 -> Test Accuracy: 84.48\n",
      "[96, 60] loss: 0.127\n",
      "[96, 120] loss: 0.128\n",
      "[96, 180] loss: 0.124\n",
      "[96, 240] loss: 0.130\n",
      "[96, 300] loss: 0.130\n",
      "[96, 360] loss: 0.132\n",
      "Epoch: 96 -> Loss: 0.120253182948\n",
      "Epoch: 96 -> Test Accuracy: 84.54\n",
      "[97, 60] loss: 0.128\n",
      "[97, 120] loss: 0.127\n",
      "[97, 180] loss: 0.120\n",
      "[97, 240] loss: 0.130\n",
      "[97, 300] loss: 0.132\n",
      "[97, 360] loss: 0.140\n",
      "Epoch: 97 -> Loss: 0.179470866919\n",
      "Epoch: 97 -> Test Accuracy: 84.5\n",
      "[98, 60] loss: 0.123\n",
      "[98, 120] loss: 0.121\n",
      "[98, 180] loss: 0.133\n",
      "[98, 240] loss: 0.126\n",
      "[98, 300] loss: 0.135\n",
      "[98, 360] loss: 0.121\n",
      "Epoch: 98 -> Loss: 0.20677497983\n",
      "Epoch: 98 -> Test Accuracy: 84.53\n",
      "[99, 60] loss: 0.126\n",
      "[99, 120] loss: 0.132\n",
      "[99, 180] loss: 0.124\n",
      "[99, 240] loss: 0.119\n",
      "[99, 300] loss: 0.123\n",
      "[99, 360] loss: 0.123\n",
      "Epoch: 99 -> Loss: 0.163127809763\n",
      "Epoch: 99 -> Test Accuracy: 84.68\n",
      "[100, 60] loss: 0.124\n",
      "[100, 120] loss: 0.123\n",
      "[100, 180] loss: 0.132\n",
      "[100, 240] loss: 0.129\n",
      "[100, 300] loss: 0.123\n",
      "[100, 360] loss: 0.129\n",
      "Epoch: 100 -> Loss: 0.155678972602\n",
      "Epoch: 100 -> Test Accuracy: 84.6\n",
      "Finished Training\n",
      "[1, 60] loss: 2.043\n",
      "[1, 120] loss: 1.892\n",
      "[1, 180] loss: 1.868\n",
      "[1, 240] loss: 1.811\n",
      "[1, 300] loss: 1.791\n",
      "[1, 360] loss: 1.790\n",
      "Epoch: 1 -> Loss: 1.8477909565\n",
      "Epoch: 1 -> Test Accuracy: 34.21\n",
      "[2, 60] loss: 1.752\n",
      "[2, 120] loss: 1.738\n",
      "[2, 180] loss: 1.723\n",
      "[2, 240] loss: 1.729\n",
      "[2, 300] loss: 1.688\n",
      "[2, 360] loss: 1.704\n",
      "Epoch: 2 -> Loss: 1.71715509892\n",
      "Epoch: 2 -> Test Accuracy: 36.0\n",
      "[3, 60] loss: 1.674\n",
      "[3, 120] loss: 1.692\n",
      "[3, 180] loss: 1.667\n",
      "[3, 240] loss: 1.656\n",
      "[3, 300] loss: 1.673\n",
      "[3, 360] loss: 1.643\n",
      "Epoch: 3 -> Loss: 1.71874904633\n",
      "Epoch: 3 -> Test Accuracy: 35.94\n",
      "[4, 60] loss: 1.636\n",
      "[4, 120] loss: 1.650\n",
      "[4, 180] loss: 1.643\n",
      "[4, 240] loss: 1.630\n",
      "[4, 300] loss: 1.620\n",
      "[4, 360] loss: 1.631\n",
      "Epoch: 4 -> Loss: 1.54903864861\n",
      "Epoch: 4 -> Test Accuracy: 38.01\n",
      "[5, 60] loss: 1.641\n",
      "[5, 120] loss: 1.615\n",
      "[5, 180] loss: 1.636\n",
      "[5, 240] loss: 1.625\n",
      "[5, 300] loss: 1.591\n",
      "[5, 360] loss: 1.617\n",
      "Epoch: 5 -> Loss: 1.67080271244\n",
      "Epoch: 5 -> Test Accuracy: 37.82\n",
      "[6, 60] loss: 1.603\n",
      "[6, 120] loss: 1.595\n",
      "[6, 180] loss: 1.582\n",
      "[6, 240] loss: 1.585\n",
      "[6, 300] loss: 1.588\n",
      "[6, 360] loss: 1.611\n",
      "Epoch: 6 -> Loss: 1.60325551033\n",
      "Epoch: 6 -> Test Accuracy: 38.86\n",
      "[7, 60] loss: 1.580\n",
      "[7, 120] loss: 1.590\n",
      "[7, 180] loss: 1.595\n",
      "[7, 240] loss: 1.598\n",
      "[7, 300] loss: 1.578\n",
      "[7, 360] loss: 1.570\n",
      "Epoch: 7 -> Loss: 1.76936268806\n",
      "Epoch: 7 -> Test Accuracy: 38.38\n",
      "[8, 60] loss: 1.560\n",
      "[8, 120] loss: 1.576\n",
      "[8, 180] loss: 1.593\n",
      "[8, 240] loss: 1.571\n",
      "[8, 300] loss: 1.577\n",
      "[8, 360] loss: 1.568\n",
      "Epoch: 8 -> Loss: 1.4629650116\n",
      "Epoch: 8 -> Test Accuracy: 39.09\n",
      "[9, 60] loss: 1.579\n",
      "[9, 120] loss: 1.560\n",
      "[9, 180] loss: 1.570\n",
      "[9, 240] loss: 1.575\n",
      "[9, 300] loss: 1.569\n",
      "[9, 360] loss: 1.565\n",
      "Epoch: 9 -> Loss: 1.43127083778\n",
      "Epoch: 9 -> Test Accuracy: 38.88\n",
      "[10, 60] loss: 1.578\n",
      "[10, 120] loss: 1.561\n",
      "[10, 180] loss: 1.570\n",
      "[10, 240] loss: 1.551\n",
      "[10, 300] loss: 1.587\n",
      "[10, 360] loss: 1.552\n",
      "Epoch: 10 -> Loss: 1.61109542847\n",
      "Epoch: 10 -> Test Accuracy: 39.71\n",
      "[11, 60] loss: 1.557\n",
      "[11, 120] loss: 1.563\n",
      "[11, 180] loss: 1.552\n",
      "[11, 240] loss: 1.570\n",
      "[11, 300] loss: 1.555\n",
      "[11, 360] loss: 1.576\n",
      "Epoch: 11 -> Loss: 1.56664466858\n",
      "Epoch: 11 -> Test Accuracy: 41.03\n",
      "[12, 60] loss: 1.540\n",
      "[12, 120] loss: 1.544\n",
      "[12, 180] loss: 1.540\n",
      "[12, 240] loss: 1.558\n",
      "[12, 300] loss: 1.572\n",
      "[12, 360] loss: 1.565\n",
      "Epoch: 12 -> Loss: 1.55165505409\n",
      "Epoch: 12 -> Test Accuracy: 40.61\n",
      "[13, 60] loss: 1.546\n",
      "[13, 120] loss: 1.523\n",
      "[13, 180] loss: 1.560\n",
      "[13, 240] loss: 1.561\n",
      "[13, 300] loss: 1.548\n",
      "[13, 360] loss: 1.553\n",
      "Epoch: 13 -> Loss: 1.5426620245\n",
      "Epoch: 13 -> Test Accuracy: 41.14\n",
      "[14, 60] loss: 1.547\n",
      "[14, 120] loss: 1.551\n",
      "[14, 180] loss: 1.549\n",
      "[14, 240] loss: 1.537\n",
      "[14, 300] loss: 1.533\n",
      "[14, 360] loss: 1.546\n",
      "Epoch: 14 -> Loss: 1.43817400932\n",
      "Epoch: 14 -> Test Accuracy: 39.81\n",
      "[15, 60] loss: 1.542\n",
      "[15, 120] loss: 1.554\n",
      "[15, 180] loss: 1.551\n",
      "[15, 240] loss: 1.541\n",
      "[15, 300] loss: 1.523\n",
      "[15, 360] loss: 1.545\n",
      "Epoch: 15 -> Loss: 1.57788670063\n",
      "Epoch: 15 -> Test Accuracy: 39.83\n",
      "[16, 60] loss: 1.546\n",
      "[16, 120] loss: 1.544\n",
      "[16, 180] loss: 1.520\n",
      "[16, 240] loss: 1.538\n",
      "[16, 300] loss: 1.554\n",
      "[16, 360] loss: 1.534\n",
      "Epoch: 16 -> Loss: 1.48108315468\n",
      "Epoch: 16 -> Test Accuracy: 40.74\n",
      "[17, 60] loss: 1.542\n",
      "[17, 120] loss: 1.532\n",
      "[17, 180] loss: 1.540\n",
      "[17, 240] loss: 1.537\n",
      "[17, 300] loss: 1.543\n",
      "[17, 360] loss: 1.540\n",
      "Epoch: 17 -> Loss: 1.40596652031\n",
      "Epoch: 17 -> Test Accuracy: 39.88\n",
      "[18, 60] loss: 1.546\n",
      "[18, 120] loss: 1.513\n",
      "[18, 180] loss: 1.532\n",
      "[18, 240] loss: 1.521\n",
      "[18, 300] loss: 1.546\n",
      "[18, 360] loss: 1.522\n",
      "Epoch: 18 -> Loss: 1.61757469177\n",
      "Epoch: 18 -> Test Accuracy: 39.96\n",
      "[19, 60] loss: 1.521\n",
      "[19, 120] loss: 1.551\n",
      "[19, 180] loss: 1.532\n",
      "[19, 240] loss: 1.524\n",
      "[19, 300] loss: 1.517\n",
      "[19, 360] loss: 1.533\n",
      "Epoch: 19 -> Loss: 1.39261817932\n",
      "Epoch: 19 -> Test Accuracy: 40.94\n",
      "[20, 60] loss: 1.515\n",
      "[20, 120] loss: 1.518\n",
      "[20, 180] loss: 1.518\n",
      "[20, 240] loss: 1.549\n",
      "[20, 300] loss: 1.538\n",
      "[20, 360] loss: 1.502\n",
      "Epoch: 20 -> Loss: 1.67349779606\n",
      "Epoch: 20 -> Test Accuracy: 40.78\n",
      "[21, 60] loss: 1.530\n",
      "[21, 120] loss: 1.533\n",
      "[21, 180] loss: 1.535\n",
      "[21, 240] loss: 1.515\n",
      "[21, 300] loss: 1.535\n",
      "[21, 360] loss: 1.535\n",
      "Epoch: 21 -> Loss: 1.44457268715\n",
      "Epoch: 21 -> Test Accuracy: 40.17\n",
      "[22, 60] loss: 1.508\n",
      "[22, 120] loss: 1.525\n",
      "[22, 180] loss: 1.535\n",
      "[22, 240] loss: 1.531\n",
      "[22, 300] loss: 1.527\n",
      "[22, 360] loss: 1.519\n",
      "Epoch: 22 -> Loss: 1.4641187191\n",
      "Epoch: 22 -> Test Accuracy: 42.4\n",
      "[23, 60] loss: 1.533\n",
      "[23, 120] loss: 1.535\n",
      "[23, 180] loss: 1.537\n",
      "[23, 240] loss: 1.517\n",
      "[23, 300] loss: 1.522\n",
      "[23, 360] loss: 1.517\n",
      "Epoch: 23 -> Loss: 1.50899231434\n",
      "Epoch: 23 -> Test Accuracy: 39.69\n",
      "[24, 60] loss: 1.532\n",
      "[24, 120] loss: 1.511\n",
      "[24, 180] loss: 1.513\n",
      "[24, 240] loss: 1.510\n",
      "[24, 300] loss: 1.531\n",
      "[24, 360] loss: 1.527\n",
      "Epoch: 24 -> Loss: 1.3042422533\n",
      "Epoch: 24 -> Test Accuracy: 40.59\n",
      "[25, 60] loss: 1.530\n",
      "[25, 120] loss: 1.533\n",
      "[25, 180] loss: 1.538\n",
      "[25, 240] loss: 1.519\n",
      "[25, 300] loss: 1.521\n",
      "[25, 360] loss: 1.522\n",
      "Epoch: 25 -> Loss: 1.43335390091\n",
      "Epoch: 25 -> Test Accuracy: 41.09\n",
      "[26, 60] loss: 1.522\n",
      "[26, 120] loss: 1.514\n",
      "[26, 180] loss: 1.515\n",
      "[26, 240] loss: 1.531\n",
      "[26, 300] loss: 1.527\n",
      "[26, 360] loss: 1.512\n",
      "Epoch: 26 -> Loss: 1.66401863098\n",
      "Epoch: 26 -> Test Accuracy: 41.3\n",
      "[27, 60] loss: 1.513\n",
      "[27, 120] loss: 1.511\n",
      "[27, 180] loss: 1.520\n",
      "[27, 240] loss: 1.510\n",
      "[27, 300] loss: 1.522\n",
      "[27, 360] loss: 1.532\n",
      "Epoch: 27 -> Loss: 1.54031968117\n",
      "Epoch: 27 -> Test Accuracy: 41.58\n",
      "[28, 60] loss: 1.512\n",
      "[28, 120] loss: 1.530\n",
      "[28, 180] loss: 1.519\n",
      "[28, 240] loss: 1.524\n",
      "[28, 300] loss: 1.520\n",
      "[28, 360] loss: 1.515\n",
      "Epoch: 28 -> Loss: 1.39198589325\n",
      "Epoch: 28 -> Test Accuracy: 41.08\n",
      "[29, 60] loss: 1.509\n",
      "[29, 120] loss: 1.516\n",
      "[29, 180] loss: 1.522\n",
      "[29, 240] loss: 1.525\n",
      "[29, 300] loss: 1.517\n",
      "[29, 360] loss: 1.527\n",
      "Epoch: 29 -> Loss: 1.70566678047\n",
      "Epoch: 29 -> Test Accuracy: 40.26\n",
      "[30, 60] loss: 1.526\n",
      "[30, 120] loss: 1.503\n",
      "[30, 180] loss: 1.498\n",
      "[30, 240] loss: 1.522\n",
      "[30, 300] loss: 1.513\n",
      "[30, 360] loss: 1.514\n",
      "Epoch: 30 -> Loss: 1.39224338531\n",
      "Epoch: 30 -> Test Accuracy: 41.59\n",
      "[31, 60] loss: 1.505\n",
      "[31, 120] loss: 1.524\n",
      "[31, 180] loss: 1.511\n",
      "[31, 240] loss: 1.531\n",
      "[31, 300] loss: 1.492\n",
      "[31, 360] loss: 1.505\n",
      "Epoch: 31 -> Loss: 1.38995099068\n",
      "Epoch: 31 -> Test Accuracy: 41.0\n",
      "[32, 60] loss: 1.489\n",
      "[32, 120] loss: 1.494\n",
      "[32, 180] loss: 1.515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 240] loss: 1.535\n",
      "[32, 300] loss: 1.523\n",
      "[32, 360] loss: 1.526\n",
      "Epoch: 32 -> Loss: 1.42221736908\n",
      "Epoch: 32 -> Test Accuracy: 41.82\n",
      "[33, 60] loss: 1.515\n",
      "[33, 120] loss: 1.521\n",
      "[33, 180] loss: 1.522\n",
      "[33, 240] loss: 1.514\n",
      "[33, 300] loss: 1.493\n",
      "[33, 360] loss: 1.521\n",
      "Epoch: 33 -> Loss: 1.49389278889\n",
      "Epoch: 33 -> Test Accuracy: 41.05\n",
      "[34, 60] loss: 1.497\n",
      "[34, 120] loss: 1.532\n",
      "[34, 180] loss: 1.533\n",
      "[34, 240] loss: 1.507\n",
      "[34, 300] loss: 1.509\n",
      "[34, 360] loss: 1.510\n",
      "Epoch: 34 -> Loss: 1.35445821285\n",
      "Epoch: 34 -> Test Accuracy: 40.5\n",
      "[35, 60] loss: 1.511\n",
      "[35, 120] loss: 1.508\n",
      "[35, 180] loss: 1.520\n",
      "[35, 240] loss: 1.506\n",
      "[35, 300] loss: 1.504\n",
      "[35, 360] loss: 1.524\n",
      "Epoch: 35 -> Loss: 1.62215542793\n",
      "Epoch: 35 -> Test Accuracy: 41.7\n",
      "[36, 60] loss: 1.473\n",
      "[36, 120] loss: 1.417\n",
      "[36, 180] loss: 1.390\n",
      "[36, 240] loss: 1.403\n",
      "[36, 300] loss: 1.405\n",
      "[36, 360] loss: 1.409\n",
      "Epoch: 36 -> Loss: 1.27038919926\n",
      "Epoch: 36 -> Test Accuracy: 45.04\n",
      "[37, 60] loss: 1.392\n",
      "[37, 120] loss: 1.404\n",
      "[37, 180] loss: 1.403\n",
      "[37, 240] loss: 1.382\n",
      "[37, 300] loss: 1.397\n",
      "[37, 360] loss: 1.380\n",
      "Epoch: 37 -> Loss: 1.38388288021\n",
      "Epoch: 37 -> Test Accuracy: 45.78\n",
      "[38, 60] loss: 1.391\n",
      "[38, 120] loss: 1.392\n",
      "[38, 180] loss: 1.382\n",
      "[38, 240] loss: 1.384\n",
      "[38, 300] loss: 1.382\n",
      "[38, 360] loss: 1.401\n",
      "Epoch: 38 -> Loss: 1.39575433731\n",
      "Epoch: 38 -> Test Accuracy: 45.44\n",
      "[39, 60] loss: 1.383\n",
      "[39, 120] loss: 1.374\n",
      "[39, 180] loss: 1.367\n",
      "[39, 240] loss: 1.388\n",
      "[39, 300] loss: 1.391\n",
      "[39, 360] loss: 1.389\n",
      "Epoch: 39 -> Loss: 1.41786599159\n",
      "Epoch: 39 -> Test Accuracy: 45.31\n",
      "[40, 60] loss: 1.380\n",
      "[40, 120] loss: 1.382\n",
      "[40, 180] loss: 1.379\n",
      "[40, 240] loss: 1.371\n",
      "[40, 300] loss: 1.366\n",
      "[40, 360] loss: 1.376\n",
      "Epoch: 40 -> Loss: 1.47069633007\n",
      "Epoch: 40 -> Test Accuracy: 45.64\n",
      "[41, 60] loss: 1.375\n",
      "[41, 120] loss: 1.372\n",
      "[41, 180] loss: 1.400\n",
      "[41, 240] loss: 1.380\n",
      "[41, 300] loss: 1.368\n",
      "[41, 360] loss: 1.359\n",
      "Epoch: 41 -> Loss: 1.48551487923\n",
      "Epoch: 41 -> Test Accuracy: 45.39\n",
      "[42, 60] loss: 1.389\n",
      "[42, 120] loss: 1.376\n",
      "[42, 180] loss: 1.374\n",
      "[42, 240] loss: 1.391\n",
      "[42, 300] loss: 1.382\n",
      "[42, 360] loss: 1.372\n",
      "Epoch: 42 -> Loss: 1.27604675293\n",
      "Epoch: 42 -> Test Accuracy: 46.12\n",
      "[43, 60] loss: 1.370\n",
      "[43, 120] loss: 1.378\n",
      "[43, 180] loss: 1.374\n",
      "[43, 240] loss: 1.387\n",
      "[43, 300] loss: 1.374\n",
      "[43, 360] loss: 1.369\n",
      "Epoch: 43 -> Loss: 1.45974802971\n",
      "Epoch: 43 -> Test Accuracy: 45.58\n",
      "[44, 60] loss: 1.393\n",
      "[44, 120] loss: 1.375\n",
      "[44, 180] loss: 1.366\n",
      "[44, 240] loss: 1.377\n",
      "[44, 300] loss: 1.381\n",
      "[44, 360] loss: 1.379\n",
      "Epoch: 44 -> Loss: 1.40635550022\n",
      "Epoch: 44 -> Test Accuracy: 45.13\n",
      "[45, 60] loss: 1.364\n",
      "[45, 120] loss: 1.382\n",
      "[45, 180] loss: 1.382\n",
      "[45, 240] loss: 1.384\n",
      "[45, 300] loss: 1.371\n",
      "[45, 360] loss: 1.374\n",
      "Epoch: 45 -> Loss: 1.48027598858\n",
      "Epoch: 45 -> Test Accuracy: 44.83\n",
      "[46, 60] loss: 1.367\n",
      "[46, 120] loss: 1.367\n",
      "[46, 180] loss: 1.361\n",
      "[46, 240] loss: 1.387\n",
      "[46, 300] loss: 1.376\n",
      "[46, 360] loss: 1.390\n",
      "Epoch: 46 -> Loss: 1.36653196812\n",
      "Epoch: 46 -> Test Accuracy: 45.3\n",
      "[47, 60] loss: 1.365\n",
      "[47, 120] loss: 1.384\n",
      "[47, 180] loss: 1.356\n",
      "[47, 240] loss: 1.396\n",
      "[47, 300] loss: 1.381\n",
      "[47, 360] loss: 1.359\n",
      "Epoch: 47 -> Loss: 1.309202075\n",
      "Epoch: 47 -> Test Accuracy: 45.31\n",
      "[48, 60] loss: 1.357\n",
      "[48, 120] loss: 1.374\n",
      "[48, 180] loss: 1.364\n",
      "[48, 240] loss: 1.384\n",
      "[48, 300] loss: 1.371\n",
      "[48, 360] loss: 1.386\n",
      "Epoch: 48 -> Loss: 1.49749732018\n",
      "Epoch: 48 -> Test Accuracy: 45.29\n",
      "[49, 60] loss: 1.373\n",
      "[49, 120] loss: 1.358\n",
      "[49, 180] loss: 1.379\n",
      "[49, 240] loss: 1.374\n",
      "[49, 300] loss: 1.372\n",
      "[49, 360] loss: 1.357\n",
      "Epoch: 49 -> Loss: 1.32078337669\n",
      "Epoch: 49 -> Test Accuracy: 45.36\n",
      "[50, 60] loss: 1.373\n",
      "[50, 120] loss: 1.382\n",
      "[50, 180] loss: 1.368\n",
      "[50, 240] loss: 1.363\n",
      "[50, 300] loss: 1.374\n",
      "[50, 360] loss: 1.386\n",
      "Epoch: 50 -> Loss: 1.49485468864\n",
      "Epoch: 50 -> Test Accuracy: 46.04\n",
      "[51, 60] loss: 1.345\n",
      "[51, 120] loss: 1.364\n",
      "[51, 180] loss: 1.379\n",
      "[51, 240] loss: 1.382\n",
      "[51, 300] loss: 1.374\n",
      "[51, 360] loss: 1.369\n",
      "Epoch: 51 -> Loss: 1.18661975861\n",
      "Epoch: 51 -> Test Accuracy: 46.64\n",
      "[52, 60] loss: 1.377\n",
      "[52, 120] loss: 1.348\n",
      "[52, 180] loss: 1.381\n",
      "[52, 240] loss: 1.379\n",
      "[52, 300] loss: 1.360\n",
      "[52, 360] loss: 1.362\n",
      "Epoch: 52 -> Loss: 1.25088834763\n",
      "Epoch: 52 -> Test Accuracy: 45.5\n",
      "[53, 60] loss: 1.373\n",
      "[53, 120] loss: 1.371\n",
      "[53, 180] loss: 1.395\n",
      "[53, 240] loss: 1.336\n",
      "[53, 300] loss: 1.384\n",
      "[53, 360] loss: 1.363\n",
      "Epoch: 53 -> Loss: 1.36608195305\n",
      "Epoch: 53 -> Test Accuracy: 45.71\n",
      "[54, 60] loss: 1.354\n",
      "[54, 120] loss: 1.367\n",
      "[54, 180] loss: 1.362\n",
      "[54, 240] loss: 1.368\n",
      "[54, 300] loss: 1.381\n",
      "[54, 360] loss: 1.368\n",
      "Epoch: 54 -> Loss: 1.44935727119\n",
      "Epoch: 54 -> Test Accuracy: 46.62\n",
      "[55, 60] loss: 1.367\n",
      "[55, 120] loss: 1.381\n",
      "[55, 180] loss: 1.381\n",
      "[55, 240] loss: 1.372\n",
      "[55, 300] loss: 1.368\n",
      "[55, 360] loss: 1.361\n",
      "Epoch: 55 -> Loss: 1.27965533733\n",
      "Epoch: 55 -> Test Accuracy: 45.78\n",
      "[56, 60] loss: 1.363\n",
      "[56, 120] loss: 1.359\n",
      "[56, 180] loss: 1.350\n",
      "[56, 240] loss: 1.380\n",
      "[56, 300] loss: 1.370\n",
      "[56, 360] loss: 1.374\n",
      "Epoch: 56 -> Loss: 1.43732047081\n",
      "Epoch: 56 -> Test Accuracy: 45.68\n",
      "[57, 60] loss: 1.362\n",
      "[57, 120] loss: 1.352\n",
      "[57, 180] loss: 1.363\n",
      "[57, 240] loss: 1.358\n",
      "[57, 300] loss: 1.381\n",
      "[57, 360] loss: 1.372\n",
      "Epoch: 57 -> Loss: 1.31427073479\n",
      "Epoch: 57 -> Test Accuracy: 46.7\n",
      "[58, 60] loss: 1.347\n",
      "[58, 120] loss: 1.378\n",
      "[58, 180] loss: 1.367\n",
      "[58, 240] loss: 1.380\n",
      "[58, 300] loss: 1.371\n",
      "[58, 360] loss: 1.348\n",
      "Epoch: 58 -> Loss: 1.24994778633\n",
      "Epoch: 58 -> Test Accuracy: 46.12\n",
      "[59, 60] loss: 1.350\n",
      "[59, 120] loss: 1.363\n",
      "[59, 180] loss: 1.354\n",
      "[59, 240] loss: 1.372\n",
      "[59, 300] loss: 1.364\n",
      "[59, 360] loss: 1.355\n",
      "Epoch: 59 -> Loss: 1.45527112484\n",
      "Epoch: 59 -> Test Accuracy: 46.29\n",
      "[60, 60] loss: 1.348\n",
      "[60, 120] loss: 1.356\n",
      "[60, 180] loss: 1.374\n",
      "[60, 240] loss: 1.368\n",
      "[60, 300] loss: 1.365\n",
      "[60, 360] loss: 1.356\n",
      "Epoch: 60 -> Loss: 1.26512885094\n",
      "Epoch: 60 -> Test Accuracy: 46.24\n",
      "[61, 60] loss: 1.351\n",
      "[61, 120] loss: 1.362\n",
      "[61, 180] loss: 1.372\n",
      "[61, 240] loss: 1.359\n",
      "[61, 300] loss: 1.364\n",
      "[61, 360] loss: 1.380\n",
      "Epoch: 61 -> Loss: 1.32708501816\n",
      "Epoch: 61 -> Test Accuracy: 45.27\n",
      "[62, 60] loss: 1.375\n",
      "[62, 120] loss: 1.386\n",
      "[62, 180] loss: 1.361\n",
      "[62, 240] loss: 1.348\n",
      "[62, 300] loss: 1.354\n",
      "[62, 360] loss: 1.346\n",
      "Epoch: 62 -> Loss: 1.4536741972\n",
      "Epoch: 62 -> Test Accuracy: 45.57\n",
      "[63, 60] loss: 1.338\n",
      "[63, 120] loss: 1.367\n",
      "[63, 180] loss: 1.360\n",
      "[63, 240] loss: 1.363\n",
      "[63, 300] loss: 1.377\n",
      "[63, 360] loss: 1.341\n",
      "Epoch: 63 -> Loss: 1.40574729443\n",
      "Epoch: 63 -> Test Accuracy: 46.43\n",
      "[64, 60] loss: 1.383\n",
      "[64, 120] loss: 1.366\n",
      "[64, 180] loss: 1.354\n",
      "[64, 240] loss: 1.365\n",
      "[64, 300] loss: 1.383\n",
      "[64, 360] loss: 1.368\n",
      "Epoch: 64 -> Loss: 1.46270942688\n",
      "Epoch: 64 -> Test Accuracy: 45.8\n",
      "[65, 60] loss: 1.371\n",
      "[65, 120] loss: 1.372\n",
      "[65, 180] loss: 1.371\n",
      "[65, 240] loss: 1.361\n",
      "[65, 300] loss: 1.348\n",
      "[65, 360] loss: 1.362\n",
      "Epoch: 65 -> Loss: 1.31586873531\n",
      "Epoch: 65 -> Test Accuracy: 45.79\n",
      "[66, 60] loss: 1.363\n",
      "[66, 120] loss: 1.369\n",
      "[66, 180] loss: 1.362\n",
      "[66, 240] loss: 1.348\n",
      "[66, 300] loss: 1.378\n",
      "[66, 360] loss: 1.353\n",
      "Epoch: 66 -> Loss: 1.5182955265\n",
      "Epoch: 66 -> Test Accuracy: 46.27\n",
      "[67, 60] loss: 1.348\n",
      "[67, 120] loss: 1.360\n",
      "[67, 180] loss: 1.338\n",
      "[67, 240] loss: 1.360\n",
      "[67, 300] loss: 1.353\n",
      "[67, 360] loss: 1.371\n",
      "Epoch: 67 -> Loss: 1.47883868217\n",
      "Epoch: 67 -> Test Accuracy: 46.49\n",
      "[68, 60] loss: 1.365\n",
      "[68, 120] loss: 1.373\n",
      "[68, 180] loss: 1.343\n",
      "[68, 240] loss: 1.355\n",
      "[68, 300] loss: 1.359\n",
      "[68, 360] loss: 1.380\n",
      "Epoch: 68 -> Loss: 1.44930040836\n",
      "Epoch: 68 -> Test Accuracy: 46.26\n",
      "[69, 60] loss: 1.354\n",
      "[69, 120] loss: 1.339\n",
      "[69, 180] loss: 1.369\n",
      "[69, 240] loss: 1.378\n",
      "[69, 300] loss: 1.344\n",
      "[69, 360] loss: 1.372\n",
      "Epoch: 69 -> Loss: 1.21213066578\n",
      "Epoch: 69 -> Test Accuracy: 46.02\n",
      "[70, 60] loss: 1.356\n",
      "[70, 120] loss: 1.366\n",
      "[70, 180] loss: 1.359\n",
      "[70, 240] loss: 1.345\n",
      "[70, 300] loss: 1.356\n",
      "[70, 360] loss: 1.358\n",
      "Epoch: 70 -> Loss: 1.47160863876\n",
      "Epoch: 70 -> Test Accuracy: 46.42\n",
      "[71, 60] loss: 1.311\n",
      "[71, 120] loss: 1.292\n",
      "[71, 180] loss: 1.272\n",
      "[71, 240] loss: 1.272\n",
      "[71, 300] loss: 1.293\n",
      "[71, 360] loss: 1.281\n",
      "Epoch: 71 -> Loss: 1.39774549007\n",
      "Epoch: 71 -> Test Accuracy: 48.56\n",
      "[72, 60] loss: 1.281\n",
      "[72, 120] loss: 1.274\n",
      "[72, 180] loss: 1.268\n",
      "[72, 240] loss: 1.289\n",
      "[72, 300] loss: 1.291\n",
      "[72, 360] loss: 1.261\n",
      "Epoch: 72 -> Loss: 1.36227869987\n",
      "Epoch: 72 -> Test Accuracy: 49.12\n",
      "[73, 60] loss: 1.261\n",
      "[73, 120] loss: 1.275\n",
      "[73, 180] loss: 1.249\n",
      "[73, 240] loss: 1.275\n",
      "[73, 300] loss: 1.262\n",
      "[73, 360] loss: 1.271\n",
      "Epoch: 73 -> Loss: 1.22236800194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 -> Test Accuracy: 49.35\n",
      "[74, 60] loss: 1.275\n",
      "[74, 120] loss: 1.267\n",
      "[74, 180] loss: 1.263\n",
      "[74, 240] loss: 1.281\n",
      "[74, 300] loss: 1.268\n",
      "[74, 360] loss: 1.261\n",
      "Epoch: 74 -> Loss: 1.29030704498\n",
      "Epoch: 74 -> Test Accuracy: 49.19\n",
      "[75, 60] loss: 1.268\n",
      "[75, 120] loss: 1.271\n",
      "[75, 180] loss: 1.252\n",
      "[75, 240] loss: 1.251\n",
      "[75, 300] loss: 1.261\n",
      "[75, 360] loss: 1.252\n",
      "Epoch: 75 -> Loss: 1.32819271088\n",
      "Epoch: 75 -> Test Accuracy: 49.67\n",
      "[76, 60] loss: 1.251\n",
      "[76, 120] loss: 1.285\n",
      "[76, 180] loss: 1.264\n",
      "[76, 240] loss: 1.267\n",
      "[76, 300] loss: 1.252\n",
      "[76, 360] loss: 1.263\n",
      "Epoch: 76 -> Loss: 1.38029789925\n",
      "Epoch: 76 -> Test Accuracy: 49.51\n",
      "[77, 60] loss: 1.265\n",
      "[77, 120] loss: 1.232\n",
      "[77, 180] loss: 1.263\n",
      "[77, 240] loss: 1.253\n",
      "[77, 300] loss: 1.268\n",
      "[77, 360] loss: 1.249\n",
      "Epoch: 77 -> Loss: 1.10905838013\n",
      "Epoch: 77 -> Test Accuracy: 48.95\n",
      "[78, 60] loss: 1.276\n",
      "[78, 120] loss: 1.237\n",
      "[78, 180] loss: 1.263\n",
      "[78, 240] loss: 1.266\n",
      "[78, 300] loss: 1.265\n",
      "[78, 360] loss: 1.245\n",
      "Epoch: 78 -> Loss: 1.41375076771\n",
      "Epoch: 78 -> Test Accuracy: 49.46\n",
      "[79, 60] loss: 1.257\n",
      "[79, 120] loss: 1.261\n",
      "[79, 180] loss: 1.268\n",
      "[79, 240] loss: 1.255\n",
      "[79, 300] loss: 1.242\n",
      "[79, 360] loss: 1.257\n",
      "Epoch: 79 -> Loss: 1.54863274097\n",
      "Epoch: 79 -> Test Accuracy: 49.77\n",
      "[80, 60] loss: 1.240\n",
      "[80, 120] loss: 1.258\n",
      "[80, 180] loss: 1.269\n",
      "[80, 240] loss: 1.264\n",
      "[80, 300] loss: 1.253\n",
      "[80, 360] loss: 1.243\n",
      "Epoch: 80 -> Loss: 1.327511549\n",
      "Epoch: 80 -> Test Accuracy: 49.48\n",
      "[81, 60] loss: 1.256\n",
      "[81, 120] loss: 1.249\n",
      "[81, 180] loss: 1.249\n",
      "[81, 240] loss: 1.250\n",
      "[81, 300] loss: 1.246\n",
      "[81, 360] loss: 1.269\n",
      "Epoch: 81 -> Loss: 1.34371185303\n",
      "Epoch: 81 -> Test Accuracy: 49.04\n",
      "[82, 60] loss: 1.265\n",
      "[82, 120] loss: 1.263\n",
      "[82, 180] loss: 1.253\n",
      "[82, 240] loss: 1.250\n",
      "[82, 300] loss: 1.260\n",
      "[82, 360] loss: 1.261\n",
      "Epoch: 82 -> Loss: 1.15736794472\n",
      "Epoch: 82 -> Test Accuracy: 49.17\n",
      "[83, 60] loss: 1.263\n",
      "[83, 120] loss: 1.241\n",
      "[83, 180] loss: 1.235\n",
      "[83, 240] loss: 1.250\n",
      "[83, 300] loss: 1.253\n",
      "[83, 360] loss: 1.288\n",
      "Epoch: 83 -> Loss: 1.33312928677\n",
      "Epoch: 83 -> Test Accuracy: 49.35\n",
      "[84, 60] loss: 1.252\n",
      "[84, 120] loss: 1.245\n",
      "[84, 180] loss: 1.274\n",
      "[84, 240] loss: 1.261\n",
      "[84, 300] loss: 1.248\n",
      "[84, 360] loss: 1.260\n",
      "Epoch: 84 -> Loss: 1.22136008739\n",
      "Epoch: 84 -> Test Accuracy: 49.88\n",
      "[85, 60] loss: 1.248\n",
      "[85, 120] loss: 1.251\n",
      "[85, 180] loss: 1.260\n",
      "[85, 240] loss: 1.265\n",
      "[85, 300] loss: 1.234\n",
      "[85, 360] loss: 1.258\n",
      "Epoch: 85 -> Loss: 1.54041218758\n",
      "Epoch: 85 -> Test Accuracy: 49.26\n",
      "[86, 60] loss: 1.220\n",
      "[86, 120] loss: 1.200\n",
      "[86, 180] loss: 1.223\n",
      "[86, 240] loss: 1.209\n",
      "[86, 300] loss: 1.237\n",
      "[86, 360] loss: 1.238\n",
      "Epoch: 86 -> Loss: 1.24673771858\n",
      "Epoch: 86 -> Test Accuracy: 50.17\n",
      "[87, 60] loss: 1.227\n",
      "[87, 120] loss: 1.205\n",
      "[87, 180] loss: 1.223\n",
      "[87, 240] loss: 1.218\n",
      "[87, 300] loss: 1.195\n",
      "[87, 360] loss: 1.230\n",
      "Epoch: 87 -> Loss: 1.10625004768\n",
      "Epoch: 87 -> Test Accuracy: 50.5\n",
      "[88, 60] loss: 1.198\n",
      "[88, 120] loss: 1.202\n",
      "[88, 180] loss: 1.219\n",
      "[88, 240] loss: 1.210\n",
      "[88, 300] loss: 1.237\n",
      "[88, 360] loss: 1.199\n",
      "Epoch: 88 -> Loss: 1.17780423164\n",
      "Epoch: 88 -> Test Accuracy: 50.52\n",
      "[89, 60] loss: 1.208\n",
      "[89, 120] loss: 1.232\n",
      "[89, 180] loss: 1.219\n",
      "[89, 240] loss: 1.212\n",
      "[89, 300] loss: 1.210\n",
      "[89, 360] loss: 1.224\n",
      "Epoch: 89 -> Loss: 1.09796237946\n",
      "Epoch: 89 -> Test Accuracy: 50.61\n",
      "[90, 60] loss: 1.229\n",
      "[90, 120] loss: 1.219\n",
      "[90, 180] loss: 1.220\n",
      "[90, 240] loss: 1.206\n",
      "[90, 300] loss: 1.201\n",
      "[90, 360] loss: 1.211\n",
      "Epoch: 90 -> Loss: 1.22075045109\n",
      "Epoch: 90 -> Test Accuracy: 50.55\n",
      "[91, 60] loss: 1.217\n",
      "[91, 120] loss: 1.214\n",
      "[91, 180] loss: 1.208\n",
      "[91, 240] loss: 1.204\n",
      "[91, 300] loss: 1.207\n",
      "[91, 360] loss: 1.196\n",
      "Epoch: 91 -> Loss: 1.24331927299\n",
      "Epoch: 91 -> Test Accuracy: 50.4\n",
      "[92, 60] loss: 1.207\n",
      "[92, 120] loss: 1.205\n",
      "[92, 180] loss: 1.206\n",
      "[92, 240] loss: 1.219\n",
      "[92, 300] loss: 1.205\n",
      "[92, 360] loss: 1.196\n",
      "Epoch: 92 -> Loss: 1.04260504246\n",
      "Epoch: 92 -> Test Accuracy: 50.73\n",
      "[93, 60] loss: 1.210\n",
      "[93, 120] loss: 1.219\n",
      "[93, 180] loss: 1.206\n",
      "[93, 240] loss: 1.205\n",
      "[93, 300] loss: 1.212\n",
      "[93, 360] loss: 1.200\n",
      "Epoch: 93 -> Loss: 1.058131814\n",
      "Epoch: 93 -> Test Accuracy: 50.8\n",
      "[94, 60] loss: 1.205\n",
      "[94, 120] loss: 1.230\n",
      "[94, 180] loss: 1.213\n",
      "[94, 240] loss: 1.205\n",
      "[94, 300] loss: 1.211\n",
      "[94, 360] loss: 1.203\n",
      "Epoch: 94 -> Loss: 1.02224087715\n",
      "Epoch: 94 -> Test Accuracy: 51.1\n",
      "[95, 60] loss: 1.207\n",
      "[95, 120] loss: 1.206\n",
      "[95, 180] loss: 1.208\n",
      "[95, 240] loss: 1.209\n",
      "[95, 300] loss: 1.217\n",
      "[95, 360] loss: 1.204\n",
      "Epoch: 95 -> Loss: 1.3429274559\n",
      "Epoch: 95 -> Test Accuracy: 51.0\n",
      "[96, 60] loss: 1.219\n",
      "[96, 120] loss: 1.221\n",
      "[96, 180] loss: 1.213\n",
      "[96, 240] loss: 1.217\n",
      "[96, 300] loss: 1.201\n",
      "[96, 360] loss: 1.198\n",
      "Epoch: 96 -> Loss: 1.17535591125\n",
      "Epoch: 96 -> Test Accuracy: 50.8\n",
      "[97, 60] loss: 1.201\n",
      "[97, 120] loss: 1.196\n",
      "[97, 180] loss: 1.191\n",
      "[97, 240] loss: 1.216\n",
      "[97, 300] loss: 1.214\n",
      "[97, 360] loss: 1.227\n",
      "Epoch: 97 -> Loss: 1.09982740879\n",
      "Epoch: 97 -> Test Accuracy: 50.56\n",
      "[98, 60] loss: 1.215\n",
      "[98, 120] loss: 1.213\n",
      "[98, 180] loss: 1.217\n",
      "[98, 240] loss: 1.207\n",
      "[98, 300] loss: 1.196\n",
      "[98, 360] loss: 1.193\n",
      "Epoch: 98 -> Loss: 1.10008943081\n",
      "Epoch: 98 -> Test Accuracy: 51.13\n",
      "[99, 60] loss: 1.194\n",
      "[99, 120] loss: 1.186\n",
      "[99, 180] loss: 1.198\n",
      "[99, 240] loss: 1.215\n",
      "[99, 300] loss: 1.202\n",
      "[99, 360] loss: 1.203\n",
      "Epoch: 99 -> Loss: 1.17532455921\n",
      "Epoch: 99 -> Test Accuracy: 50.88\n",
      "[100, 60] loss: 1.201\n",
      "[100, 120] loss: 1.194\n",
      "[100, 180] loss: 1.199\n",
      "[100, 240] loss: 1.207\n",
      "[100, 300] loss: 1.201\n",
      "[100, 360] loss: 1.193\n",
      "Epoch: 100 -> Loss: 1.25166594982\n",
      "Epoch: 100 -> Test Accuracy: 51.09\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train ConvClassifiers on feature map of net_3block\n",
    "conv_block4_loss_log, conv_block4_valid_accuracy_log, conv_block4_test_accuracy_log, conv_block4_max_accuracy, \\\n",
    "conv_block4_best_epoch = tr.train_all_blocks(4, 10, [0.1, 0.02, 0.004, 0.0008], [35, 70, 85, 100], 0.9, 5e-4, net_block4, \n",
    "                                            criterion, trainloader, None, testloader, use_ConvClassifier=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename files\n",
    "fm.add_block_to_name(4, [100, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Block RotNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "net_block5 = RN.RotNet(num_classes=4, num_conv_block=5, add_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.153\n",
      "[1, 120] loss: 1.010\n",
      "[1, 180] loss: 0.952\n",
      "[1, 240] loss: 0.894\n",
      "[1, 300] loss: 0.847\n",
      "[1, 360] loss: 0.827\n",
      "Epoch: 1 -> Loss: 0.694923758507\n",
      "Epoch: 1 -> Test Accuracy: 68.66\n",
      "[2, 60] loss: 0.758\n",
      "[2, 120] loss: 0.748\n",
      "[2, 180] loss: 0.735\n",
      "[2, 240] loss: 0.700\n",
      "[2, 300] loss: 0.693\n",
      "[2, 360] loss: 0.688\n",
      "Epoch: 2 -> Loss: 0.559562981129\n",
      "Epoch: 2 -> Test Accuracy: 74.1425\n",
      "[3, 60] loss: 0.637\n",
      "[3, 120] loss: 0.633\n",
      "[3, 180] loss: 0.611\n",
      "[3, 240] loss: 0.618\n",
      "[3, 300] loss: 0.587\n",
      "[3, 360] loss: 0.584\n",
      "Epoch: 3 -> Loss: 0.49524974823\n",
      "Epoch: 3 -> Test Accuracy: 76.5075\n",
      "[4, 60] loss: 0.588\n",
      "[4, 120] loss: 0.539\n",
      "[4, 180] loss: 0.552\n",
      "[4, 240] loss: 0.550\n",
      "[4, 300] loss: 0.541\n",
      "[4, 360] loss: 0.536\n",
      "Epoch: 4 -> Loss: 0.694020569324\n",
      "Epoch: 4 -> Test Accuracy: 79.0375\n",
      "[5, 60] loss: 0.522\n",
      "[5, 120] loss: 0.516\n",
      "[5, 180] loss: 0.517\n",
      "[5, 240] loss: 0.487\n",
      "[5, 300] loss: 0.507\n",
      "[5, 360] loss: 0.507\n",
      "Epoch: 5 -> Loss: 0.350269109011\n",
      "Epoch: 5 -> Test Accuracy: 80.38\n",
      "[6, 60] loss: 0.486\n",
      "[6, 120] loss: 0.495\n",
      "[6, 180] loss: 0.481\n",
      "[6, 240] loss: 0.477\n",
      "[6, 300] loss: 0.490\n",
      "[6, 360] loss: 0.467\n",
      "Epoch: 6 -> Loss: 0.349258065224\n",
      "Epoch: 6 -> Test Accuracy: 82.0325\n",
      "[7, 60] loss: 0.458\n",
      "[7, 120] loss: 0.450\n",
      "[7, 180] loss: 0.476\n",
      "[7, 240] loss: 0.458\n",
      "[7, 300] loss: 0.452\n",
      "[7, 360] loss: 0.448\n",
      "Epoch: 7 -> Loss: 0.414767742157\n",
      "Epoch: 7 -> Test Accuracy: 82.765\n",
      "[8, 60] loss: 0.442\n",
      "[8, 120] loss: 0.451\n",
      "[8, 180] loss: 0.439\n",
      "[8, 240] loss: 0.451\n",
      "[8, 300] loss: 0.427\n",
      "[8, 360] loss: 0.436\n",
      "Epoch: 8 -> Loss: 0.42722851038\n",
      "Epoch: 8 -> Test Accuracy: 83.1025\n",
      "[9, 60] loss: 0.421\n",
      "[9, 120] loss: 0.429\n",
      "[9, 180] loss: 0.430\n",
      "[9, 240] loss: 0.429\n",
      "[9, 300] loss: 0.425\n",
      "[9, 360] loss: 0.429\n",
      "Epoch: 9 -> Loss: 0.563561141491\n",
      "Epoch: 9 -> Test Accuracy: 81.175\n",
      "[10, 60] loss: 0.410\n",
      "[10, 120] loss: 0.419\n",
      "[10, 180] loss: 0.432\n",
      "[10, 240] loss: 0.415\n",
      "[10, 300] loss: 0.405\n",
      "[10, 360] loss: 0.405\n",
      "Epoch: 10 -> Loss: 0.56898868084\n",
      "Epoch: 10 -> Test Accuracy: 83.6175\n",
      "[11, 60] loss: 0.406\n",
      "[11, 120] loss: 0.402\n",
      "[11, 180] loss: 0.403\n",
      "[11, 240] loss: 0.401\n",
      "[11, 300] loss: 0.404\n",
      "[11, 360] loss: 0.404\n",
      "Epoch: 11 -> Loss: 0.350681960583\n",
      "Epoch: 11 -> Test Accuracy: 83.0475\n",
      "[12, 60] loss: 0.397\n",
      "[12, 120] loss: 0.394\n",
      "[12, 180] loss: 0.390\n",
      "[12, 240] loss: 0.405\n",
      "[12, 300] loss: 0.390\n",
      "[12, 360] loss: 0.383\n",
      "Epoch: 12 -> Loss: 0.322449028492\n",
      "Epoch: 12 -> Test Accuracy: 84.66\n",
      "[13, 60] loss: 0.389\n",
      "[13, 120] loss: 0.380\n",
      "[13, 180] loss: 0.376\n",
      "[13, 240] loss: 0.388\n",
      "[13, 300] loss: 0.388\n",
      "[13, 360] loss: 0.393\n",
      "Epoch: 13 -> Loss: 0.370705425739\n",
      "Epoch: 13 -> Test Accuracy: 85.2375\n",
      "[14, 60] loss: 0.374\n",
      "[14, 120] loss: 0.389\n",
      "[14, 180] loss: 0.365\n",
      "[14, 240] loss: 0.381\n",
      "[14, 300] loss: 0.365\n",
      "[14, 360] loss: 0.389\n",
      "Epoch: 14 -> Loss: 0.376873642206\n",
      "Epoch: 14 -> Test Accuracy: 84.0025\n",
      "[15, 60] loss: 0.365\n",
      "[15, 120] loss: 0.377\n",
      "[15, 180] loss: 0.368\n",
      "[15, 240] loss: 0.381\n",
      "[15, 300] loss: 0.371\n",
      "[15, 360] loss: 0.370\n",
      "Epoch: 15 -> Loss: 0.392606437206\n",
      "Epoch: 15 -> Test Accuracy: 83.955\n",
      "[16, 60] loss: 0.370\n",
      "[16, 120] loss: 0.373\n",
      "[16, 180] loss: 0.353\n",
      "[16, 240] loss: 0.368\n",
      "[16, 300] loss: 0.365\n",
      "[16, 360] loss: 0.356\n",
      "Epoch: 16 -> Loss: 0.470078855753\n",
      "Epoch: 16 -> Test Accuracy: 84.0875\n",
      "[17, 60] loss: 0.351\n",
      "[17, 120] loss: 0.379\n",
      "[17, 180] loss: 0.355\n",
      "[17, 240] loss: 0.374\n",
      "[17, 300] loss: 0.357\n",
      "[17, 360] loss: 0.366\n",
      "Epoch: 17 -> Loss: 0.515791833401\n",
      "Epoch: 17 -> Test Accuracy: 84.04\n",
      "[18, 60] loss: 0.354\n",
      "[18, 120] loss: 0.350\n",
      "[18, 180] loss: 0.354\n",
      "[18, 240] loss: 0.360\n",
      "[18, 300] loss: 0.354\n",
      "[18, 360] loss: 0.366\n",
      "Epoch: 18 -> Loss: 0.329248011112\n",
      "Epoch: 18 -> Test Accuracy: 85.7075\n",
      "[19, 60] loss: 0.353\n",
      "[19, 120] loss: 0.358\n",
      "[19, 180] loss: 0.357\n",
      "[19, 240] loss: 0.363\n",
      "[19, 300] loss: 0.346\n",
      "[19, 360] loss: 0.367\n",
      "Epoch: 19 -> Loss: 0.377302467823\n",
      "Epoch: 19 -> Test Accuracy: 85.0325\n",
      "[20, 60] loss: 0.351\n",
      "[20, 120] loss: 0.349\n",
      "[20, 180] loss: 0.364\n",
      "[20, 240] loss: 0.351\n",
      "[20, 300] loss: 0.341\n",
      "[20, 360] loss: 0.338\n",
      "Epoch: 20 -> Loss: 0.428896814585\n",
      "Epoch: 20 -> Test Accuracy: 84.99\n",
      "[21, 60] loss: 0.337\n",
      "[21, 120] loss: 0.350\n",
      "[21, 180] loss: 0.340\n",
      "[21, 240] loss: 0.347\n",
      "[21, 300] loss: 0.346\n",
      "[21, 360] loss: 0.357\n",
      "Epoch: 21 -> Loss: 0.306595295668\n",
      "Epoch: 21 -> Test Accuracy: 85.54\n",
      "[22, 60] loss: 0.334\n",
      "[22, 120] loss: 0.343\n",
      "[22, 180] loss: 0.342\n",
      "[22, 240] loss: 0.334\n",
      "[22, 300] loss: 0.351\n",
      "[22, 360] loss: 0.368\n",
      "Epoch: 22 -> Loss: 0.36098074913\n",
      "Epoch: 22 -> Test Accuracy: 85.1075\n",
      "[23, 60] loss: 0.323\n",
      "[23, 120] loss: 0.347\n",
      "[23, 180] loss: 0.340\n",
      "[23, 240] loss: 0.353\n",
      "[23, 300] loss: 0.333\n",
      "[23, 360] loss: 0.347\n",
      "Epoch: 23 -> Loss: 0.243895053864\n",
      "Epoch: 23 -> Test Accuracy: 85.97\n",
      "[24, 60] loss: 0.333\n",
      "[24, 120] loss: 0.339\n",
      "[24, 180] loss: 0.339\n",
      "[24, 240] loss: 0.333\n",
      "[24, 300] loss: 0.342\n",
      "[24, 360] loss: 0.338\n",
      "Epoch: 24 -> Loss: 0.246161296964\n",
      "Epoch: 24 -> Test Accuracy: 85.1925\n",
      "[25, 60] loss: 0.322\n",
      "[25, 120] loss: 0.322\n",
      "[25, 180] loss: 0.338\n",
      "[25, 240] loss: 0.346\n",
      "[25, 300] loss: 0.328\n",
      "[25, 360] loss: 0.356\n",
      "Epoch: 25 -> Loss: 0.448965787888\n",
      "Epoch: 25 -> Test Accuracy: 85.09\n",
      "[26, 60] loss: 0.327\n",
      "[26, 120] loss: 0.326\n",
      "[26, 180] loss: 0.330\n",
      "[26, 240] loss: 0.352\n",
      "[26, 300] loss: 0.343\n",
      "[26, 360] loss: 0.331\n",
      "Epoch: 26 -> Loss: 0.417728573084\n",
      "Epoch: 26 -> Test Accuracy: 86.2075\n",
      "[27, 60] loss: 0.306\n",
      "[27, 120] loss: 0.325\n",
      "[27, 180] loss: 0.338\n",
      "[27, 240] loss: 0.337\n",
      "[27, 300] loss: 0.344\n",
      "[27, 360] loss: 0.345\n",
      "Epoch: 27 -> Loss: 0.265610903502\n",
      "Epoch: 27 -> Test Accuracy: 85.1275\n",
      "[28, 60] loss: 0.330\n",
      "[28, 120] loss: 0.314\n",
      "[28, 180] loss: 0.334\n",
      "[28, 240] loss: 0.330\n",
      "[28, 300] loss: 0.337\n",
      "[28, 360] loss: 0.335\n",
      "Epoch: 28 -> Loss: 0.302782773972\n",
      "Epoch: 28 -> Test Accuracy: 85.97\n",
      "[29, 60] loss: 0.316\n",
      "[29, 120] loss: 0.325\n",
      "[29, 180] loss: 0.310\n",
      "[29, 240] loss: 0.336\n",
      "[29, 300] loss: 0.317\n",
      "[29, 360] loss: 0.341\n",
      "Epoch: 29 -> Loss: 0.344891965389\n",
      "Epoch: 29 -> Test Accuracy: 85.475\n",
      "[30, 60] loss: 0.313\n",
      "[30, 120] loss: 0.325\n",
      "[30, 180] loss: 0.329\n",
      "[30, 240] loss: 0.339\n",
      "[30, 300] loss: 0.321\n",
      "[30, 360] loss: 0.329\n",
      "Epoch: 30 -> Loss: 0.418658494949\n",
      "Epoch: 30 -> Test Accuracy: 86.5425\n",
      "[31, 60] loss: 0.319\n",
      "[31, 120] loss: 0.332\n",
      "[31, 180] loss: 0.330\n",
      "[31, 240] loss: 0.317\n",
      "[31, 300] loss: 0.334\n",
      "[31, 360] loss: 0.319\n",
      "Epoch: 31 -> Loss: 0.36334002018\n",
      "Epoch: 31 -> Test Accuracy: 85.93\n",
      "[32, 60] loss: 0.303\n",
      "[32, 120] loss: 0.335\n",
      "[32, 180] loss: 0.314\n",
      "[32, 240] loss: 0.328\n",
      "[32, 300] loss: 0.338\n",
      "[32, 360] loss: 0.327\n",
      "Epoch: 32 -> Loss: 0.276534199715\n",
      "Epoch: 32 -> Test Accuracy: 86.81\n",
      "[33, 60] loss: 0.305\n",
      "[33, 120] loss: 0.327\n",
      "[33, 180] loss: 0.310\n",
      "[33, 240] loss: 0.327\n",
      "[33, 300] loss: 0.324\n",
      "[33, 360] loss: 0.326\n",
      "Epoch: 33 -> Loss: 0.261321663857\n",
      "Epoch: 33 -> Test Accuracy: 86.7825\n",
      "[34, 60] loss: 0.304\n",
      "[34, 120] loss: 0.317\n",
      "[34, 180] loss: 0.323\n",
      "[34, 240] loss: 0.319\n",
      "[34, 300] loss: 0.330\n",
      "[34, 360] loss: 0.323\n",
      "Epoch: 34 -> Loss: 0.311412960291\n",
      "Epoch: 34 -> Test Accuracy: 86.44\n",
      "[35, 60] loss: 0.306\n",
      "[35, 120] loss: 0.310\n",
      "[35, 180] loss: 0.314\n",
      "[35, 240] loss: 0.327\n",
      "[35, 300] loss: 0.326\n",
      "[35, 360] loss: 0.325\n",
      "Epoch: 35 -> Loss: 0.432751357555\n",
      "Epoch: 35 -> Test Accuracy: 85.425\n",
      "[36, 60] loss: 0.322\n",
      "[36, 120] loss: 0.311\n",
      "[36, 180] loss: 0.328\n",
      "[36, 240] loss: 0.310\n",
      "[36, 300] loss: 0.325\n",
      "[36, 360] loss: 0.331\n",
      "Epoch: 36 -> Loss: 0.405208826065\n",
      "Epoch: 36 -> Test Accuracy: 85.8425\n",
      "[37, 60] loss: 0.310\n",
      "[37, 120] loss: 0.308\n",
      "[37, 180] loss: 0.317\n",
      "[37, 240] loss: 0.319\n",
      "[37, 300] loss: 0.308\n",
      "[37, 360] loss: 0.329\n",
      "Epoch: 37 -> Loss: 0.359218716621\n",
      "Epoch: 37 -> Test Accuracy: 85.845\n",
      "[38, 60] loss: 0.301\n",
      "[38, 120] loss: 0.317\n",
      "[38, 180] loss: 0.308\n",
      "[38, 240] loss: 0.315\n",
      "[38, 300] loss: 0.330\n",
      "[38, 360] loss: 0.319\n",
      "Epoch: 38 -> Loss: 0.222602963448\n",
      "Epoch: 38 -> Test Accuracy: 85.63\n",
      "[39, 60] loss: 0.297\n",
      "[39, 120] loss: 0.314\n",
      "[39, 180] loss: 0.320\n",
      "[39, 240] loss: 0.337\n",
      "[39, 300] loss: 0.317\n",
      "[39, 360] loss: 0.322\n",
      "Epoch: 39 -> Loss: 0.322008788586\n",
      "Epoch: 39 -> Test Accuracy: 86.6475\n",
      "[40, 60] loss: 0.305\n",
      "[40, 120] loss: 0.303\n",
      "[40, 180] loss: 0.314\n",
      "[40, 240] loss: 0.305\n",
      "[40, 300] loss: 0.306\n",
      "[40, 360] loss: 0.331\n",
      "Epoch: 40 -> Loss: 0.278406530619\n",
      "Epoch: 40 -> Test Accuracy: 86.005\n",
      "[41, 60] loss: 0.306\n",
      "[41, 120] loss: 0.313\n",
      "[41, 180] loss: 0.304\n",
      "[41, 240] loss: 0.321\n",
      "[41, 300] loss: 0.303\n",
      "[41, 360] loss: 0.318\n",
      "Epoch: 41 -> Loss: 0.420011907816\n",
      "Epoch: 41 -> Test Accuracy: 86.2\n",
      "[42, 60] loss: 0.311\n",
      "[42, 120] loss: 0.309\n",
      "[42, 180] loss: 0.317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 240] loss: 0.321\n",
      "[42, 300] loss: 0.307\n",
      "[42, 360] loss: 0.306\n",
      "Epoch: 42 -> Loss: 0.241120740771\n",
      "Epoch: 42 -> Test Accuracy: 86.5675\n",
      "[43, 60] loss: 0.306\n",
      "[43, 120] loss: 0.312\n",
      "[43, 180] loss: 0.303\n",
      "[43, 240] loss: 0.321\n",
      "[43, 300] loss: 0.322\n",
      "[43, 360] loss: 0.313\n",
      "Epoch: 43 -> Loss: 0.267006337643\n",
      "Epoch: 43 -> Test Accuracy: 86.4675\n",
      "[44, 60] loss: 0.299\n",
      "[44, 120] loss: 0.300\n",
      "[44, 180] loss: 0.332\n",
      "[44, 240] loss: 0.310\n",
      "[44, 300] loss: 0.308\n",
      "[44, 360] loss: 0.328\n",
      "Epoch: 44 -> Loss: 0.352603018284\n",
      "Epoch: 44 -> Test Accuracy: 85.515\n",
      "[45, 60] loss: 0.299\n",
      "[45, 120] loss: 0.322\n",
      "[45, 180] loss: 0.307\n",
      "[45, 240] loss: 0.322\n",
      "[45, 300] loss: 0.299\n",
      "[45, 360] loss: 0.317\n",
      "Epoch: 45 -> Loss: 0.194677904248\n",
      "Epoch: 45 -> Test Accuracy: 86.895\n",
      "[46, 60] loss: 0.309\n",
      "[46, 120] loss: 0.297\n",
      "[46, 180] loss: 0.317\n",
      "[46, 240] loss: 0.317\n",
      "[46, 300] loss: 0.318\n",
      "[46, 360] loss: 0.306\n",
      "Epoch: 46 -> Loss: 0.206796526909\n",
      "Epoch: 46 -> Test Accuracy: 87.08\n",
      "[47, 60] loss: 0.311\n",
      "[47, 120] loss: 0.304\n",
      "[47, 180] loss: 0.307\n",
      "[47, 240] loss: 0.314\n",
      "[47, 300] loss: 0.309\n",
      "[47, 360] loss: 0.313\n",
      "Epoch: 47 -> Loss: 0.310478836298\n",
      "Epoch: 47 -> Test Accuracy: 85.31\n",
      "[48, 60] loss: 0.297\n",
      "[48, 120] loss: 0.305\n",
      "[48, 180] loss: 0.312\n",
      "[48, 240] loss: 0.313\n",
      "[48, 300] loss: 0.300\n",
      "[48, 360] loss: 0.320\n",
      "Epoch: 48 -> Loss: 0.414184421301\n",
      "Epoch: 48 -> Test Accuracy: 86.3225\n",
      "[49, 60] loss: 0.305\n",
      "[49, 120] loss: 0.311\n",
      "[49, 180] loss: 0.308\n",
      "[49, 240] loss: 0.313\n",
      "[49, 300] loss: 0.318\n",
      "[49, 360] loss: 0.313\n",
      "Epoch: 49 -> Loss: 0.250473946333\n",
      "Epoch: 49 -> Test Accuracy: 86.505\n",
      "[50, 60] loss: 0.289\n",
      "[50, 120] loss: 0.316\n",
      "[50, 180] loss: 0.305\n",
      "[50, 240] loss: 0.304\n",
      "[50, 300] loss: 0.316\n",
      "[50, 360] loss: 0.305\n",
      "Epoch: 50 -> Loss: 0.384172022343\n",
      "Epoch: 50 -> Test Accuracy: 86.0625\n",
      "[51, 60] loss: 0.308\n",
      "[51, 120] loss: 0.293\n",
      "[51, 180] loss: 0.297\n",
      "[51, 240] loss: 0.316\n",
      "[51, 300] loss: 0.314\n",
      "[51, 360] loss: 0.307\n",
      "Epoch: 51 -> Loss: 0.319667994976\n",
      "Epoch: 51 -> Test Accuracy: 87.085\n",
      "[52, 60] loss: 0.299\n",
      "[52, 120] loss: 0.297\n",
      "[52, 180] loss: 0.317\n",
      "[52, 240] loss: 0.310\n",
      "[52, 300] loss: 0.316\n",
      "[52, 360] loss: 0.309\n",
      "Epoch: 52 -> Loss: 0.208092421293\n",
      "Epoch: 52 -> Test Accuracy: 86.5975\n",
      "[53, 60] loss: 0.293\n",
      "[53, 120] loss: 0.306\n",
      "[53, 180] loss: 0.299\n",
      "[53, 240] loss: 0.315\n",
      "[53, 300] loss: 0.317\n",
      "[53, 360] loss: 0.314\n",
      "Epoch: 53 -> Loss: 0.312608867884\n",
      "Epoch: 53 -> Test Accuracy: 86.9475\n",
      "[54, 60] loss: 0.295\n",
      "[54, 120] loss: 0.300\n",
      "[54, 180] loss: 0.310\n",
      "[54, 240] loss: 0.310\n",
      "[54, 300] loss: 0.308\n",
      "[54, 360] loss: 0.318\n",
      "Epoch: 54 -> Loss: 0.305385053158\n",
      "Epoch: 54 -> Test Accuracy: 87.325\n",
      "[55, 60] loss: 0.315\n",
      "[55, 120] loss: 0.311\n",
      "[55, 180] loss: 0.300\n",
      "[55, 240] loss: 0.295\n",
      "[55, 300] loss: 0.305\n",
      "[55, 360] loss: 0.313\n",
      "Epoch: 55 -> Loss: 0.559423089027\n",
      "Epoch: 55 -> Test Accuracy: 86.4075\n",
      "[56, 60] loss: 0.294\n",
      "[56, 120] loss: 0.293\n",
      "[56, 180] loss: 0.310\n",
      "[56, 240] loss: 0.309\n",
      "[56, 300] loss: 0.323\n",
      "[56, 360] loss: 0.307\n",
      "Epoch: 56 -> Loss: 0.393173635006\n",
      "Epoch: 56 -> Test Accuracy: 85.815\n",
      "[57, 60] loss: 0.299\n",
      "[57, 120] loss: 0.314\n",
      "[57, 180] loss: 0.301\n",
      "[57, 240] loss: 0.297\n",
      "[57, 300] loss: 0.313\n",
      "[57, 360] loss: 0.306\n",
      "Epoch: 57 -> Loss: 0.264588981867\n",
      "Epoch: 57 -> Test Accuracy: 86.0675\n",
      "[58, 60] loss: 0.286\n",
      "[58, 120] loss: 0.311\n",
      "[58, 180] loss: 0.298\n",
      "[58, 240] loss: 0.304\n",
      "[58, 300] loss: 0.304\n",
      "[58, 360] loss: 0.322\n",
      "Epoch: 58 -> Loss: 0.258608847857\n",
      "Epoch: 58 -> Test Accuracy: 87.2225\n",
      "[59, 60] loss: 0.292\n",
      "[59, 120] loss: 0.298\n",
      "[59, 180] loss: 0.311\n",
      "[59, 240] loss: 0.306\n",
      "[59, 300] loss: 0.309\n",
      "[59, 360] loss: 0.314\n",
      "Epoch: 59 -> Loss: 0.274384975433\n",
      "Epoch: 59 -> Test Accuracy: 87.1975\n",
      "[60, 60] loss: 0.290\n",
      "[60, 120] loss: 0.294\n",
      "[60, 180] loss: 0.301\n",
      "[60, 240] loss: 0.315\n",
      "[60, 300] loss: 0.309\n",
      "[60, 360] loss: 0.307\n",
      "Epoch: 60 -> Loss: 0.167207375169\n",
      "Epoch: 60 -> Test Accuracy: 87.3325\n",
      "[61, 60] loss: 0.230\n",
      "[61, 120] loss: 0.188\n",
      "[61, 180] loss: 0.194\n",
      "[61, 240] loss: 0.190\n",
      "[61, 300] loss: 0.190\n",
      "[61, 360] loss: 0.186\n",
      "Epoch: 61 -> Loss: 0.121815942228\n",
      "Epoch: 61 -> Test Accuracy: 91.025\n",
      "[62, 60] loss: 0.168\n",
      "[62, 120] loss: 0.169\n",
      "[62, 180] loss: 0.171\n",
      "[62, 240] loss: 0.175\n",
      "[62, 300] loss: 0.173\n",
      "[62, 360] loss: 0.164\n",
      "Epoch: 62 -> Loss: 0.149426415563\n",
      "Epoch: 62 -> Test Accuracy: 90.8125\n",
      "[63, 60] loss: 0.155\n",
      "[63, 120] loss: 0.164\n",
      "[63, 180] loss: 0.159\n",
      "[63, 240] loss: 0.162\n",
      "[63, 300] loss: 0.170\n",
      "[63, 360] loss: 0.157\n",
      "Epoch: 63 -> Loss: 0.188729017973\n",
      "Epoch: 63 -> Test Accuracy: 90.8675\n",
      "[64, 60] loss: 0.140\n",
      "[64, 120] loss: 0.151\n",
      "[64, 180] loss: 0.152\n",
      "[64, 240] loss: 0.163\n",
      "[64, 300] loss: 0.164\n",
      "[64, 360] loss: 0.153\n",
      "Epoch: 64 -> Loss: 0.155340895057\n",
      "Epoch: 64 -> Test Accuracy: 90.6625\n",
      "[65, 60] loss: 0.142\n",
      "[65, 120] loss: 0.152\n",
      "[65, 180] loss: 0.154\n",
      "[65, 240] loss: 0.154\n",
      "[65, 300] loss: 0.152\n",
      "[65, 360] loss: 0.155\n",
      "Epoch: 65 -> Loss: 0.145837962627\n",
      "Epoch: 65 -> Test Accuracy: 90.9075\n",
      "[66, 60] loss: 0.144\n",
      "[66, 120] loss: 0.148\n",
      "[66, 180] loss: 0.147\n",
      "[66, 240] loss: 0.147\n",
      "[66, 300] loss: 0.154\n",
      "[66, 360] loss: 0.151\n",
      "Epoch: 66 -> Loss: 0.133210048079\n",
      "Epoch: 66 -> Test Accuracy: 90.845\n",
      "[67, 60] loss: 0.143\n",
      "[67, 120] loss: 0.142\n",
      "[67, 180] loss: 0.142\n",
      "[67, 240] loss: 0.159\n",
      "[67, 300] loss: 0.153\n",
      "[67, 360] loss: 0.152\n",
      "Epoch: 67 -> Loss: 0.0641933083534\n",
      "Epoch: 67 -> Test Accuracy: 90.5575\n",
      "[68, 60] loss: 0.144\n",
      "[68, 120] loss: 0.141\n",
      "[68, 180] loss: 0.146\n",
      "[68, 240] loss: 0.148\n",
      "[68, 300] loss: 0.146\n",
      "[68, 360] loss: 0.151\n",
      "Epoch: 68 -> Loss: 0.0942502319813\n",
      "Epoch: 68 -> Test Accuracy: 90.7725\n",
      "[69, 60] loss: 0.131\n",
      "[69, 120] loss: 0.158\n",
      "[69, 180] loss: 0.147\n",
      "[69, 240] loss: 0.148\n",
      "[69, 300] loss: 0.155\n",
      "[69, 360] loss: 0.147\n",
      "Epoch: 69 -> Loss: 0.17575648427\n",
      "Epoch: 69 -> Test Accuracy: 90.505\n",
      "[70, 60] loss: 0.135\n",
      "[70, 120] loss: 0.140\n",
      "[70, 180] loss: 0.147\n",
      "[70, 240] loss: 0.155\n",
      "[70, 300] loss: 0.152\n",
      "[70, 360] loss: 0.154\n",
      "Epoch: 70 -> Loss: 0.145501196384\n",
      "Epoch: 70 -> Test Accuracy: 90.2675\n",
      "[71, 60] loss: 0.136\n",
      "[71, 120] loss: 0.139\n",
      "[71, 180] loss: 0.144\n",
      "[71, 240] loss: 0.150\n",
      "[71, 300] loss: 0.155\n",
      "[71, 360] loss: 0.154\n",
      "Epoch: 71 -> Loss: 0.160739764571\n",
      "Epoch: 71 -> Test Accuracy: 90.4125\n",
      "[72, 60] loss: 0.127\n",
      "[72, 120] loss: 0.144\n",
      "[72, 180] loss: 0.146\n",
      "[72, 240] loss: 0.157\n",
      "[72, 300] loss: 0.150\n",
      "[72, 360] loss: 0.162\n",
      "Epoch: 72 -> Loss: 0.143089413643\n",
      "Epoch: 72 -> Test Accuracy: 90.5975\n",
      "[73, 60] loss: 0.139\n",
      "[73, 120] loss: 0.151\n",
      "[73, 180] loss: 0.143\n",
      "[73, 240] loss: 0.145\n",
      "[73, 300] loss: 0.149\n",
      "[73, 360] loss: 0.163\n",
      "Epoch: 73 -> Loss: 0.190334349871\n",
      "Epoch: 73 -> Test Accuracy: 90.2\n",
      "[74, 60] loss: 0.133\n",
      "[74, 120] loss: 0.140\n",
      "[74, 180] loss: 0.145\n",
      "[74, 240] loss: 0.148\n",
      "[74, 300] loss: 0.157\n",
      "[74, 360] loss: 0.153\n",
      "Epoch: 74 -> Loss: 0.258821427822\n",
      "Epoch: 74 -> Test Accuracy: 90.2875\n",
      "[75, 60] loss: 0.136\n",
      "[75, 120] loss: 0.150\n",
      "[75, 180] loss: 0.149\n",
      "[75, 240] loss: 0.148\n",
      "[75, 300] loss: 0.151\n",
      "[75, 360] loss: 0.158\n",
      "Epoch: 75 -> Loss: 0.150803938508\n",
      "Epoch: 75 -> Test Accuracy: 90.3025\n",
      "[76, 60] loss: 0.141\n",
      "[76, 120] loss: 0.148\n",
      "[76, 180] loss: 0.151\n",
      "[76, 240] loss: 0.159\n",
      "[76, 300] loss: 0.157\n",
      "[76, 360] loss: 0.154\n",
      "Epoch: 76 -> Loss: 0.152088910341\n",
      "Epoch: 76 -> Test Accuracy: 90.755\n",
      "[77, 60] loss: 0.140\n",
      "[77, 120] loss: 0.149\n",
      "[77, 180] loss: 0.152\n",
      "[77, 240] loss: 0.150\n",
      "[77, 300] loss: 0.149\n",
      "[77, 360] loss: 0.150\n",
      "Epoch: 77 -> Loss: 0.140209496021\n",
      "Epoch: 77 -> Test Accuracy: 90.395\n",
      "[78, 60] loss: 0.135\n",
      "[78, 120] loss: 0.136\n",
      "[78, 180] loss: 0.163\n",
      "[78, 240] loss: 0.145\n",
      "[78, 300] loss: 0.154\n",
      "[78, 360] loss: 0.151\n",
      "Epoch: 78 -> Loss: 0.178333371878\n",
      "Epoch: 78 -> Test Accuracy: 90.465\n",
      "[79, 60] loss: 0.142\n",
      "[79, 120] loss: 0.143\n",
      "[79, 180] loss: 0.149\n",
      "[79, 240] loss: 0.146\n",
      "[79, 300] loss: 0.149\n",
      "[79, 360] loss: 0.168\n",
      "Epoch: 79 -> Loss: 0.0998848229647\n",
      "Epoch: 79 -> Test Accuracy: 90.3825\n",
      "[80, 60] loss: 0.132\n",
      "[80, 120] loss: 0.138\n",
      "[80, 180] loss: 0.156\n",
      "[80, 240] loss: 0.150\n",
      "[80, 300] loss: 0.157\n",
      "[80, 360] loss: 0.161\n",
      "Epoch: 80 -> Loss: 0.208413600922\n",
      "Epoch: 80 -> Test Accuracy: 90.155\n",
      "[81, 60] loss: 0.130\n",
      "[81, 120] loss: 0.153\n",
      "[81, 180] loss: 0.149\n",
      "[81, 240] loss: 0.151\n",
      "[81, 300] loss: 0.151\n",
      "[81, 360] loss: 0.153\n",
      "Epoch: 81 -> Loss: 0.146576553583\n",
      "Epoch: 81 -> Test Accuracy: 90.5925\n",
      "[82, 60] loss: 0.141\n",
      "[82, 120] loss: 0.145\n",
      "[82, 180] loss: 0.147\n",
      "[82, 240] loss: 0.148\n",
      "[82, 300] loss: 0.146\n",
      "[82, 360] loss: 0.156\n",
      "Epoch: 82 -> Loss: 0.0882002264261\n",
      "Epoch: 82 -> Test Accuracy: 90.28\n",
      "[83, 60] loss: 0.135\n",
      "[83, 120] loss: 0.145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83, 180] loss: 0.139\n",
      "[83, 240] loss: 0.148\n",
      "[83, 300] loss: 0.153\n",
      "[83, 360] loss: 0.155\n",
      "Epoch: 83 -> Loss: 0.18065674603\n",
      "Epoch: 83 -> Test Accuracy: 90.4\n",
      "[84, 60] loss: 0.132\n",
      "[84, 120] loss: 0.147\n",
      "[84, 180] loss: 0.150\n",
      "[84, 240] loss: 0.151\n",
      "[84, 300] loss: 0.150\n",
      "[84, 360] loss: 0.152\n",
      "Epoch: 84 -> Loss: 0.198366522789\n",
      "Epoch: 84 -> Test Accuracy: 90.0775\n",
      "[85, 60] loss: 0.142\n",
      "[85, 120] loss: 0.148\n",
      "[85, 180] loss: 0.138\n",
      "[85, 240] loss: 0.144\n",
      "[85, 300] loss: 0.151\n",
      "[85, 360] loss: 0.161\n",
      "Epoch: 85 -> Loss: 0.18511582911\n",
      "Epoch: 85 -> Test Accuracy: 90.5125\n",
      "[86, 60] loss: 0.139\n",
      "[86, 120] loss: 0.139\n",
      "[86, 180] loss: 0.145\n",
      "[86, 240] loss: 0.151\n",
      "[86, 300] loss: 0.147\n",
      "[86, 360] loss: 0.151\n",
      "Epoch: 86 -> Loss: 0.151367396116\n",
      "Epoch: 86 -> Test Accuracy: 90.2225\n",
      "[87, 60] loss: 0.129\n",
      "[87, 120] loss: 0.138\n",
      "[87, 180] loss: 0.147\n",
      "[87, 240] loss: 0.148\n",
      "[87, 300] loss: 0.165\n",
      "[87, 360] loss: 0.151\n",
      "Epoch: 87 -> Loss: 0.117181479931\n",
      "Epoch: 87 -> Test Accuracy: 90.3525\n",
      "[88, 60] loss: 0.145\n",
      "[88, 120] loss: 0.140\n",
      "[88, 180] loss: 0.145\n",
      "[88, 240] loss: 0.145\n",
      "[88, 300] loss: 0.149\n",
      "[88, 360] loss: 0.150\n",
      "Epoch: 88 -> Loss: 0.164308637381\n",
      "Epoch: 88 -> Test Accuracy: 90.335\n",
      "[89, 60] loss: 0.131\n",
      "[89, 120] loss: 0.145\n",
      "[89, 180] loss: 0.146\n",
      "[89, 240] loss: 0.154\n",
      "[89, 300] loss: 0.148\n",
      "[89, 360] loss: 0.143\n",
      "Epoch: 89 -> Loss: 0.186853975058\n",
      "Epoch: 89 -> Test Accuracy: 89.7725\n",
      "[90, 60] loss: 0.131\n",
      "[90, 120] loss: 0.150\n",
      "[90, 180] loss: 0.140\n",
      "[90, 240] loss: 0.139\n",
      "[90, 300] loss: 0.149\n",
      "[90, 360] loss: 0.154\n",
      "Epoch: 90 -> Loss: 0.0945761650801\n",
      "Epoch: 90 -> Test Accuracy: 90.56\n",
      "[91, 60] loss: 0.121\n",
      "[91, 120] loss: 0.144\n",
      "[91, 180] loss: 0.151\n",
      "[91, 240] loss: 0.135\n",
      "[91, 300] loss: 0.150\n",
      "[91, 360] loss: 0.151\n",
      "Epoch: 91 -> Loss: 0.13092713058\n",
      "Epoch: 91 -> Test Accuracy: 90.455\n",
      "[92, 60] loss: 0.132\n",
      "[92, 120] loss: 0.131\n",
      "[92, 180] loss: 0.147\n",
      "[92, 240] loss: 0.146\n",
      "[92, 300] loss: 0.153\n",
      "[92, 360] loss: 0.149\n",
      "Epoch: 92 -> Loss: 0.129557222128\n",
      "Epoch: 92 -> Test Accuracy: 90.0525\n",
      "[93, 60] loss: 0.132\n",
      "[93, 120] loss: 0.137\n",
      "[93, 180] loss: 0.141\n",
      "[93, 240] loss: 0.152\n",
      "[93, 300] loss: 0.144\n",
      "[93, 360] loss: 0.150\n",
      "Epoch: 93 -> Loss: 0.165919333696\n",
      "Epoch: 93 -> Test Accuracy: 90.475\n",
      "[94, 60] loss: 0.135\n",
      "[94, 120] loss: 0.133\n",
      "[94, 180] loss: 0.146\n",
      "[94, 240] loss: 0.138\n",
      "[94, 300] loss: 0.141\n",
      "[94, 360] loss: 0.154\n",
      "Epoch: 94 -> Loss: 0.133956596255\n",
      "Epoch: 94 -> Test Accuracy: 90.6425\n",
      "[95, 60] loss: 0.136\n",
      "[95, 120] loss: 0.141\n",
      "[95, 180] loss: 0.140\n",
      "[95, 240] loss: 0.139\n",
      "[95, 300] loss: 0.143\n",
      "[95, 360] loss: 0.154\n",
      "Epoch: 95 -> Loss: 0.0965797305107\n",
      "Epoch: 95 -> Test Accuracy: 90.4\n",
      "[96, 60] loss: 0.130\n",
      "[96, 120] loss: 0.138\n",
      "[96, 180] loss: 0.141\n",
      "[96, 240] loss: 0.146\n",
      "[96, 300] loss: 0.142\n",
      "[96, 360] loss: 0.147\n",
      "Epoch: 96 -> Loss: 0.190542817116\n",
      "Epoch: 96 -> Test Accuracy: 90.415\n",
      "[97, 60] loss: 0.131\n",
      "[97, 120] loss: 0.140\n",
      "[97, 180] loss: 0.144\n",
      "[97, 240] loss: 0.145\n",
      "[97, 300] loss: 0.148\n",
      "[97, 360] loss: 0.141\n",
      "Epoch: 97 -> Loss: 0.213080212474\n",
      "Epoch: 97 -> Test Accuracy: 90.3375\n",
      "[98, 60] loss: 0.130\n",
      "[98, 120] loss: 0.138\n",
      "[98, 180] loss: 0.135\n",
      "[98, 240] loss: 0.142\n",
      "[98, 300] loss: 0.144\n",
      "[98, 360] loss: 0.140\n",
      "Epoch: 98 -> Loss: 0.154670402408\n",
      "Epoch: 98 -> Test Accuracy: 90.3075\n",
      "[99, 60] loss: 0.133\n",
      "[99, 120] loss: 0.132\n",
      "[99, 180] loss: 0.134\n",
      "[99, 240] loss: 0.146\n",
      "[99, 300] loss: 0.135\n",
      "[99, 360] loss: 0.148\n",
      "Epoch: 99 -> Loss: 0.189413577318\n",
      "Epoch: 99 -> Test Accuracy: 90.3775\n",
      "[100, 60] loss: 0.133\n",
      "[100, 120] loss: 0.135\n",
      "[100, 180] loss: 0.139\n",
      "[100, 240] loss: 0.143\n",
      "[100, 300] loss: 0.131\n",
      "[100, 360] loss: 0.144\n",
      "Epoch: 100 -> Loss: 0.109761953354\n",
      "Epoch: 100 -> Test Accuracy: 90.3175\n",
      "[101, 60] loss: 0.130\n",
      "[101, 120] loss: 0.134\n",
      "[101, 180] loss: 0.141\n",
      "[101, 240] loss: 0.140\n",
      "[101, 300] loss: 0.150\n",
      "[101, 360] loss: 0.141\n",
      "Epoch: 101 -> Loss: 0.0699058398604\n",
      "Epoch: 101 -> Test Accuracy: 90.15\n",
      "[102, 60] loss: 0.126\n",
      "[102, 120] loss: 0.135\n",
      "[102, 180] loss: 0.131\n",
      "[102, 240] loss: 0.139\n",
      "[102, 300] loss: 0.146\n",
      "[102, 360] loss: 0.152\n",
      "Epoch: 102 -> Loss: 0.11371409893\n",
      "Epoch: 102 -> Test Accuracy: 90.005\n",
      "[103, 60] loss: 0.130\n",
      "[103, 120] loss: 0.146\n",
      "[103, 180] loss: 0.126\n",
      "[103, 240] loss: 0.138\n",
      "[103, 300] loss: 0.146\n",
      "[103, 360] loss: 0.146\n",
      "Epoch: 103 -> Loss: 0.187924802303\n",
      "Epoch: 103 -> Test Accuracy: 90.255\n",
      "[104, 60] loss: 0.128\n",
      "[104, 120] loss: 0.134\n",
      "[104, 180] loss: 0.144\n",
      "[104, 240] loss: 0.136\n",
      "[104, 300] loss: 0.140\n",
      "[104, 360] loss: 0.145\n",
      "Epoch: 104 -> Loss: 0.204277127981\n",
      "Epoch: 104 -> Test Accuracy: 90.105\n",
      "[105, 60] loss: 0.135\n",
      "[105, 120] loss: 0.138\n",
      "[105, 180] loss: 0.134\n",
      "[105, 240] loss: 0.140\n",
      "[105, 300] loss: 0.147\n",
      "[105, 360] loss: 0.135\n",
      "Epoch: 105 -> Loss: 0.118173874915\n",
      "Epoch: 105 -> Test Accuracy: 89.8175\n",
      "[106, 60] loss: 0.128\n",
      "[106, 120] loss: 0.136\n",
      "[106, 180] loss: 0.135\n",
      "[106, 240] loss: 0.145\n",
      "[106, 300] loss: 0.142\n",
      "[106, 360] loss: 0.137\n",
      "Epoch: 106 -> Loss: 0.139957457781\n",
      "Epoch: 106 -> Test Accuracy: 90.6825\n",
      "[107, 60] loss: 0.119\n",
      "[107, 120] loss: 0.133\n",
      "[107, 180] loss: 0.136\n",
      "[107, 240] loss: 0.141\n",
      "[107, 300] loss: 0.137\n",
      "[107, 360] loss: 0.141\n",
      "Epoch: 107 -> Loss: 0.139363884926\n",
      "Epoch: 107 -> Test Accuracy: 89.9775\n",
      "[108, 60] loss: 0.122\n",
      "[108, 120] loss: 0.133\n",
      "[108, 180] loss: 0.140\n",
      "[108, 240] loss: 0.141\n",
      "[108, 300] loss: 0.144\n",
      "[108, 360] loss: 0.145\n",
      "Epoch: 108 -> Loss: 0.103750787675\n",
      "Epoch: 108 -> Test Accuracy: 90.4425\n",
      "[109, 60] loss: 0.126\n",
      "[109, 120] loss: 0.132\n",
      "[109, 180] loss: 0.132\n",
      "[109, 240] loss: 0.137\n",
      "[109, 300] loss: 0.138\n",
      "[109, 360] loss: 0.150\n",
      "Epoch: 109 -> Loss: 0.111662790179\n",
      "Epoch: 109 -> Test Accuracy: 89.97\n",
      "[110, 60] loss: 0.121\n",
      "[110, 120] loss: 0.131\n",
      "[110, 180] loss: 0.142\n",
      "[110, 240] loss: 0.134\n",
      "[110, 300] loss: 0.135\n",
      "[110, 360] loss: 0.152\n",
      "Epoch: 110 -> Loss: 0.18588103354\n",
      "Epoch: 110 -> Test Accuracy: 90.385\n",
      "[111, 60] loss: 0.129\n",
      "[111, 120] loss: 0.132\n",
      "[111, 180] loss: 0.143\n",
      "[111, 240] loss: 0.137\n",
      "[111, 300] loss: 0.138\n",
      "[111, 360] loss: 0.134\n",
      "Epoch: 111 -> Loss: 0.162824645638\n",
      "Epoch: 111 -> Test Accuracy: 90.5025\n",
      "[112, 60] loss: 0.131\n",
      "[112, 120] loss: 0.133\n",
      "[112, 180] loss: 0.138\n",
      "[112, 240] loss: 0.133\n",
      "[112, 300] loss: 0.144\n",
      "[112, 360] loss: 0.151\n",
      "Epoch: 112 -> Loss: 0.115757800639\n",
      "Epoch: 112 -> Test Accuracy: 89.785\n",
      "[113, 60] loss: 0.130\n",
      "[113, 120] loss: 0.130\n",
      "[113, 180] loss: 0.136\n",
      "[113, 240] loss: 0.136\n",
      "[113, 300] loss: 0.144\n",
      "[113, 360] loss: 0.137\n",
      "Epoch: 113 -> Loss: 0.250837028027\n",
      "Epoch: 113 -> Test Accuracy: 90.225\n",
      "[114, 60] loss: 0.118\n",
      "[114, 120] loss: 0.136\n",
      "[114, 180] loss: 0.134\n",
      "[114, 240] loss: 0.138\n",
      "[114, 300] loss: 0.139\n",
      "[114, 360] loss: 0.141\n",
      "Epoch: 114 -> Loss: 0.108648277819\n",
      "Epoch: 114 -> Test Accuracy: 90.045\n",
      "[115, 60] loss: 0.130\n",
      "[115, 120] loss: 0.129\n",
      "[115, 180] loss: 0.134\n",
      "[115, 240] loss: 0.131\n",
      "[115, 300] loss: 0.138\n",
      "[115, 360] loss: 0.135\n",
      "Epoch: 115 -> Loss: 0.200071722269\n",
      "Epoch: 115 -> Test Accuracy: 90.225\n",
      "[116, 60] loss: 0.131\n",
      "[116, 120] loss: 0.130\n",
      "[116, 180] loss: 0.130\n",
      "[116, 240] loss: 0.137\n",
      "[116, 300] loss: 0.136\n",
      "[116, 360] loss: 0.134\n",
      "Epoch: 116 -> Loss: 0.122171841562\n",
      "Epoch: 116 -> Test Accuracy: 90.5875\n",
      "[117, 60] loss: 0.124\n",
      "[117, 120] loss: 0.128\n",
      "[117, 180] loss: 0.137\n",
      "[117, 240] loss: 0.144\n",
      "[117, 300] loss: 0.134\n",
      "[117, 360] loss: 0.141\n",
      "Epoch: 117 -> Loss: 0.15997235477\n",
      "Epoch: 117 -> Test Accuracy: 90.6325\n",
      "[118, 60] loss: 0.121\n",
      "[118, 120] loss: 0.119\n",
      "[118, 180] loss: 0.133\n",
      "[118, 240] loss: 0.135\n",
      "[118, 300] loss: 0.148\n",
      "[118, 360] loss: 0.136\n",
      "Epoch: 118 -> Loss: 0.130268320441\n",
      "Epoch: 118 -> Test Accuracy: 90.25\n",
      "[119, 60] loss: 0.132\n",
      "[119, 120] loss: 0.127\n",
      "[119, 180] loss: 0.136\n",
      "[119, 240] loss: 0.142\n",
      "[119, 300] loss: 0.131\n",
      "[119, 360] loss: 0.137\n",
      "Epoch: 119 -> Loss: 0.13190934062\n",
      "Epoch: 119 -> Test Accuracy: 89.9075\n",
      "[120, 60] loss: 0.127\n",
      "[120, 120] loss: 0.130\n",
      "[120, 180] loss: 0.130\n",
      "[120, 240] loss: 0.132\n",
      "[120, 300] loss: 0.135\n",
      "[120, 360] loss: 0.143\n",
      "Epoch: 120 -> Loss: 0.134467303753\n",
      "Epoch: 120 -> Test Accuracy: 90.1375\n",
      "[121, 60] loss: 0.090\n",
      "[121, 120] loss: 0.074\n",
      "[121, 180] loss: 0.074\n",
      "[121, 240] loss: 0.068\n",
      "[121, 300] loss: 0.066\n",
      "[121, 360] loss: 0.063\n",
      "Epoch: 121 -> Loss: 0.0539233498275\n",
      "Epoch: 121 -> Test Accuracy: 92.1425\n",
      "[122, 60] loss: 0.057\n",
      "[122, 120] loss: 0.054\n",
      "[122, 180] loss: 0.050\n",
      "[122, 240] loss: 0.053\n",
      "[122, 300] loss: 0.058\n",
      "[122, 360] loss: 0.055\n",
      "Epoch: 122 -> Loss: 0.0233521722257\n",
      "Epoch: 122 -> Test Accuracy: 92.295\n",
      "[123, 60] loss: 0.046\n",
      "[123, 120] loss: 0.049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123, 180] loss: 0.043\n",
      "[123, 240] loss: 0.049\n",
      "[123, 300] loss: 0.051\n",
      "[123, 360] loss: 0.051\n",
      "Epoch: 123 -> Loss: 0.0513493791223\n",
      "Epoch: 123 -> Test Accuracy: 91.96\n",
      "[124, 60] loss: 0.042\n",
      "[124, 120] loss: 0.046\n",
      "[124, 180] loss: 0.044\n",
      "[124, 240] loss: 0.045\n",
      "[124, 300] loss: 0.044\n",
      "[124, 360] loss: 0.048\n",
      "Epoch: 124 -> Loss: 0.0551013723016\n",
      "Epoch: 124 -> Test Accuracy: 91.9875\n",
      "[125, 60] loss: 0.041\n",
      "[125, 120] loss: 0.039\n",
      "[125, 180] loss: 0.041\n",
      "[125, 240] loss: 0.042\n",
      "[125, 300] loss: 0.043\n",
      "[125, 360] loss: 0.037\n",
      "Epoch: 125 -> Loss: 0.0373148061335\n",
      "Epoch: 125 -> Test Accuracy: 91.975\n",
      "[126, 60] loss: 0.035\n",
      "[126, 120] loss: 0.037\n",
      "[126, 180] loss: 0.036\n",
      "[126, 240] loss: 0.037\n",
      "[126, 300] loss: 0.039\n",
      "[126, 360] loss: 0.039\n",
      "Epoch: 126 -> Loss: 0.017912235111\n",
      "Epoch: 126 -> Test Accuracy: 91.9475\n",
      "[127, 60] loss: 0.037\n",
      "[127, 120] loss: 0.036\n",
      "[127, 180] loss: 0.034\n",
      "[127, 240] loss: 0.033\n",
      "[127, 300] loss: 0.037\n",
      "[127, 360] loss: 0.041\n",
      "Epoch: 127 -> Loss: 0.0344842784107\n",
      "Epoch: 127 -> Test Accuracy: 91.7075\n",
      "[128, 60] loss: 0.033\n",
      "[128, 120] loss: 0.030\n",
      "[128, 180] loss: 0.035\n",
      "[128, 240] loss: 0.035\n",
      "[128, 300] loss: 0.037\n",
      "[128, 360] loss: 0.035\n",
      "Epoch: 128 -> Loss: 0.0184338204563\n",
      "Epoch: 128 -> Test Accuracy: 91.935\n",
      "[129, 60] loss: 0.032\n",
      "[129, 120] loss: 0.035\n",
      "[129, 180] loss: 0.033\n",
      "[129, 240] loss: 0.033\n",
      "[129, 300] loss: 0.037\n",
      "[129, 360] loss: 0.035\n",
      "Epoch: 129 -> Loss: 0.0266400780529\n",
      "Epoch: 129 -> Test Accuracy: 91.99\n",
      "[130, 60] loss: 0.032\n",
      "[130, 120] loss: 0.033\n",
      "[130, 180] loss: 0.032\n",
      "[130, 240] loss: 0.034\n",
      "[130, 300] loss: 0.031\n",
      "[130, 360] loss: 0.033\n",
      "Epoch: 130 -> Loss: 0.0388426408172\n",
      "Epoch: 130 -> Test Accuracy: 91.8125\n",
      "[131, 60] loss: 0.031\n",
      "[131, 120] loss: 0.033\n",
      "[131, 180] loss: 0.031\n",
      "[131, 240] loss: 0.032\n",
      "[131, 300] loss: 0.032\n",
      "[131, 360] loss: 0.031\n",
      "Epoch: 131 -> Loss: 0.0234437473118\n",
      "Epoch: 131 -> Test Accuracy: 91.8775\n",
      "[132, 60] loss: 0.029\n",
      "[132, 120] loss: 0.032\n",
      "[132, 180] loss: 0.031\n",
      "[132, 240] loss: 0.030\n",
      "[132, 300] loss: 0.032\n",
      "[132, 360] loss: 0.032\n",
      "Epoch: 132 -> Loss: 0.0384026989341\n",
      "Epoch: 132 -> Test Accuracy: 91.945\n",
      "[133, 60] loss: 0.028\n",
      "[133, 120] loss: 0.030\n",
      "[133, 180] loss: 0.029\n",
      "[133, 240] loss: 0.034\n",
      "[133, 300] loss: 0.028\n",
      "[133, 360] loss: 0.029\n",
      "Epoch: 133 -> Loss: 0.0894324406981\n",
      "Epoch: 133 -> Test Accuracy: 91.9475\n",
      "[134, 60] loss: 0.027\n",
      "[134, 120] loss: 0.030\n",
      "[134, 180] loss: 0.029\n",
      "[134, 240] loss: 0.032\n",
      "[134, 300] loss: 0.031\n",
      "[134, 360] loss: 0.029\n",
      "Epoch: 134 -> Loss: 0.0506775975227\n",
      "Epoch: 134 -> Test Accuracy: 91.6625\n",
      "[135, 60] loss: 0.030\n",
      "[135, 120] loss: 0.028\n",
      "[135, 180] loss: 0.027\n",
      "[135, 240] loss: 0.031\n",
      "[135, 300] loss: 0.031\n",
      "[135, 360] loss: 0.034\n",
      "Epoch: 135 -> Loss: 0.0219914931804\n",
      "Epoch: 135 -> Test Accuracy: 91.495\n",
      "[136, 60] loss: 0.025\n",
      "[136, 120] loss: 0.027\n",
      "[136, 180] loss: 0.030\n",
      "[136, 240] loss: 0.030\n",
      "[136, 300] loss: 0.028\n",
      "[136, 360] loss: 0.033\n",
      "Epoch: 136 -> Loss: 0.030540894717\n",
      "Epoch: 136 -> Test Accuracy: 91.9775\n",
      "[137, 60] loss: 0.029\n",
      "[137, 120] loss: 0.025\n",
      "[137, 180] loss: 0.028\n",
      "[137, 240] loss: 0.030\n",
      "[137, 300] loss: 0.035\n",
      "[137, 360] loss: 0.029\n",
      "Epoch: 137 -> Loss: 0.0237850286067\n",
      "Epoch: 137 -> Test Accuracy: 91.345\n",
      "[138, 60] loss: 0.027\n",
      "[138, 120] loss: 0.024\n",
      "[138, 180] loss: 0.027\n",
      "[138, 240] loss: 0.030\n",
      "[138, 300] loss: 0.030\n",
      "[138, 360] loss: 0.032\n",
      "Epoch: 138 -> Loss: 0.0134180439636\n",
      "Epoch: 138 -> Test Accuracy: 91.5825\n",
      "[139, 60] loss: 0.026\n",
      "[139, 120] loss: 0.026\n",
      "[139, 180] loss: 0.029\n",
      "[139, 240] loss: 0.027\n",
      "[139, 300] loss: 0.030\n",
      "[139, 360] loss: 0.029\n",
      "Epoch: 139 -> Loss: 0.0287095867097\n",
      "Epoch: 139 -> Test Accuracy: 91.4725\n",
      "[140, 60] loss: 0.027\n",
      "[140, 120] loss: 0.024\n",
      "[140, 180] loss: 0.028\n",
      "[140, 240] loss: 0.028\n",
      "[140, 300] loss: 0.031\n",
      "[140, 360] loss: 0.030\n",
      "Epoch: 140 -> Loss: 0.0200080312788\n",
      "Epoch: 140 -> Test Accuracy: 91.865\n",
      "[141, 60] loss: 0.024\n",
      "[141, 120] loss: 0.027\n",
      "[141, 180] loss: 0.024\n",
      "[141, 240] loss: 0.026\n",
      "[141, 300] loss: 0.028\n",
      "[141, 360] loss: 0.030\n",
      "Epoch: 141 -> Loss: 0.0351887270808\n",
      "Epoch: 141 -> Test Accuracy: 91.5025\n",
      "[142, 60] loss: 0.029\n",
      "[142, 120] loss: 0.029\n",
      "[142, 180] loss: 0.031\n",
      "[142, 240] loss: 0.030\n",
      "[142, 300] loss: 0.031\n",
      "[142, 360] loss: 0.028\n",
      "Epoch: 142 -> Loss: 0.0317451432347\n",
      "Epoch: 142 -> Test Accuracy: 91.265\n",
      "[143, 60] loss: 0.025\n",
      "[143, 120] loss: 0.026\n",
      "[143, 180] loss: 0.027\n",
      "[143, 240] loss: 0.028\n",
      "[143, 300] loss: 0.030\n",
      "[143, 360] loss: 0.032\n",
      "Epoch: 143 -> Loss: 0.00827003456652\n",
      "Epoch: 143 -> Test Accuracy: 91.6425\n",
      "[144, 60] loss: 0.025\n",
      "[144, 120] loss: 0.027\n",
      "[144, 180] loss: 0.027\n",
      "[144, 240] loss: 0.032\n",
      "[144, 300] loss: 0.028\n",
      "[144, 360] loss: 0.030\n",
      "Epoch: 144 -> Loss: 0.0257267411798\n",
      "Epoch: 144 -> Test Accuracy: 91.505\n",
      "[145, 60] loss: 0.024\n",
      "[145, 120] loss: 0.026\n",
      "[145, 180] loss: 0.029\n",
      "[145, 240] loss: 0.029\n",
      "[145, 300] loss: 0.031\n",
      "[145, 360] loss: 0.031\n",
      "Epoch: 145 -> Loss: 0.0242836289108\n",
      "Epoch: 145 -> Test Accuracy: 91.25\n",
      "[146, 60] loss: 0.027\n",
      "[146, 120] loss: 0.025\n",
      "[146, 180] loss: 0.027\n",
      "[146, 240] loss: 0.028\n",
      "[146, 300] loss: 0.029\n",
      "[146, 360] loss: 0.028\n",
      "Epoch: 146 -> Loss: 0.0233608279377\n",
      "Epoch: 146 -> Test Accuracy: 91.2325\n",
      "[147, 60] loss: 0.027\n",
      "[147, 120] loss: 0.028\n",
      "[147, 180] loss: 0.030\n",
      "[147, 240] loss: 0.027\n",
      "[147, 300] loss: 0.032\n",
      "[147, 360] loss: 0.030\n",
      "Epoch: 147 -> Loss: 0.0254440959543\n",
      "Epoch: 147 -> Test Accuracy: 91.21\n",
      "[148, 60] loss: 0.027\n",
      "[148, 120] loss: 0.029\n",
      "[148, 180] loss: 0.028\n",
      "[148, 240] loss: 0.029\n",
      "[148, 300] loss: 0.034\n",
      "[148, 360] loss: 0.033\n",
      "Epoch: 148 -> Loss: 0.0097988191992\n",
      "Epoch: 148 -> Test Accuracy: 91.8\n",
      "[149, 60] loss: 0.027\n",
      "[149, 120] loss: 0.026\n",
      "[149, 180] loss: 0.028\n",
      "[149, 240] loss: 0.030\n",
      "[149, 300] loss: 0.027\n",
      "[149, 360] loss: 0.032\n",
      "Epoch: 149 -> Loss: 0.061853133142\n",
      "Epoch: 149 -> Test Accuracy: 91.665\n",
      "[150, 60] loss: 0.028\n",
      "[150, 120] loss: 0.027\n",
      "[150, 180] loss: 0.028\n",
      "[150, 240] loss: 0.026\n",
      "[150, 300] loss: 0.033\n",
      "[150, 360] loss: 0.031\n",
      "Epoch: 150 -> Loss: 0.0474155321717\n",
      "Epoch: 150 -> Test Accuracy: 91.545\n",
      "[151, 60] loss: 0.028\n",
      "[151, 120] loss: 0.027\n",
      "[151, 180] loss: 0.028\n",
      "[151, 240] loss: 0.028\n",
      "[151, 300] loss: 0.027\n",
      "[151, 360] loss: 0.031\n",
      "Epoch: 151 -> Loss: 0.015008283779\n",
      "Epoch: 151 -> Test Accuracy: 91.485\n",
      "[152, 60] loss: 0.027\n",
      "[152, 120] loss: 0.026\n",
      "[152, 180] loss: 0.026\n",
      "[152, 240] loss: 0.029\n",
      "[152, 300] loss: 0.029\n",
      "[152, 360] loss: 0.031\n",
      "Epoch: 152 -> Loss: 0.0305122174323\n",
      "Epoch: 152 -> Test Accuracy: 91.17\n",
      "[153, 60] loss: 0.027\n",
      "[153, 120] loss: 0.026\n",
      "[153, 180] loss: 0.029\n",
      "[153, 240] loss: 0.032\n",
      "[153, 300] loss: 0.028\n",
      "[153, 360] loss: 0.032\n",
      "Epoch: 153 -> Loss: 0.0333011373878\n",
      "Epoch: 153 -> Test Accuracy: 91.6525\n",
      "[154, 60] loss: 0.029\n",
      "[154, 120] loss: 0.030\n",
      "[154, 180] loss: 0.029\n",
      "[154, 240] loss: 0.030\n",
      "[154, 300] loss: 0.030\n",
      "[154, 360] loss: 0.034\n",
      "Epoch: 154 -> Loss: 0.0124064907432\n",
      "Epoch: 154 -> Test Accuracy: 91.3575\n",
      "[155, 60] loss: 0.030\n",
      "[155, 120] loss: 0.029\n",
      "[155, 180] loss: 0.029\n",
      "[155, 240] loss: 0.033\n",
      "[155, 300] loss: 0.031\n",
      "[155, 360] loss: 0.034\n",
      "Epoch: 155 -> Loss: 0.0560123622417\n",
      "Epoch: 155 -> Test Accuracy: 91.37\n",
      "[156, 60] loss: 0.029\n",
      "[156, 120] loss: 0.026\n",
      "[156, 180] loss: 0.030\n",
      "[156, 240] loss: 0.028\n",
      "[156, 300] loss: 0.036\n",
      "[156, 360] loss: 0.030\n",
      "Epoch: 156 -> Loss: 0.0142730679363\n",
      "Epoch: 156 -> Test Accuracy: 91.6175\n",
      "[157, 60] loss: 0.028\n",
      "[157, 120] loss: 0.027\n",
      "[157, 180] loss: 0.028\n",
      "[157, 240] loss: 0.029\n",
      "[157, 300] loss: 0.029\n",
      "[157, 360] loss: 0.031\n",
      "Epoch: 157 -> Loss: 0.0303398612887\n",
      "Epoch: 157 -> Test Accuracy: 91.3175\n",
      "[158, 60] loss: 0.026\n",
      "[158, 120] loss: 0.028\n",
      "[158, 180] loss: 0.031\n",
      "[158, 240] loss: 0.031\n",
      "[158, 300] loss: 0.034\n",
      "[158, 360] loss: 0.030\n",
      "Epoch: 158 -> Loss: 0.0294480510056\n",
      "Epoch: 158 -> Test Accuracy: 91.16\n",
      "[159, 60] loss: 0.025\n",
      "[159, 120] loss: 0.026\n",
      "[159, 180] loss: 0.029\n",
      "[159, 240] loss: 0.032\n",
      "[159, 300] loss: 0.030\n",
      "[159, 360] loss: 0.030\n",
      "Epoch: 159 -> Loss: 0.0503417737782\n",
      "Epoch: 159 -> Test Accuracy: 91.1925\n",
      "[160, 60] loss: 0.027\n",
      "[160, 120] loss: 0.030\n",
      "[160, 180] loss: 0.032\n",
      "[160, 240] loss: 0.028\n",
      "[160, 300] loss: 0.033\n",
      "[160, 360] loss: 0.033\n",
      "Epoch: 160 -> Loss: 0.0513433106244\n",
      "Epoch: 160 -> Test Accuracy: 91.23\n",
      "[161, 60] loss: 0.028\n",
      "[161, 120] loss: 0.019\n",
      "[161, 180] loss: 0.017\n",
      "[161, 240] loss: 0.016\n",
      "[161, 300] loss: 0.015\n",
      "[161, 360] loss: 0.015\n",
      "Epoch: 161 -> Loss: 0.0029222802259\n",
      "Epoch: 161 -> Test Accuracy: 92.025\n",
      "[162, 60] loss: 0.013\n",
      "[162, 120] loss: 0.012\n",
      "[162, 180] loss: 0.013\n",
      "[162, 240] loss: 0.012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[162, 300] loss: 0.012\n",
      "[162, 360] loss: 0.013\n",
      "Epoch: 162 -> Loss: 0.0210941005498\n",
      "Epoch: 162 -> Test Accuracy: 92.0025\n",
      "[163, 60] loss: 0.011\n",
      "[163, 120] loss: 0.010\n",
      "[163, 180] loss: 0.011\n",
      "[163, 240] loss: 0.011\n",
      "[163, 300] loss: 0.010\n",
      "[163, 360] loss: 0.011\n",
      "Epoch: 163 -> Loss: 0.0141010284424\n",
      "Epoch: 163 -> Test Accuracy: 92.0225\n",
      "[164, 60] loss: 0.009\n",
      "[164, 120] loss: 0.010\n",
      "[164, 180] loss: 0.010\n",
      "[164, 240] loss: 0.010\n",
      "[164, 300] loss: 0.010\n",
      "[164, 360] loss: 0.010\n",
      "Epoch: 164 -> Loss: 0.00539414072409\n",
      "Epoch: 164 -> Test Accuracy: 92.105\n",
      "[165, 60] loss: 0.010\n",
      "[165, 120] loss: 0.009\n",
      "[165, 180] loss: 0.009\n",
      "[165, 240] loss: 0.008\n",
      "[165, 300] loss: 0.010\n",
      "[165, 360] loss: 0.009\n",
      "Epoch: 165 -> Loss: 0.0214394032955\n",
      "Epoch: 165 -> Test Accuracy: 92.1225\n",
      "[166, 60] loss: 0.009\n",
      "[166, 120] loss: 0.008\n",
      "[166, 180] loss: 0.009\n",
      "[166, 240] loss: 0.008\n",
      "[166, 300] loss: 0.009\n",
      "[166, 360] loss: 0.009\n",
      "Epoch: 166 -> Loss: 0.00584331573918\n",
      "Epoch: 166 -> Test Accuracy: 92.1\n",
      "[167, 60] loss: 0.008\n",
      "[167, 120] loss: 0.008\n",
      "[167, 180] loss: 0.009\n",
      "[167, 240] loss: 0.009\n",
      "[167, 300] loss: 0.008\n",
      "[167, 360] loss: 0.008\n",
      "Epoch: 167 -> Loss: 0.00620787916705\n",
      "Epoch: 167 -> Test Accuracy: 92.0725\n",
      "[168, 60] loss: 0.008\n",
      "[168, 120] loss: 0.007\n",
      "[168, 180] loss: 0.007\n",
      "[168, 240] loss: 0.008\n",
      "[168, 300] loss: 0.008\n",
      "[168, 360] loss: 0.008\n",
      "Epoch: 168 -> Loss: 0.00278404494748\n",
      "Epoch: 168 -> Test Accuracy: 92.13\n",
      "[169, 60] loss: 0.007\n",
      "[169, 120] loss: 0.008\n",
      "[169, 180] loss: 0.008\n",
      "[169, 240] loss: 0.009\n",
      "[169, 300] loss: 0.008\n",
      "[169, 360] loss: 0.008\n",
      "Epoch: 169 -> Loss: 0.00760257150978\n",
      "Epoch: 169 -> Test Accuracy: 92.11\n",
      "[170, 60] loss: 0.008\n",
      "[170, 120] loss: 0.007\n",
      "[170, 180] loss: 0.007\n",
      "[170, 240] loss: 0.008\n",
      "[170, 300] loss: 0.007\n",
      "[170, 360] loss: 0.007\n",
      "Epoch: 170 -> Loss: 0.00946605671197\n",
      "Epoch: 170 -> Test Accuracy: 92.1125\n",
      "[171, 60] loss: 0.006\n",
      "[171, 120] loss: 0.006\n",
      "[171, 180] loss: 0.008\n",
      "[171, 240] loss: 0.007\n",
      "[171, 300] loss: 0.007\n",
      "[171, 360] loss: 0.007\n",
      "Epoch: 171 -> Loss: 0.0124780889601\n",
      "Epoch: 171 -> Test Accuracy: 92.005\n",
      "[172, 60] loss: 0.006\n",
      "[172, 120] loss: 0.007\n",
      "[172, 180] loss: 0.007\n",
      "[172, 240] loss: 0.007\n",
      "[172, 300] loss: 0.007\n",
      "[172, 360] loss: 0.007\n",
      "Epoch: 172 -> Loss: 0.00597655400634\n",
      "Epoch: 172 -> Test Accuracy: 92.155\n",
      "[173, 60] loss: 0.006\n",
      "[173, 120] loss: 0.007\n",
      "[173, 180] loss: 0.006\n",
      "[173, 240] loss: 0.006\n",
      "[173, 300] loss: 0.007\n",
      "[173, 360] loss: 0.007\n",
      "Epoch: 173 -> Loss: 0.00489861518145\n",
      "Epoch: 173 -> Test Accuracy: 92.145\n",
      "[174, 60] loss: 0.006\n",
      "[174, 120] loss: 0.006\n",
      "[174, 180] loss: 0.006\n",
      "[174, 240] loss: 0.008\n",
      "[174, 300] loss: 0.006\n",
      "[174, 360] loss: 0.006\n",
      "Epoch: 174 -> Loss: 0.00871469266713\n",
      "Epoch: 174 -> Test Accuracy: 92.0675\n",
      "[175, 60] loss: 0.006\n",
      "[175, 120] loss: 0.007\n",
      "[175, 180] loss: 0.007\n",
      "[175, 240] loss: 0.006\n",
      "[175, 300] loss: 0.006\n",
      "[175, 360] loss: 0.006\n",
      "Epoch: 175 -> Loss: 0.0146858412772\n",
      "Epoch: 175 -> Test Accuracy: 92.125\n",
      "[176, 60] loss: 0.006\n",
      "[176, 120] loss: 0.006\n",
      "[176, 180] loss: 0.006\n",
      "[176, 240] loss: 0.006\n",
      "[176, 300] loss: 0.006\n",
      "[176, 360] loss: 0.006\n",
      "Epoch: 176 -> Loss: 0.0106286387891\n",
      "Epoch: 176 -> Test Accuracy: 92.065\n",
      "[177, 60] loss: 0.007\n",
      "[177, 120] loss: 0.007\n",
      "[177, 180] loss: 0.006\n",
      "[177, 240] loss: 0.007\n",
      "[177, 300] loss: 0.005\n",
      "[177, 360] loss: 0.005\n",
      "Epoch: 177 -> Loss: 0.00142349675298\n",
      "Epoch: 177 -> Test Accuracy: 92.0975\n",
      "[178, 60] loss: 0.006\n",
      "[178, 120] loss: 0.006\n",
      "[178, 180] loss: 0.005\n",
      "[178, 240] loss: 0.006\n",
      "[178, 300] loss: 0.006\n",
      "[178, 360] loss: 0.005\n",
      "Epoch: 178 -> Loss: 0.00191520084627\n",
      "Epoch: 178 -> Test Accuracy: 92.1175\n",
      "[179, 60] loss: 0.006\n",
      "[179, 120] loss: 0.006\n",
      "[179, 180] loss: 0.006\n",
      "[179, 240] loss: 0.006\n",
      "[179, 300] loss: 0.006\n",
      "[179, 360] loss: 0.006\n",
      "Epoch: 179 -> Loss: 0.00468342378736\n",
      "Epoch: 179 -> Test Accuracy: 92.1875\n",
      "[180, 60] loss: 0.005\n",
      "[180, 120] loss: 0.006\n",
      "[180, 180] loss: 0.005\n",
      "[180, 240] loss: 0.006\n",
      "[180, 300] loss: 0.006\n",
      "[180, 360] loss: 0.006\n",
      "Epoch: 180 -> Loss: 0.0333884581923\n",
      "Epoch: 180 -> Test Accuracy: 92.0475\n",
      "[181, 60] loss: 0.006\n",
      "[181, 120] loss: 0.004\n",
      "[181, 180] loss: 0.005\n",
      "[181, 240] loss: 0.005\n",
      "[181, 300] loss: 0.006\n",
      "[181, 360] loss: 0.005\n",
      "Epoch: 181 -> Loss: 0.00301936571486\n",
      "Epoch: 181 -> Test Accuracy: 92.1175\n",
      "[182, 60] loss: 0.005\n",
      "[182, 120] loss: 0.005\n",
      "[182, 180] loss: 0.005\n",
      "[182, 240] loss: 0.005\n",
      "[182, 300] loss: 0.006\n",
      "[182, 360] loss: 0.005\n",
      "Epoch: 182 -> Loss: 0.0125302523375\n",
      "Epoch: 182 -> Test Accuracy: 91.9925\n",
      "[183, 60] loss: 0.005\n",
      "[183, 120] loss: 0.006\n",
      "[183, 180] loss: 0.005\n",
      "[183, 240] loss: 0.005\n",
      "[183, 300] loss: 0.005\n",
      "[183, 360] loss: 0.004\n",
      "Epoch: 183 -> Loss: 0.00278570572846\n",
      "Epoch: 183 -> Test Accuracy: 92.09\n",
      "[184, 60] loss: 0.004\n",
      "[184, 120] loss: 0.005\n",
      "[184, 180] loss: 0.005\n",
      "[184, 240] loss: 0.005\n",
      "[184, 300] loss: 0.005\n",
      "[184, 360] loss: 0.005\n",
      "Epoch: 184 -> Loss: 0.00321592693217\n",
      "Epoch: 184 -> Test Accuracy: 92.05\n",
      "[185, 60] loss: 0.005\n",
      "[185, 120] loss: 0.005\n",
      "[185, 180] loss: 0.005\n",
      "[185, 240] loss: 0.006\n",
      "[185, 300] loss: 0.005\n",
      "[185, 360] loss: 0.004\n",
      "Epoch: 185 -> Loss: 0.0431872792542\n",
      "Epoch: 185 -> Test Accuracy: 92.04\n",
      "[186, 60] loss: 0.005\n",
      "[186, 120] loss: 0.005\n",
      "[186, 180] loss: 0.004\n",
      "[186, 240] loss: 0.005\n",
      "[186, 300] loss: 0.005\n",
      "[186, 360] loss: 0.005\n",
      "Epoch: 186 -> Loss: 0.00244244257919\n",
      "Epoch: 186 -> Test Accuracy: 92.1925\n",
      "[187, 60] loss: 0.005\n",
      "[187, 120] loss: 0.005\n",
      "[187, 180] loss: 0.005\n",
      "[187, 240] loss: 0.005\n",
      "[187, 300] loss: 0.006\n",
      "[187, 360] loss: 0.005\n",
      "Epoch: 187 -> Loss: 0.0036028441973\n",
      "Epoch: 187 -> Test Accuracy: 92.135\n",
      "[188, 60] loss: 0.005\n",
      "[188, 120] loss: 0.004\n",
      "[188, 180] loss: 0.004\n",
      "[188, 240] loss: 0.005\n",
      "[188, 300] loss: 0.005\n",
      "[188, 360] loss: 0.005\n",
      "Epoch: 188 -> Loss: 0.0025260404218\n",
      "Epoch: 188 -> Test Accuracy: 92.1675\n",
      "[189, 60] loss: 0.005\n",
      "[189, 120] loss: 0.006\n",
      "[189, 180] loss: 0.005\n",
      "[189, 240] loss: 0.005\n",
      "[189, 300] loss: 0.005\n",
      "[189, 360] loss: 0.004\n",
      "Epoch: 189 -> Loss: 0.00673134019598\n",
      "Epoch: 189 -> Test Accuracy: 92.12\n",
      "[190, 60] loss: 0.004\n",
      "[190, 120] loss: 0.004\n",
      "[190, 180] loss: 0.005\n",
      "[190, 240] loss: 0.005\n",
      "[190, 300] loss: 0.004\n",
      "[190, 360] loss: 0.005\n",
      "Epoch: 190 -> Loss: 0.00380113115534\n",
      "Epoch: 190 -> Test Accuracy: 91.9875\n",
      "[191, 60] loss: 0.004\n",
      "[191, 120] loss: 0.005\n",
      "[191, 180] loss: 0.004\n",
      "[191, 240] loss: 0.005\n",
      "[191, 300] loss: 0.004\n",
      "[191, 360] loss: 0.005\n",
      "Epoch: 191 -> Loss: 0.00284886290319\n",
      "Epoch: 191 -> Test Accuracy: 92.13\n",
      "[192, 60] loss: 0.005\n",
      "[192, 120] loss: 0.005\n",
      "[192, 180] loss: 0.004\n",
      "[192, 240] loss: 0.004\n",
      "[192, 300] loss: 0.004\n",
      "[192, 360] loss: 0.004\n",
      "Epoch: 192 -> Loss: 0.00353298941627\n",
      "Epoch: 192 -> Test Accuracy: 92.0425\n",
      "[193, 60] loss: 0.004\n",
      "[193, 120] loss: 0.005\n",
      "[193, 180] loss: 0.005\n",
      "[193, 240] loss: 0.004\n",
      "[193, 300] loss: 0.004\n",
      "[193, 360] loss: 0.005\n",
      "Epoch: 193 -> Loss: 0.00420574378222\n",
      "Epoch: 193 -> Test Accuracy: 91.98\n",
      "[194, 60] loss: 0.005\n",
      "[194, 120] loss: 0.004\n",
      "[194, 180] loss: 0.004\n",
      "[194, 240] loss: 0.004\n",
      "[194, 300] loss: 0.004\n",
      "[194, 360] loss: 0.005\n",
      "Epoch: 194 -> Loss: 0.0147659778595\n",
      "Epoch: 194 -> Test Accuracy: 92.085\n",
      "[195, 60] loss: 0.004\n",
      "[195, 120] loss: 0.004\n",
      "[195, 180] loss: 0.004\n",
      "[195, 240] loss: 0.004\n",
      "[195, 300] loss: 0.004\n",
      "[195, 360] loss: 0.004\n",
      "Epoch: 195 -> Loss: 0.00557369738817\n",
      "Epoch: 195 -> Test Accuracy: 92.03\n",
      "[196, 60] loss: 0.004\n",
      "[196, 120] loss: 0.004\n",
      "[196, 180] loss: 0.005\n",
      "[196, 240] loss: 0.004\n",
      "[196, 300] loss: 0.004\n",
      "[196, 360] loss: 0.004\n",
      "Epoch: 196 -> Loss: 0.00225464021787\n",
      "Epoch: 196 -> Test Accuracy: 92.03\n",
      "[197, 60] loss: 0.004\n",
      "[197, 120] loss: 0.004\n",
      "[197, 180] loss: 0.004\n",
      "[197, 240] loss: 0.005\n",
      "[197, 300] loss: 0.004\n",
      "[197, 360] loss: 0.004\n",
      "Epoch: 197 -> Loss: 0.00342247937806\n",
      "Epoch: 197 -> Test Accuracy: 92.1\n",
      "[198, 60] loss: 0.004\n",
      "[198, 120] loss: 0.004\n",
      "[198, 180] loss: 0.003\n",
      "[198, 240] loss: 0.004\n",
      "[198, 300] loss: 0.004\n",
      "[198, 360] loss: 0.004\n",
      "Epoch: 198 -> Loss: 0.00812376476824\n",
      "Epoch: 198 -> Test Accuracy: 92.09\n",
      "[199, 60] loss: 0.005\n",
      "[199, 120] loss: 0.004\n",
      "[199, 180] loss: 0.004\n",
      "[199, 240] loss: 0.004\n",
      "[199, 300] loss: 0.004\n",
      "[199, 360] loss: 0.004\n",
      "Epoch: 199 -> Loss: 0.00199968880042\n",
      "Epoch: 199 -> Test Accuracy: 92.0925\n",
      "[200, 60] loss: 0.004\n",
      "[200, 120] loss: 0.004\n",
      "[200, 180] loss: 0.004\n",
      "[200, 240] loss: 0.004\n",
      "[200, 300] loss: 0.004\n",
      "[200, 360] loss: 0.004\n",
      "Epoch: 200 -> Loss: 0.00689739733934\n",
      "Epoch: 200 -> Test Accuracy: 92.055\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "rot_block5_loss_log, rot_block5_valid_accuracy_log, rot_block5_test_accuracy_log, rot_block5_max_accuracy, \\\n",
    "rot_block5_best_epoch = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], [60, 120, 160, 200], 0.9, 5e-4, net_block5, \n",
    "                                             criterion, trainloader, None, testloader, rot=['90', '180', '270'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 2.231\n",
      "[1, 120] loss: 1.244\n",
      "[1, 180] loss: 1.141\n",
      "[1, 240] loss: 1.059\n",
      "[1, 300] loss: 1.039\n",
      "[1, 360] loss: 1.015\n",
      "Epoch: 1 -> Loss: 0.975417912006\n",
      "Epoch: 1 -> Test Accuracy: 67.66\n",
      "[2, 60] loss: 0.960\n",
      "[2, 120] loss: 0.939\n",
      "[2, 180] loss: 0.912\n",
      "[2, 240] loss: 0.891\n",
      "[2, 300] loss: 0.875\n",
      "[2, 360] loss: 0.873\n",
      "Epoch: 2 -> Loss: 0.753490507603\n",
      "Epoch: 2 -> Test Accuracy: 71.6\n",
      "[3, 60] loss: 0.829\n",
      "[3, 120] loss: 0.824\n",
      "[3, 180] loss: 0.813\n",
      "[3, 240] loss: 0.826\n",
      "[3, 300] loss: 0.805\n",
      "[3, 360] loss: 0.806\n",
      "Epoch: 3 -> Loss: 0.915134549141\n",
      "Epoch: 3 -> Test Accuracy: 73.14\n",
      "[4, 60] loss: 0.766\n",
      "[4, 120] loss: 0.769\n",
      "[4, 180] loss: 0.760\n",
      "[4, 240] loss: 0.766\n",
      "[4, 300] loss: 0.761\n",
      "[4, 360] loss: 0.763\n",
      "Epoch: 4 -> Loss: 0.655376851559\n",
      "Epoch: 4 -> Test Accuracy: 74.74\n",
      "[5, 60] loss: 0.732\n",
      "[5, 120] loss: 0.709\n",
      "[5, 180] loss: 0.744\n",
      "[5, 240] loss: 0.734\n",
      "[5, 300] loss: 0.736\n",
      "[5, 360] loss: 0.708\n",
      "Epoch: 5 -> Loss: 0.844153225422\n",
      "Epoch: 5 -> Test Accuracy: 76.23\n",
      "[6, 60] loss: 0.692\n",
      "[6, 120] loss: 0.701\n",
      "[6, 180] loss: 0.708\n",
      "[6, 240] loss: 0.690\n",
      "[6, 300] loss: 0.704\n",
      "[6, 360] loss: 0.720\n",
      "Epoch: 6 -> Loss: 0.743290364742\n",
      "Epoch: 6 -> Test Accuracy: 76.76\n",
      "[7, 60] loss: 0.684\n",
      "[7, 120] loss: 0.674\n",
      "[7, 180] loss: 0.681\n",
      "[7, 240] loss: 0.694\n",
      "[7, 300] loss: 0.698\n",
      "[7, 360] loss: 0.686\n",
      "Epoch: 7 -> Loss: 0.634222328663\n",
      "Epoch: 7 -> Test Accuracy: 76.9\n",
      "[8, 60] loss: 0.662\n",
      "[8, 120] loss: 0.676\n",
      "[8, 180] loss: 0.673\n",
      "[8, 240] loss: 0.681\n",
      "[8, 300] loss: 0.685\n",
      "[8, 360] loss: 0.684\n",
      "Epoch: 8 -> Loss: 0.575144350529\n",
      "Epoch: 8 -> Test Accuracy: 76.69\n",
      "[9, 60] loss: 0.649\n",
      "[9, 120] loss: 0.656\n",
      "[9, 180] loss: 0.645\n",
      "[9, 240] loss: 0.669\n",
      "[9, 300] loss: 0.678\n",
      "[9, 360] loss: 0.665\n",
      "Epoch: 9 -> Loss: 0.587389290333\n",
      "Epoch: 9 -> Test Accuracy: 77.88\n",
      "[10, 60] loss: 0.659\n",
      "[10, 120] loss: 0.630\n",
      "[10, 180] loss: 0.653\n",
      "[10, 240] loss: 0.661\n",
      "[10, 300] loss: 0.658\n",
      "[10, 360] loss: 0.638\n",
      "Epoch: 10 -> Loss: 0.721288442612\n",
      "Epoch: 10 -> Test Accuracy: 77.82\n",
      "[11, 60] loss: 0.639\n",
      "[11, 120] loss: 0.619\n",
      "[11, 180] loss: 0.635\n",
      "[11, 240] loss: 0.641\n",
      "[11, 300] loss: 0.643\n",
      "[11, 360] loss: 0.638\n",
      "Epoch: 11 -> Loss: 0.812289535999\n",
      "Epoch: 11 -> Test Accuracy: 78.05\n",
      "[12, 60] loss: 0.646\n",
      "[12, 120] loss: 0.630\n",
      "[12, 180] loss: 0.642\n",
      "[12, 240] loss: 0.644\n",
      "[12, 300] loss: 0.637\n",
      "[12, 360] loss: 0.649\n",
      "Epoch: 12 -> Loss: 0.618523657322\n",
      "Epoch: 12 -> Test Accuracy: 78.05\n",
      "[13, 60] loss: 0.615\n",
      "[13, 120] loss: 0.608\n",
      "[13, 180] loss: 0.611\n",
      "[13, 240] loss: 0.644\n",
      "[13, 300] loss: 0.637\n",
      "[13, 360] loss: 0.659\n",
      "Epoch: 13 -> Loss: 0.669454157352\n",
      "Epoch: 13 -> Test Accuracy: 78.68\n",
      "[14, 60] loss: 0.600\n",
      "[14, 120] loss: 0.624\n",
      "[14, 180] loss: 0.642\n",
      "[14, 240] loss: 0.618\n",
      "[14, 300] loss: 0.647\n",
      "[14, 360] loss: 0.640\n",
      "Epoch: 14 -> Loss: 0.644244790077\n",
      "Epoch: 14 -> Test Accuracy: 78.6\n",
      "[15, 60] loss: 0.585\n",
      "[15, 120] loss: 0.619\n",
      "[15, 180] loss: 0.618\n",
      "[15, 240] loss: 0.624\n",
      "[15, 300] loss: 0.615\n",
      "[15, 360] loss: 0.640\n",
      "Epoch: 15 -> Loss: 0.534644067287\n",
      "Epoch: 15 -> Test Accuracy: 78.36\n",
      "[16, 60] loss: 0.597\n",
      "[16, 120] loss: 0.623\n",
      "[16, 180] loss: 0.620\n",
      "[16, 240] loss: 0.632\n",
      "[16, 300] loss: 0.601\n",
      "[16, 360] loss: 0.622\n",
      "Epoch: 16 -> Loss: 0.605383515358\n",
      "Epoch: 16 -> Test Accuracy: 78.61\n",
      "[17, 60] loss: 0.603\n",
      "[17, 120] loss: 0.589\n",
      "[17, 180] loss: 0.635\n",
      "[17, 240] loss: 0.614\n",
      "[17, 300] loss: 0.618\n",
      "[17, 360] loss: 0.606\n",
      "Epoch: 17 -> Loss: 0.513262450695\n",
      "Epoch: 17 -> Test Accuracy: 78.28\n",
      "[18, 60] loss: 0.612\n",
      "[18, 120] loss: 0.616\n",
      "[18, 180] loss: 0.597\n",
      "[18, 240] loss: 0.617\n",
      "[18, 300] loss: 0.629\n",
      "[18, 360] loss: 0.603\n",
      "Epoch: 18 -> Loss: 0.42476812005\n",
      "Epoch: 18 -> Test Accuracy: 78.81\n",
      "[19, 60] loss: 0.594\n",
      "[19, 120] loss: 0.605\n",
      "[19, 180] loss: 0.601\n",
      "[19, 240] loss: 0.626\n",
      "[19, 300] loss: 0.597\n",
      "[19, 360] loss: 0.616\n",
      "Epoch: 19 -> Loss: 0.79298055172\n",
      "Epoch: 19 -> Test Accuracy: 78.19\n",
      "[20, 60] loss: 0.604\n",
      "[20, 120] loss: 0.586\n",
      "[20, 180] loss: 0.611\n",
      "[20, 240] loss: 0.575\n",
      "[20, 300] loss: 0.616\n",
      "[20, 360] loss: 0.611\n",
      "Epoch: 20 -> Loss: 0.738569021225\n",
      "Epoch: 20 -> Test Accuracy: 79.03\n",
      "[21, 60] loss: 0.560\n",
      "[21, 120] loss: 0.524\n",
      "[21, 180] loss: 0.537\n",
      "[21, 240] loss: 0.488\n",
      "[21, 300] loss: 0.488\n",
      "[21, 360] loss: 0.500\n",
      "Epoch: 21 -> Loss: 0.633026182652\n",
      "Epoch: 21 -> Test Accuracy: 80.72\n",
      "[22, 60] loss: 0.480\n",
      "[22, 120] loss: 0.477\n",
      "[22, 180] loss: 0.466\n",
      "[22, 240] loss: 0.456\n",
      "[22, 300] loss: 0.486\n",
      "[22, 360] loss: 0.471\n",
      "Epoch: 22 -> Loss: 0.577553272247\n",
      "Epoch: 22 -> Test Accuracy: 80.96\n",
      "[23, 60] loss: 0.453\n",
      "[23, 120] loss: 0.464\n",
      "[23, 180] loss: 0.435\n",
      "[23, 240] loss: 0.467\n",
      "[23, 300] loss: 0.441\n",
      "[23, 360] loss: 0.467\n",
      "Epoch: 23 -> Loss: 0.321594119072\n",
      "Epoch: 23 -> Test Accuracy: 81.67\n",
      "[24, 60] loss: 0.438\n",
      "[24, 120] loss: 0.429\n",
      "[24, 180] loss: 0.447\n",
      "[24, 240] loss: 0.422\n",
      "[24, 300] loss: 0.443\n",
      "[24, 360] loss: 0.446\n",
      "Epoch: 24 -> Loss: 0.423196941614\n",
      "Epoch: 24 -> Test Accuracy: 81.5\n",
      "[25, 60] loss: 0.421\n",
      "[25, 120] loss: 0.439\n",
      "[25, 180] loss: 0.432\n",
      "[25, 240] loss: 0.429\n",
      "[25, 300] loss: 0.440\n",
      "[25, 360] loss: 0.439\n",
      "Epoch: 25 -> Loss: 0.396030366421\n",
      "Epoch: 25 -> Test Accuracy: 81.75\n",
      "[26, 60] loss: 0.412\n",
      "[26, 120] loss: 0.423\n",
      "[26, 180] loss: 0.429\n",
      "[26, 240] loss: 0.442\n",
      "[26, 300] loss: 0.438\n",
      "[26, 360] loss: 0.438\n",
      "Epoch: 26 -> Loss: 0.444499641657\n",
      "Epoch: 26 -> Test Accuracy: 81.12\n",
      "[27, 60] loss: 0.418\n",
      "[27, 120] loss: 0.419\n",
      "[27, 180] loss: 0.426\n",
      "[27, 240] loss: 0.413\n",
      "[27, 300] loss: 0.436\n",
      "[27, 360] loss: 0.436\n",
      "Epoch: 27 -> Loss: 0.452709913254\n",
      "Epoch: 27 -> Test Accuracy: 81.85\n",
      "[28, 60] loss: 0.401\n",
      "[28, 120] loss: 0.402\n",
      "[28, 180] loss: 0.399\n",
      "[28, 240] loss: 0.421\n",
      "[28, 300] loss: 0.433\n",
      "[28, 360] loss: 0.404\n",
      "Epoch: 28 -> Loss: 0.550650417805\n",
      "Epoch: 28 -> Test Accuracy: 81.86\n",
      "[29, 60] loss: 0.387\n",
      "[29, 120] loss: 0.424\n",
      "[29, 180] loss: 0.415\n",
      "[29, 240] loss: 0.407\n",
      "[29, 300] loss: 0.419\n",
      "[29, 360] loss: 0.423\n",
      "Epoch: 29 -> Loss: 0.447480857372\n",
      "Epoch: 29 -> Test Accuracy: 81.65\n",
      "[30, 60] loss: 0.387\n",
      "[30, 120] loss: 0.409\n",
      "[30, 180] loss: 0.417\n",
      "[30, 240] loss: 0.415\n",
      "[30, 300] loss: 0.409\n",
      "[30, 360] loss: 0.420\n",
      "Epoch: 30 -> Loss: 0.513758480549\n",
      "Epoch: 30 -> Test Accuracy: 82.1\n",
      "[31, 60] loss: 0.387\n",
      "[31, 120] loss: 0.404\n",
      "[31, 180] loss: 0.407\n",
      "[31, 240] loss: 0.409\n",
      "[31, 300] loss: 0.417\n",
      "[31, 360] loss: 0.423\n",
      "Epoch: 31 -> Loss: 0.415537118912\n",
      "Epoch: 31 -> Test Accuracy: 81.74\n",
      "[32, 60] loss: 0.392\n",
      "[32, 120] loss: 0.409\n",
      "[32, 180] loss: 0.413\n",
      "[32, 240] loss: 0.406\n",
      "[32, 300] loss: 0.409\n",
      "[32, 360] loss: 0.406\n",
      "Epoch: 32 -> Loss: 0.698387265205\n",
      "Epoch: 32 -> Test Accuracy: 81.74\n",
      "[33, 60] loss: 0.388\n",
      "[33, 120] loss: 0.389\n",
      "[33, 180] loss: 0.400\n",
      "[33, 240] loss: 0.395\n",
      "[33, 300] loss: 0.409\n",
      "[33, 360] loss: 0.408\n",
      "Epoch: 33 -> Loss: 0.4932538867\n",
      "Epoch: 33 -> Test Accuracy: 81.53\n",
      "[34, 60] loss: 0.390\n",
      "[34, 120] loss: 0.388\n",
      "[34, 180] loss: 0.406\n",
      "[34, 240] loss: 0.404\n",
      "[34, 300] loss: 0.420\n",
      "[34, 360] loss: 0.418\n",
      "Epoch: 34 -> Loss: 0.375450283289\n",
      "Epoch: 34 -> Test Accuracy: 81.72\n",
      "[35, 60] loss: 0.389\n",
      "[35, 120] loss: 0.397\n",
      "[35, 180] loss: 0.402\n",
      "[35, 240] loss: 0.408\n",
      "[35, 300] loss: 0.381\n",
      "[35, 360] loss: 0.412\n",
      "Epoch: 35 -> Loss: 0.496777057648\n",
      "Epoch: 35 -> Test Accuracy: 81.65\n",
      "[36, 60] loss: 0.380\n",
      "[36, 120] loss: 0.386\n",
      "[36, 180] loss: 0.386\n",
      "[36, 240] loss: 0.415\n",
      "[36, 300] loss: 0.400\n",
      "[36, 360] loss: 0.416\n",
      "Epoch: 36 -> Loss: 0.438303291798\n",
      "Epoch: 36 -> Test Accuracy: 81.32\n",
      "[37, 60] loss: 0.383\n",
      "[37, 120] loss: 0.391\n",
      "[37, 180] loss: 0.401\n",
      "[37, 240] loss: 0.399\n",
      "[37, 300] loss: 0.387\n",
      "[37, 360] loss: 0.396\n",
      "Epoch: 37 -> Loss: 0.324328839779\n",
      "Epoch: 37 -> Test Accuracy: 81.38\n",
      "[38, 60] loss: 0.376\n",
      "[38, 120] loss: 0.376\n",
      "[38, 180] loss: 0.400\n",
      "[38, 240] loss: 0.400\n",
      "[38, 300] loss: 0.411\n",
      "[38, 360] loss: 0.400\n",
      "Epoch: 38 -> Loss: 0.411996603012\n",
      "Epoch: 38 -> Test Accuracy: 81.81\n",
      "[39, 60] loss: 0.385\n",
      "[39, 120] loss: 0.402\n",
      "[39, 180] loss: 0.404\n",
      "[39, 240] loss: 0.408\n",
      "[39, 300] loss: 0.403\n",
      "[39, 360] loss: 0.410\n",
      "Epoch: 39 -> Loss: 0.470553547144\n",
      "Epoch: 39 -> Test Accuracy: 81.25\n",
      "[40, 60] loss: 0.389\n",
      "[40, 120] loss: 0.393\n",
      "[40, 180] loss: 0.378\n",
      "[40, 240] loss: 0.396\n",
      "[40, 300] loss: 0.393\n",
      "[40, 360] loss: 0.394\n",
      "Epoch: 40 -> Loss: 0.534683585167\n",
      "Epoch: 40 -> Test Accuracy: 81.86\n",
      "[41, 60] loss: 0.371\n",
      "[41, 120] loss: 0.349\n",
      "[41, 180] loss: 0.339\n",
      "[41, 240] loss: 0.350\n",
      "[41, 300] loss: 0.353\n",
      "[41, 360] loss: 0.336\n",
      "Epoch: 41 -> Loss: 0.272596687078\n",
      "Epoch: 41 -> Test Accuracy: 82.63\n",
      "[42, 60] loss: 0.326\n",
      "[42, 120] loss: 0.332\n",
      "[42, 180] loss: 0.338\n",
      "[42, 240] loss: 0.341\n",
      "[42, 300] loss: 0.325\n",
      "[42, 360] loss: 0.339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.220982000232\n",
      "Epoch: 42 -> Test Accuracy: 82.62\n",
      "[43, 60] loss: 0.319\n",
      "[43, 120] loss: 0.319\n",
      "[43, 180] loss: 0.327\n",
      "[43, 240] loss: 0.314\n",
      "[43, 300] loss: 0.316\n",
      "[43, 360] loss: 0.318\n",
      "Epoch: 43 -> Loss: 0.445872962475\n",
      "Epoch: 43 -> Test Accuracy: 82.86\n",
      "[44, 60] loss: 0.295\n",
      "[44, 120] loss: 0.312\n",
      "[44, 180] loss: 0.310\n",
      "[44, 240] loss: 0.313\n",
      "[44, 300] loss: 0.311\n",
      "[44, 360] loss: 0.326\n",
      "Epoch: 44 -> Loss: 0.25137218833\n",
      "Epoch: 44 -> Test Accuracy: 82.7\n",
      "[45, 60] loss: 0.311\n",
      "[45, 120] loss: 0.304\n",
      "[45, 180] loss: 0.308\n",
      "[45, 240] loss: 0.304\n",
      "[45, 300] loss: 0.298\n",
      "[45, 360] loss: 0.301\n",
      "Epoch: 45 -> Loss: 0.329112589359\n",
      "Epoch: 45 -> Test Accuracy: 82.84\n",
      "[46, 60] loss: 0.296\n",
      "[46, 120] loss: 0.289\n",
      "[46, 180] loss: 0.293\n",
      "[46, 240] loss: 0.294\n",
      "[46, 300] loss: 0.276\n",
      "[46, 360] loss: 0.286\n",
      "Epoch: 46 -> Loss: 0.280040770769\n",
      "Epoch: 46 -> Test Accuracy: 83.05\n",
      "[47, 60] loss: 0.298\n",
      "[47, 120] loss: 0.287\n",
      "[47, 180] loss: 0.278\n",
      "[47, 240] loss: 0.286\n",
      "[47, 300] loss: 0.292\n",
      "[47, 360] loss: 0.289\n",
      "Epoch: 47 -> Loss: 0.2835547328\n",
      "Epoch: 47 -> Test Accuracy: 83.07\n",
      "[48, 60] loss: 0.282\n",
      "[48, 120] loss: 0.288\n",
      "[48, 180] loss: 0.278\n",
      "[48, 240] loss: 0.283\n",
      "[48, 300] loss: 0.289\n",
      "[48, 360] loss: 0.286\n",
      "Epoch: 48 -> Loss: 0.321089893579\n",
      "Epoch: 48 -> Test Accuracy: 82.97\n",
      "[49, 60] loss: 0.283\n",
      "[49, 120] loss: 0.278\n",
      "[49, 180] loss: 0.303\n",
      "[49, 240] loss: 0.277\n",
      "[49, 300] loss: 0.271\n",
      "[49, 360] loss: 0.281\n",
      "Epoch: 49 -> Loss: 0.348754197359\n",
      "Epoch: 49 -> Test Accuracy: 83.02\n",
      "[50, 60] loss: 0.279\n",
      "[50, 120] loss: 0.275\n",
      "[50, 180] loss: 0.281\n",
      "[50, 240] loss: 0.283\n",
      "[50, 300] loss: 0.289\n",
      "[50, 360] loss: 0.291\n",
      "Epoch: 50 -> Loss: 0.36596852541\n",
      "Epoch: 50 -> Test Accuracy: 83.15\n",
      "[51, 60] loss: 0.281\n",
      "[51, 120] loss: 0.279\n",
      "[51, 180] loss: 0.294\n",
      "[51, 240] loss: 0.292\n",
      "[51, 300] loss: 0.279\n",
      "[51, 360] loss: 0.282\n",
      "Epoch: 51 -> Loss: 0.305279791355\n",
      "Epoch: 51 -> Test Accuracy: 83.15\n",
      "[52, 60] loss: 0.281\n",
      "[52, 120] loss: 0.275\n",
      "[52, 180] loss: 0.284\n",
      "[52, 240] loss: 0.273\n",
      "[52, 300] loss: 0.277\n",
      "[52, 360] loss: 0.281\n",
      "Epoch: 52 -> Loss: 0.233882546425\n",
      "Epoch: 52 -> Test Accuracy: 83.11\n",
      "[53, 60] loss: 0.273\n",
      "[53, 120] loss: 0.274\n",
      "[53, 180] loss: 0.283\n",
      "[53, 240] loss: 0.270\n",
      "[53, 300] loss: 0.281\n",
      "[53, 360] loss: 0.285\n",
      "Epoch: 53 -> Loss: 0.204650253057\n",
      "Epoch: 53 -> Test Accuracy: 83.24\n",
      "[54, 60] loss: 0.275\n",
      "[54, 120] loss: 0.278\n",
      "[54, 180] loss: 0.271\n",
      "[54, 240] loss: 0.280\n",
      "[54, 300] loss: 0.285\n",
      "[54, 360] loss: 0.273\n",
      "Epoch: 54 -> Loss: 0.183086246252\n",
      "Epoch: 54 -> Test Accuracy: 83.26\n",
      "[55, 60] loss: 0.265\n",
      "[55, 120] loss: 0.280\n",
      "[55, 180] loss: 0.278\n",
      "[55, 240] loss: 0.282\n",
      "[55, 300] loss: 0.272\n",
      "[55, 360] loss: 0.266\n",
      "Epoch: 55 -> Loss: 0.1618822366\n",
      "Epoch: 55 -> Test Accuracy: 83.01\n",
      "[56, 60] loss: 0.273\n",
      "[56, 120] loss: 0.277\n",
      "[56, 180] loss: 0.266\n",
      "[56, 240] loss: 0.273\n",
      "[56, 300] loss: 0.280\n",
      "[56, 360] loss: 0.265\n",
      "Epoch: 56 -> Loss: 0.168948844075\n",
      "Epoch: 56 -> Test Accuracy: 83.01\n",
      "[57, 60] loss: 0.281\n",
      "[57, 120] loss: 0.270\n",
      "[57, 180] loss: 0.270\n",
      "[57, 240] loss: 0.281\n",
      "[57, 300] loss: 0.277\n",
      "[57, 360] loss: 0.282\n",
      "Epoch: 57 -> Loss: 0.171209648252\n",
      "Epoch: 57 -> Test Accuracy: 83.11\n",
      "[58, 60] loss: 0.271\n",
      "[58, 120] loss: 0.269\n",
      "[58, 180] loss: 0.260\n",
      "[58, 240] loss: 0.280\n",
      "[58, 300] loss: 0.276\n",
      "[58, 360] loss: 0.267\n",
      "Epoch: 58 -> Loss: 0.221290871501\n",
      "Epoch: 58 -> Test Accuracy: 83.36\n",
      "[59, 60] loss: 0.276\n",
      "[59, 120] loss: 0.268\n",
      "[59, 180] loss: 0.264\n",
      "[59, 240] loss: 0.286\n",
      "[59, 300] loss: 0.272\n",
      "[59, 360] loss: 0.266\n",
      "Epoch: 59 -> Loss: 0.423521906137\n",
      "Epoch: 59 -> Test Accuracy: 83.28\n",
      "[60, 60] loss: 0.262\n",
      "[60, 120] loss: 0.266\n",
      "[60, 180] loss: 0.267\n",
      "[60, 240] loss: 0.278\n",
      "[60, 300] loss: 0.270\n",
      "[60, 360] loss: 0.258\n",
      "Epoch: 60 -> Loss: 0.288781225681\n",
      "Epoch: 60 -> Test Accuracy: 83.3\n",
      "[61, 60] loss: 0.263\n",
      "[61, 120] loss: 0.264\n",
      "[61, 180] loss: 0.270\n",
      "[61, 240] loss: 0.263\n",
      "[61, 300] loss: 0.266\n",
      "[61, 360] loss: 0.275\n",
      "Epoch: 61 -> Loss: 0.190161675215\n",
      "Epoch: 61 -> Test Accuracy: 83.46\n",
      "[62, 60] loss: 0.259\n",
      "[62, 120] loss: 0.277\n",
      "[62, 180] loss: 0.273\n",
      "[62, 240] loss: 0.269\n",
      "[62, 300] loss: 0.266\n",
      "[62, 360] loss: 0.271\n",
      "Epoch: 62 -> Loss: 0.216477066278\n",
      "Epoch: 62 -> Test Accuracy: 83.48\n",
      "[63, 60] loss: 0.264\n",
      "[63, 120] loss: 0.271\n",
      "[63, 180] loss: 0.264\n",
      "[63, 240] loss: 0.269\n",
      "[63, 300] loss: 0.257\n",
      "[63, 360] loss: 0.255\n",
      "Epoch: 63 -> Loss: 0.314389646053\n",
      "Epoch: 63 -> Test Accuracy: 83.36\n",
      "[64, 60] loss: 0.261\n",
      "[64, 120] loss: 0.251\n",
      "[64, 180] loss: 0.263\n",
      "[64, 240] loss: 0.261\n",
      "[64, 300] loss: 0.261\n",
      "[64, 360] loss: 0.274\n",
      "Epoch: 64 -> Loss: 0.279850780964\n",
      "Epoch: 64 -> Test Accuracy: 83.33\n",
      "[65, 60] loss: 0.266\n",
      "[65, 120] loss: 0.267\n",
      "[65, 180] loss: 0.255\n",
      "[65, 240] loss: 0.261\n",
      "[65, 300] loss: 0.267\n",
      "[65, 360] loss: 0.271\n",
      "Epoch: 65 -> Loss: 0.314710080624\n",
      "Epoch: 65 -> Test Accuracy: 83.44\n",
      "[66, 60] loss: 0.250\n",
      "[66, 120] loss: 0.268\n",
      "[66, 180] loss: 0.263\n",
      "[66, 240] loss: 0.261\n",
      "[66, 300] loss: 0.264\n",
      "[66, 360] loss: 0.265\n",
      "Epoch: 66 -> Loss: 0.306922376156\n",
      "Epoch: 66 -> Test Accuracy: 83.29\n",
      "[67, 60] loss: 0.256\n",
      "[67, 120] loss: 0.255\n",
      "[67, 180] loss: 0.257\n",
      "[67, 240] loss: 0.254\n",
      "[67, 300] loss: 0.273\n",
      "[67, 360] loss: 0.254\n",
      "Epoch: 67 -> Loss: 0.164356261492\n",
      "Epoch: 67 -> Test Accuracy: 83.22\n",
      "[68, 60] loss: 0.256\n",
      "[68, 120] loss: 0.254\n",
      "[68, 180] loss: 0.251\n",
      "[68, 240] loss: 0.253\n",
      "[68, 300] loss: 0.270\n",
      "[68, 360] loss: 0.258\n",
      "Epoch: 68 -> Loss: 0.238198280334\n",
      "Epoch: 68 -> Test Accuracy: 83.33\n",
      "[69, 60] loss: 0.258\n",
      "[69, 120] loss: 0.269\n",
      "[69, 180] loss: 0.256\n",
      "[69, 240] loss: 0.247\n",
      "[69, 300] loss: 0.265\n",
      "[69, 360] loss: 0.268\n",
      "Epoch: 69 -> Loss: 0.374649614096\n",
      "Epoch: 69 -> Test Accuracy: 83.43\n",
      "[70, 60] loss: 0.264\n",
      "[70, 120] loss: 0.247\n",
      "[70, 180] loss: 0.265\n",
      "[70, 240] loss: 0.259\n",
      "[70, 300] loss: 0.261\n",
      "[70, 360] loss: 0.254\n",
      "Epoch: 70 -> Loss: 0.275229126215\n",
      "Epoch: 70 -> Test Accuracy: 83.35\n",
      "[71, 60] loss: 0.247\n",
      "[71, 120] loss: 0.262\n",
      "[71, 180] loss: 0.251\n",
      "[71, 240] loss: 0.269\n",
      "[71, 300] loss: 0.248\n",
      "[71, 360] loss: 0.259\n",
      "Epoch: 71 -> Loss: 0.302333086729\n",
      "Epoch: 71 -> Test Accuracy: 83.35\n",
      "[72, 60] loss: 0.261\n",
      "[72, 120] loss: 0.259\n",
      "[72, 180] loss: 0.255\n",
      "[72, 240] loss: 0.254\n",
      "[72, 300] loss: 0.260\n",
      "[72, 360] loss: 0.248\n",
      "Epoch: 72 -> Loss: 0.225901275873\n",
      "Epoch: 72 -> Test Accuracy: 83.43\n",
      "[73, 60] loss: 0.253\n",
      "[73, 120] loss: 0.248\n",
      "[73, 180] loss: 0.243\n",
      "[73, 240] loss: 0.267\n",
      "[73, 300] loss: 0.259\n",
      "[73, 360] loss: 0.266\n",
      "Epoch: 73 -> Loss: 0.194941610098\n",
      "Epoch: 73 -> Test Accuracy: 83.47\n",
      "[74, 60] loss: 0.249\n",
      "[74, 120] loss: 0.263\n",
      "[74, 180] loss: 0.257\n",
      "[74, 240] loss: 0.247\n",
      "[74, 300] loss: 0.246\n",
      "[74, 360] loss: 0.260\n",
      "Epoch: 74 -> Loss: 0.253519237041\n",
      "Epoch: 74 -> Test Accuracy: 83.41\n",
      "[75, 60] loss: 0.256\n",
      "[75, 120] loss: 0.261\n",
      "[75, 180] loss: 0.258\n",
      "[75, 240] loss: 0.260\n",
      "[75, 300] loss: 0.250\n",
      "[75, 360] loss: 0.240\n",
      "Epoch: 75 -> Loss: 0.293797433376\n",
      "Epoch: 75 -> Test Accuracy: 83.42\n",
      "[76, 60] loss: 0.262\n",
      "[76, 120] loss: 0.248\n",
      "[76, 180] loss: 0.263\n",
      "[76, 240] loss: 0.262\n",
      "[76, 300] loss: 0.235\n",
      "[76, 360] loss: 0.260\n",
      "Epoch: 76 -> Loss: 0.248577073216\n",
      "Epoch: 76 -> Test Accuracy: 83.27\n",
      "[77, 60] loss: 0.248\n",
      "[77, 120] loss: 0.237\n",
      "[77, 180] loss: 0.258\n",
      "[77, 240] loss: 0.252\n",
      "[77, 300] loss: 0.256\n",
      "[77, 360] loss: 0.248\n",
      "Epoch: 77 -> Loss: 0.313699632883\n",
      "Epoch: 77 -> Test Accuracy: 83.37\n",
      "[78, 60] loss: 0.251\n",
      "[78, 120] loss: 0.255\n",
      "[78, 180] loss: 0.250\n",
      "[78, 240] loss: 0.243\n",
      "[78, 300] loss: 0.241\n",
      "[78, 360] loss: 0.252\n",
      "Epoch: 78 -> Loss: 0.212097018957\n",
      "Epoch: 78 -> Test Accuracy: 83.31\n",
      "[79, 60] loss: 0.252\n",
      "[79, 120] loss: 0.250\n",
      "[79, 180] loss: 0.250\n",
      "[79, 240] loss: 0.241\n",
      "[79, 300] loss: 0.255\n",
      "[79, 360] loss: 0.243\n",
      "Epoch: 79 -> Loss: 0.38110011816\n",
      "Epoch: 79 -> Test Accuracy: 83.41\n",
      "[80, 60] loss: 0.244\n",
      "[80, 120] loss: 0.251\n",
      "[80, 180] loss: 0.256\n",
      "[80, 240] loss: 0.253\n",
      "[80, 300] loss: 0.237\n",
      "[80, 360] loss: 0.234\n",
      "Epoch: 80 -> Loss: 0.182914689183\n",
      "Epoch: 80 -> Test Accuracy: 83.28\n",
      "[81, 60] loss: 0.254\n",
      "[81, 120] loss: 0.246\n",
      "[81, 180] loss: 0.251\n",
      "[81, 240] loss: 0.241\n",
      "[81, 300] loss: 0.246\n",
      "[81, 360] loss: 0.254\n",
      "Epoch: 81 -> Loss: 0.26890707016\n",
      "Epoch: 81 -> Test Accuracy: 83.23\n",
      "[82, 60] loss: 0.236\n",
      "[82, 120] loss: 0.242\n",
      "[82, 180] loss: 0.250\n",
      "[82, 240] loss: 0.245\n",
      "[82, 300] loss: 0.242\n",
      "[82, 360] loss: 0.246\n",
      "Epoch: 82 -> Loss: 0.289670050144\n",
      "Epoch: 82 -> Test Accuracy: 83.27\n",
      "[83, 60] loss: 0.236\n",
      "[83, 120] loss: 0.235\n",
      "[83, 180] loss: 0.245\n",
      "[83, 240] loss: 0.257\n",
      "[83, 300] loss: 0.255\n",
      "[83, 360] loss: 0.239\n",
      "Epoch: 83 -> Loss: 0.255106121302\n",
      "Epoch: 83 -> Test Accuracy: 83.35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.251\n",
      "[84, 120] loss: 0.246\n",
      "[84, 180] loss: 0.241\n",
      "[84, 240] loss: 0.256\n",
      "[84, 300] loss: 0.235\n",
      "[84, 360] loss: 0.241\n",
      "Epoch: 84 -> Loss: 0.246954202652\n",
      "Epoch: 84 -> Test Accuracy: 83.45\n",
      "[85, 60] loss: 0.234\n",
      "[85, 120] loss: 0.241\n",
      "[85, 180] loss: 0.239\n",
      "[85, 240] loss: 0.243\n",
      "[85, 300] loss: 0.239\n",
      "[85, 360] loss: 0.238\n",
      "Epoch: 85 -> Loss: 0.22777299583\n",
      "Epoch: 85 -> Test Accuracy: 83.37\n",
      "[86, 60] loss: 0.248\n",
      "[86, 120] loss: 0.249\n",
      "[86, 180] loss: 0.245\n",
      "[86, 240] loss: 0.243\n",
      "[86, 300] loss: 0.252\n",
      "[86, 360] loss: 0.234\n",
      "Epoch: 86 -> Loss: 0.255852162838\n",
      "Epoch: 86 -> Test Accuracy: 83.32\n",
      "[87, 60] loss: 0.250\n",
      "[87, 120] loss: 0.252\n",
      "[87, 180] loss: 0.244\n",
      "[87, 240] loss: 0.233\n",
      "[87, 300] loss: 0.240\n",
      "[87, 360] loss: 0.252\n",
      "Epoch: 87 -> Loss: 0.240231230855\n",
      "Epoch: 87 -> Test Accuracy: 83.38\n",
      "[88, 60] loss: 0.236\n",
      "[88, 120] loss: 0.229\n",
      "[88, 180] loss: 0.232\n",
      "[88, 240] loss: 0.238\n",
      "[88, 300] loss: 0.228\n",
      "[88, 360] loss: 0.246\n",
      "Epoch: 88 -> Loss: 0.281571239233\n",
      "Epoch: 88 -> Test Accuracy: 83.31\n",
      "[89, 60] loss: 0.242\n",
      "[89, 120] loss: 0.246\n",
      "[89, 180] loss: 0.233\n",
      "[89, 240] loss: 0.244\n",
      "[89, 300] loss: 0.236\n",
      "[89, 360] loss: 0.251\n",
      "Epoch: 89 -> Loss: 0.148396864533\n",
      "Epoch: 89 -> Test Accuracy: 83.38\n",
      "[90, 60] loss: 0.239\n",
      "[90, 120] loss: 0.228\n",
      "[90, 180] loss: 0.235\n",
      "[90, 240] loss: 0.249\n",
      "[90, 300] loss: 0.248\n",
      "[90, 360] loss: 0.245\n",
      "Epoch: 90 -> Loss: 0.431709766388\n",
      "Epoch: 90 -> Test Accuracy: 83.45\n",
      "[91, 60] loss: 0.232\n",
      "[91, 120] loss: 0.230\n",
      "[91, 180] loss: 0.236\n",
      "[91, 240] loss: 0.243\n",
      "[91, 300] loss: 0.232\n",
      "[91, 360] loss: 0.248\n",
      "Epoch: 91 -> Loss: 0.154276877642\n",
      "Epoch: 91 -> Test Accuracy: 83.41\n",
      "[92, 60] loss: 0.236\n",
      "[92, 120] loss: 0.230\n",
      "[92, 180] loss: 0.239\n",
      "[92, 240] loss: 0.242\n",
      "[92, 300] loss: 0.247\n",
      "[92, 360] loss: 0.230\n",
      "Epoch: 92 -> Loss: 0.245642378926\n",
      "Epoch: 92 -> Test Accuracy: 83.28\n",
      "[93, 60] loss: 0.245\n",
      "[93, 120] loss: 0.235\n",
      "[93, 180] loss: 0.245\n",
      "[93, 240] loss: 0.244\n",
      "[93, 300] loss: 0.232\n",
      "[93, 360] loss: 0.230\n",
      "Epoch: 93 -> Loss: 0.265116930008\n",
      "Epoch: 93 -> Test Accuracy: 83.41\n",
      "[94, 60] loss: 0.232\n",
      "[94, 120] loss: 0.231\n",
      "[94, 180] loss: 0.237\n",
      "[94, 240] loss: 0.239\n",
      "[94, 300] loss: 0.224\n",
      "[94, 360] loss: 0.229\n",
      "Epoch: 94 -> Loss: 0.449088901281\n",
      "Epoch: 94 -> Test Accuracy: 83.47\n",
      "[95, 60] loss: 0.240\n",
      "[95, 120] loss: 0.242\n",
      "[95, 180] loss: 0.231\n",
      "[95, 240] loss: 0.238\n",
      "[95, 300] loss: 0.230\n",
      "[95, 360] loss: 0.232\n",
      "Epoch: 95 -> Loss: 0.26274895668\n",
      "Epoch: 95 -> Test Accuracy: 83.41\n",
      "[96, 60] loss: 0.222\n",
      "[96, 120] loss: 0.231\n",
      "[96, 180] loss: 0.238\n",
      "[96, 240] loss: 0.225\n",
      "[96, 300] loss: 0.231\n",
      "[96, 360] loss: 0.237\n",
      "Epoch: 96 -> Loss: 0.239543154836\n",
      "Epoch: 96 -> Test Accuracy: 83.44\n",
      "[97, 60] loss: 0.239\n",
      "[97, 120] loss: 0.236\n",
      "[97, 180] loss: 0.233\n",
      "[97, 240] loss: 0.237\n",
      "[97, 300] loss: 0.230\n",
      "[97, 360] loss: 0.226\n",
      "Epoch: 97 -> Loss: 0.244355291128\n",
      "Epoch: 97 -> Test Accuracy: 83.49\n",
      "[98, 60] loss: 0.236\n",
      "[98, 120] loss: 0.227\n",
      "[98, 180] loss: 0.234\n",
      "[98, 240] loss: 0.224\n",
      "[98, 300] loss: 0.234\n",
      "[98, 360] loss: 0.229\n",
      "Epoch: 98 -> Loss: 0.222419142723\n",
      "Epoch: 98 -> Test Accuracy: 83.42\n",
      "[99, 60] loss: 0.229\n",
      "[99, 120] loss: 0.223\n",
      "[99, 180] loss: 0.232\n",
      "[99, 240] loss: 0.235\n",
      "[99, 300] loss: 0.239\n",
      "[99, 360] loss: 0.233\n",
      "Epoch: 99 -> Loss: 0.245740026236\n",
      "Epoch: 99 -> Test Accuracy: 83.48\n",
      "[100, 60] loss: 0.226\n",
      "[100, 120] loss: 0.223\n",
      "[100, 180] loss: 0.229\n",
      "[100, 240] loss: 0.230\n",
      "[100, 300] loss: 0.238\n",
      "[100, 360] loss: 0.225\n",
      "Epoch: 100 -> Loss: 0.168329194188\n",
      "Epoch: 100 -> Test Accuracy: 83.27\n",
      "Finished Training\n",
      "[1, 60] loss: 1.745\n",
      "[1, 120] loss: 0.863\n",
      "[1, 180] loss: 0.774\n",
      "[1, 240] loss: 0.731\n",
      "[1, 300] loss: 0.680\n",
      "[1, 360] loss: 0.650\n",
      "Epoch: 1 -> Loss: 0.654619693756\n",
      "Epoch: 1 -> Test Accuracy: 77.24\n",
      "[2, 60] loss: 0.620\n",
      "[2, 120] loss: 0.608\n",
      "[2, 180] loss: 0.579\n",
      "[2, 240] loss: 0.570\n",
      "[2, 300] loss: 0.586\n",
      "[2, 360] loss: 0.579\n",
      "Epoch: 2 -> Loss: 0.530576348305\n",
      "Epoch: 2 -> Test Accuracy: 80.24\n",
      "[3, 60] loss: 0.530\n",
      "[3, 120] loss: 0.524\n",
      "[3, 180] loss: 0.531\n",
      "[3, 240] loss: 0.523\n",
      "[3, 300] loss: 0.513\n",
      "[3, 360] loss: 0.513\n",
      "Epoch: 3 -> Loss: 0.546792626381\n",
      "Epoch: 3 -> Test Accuracy: 81.55\n",
      "[4, 60] loss: 0.466\n",
      "[4, 120] loss: 0.478\n",
      "[4, 180] loss: 0.505\n",
      "[4, 240] loss: 0.478\n",
      "[4, 300] loss: 0.491\n",
      "[4, 360] loss: 0.492\n",
      "Epoch: 4 -> Loss: 0.443181037903\n",
      "Epoch: 4 -> Test Accuracy: 82.72\n",
      "[5, 60] loss: 0.453\n",
      "[5, 120] loss: 0.447\n",
      "[5, 180] loss: 0.456\n",
      "[5, 240] loss: 0.459\n",
      "[5, 300] loss: 0.462\n",
      "[5, 360] loss: 0.471\n",
      "Epoch: 5 -> Loss: 0.455438524485\n",
      "Epoch: 5 -> Test Accuracy: 82.84\n",
      "[6, 60] loss: 0.428\n",
      "[6, 120] loss: 0.435\n",
      "[6, 180] loss: 0.454\n",
      "[6, 240] loss: 0.438\n",
      "[6, 300] loss: 0.446\n",
      "[6, 360] loss: 0.447\n",
      "Epoch: 6 -> Loss: 0.50439119339\n",
      "Epoch: 6 -> Test Accuracy: 82.53\n",
      "[7, 60] loss: 0.421\n",
      "[7, 120] loss: 0.425\n",
      "[7, 180] loss: 0.444\n",
      "[7, 240] loss: 0.429\n",
      "[7, 300] loss: 0.450\n",
      "[7, 360] loss: 0.426\n",
      "Epoch: 7 -> Loss: 0.330092012882\n",
      "Epoch: 7 -> Test Accuracy: 83.4\n",
      "[8, 60] loss: 0.394\n",
      "[8, 120] loss: 0.424\n",
      "[8, 180] loss: 0.428\n",
      "[8, 240] loss: 0.428\n",
      "[8, 300] loss: 0.426\n",
      "[8, 360] loss: 0.433\n",
      "Epoch: 8 -> Loss: 0.392421901226\n",
      "Epoch: 8 -> Test Accuracy: 83.34\n",
      "[9, 60] loss: 0.396\n",
      "[9, 120] loss: 0.404\n",
      "[9, 180] loss: 0.407\n",
      "[9, 240] loss: 0.406\n",
      "[9, 300] loss: 0.427\n",
      "[9, 360] loss: 0.438\n",
      "Epoch: 9 -> Loss: 0.2425096035\n",
      "Epoch: 9 -> Test Accuracy: 83.65\n",
      "[10, 60] loss: 0.383\n",
      "[10, 120] loss: 0.413\n",
      "[10, 180] loss: 0.392\n",
      "[10, 240] loss: 0.408\n",
      "[10, 300] loss: 0.419\n",
      "[10, 360] loss: 0.416\n",
      "Epoch: 10 -> Loss: 0.36045640707\n",
      "Epoch: 10 -> Test Accuracy: 83.18\n",
      "[11, 60] loss: 0.384\n",
      "[11, 120] loss: 0.391\n",
      "[11, 180] loss: 0.387\n",
      "[11, 240] loss: 0.404\n",
      "[11, 300] loss: 0.413\n",
      "[11, 360] loss: 0.404\n",
      "Epoch: 11 -> Loss: 0.348749935627\n",
      "Epoch: 11 -> Test Accuracy: 83.21\n",
      "[12, 60] loss: 0.399\n",
      "[12, 120] loss: 0.386\n",
      "[12, 180] loss: 0.407\n",
      "[12, 240] loss: 0.392\n",
      "[12, 300] loss: 0.404\n",
      "[12, 360] loss: 0.408\n",
      "Epoch: 12 -> Loss: 0.432264626026\n",
      "Epoch: 12 -> Test Accuracy: 83.19\n",
      "[13, 60] loss: 0.383\n",
      "[13, 120] loss: 0.363\n",
      "[13, 180] loss: 0.397\n",
      "[13, 240] loss: 0.391\n",
      "[13, 300] loss: 0.395\n",
      "[13, 360] loss: 0.408\n",
      "Epoch: 13 -> Loss: 0.518537342548\n",
      "Epoch: 13 -> Test Accuracy: 83.34\n",
      "[14, 60] loss: 0.385\n",
      "[14, 120] loss: 0.377\n",
      "[14, 180] loss: 0.378\n",
      "[14, 240] loss: 0.394\n",
      "[14, 300] loss: 0.407\n",
      "[14, 360] loss: 0.398\n",
      "Epoch: 14 -> Loss: 0.356678009033\n",
      "Epoch: 14 -> Test Accuracy: 82.95\n",
      "[15, 60] loss: 0.369\n",
      "[15, 120] loss: 0.380\n",
      "[15, 180] loss: 0.377\n",
      "[15, 240] loss: 0.402\n",
      "[15, 300] loss: 0.384\n",
      "[15, 360] loss: 0.384\n",
      "Epoch: 15 -> Loss: 0.357821047306\n",
      "Epoch: 15 -> Test Accuracy: 83.27\n",
      "[16, 60] loss: 0.375\n",
      "[16, 120] loss: 0.380\n",
      "[16, 180] loss: 0.389\n",
      "[16, 240] loss: 0.371\n",
      "[16, 300] loss: 0.392\n",
      "[16, 360] loss: 0.412\n",
      "Epoch: 16 -> Loss: 0.727183580399\n",
      "Epoch: 16 -> Test Accuracy: 83.47\n",
      "[17, 60] loss: 0.361\n",
      "[17, 120] loss: 0.355\n",
      "[17, 180] loss: 0.382\n",
      "[17, 240] loss: 0.381\n",
      "[17, 300] loss: 0.391\n",
      "[17, 360] loss: 0.392\n",
      "Epoch: 17 -> Loss: 0.671167373657\n",
      "Epoch: 17 -> Test Accuracy: 83.45\n",
      "[18, 60] loss: 0.374\n",
      "[18, 120] loss: 0.363\n",
      "[18, 180] loss: 0.372\n",
      "[18, 240] loss: 0.376\n",
      "[18, 300] loss: 0.394\n",
      "[18, 360] loss: 0.401\n",
      "Epoch: 18 -> Loss: 0.520504593849\n",
      "Epoch: 18 -> Test Accuracy: 83.52\n",
      "[19, 60] loss: 0.367\n",
      "[19, 120] loss: 0.371\n",
      "[19, 180] loss: 0.390\n",
      "[19, 240] loss: 0.362\n",
      "[19, 300] loss: 0.393\n",
      "[19, 360] loss: 0.384\n",
      "Epoch: 19 -> Loss: 0.380099594593\n",
      "Epoch: 19 -> Test Accuracy: 83.64\n",
      "[20, 60] loss: 0.354\n",
      "[20, 120] loss: 0.363\n",
      "[20, 180] loss: 0.387\n",
      "[20, 240] loss: 0.379\n",
      "[20, 300] loss: 0.384\n",
      "[20, 360] loss: 0.377\n",
      "Epoch: 20 -> Loss: 0.305805236101\n",
      "Epoch: 20 -> Test Accuracy: 83.18\n",
      "[21, 60] loss: 0.334\n",
      "[21, 120] loss: 0.307\n",
      "[21, 180] loss: 0.293\n",
      "[21, 240] loss: 0.296\n",
      "[21, 300] loss: 0.293\n",
      "[21, 360] loss: 0.288\n",
      "Epoch: 21 -> Loss: 0.183130770922\n",
      "Epoch: 21 -> Test Accuracy: 85.56\n",
      "[22, 60] loss: 0.277\n",
      "[22, 120] loss: 0.257\n",
      "[22, 180] loss: 0.277\n",
      "[22, 240] loss: 0.269\n",
      "[22, 300] loss: 0.265\n",
      "[22, 360] loss: 0.272\n",
      "Epoch: 22 -> Loss: 0.311289221048\n",
      "Epoch: 22 -> Test Accuracy: 86.05\n",
      "[23, 60] loss: 0.243\n",
      "[23, 120] loss: 0.245\n",
      "[23, 180] loss: 0.246\n",
      "[23, 240] loss: 0.257\n",
      "[23, 300] loss: 0.255\n",
      "[23, 360] loss: 0.255\n",
      "Epoch: 23 -> Loss: 0.198388040066\n",
      "Epoch: 23 -> Test Accuracy: 85.74\n",
      "[24, 60] loss: 0.235\n",
      "[24, 120] loss: 0.231\n",
      "[24, 180] loss: 0.227\n",
      "[24, 240] loss: 0.230\n",
      "[24, 300] loss: 0.241\n",
      "[24, 360] loss: 0.246\n",
      "Epoch: 24 -> Loss: 0.46536809206\n",
      "Epoch: 24 -> Test Accuracy: 85.98\n",
      "[25, 60] loss: 0.233\n",
      "[25, 120] loss: 0.236\n",
      "[25, 180] loss: 0.235\n",
      "[25, 240] loss: 0.232\n",
      "[25, 300] loss: 0.238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 360] loss: 0.227\n",
      "Epoch: 25 -> Loss: 0.221594288945\n",
      "Epoch: 25 -> Test Accuracy: 86.12\n",
      "[26, 60] loss: 0.226\n",
      "[26, 120] loss: 0.213\n",
      "[26, 180] loss: 0.226\n",
      "[26, 240] loss: 0.223\n",
      "[26, 300] loss: 0.225\n",
      "[26, 360] loss: 0.235\n",
      "Epoch: 26 -> Loss: 0.343708008528\n",
      "Epoch: 26 -> Test Accuracy: 85.9\n",
      "[27, 60] loss: 0.200\n",
      "[27, 120] loss: 0.206\n",
      "[27, 180] loss: 0.219\n",
      "[27, 240] loss: 0.209\n",
      "[27, 300] loss: 0.229\n",
      "[27, 360] loss: 0.223\n",
      "Epoch: 27 -> Loss: 0.201035663486\n",
      "Epoch: 27 -> Test Accuracy: 86.02\n",
      "[28, 60] loss: 0.213\n",
      "[28, 120] loss: 0.208\n",
      "[28, 180] loss: 0.209\n",
      "[28, 240] loss: 0.218\n",
      "[28, 300] loss: 0.201\n",
      "[28, 360] loss: 0.223\n",
      "Epoch: 28 -> Loss: 0.112594246864\n",
      "Epoch: 28 -> Test Accuracy: 85.92\n",
      "[29, 60] loss: 0.207\n",
      "[29, 120] loss: 0.206\n",
      "[29, 180] loss: 0.206\n",
      "[29, 240] loss: 0.220\n",
      "[29, 300] loss: 0.211\n",
      "[29, 360] loss: 0.218\n",
      "Epoch: 29 -> Loss: 0.23797211051\n",
      "Epoch: 29 -> Test Accuracy: 85.39\n",
      "[30, 60] loss: 0.206\n",
      "[30, 120] loss: 0.203\n",
      "[30, 180] loss: 0.208\n",
      "[30, 240] loss: 0.219\n",
      "[30, 300] loss: 0.202\n",
      "[30, 360] loss: 0.220\n",
      "Epoch: 30 -> Loss: 0.369150429964\n",
      "Epoch: 30 -> Test Accuracy: 86.01\n",
      "[31, 60] loss: 0.201\n",
      "[31, 120] loss: 0.203\n",
      "[31, 180] loss: 0.198\n",
      "[31, 240] loss: 0.211\n",
      "[31, 300] loss: 0.223\n",
      "[31, 360] loss: 0.212\n",
      "Epoch: 31 -> Loss: 0.16332963109\n",
      "Epoch: 31 -> Test Accuracy: 85.67\n",
      "[32, 60] loss: 0.196\n",
      "[32, 120] loss: 0.191\n",
      "[32, 180] loss: 0.206\n",
      "[32, 240] loss: 0.207\n",
      "[32, 300] loss: 0.206\n",
      "[32, 360] loss: 0.214\n",
      "Epoch: 32 -> Loss: 0.256799221039\n",
      "Epoch: 32 -> Test Accuracy: 85.44\n",
      "[33, 60] loss: 0.200\n",
      "[33, 120] loss: 0.202\n",
      "[33, 180] loss: 0.203\n",
      "[33, 240] loss: 0.196\n",
      "[33, 300] loss: 0.208\n",
      "[33, 360] loss: 0.213\n",
      "Epoch: 33 -> Loss: 0.229832261801\n",
      "Epoch: 33 -> Test Accuracy: 86.03\n",
      "[34, 60] loss: 0.194\n",
      "[34, 120] loss: 0.201\n",
      "[34, 180] loss: 0.197\n",
      "[34, 240] loss: 0.193\n",
      "[34, 300] loss: 0.214\n",
      "[34, 360] loss: 0.212\n",
      "Epoch: 34 -> Loss: 0.262750774622\n",
      "Epoch: 34 -> Test Accuracy: 85.88\n",
      "[35, 60] loss: 0.195\n",
      "[35, 120] loss: 0.205\n",
      "[35, 180] loss: 0.204\n",
      "[35, 240] loss: 0.207\n",
      "[35, 300] loss: 0.214\n",
      "[35, 360] loss: 0.216\n",
      "Epoch: 35 -> Loss: 0.270020514727\n",
      "Epoch: 35 -> Test Accuracy: 85.57\n",
      "[36, 60] loss: 0.197\n",
      "[36, 120] loss: 0.197\n",
      "[36, 180] loss: 0.204\n",
      "[36, 240] loss: 0.201\n",
      "[36, 300] loss: 0.212\n",
      "[36, 360] loss: 0.202\n",
      "Epoch: 36 -> Loss: 0.188324958086\n",
      "Epoch: 36 -> Test Accuracy: 85.12\n",
      "[37, 60] loss: 0.196\n",
      "[37, 120] loss: 0.196\n",
      "[37, 180] loss: 0.205\n",
      "[37, 240] loss: 0.205\n",
      "[37, 300] loss: 0.197\n",
      "[37, 360] loss: 0.206\n",
      "Epoch: 37 -> Loss: 0.202489495277\n",
      "Epoch: 37 -> Test Accuracy: 85.44\n",
      "[38, 60] loss: 0.189\n",
      "[38, 120] loss: 0.206\n",
      "[38, 180] loss: 0.192\n",
      "[38, 240] loss: 0.200\n",
      "[38, 300] loss: 0.210\n",
      "[38, 360] loss: 0.207\n",
      "Epoch: 38 -> Loss: 0.174745589495\n",
      "Epoch: 38 -> Test Accuracy: 85.24\n",
      "[39, 60] loss: 0.184\n",
      "[39, 120] loss: 0.187\n",
      "[39, 180] loss: 0.200\n",
      "[39, 240] loss: 0.199\n",
      "[39, 300] loss: 0.207\n",
      "[39, 360] loss: 0.194\n",
      "Epoch: 39 -> Loss: 0.152025312185\n",
      "Epoch: 39 -> Test Accuracy: 85.1\n",
      "[40, 60] loss: 0.199\n",
      "[40, 120] loss: 0.190\n",
      "[40, 180] loss: 0.198\n",
      "[40, 240] loss: 0.190\n",
      "[40, 300] loss: 0.208\n",
      "[40, 360] loss: 0.208\n",
      "Epoch: 40 -> Loss: 0.209080785513\n",
      "Epoch: 40 -> Test Accuracy: 85.56\n",
      "[41, 60] loss: 0.184\n",
      "[41, 120] loss: 0.174\n",
      "[41, 180] loss: 0.172\n",
      "[41, 240] loss: 0.176\n",
      "[41, 300] loss: 0.159\n",
      "[41, 360] loss: 0.149\n",
      "Epoch: 41 -> Loss: 0.174417421222\n",
      "Epoch: 41 -> Test Accuracy: 86.24\n",
      "[42, 60] loss: 0.149\n",
      "[42, 120] loss: 0.155\n",
      "[42, 180] loss: 0.155\n",
      "[42, 240] loss: 0.150\n",
      "[42, 300] loss: 0.155\n",
      "[42, 360] loss: 0.141\n",
      "Epoch: 42 -> Loss: 0.166229009628\n",
      "Epoch: 42 -> Test Accuracy: 86.44\n",
      "[43, 60] loss: 0.142\n",
      "[43, 120] loss: 0.137\n",
      "[43, 180] loss: 0.136\n",
      "[43, 240] loss: 0.132\n",
      "[43, 300] loss: 0.152\n",
      "[43, 360] loss: 0.145\n",
      "Epoch: 43 -> Loss: 0.136629015207\n",
      "Epoch: 43 -> Test Accuracy: 86.44\n",
      "[44, 60] loss: 0.133\n",
      "[44, 120] loss: 0.134\n",
      "[44, 180] loss: 0.129\n",
      "[44, 240] loss: 0.129\n",
      "[44, 300] loss: 0.136\n",
      "[44, 360] loss: 0.130\n",
      "Epoch: 44 -> Loss: 0.247877046466\n",
      "Epoch: 44 -> Test Accuracy: 86.29\n",
      "[45, 60] loss: 0.132\n",
      "[45, 120] loss: 0.127\n",
      "[45, 180] loss: 0.128\n",
      "[45, 240] loss: 0.123\n",
      "[45, 300] loss: 0.121\n",
      "[45, 360] loss: 0.134\n",
      "Epoch: 45 -> Loss: 0.179699271917\n",
      "Epoch: 45 -> Test Accuracy: 86.55\n",
      "[46, 60] loss: 0.126\n",
      "[46, 120] loss: 0.123\n",
      "[46, 180] loss: 0.119\n",
      "[46, 240] loss: 0.118\n",
      "[46, 300] loss: 0.118\n",
      "[46, 360] loss: 0.124\n",
      "Epoch: 46 -> Loss: 0.213621348143\n",
      "Epoch: 46 -> Test Accuracy: 86.7\n",
      "[47, 60] loss: 0.117\n",
      "[47, 120] loss: 0.118\n",
      "[47, 180] loss: 0.116\n",
      "[47, 240] loss: 0.119\n",
      "[47, 300] loss: 0.121\n",
      "[47, 360] loss: 0.127\n",
      "Epoch: 47 -> Loss: 0.179429680109\n",
      "Epoch: 47 -> Test Accuracy: 86.46\n",
      "[48, 60] loss: 0.113\n",
      "[48, 120] loss: 0.121\n",
      "[48, 180] loss: 0.128\n",
      "[48, 240] loss: 0.113\n",
      "[48, 300] loss: 0.116\n",
      "[48, 360] loss: 0.114\n",
      "Epoch: 48 -> Loss: 0.0574719682336\n",
      "Epoch: 48 -> Test Accuracy: 86.69\n",
      "[49, 60] loss: 0.113\n",
      "[49, 120] loss: 0.119\n",
      "[49, 180] loss: 0.111\n",
      "[49, 240] loss: 0.119\n",
      "[49, 300] loss: 0.121\n",
      "[49, 360] loss: 0.119\n",
      "Epoch: 49 -> Loss: 0.165435880423\n",
      "Epoch: 49 -> Test Accuracy: 86.65\n",
      "[50, 60] loss: 0.111\n",
      "[50, 120] loss: 0.119\n",
      "[50, 180] loss: 0.115\n",
      "[50, 240] loss: 0.119\n",
      "[50, 300] loss: 0.115\n",
      "[50, 360] loss: 0.105\n",
      "Epoch: 50 -> Loss: 0.0711587145925\n",
      "Epoch: 50 -> Test Accuracy: 86.67\n",
      "[51, 60] loss: 0.112\n",
      "[51, 120] loss: 0.104\n",
      "[51, 180] loss: 0.114\n",
      "[51, 240] loss: 0.107\n",
      "[51, 300] loss: 0.116\n",
      "[51, 360] loss: 0.104\n",
      "Epoch: 51 -> Loss: 0.0655413642526\n",
      "Epoch: 51 -> Test Accuracy: 86.59\n",
      "[52, 60] loss: 0.112\n",
      "[52, 120] loss: 0.105\n",
      "[52, 180] loss: 0.107\n",
      "[52, 240] loss: 0.113\n",
      "[52, 300] loss: 0.117\n",
      "[52, 360] loss: 0.104\n",
      "Epoch: 52 -> Loss: 0.0957195907831\n",
      "Epoch: 52 -> Test Accuracy: 86.6\n",
      "[53, 60] loss: 0.109\n",
      "[53, 120] loss: 0.112\n",
      "[53, 180] loss: 0.123\n",
      "[53, 240] loss: 0.117\n",
      "[53, 300] loss: 0.105\n",
      "[53, 360] loss: 0.111\n",
      "Epoch: 53 -> Loss: 0.163976818323\n",
      "Epoch: 53 -> Test Accuracy: 86.55\n",
      "[54, 60] loss: 0.108\n",
      "[54, 120] loss: 0.113\n",
      "[54, 180] loss: 0.104\n",
      "[54, 240] loss: 0.107\n",
      "[54, 300] loss: 0.118\n",
      "[54, 360] loss: 0.105\n",
      "Epoch: 54 -> Loss: 0.102619744837\n",
      "Epoch: 54 -> Test Accuracy: 86.62\n",
      "[55, 60] loss: 0.103\n",
      "[55, 120] loss: 0.110\n",
      "[55, 180] loss: 0.109\n",
      "[55, 240] loss: 0.108\n",
      "[55, 300] loss: 0.110\n",
      "[55, 360] loss: 0.108\n",
      "Epoch: 55 -> Loss: 0.149560600519\n",
      "Epoch: 55 -> Test Accuracy: 86.76\n",
      "[56, 60] loss: 0.108\n",
      "[56, 120] loss: 0.110\n",
      "[56, 180] loss: 0.122\n",
      "[56, 240] loss: 0.105\n",
      "[56, 300] loss: 0.109\n",
      "[56, 360] loss: 0.106\n",
      "Epoch: 56 -> Loss: 0.132955789566\n",
      "Epoch: 56 -> Test Accuracy: 86.67\n",
      "[57, 60] loss: 0.107\n",
      "[57, 120] loss: 0.098\n",
      "[57, 180] loss: 0.103\n",
      "[57, 240] loss: 0.108\n",
      "[57, 300] loss: 0.112\n",
      "[57, 360] loss: 0.115\n",
      "Epoch: 57 -> Loss: 0.0615687668324\n",
      "Epoch: 57 -> Test Accuracy: 86.63\n",
      "[58, 60] loss: 0.102\n",
      "[58, 120] loss: 0.098\n",
      "[58, 180] loss: 0.118\n",
      "[58, 240] loss: 0.106\n",
      "[58, 300] loss: 0.099\n",
      "[58, 360] loss: 0.107\n",
      "Epoch: 58 -> Loss: 0.183577463031\n",
      "Epoch: 58 -> Test Accuracy: 86.58\n",
      "[59, 60] loss: 0.108\n",
      "[59, 120] loss: 0.096\n",
      "[59, 180] loss: 0.102\n",
      "[59, 240] loss: 0.106\n",
      "[59, 300] loss: 0.106\n",
      "[59, 360] loss: 0.103\n",
      "Epoch: 59 -> Loss: 0.0836831331253\n",
      "Epoch: 59 -> Test Accuracy: 86.66\n",
      "[60, 60] loss: 0.097\n",
      "[60, 120] loss: 0.097\n",
      "[60, 180] loss: 0.105\n",
      "[60, 240] loss: 0.103\n",
      "[60, 300] loss: 0.101\n",
      "[60, 360] loss: 0.104\n",
      "Epoch: 60 -> Loss: 0.156820297241\n",
      "Epoch: 60 -> Test Accuracy: 86.77\n",
      "[61, 60] loss: 0.099\n",
      "[61, 120] loss: 0.104\n",
      "[61, 180] loss: 0.104\n",
      "[61, 240] loss: 0.104\n",
      "[61, 300] loss: 0.099\n",
      "[61, 360] loss: 0.106\n",
      "Epoch: 61 -> Loss: 0.226027518511\n",
      "Epoch: 61 -> Test Accuracy: 86.71\n",
      "[62, 60] loss: 0.098\n",
      "[62, 120] loss: 0.094\n",
      "[62, 180] loss: 0.100\n",
      "[62, 240] loss: 0.097\n",
      "[62, 300] loss: 0.110\n",
      "[62, 360] loss: 0.102\n",
      "Epoch: 62 -> Loss: 0.11260779202\n",
      "Epoch: 62 -> Test Accuracy: 86.78\n",
      "[63, 60] loss: 0.101\n",
      "[63, 120] loss: 0.103\n",
      "[63, 180] loss: 0.099\n",
      "[63, 240] loss: 0.103\n",
      "[63, 300] loss: 0.094\n",
      "[63, 360] loss: 0.102\n",
      "Epoch: 63 -> Loss: 0.056285161525\n",
      "Epoch: 63 -> Test Accuracy: 86.77\n",
      "[64, 60] loss: 0.097\n",
      "[64, 120] loss: 0.103\n",
      "[64, 180] loss: 0.096\n",
      "[64, 240] loss: 0.092\n",
      "[64, 300] loss: 0.093\n",
      "[64, 360] loss: 0.103\n",
      "Epoch: 64 -> Loss: 0.0294111128896\n",
      "Epoch: 64 -> Test Accuracy: 86.76\n",
      "[65, 60] loss: 0.096\n",
      "[65, 120] loss: 0.097\n",
      "[65, 180] loss: 0.103\n",
      "[65, 240] loss: 0.100\n",
      "[65, 300] loss: 0.099\n",
      "[65, 360] loss: 0.097\n",
      "Epoch: 65 -> Loss: 0.0502840280533\n",
      "Epoch: 65 -> Test Accuracy: 86.88\n",
      "[66, 60] loss: 0.097\n",
      "[66, 120] loss: 0.093\n",
      "[66, 180] loss: 0.091\n",
      "[66, 240] loss: 0.094\n",
      "[66, 300] loss: 0.098\n",
      "[66, 360] loss: 0.096\n",
      "Epoch: 66 -> Loss: 0.0910816043615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Test Accuracy: 86.76\n",
      "[67, 60] loss: 0.096\n",
      "[67, 120] loss: 0.091\n",
      "[67, 180] loss: 0.092\n",
      "[67, 240] loss: 0.099\n",
      "[67, 300] loss: 0.098\n",
      "[67, 360] loss: 0.098\n",
      "Epoch: 67 -> Loss: 0.113866731524\n",
      "Epoch: 67 -> Test Accuracy: 86.73\n",
      "[68, 60] loss: 0.101\n",
      "[68, 120] loss: 0.098\n",
      "[68, 180] loss: 0.097\n",
      "[68, 240] loss: 0.101\n",
      "[68, 300] loss: 0.095\n",
      "[68, 360] loss: 0.091\n",
      "Epoch: 68 -> Loss: 0.0782416015863\n",
      "Epoch: 68 -> Test Accuracy: 86.71\n",
      "[69, 60] loss: 0.096\n",
      "[69, 120] loss: 0.100\n",
      "[69, 180] loss: 0.091\n",
      "[69, 240] loss: 0.092\n",
      "[69, 300] loss: 0.100\n",
      "[69, 360] loss: 0.095\n",
      "Epoch: 69 -> Loss: 0.112689360976\n",
      "Epoch: 69 -> Test Accuracy: 86.73\n",
      "[70, 60] loss: 0.093\n",
      "[70, 120] loss: 0.095\n",
      "[70, 180] loss: 0.095\n",
      "[70, 240] loss: 0.092\n",
      "[70, 300] loss: 0.092\n",
      "[70, 360] loss: 0.094\n",
      "Epoch: 70 -> Loss: 0.143882080913\n",
      "Epoch: 70 -> Test Accuracy: 86.65\n",
      "[71, 60] loss: 0.088\n",
      "[71, 120] loss: 0.087\n",
      "[71, 180] loss: 0.086\n",
      "[71, 240] loss: 0.098\n",
      "[71, 300] loss: 0.096\n",
      "[71, 360] loss: 0.088\n",
      "Epoch: 71 -> Loss: 0.212040945888\n",
      "Epoch: 71 -> Test Accuracy: 86.73\n",
      "[72, 60] loss: 0.087\n",
      "[72, 120] loss: 0.095\n",
      "[72, 180] loss: 0.093\n",
      "[72, 240] loss: 0.094\n",
      "[72, 300] loss: 0.098\n",
      "[72, 360] loss: 0.096\n",
      "Epoch: 72 -> Loss: 0.068669192493\n",
      "Epoch: 72 -> Test Accuracy: 86.72\n",
      "[73, 60] loss: 0.096\n",
      "[73, 120] loss: 0.082\n",
      "[73, 180] loss: 0.083\n",
      "[73, 240] loss: 0.084\n",
      "[73, 300] loss: 0.088\n",
      "[73, 360] loss: 0.095\n",
      "Epoch: 73 -> Loss: 0.0874121785164\n",
      "Epoch: 73 -> Test Accuracy: 86.6\n",
      "[74, 60] loss: 0.088\n",
      "[74, 120] loss: 0.088\n",
      "[74, 180] loss: 0.086\n",
      "[74, 240] loss: 0.094\n",
      "[74, 300] loss: 0.092\n",
      "[74, 360] loss: 0.093\n",
      "Epoch: 74 -> Loss: 0.1524784863\n",
      "Epoch: 74 -> Test Accuracy: 86.75\n",
      "[75, 60] loss: 0.087\n",
      "[75, 120] loss: 0.095\n",
      "[75, 180] loss: 0.084\n",
      "[75, 240] loss: 0.090\n",
      "[75, 300] loss: 0.095\n",
      "[75, 360] loss: 0.088\n",
      "Epoch: 75 -> Loss: 0.117924071848\n",
      "Epoch: 75 -> Test Accuracy: 86.69\n",
      "[76, 60] loss: 0.086\n",
      "[76, 120] loss: 0.089\n",
      "[76, 180] loss: 0.089\n",
      "[76, 240] loss: 0.092\n",
      "[76, 300] loss: 0.098\n",
      "[76, 360] loss: 0.089\n",
      "Epoch: 76 -> Loss: 0.0655680000782\n",
      "Epoch: 76 -> Test Accuracy: 86.66\n",
      "[77, 60] loss: 0.094\n",
      "[77, 120] loss: 0.100\n",
      "[77, 180] loss: 0.086\n",
      "[77, 240] loss: 0.094\n",
      "[77, 300] loss: 0.086\n",
      "[77, 360] loss: 0.086\n",
      "Epoch: 77 -> Loss: 0.1560960114\n",
      "Epoch: 77 -> Test Accuracy: 86.7\n",
      "[78, 60] loss: 0.084\n",
      "[78, 120] loss: 0.080\n",
      "[78, 180] loss: 0.088\n",
      "[78, 240] loss: 0.099\n",
      "[78, 300] loss: 0.084\n",
      "[78, 360] loss: 0.099\n",
      "Epoch: 78 -> Loss: 0.186573892832\n",
      "Epoch: 78 -> Test Accuracy: 86.57\n",
      "[79, 60] loss: 0.086\n",
      "[79, 120] loss: 0.091\n",
      "[79, 180] loss: 0.094\n",
      "[79, 240] loss: 0.089\n",
      "[79, 300] loss: 0.090\n",
      "[79, 360] loss: 0.079\n",
      "Epoch: 79 -> Loss: 0.218056842685\n",
      "Epoch: 79 -> Test Accuracy: 86.71\n",
      "[80, 60] loss: 0.088\n",
      "[80, 120] loss: 0.080\n",
      "[80, 180] loss: 0.089\n",
      "[80, 240] loss: 0.090\n",
      "[80, 300] loss: 0.082\n",
      "[80, 360] loss: 0.090\n",
      "Epoch: 80 -> Loss: 0.0320429876447\n",
      "Epoch: 80 -> Test Accuracy: 86.48\n",
      "[81, 60] loss: 0.083\n",
      "[81, 120] loss: 0.087\n",
      "[81, 180] loss: 0.085\n",
      "[81, 240] loss: 0.092\n",
      "[81, 300] loss: 0.082\n",
      "[81, 360] loss: 0.094\n",
      "Epoch: 81 -> Loss: 0.0482819490135\n",
      "Epoch: 81 -> Test Accuracy: 86.65\n",
      "[82, 60] loss: 0.083\n",
      "[82, 120] loss: 0.091\n",
      "[82, 180] loss: 0.091\n",
      "[82, 240] loss: 0.088\n",
      "[82, 300] loss: 0.082\n",
      "[82, 360] loss: 0.091\n",
      "Epoch: 82 -> Loss: 0.0644832402468\n",
      "Epoch: 82 -> Test Accuracy: 86.61\n",
      "[83, 60] loss: 0.092\n",
      "[83, 120] loss: 0.081\n",
      "[83, 180] loss: 0.087\n",
      "[83, 240] loss: 0.086\n",
      "[83, 300] loss: 0.091\n",
      "[83, 360] loss: 0.086\n",
      "Epoch: 83 -> Loss: 0.0549323260784\n",
      "Epoch: 83 -> Test Accuracy: 86.68\n",
      "[84, 60] loss: 0.085\n",
      "[84, 120] loss: 0.082\n",
      "[84, 180] loss: 0.081\n",
      "[84, 240] loss: 0.085\n",
      "[84, 300] loss: 0.082\n",
      "[84, 360] loss: 0.090\n",
      "Epoch: 84 -> Loss: 0.0366403162479\n",
      "Epoch: 84 -> Test Accuracy: 86.7\n",
      "[85, 60] loss: 0.090\n",
      "[85, 120] loss: 0.086\n",
      "[85, 180] loss: 0.086\n",
      "[85, 240] loss: 0.087\n",
      "[85, 300] loss: 0.088\n",
      "[85, 360] loss: 0.081\n",
      "Epoch: 85 -> Loss: 0.0787879675627\n",
      "Epoch: 85 -> Test Accuracy: 86.59\n",
      "[86, 60] loss: 0.080\n",
      "[86, 120] loss: 0.091\n",
      "[86, 180] loss: 0.088\n",
      "[86, 240] loss: 0.086\n",
      "[86, 300] loss: 0.085\n",
      "[86, 360] loss: 0.088\n",
      "Epoch: 86 -> Loss: 0.136792734265\n",
      "Epoch: 86 -> Test Accuracy: 86.52\n",
      "[87, 60] loss: 0.085\n",
      "[87, 120] loss: 0.084\n",
      "[87, 180] loss: 0.084\n",
      "[87, 240] loss: 0.083\n",
      "[87, 300] loss: 0.086\n",
      "[87, 360] loss: 0.078\n",
      "Epoch: 87 -> Loss: 0.108244851232\n",
      "Epoch: 87 -> Test Accuracy: 86.47\n",
      "[88, 60] loss: 0.088\n",
      "[88, 120] loss: 0.087\n",
      "[88, 180] loss: 0.075\n",
      "[88, 240] loss: 0.080\n",
      "[88, 300] loss: 0.085\n",
      "[88, 360] loss: 0.081\n",
      "Epoch: 88 -> Loss: 0.0468224659562\n",
      "Epoch: 88 -> Test Accuracy: 86.65\n",
      "[89, 60] loss: 0.083\n",
      "[89, 120] loss: 0.082\n",
      "[89, 180] loss: 0.086\n",
      "[89, 240] loss: 0.083\n",
      "[89, 300] loss: 0.088\n",
      "[89, 360] loss: 0.078\n",
      "Epoch: 89 -> Loss: 0.0911633372307\n",
      "Epoch: 89 -> Test Accuracy: 86.78\n",
      "[90, 60] loss: 0.081\n",
      "[90, 120] loss: 0.074\n",
      "[90, 180] loss: 0.086\n",
      "[90, 240] loss: 0.082\n",
      "[90, 300] loss: 0.083\n",
      "[90, 360] loss: 0.080\n",
      "Epoch: 90 -> Loss: 0.0690795481205\n",
      "Epoch: 90 -> Test Accuracy: 86.72\n",
      "[91, 60] loss: 0.087\n",
      "[91, 120] loss: 0.082\n",
      "[91, 180] loss: 0.078\n",
      "[91, 240] loss: 0.085\n",
      "[91, 300] loss: 0.078\n",
      "[91, 360] loss: 0.085\n",
      "Epoch: 91 -> Loss: 0.0545829311013\n",
      "Epoch: 91 -> Test Accuracy: 86.72\n",
      "[92, 60] loss: 0.083\n",
      "[92, 120] loss: 0.077\n",
      "[92, 180] loss: 0.084\n",
      "[92, 240] loss: 0.079\n",
      "[92, 300] loss: 0.087\n",
      "[92, 360] loss: 0.076\n",
      "Epoch: 92 -> Loss: 0.177112072706\n",
      "Epoch: 92 -> Test Accuracy: 86.64\n",
      "[93, 60] loss: 0.084\n",
      "[93, 120] loss: 0.082\n",
      "[93, 180] loss: 0.085\n",
      "[93, 240] loss: 0.081\n",
      "[93, 300] loss: 0.088\n",
      "[93, 360] loss: 0.077\n",
      "Epoch: 93 -> Loss: 0.116029545665\n",
      "Epoch: 93 -> Test Accuracy: 86.71\n",
      "[94, 60] loss: 0.086\n",
      "[94, 120] loss: 0.074\n",
      "[94, 180] loss: 0.074\n",
      "[94, 240] loss: 0.085\n",
      "[94, 300] loss: 0.084\n",
      "[94, 360] loss: 0.078\n",
      "Epoch: 94 -> Loss: 0.0930051058531\n",
      "Epoch: 94 -> Test Accuracy: 86.6\n",
      "[95, 60] loss: 0.072\n",
      "[95, 120] loss: 0.078\n",
      "[95, 180] loss: 0.078\n",
      "[95, 240] loss: 0.076\n",
      "[95, 300] loss: 0.083\n",
      "[95, 360] loss: 0.085\n",
      "Epoch: 95 -> Loss: 0.0507537014782\n",
      "Epoch: 95 -> Test Accuracy: 86.53\n",
      "[96, 60] loss: 0.075\n",
      "[96, 120] loss: 0.082\n",
      "[96, 180] loss: 0.080\n",
      "[96, 240] loss: 0.078\n",
      "[96, 300] loss: 0.089\n",
      "[96, 360] loss: 0.073\n",
      "Epoch: 96 -> Loss: 0.0957245975733\n",
      "Epoch: 96 -> Test Accuracy: 86.64\n",
      "[97, 60] loss: 0.076\n",
      "[97, 120] loss: 0.075\n",
      "[97, 180] loss: 0.074\n",
      "[97, 240] loss: 0.075\n",
      "[97, 300] loss: 0.088\n",
      "[97, 360] loss: 0.080\n",
      "Epoch: 97 -> Loss: 0.0793791413307\n",
      "Epoch: 97 -> Test Accuracy: 86.57\n",
      "[98, 60] loss: 0.074\n",
      "[98, 120] loss: 0.079\n",
      "[98, 180] loss: 0.082\n",
      "[98, 240] loss: 0.076\n",
      "[98, 300] loss: 0.083\n",
      "[98, 360] loss: 0.079\n",
      "Epoch: 98 -> Loss: 0.111175380647\n",
      "Epoch: 98 -> Test Accuracy: 86.65\n",
      "[99, 60] loss: 0.072\n",
      "[99, 120] loss: 0.074\n",
      "[99, 180] loss: 0.073\n",
      "[99, 240] loss: 0.078\n",
      "[99, 300] loss: 0.068\n",
      "[99, 360] loss: 0.084\n",
      "Epoch: 99 -> Loss: 0.0964418426156\n",
      "Epoch: 99 -> Test Accuracy: 86.68\n",
      "[100, 60] loss: 0.079\n",
      "[100, 120] loss: 0.078\n",
      "[100, 180] loss: 0.071\n",
      "[100, 240] loss: 0.075\n",
      "[100, 300] loss: 0.078\n",
      "[100, 360] loss: 0.076\n",
      "Epoch: 100 -> Loss: 0.102038219571\n",
      "Epoch: 100 -> Test Accuracy: 86.71\n",
      "Finished Training\n",
      "[1, 60] loss: 1.687\n",
      "[1, 120] loss: 0.870\n",
      "[1, 180] loss: 0.817\n",
      "[1, 240] loss: 0.762\n",
      "[1, 300] loss: 0.737\n",
      "[1, 360] loss: 0.744\n",
      "Epoch: 1 -> Loss: 0.684639036655\n",
      "Epoch: 1 -> Test Accuracy: 73.79\n",
      "[2, 60] loss: 0.674\n",
      "[2, 120] loss: 0.682\n",
      "[2, 180] loss: 0.653\n",
      "[2, 240] loss: 0.647\n",
      "[2, 300] loss: 0.650\n",
      "[2, 360] loss: 0.650\n",
      "Epoch: 2 -> Loss: 0.598153531551\n",
      "Epoch: 2 -> Test Accuracy: 76.34\n",
      "[3, 60] loss: 0.614\n",
      "[3, 120] loss: 0.624\n",
      "[3, 180] loss: 0.598\n",
      "[3, 240] loss: 0.618\n",
      "[3, 300] loss: 0.606\n",
      "[3, 360] loss: 0.590\n",
      "Epoch: 3 -> Loss: 0.789441525936\n",
      "Epoch: 3 -> Test Accuracy: 77.38\n",
      "[4, 60] loss: 0.580\n",
      "[4, 120] loss: 0.586\n",
      "[4, 180] loss: 0.568\n",
      "[4, 240] loss: 0.572\n",
      "[4, 300] loss: 0.588\n",
      "[4, 360] loss: 0.569\n",
      "Epoch: 4 -> Loss: 0.512693703175\n",
      "Epoch: 4 -> Test Accuracy: 77.89\n",
      "[5, 60] loss: 0.545\n",
      "[5, 120] loss: 0.566\n",
      "[5, 180] loss: 0.564\n",
      "[5, 240] loss: 0.564\n",
      "[5, 300] loss: 0.556\n",
      "[5, 360] loss: 0.562\n",
      "Epoch: 5 -> Loss: 0.434615463018\n",
      "Epoch: 5 -> Test Accuracy: 77.65\n",
      "[6, 60] loss: 0.540\n",
      "[6, 120] loss: 0.544\n",
      "[6, 180] loss: 0.542\n",
      "[6, 240] loss: 0.544\n",
      "[6, 300] loss: 0.537\n",
      "[6, 360] loss: 0.546\n",
      "Epoch: 6 -> Loss: 0.415800988674\n",
      "Epoch: 6 -> Test Accuracy: 78.6\n",
      "[7, 60] loss: 0.525\n",
      "[7, 120] loss: 0.509\n",
      "[7, 180] loss: 0.535\n",
      "[7, 240] loss: 0.536\n",
      "[7, 300] loss: 0.547\n",
      "[7, 360] loss: 0.535\n",
      "Epoch: 7 -> Loss: 0.568326175213\n",
      "Epoch: 7 -> Test Accuracy: 78.53\n",
      "[8, 60] loss: 0.513\n",
      "[8, 120] loss: 0.521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 180] loss: 0.522\n",
      "[8, 240] loss: 0.537\n",
      "[8, 300] loss: 0.519\n",
      "[8, 360] loss: 0.519\n",
      "Epoch: 8 -> Loss: 0.485580921173\n",
      "Epoch: 8 -> Test Accuracy: 78.78\n",
      "[9, 60] loss: 0.519\n",
      "[9, 120] loss: 0.498\n",
      "[9, 180] loss: 0.509\n",
      "[9, 240] loss: 0.524\n",
      "[9, 300] loss: 0.525\n",
      "[9, 360] loss: 0.530\n",
      "Epoch: 9 -> Loss: 0.718882203102\n",
      "Epoch: 9 -> Test Accuracy: 79.1\n",
      "[10, 60] loss: 0.493\n",
      "[10, 120] loss: 0.506\n",
      "[10, 180] loss: 0.523\n",
      "[10, 240] loss: 0.521\n",
      "[10, 300] loss: 0.515\n",
      "[10, 360] loss: 0.517\n",
      "Epoch: 10 -> Loss: 0.552429378033\n",
      "Epoch: 10 -> Test Accuracy: 78.67\n",
      "[11, 60] loss: 0.491\n",
      "[11, 120] loss: 0.499\n",
      "[11, 180] loss: 0.497\n",
      "[11, 240] loss: 0.521\n",
      "[11, 300] loss: 0.512\n",
      "[11, 360] loss: 0.504\n",
      "Epoch: 11 -> Loss: 0.56935864687\n",
      "Epoch: 11 -> Test Accuracy: 78.76\n",
      "[12, 60] loss: 0.468\n",
      "[12, 120] loss: 0.512\n",
      "[12, 180] loss: 0.492\n",
      "[12, 240] loss: 0.497\n",
      "[12, 300] loss: 0.511\n",
      "[12, 360] loss: 0.525\n",
      "Epoch: 12 -> Loss: 0.377523958683\n",
      "Epoch: 12 -> Test Accuracy: 78.71\n",
      "[13, 60] loss: 0.485\n",
      "[13, 120] loss: 0.494\n",
      "[13, 180] loss: 0.495\n",
      "[13, 240] loss: 0.520\n",
      "[13, 300] loss: 0.485\n",
      "[13, 360] loss: 0.513\n",
      "Epoch: 13 -> Loss: 0.487623214722\n",
      "Epoch: 13 -> Test Accuracy: 79.19\n",
      "[14, 60] loss: 0.476\n",
      "[14, 120] loss: 0.481\n",
      "[14, 180] loss: 0.492\n",
      "[14, 240] loss: 0.487\n",
      "[14, 300] loss: 0.515\n",
      "[14, 360] loss: 0.483\n",
      "Epoch: 14 -> Loss: 0.53549516201\n",
      "Epoch: 14 -> Test Accuracy: 78.59\n",
      "[15, 60] loss: 0.477\n",
      "[15, 120] loss: 0.469\n",
      "[15, 180] loss: 0.493\n",
      "[15, 240] loss: 0.492\n",
      "[15, 300] loss: 0.509\n",
      "[15, 360] loss: 0.510\n",
      "Epoch: 15 -> Loss: 0.524719357491\n",
      "Epoch: 15 -> Test Accuracy: 79.47\n",
      "[16, 60] loss: 0.489\n",
      "[16, 120] loss: 0.474\n",
      "[16, 180] loss: 0.488\n",
      "[16, 240] loss: 0.480\n",
      "[16, 300] loss: 0.512\n",
      "[16, 360] loss: 0.513\n",
      "Epoch: 16 -> Loss: 0.491642475128\n",
      "Epoch: 16 -> Test Accuracy: 79.17\n",
      "[17, 60] loss: 0.491\n",
      "[17, 120] loss: 0.479\n",
      "[17, 180] loss: 0.483\n",
      "[17, 240] loss: 0.474\n",
      "[17, 300] loss: 0.501\n",
      "[17, 360] loss: 0.498\n",
      "Epoch: 17 -> Loss: 0.527418911457\n",
      "Epoch: 17 -> Test Accuracy: 79.42\n",
      "[18, 60] loss: 0.469\n",
      "[18, 120] loss: 0.494\n",
      "[18, 180] loss: 0.480\n",
      "[18, 240] loss: 0.475\n",
      "[18, 300] loss: 0.491\n",
      "[18, 360] loss: 0.497\n",
      "Epoch: 18 -> Loss: 0.628621041775\n",
      "Epoch: 18 -> Test Accuracy: 79.78\n",
      "[19, 60] loss: 0.488\n",
      "[19, 120] loss: 0.470\n",
      "[19, 180] loss: 0.482\n",
      "[19, 240] loss: 0.477\n",
      "[19, 300] loss: 0.482\n",
      "[19, 360] loss: 0.491\n",
      "Epoch: 19 -> Loss: 0.420696496964\n",
      "Epoch: 19 -> Test Accuracy: 78.78\n",
      "[20, 60] loss: 0.487\n",
      "[20, 120] loss: 0.481\n",
      "[20, 180] loss: 0.479\n",
      "[20, 240] loss: 0.478\n",
      "[20, 300] loss: 0.479\n",
      "[20, 360] loss: 0.483\n",
      "Epoch: 20 -> Loss: 0.463486015797\n",
      "Epoch: 20 -> Test Accuracy: 79.69\n",
      "[21, 60] loss: 0.439\n",
      "[21, 120] loss: 0.424\n",
      "[21, 180] loss: 0.427\n",
      "[21, 240] loss: 0.406\n",
      "[21, 300] loss: 0.395\n",
      "[21, 360] loss: 0.421\n",
      "Epoch: 21 -> Loss: 0.546371817589\n",
      "Epoch: 21 -> Test Accuracy: 81.18\n",
      "[22, 60] loss: 0.382\n",
      "[22, 120] loss: 0.380\n",
      "[22, 180] loss: 0.380\n",
      "[22, 240] loss: 0.383\n",
      "[22, 300] loss: 0.367\n",
      "[22, 360] loss: 0.383\n",
      "Epoch: 22 -> Loss: 0.514415621758\n",
      "Epoch: 22 -> Test Accuracy: 81.27\n",
      "[23, 60] loss: 0.395\n",
      "[23, 120] loss: 0.367\n",
      "[23, 180] loss: 0.376\n",
      "[23, 240] loss: 0.370\n",
      "[23, 300] loss: 0.367\n",
      "[23, 360] loss: 0.373\n",
      "Epoch: 23 -> Loss: 0.454000145197\n",
      "Epoch: 23 -> Test Accuracy: 81.91\n",
      "[24, 60] loss: 0.359\n",
      "[24, 120] loss: 0.356\n",
      "[24, 180] loss: 0.369\n",
      "[24, 240] loss: 0.361\n",
      "[24, 300] loss: 0.337\n",
      "[24, 360] loss: 0.349\n",
      "Epoch: 24 -> Loss: 0.379921317101\n",
      "Epoch: 24 -> Test Accuracy: 81.81\n",
      "[25, 60] loss: 0.359\n",
      "[25, 120] loss: 0.347\n",
      "[25, 180] loss: 0.357\n",
      "[25, 240] loss: 0.349\n",
      "[25, 300] loss: 0.351\n",
      "[25, 360] loss: 0.350\n",
      "Epoch: 25 -> Loss: 0.407897055149\n",
      "Epoch: 25 -> Test Accuracy: 81.87\n",
      "[26, 60] loss: 0.336\n",
      "[26, 120] loss: 0.327\n",
      "[26, 180] loss: 0.343\n",
      "[26, 240] loss: 0.350\n",
      "[26, 300] loss: 0.344\n",
      "[26, 360] loss: 0.355\n",
      "Epoch: 26 -> Loss: 0.545832753181\n",
      "Epoch: 26 -> Test Accuracy: 81.54\n",
      "[27, 60] loss: 0.336\n",
      "[27, 120] loss: 0.345\n",
      "[27, 180] loss: 0.361\n",
      "[27, 240] loss: 0.351\n",
      "[27, 300] loss: 0.339\n",
      "[27, 360] loss: 0.332\n",
      "Epoch: 27 -> Loss: 0.225874498487\n",
      "Epoch: 27 -> Test Accuracy: 81.74\n",
      "[28, 60] loss: 0.338\n",
      "[28, 120] loss: 0.335\n",
      "[28, 180] loss: 0.324\n",
      "[28, 240] loss: 0.328\n",
      "[28, 300] loss: 0.338\n",
      "[28, 360] loss: 0.343\n",
      "Epoch: 28 -> Loss: 0.396520793438\n",
      "Epoch: 28 -> Test Accuracy: 82.23\n",
      "[29, 60] loss: 0.312\n",
      "[29, 120] loss: 0.330\n",
      "[29, 180] loss: 0.343\n",
      "[29, 240] loss: 0.337\n",
      "[29, 300] loss: 0.339\n",
      "[29, 360] loss: 0.331\n",
      "Epoch: 29 -> Loss: 0.300642311573\n",
      "Epoch: 29 -> Test Accuracy: 81.68\n",
      "[30, 60] loss: 0.327\n",
      "[30, 120] loss: 0.335\n",
      "[30, 180] loss: 0.330\n",
      "[30, 240] loss: 0.333\n",
      "[30, 300] loss: 0.332\n",
      "[30, 360] loss: 0.337\n",
      "Epoch: 30 -> Loss: 0.268537729979\n",
      "Epoch: 30 -> Test Accuracy: 81.74\n",
      "[31, 60] loss: 0.317\n",
      "[31, 120] loss: 0.337\n",
      "[31, 180] loss: 0.321\n",
      "[31, 240] loss: 0.327\n",
      "[31, 300] loss: 0.336\n",
      "[31, 360] loss: 0.344\n",
      "Epoch: 31 -> Loss: 0.205854818225\n",
      "Epoch: 31 -> Test Accuracy: 81.73\n",
      "[32, 60] loss: 0.307\n",
      "[32, 120] loss: 0.311\n",
      "[32, 180] loss: 0.316\n",
      "[32, 240] loss: 0.325\n",
      "[32, 300] loss: 0.335\n",
      "[32, 360] loss: 0.332\n",
      "Epoch: 32 -> Loss: 0.354845225811\n",
      "Epoch: 32 -> Test Accuracy: 81.74\n",
      "[33, 60] loss: 0.317\n",
      "[33, 120] loss: 0.330\n",
      "[33, 180] loss: 0.323\n",
      "[33, 240] loss: 0.341\n",
      "[33, 300] loss: 0.324\n",
      "[33, 360] loss: 0.331\n",
      "Epoch: 33 -> Loss: 0.464251279831\n",
      "Epoch: 33 -> Test Accuracy: 82.05\n",
      "[34, 60] loss: 0.327\n",
      "[34, 120] loss: 0.311\n",
      "[34, 180] loss: 0.321\n",
      "[34, 240] loss: 0.310\n",
      "[34, 300] loss: 0.343\n",
      "[34, 360] loss: 0.331\n",
      "Epoch: 34 -> Loss: 0.356078207493\n",
      "Epoch: 34 -> Test Accuracy: 81.89\n",
      "[35, 60] loss: 0.311\n",
      "[35, 120] loss: 0.319\n",
      "[35, 180] loss: 0.327\n",
      "[35, 240] loss: 0.320\n",
      "[35, 300] loss: 0.321\n",
      "[35, 360] loss: 0.321\n",
      "Epoch: 35 -> Loss: 0.40503269434\n",
      "Epoch: 35 -> Test Accuracy: 82.12\n",
      "[36, 60] loss: 0.307\n",
      "[36, 120] loss: 0.301\n",
      "[36, 180] loss: 0.326\n",
      "[36, 240] loss: 0.326\n",
      "[36, 300] loss: 0.324\n",
      "[36, 360] loss: 0.339\n",
      "Epoch: 36 -> Loss: 0.414452254772\n",
      "Epoch: 36 -> Test Accuracy: 81.57\n",
      "[37, 60] loss: 0.295\n",
      "[37, 120] loss: 0.309\n",
      "[37, 180] loss: 0.316\n",
      "[37, 240] loss: 0.336\n",
      "[37, 300] loss: 0.333\n",
      "[37, 360] loss: 0.324\n",
      "Epoch: 37 -> Loss: 0.398861318827\n",
      "Epoch: 37 -> Test Accuracy: 82.07\n",
      "[38, 60] loss: 0.308\n",
      "[38, 120] loss: 0.313\n",
      "[38, 180] loss: 0.318\n",
      "[38, 240] loss: 0.326\n",
      "[38, 300] loss: 0.318\n",
      "[38, 360] loss: 0.313\n",
      "Epoch: 38 -> Loss: 0.306469619274\n",
      "Epoch: 38 -> Test Accuracy: 81.98\n",
      "[39, 60] loss: 0.310\n",
      "[39, 120] loss: 0.323\n",
      "[39, 180] loss: 0.315\n",
      "[39, 240] loss: 0.310\n",
      "[39, 300] loss: 0.314\n",
      "[39, 360] loss: 0.330\n",
      "Epoch: 39 -> Loss: 0.514701128006\n",
      "Epoch: 39 -> Test Accuracy: 81.69\n",
      "[40, 60] loss: 0.308\n",
      "[40, 120] loss: 0.314\n",
      "[40, 180] loss: 0.310\n",
      "[40, 240] loss: 0.305\n",
      "[40, 300] loss: 0.327\n",
      "[40, 360] loss: 0.350\n",
      "Epoch: 40 -> Loss: 0.375910580158\n",
      "Epoch: 40 -> Test Accuracy: 81.84\n",
      "[41, 60] loss: 0.291\n",
      "[41, 120] loss: 0.288\n",
      "[41, 180] loss: 0.301\n",
      "[41, 240] loss: 0.283\n",
      "[41, 300] loss: 0.278\n",
      "[41, 360] loss: 0.277\n",
      "Epoch: 41 -> Loss: 0.205110386014\n",
      "Epoch: 41 -> Test Accuracy: 82.73\n",
      "[42, 60] loss: 0.271\n",
      "[42, 120] loss: 0.264\n",
      "[42, 180] loss: 0.266\n",
      "[42, 240] loss: 0.265\n",
      "[42, 300] loss: 0.261\n",
      "[42, 360] loss: 0.273\n",
      "Epoch: 42 -> Loss: 0.378046244383\n",
      "Epoch: 42 -> Test Accuracy: 82.92\n",
      "[43, 60] loss: 0.255\n",
      "[43, 120] loss: 0.256\n",
      "[43, 180] loss: 0.251\n",
      "[43, 240] loss: 0.260\n",
      "[43, 300] loss: 0.259\n",
      "[43, 360] loss: 0.261\n",
      "Epoch: 43 -> Loss: 0.351432323456\n",
      "Epoch: 43 -> Test Accuracy: 82.67\n",
      "[44, 60] loss: 0.254\n",
      "[44, 120] loss: 0.245\n",
      "[44, 180] loss: 0.257\n",
      "[44, 240] loss: 0.251\n",
      "[44, 300] loss: 0.258\n",
      "[44, 360] loss: 0.259\n",
      "Epoch: 44 -> Loss: 0.202488034964\n",
      "Epoch: 44 -> Test Accuracy: 82.68\n",
      "[45, 60] loss: 0.248\n",
      "[45, 120] loss: 0.242\n",
      "[45, 180] loss: 0.251\n",
      "[45, 240] loss: 0.256\n",
      "[45, 300] loss: 0.238\n",
      "[45, 360] loss: 0.241\n",
      "Epoch: 45 -> Loss: 0.133734300733\n",
      "Epoch: 45 -> Test Accuracy: 82.61\n",
      "[46, 60] loss: 0.257\n",
      "[46, 120] loss: 0.254\n",
      "[46, 180] loss: 0.228\n",
      "[46, 240] loss: 0.229\n",
      "[46, 300] loss: 0.239\n",
      "[46, 360] loss: 0.244\n",
      "Epoch: 46 -> Loss: 0.266154229641\n",
      "Epoch: 46 -> Test Accuracy: 82.86\n",
      "[47, 60] loss: 0.235\n",
      "[47, 120] loss: 0.227\n",
      "[47, 180] loss: 0.228\n",
      "[47, 240] loss: 0.234\n",
      "[47, 300] loss: 0.239\n",
      "[47, 360] loss: 0.227\n",
      "Epoch: 47 -> Loss: 0.288717061281\n",
      "Epoch: 47 -> Test Accuracy: 82.84\n",
      "[48, 60] loss: 0.234\n",
      "[48, 120] loss: 0.230\n",
      "[48, 180] loss: 0.236\n",
      "[48, 240] loss: 0.244\n",
      "[48, 300] loss: 0.243\n",
      "[48, 360] loss: 0.228\n",
      "Epoch: 48 -> Loss: 0.228378489614\n",
      "Epoch: 48 -> Test Accuracy: 82.87\n",
      "[49, 60] loss: 0.239\n",
      "[49, 120] loss: 0.218\n",
      "[49, 180] loss: 0.224\n",
      "[49, 240] loss: 0.235\n",
      "[49, 300] loss: 0.229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 360] loss: 0.238\n",
      "Epoch: 49 -> Loss: 0.280438363552\n",
      "Epoch: 49 -> Test Accuracy: 83.13\n",
      "[50, 60] loss: 0.236\n",
      "[50, 120] loss: 0.236\n",
      "[50, 180] loss: 0.224\n",
      "[50, 240] loss: 0.236\n",
      "[50, 300] loss: 0.226\n",
      "[50, 360] loss: 0.222\n",
      "Epoch: 50 -> Loss: 0.295331835747\n",
      "Epoch: 50 -> Test Accuracy: 82.97\n",
      "[51, 60] loss: 0.230\n",
      "[51, 120] loss: 0.217\n",
      "[51, 180] loss: 0.221\n",
      "[51, 240] loss: 0.225\n",
      "[51, 300] loss: 0.237\n",
      "[51, 360] loss: 0.233\n",
      "Epoch: 51 -> Loss: 0.190095052123\n",
      "Epoch: 51 -> Test Accuracy: 82.95\n",
      "[52, 60] loss: 0.210\n",
      "[52, 120] loss: 0.210\n",
      "[52, 180] loss: 0.233\n",
      "[52, 240] loss: 0.223\n",
      "[52, 300] loss: 0.222\n",
      "[52, 360] loss: 0.226\n",
      "Epoch: 52 -> Loss: 0.22531029582\n",
      "Epoch: 52 -> Test Accuracy: 82.92\n",
      "[53, 60] loss: 0.228\n",
      "[53, 120] loss: 0.233\n",
      "[53, 180] loss: 0.220\n",
      "[53, 240] loss: 0.212\n",
      "[53, 300] loss: 0.220\n",
      "[53, 360] loss: 0.217\n",
      "Epoch: 53 -> Loss: 0.2197689116\n",
      "Epoch: 53 -> Test Accuracy: 83.15\n",
      "[54, 60] loss: 0.227\n",
      "[54, 120] loss: 0.212\n",
      "[54, 180] loss: 0.236\n",
      "[54, 240] loss: 0.227\n",
      "[54, 300] loss: 0.221\n",
      "[54, 360] loss: 0.221\n",
      "Epoch: 54 -> Loss: 0.231262251735\n",
      "Epoch: 54 -> Test Accuracy: 83.1\n",
      "[55, 60] loss: 0.221\n",
      "[55, 120] loss: 0.223\n",
      "[55, 180] loss: 0.217\n",
      "[55, 240] loss: 0.216\n",
      "[55, 300] loss: 0.220\n",
      "[55, 360] loss: 0.219\n",
      "Epoch: 55 -> Loss: 0.224626064301\n",
      "Epoch: 55 -> Test Accuracy: 83.14\n",
      "[56, 60] loss: 0.221\n",
      "[56, 120] loss: 0.217\n",
      "[56, 180] loss: 0.210\n",
      "[56, 240] loss: 0.211\n",
      "[56, 300] loss: 0.219\n",
      "[56, 360] loss: 0.218\n",
      "Epoch: 56 -> Loss: 0.111415363848\n",
      "Epoch: 56 -> Test Accuracy: 83.07\n",
      "[57, 60] loss: 0.220\n",
      "[57, 120] loss: 0.224\n",
      "[57, 180] loss: 0.216\n",
      "[57, 240] loss: 0.215\n",
      "[57, 300] loss: 0.217\n",
      "[57, 360] loss: 0.224\n",
      "Epoch: 57 -> Loss: 0.217702150345\n",
      "Epoch: 57 -> Test Accuracy: 83.02\n",
      "[58, 60] loss: 0.218\n",
      "[58, 120] loss: 0.210\n",
      "[58, 180] loss: 0.227\n",
      "[58, 240] loss: 0.216\n",
      "[58, 300] loss: 0.225\n",
      "[58, 360] loss: 0.224\n",
      "Epoch: 58 -> Loss: 0.253460288048\n",
      "Epoch: 58 -> Test Accuracy: 83.2\n",
      "[59, 60] loss: 0.219\n",
      "[59, 120] loss: 0.211\n",
      "[59, 180] loss: 0.209\n",
      "[59, 240] loss: 0.223\n",
      "[59, 300] loss: 0.219\n",
      "[59, 360] loss: 0.223\n",
      "Epoch: 59 -> Loss: 0.210766643286\n",
      "Epoch: 59 -> Test Accuracy: 83.17\n",
      "[60, 60] loss: 0.209\n",
      "[60, 120] loss: 0.213\n",
      "[60, 180] loss: 0.219\n",
      "[60, 240] loss: 0.202\n",
      "[60, 300] loss: 0.224\n",
      "[60, 360] loss: 0.209\n",
      "Epoch: 60 -> Loss: 0.194272816181\n",
      "Epoch: 60 -> Test Accuracy: 83.21\n",
      "[61, 60] loss: 0.219\n",
      "[61, 120] loss: 0.212\n",
      "[61, 180] loss: 0.218\n",
      "[61, 240] loss: 0.200\n",
      "[61, 300] loss: 0.213\n",
      "[61, 360] loss: 0.224\n",
      "Epoch: 61 -> Loss: 0.30106779933\n",
      "Epoch: 61 -> Test Accuracy: 83.21\n",
      "[62, 60] loss: 0.212\n",
      "[62, 120] loss: 0.217\n",
      "[62, 180] loss: 0.205\n",
      "[62, 240] loss: 0.206\n",
      "[62, 300] loss: 0.212\n",
      "[62, 360] loss: 0.207\n",
      "Epoch: 62 -> Loss: 0.111170068383\n",
      "Epoch: 62 -> Test Accuracy: 83.15\n",
      "[63, 60] loss: 0.220\n",
      "[63, 120] loss: 0.211\n",
      "[63, 180] loss: 0.211\n",
      "[63, 240] loss: 0.213\n",
      "[63, 300] loss: 0.207\n",
      "[63, 360] loss: 0.201\n",
      "Epoch: 63 -> Loss: 0.294790834188\n",
      "Epoch: 63 -> Test Accuracy: 83.09\n",
      "[64, 60] loss: 0.209\n",
      "[64, 120] loss: 0.214\n",
      "[64, 180] loss: 0.202\n",
      "[64, 240] loss: 0.217\n",
      "[64, 300] loss: 0.209\n",
      "[64, 360] loss: 0.217\n",
      "Epoch: 64 -> Loss: 0.157702043653\n",
      "Epoch: 64 -> Test Accuracy: 83.2\n",
      "[65, 60] loss: 0.214\n",
      "[65, 120] loss: 0.207\n",
      "[65, 180] loss: 0.210\n",
      "[65, 240] loss: 0.217\n",
      "[65, 300] loss: 0.206\n",
      "[65, 360] loss: 0.201\n",
      "Epoch: 65 -> Loss: 0.322976469994\n",
      "Epoch: 65 -> Test Accuracy: 83.17\n",
      "[66, 60] loss: 0.202\n",
      "[66, 120] loss: 0.211\n",
      "[66, 180] loss: 0.212\n",
      "[66, 240] loss: 0.201\n",
      "[66, 300] loss: 0.204\n",
      "[66, 360] loss: 0.213\n",
      "Epoch: 66 -> Loss: 0.130479007959\n",
      "Epoch: 66 -> Test Accuracy: 83.22\n",
      "[67, 60] loss: 0.204\n",
      "[67, 120] loss: 0.202\n",
      "[67, 180] loss: 0.214\n",
      "[67, 240] loss: 0.212\n",
      "[67, 300] loss: 0.203\n",
      "[67, 360] loss: 0.212\n",
      "Epoch: 67 -> Loss: 0.281230032444\n",
      "Epoch: 67 -> Test Accuracy: 83.14\n",
      "[68, 60] loss: 0.204\n",
      "[68, 120] loss: 0.204\n",
      "[68, 180] loss: 0.203\n",
      "[68, 240] loss: 0.209\n",
      "[68, 300] loss: 0.205\n",
      "[68, 360] loss: 0.206\n",
      "Epoch: 68 -> Loss: 0.268533557653\n",
      "Epoch: 68 -> Test Accuracy: 83.06\n",
      "[69, 60] loss: 0.205\n",
      "[69, 120] loss: 0.208\n",
      "[69, 180] loss: 0.204\n",
      "[69, 240] loss: 0.203\n",
      "[69, 300] loss: 0.196\n",
      "[69, 360] loss: 0.199\n",
      "Epoch: 69 -> Loss: 0.158893913031\n",
      "Epoch: 69 -> Test Accuracy: 82.9\n",
      "[70, 60] loss: 0.199\n",
      "[70, 120] loss: 0.199\n",
      "[70, 180] loss: 0.207\n",
      "[70, 240] loss: 0.206\n",
      "[70, 300] loss: 0.199\n",
      "[70, 360] loss: 0.199\n",
      "Epoch: 70 -> Loss: 0.304592907429\n",
      "Epoch: 70 -> Test Accuracy: 83.08\n",
      "[71, 60] loss: 0.202\n",
      "[71, 120] loss: 0.214\n",
      "[71, 180] loss: 0.203\n",
      "[71, 240] loss: 0.199\n",
      "[71, 300] loss: 0.210\n",
      "[71, 360] loss: 0.191\n",
      "Epoch: 71 -> Loss: 0.239686638117\n",
      "Epoch: 71 -> Test Accuracy: 83.19\n",
      "[72, 60] loss: 0.187\n",
      "[72, 120] loss: 0.211\n",
      "[72, 180] loss: 0.206\n",
      "[72, 240] loss: 0.207\n",
      "[72, 300] loss: 0.202\n",
      "[72, 360] loss: 0.195\n",
      "Epoch: 72 -> Loss: 0.401748090982\n",
      "Epoch: 72 -> Test Accuracy: 83.08\n",
      "[73, 60] loss: 0.192\n",
      "[73, 120] loss: 0.204\n",
      "[73, 180] loss: 0.200\n",
      "[73, 240] loss: 0.195\n",
      "[73, 300] loss: 0.202\n",
      "[73, 360] loss: 0.211\n",
      "Epoch: 73 -> Loss: 0.285659313202\n",
      "Epoch: 73 -> Test Accuracy: 83.03\n",
      "[74, 60] loss: 0.202\n",
      "[74, 120] loss: 0.198\n",
      "[74, 180] loss: 0.209\n",
      "[74, 240] loss: 0.196\n",
      "[74, 300] loss: 0.205\n",
      "[74, 360] loss: 0.200\n",
      "Epoch: 74 -> Loss: 0.160533830523\n",
      "Epoch: 74 -> Test Accuracy: 82.99\n",
      "[75, 60] loss: 0.194\n",
      "[75, 120] loss: 0.204\n",
      "[75, 180] loss: 0.191\n",
      "[75, 240] loss: 0.211\n",
      "[75, 300] loss: 0.200\n",
      "[75, 360] loss: 0.205\n",
      "Epoch: 75 -> Loss: 0.115303948522\n",
      "Epoch: 75 -> Test Accuracy: 83.0\n",
      "[76, 60] loss: 0.198\n",
      "[76, 120] loss: 0.201\n",
      "[76, 180] loss: 0.201\n",
      "[76, 240] loss: 0.205\n",
      "[76, 300] loss: 0.195\n",
      "[76, 360] loss: 0.185\n",
      "Epoch: 76 -> Loss: 0.238714650273\n",
      "Epoch: 76 -> Test Accuracy: 82.96\n",
      "[77, 60] loss: 0.185\n",
      "[77, 120] loss: 0.202\n",
      "[77, 180] loss: 0.210\n",
      "[77, 240] loss: 0.202\n",
      "[77, 300] loss: 0.206\n",
      "[77, 360] loss: 0.192\n",
      "Epoch: 77 -> Loss: 0.0947173461318\n",
      "Epoch: 77 -> Test Accuracy: 83.16\n",
      "[78, 60] loss: 0.198\n",
      "[78, 120] loss: 0.198\n",
      "[78, 180] loss: 0.196\n",
      "[78, 240] loss: 0.197\n",
      "[78, 300] loss: 0.194\n",
      "[78, 360] loss: 0.201\n",
      "Epoch: 78 -> Loss: 0.226702690125\n",
      "Epoch: 78 -> Test Accuracy: 82.99\n",
      "[79, 60] loss: 0.194\n",
      "[79, 120] loss: 0.194\n",
      "[79, 180] loss: 0.200\n",
      "[79, 240] loss: 0.196\n",
      "[79, 300] loss: 0.193\n",
      "[79, 360] loss: 0.195\n",
      "Epoch: 79 -> Loss: 0.143659695983\n",
      "Epoch: 79 -> Test Accuracy: 83.08\n",
      "[80, 60] loss: 0.201\n",
      "[80, 120] loss: 0.185\n",
      "[80, 180] loss: 0.199\n",
      "[80, 240] loss: 0.197\n",
      "[80, 300] loss: 0.200\n",
      "[80, 360] loss: 0.192\n",
      "Epoch: 80 -> Loss: 0.289796113968\n",
      "Epoch: 80 -> Test Accuracy: 83.14\n",
      "[81, 60] loss: 0.198\n",
      "[81, 120] loss: 0.197\n",
      "[81, 180] loss: 0.195\n",
      "[81, 240] loss: 0.199\n",
      "[81, 300] loss: 0.197\n",
      "[81, 360] loss: 0.186\n",
      "Epoch: 81 -> Loss: 0.199414044619\n",
      "Epoch: 81 -> Test Accuracy: 83.21\n",
      "[82, 60] loss: 0.203\n",
      "[82, 120] loss: 0.192\n",
      "[82, 180] loss: 0.194\n",
      "[82, 240] loss: 0.182\n",
      "[82, 300] loss: 0.203\n",
      "[82, 360] loss: 0.185\n",
      "Epoch: 82 -> Loss: 0.203896477818\n",
      "Epoch: 82 -> Test Accuracy: 83.26\n",
      "[83, 60] loss: 0.195\n",
      "[83, 120] loss: 0.189\n",
      "[83, 180] loss: 0.196\n",
      "[83, 240] loss: 0.206\n",
      "[83, 300] loss: 0.193\n",
      "[83, 360] loss: 0.191\n",
      "Epoch: 83 -> Loss: 0.31572291255\n",
      "Epoch: 83 -> Test Accuracy: 83.15\n",
      "[84, 60] loss: 0.189\n",
      "[84, 120] loss: 0.200\n",
      "[84, 180] loss: 0.189\n",
      "[84, 240] loss: 0.196\n",
      "[84, 300] loss: 0.193\n",
      "[84, 360] loss: 0.177\n",
      "Epoch: 84 -> Loss: 0.177299886942\n",
      "Epoch: 84 -> Test Accuracy: 83.06\n",
      "[85, 60] loss: 0.199\n",
      "[85, 120] loss: 0.196\n",
      "[85, 180] loss: 0.191\n",
      "[85, 240] loss: 0.195\n",
      "[85, 300] loss: 0.199\n",
      "[85, 360] loss: 0.188\n",
      "Epoch: 85 -> Loss: 0.287552535534\n",
      "Epoch: 85 -> Test Accuracy: 83.16\n",
      "[86, 60] loss: 0.185\n",
      "[86, 120] loss: 0.190\n",
      "[86, 180] loss: 0.198\n",
      "[86, 240] loss: 0.194\n",
      "[86, 300] loss: 0.192\n",
      "[86, 360] loss: 0.200\n",
      "Epoch: 86 -> Loss: 0.262778043747\n",
      "Epoch: 86 -> Test Accuracy: 83.07\n",
      "[87, 60] loss: 0.182\n",
      "[87, 120] loss: 0.197\n",
      "[87, 180] loss: 0.183\n",
      "[87, 240] loss: 0.184\n",
      "[87, 300] loss: 0.189\n",
      "[87, 360] loss: 0.202\n",
      "Epoch: 87 -> Loss: 0.181507870555\n",
      "Epoch: 87 -> Test Accuracy: 83.08\n",
      "[88, 60] loss: 0.187\n",
      "[88, 120] loss: 0.189\n",
      "[88, 180] loss: 0.175\n",
      "[88, 240] loss: 0.193\n",
      "[88, 300] loss: 0.187\n",
      "[88, 360] loss: 0.194\n",
      "Epoch: 88 -> Loss: 0.0544217452407\n",
      "Epoch: 88 -> Test Accuracy: 83.06\n",
      "[89, 60] loss: 0.185\n",
      "[89, 120] loss: 0.195\n",
      "[89, 180] loss: 0.186\n",
      "[89, 240] loss: 0.192\n",
      "[89, 300] loss: 0.185\n",
      "[89, 360] loss: 0.189\n",
      "Epoch: 89 -> Loss: 0.274021923542\n",
      "Epoch: 89 -> Test Accuracy: 82.9\n",
      "[90, 60] loss: 0.182\n",
      "[90, 120] loss: 0.176\n",
      "[90, 180] loss: 0.178\n",
      "[90, 240] loss: 0.186\n",
      "[90, 300] loss: 0.188\n",
      "[90, 360] loss: 0.190\n",
      "Epoch: 90 -> Loss: 0.199755996466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 -> Test Accuracy: 83.15\n",
      "[91, 60] loss: 0.192\n",
      "[91, 120] loss: 0.191\n",
      "[91, 180] loss: 0.181\n",
      "[91, 240] loss: 0.186\n",
      "[91, 300] loss: 0.173\n",
      "[91, 360] loss: 0.184\n",
      "Epoch: 91 -> Loss: 0.323404729366\n",
      "Epoch: 91 -> Test Accuracy: 83.01\n",
      "[92, 60] loss: 0.186\n",
      "[92, 120] loss: 0.192\n",
      "[92, 180] loss: 0.188\n",
      "[92, 240] loss: 0.189\n",
      "[92, 300] loss: 0.182\n",
      "[92, 360] loss: 0.180\n",
      "Epoch: 92 -> Loss: 0.202837914228\n",
      "Epoch: 92 -> Test Accuracy: 82.99\n",
      "[93, 60] loss: 0.181\n",
      "[93, 120] loss: 0.190\n",
      "[93, 180] loss: 0.191\n",
      "[93, 240] loss: 0.175\n",
      "[93, 300] loss: 0.177\n",
      "[93, 360] loss: 0.188\n",
      "Epoch: 93 -> Loss: 0.27390986681\n",
      "Epoch: 93 -> Test Accuracy: 82.92\n",
      "[94, 60] loss: 0.180\n",
      "[94, 120] loss: 0.190\n",
      "[94, 180] loss: 0.169\n",
      "[94, 240] loss: 0.191\n",
      "[94, 300] loss: 0.201\n",
      "[94, 360] loss: 0.171\n",
      "Epoch: 94 -> Loss: 0.152767449617\n",
      "Epoch: 94 -> Test Accuracy: 82.99\n",
      "[95, 60] loss: 0.181\n",
      "[95, 120] loss: 0.188\n",
      "[95, 180] loss: 0.187\n",
      "[95, 240] loss: 0.178\n",
      "[95, 300] loss: 0.178\n",
      "[95, 360] loss: 0.184\n",
      "Epoch: 95 -> Loss: 0.212411731482\n",
      "Epoch: 95 -> Test Accuracy: 83.01\n",
      "[96, 60] loss: 0.180\n",
      "[96, 120] loss: 0.187\n",
      "[96, 180] loss: 0.175\n",
      "[96, 240] loss: 0.180\n",
      "[96, 300] loss: 0.194\n",
      "[96, 360] loss: 0.184\n",
      "Epoch: 96 -> Loss: 0.121260680258\n",
      "Epoch: 96 -> Test Accuracy: 82.97\n",
      "[97, 60] loss: 0.188\n",
      "[97, 120] loss: 0.182\n",
      "[97, 180] loss: 0.183\n",
      "[97, 240] loss: 0.184\n",
      "[97, 300] loss: 0.190\n",
      "[97, 360] loss: 0.175\n",
      "Epoch: 97 -> Loss: 0.298063516617\n",
      "Epoch: 97 -> Test Accuracy: 83.04\n",
      "[98, 60] loss: 0.175\n",
      "[98, 120] loss: 0.179\n",
      "[98, 180] loss: 0.173\n",
      "[98, 240] loss: 0.184\n",
      "[98, 300] loss: 0.188\n",
      "[98, 360] loss: 0.184\n",
      "Epoch: 98 -> Loss: 0.163528889418\n",
      "Epoch: 98 -> Test Accuracy: 82.99\n",
      "[99, 60] loss: 0.177\n",
      "[99, 120] loss: 0.178\n",
      "[99, 180] loss: 0.184\n",
      "[99, 240] loss: 0.185\n",
      "[99, 300] loss: 0.176\n",
      "[99, 360] loss: 0.177\n",
      "Epoch: 99 -> Loss: 0.191878944635\n",
      "Epoch: 99 -> Test Accuracy: 83.1\n",
      "[100, 60] loss: 0.175\n",
      "[100, 120] loss: 0.177\n",
      "[100, 180] loss: 0.165\n",
      "[100, 240] loss: 0.182\n",
      "[100, 300] loss: 0.178\n",
      "[100, 360] loss: 0.192\n",
      "Epoch: 100 -> Loss: 0.153581276536\n",
      "Epoch: 100 -> Test Accuracy: 82.99\n",
      "Finished Training\n",
      "[1, 60] loss: 2.285\n",
      "[1, 120] loss: 1.493\n",
      "[1, 180] loss: 1.381\n",
      "[1, 240] loss: 1.309\n",
      "[1, 300] loss: 1.279\n",
      "[1, 360] loss: 1.245\n",
      "Epoch: 1 -> Loss: 1.03467130661\n",
      "Epoch: 1 -> Test Accuracy: 51.94\n",
      "[2, 60] loss: 1.194\n",
      "[2, 120] loss: 1.175\n",
      "[2, 180] loss: 1.185\n",
      "[2, 240] loss: 1.164\n",
      "[2, 300] loss: 1.164\n",
      "[2, 360] loss: 1.130\n",
      "Epoch: 2 -> Loss: 1.09169697762\n",
      "Epoch: 2 -> Test Accuracy: 54.89\n",
      "[3, 60] loss: 1.114\n",
      "[3, 120] loss: 1.104\n",
      "[3, 180] loss: 1.120\n",
      "[3, 240] loss: 1.113\n",
      "[3, 300] loss: 1.105\n",
      "[3, 360] loss: 1.100\n",
      "Epoch: 3 -> Loss: 1.09216761589\n",
      "Epoch: 3 -> Test Accuracy: 56.72\n",
      "[4, 60] loss: 1.070\n",
      "[4, 120] loss: 1.076\n",
      "[4, 180] loss: 1.114\n",
      "[4, 240] loss: 1.078\n",
      "[4, 300] loss: 1.069\n",
      "[4, 360] loss: 1.053\n",
      "Epoch: 4 -> Loss: 1.2539242506\n",
      "Epoch: 4 -> Test Accuracy: 56.08\n",
      "[5, 60] loss: 1.058\n",
      "[5, 120] loss: 1.052\n",
      "[5, 180] loss: 1.070\n",
      "[5, 240] loss: 1.065\n",
      "[5, 300] loss: 1.034\n",
      "[5, 360] loss: 1.075\n",
      "Epoch: 5 -> Loss: 1.06169307232\n",
      "Epoch: 5 -> Test Accuracy: 58.07\n",
      "[6, 60] loss: 1.040\n",
      "[6, 120] loss: 1.027\n",
      "[6, 180] loss: 1.055\n",
      "[6, 240] loss: 1.063\n",
      "[6, 300] loss: 1.035\n",
      "[6, 360] loss: 1.050\n",
      "Epoch: 6 -> Loss: 1.0646905899\n",
      "Epoch: 6 -> Test Accuracy: 57.66\n",
      "[7, 60] loss: 1.031\n",
      "[7, 120] loss: 1.038\n",
      "[7, 180] loss: 1.045\n",
      "[7, 240] loss: 1.053\n",
      "[7, 300] loss: 1.052\n",
      "[7, 360] loss: 1.029\n",
      "Epoch: 7 -> Loss: 1.07096171379\n",
      "Epoch: 7 -> Test Accuracy: 58.07\n",
      "[8, 60] loss: 1.032\n",
      "[8, 120] loss: 1.059\n",
      "[8, 180] loss: 1.029\n",
      "[8, 240] loss: 1.043\n",
      "[8, 300] loss: 1.009\n",
      "[8, 360] loss: 1.036\n",
      "Epoch: 8 -> Loss: 1.18624556065\n",
      "Epoch: 8 -> Test Accuracy: 56.83\n",
      "[9, 60] loss: 0.993\n",
      "[9, 120] loss: 1.040\n",
      "[9, 180] loss: 1.041\n",
      "[9, 240] loss: 1.044\n",
      "[9, 300] loss: 1.033\n",
      "[9, 360] loss: 1.026\n",
      "Epoch: 9 -> Loss: 1.08717298508\n",
      "Epoch: 9 -> Test Accuracy: 58.84\n",
      "[10, 60] loss: 1.032\n",
      "[10, 120] loss: 1.029\n",
      "[10, 180] loss: 1.024\n",
      "[10, 240] loss: 1.011\n",
      "[10, 300] loss: 1.037\n",
      "[10, 360] loss: 1.017\n",
      "Epoch: 10 -> Loss: 1.05307245255\n",
      "Epoch: 10 -> Test Accuracy: 58.94\n",
      "[11, 60] loss: 1.024\n",
      "[11, 120] loss: 1.014\n",
      "[11, 180] loss: 1.029\n",
      "[11, 240] loss: 1.014\n",
      "[11, 300] loss: 1.026\n",
      "[11, 360] loss: 1.016\n",
      "Epoch: 11 -> Loss: 1.01210284233\n",
      "Epoch: 11 -> Test Accuracy: 58.55\n",
      "[12, 60] loss: 1.015\n",
      "[12, 120] loss: 1.014\n",
      "[12, 180] loss: 1.024\n",
      "[12, 240] loss: 1.020\n",
      "[12, 300] loss: 0.999\n",
      "[12, 360] loss: 1.032\n",
      "Epoch: 12 -> Loss: 1.07989180088\n",
      "Epoch: 12 -> Test Accuracy: 59.1\n",
      "[13, 60] loss: 0.999\n",
      "[13, 120] loss: 1.000\n",
      "[13, 180] loss: 1.010\n",
      "[13, 240] loss: 1.048\n",
      "[13, 300] loss: 1.004\n",
      "[13, 360] loss: 1.027\n",
      "Epoch: 13 -> Loss: 1.00448417664\n",
      "Epoch: 13 -> Test Accuracy: 59.23\n",
      "[14, 60] loss: 1.021\n",
      "[14, 120] loss: 1.011\n",
      "[14, 180] loss: 1.001\n",
      "[14, 240] loss: 0.998\n",
      "[14, 300] loss: 1.025\n",
      "[14, 360] loss: 1.027\n",
      "Epoch: 14 -> Loss: 1.12899231911\n",
      "Epoch: 14 -> Test Accuracy: 58.28\n",
      "[15, 60] loss: 1.011\n",
      "[15, 120] loss: 0.997\n",
      "[15, 180] loss: 0.992\n",
      "[15, 240] loss: 1.021\n",
      "[15, 300] loss: 1.008\n",
      "[15, 360] loss: 1.012\n",
      "Epoch: 15 -> Loss: 1.12742888927\n",
      "Epoch: 15 -> Test Accuracy: 58.9\n",
      "[16, 60] loss: 1.010\n",
      "[16, 120] loss: 0.991\n",
      "[16, 180] loss: 1.007\n",
      "[16, 240] loss: 0.996\n",
      "[16, 300] loss: 1.032\n",
      "[16, 360] loss: 1.010\n",
      "Epoch: 16 -> Loss: 0.941190123558\n",
      "Epoch: 16 -> Test Accuracy: 58.86\n",
      "[17, 60] loss: 1.018\n",
      "[17, 120] loss: 0.981\n",
      "[17, 180] loss: 1.004\n",
      "[17, 240] loss: 0.990\n",
      "[17, 300] loss: 1.003\n",
      "[17, 360] loss: 1.032\n",
      "Epoch: 17 -> Loss: 1.02840256691\n",
      "Epoch: 17 -> Test Accuracy: 58.95\n",
      "[18, 60] loss: 0.999\n",
      "[18, 120] loss: 0.987\n",
      "[18, 180] loss: 1.010\n",
      "[18, 240] loss: 1.000\n",
      "[18, 300] loss: 1.004\n",
      "[18, 360] loss: 1.032\n",
      "Epoch: 18 -> Loss: 1.02951383591\n",
      "Epoch: 18 -> Test Accuracy: 59.2\n",
      "[19, 60] loss: 0.989\n",
      "[19, 120] loss: 1.008\n",
      "[19, 180] loss: 1.028\n",
      "[19, 240] loss: 0.995\n",
      "[19, 300] loss: 1.012\n",
      "[19, 360] loss: 1.005\n",
      "Epoch: 19 -> Loss: 1.02539134026\n",
      "Epoch: 19 -> Test Accuracy: 58.87\n",
      "[20, 60] loss: 1.003\n",
      "[20, 120] loss: 0.988\n",
      "[20, 180] loss: 1.011\n",
      "[20, 240] loss: 1.002\n",
      "[20, 300] loss: 1.031\n",
      "[20, 360] loss: 0.998\n",
      "Epoch: 20 -> Loss: 0.866331756115\n",
      "Epoch: 20 -> Test Accuracy: 59.45\n",
      "[21, 60] loss: 0.955\n",
      "[21, 120] loss: 0.937\n",
      "[21, 180] loss: 0.916\n",
      "[21, 240] loss: 0.890\n",
      "[21, 300] loss: 0.915\n",
      "[21, 360] loss: 0.896\n",
      "Epoch: 21 -> Loss: 0.907217621803\n",
      "Epoch: 21 -> Test Accuracy: 62.97\n",
      "[22, 60] loss: 0.887\n",
      "[22, 120] loss: 0.870\n",
      "[22, 180] loss: 0.908\n",
      "[22, 240] loss: 0.894\n",
      "[22, 300] loss: 0.893\n",
      "[22, 360] loss: 0.905\n",
      "Epoch: 22 -> Loss: 0.840113937855\n",
      "Epoch: 22 -> Test Accuracy: 62.94\n",
      "[23, 60] loss: 0.864\n",
      "[23, 120] loss: 0.871\n",
      "[23, 180] loss: 0.879\n",
      "[23, 240] loss: 0.852\n",
      "[23, 300] loss: 0.907\n",
      "[23, 360] loss: 0.857\n",
      "Epoch: 23 -> Loss: 0.863354563713\n",
      "Epoch: 23 -> Test Accuracy: 63.52\n",
      "[24, 60] loss: 0.868\n",
      "[24, 120] loss: 0.855\n",
      "[24, 180] loss: 0.870\n",
      "[24, 240] loss: 0.882\n",
      "[24, 300] loss: 0.869\n",
      "[24, 360] loss: 0.876\n",
      "Epoch: 24 -> Loss: 0.791432499886\n",
      "Epoch: 24 -> Test Accuracy: 62.75\n",
      "[25, 60] loss: 0.862\n",
      "[25, 120] loss: 0.857\n",
      "[25, 180] loss: 0.859\n",
      "[25, 240] loss: 0.861\n",
      "[25, 300] loss: 0.854\n",
      "[25, 360] loss: 0.875\n",
      "Epoch: 25 -> Loss: 0.827188372612\n",
      "Epoch: 25 -> Test Accuracy: 63.92\n",
      "[26, 60] loss: 0.858\n",
      "[26, 120] loss: 0.844\n",
      "[26, 180] loss: 0.857\n",
      "[26, 240] loss: 0.871\n",
      "[26, 300] loss: 0.869\n",
      "[26, 360] loss: 0.848\n",
      "Epoch: 26 -> Loss: 0.903440117836\n",
      "Epoch: 26 -> Test Accuracy: 63.93\n",
      "[27, 60] loss: 0.860\n",
      "[27, 120] loss: 0.866\n",
      "[27, 180] loss: 0.849\n",
      "[27, 240] loss: 0.878\n",
      "[27, 300] loss: 0.866\n",
      "[27, 360] loss: 0.858\n",
      "Epoch: 27 -> Loss: 0.840372264385\n",
      "Epoch: 27 -> Test Accuracy: 63.9\n",
      "[28, 60] loss: 0.859\n",
      "[28, 120] loss: 0.847\n",
      "[28, 180] loss: 0.864\n",
      "[28, 240] loss: 0.846\n",
      "[28, 300] loss: 0.854\n",
      "[28, 360] loss: 0.863\n",
      "Epoch: 28 -> Loss: 0.76533228159\n",
      "Epoch: 28 -> Test Accuracy: 62.76\n",
      "[29, 60] loss: 0.851\n",
      "[29, 120] loss: 0.845\n",
      "[29, 180] loss: 0.864\n",
      "[29, 240] loss: 0.853\n",
      "[29, 300] loss: 0.862\n",
      "[29, 360] loss: 0.864\n",
      "Epoch: 29 -> Loss: 0.776900529861\n",
      "Epoch: 29 -> Test Accuracy: 64.07\n",
      "[30, 60] loss: 0.856\n",
      "[30, 120] loss: 0.857\n",
      "[30, 180] loss: 0.865\n",
      "[30, 240] loss: 0.844\n",
      "[30, 300] loss: 0.851\n",
      "[30, 360] loss: 0.857\n",
      "Epoch: 30 -> Loss: 0.94649040699\n",
      "Epoch: 30 -> Test Accuracy: 63.56\n",
      "[31, 60] loss: 0.852\n",
      "[31, 120] loss: 0.851\n",
      "[31, 180] loss: 0.863\n",
      "[31, 240] loss: 0.863\n",
      "[31, 300] loss: 0.861\n",
      "[31, 360] loss: 0.869\n",
      "Epoch: 31 -> Loss: 0.808486461639\n",
      "Epoch: 31 -> Test Accuracy: 63.81\n",
      "[32, 60] loss: 0.851\n",
      "[32, 120] loss: 0.849\n",
      "[32, 180] loss: 0.866\n",
      "[32, 240] loss: 0.858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 300] loss: 0.848\n",
      "[32, 360] loss: 0.835\n",
      "Epoch: 32 -> Loss: 0.958526968956\n",
      "Epoch: 32 -> Test Accuracy: 63.73\n",
      "[33, 60] loss: 0.845\n",
      "[33, 120] loss: 0.841\n",
      "[33, 180] loss: 0.874\n",
      "[33, 240] loss: 0.852\n",
      "[33, 300] loss: 0.845\n",
      "[33, 360] loss: 0.862\n",
      "Epoch: 33 -> Loss: 0.694599032402\n",
      "Epoch: 33 -> Test Accuracy: 63.8\n",
      "[34, 60] loss: 0.846\n",
      "[34, 120] loss: 0.849\n",
      "[34, 180] loss: 0.844\n",
      "[34, 240] loss: 0.842\n",
      "[34, 300] loss: 0.844\n",
      "[34, 360] loss: 0.887\n",
      "Epoch: 34 -> Loss: 0.925305724144\n",
      "Epoch: 34 -> Test Accuracy: 63.26\n",
      "[35, 60] loss: 0.840\n",
      "[35, 120] loss: 0.858\n",
      "[35, 180] loss: 0.843\n",
      "[35, 240] loss: 0.859\n",
      "[35, 300] loss: 0.835\n",
      "[35, 360] loss: 0.845\n",
      "Epoch: 35 -> Loss: 0.723078131676\n",
      "Epoch: 35 -> Test Accuracy: 63.31\n",
      "[36, 60] loss: 0.863\n",
      "[36, 120] loss: 0.856\n",
      "[36, 180] loss: 0.846\n",
      "[36, 240] loss: 0.848\n",
      "[36, 300] loss: 0.846\n",
      "[36, 360] loss: 0.860\n",
      "Epoch: 36 -> Loss: 0.755991637707\n",
      "Epoch: 36 -> Test Accuracy: 63.3\n",
      "[37, 60] loss: 0.828\n",
      "[37, 120] loss: 0.862\n",
      "[37, 180] loss: 0.835\n",
      "[37, 240] loss: 0.860\n",
      "[37, 300] loss: 0.866\n",
      "[37, 360] loss: 0.859\n",
      "Epoch: 37 -> Loss: 0.832694888115\n",
      "Epoch: 37 -> Test Accuracy: 63.8\n",
      "[38, 60] loss: 0.823\n",
      "[38, 120] loss: 0.837\n",
      "[38, 180] loss: 0.868\n",
      "[38, 240] loss: 0.835\n",
      "[38, 300] loss: 0.853\n",
      "[38, 360] loss: 0.864\n",
      "Epoch: 38 -> Loss: 0.826617121696\n",
      "Epoch: 38 -> Test Accuracy: 63.58\n",
      "[39, 60] loss: 0.862\n",
      "[39, 120] loss: 0.824\n",
      "[39, 180] loss: 0.845\n",
      "[39, 240] loss: 0.876\n",
      "[39, 300] loss: 0.842\n",
      "[39, 360] loss: 0.839\n",
      "Epoch: 39 -> Loss: 0.80114620924\n",
      "Epoch: 39 -> Test Accuracy: 63.69\n",
      "[40, 60] loss: 0.842\n",
      "[40, 120] loss: 0.851\n",
      "[40, 180] loss: 0.842\n",
      "[40, 240] loss: 0.855\n",
      "[40, 300] loss: 0.839\n",
      "[40, 360] loss: 0.854\n",
      "Epoch: 40 -> Loss: 0.960075080395\n",
      "Epoch: 40 -> Test Accuracy: 63.73\n",
      "[41, 60] loss: 0.805\n",
      "[41, 120] loss: 0.800\n",
      "[41, 180] loss: 0.785\n",
      "[41, 240] loss: 0.806\n",
      "[41, 300] loss: 0.799\n",
      "[41, 360] loss: 0.778\n",
      "Epoch: 41 -> Loss: 0.756761431694\n",
      "Epoch: 41 -> Test Accuracy: 65.34\n",
      "[42, 60] loss: 0.776\n",
      "[42, 120] loss: 0.774\n",
      "[42, 180] loss: 0.769\n",
      "[42, 240] loss: 0.765\n",
      "[42, 300] loss: 0.787\n",
      "[42, 360] loss: 0.797\n",
      "Epoch: 42 -> Loss: 0.75731241703\n",
      "Epoch: 42 -> Test Accuracy: 65.75\n",
      "[43, 60] loss: 0.777\n",
      "[43, 120] loss: 0.761\n",
      "[43, 180] loss: 0.763\n",
      "[43, 240] loss: 0.754\n",
      "[43, 300] loss: 0.770\n",
      "[43, 360] loss: 0.773\n",
      "Epoch: 43 -> Loss: 0.784428954124\n",
      "Epoch: 43 -> Test Accuracy: 65.3\n",
      "[44, 60] loss: 0.773\n",
      "[44, 120] loss: 0.750\n",
      "[44, 180] loss: 0.775\n",
      "[44, 240] loss: 0.763\n",
      "[44, 300] loss: 0.759\n",
      "[44, 360] loss: 0.764\n",
      "Epoch: 44 -> Loss: 0.806028962135\n",
      "Epoch: 44 -> Test Accuracy: 66.15\n",
      "[45, 60] loss: 0.753\n",
      "[45, 120] loss: 0.768\n",
      "[45, 180] loss: 0.767\n",
      "[45, 240] loss: 0.770\n",
      "[45, 300] loss: 0.755\n",
      "[45, 360] loss: 0.760\n",
      "Epoch: 45 -> Loss: 0.968176186085\n",
      "Epoch: 45 -> Test Accuracy: 65.78\n",
      "[46, 60] loss: 0.763\n",
      "[46, 120] loss: 0.755\n",
      "[46, 180] loss: 0.749\n",
      "[46, 240] loss: 0.748\n",
      "[46, 300] loss: 0.742\n",
      "[46, 360] loss: 0.749\n",
      "Epoch: 46 -> Loss: 0.791005730629\n",
      "Epoch: 46 -> Test Accuracy: 66.1\n",
      "[47, 60] loss: 0.756\n",
      "[47, 120] loss: 0.785\n",
      "[47, 180] loss: 0.750\n",
      "[47, 240] loss: 0.743\n",
      "[47, 300] loss: 0.743\n",
      "[47, 360] loss: 0.706\n",
      "Epoch: 47 -> Loss: 0.682918906212\n",
      "Epoch: 47 -> Test Accuracy: 66.49\n",
      "[48, 60] loss: 0.725\n",
      "[48, 120] loss: 0.761\n",
      "[48, 180] loss: 0.736\n",
      "[48, 240] loss: 0.743\n",
      "[48, 300] loss: 0.749\n",
      "[48, 360] loss: 0.730\n",
      "Epoch: 48 -> Loss: 0.761852145195\n",
      "Epoch: 48 -> Test Accuracy: 66.57\n",
      "[49, 60] loss: 0.731\n",
      "[49, 120] loss: 0.747\n",
      "[49, 180] loss: 0.748\n",
      "[49, 240] loss: 0.734\n",
      "[49, 300] loss: 0.760\n",
      "[49, 360] loss: 0.740\n",
      "Epoch: 49 -> Loss: 0.955061137676\n",
      "Epoch: 49 -> Test Accuracy: 66.54\n",
      "[50, 60] loss: 0.735\n",
      "[50, 120] loss: 0.760\n",
      "[50, 180] loss: 0.706\n",
      "[50, 240] loss: 0.728\n",
      "[50, 300] loss: 0.743\n",
      "[50, 360] loss: 0.740\n",
      "Epoch: 50 -> Loss: 1.01907086372\n",
      "Epoch: 50 -> Test Accuracy: 66.67\n",
      "[51, 60] loss: 0.727\n",
      "[51, 120] loss: 0.759\n",
      "[51, 180] loss: 0.728\n",
      "[51, 240] loss: 0.752\n",
      "[51, 300] loss: 0.742\n",
      "[51, 360] loss: 0.736\n",
      "Epoch: 51 -> Loss: 0.693717896938\n",
      "Epoch: 51 -> Test Accuracy: 66.43\n",
      "[52, 60] loss: 0.715\n",
      "[52, 120] loss: 0.731\n",
      "[52, 180] loss: 0.742\n",
      "[52, 240] loss: 0.730\n",
      "[52, 300] loss: 0.727\n",
      "[52, 360] loss: 0.742\n",
      "Epoch: 52 -> Loss: 0.841146349907\n",
      "Epoch: 52 -> Test Accuracy: 66.58\n",
      "[53, 60] loss: 0.729\n",
      "[53, 120] loss: 0.726\n",
      "[53, 180] loss: 0.734\n",
      "[53, 240] loss: 0.740\n",
      "[53, 300] loss: 0.739\n",
      "[53, 360] loss: 0.746\n",
      "Epoch: 53 -> Loss: 0.724834144115\n",
      "Epoch: 53 -> Test Accuracy: 66.56\n",
      "[54, 60] loss: 0.710\n",
      "[54, 120] loss: 0.746\n",
      "[54, 180] loss: 0.735\n",
      "[54, 240] loss: 0.739\n",
      "[54, 300] loss: 0.740\n",
      "[54, 360] loss: 0.746\n",
      "Epoch: 54 -> Loss: 0.902658104897\n",
      "Epoch: 54 -> Test Accuracy: 66.69\n",
      "[55, 60] loss: 0.728\n",
      "[55, 120] loss: 0.715\n",
      "[55, 180] loss: 0.730\n",
      "[55, 240] loss: 0.742\n",
      "[55, 300] loss: 0.738\n",
      "[55, 360] loss: 0.713\n",
      "Epoch: 55 -> Loss: 0.764953196049\n",
      "Epoch: 55 -> Test Accuracy: 66.63\n",
      "[56, 60] loss: 0.734\n",
      "[56, 120] loss: 0.716\n",
      "[56, 180] loss: 0.732\n",
      "[56, 240] loss: 0.732\n",
      "[56, 300] loss: 0.727\n",
      "[56, 360] loss: 0.717\n",
      "Epoch: 56 -> Loss: 0.813167273998\n",
      "Epoch: 56 -> Test Accuracy: 66.5\n",
      "[57, 60] loss: 0.724\n",
      "[57, 120] loss: 0.724\n",
      "[57, 180] loss: 0.744\n",
      "[57, 240] loss: 0.729\n",
      "[57, 300] loss: 0.721\n",
      "[57, 360] loss: 0.728\n",
      "Epoch: 57 -> Loss: 0.768337845802\n",
      "Epoch: 57 -> Test Accuracy: 66.6\n",
      "[58, 60] loss: 0.742\n",
      "[58, 120] loss: 0.727\n",
      "[58, 180] loss: 0.737\n",
      "[58, 240] loss: 0.737\n",
      "[58, 300] loss: 0.707\n",
      "[58, 360] loss: 0.736\n",
      "Epoch: 58 -> Loss: 0.894430816174\n",
      "Epoch: 58 -> Test Accuracy: 66.97\n",
      "[59, 60] loss: 0.719\n",
      "[59, 120] loss: 0.751\n",
      "[59, 180] loss: 0.736\n",
      "[59, 240] loss: 0.736\n",
      "[59, 300] loss: 0.737\n",
      "[59, 360] loss: 0.709\n",
      "Epoch: 59 -> Loss: 0.702912449837\n",
      "Epoch: 59 -> Test Accuracy: 66.79\n",
      "[60, 60] loss: 0.730\n",
      "[60, 120] loss: 0.729\n",
      "[60, 180] loss: 0.723\n",
      "[60, 240] loss: 0.727\n",
      "[60, 300] loss: 0.716\n",
      "[60, 360] loss: 0.736\n",
      "Epoch: 60 -> Loss: 0.589941263199\n",
      "Epoch: 60 -> Test Accuracy: 66.51\n",
      "[61, 60] loss: 0.735\n",
      "[61, 120] loss: 0.715\n",
      "[61, 180] loss: 0.721\n",
      "[61, 240] loss: 0.748\n",
      "[61, 300] loss: 0.721\n",
      "[61, 360] loss: 0.714\n",
      "Epoch: 61 -> Loss: 0.711781144142\n",
      "Epoch: 61 -> Test Accuracy: 66.73\n",
      "[62, 60] loss: 0.724\n",
      "[62, 120] loss: 0.718\n",
      "[62, 180] loss: 0.707\n",
      "[62, 240] loss: 0.730\n",
      "[62, 300] loss: 0.725\n",
      "[62, 360] loss: 0.722\n",
      "Epoch: 62 -> Loss: 0.932108998299\n",
      "Epoch: 62 -> Test Accuracy: 66.64\n",
      "[63, 60] loss: 0.718\n",
      "[63, 120] loss: 0.724\n",
      "[63, 180] loss: 0.743\n",
      "[63, 240] loss: 0.734\n",
      "[63, 300] loss: 0.718\n",
      "[63, 360] loss: 0.737\n",
      "Epoch: 63 -> Loss: 0.725174546242\n",
      "Epoch: 63 -> Test Accuracy: 66.56\n",
      "[64, 60] loss: 0.726\n",
      "[64, 120] loss: 0.731\n",
      "[64, 180] loss: 0.721\n",
      "[64, 240] loss: 0.735\n",
      "[64, 300] loss: 0.713\n",
      "[64, 360] loss: 0.714\n",
      "Epoch: 64 -> Loss: 0.727840304375\n",
      "Epoch: 64 -> Test Accuracy: 66.94\n",
      "[65, 60] loss: 0.724\n",
      "[65, 120] loss: 0.737\n",
      "[65, 180] loss: 0.730\n",
      "[65, 240] loss: 0.693\n",
      "[65, 300] loss: 0.738\n",
      "[65, 360] loss: 0.741\n",
      "Epoch: 65 -> Loss: 0.768650531769\n",
      "Epoch: 65 -> Test Accuracy: 66.86\n",
      "[66, 60] loss: 0.722\n",
      "[66, 120] loss: 0.728\n",
      "[66, 180] loss: 0.723\n",
      "[66, 240] loss: 0.719\n",
      "[66, 300] loss: 0.713\n",
      "[66, 360] loss: 0.731\n",
      "Epoch: 66 -> Loss: 0.667760074139\n",
      "Epoch: 66 -> Test Accuracy: 66.75\n",
      "[67, 60] loss: 0.717\n",
      "[67, 120] loss: 0.749\n",
      "[67, 180] loss: 0.721\n",
      "[67, 240] loss: 0.752\n",
      "[67, 300] loss: 0.720\n",
      "[67, 360] loss: 0.721\n",
      "Epoch: 67 -> Loss: 0.831469357014\n",
      "Epoch: 67 -> Test Accuracy: 66.72\n",
      "[68, 60] loss: 0.713\n",
      "[68, 120] loss: 0.709\n",
      "[68, 180] loss: 0.734\n",
      "[68, 240] loss: 0.722\n",
      "[68, 300] loss: 0.721\n",
      "[68, 360] loss: 0.732\n",
      "Epoch: 68 -> Loss: 0.70751529932\n",
      "Epoch: 68 -> Test Accuracy: 66.84\n",
      "[69, 60] loss: 0.726\n",
      "[69, 120] loss: 0.705\n",
      "[69, 180] loss: 0.722\n",
      "[69, 240] loss: 0.730\n",
      "[69, 300] loss: 0.746\n",
      "[69, 360] loss: 0.724\n",
      "Epoch: 69 -> Loss: 0.755963683128\n",
      "Epoch: 69 -> Test Accuracy: 66.78\n",
      "[70, 60] loss: 0.707\n",
      "[70, 120] loss: 0.733\n",
      "[70, 180] loss: 0.715\n",
      "[70, 240] loss: 0.733\n",
      "[70, 300] loss: 0.729\n",
      "[70, 360] loss: 0.742\n",
      "Epoch: 70 -> Loss: 0.654457092285\n",
      "Epoch: 70 -> Test Accuracy: 66.63\n",
      "[71, 60] loss: 0.712\n",
      "[71, 120] loss: 0.731\n",
      "[71, 180] loss: 0.714\n",
      "[71, 240] loss: 0.732\n",
      "[71, 300] loss: 0.715\n",
      "[71, 360] loss: 0.713\n",
      "Epoch: 71 -> Loss: 0.733574032784\n",
      "Epoch: 71 -> Test Accuracy: 66.87\n",
      "[72, 60] loss: 0.711\n",
      "[72, 120] loss: 0.725\n",
      "[72, 180] loss: 0.720\n",
      "[72, 240] loss: 0.733\n",
      "[72, 300] loss: 0.726\n",
      "[72, 360] loss: 0.718\n",
      "Epoch: 72 -> Loss: 0.77062189579\n",
      "Epoch: 72 -> Test Accuracy: 66.82\n",
      "[73, 60] loss: 0.728\n",
      "[73, 120] loss: 0.736\n",
      "[73, 180] loss: 0.728\n",
      "[73, 240] loss: 0.711\n",
      "[73, 300] loss: 0.706\n",
      "[73, 360] loss: 0.722\n",
      "Epoch: 73 -> Loss: 0.737808048725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 -> Test Accuracy: 66.74\n",
      "[74, 60] loss: 0.708\n",
      "[74, 120] loss: 0.702\n",
      "[74, 180] loss: 0.714\n",
      "[74, 240] loss: 0.732\n",
      "[74, 300] loss: 0.707\n",
      "[74, 360] loss: 0.724\n",
      "Epoch: 74 -> Loss: 0.642304718494\n",
      "Epoch: 74 -> Test Accuracy: 66.81\n",
      "[75, 60] loss: 0.731\n",
      "[75, 120] loss: 0.727\n",
      "[75, 180] loss: 0.725\n",
      "[75, 240] loss: 0.696\n",
      "[75, 300] loss: 0.729\n",
      "[75, 360] loss: 0.739\n",
      "Epoch: 75 -> Loss: 0.815887629986\n",
      "Epoch: 75 -> Test Accuracy: 66.86\n",
      "[76, 60] loss: 0.694\n",
      "[76, 120] loss: 0.720\n",
      "[76, 180] loss: 0.717\n",
      "[76, 240] loss: 0.723\n",
      "[76, 300] loss: 0.725\n",
      "[76, 360] loss: 0.715\n",
      "Epoch: 76 -> Loss: 0.735110878944\n",
      "Epoch: 76 -> Test Accuracy: 67.01\n",
      "[77, 60] loss: 0.727\n",
      "[77, 120] loss: 0.713\n",
      "[77, 180] loss: 0.714\n",
      "[77, 240] loss: 0.710\n",
      "[77, 300] loss: 0.714\n",
      "[77, 360] loss: 0.714\n",
      "Epoch: 77 -> Loss: 0.786464512348\n",
      "Epoch: 77 -> Test Accuracy: 66.91\n",
      "[78, 60] loss: 0.698\n",
      "[78, 120] loss: 0.728\n",
      "[78, 180] loss: 0.725\n",
      "[78, 240] loss: 0.718\n",
      "[78, 300] loss: 0.720\n",
      "[78, 360] loss: 0.721\n",
      "Epoch: 78 -> Loss: 0.694241642952\n",
      "Epoch: 78 -> Test Accuracy: 66.79\n",
      "[79, 60] loss: 0.725\n",
      "[79, 120] loss: 0.721\n",
      "[79, 180] loss: 0.732\n",
      "[79, 240] loss: 0.704\n",
      "[79, 300] loss: 0.707\n",
      "[79, 360] loss: 0.715\n",
      "Epoch: 79 -> Loss: 0.73432290554\n",
      "Epoch: 79 -> Test Accuracy: 66.98\n",
      "[80, 60] loss: 0.720\n",
      "[80, 120] loss: 0.720\n",
      "[80, 180] loss: 0.706\n",
      "[80, 240] loss: 0.716\n",
      "[80, 300] loss: 0.707\n",
      "[80, 360] loss: 0.729\n",
      "Epoch: 80 -> Loss: 0.72200357914\n",
      "Epoch: 80 -> Test Accuracy: 66.84\n",
      "[81, 60] loss: 0.722\n",
      "[81, 120] loss: 0.710\n",
      "[81, 180] loss: 0.712\n",
      "[81, 240] loss: 0.698\n",
      "[81, 300] loss: 0.730\n",
      "[81, 360] loss: 0.733\n",
      "Epoch: 81 -> Loss: 0.725694000721\n",
      "Epoch: 81 -> Test Accuracy: 66.66\n",
      "[82, 60] loss: 0.720\n",
      "[82, 120] loss: 0.703\n",
      "[82, 180] loss: 0.717\n",
      "[82, 240] loss: 0.722\n",
      "[82, 300] loss: 0.715\n",
      "[82, 360] loss: 0.701\n",
      "Epoch: 82 -> Loss: 0.490757405758\n",
      "Epoch: 82 -> Test Accuracy: 67.08\n",
      "[83, 60] loss: 0.693\n",
      "[83, 120] loss: 0.713\n",
      "[83, 180] loss: 0.728\n",
      "[83, 240] loss: 0.707\n",
      "[83, 300] loss: 0.719\n",
      "[83, 360] loss: 0.720\n",
      "Epoch: 83 -> Loss: 0.758738398552\n",
      "Epoch: 83 -> Test Accuracy: 66.65\n",
      "[84, 60] loss: 0.695\n",
      "[84, 120] loss: 0.712\n",
      "[84, 180] loss: 0.708\n",
      "[84, 240] loss: 0.711\n",
      "[84, 300] loss: 0.713\n",
      "[84, 360] loss: 0.730\n",
      "Epoch: 84 -> Loss: 0.865020573139\n",
      "Epoch: 84 -> Test Accuracy: 66.79\n",
      "[85, 60] loss: 0.721\n",
      "[85, 120] loss: 0.720\n",
      "[85, 180] loss: 0.710\n",
      "[85, 240] loss: 0.703\n",
      "[85, 300] loss: 0.683\n",
      "[85, 360] loss: 0.717\n",
      "Epoch: 85 -> Loss: 0.643898367882\n",
      "Epoch: 85 -> Test Accuracy: 66.75\n",
      "[86, 60] loss: 0.707\n",
      "[86, 120] loss: 0.717\n",
      "[86, 180] loss: 0.722\n",
      "[86, 240] loss: 0.707\n",
      "[86, 300] loss: 0.700\n",
      "[86, 360] loss: 0.734\n",
      "Epoch: 86 -> Loss: 0.607029497623\n",
      "Epoch: 86 -> Test Accuracy: 66.88\n",
      "[87, 60] loss: 0.696\n",
      "[87, 120] loss: 0.705\n",
      "[87, 180] loss: 0.691\n",
      "[87, 240] loss: 0.718\n",
      "[87, 300] loss: 0.723\n",
      "[87, 360] loss: 0.726\n",
      "Epoch: 87 -> Loss: 0.792208850384\n",
      "Epoch: 87 -> Test Accuracy: 66.69\n",
      "[88, 60] loss: 0.721\n",
      "[88, 120] loss: 0.705\n",
      "[88, 180] loss: 0.696\n",
      "[88, 240] loss: 0.711\n",
      "[88, 300] loss: 0.688\n",
      "[88, 360] loss: 0.712\n",
      "Epoch: 88 -> Loss: 0.638496994972\n",
      "Epoch: 88 -> Test Accuracy: 66.81\n",
      "[89, 60] loss: 0.704\n",
      "[89, 120] loss: 0.723\n",
      "[89, 180] loss: 0.700\n",
      "[89, 240] loss: 0.699\n",
      "[89, 300] loss: 0.712\n",
      "[89, 360] loss: 0.709\n",
      "Epoch: 89 -> Loss: 0.623525500298\n",
      "Epoch: 89 -> Test Accuracy: 66.71\n",
      "[90, 60] loss: 0.705\n",
      "[90, 120] loss: 0.691\n",
      "[90, 180] loss: 0.732\n",
      "[90, 240] loss: 0.713\n",
      "[90, 300] loss: 0.709\n",
      "[90, 360] loss: 0.703\n",
      "Epoch: 90 -> Loss: 0.658179819584\n",
      "Epoch: 90 -> Test Accuracy: 66.93\n",
      "[91, 60] loss: 0.717\n",
      "[91, 120] loss: 0.718\n",
      "[91, 180] loss: 0.702\n",
      "[91, 240] loss: 0.700\n",
      "[91, 300] loss: 0.715\n",
      "[91, 360] loss: 0.709\n",
      "Epoch: 91 -> Loss: 0.735901772976\n",
      "Epoch: 91 -> Test Accuracy: 66.86\n",
      "[92, 60] loss: 0.711\n",
      "[92, 120] loss: 0.713\n",
      "[92, 180] loss: 0.706\n",
      "[92, 240] loss: 0.722\n",
      "[92, 300] loss: 0.705\n",
      "[92, 360] loss: 0.711\n",
      "Epoch: 92 -> Loss: 0.513325333595\n",
      "Epoch: 92 -> Test Accuracy: 66.99\n",
      "[93, 60] loss: 0.718\n",
      "[93, 120] loss: 0.720\n",
      "[93, 180] loss: 0.696\n",
      "[93, 240] loss: 0.695\n",
      "[93, 300] loss: 0.688\n",
      "[93, 360] loss: 0.709\n",
      "Epoch: 93 -> Loss: 0.84111481905\n",
      "Epoch: 93 -> Test Accuracy: 66.88\n",
      "[94, 60] loss: 0.693\n",
      "[94, 120] loss: 0.694\n",
      "[94, 180] loss: 0.719\n",
      "[94, 240] loss: 0.706\n",
      "[94, 300] loss: 0.717\n",
      "[94, 360] loss: 0.734\n",
      "Epoch: 94 -> Loss: 0.552917480469\n",
      "Epoch: 94 -> Test Accuracy: 66.8\n",
      "[95, 60] loss: 0.689\n",
      "[95, 120] loss: 0.696\n",
      "[95, 180] loss: 0.702\n",
      "[95, 240] loss: 0.729\n",
      "[95, 300] loss: 0.707\n",
      "[95, 360] loss: 0.694\n",
      "Epoch: 95 -> Loss: 0.75840651989\n",
      "Epoch: 95 -> Test Accuracy: 66.7\n",
      "[96, 60] loss: 0.694\n",
      "[96, 120] loss: 0.710\n",
      "[96, 180] loss: 0.702\n",
      "[96, 240] loss: 0.707\n",
      "[96, 300] loss: 0.701\n",
      "[96, 360] loss: 0.709\n",
      "Epoch: 96 -> Loss: 0.79886496067\n",
      "Epoch: 96 -> Test Accuracy: 66.93\n",
      "[97, 60] loss: 0.706\n",
      "[97, 120] loss: 0.720\n",
      "[97, 180] loss: 0.695\n",
      "[97, 240] loss: 0.690\n",
      "[97, 300] loss: 0.708\n",
      "[97, 360] loss: 0.709\n",
      "Epoch: 97 -> Loss: 0.681547284126\n",
      "Epoch: 97 -> Test Accuracy: 66.98\n",
      "[98, 60] loss: 0.717\n",
      "[98, 120] loss: 0.694\n",
      "[98, 180] loss: 0.697\n",
      "[98, 240] loss: 0.706\n",
      "[98, 300] loss: 0.708\n",
      "[98, 360] loss: 0.704\n",
      "Epoch: 98 -> Loss: 0.861786842346\n",
      "Epoch: 98 -> Test Accuracy: 66.8\n",
      "[99, 60] loss: 0.701\n",
      "[99, 120] loss: 0.699\n",
      "[99, 180] loss: 0.711\n",
      "[99, 240] loss: 0.697\n",
      "[99, 300] loss: 0.691\n",
      "[99, 360] loss: 0.690\n",
      "Epoch: 99 -> Loss: 0.597368896008\n",
      "Epoch: 99 -> Test Accuracy: 66.83\n",
      "[100, 60] loss: 0.695\n",
      "[100, 120] loss: 0.722\n",
      "[100, 180] loss: 0.690\n",
      "[100, 240] loss: 0.702\n",
      "[100, 300] loss: 0.707\n",
      "[100, 360] loss: 0.705\n",
      "Epoch: 100 -> Loss: 0.671653628349\n",
      "Epoch: 100 -> Test Accuracy: 66.95\n",
      "Finished Training\n",
      "[1, 60] loss: 2.801\n",
      "[1, 120] loss: 2.124\n",
      "[1, 180] loss: 2.085\n",
      "[1, 240] loss: 2.042\n",
      "[1, 300] loss: 2.014\n",
      "[1, 360] loss: 2.005\n",
      "Epoch: 1 -> Loss: 2.10554265976\n",
      "Epoch: 1 -> Test Accuracy: 24.83\n",
      "[2, 60] loss: 1.979\n",
      "[2, 120] loss: 1.969\n",
      "[2, 180] loss: 1.959\n",
      "[2, 240] loss: 1.946\n",
      "[2, 300] loss: 1.948\n",
      "[2, 360] loss: 1.928\n",
      "Epoch: 2 -> Loss: 1.8019644022\n",
      "Epoch: 2 -> Test Accuracy: 27.5\n",
      "[3, 60] loss: 1.921\n",
      "[3, 120] loss: 1.916\n",
      "[3, 180] loss: 1.912\n",
      "[3, 240] loss: 1.890\n",
      "[3, 300] loss: 1.897\n",
      "[3, 360] loss: 1.894\n",
      "Epoch: 3 -> Loss: 1.89750289917\n",
      "Epoch: 3 -> Test Accuracy: 28.45\n",
      "[4, 60] loss: 1.896\n",
      "[4, 120] loss: 1.897\n",
      "[4, 180] loss: 1.885\n",
      "[4, 240] loss: 1.876\n",
      "[4, 300] loss: 1.884\n",
      "[4, 360] loss: 1.877\n",
      "Epoch: 4 -> Loss: 1.85031247139\n",
      "Epoch: 4 -> Test Accuracy: 28.06\n",
      "[5, 60] loss: 1.871\n",
      "[5, 120] loss: 1.871\n",
      "[5, 180] loss: 1.886\n",
      "[5, 240] loss: 1.853\n",
      "[5, 300] loss: 1.857\n",
      "[5, 360] loss: 1.859\n",
      "Epoch: 5 -> Loss: 1.89104247093\n",
      "Epoch: 5 -> Test Accuracy: 29.14\n",
      "[6, 60] loss: 1.865\n",
      "[6, 120] loss: 1.859\n",
      "[6, 180] loss: 1.851\n",
      "[6, 240] loss: 1.836\n",
      "[6, 300] loss: 1.859\n",
      "[6, 360] loss: 1.877\n",
      "Epoch: 6 -> Loss: 1.72679746151\n",
      "Epoch: 6 -> Test Accuracy: 29.49\n",
      "[7, 60] loss: 1.832\n",
      "[7, 120] loss: 1.854\n",
      "[7, 180] loss: 1.864\n",
      "[7, 240] loss: 1.844\n",
      "[7, 300] loss: 1.861\n",
      "[7, 360] loss: 1.856\n",
      "Epoch: 7 -> Loss: 1.81455171108\n",
      "Epoch: 7 -> Test Accuracy: 29.99\n",
      "[8, 60] loss: 1.850\n",
      "[8, 120] loss: 1.847\n",
      "[8, 180] loss: 1.860\n",
      "[8, 240] loss: 1.836\n",
      "[8, 300] loss: 1.838\n",
      "[8, 360] loss: 1.840\n",
      "Epoch: 8 -> Loss: 1.76650500298\n",
      "Epoch: 8 -> Test Accuracy: 28.45\n",
      "[9, 60] loss: 1.855\n",
      "[9, 120] loss: 1.833\n",
      "[9, 180] loss: 1.844\n",
      "[9, 240] loss: 1.831\n",
      "[9, 300] loss: 1.835\n",
      "[9, 360] loss: 1.855\n",
      "Epoch: 9 -> Loss: 1.82068884373\n",
      "Epoch: 9 -> Test Accuracy: 30.46\n",
      "[10, 60] loss: 1.848\n",
      "[10, 120] loss: 1.849\n",
      "[10, 180] loss: 1.840\n",
      "[10, 240] loss: 1.834\n",
      "[10, 300] loss: 1.840\n",
      "[10, 360] loss: 1.830\n",
      "Epoch: 10 -> Loss: 2.00391530991\n",
      "Epoch: 10 -> Test Accuracy: 30.32\n",
      "[11, 60] loss: 1.835\n",
      "[11, 120] loss: 1.842\n",
      "[11, 180] loss: 1.832\n",
      "[11, 240] loss: 1.830\n",
      "[11, 300] loss: 1.833\n",
      "[11, 360] loss: 1.842\n",
      "Epoch: 11 -> Loss: 1.77310025692\n",
      "Epoch: 11 -> Test Accuracy: 30.38\n",
      "[12, 60] loss: 1.836\n",
      "[12, 120] loss: 1.845\n",
      "[12, 180] loss: 1.833\n",
      "[12, 240] loss: 1.838\n",
      "[12, 300] loss: 1.824\n",
      "[12, 360] loss: 1.844\n",
      "Epoch: 12 -> Loss: 1.98878157139\n",
      "Epoch: 12 -> Test Accuracy: 30.51\n",
      "[13, 60] loss: 1.838\n",
      "[13, 120] loss: 1.824\n",
      "[13, 180] loss: 1.842\n",
      "[13, 240] loss: 1.810\n",
      "[13, 300] loss: 1.834\n",
      "[13, 360] loss: 1.836\n",
      "Epoch: 13 -> Loss: 1.85479617119\n",
      "Epoch: 13 -> Test Accuracy: 30.06\n",
      "[14, 60] loss: 1.809\n",
      "[14, 120] loss: 1.834\n",
      "[14, 180] loss: 1.835\n",
      "[14, 240] loss: 1.825\n",
      "[14, 300] loss: 1.823\n",
      "[14, 360] loss: 1.834\n",
      "Epoch: 14 -> Loss: 1.93999326229\n",
      "Epoch: 14 -> Test Accuracy: 30.59\n",
      "[15, 60] loss: 1.816\n",
      "[15, 120] loss: 1.824\n",
      "[15, 180] loss: 1.829\n",
      "[15, 240] loss: 1.835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 300] loss: 1.831\n",
      "[15, 360] loss: 1.835\n",
      "Epoch: 15 -> Loss: 1.70649170876\n",
      "Epoch: 15 -> Test Accuracy: 30.49\n",
      "[16, 60] loss: 1.830\n",
      "[16, 120] loss: 1.822\n",
      "[16, 180] loss: 1.836\n",
      "[16, 240] loss: 1.824\n",
      "[16, 300] loss: 1.830\n",
      "[16, 360] loss: 1.842\n",
      "Epoch: 16 -> Loss: 1.86377358437\n",
      "Epoch: 16 -> Test Accuracy: 31.06\n",
      "[17, 60] loss: 1.834\n",
      "[17, 120] loss: 1.818\n",
      "[17, 180] loss: 1.828\n",
      "[17, 240] loss: 1.820\n",
      "[17, 300] loss: 1.827\n",
      "[17, 360] loss: 1.821\n",
      "Epoch: 17 -> Loss: 2.02896928787\n",
      "Epoch: 17 -> Test Accuracy: 30.94\n",
      "[18, 60] loss: 1.797\n",
      "[18, 120] loss: 1.828\n",
      "[18, 180] loss: 1.818\n",
      "[18, 240] loss: 1.824\n",
      "[18, 300] loss: 1.838\n",
      "[18, 360] loss: 1.824\n",
      "Epoch: 18 -> Loss: 1.92600655556\n",
      "Epoch: 18 -> Test Accuracy: 30.84\n",
      "[19, 60] loss: 1.827\n",
      "[19, 120] loss: 1.821\n",
      "[19, 180] loss: 1.820\n",
      "[19, 240] loss: 1.819\n",
      "[19, 300] loss: 1.834\n",
      "[19, 360] loss: 1.827\n",
      "Epoch: 19 -> Loss: 1.73285865784\n",
      "Epoch: 19 -> Test Accuracy: 29.71\n",
      "[20, 60] loss: 1.801\n",
      "[20, 120] loss: 1.809\n",
      "[20, 180] loss: 1.826\n",
      "[20, 240] loss: 1.841\n",
      "[20, 300] loss: 1.839\n",
      "[20, 360] loss: 1.823\n",
      "Epoch: 20 -> Loss: 1.78491044044\n",
      "Epoch: 20 -> Test Accuracy: 30.1\n",
      "[21, 60] loss: 1.801\n",
      "[21, 120] loss: 1.759\n",
      "[21, 180] loss: 1.745\n",
      "[21, 240] loss: 1.776\n",
      "[21, 300] loss: 1.751\n",
      "[21, 360] loss: 1.760\n",
      "Epoch: 21 -> Loss: 1.86764216423\n",
      "Epoch: 21 -> Test Accuracy: 32.81\n",
      "[22, 60] loss: 1.738\n",
      "[22, 120] loss: 1.745\n",
      "[22, 180] loss: 1.745\n",
      "[22, 240] loss: 1.731\n",
      "[22, 300] loss: 1.726\n",
      "[22, 360] loss: 1.735\n",
      "Epoch: 22 -> Loss: 1.66031241417\n",
      "Epoch: 22 -> Test Accuracy: 33.01\n",
      "[23, 60] loss: 1.741\n",
      "[23, 120] loss: 1.736\n",
      "[23, 180] loss: 1.721\n",
      "[23, 240] loss: 1.718\n",
      "[23, 300] loss: 1.722\n",
      "[23, 360] loss: 1.729\n",
      "Epoch: 23 -> Loss: 1.72874104977\n",
      "Epoch: 23 -> Test Accuracy: 33.68\n",
      "[24, 60] loss: 1.727\n",
      "[24, 120] loss: 1.711\n",
      "[24, 180] loss: 1.711\n",
      "[24, 240] loss: 1.723\n",
      "[24, 300] loss: 1.737\n",
      "[24, 360] loss: 1.727\n",
      "Epoch: 24 -> Loss: 1.77016329765\n",
      "Epoch: 24 -> Test Accuracy: 32.75\n",
      "[25, 60] loss: 1.720\n",
      "[25, 120] loss: 1.722\n",
      "[25, 180] loss: 1.730\n",
      "[25, 240] loss: 1.721\n",
      "[25, 300] loss: 1.716\n",
      "[25, 360] loss: 1.722\n",
      "Epoch: 25 -> Loss: 1.55483555794\n",
      "Epoch: 25 -> Test Accuracy: 33.0\n",
      "[26, 60] loss: 1.701\n",
      "[26, 120] loss: 1.712\n",
      "[26, 180] loss: 1.722\n",
      "[26, 240] loss: 1.735\n",
      "[26, 300] loss: 1.712\n",
      "[26, 360] loss: 1.725\n",
      "Epoch: 26 -> Loss: 1.67087340355\n",
      "Epoch: 26 -> Test Accuracy: 33.94\n",
      "[27, 60] loss: 1.701\n",
      "[27, 120] loss: 1.717\n",
      "[27, 180] loss: 1.720\n",
      "[27, 240] loss: 1.717\n",
      "[27, 300] loss: 1.704\n",
      "[27, 360] loss: 1.735\n",
      "Epoch: 27 -> Loss: 1.7849727869\n",
      "Epoch: 27 -> Test Accuracy: 33.89\n",
      "[28, 60] loss: 1.708\n",
      "[28, 120] loss: 1.715\n",
      "[28, 180] loss: 1.710\n",
      "[28, 240] loss: 1.720\n",
      "[28, 300] loss: 1.729\n",
      "[28, 360] loss: 1.707\n",
      "Epoch: 28 -> Loss: 1.48075020313\n",
      "Epoch: 28 -> Test Accuracy: 33.45\n",
      "[29, 60] loss: 1.706\n",
      "[29, 120] loss: 1.734\n",
      "[29, 180] loss: 1.704\n",
      "[29, 240] loss: 1.708\n",
      "[29, 300] loss: 1.723\n",
      "[29, 360] loss: 1.691\n",
      "Epoch: 29 -> Loss: 1.84378647804\n",
      "Epoch: 29 -> Test Accuracy: 33.53\n",
      "[30, 60] loss: 1.720\n",
      "[30, 120] loss: 1.727\n",
      "[30, 180] loss: 1.724\n",
      "[30, 240] loss: 1.722\n",
      "[30, 300] loss: 1.712\n",
      "[30, 360] loss: 1.696\n",
      "Epoch: 30 -> Loss: 1.91728878021\n",
      "Epoch: 30 -> Test Accuracy: 34.16\n",
      "[31, 60] loss: 1.714\n",
      "[31, 120] loss: 1.724\n",
      "[31, 180] loss: 1.714\n",
      "[31, 240] loss: 1.713\n",
      "[31, 300] loss: 1.705\n",
      "[31, 360] loss: 1.706\n",
      "Epoch: 31 -> Loss: 1.75429224968\n",
      "Epoch: 31 -> Test Accuracy: 34.29\n",
      "[32, 60] loss: 1.714\n",
      "[32, 120] loss: 1.719\n",
      "[32, 180] loss: 1.717\n",
      "[32, 240] loss: 1.685\n",
      "[32, 300] loss: 1.706\n",
      "[32, 360] loss: 1.701\n",
      "Epoch: 32 -> Loss: 1.77868843079\n",
      "Epoch: 32 -> Test Accuracy: 33.4\n",
      "[33, 60] loss: 1.702\n",
      "[33, 120] loss: 1.705\n",
      "[33, 180] loss: 1.707\n",
      "[33, 240] loss: 1.715\n",
      "[33, 300] loss: 1.696\n",
      "[33, 360] loss: 1.709\n",
      "Epoch: 33 -> Loss: 1.77195191383\n",
      "Epoch: 33 -> Test Accuracy: 32.85\n",
      "[34, 60] loss: 1.699\n",
      "[34, 120] loss: 1.718\n",
      "[34, 180] loss: 1.713\n",
      "[34, 240] loss: 1.721\n",
      "[34, 300] loss: 1.725\n",
      "[34, 360] loss: 1.698\n",
      "Epoch: 34 -> Loss: 1.88255536556\n",
      "Epoch: 34 -> Test Accuracy: 33.16\n",
      "[35, 60] loss: 1.699\n",
      "[35, 120] loss: 1.697\n",
      "[35, 180] loss: 1.689\n",
      "[35, 240] loss: 1.722\n",
      "[35, 300] loss: 1.724\n",
      "[35, 360] loss: 1.717\n",
      "Epoch: 35 -> Loss: 1.76822912693\n",
      "Epoch: 35 -> Test Accuracy: 33.15\n",
      "[36, 60] loss: 1.720\n",
      "[36, 120] loss: 1.715\n",
      "[36, 180] loss: 1.695\n",
      "[36, 240] loss: 1.722\n",
      "[36, 300] loss: 1.700\n",
      "[36, 360] loss: 1.722\n",
      "Epoch: 36 -> Loss: 1.56048882008\n",
      "Epoch: 36 -> Test Accuracy: 33.78\n",
      "[37, 60] loss: 1.717\n",
      "[37, 120] loss: 1.706\n",
      "[37, 180] loss: 1.718\n",
      "[37, 240] loss: 1.711\n",
      "[37, 300] loss: 1.711\n",
      "[37, 360] loss: 1.704\n",
      "Epoch: 37 -> Loss: 2.00648331642\n",
      "Epoch: 37 -> Test Accuracy: 33.37\n",
      "[38, 60] loss: 1.705\n",
      "[38, 120] loss: 1.700\n",
      "[38, 180] loss: 1.707\n",
      "[38, 240] loss: 1.699\n",
      "[38, 300] loss: 1.727\n",
      "[38, 360] loss: 1.700\n",
      "Epoch: 38 -> Loss: 1.73805868626\n",
      "Epoch: 38 -> Test Accuracy: 33.63\n",
      "[39, 60] loss: 1.709\n",
      "[39, 120] loss: 1.695\n",
      "[39, 180] loss: 1.709\n",
      "[39, 240] loss: 1.707\n",
      "[39, 300] loss: 1.700\n",
      "[39, 360] loss: 1.719\n",
      "Epoch: 39 -> Loss: 1.61348211765\n",
      "Epoch: 39 -> Test Accuracy: 33.27\n",
      "[40, 60] loss: 1.693\n",
      "[40, 120] loss: 1.710\n",
      "[40, 180] loss: 1.716\n",
      "[40, 240] loss: 1.692\n",
      "[40, 300] loss: 1.700\n",
      "[40, 360] loss: 1.708\n",
      "Epoch: 40 -> Loss: 1.63505649567\n",
      "Epoch: 40 -> Test Accuracy: 34.22\n",
      "[41, 60] loss: 1.713\n",
      "[41, 120] loss: 1.683\n",
      "[41, 180] loss: 1.673\n",
      "[41, 240] loss: 1.674\n",
      "[41, 300] loss: 1.661\n",
      "[41, 360] loss: 1.656\n",
      "Epoch: 41 -> Loss: 1.56636738777\n",
      "Epoch: 41 -> Test Accuracy: 34.65\n",
      "[42, 60] loss: 1.652\n",
      "[42, 120] loss: 1.649\n",
      "[42, 180] loss: 1.660\n",
      "[42, 240] loss: 1.672\n",
      "[42, 300] loss: 1.634\n",
      "[42, 360] loss: 1.642\n",
      "Epoch: 42 -> Loss: 1.48306429386\n",
      "Epoch: 42 -> Test Accuracy: 34.79\n",
      "[43, 60] loss: 1.644\n",
      "[43, 120] loss: 1.661\n",
      "[43, 180] loss: 1.647\n",
      "[43, 240] loss: 1.642\n",
      "[43, 300] loss: 1.662\n",
      "[43, 360] loss: 1.654\n",
      "Epoch: 43 -> Loss: 1.6304473877\n",
      "Epoch: 43 -> Test Accuracy: 34.93\n",
      "[44, 60] loss: 1.650\n",
      "[44, 120] loss: 1.634\n",
      "[44, 180] loss: 1.647\n",
      "[44, 240] loss: 1.642\n",
      "[44, 300] loss: 1.643\n",
      "[44, 360] loss: 1.648\n",
      "Epoch: 44 -> Loss: 1.79551196098\n",
      "Epoch: 44 -> Test Accuracy: 34.99\n",
      "[45, 60] loss: 1.635\n",
      "[45, 120] loss: 1.658\n",
      "[45, 180] loss: 1.660\n",
      "[45, 240] loss: 1.651\n",
      "[45, 300] loss: 1.652\n",
      "[45, 360] loss: 1.637\n",
      "Epoch: 45 -> Loss: 1.70611703396\n",
      "Epoch: 45 -> Test Accuracy: 35.1\n",
      "[46, 60] loss: 1.625\n",
      "[46, 120] loss: 1.623\n",
      "[46, 180] loss: 1.628\n",
      "[46, 240] loss: 1.643\n",
      "[46, 300] loss: 1.632\n",
      "[46, 360] loss: 1.639\n",
      "Epoch: 46 -> Loss: 1.57535851002\n",
      "Epoch: 46 -> Test Accuracy: 35.45\n",
      "[47, 60] loss: 1.626\n",
      "[47, 120] loss: 1.649\n",
      "[47, 180] loss: 1.620\n",
      "[47, 240] loss: 1.627\n",
      "[47, 300] loss: 1.620\n",
      "[47, 360] loss: 1.631\n",
      "Epoch: 47 -> Loss: 1.76397681236\n",
      "Epoch: 47 -> Test Accuracy: 35.6\n",
      "[48, 60] loss: 1.629\n",
      "[48, 120] loss: 1.608\n",
      "[48, 180] loss: 1.635\n",
      "[48, 240] loss: 1.638\n",
      "[48, 300] loss: 1.652\n",
      "[48, 360] loss: 1.631\n",
      "Epoch: 48 -> Loss: 1.4792330265\n",
      "Epoch: 48 -> Test Accuracy: 35.31\n",
      "[49, 60] loss: 1.613\n",
      "[49, 120] loss: 1.629\n",
      "[49, 180] loss: 1.627\n",
      "[49, 240] loss: 1.620\n",
      "[49, 300] loss: 1.648\n",
      "[49, 360] loss: 1.624\n",
      "Epoch: 49 -> Loss: 1.63078057766\n",
      "Epoch: 49 -> Test Accuracy: 35.59\n",
      "[50, 60] loss: 1.617\n",
      "[50, 120] loss: 1.629\n",
      "[50, 180] loss: 1.634\n",
      "[50, 240] loss: 1.609\n",
      "[50, 300] loss: 1.617\n",
      "[50, 360] loss: 1.639\n",
      "Epoch: 50 -> Loss: 1.67563343048\n",
      "Epoch: 50 -> Test Accuracy: 35.39\n",
      "[51, 60] loss: 1.631\n",
      "[51, 120] loss: 1.642\n",
      "[51, 180] loss: 1.631\n",
      "[51, 240] loss: 1.623\n",
      "[51, 300] loss: 1.603\n",
      "[51, 360] loss: 1.624\n",
      "Epoch: 51 -> Loss: 1.81560969353\n",
      "Epoch: 51 -> Test Accuracy: 35.4\n",
      "[52, 60] loss: 1.627\n",
      "[52, 120] loss: 1.616\n",
      "[52, 180] loss: 1.638\n",
      "[52, 240] loss: 1.635\n",
      "[52, 300] loss: 1.615\n",
      "[52, 360] loss: 1.622\n",
      "Epoch: 52 -> Loss: 1.36365902424\n",
      "Epoch: 52 -> Test Accuracy: 35.43\n",
      "[53, 60] loss: 1.632\n",
      "[53, 120] loss: 1.617\n",
      "[53, 180] loss: 1.625\n",
      "[53, 240] loss: 1.616\n",
      "[53, 300] loss: 1.625\n",
      "[53, 360] loss: 1.624\n",
      "Epoch: 53 -> Loss: 1.6519010067\n",
      "Epoch: 53 -> Test Accuracy: 35.66\n",
      "[54, 60] loss: 1.626\n",
      "[54, 120] loss: 1.624\n",
      "[54, 180] loss: 1.612\n",
      "[54, 240] loss: 1.628\n",
      "[54, 300] loss: 1.631\n",
      "[54, 360] loss: 1.631\n",
      "Epoch: 54 -> Loss: 1.46844887733\n",
      "Epoch: 54 -> Test Accuracy: 35.7\n",
      "[55, 60] loss: 1.608\n",
      "[55, 120] loss: 1.630\n",
      "[55, 180] loss: 1.617\n",
      "[55, 240] loss: 1.630\n",
      "[55, 300] loss: 1.620\n",
      "[55, 360] loss: 1.611\n",
      "Epoch: 55 -> Loss: 1.66001152992\n",
      "Epoch: 55 -> Test Accuracy: 35.64\n",
      "[56, 60] loss: 1.614\n",
      "[56, 120] loss: 1.636\n",
      "[56, 180] loss: 1.625\n",
      "[56, 240] loss: 1.622\n",
      "[56, 300] loss: 1.631\n",
      "[56, 360] loss: 1.627\n",
      "Epoch: 56 -> Loss: 1.64013266563\n",
      "Epoch: 56 -> Test Accuracy: 35.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57, 60] loss: 1.619\n",
      "[57, 120] loss: 1.629\n",
      "[57, 180] loss: 1.613\n",
      "[57, 240] loss: 1.615\n",
      "[57, 300] loss: 1.612\n",
      "[57, 360] loss: 1.624\n",
      "Epoch: 57 -> Loss: 1.7365449667\n",
      "Epoch: 57 -> Test Accuracy: 35.95\n",
      "[58, 60] loss: 1.629\n",
      "[58, 120] loss: 1.605\n",
      "[58, 180] loss: 1.635\n",
      "[58, 240] loss: 1.618\n",
      "[58, 300] loss: 1.618\n",
      "[58, 360] loss: 1.622\n",
      "Epoch: 58 -> Loss: 1.57100939751\n",
      "Epoch: 58 -> Test Accuracy: 35.43\n",
      "[59, 60] loss: 1.623\n",
      "[59, 120] loss: 1.618\n",
      "[59, 180] loss: 1.610\n",
      "[59, 240] loss: 1.626\n",
      "[59, 300] loss: 1.622\n",
      "[59, 360] loss: 1.621\n",
      "Epoch: 59 -> Loss: 1.63170313835\n",
      "Epoch: 59 -> Test Accuracy: 35.89\n",
      "[60, 60] loss: 1.607\n",
      "[60, 120] loss: 1.625\n",
      "[60, 180] loss: 1.620\n",
      "[60, 240] loss: 1.614\n",
      "[60, 300] loss: 1.625\n",
      "[60, 360] loss: 1.615\n",
      "Epoch: 60 -> Loss: 1.71080267429\n",
      "Epoch: 60 -> Test Accuracy: 35.83\n",
      "[61, 60] loss: 1.619\n",
      "[61, 120] loss: 1.644\n",
      "[61, 180] loss: 1.629\n",
      "[61, 240] loss: 1.601\n",
      "[61, 300] loss: 1.620\n",
      "[61, 360] loss: 1.602\n",
      "Epoch: 61 -> Loss: 1.66555142403\n",
      "Epoch: 61 -> Test Accuracy: 35.87\n",
      "[62, 60] loss: 1.624\n",
      "[62, 120] loss: 1.621\n",
      "[62, 180] loss: 1.617\n",
      "[62, 240] loss: 1.606\n",
      "[62, 300] loss: 1.622\n",
      "[62, 360] loss: 1.610\n",
      "Epoch: 62 -> Loss: 1.61617088318\n",
      "Epoch: 62 -> Test Accuracy: 35.82\n",
      "[63, 60] loss: 1.626\n",
      "[63, 120] loss: 1.617\n",
      "[63, 180] loss: 1.620\n",
      "[63, 240] loss: 1.617\n",
      "[63, 300] loss: 1.621\n",
      "[63, 360] loss: 1.624\n",
      "Epoch: 63 -> Loss: 1.64541316032\n",
      "Epoch: 63 -> Test Accuracy: 35.84\n",
      "[64, 60] loss: 1.600\n",
      "[64, 120] loss: 1.622\n",
      "[64, 180] loss: 1.628\n",
      "[64, 240] loss: 1.618\n",
      "[64, 300] loss: 1.617\n",
      "[64, 360] loss: 1.602\n",
      "Epoch: 64 -> Loss: 1.72978591919\n",
      "Epoch: 64 -> Test Accuracy: 36.09\n",
      "[65, 60] loss: 1.610\n",
      "[65, 120] loss: 1.637\n",
      "[65, 180] loss: 1.616\n",
      "[65, 240] loss: 1.605\n",
      "[65, 300] loss: 1.617\n",
      "[65, 360] loss: 1.600\n",
      "Epoch: 65 -> Loss: 1.48209381104\n",
      "Epoch: 65 -> Test Accuracy: 36.09\n",
      "[66, 60] loss: 1.609\n",
      "[66, 120] loss: 1.610\n",
      "[66, 180] loss: 1.597\n",
      "[66, 240] loss: 1.601\n",
      "[66, 300] loss: 1.626\n",
      "[66, 360] loss: 1.617\n",
      "Epoch: 66 -> Loss: 1.73036134243\n",
      "Epoch: 66 -> Test Accuracy: 36.16\n",
      "[67, 60] loss: 1.609\n",
      "[67, 120] loss: 1.614\n",
      "[67, 180] loss: 1.617\n",
      "[67, 240] loss: 1.605\n",
      "[67, 300] loss: 1.622\n",
      "[67, 360] loss: 1.602\n",
      "Epoch: 67 -> Loss: 1.73703253269\n",
      "Epoch: 67 -> Test Accuracy: 35.91\n",
      "[68, 60] loss: 1.612\n",
      "[68, 120] loss: 1.610\n",
      "[68, 180] loss: 1.616\n",
      "[68, 240] loss: 1.616\n",
      "[68, 300] loss: 1.631\n",
      "[68, 360] loss: 1.623\n",
      "Epoch: 68 -> Loss: 1.55661261082\n",
      "Epoch: 68 -> Test Accuracy: 35.92\n",
      "[69, 60] loss: 1.610\n",
      "[69, 120] loss: 1.622\n",
      "[69, 180] loss: 1.607\n",
      "[69, 240] loss: 1.603\n",
      "[69, 300] loss: 1.604\n",
      "[69, 360] loss: 1.636\n",
      "Epoch: 69 -> Loss: 1.59941411018\n",
      "Epoch: 69 -> Test Accuracy: 36.03\n",
      "[70, 60] loss: 1.613\n",
      "[70, 120] loss: 1.613\n",
      "[70, 180] loss: 1.610\n",
      "[70, 240] loss: 1.604\n",
      "[70, 300] loss: 1.610\n",
      "[70, 360] loss: 1.616\n",
      "Epoch: 70 -> Loss: 1.74226593971\n",
      "Epoch: 70 -> Test Accuracy: 36.15\n",
      "[71, 60] loss: 1.592\n",
      "[71, 120] loss: 1.613\n",
      "[71, 180] loss: 1.626\n",
      "[71, 240] loss: 1.623\n",
      "[71, 300] loss: 1.615\n",
      "[71, 360] loss: 1.609\n",
      "Epoch: 71 -> Loss: 1.65890955925\n",
      "Epoch: 71 -> Test Accuracy: 36.19\n",
      "[72, 60] loss: 1.625\n",
      "[72, 120] loss: 1.610\n",
      "[72, 180] loss: 1.633\n",
      "[72, 240] loss: 1.621\n",
      "[72, 300] loss: 1.614\n",
      "[72, 360] loss: 1.607\n",
      "Epoch: 72 -> Loss: 1.63195478916\n",
      "Epoch: 72 -> Test Accuracy: 36.32\n",
      "[73, 60] loss: 1.619\n",
      "[73, 120] loss: 1.597\n",
      "[73, 180] loss: 1.612\n",
      "[73, 240] loss: 1.603\n",
      "[73, 300] loss: 1.621\n",
      "[73, 360] loss: 1.615\n",
      "Epoch: 73 -> Loss: 1.65996837616\n",
      "Epoch: 73 -> Test Accuracy: 36.03\n",
      "[74, 60] loss: 1.608\n",
      "[74, 120] loss: 1.610\n",
      "[74, 180] loss: 1.614\n",
      "[74, 240] loss: 1.586\n",
      "[74, 300] loss: 1.600\n",
      "[74, 360] loss: 1.608\n",
      "Epoch: 74 -> Loss: 1.61318683624\n",
      "Epoch: 74 -> Test Accuracy: 36.34\n",
      "[75, 60] loss: 1.605\n",
      "[75, 120] loss: 1.607\n",
      "[75, 180] loss: 1.617\n",
      "[75, 240] loss: 1.604\n",
      "[75, 300] loss: 1.603\n",
      "[75, 360] loss: 1.622\n",
      "Epoch: 75 -> Loss: 1.5970621109\n",
      "Epoch: 75 -> Test Accuracy: 36.42\n",
      "[76, 60] loss: 1.605\n",
      "[76, 120] loss: 1.605\n",
      "[76, 180] loss: 1.616\n",
      "[76, 240] loss: 1.618\n",
      "[76, 300] loss: 1.609\n",
      "[76, 360] loss: 1.603\n",
      "Epoch: 76 -> Loss: 1.57118356228\n",
      "Epoch: 76 -> Test Accuracy: 36.47\n",
      "[77, 60] loss: 1.615\n",
      "[77, 120] loss: 1.610\n",
      "[77, 180] loss: 1.602\n",
      "[77, 240] loss: 1.612\n",
      "[77, 300] loss: 1.610\n",
      "[77, 360] loss: 1.604\n",
      "Epoch: 77 -> Loss: 1.76814961433\n",
      "Epoch: 77 -> Test Accuracy: 36.45\n",
      "[78, 60] loss: 1.600\n",
      "[78, 120] loss: 1.608\n",
      "[78, 180] loss: 1.614\n",
      "[78, 240] loss: 1.608\n",
      "[78, 300] loss: 1.615\n",
      "[78, 360] loss: 1.627\n",
      "Epoch: 78 -> Loss: 1.58604383469\n",
      "Epoch: 78 -> Test Accuracy: 36.09\n",
      "[79, 60] loss: 1.601\n",
      "[79, 120] loss: 1.620\n",
      "[79, 180] loss: 1.605\n",
      "[79, 240] loss: 1.602\n",
      "[79, 300] loss: 1.581\n",
      "[79, 360] loss: 1.622\n",
      "Epoch: 79 -> Loss: 1.50614178181\n",
      "Epoch: 79 -> Test Accuracy: 35.86\n",
      "[80, 60] loss: 1.601\n",
      "[80, 120] loss: 1.594\n",
      "[80, 180] loss: 1.596\n",
      "[80, 240] loss: 1.621\n",
      "[80, 300] loss: 1.608\n",
      "[80, 360] loss: 1.600\n",
      "Epoch: 80 -> Loss: 1.57409012318\n",
      "Epoch: 80 -> Test Accuracy: 36.45\n",
      "[81, 60] loss: 1.603\n",
      "[81, 120] loss: 1.609\n",
      "[81, 180] loss: 1.588\n",
      "[81, 240] loss: 1.585\n",
      "[81, 300] loss: 1.628\n",
      "[81, 360] loss: 1.621\n",
      "Epoch: 81 -> Loss: 1.42832589149\n",
      "Epoch: 81 -> Test Accuracy: 36.47\n",
      "[82, 60] loss: 1.603\n",
      "[82, 120] loss: 1.604\n",
      "[82, 180] loss: 1.586\n",
      "[82, 240] loss: 1.605\n",
      "[82, 300] loss: 1.627\n",
      "[82, 360] loss: 1.603\n",
      "Epoch: 82 -> Loss: 1.49425959587\n",
      "Epoch: 82 -> Test Accuracy: 36.33\n",
      "[83, 60] loss: 1.597\n",
      "[83, 120] loss: 1.599\n",
      "[83, 180] loss: 1.605\n",
      "[83, 240] loss: 1.617\n",
      "[83, 300] loss: 1.593\n",
      "[83, 360] loss: 1.602\n",
      "Epoch: 83 -> Loss: 1.56144833565\n",
      "Epoch: 83 -> Test Accuracy: 36.36\n",
      "[84, 60] loss: 1.599\n",
      "[84, 120] loss: 1.605\n",
      "[84, 180] loss: 1.601\n",
      "[84, 240] loss: 1.614\n",
      "[84, 300] loss: 1.606\n",
      "[84, 360] loss: 1.618\n",
      "Epoch: 84 -> Loss: 1.6805254221\n",
      "Epoch: 84 -> Test Accuracy: 36.45\n",
      "[85, 60] loss: 1.613\n",
      "[85, 120] loss: 1.616\n",
      "[85, 180] loss: 1.613\n",
      "[85, 240] loss: 1.614\n",
      "[85, 300] loss: 1.617\n",
      "[85, 360] loss: 1.595\n",
      "Epoch: 85 -> Loss: 1.6785800457\n",
      "Epoch: 85 -> Test Accuracy: 36.42\n",
      "[86, 60] loss: 1.594\n",
      "[86, 120] loss: 1.617\n",
      "[86, 180] loss: 1.609\n",
      "[86, 240] loss: 1.604\n",
      "[86, 300] loss: 1.588\n",
      "[86, 360] loss: 1.592\n",
      "Epoch: 86 -> Loss: 1.62526297569\n",
      "Epoch: 86 -> Test Accuracy: 36.19\n",
      "[87, 60] loss: 1.619\n",
      "[87, 120] loss: 1.627\n",
      "[87, 180] loss: 1.593\n",
      "[87, 240] loss: 1.617\n",
      "[87, 300] loss: 1.574\n",
      "[87, 360] loss: 1.589\n",
      "Epoch: 87 -> Loss: 1.64488255978\n",
      "Epoch: 87 -> Test Accuracy: 36.39\n",
      "[88, 60] loss: 1.611\n",
      "[88, 120] loss: 1.617\n",
      "[88, 180] loss: 1.607\n",
      "[88, 240] loss: 1.596\n",
      "[88, 300] loss: 1.599\n",
      "[88, 360] loss: 1.594\n",
      "Epoch: 88 -> Loss: 1.48999273777\n",
      "Epoch: 88 -> Test Accuracy: 36.62\n",
      "[89, 60] loss: 1.596\n",
      "[89, 120] loss: 1.596\n",
      "[89, 180] loss: 1.602\n",
      "[89, 240] loss: 1.611\n",
      "[89, 300] loss: 1.597\n",
      "[89, 360] loss: 1.615\n",
      "Epoch: 89 -> Loss: 1.90081441402\n",
      "Epoch: 89 -> Test Accuracy: 36.26\n",
      "[90, 60] loss: 1.589\n",
      "[90, 120] loss: 1.600\n",
      "[90, 180] loss: 1.604\n",
      "[90, 240] loss: 1.603\n",
      "[90, 300] loss: 1.605\n",
      "[90, 360] loss: 1.607\n",
      "Epoch: 90 -> Loss: 1.64205622673\n",
      "Epoch: 90 -> Test Accuracy: 36.15\n",
      "[91, 60] loss: 1.611\n",
      "[91, 120] loss: 1.599\n",
      "[91, 180] loss: 1.604\n",
      "[91, 240] loss: 1.608\n",
      "[91, 300] loss: 1.585\n",
      "[91, 360] loss: 1.591\n",
      "Epoch: 91 -> Loss: 1.51117026806\n",
      "Epoch: 91 -> Test Accuracy: 36.11\n",
      "[92, 60] loss: 1.602\n",
      "[92, 120] loss: 1.589\n",
      "[92, 180] loss: 1.587\n",
      "[92, 240] loss: 1.624\n",
      "[92, 300] loss: 1.607\n",
      "[92, 360] loss: 1.618\n",
      "Epoch: 92 -> Loss: 1.60254824162\n",
      "Epoch: 92 -> Test Accuracy: 36.35\n",
      "[93, 60] loss: 1.603\n",
      "[93, 120] loss: 1.612\n",
      "[93, 180] loss: 1.594\n",
      "[93, 240] loss: 1.593\n",
      "[93, 300] loss: 1.612\n",
      "[93, 360] loss: 1.609\n",
      "Epoch: 93 -> Loss: 1.69775176048\n",
      "Epoch: 93 -> Test Accuracy: 36.42\n",
      "[94, 60] loss: 1.599\n",
      "[94, 120] loss: 1.611\n",
      "[94, 180] loss: 1.614\n",
      "[94, 240] loss: 1.609\n",
      "[94, 300] loss: 1.588\n",
      "[94, 360] loss: 1.591\n",
      "Epoch: 94 -> Loss: 1.42407715321\n",
      "Epoch: 94 -> Test Accuracy: 36.39\n",
      "[95, 60] loss: 1.586\n",
      "[95, 120] loss: 1.609\n",
      "[95, 180] loss: 1.607\n",
      "[95, 240] loss: 1.604\n",
      "[95, 300] loss: 1.618\n",
      "[95, 360] loss: 1.608\n",
      "Epoch: 95 -> Loss: 1.62120783329\n",
      "Epoch: 95 -> Test Accuracy: 36.26\n",
      "[96, 60] loss: 1.582\n",
      "[96, 120] loss: 1.616\n",
      "[96, 180] loss: 1.597\n",
      "[96, 240] loss: 1.606\n",
      "[96, 300] loss: 1.604\n",
      "[96, 360] loss: 1.605\n",
      "Epoch: 96 -> Loss: 1.70124495029\n",
      "Epoch: 96 -> Test Accuracy: 36.27\n",
      "[97, 60] loss: 1.627\n",
      "[97, 120] loss: 1.607\n",
      "[97, 180] loss: 1.597\n",
      "[97, 240] loss: 1.600\n",
      "[97, 300] loss: 1.591\n",
      "[97, 360] loss: 1.603\n",
      "Epoch: 97 -> Loss: 1.54747164249\n",
      "Epoch: 97 -> Test Accuracy: 36.34\n",
      "[98, 60] loss: 1.608\n",
      "[98, 120] loss: 1.605\n",
      "[98, 180] loss: 1.596\n",
      "[98, 240] loss: 1.593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98, 300] loss: 1.609\n",
      "[98, 360] loss: 1.598\n",
      "Epoch: 98 -> Loss: 1.46377551556\n",
      "Epoch: 98 -> Test Accuracy: 36.46\n",
      "[99, 60] loss: 1.594\n",
      "[99, 120] loss: 1.588\n",
      "[99, 180] loss: 1.604\n",
      "[99, 240] loss: 1.605\n",
      "[99, 300] loss: 1.606\n",
      "[99, 360] loss: 1.622\n",
      "Epoch: 99 -> Loss: 1.57426095009\n",
      "Epoch: 99 -> Test Accuracy: 36.35\n",
      "[100, 60] loss: 1.594\n",
      "[100, 120] loss: 1.595\n",
      "[100, 180] loss: 1.586\n",
      "[100, 240] loss: 1.611\n",
      "[100, 300] loss: 1.601\n",
      "[100, 360] loss: 1.619\n",
      "Epoch: 100 -> Loss: 1.53962469101\n",
      "Epoch: 100 -> Test Accuracy: 36.62\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train NonLinearClassifiers on feature map of net_3block\n",
    "block5_loss_log, block5_valid_accuracy_log, block5_test_accuracy_log, block5_max_accuracy, block5_best_epoch = \\\n",
    "tr.train_all_blocks(5, 10, [0.1, 0.02, 0.004, 0.0008], [20, 40, 45, 100], 0.9, 5e-4, net_block5, criterion, trainloader,\n",
    "                    None, testloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.359\n",
      "[1, 120] loss: 1.048\n",
      "[1, 180] loss: 0.956\n",
      "[1, 240] loss: 0.891\n",
      "[1, 300] loss: 0.849\n",
      "[1, 360] loss: 0.825\n",
      "Epoch: 1 -> Loss: 0.698797106743\n",
      "Epoch: 1 -> Test Accuracy: 71.24\n",
      "[2, 60] loss: 0.753\n",
      "[2, 120] loss: 0.734\n",
      "[2, 180] loss: 0.742\n",
      "[2, 240] loss: 0.690\n",
      "[2, 300] loss: 0.689\n",
      "[2, 360] loss: 0.679\n",
      "Epoch: 2 -> Loss: 0.523573637009\n",
      "Epoch: 2 -> Test Accuracy: 75.06\n",
      "[3, 60] loss: 0.655\n",
      "[3, 120] loss: 0.626\n",
      "[3, 180] loss: 0.632\n",
      "[3, 240] loss: 0.625\n",
      "[3, 300] loss: 0.607\n",
      "[3, 360] loss: 0.610\n",
      "Epoch: 3 -> Loss: 0.666435062885\n",
      "Epoch: 3 -> Test Accuracy: 75.79\n",
      "[4, 60] loss: 0.590\n",
      "[4, 120] loss: 0.609\n",
      "[4, 180] loss: 0.590\n",
      "[4, 240] loss: 0.592\n",
      "[4, 300] loss: 0.578\n",
      "[4, 360] loss: 0.576\n",
      "Epoch: 4 -> Loss: 0.55528485775\n",
      "Epoch: 4 -> Test Accuracy: 76.73\n",
      "[5, 60] loss: 0.540\n",
      "[5, 120] loss: 0.554\n",
      "[5, 180] loss: 0.548\n",
      "[5, 240] loss: 0.561\n",
      "[5, 300] loss: 0.561\n",
      "[5, 360] loss: 0.559\n",
      "Epoch: 5 -> Loss: 0.584720492363\n",
      "Epoch: 5 -> Test Accuracy: 77.77\n",
      "[6, 60] loss: 0.520\n",
      "[6, 120] loss: 0.515\n",
      "[6, 180] loss: 0.532\n",
      "[6, 240] loss: 0.534\n",
      "[6, 300] loss: 0.533\n",
      "[6, 360] loss: 0.538\n",
      "Epoch: 6 -> Loss: 0.733087956905\n",
      "Epoch: 6 -> Test Accuracy: 78.0\n",
      "[7, 60] loss: 0.504\n",
      "[7, 120] loss: 0.514\n",
      "[7, 180] loss: 0.510\n",
      "[7, 240] loss: 0.502\n",
      "[7, 300] loss: 0.520\n",
      "[7, 360] loss: 0.538\n",
      "Epoch: 7 -> Loss: 0.48043975234\n",
      "Epoch: 7 -> Test Accuracy: 78.35\n",
      "[8, 60] loss: 0.516\n",
      "[8, 120] loss: 0.490\n",
      "[8, 180] loss: 0.509\n",
      "[8, 240] loss: 0.501\n",
      "[8, 300] loss: 0.487\n",
      "[8, 360] loss: 0.498\n",
      "Epoch: 8 -> Loss: 0.386042416096\n",
      "Epoch: 8 -> Test Accuracy: 78.84\n",
      "[9, 60] loss: 0.471\n",
      "[9, 120] loss: 0.500\n",
      "[9, 180] loss: 0.485\n",
      "[9, 240] loss: 0.493\n",
      "[9, 300] loss: 0.487\n",
      "[9, 360] loss: 0.492\n",
      "Epoch: 9 -> Loss: 0.618415236473\n",
      "Epoch: 9 -> Test Accuracy: 79.2\n",
      "[10, 60] loss: 0.463\n",
      "[10, 120] loss: 0.466\n",
      "[10, 180] loss: 0.480\n",
      "[10, 240] loss: 0.490\n",
      "[10, 300] loss: 0.470\n",
      "[10, 360] loss: 0.480\n",
      "Epoch: 10 -> Loss: 0.401364952326\n",
      "Epoch: 10 -> Test Accuracy: 79.23\n",
      "[11, 60] loss: 0.453\n",
      "[11, 120] loss: 0.460\n",
      "[11, 180] loss: 0.476\n",
      "[11, 240] loss: 0.484\n",
      "[11, 300] loss: 0.460\n",
      "[11, 360] loss: 0.485\n",
      "Epoch: 11 -> Loss: 0.491122543812\n",
      "Epoch: 11 -> Test Accuracy: 80.23\n",
      "[12, 60] loss: 0.451\n",
      "[12, 120] loss: 0.478\n",
      "[12, 180] loss: 0.464\n",
      "[12, 240] loss: 0.461\n",
      "[12, 300] loss: 0.474\n",
      "[12, 360] loss: 0.473\n",
      "Epoch: 12 -> Loss: 0.57316160202\n",
      "Epoch: 12 -> Test Accuracy: 79.47\n",
      "[13, 60] loss: 0.436\n",
      "[13, 120] loss: 0.458\n",
      "[13, 180] loss: 0.467\n",
      "[13, 240] loss: 0.464\n",
      "[13, 300] loss: 0.458\n",
      "[13, 360] loss: 0.485\n",
      "Epoch: 13 -> Loss: 0.589000225067\n",
      "Epoch: 13 -> Test Accuracy: 80.89\n",
      "[14, 60] loss: 0.432\n",
      "[14, 120] loss: 0.455\n",
      "[14, 180] loss: 0.437\n",
      "[14, 240] loss: 0.466\n",
      "[14, 300] loss: 0.480\n",
      "[14, 360] loss: 0.469\n",
      "Epoch: 14 -> Loss: 0.427406489849\n",
      "Epoch: 14 -> Test Accuracy: 80.81\n",
      "[15, 60] loss: 0.416\n",
      "[15, 120] loss: 0.434\n",
      "[15, 180] loss: 0.433\n",
      "[15, 240] loss: 0.454\n",
      "[15, 300] loss: 0.464\n",
      "[15, 360] loss: 0.473\n",
      "Epoch: 15 -> Loss: 0.447949558496\n",
      "Epoch: 15 -> Test Accuracy: 80.7\n",
      "[16, 60] loss: 0.431\n",
      "[16, 120] loss: 0.440\n",
      "[16, 180] loss: 0.438\n",
      "[16, 240] loss: 0.470\n",
      "[16, 300] loss: 0.468\n",
      "[16, 360] loss: 0.439\n",
      "Epoch: 16 -> Loss: 0.480602025986\n",
      "Epoch: 16 -> Test Accuracy: 80.99\n",
      "[17, 60] loss: 0.425\n",
      "[17, 120] loss: 0.418\n",
      "[17, 180] loss: 0.444\n",
      "[17, 240] loss: 0.438\n",
      "[17, 300] loss: 0.444\n",
      "[17, 360] loss: 0.443\n",
      "Epoch: 17 -> Loss: 0.424094855785\n",
      "Epoch: 17 -> Test Accuracy: 79.38\n",
      "[18, 60] loss: 0.428\n",
      "[18, 120] loss: 0.442\n",
      "[18, 180] loss: 0.448\n",
      "[18, 240] loss: 0.439\n",
      "[18, 300] loss: 0.434\n",
      "[18, 360] loss: 0.449\n",
      "Epoch: 18 -> Loss: 0.538537561893\n",
      "Epoch: 18 -> Test Accuracy: 81.33\n",
      "[19, 60] loss: 0.419\n",
      "[19, 120] loss: 0.434\n",
      "[19, 180] loss: 0.439\n",
      "[19, 240] loss: 0.434\n",
      "[19, 300] loss: 0.443\n",
      "[19, 360] loss: 0.462\n",
      "Epoch: 19 -> Loss: 0.558958888054\n",
      "Epoch: 19 -> Test Accuracy: 81.75\n",
      "[20, 60] loss: 0.392\n",
      "[20, 120] loss: 0.420\n",
      "[20, 180] loss: 0.439\n",
      "[20, 240] loss: 0.456\n",
      "[20, 300] loss: 0.451\n",
      "[20, 360] loss: 0.434\n",
      "Epoch: 20 -> Loss: 0.340055465698\n",
      "Epoch: 20 -> Test Accuracy: 80.81\n",
      "[21, 60] loss: 0.413\n",
      "[21, 120] loss: 0.436\n",
      "[21, 180] loss: 0.441\n",
      "[21, 240] loss: 0.439\n",
      "[21, 300] loss: 0.441\n",
      "[21, 360] loss: 0.444\n",
      "Epoch: 21 -> Loss: 0.452147483826\n",
      "Epoch: 21 -> Test Accuracy: 81.77\n",
      "[22, 60] loss: 0.389\n",
      "[22, 120] loss: 0.427\n",
      "[22, 180] loss: 0.426\n",
      "[22, 240] loss: 0.453\n",
      "[22, 300] loss: 0.435\n",
      "[22, 360] loss: 0.437\n",
      "Epoch: 22 -> Loss: 0.654807507992\n",
      "Epoch: 22 -> Test Accuracy: 78.9\n",
      "[23, 60] loss: 0.409\n",
      "[23, 120] loss: 0.417\n",
      "[23, 180] loss: 0.438\n",
      "[23, 240] loss: 0.429\n",
      "[23, 300] loss: 0.447\n",
      "[23, 360] loss: 0.440\n",
      "Epoch: 23 -> Loss: 0.350196093321\n",
      "Epoch: 23 -> Test Accuracy: 81.61\n",
      "[24, 60] loss: 0.414\n",
      "[24, 120] loss: 0.408\n",
      "[24, 180] loss: 0.426\n",
      "[24, 240] loss: 0.421\n",
      "[24, 300] loss: 0.419\n",
      "[24, 360] loss: 0.429\n",
      "Epoch: 24 -> Loss: 0.331459790468\n",
      "Epoch: 24 -> Test Accuracy: 80.39\n",
      "[25, 60] loss: 0.412\n",
      "[25, 120] loss: 0.419\n",
      "[25, 180] loss: 0.413\n",
      "[25, 240] loss: 0.430\n",
      "[25, 300] loss: 0.426\n",
      "[25, 360] loss: 0.435\n",
      "Epoch: 25 -> Loss: 0.423521280289\n",
      "Epoch: 25 -> Test Accuracy: 79.52\n",
      "[26, 60] loss: 0.409\n",
      "[26, 120] loss: 0.409\n",
      "[26, 180] loss: 0.425\n",
      "[26, 240] loss: 0.442\n",
      "[26, 300] loss: 0.414\n",
      "[26, 360] loss: 0.430\n",
      "Epoch: 26 -> Loss: 0.494999706745\n",
      "Epoch: 26 -> Test Accuracy: 81.08\n",
      "[27, 60] loss: 0.403\n",
      "[27, 120] loss: 0.422\n",
      "[27, 180] loss: 0.408\n",
      "[27, 240] loss: 0.426\n",
      "[27, 300] loss: 0.436\n",
      "[27, 360] loss: 0.436\n",
      "Epoch: 27 -> Loss: 0.473553568125\n",
      "Epoch: 27 -> Test Accuracy: 81.07\n",
      "[28, 60] loss: 0.403\n",
      "[28, 120] loss: 0.419\n",
      "[28, 180] loss: 0.421\n",
      "[28, 240] loss: 0.419\n",
      "[28, 300] loss: 0.445\n",
      "[28, 360] loss: 0.432\n",
      "Epoch: 28 -> Loss: 0.494851410389\n",
      "Epoch: 28 -> Test Accuracy: 81.04\n",
      "[29, 60] loss: 0.390\n",
      "[29, 120] loss: 0.403\n",
      "[29, 180] loss: 0.407\n",
      "[29, 240] loss: 0.420\n",
      "[29, 300] loss: 0.444\n",
      "[29, 360] loss: 0.440\n",
      "Epoch: 29 -> Loss: 0.382661640644\n",
      "Epoch: 29 -> Test Accuracy: 81.22\n",
      "[30, 60] loss: 0.388\n",
      "[30, 120] loss: 0.398\n",
      "[30, 180] loss: 0.432\n",
      "[30, 240] loss: 0.425\n",
      "[30, 300] loss: 0.436\n",
      "[30, 360] loss: 0.423\n",
      "Epoch: 30 -> Loss: 0.498839318752\n",
      "Epoch: 30 -> Test Accuracy: 81.48\n",
      "[31, 60] loss: 0.392\n",
      "[31, 120] loss: 0.413\n",
      "[31, 180] loss: 0.410\n",
      "[31, 240] loss: 0.414\n",
      "[31, 300] loss: 0.426\n",
      "[31, 360] loss: 0.431\n",
      "Epoch: 31 -> Loss: 0.308142006397\n",
      "Epoch: 31 -> Test Accuracy: 80.68\n",
      "[32, 60] loss: 0.393\n",
      "[32, 120] loss: 0.399\n",
      "[32, 180] loss: 0.433\n",
      "[32, 240] loss: 0.427\n",
      "[32, 300] loss: 0.426\n",
      "[32, 360] loss: 0.414\n",
      "Epoch: 32 -> Loss: 0.446713745594\n",
      "Epoch: 32 -> Test Accuracy: 81.11\n",
      "[33, 60] loss: 0.394\n",
      "[33, 120] loss: 0.409\n",
      "[33, 180] loss: 0.418\n",
      "[33, 240] loss: 0.412\n",
      "[33, 300] loss: 0.408\n",
      "[33, 360] loss: 0.431\n",
      "Epoch: 33 -> Loss: 0.508966505527\n",
      "Epoch: 33 -> Test Accuracy: 80.13\n",
      "[34, 60] loss: 0.401\n",
      "[34, 120] loss: 0.413\n",
      "[34, 180] loss: 0.423\n",
      "[34, 240] loss: 0.420\n",
      "[34, 300] loss: 0.408\n",
      "[34, 360] loss: 0.427\n",
      "Epoch: 34 -> Loss: 0.495952934027\n",
      "Epoch: 34 -> Test Accuracy: 81.07\n",
      "[35, 60] loss: 0.404\n",
      "[35, 120] loss: 0.397\n",
      "[35, 180] loss: 0.414\n",
      "[35, 240] loss: 0.422\n",
      "[35, 300] loss: 0.408\n",
      "[35, 360] loss: 0.431\n",
      "Epoch: 35 -> Loss: 0.333980500698\n",
      "Epoch: 35 -> Test Accuracy: 81.77\n",
      "[36, 60] loss: 0.337\n",
      "[36, 120] loss: 0.292\n",
      "[36, 180] loss: 0.296\n",
      "[36, 240] loss: 0.279\n",
      "[36, 300] loss: 0.277\n",
      "[36, 360] loss: 0.282\n",
      "Epoch: 36 -> Loss: 0.293914139271\n",
      "Epoch: 36 -> Test Accuracy: 85.47\n",
      "[37, 60] loss: 0.274\n",
      "[37, 120] loss: 0.247\n",
      "[37, 180] loss: 0.252\n",
      "[37, 240] loss: 0.251\n",
      "[37, 300] loss: 0.258\n",
      "[37, 360] loss: 0.262\n",
      "Epoch: 37 -> Loss: 0.251973479986\n",
      "Epoch: 37 -> Test Accuracy: 85.88\n",
      "[38, 60] loss: 0.248\n",
      "[38, 120] loss: 0.239\n",
      "[38, 180] loss: 0.246\n",
      "[38, 240] loss: 0.236\n",
      "[38, 300] loss: 0.252\n",
      "[38, 360] loss: 0.250\n",
      "Epoch: 38 -> Loss: 0.277109324932\n",
      "Epoch: 38 -> Test Accuracy: 85.76\n",
      "[39, 60] loss: 0.228\n",
      "[39, 120] loss: 0.241\n",
      "[39, 180] loss: 0.236\n",
      "[39, 240] loss: 0.232\n",
      "[39, 300] loss: 0.240\n",
      "[39, 360] loss: 0.247\n",
      "Epoch: 39 -> Loss: 0.294429123402\n",
      "Epoch: 39 -> Test Accuracy: 86.53\n",
      "[40, 60] loss: 0.219\n",
      "[40, 120] loss: 0.232\n",
      "[40, 180] loss: 0.222\n",
      "[40, 240] loss: 0.247\n",
      "[40, 300] loss: 0.240\n",
      "[40, 360] loss: 0.237\n",
      "Epoch: 40 -> Loss: 0.255616486073\n",
      "Epoch: 40 -> Test Accuracy: 85.86\n",
      "[41, 60] loss: 0.216\n",
      "[41, 120] loss: 0.232\n",
      "[41, 180] loss: 0.218\n",
      "[41, 240] loss: 0.228\n",
      "[41, 300] loss: 0.234\n",
      "[41, 360] loss: 0.239\n",
      "Epoch: 41 -> Loss: 0.253560960293\n",
      "Epoch: 41 -> Test Accuracy: 85.58\n",
      "[42, 60] loss: 0.213\n",
      "[42, 120] loss: 0.217\n",
      "[42, 180] loss: 0.223\n",
      "[42, 240] loss: 0.227\n",
      "[42, 300] loss: 0.233\n",
      "[42, 360] loss: 0.240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.293508440256\n",
      "Epoch: 42 -> Test Accuracy: 84.93\n",
      "[43, 60] loss: 0.198\n",
      "[43, 120] loss: 0.219\n",
      "[43, 180] loss: 0.223\n",
      "[43, 240] loss: 0.216\n",
      "[43, 300] loss: 0.230\n",
      "[43, 360] loss: 0.244\n",
      "Epoch: 43 -> Loss: 0.247717544436\n",
      "Epoch: 43 -> Test Accuracy: 84.85\n",
      "[44, 60] loss: 0.214\n",
      "[44, 120] loss: 0.219\n",
      "[44, 180] loss: 0.215\n",
      "[44, 240] loss: 0.229\n",
      "[44, 300] loss: 0.230\n",
      "[44, 360] loss: 0.233\n",
      "Epoch: 44 -> Loss: 0.220821380615\n",
      "Epoch: 44 -> Test Accuracy: 85.52\n",
      "[45, 60] loss: 0.203\n",
      "[45, 120] loss: 0.215\n",
      "[45, 180] loss: 0.221\n",
      "[45, 240] loss: 0.220\n",
      "[45, 300] loss: 0.234\n",
      "[45, 360] loss: 0.243\n",
      "Epoch: 45 -> Loss: 0.167318031192\n",
      "Epoch: 45 -> Test Accuracy: 84.84\n",
      "[46, 60] loss: 0.200\n",
      "[46, 120] loss: 0.216\n",
      "[46, 180] loss: 0.227\n",
      "[46, 240] loss: 0.231\n",
      "[46, 300] loss: 0.228\n",
      "[46, 360] loss: 0.239\n",
      "Epoch: 46 -> Loss: 0.233666539192\n",
      "Epoch: 46 -> Test Accuracy: 85.14\n",
      "[47, 60] loss: 0.217\n",
      "[47, 120] loss: 0.205\n",
      "[47, 180] loss: 0.221\n",
      "[47, 240] loss: 0.224\n",
      "[47, 300] loss: 0.218\n",
      "[47, 360] loss: 0.244\n",
      "Epoch: 47 -> Loss: 0.502202630043\n",
      "Epoch: 47 -> Test Accuracy: 84.7\n",
      "[48, 60] loss: 0.222\n",
      "[48, 120] loss: 0.214\n",
      "[48, 180] loss: 0.225\n",
      "[48, 240] loss: 0.229\n",
      "[48, 300] loss: 0.220\n",
      "[48, 360] loss: 0.226\n",
      "Epoch: 48 -> Loss: 0.223110958934\n",
      "Epoch: 48 -> Test Accuracy: 84.64\n",
      "[49, 60] loss: 0.214\n",
      "[49, 120] loss: 0.215\n",
      "[49, 180] loss: 0.240\n",
      "[49, 240] loss: 0.221\n",
      "[49, 300] loss: 0.237\n",
      "[49, 360] loss: 0.237\n",
      "Epoch: 49 -> Loss: 0.258769214153\n",
      "Epoch: 49 -> Test Accuracy: 84.39\n",
      "[50, 60] loss: 0.217\n",
      "[50, 120] loss: 0.201\n",
      "[50, 180] loss: 0.216\n",
      "[50, 240] loss: 0.221\n",
      "[50, 300] loss: 0.227\n",
      "[50, 360] loss: 0.237\n",
      "Epoch: 50 -> Loss: 0.201005503535\n",
      "Epoch: 50 -> Test Accuracy: 84.44\n",
      "[51, 60] loss: 0.210\n",
      "[51, 120] loss: 0.206\n",
      "[51, 180] loss: 0.225\n",
      "[51, 240] loss: 0.238\n",
      "[51, 300] loss: 0.235\n",
      "[51, 360] loss: 0.236\n",
      "Epoch: 51 -> Loss: 0.211706548929\n",
      "Epoch: 51 -> Test Accuracy: 84.17\n",
      "[52, 60] loss: 0.208\n",
      "[52, 120] loss: 0.230\n",
      "[52, 180] loss: 0.221\n",
      "[52, 240] loss: 0.221\n",
      "[52, 300] loss: 0.247\n",
      "[52, 360] loss: 0.228\n",
      "Epoch: 52 -> Loss: 0.24730078876\n",
      "Epoch: 52 -> Test Accuracy: 84.48\n",
      "[53, 60] loss: 0.201\n",
      "[53, 120] loss: 0.221\n",
      "[53, 180] loss: 0.218\n",
      "[53, 240] loss: 0.224\n",
      "[53, 300] loss: 0.239\n",
      "[53, 360] loss: 0.226\n",
      "Epoch: 53 -> Loss: 0.330116093159\n",
      "Epoch: 53 -> Test Accuracy: 84.73\n",
      "[54, 60] loss: 0.217\n",
      "[54, 120] loss: 0.216\n",
      "[54, 180] loss: 0.216\n",
      "[54, 240] loss: 0.201\n",
      "[54, 300] loss: 0.229\n",
      "[54, 360] loss: 0.234\n",
      "Epoch: 54 -> Loss: 0.17591509223\n",
      "Epoch: 54 -> Test Accuracy: 84.14\n",
      "[55, 60] loss: 0.202\n",
      "[55, 120] loss: 0.211\n",
      "[55, 180] loss: 0.230\n",
      "[55, 240] loss: 0.229\n",
      "[55, 300] loss: 0.224\n",
      "[55, 360] loss: 0.237\n",
      "Epoch: 55 -> Loss: 0.415069878101\n",
      "Epoch: 55 -> Test Accuracy: 84.75\n",
      "[56, 60] loss: 0.214\n",
      "[56, 120] loss: 0.219\n",
      "[56, 180] loss: 0.223\n",
      "[56, 240] loss: 0.231\n",
      "[56, 300] loss: 0.221\n",
      "[56, 360] loss: 0.241\n",
      "Epoch: 56 -> Loss: 0.210614487529\n",
      "Epoch: 56 -> Test Accuracy: 85.25\n",
      "[57, 60] loss: 0.206\n",
      "[57, 120] loss: 0.205\n",
      "[57, 180] loss: 0.219\n",
      "[57, 240] loss: 0.219\n",
      "[57, 300] loss: 0.228\n",
      "[57, 360] loss: 0.236\n",
      "Epoch: 57 -> Loss: 0.255785882473\n",
      "Epoch: 57 -> Test Accuracy: 84.22\n",
      "[58, 60] loss: 0.209\n",
      "[58, 120] loss: 0.209\n",
      "[58, 180] loss: 0.215\n",
      "[58, 240] loss: 0.235\n",
      "[58, 300] loss: 0.235\n",
      "[58, 360] loss: 0.230\n",
      "Epoch: 58 -> Loss: 0.219892144203\n",
      "Epoch: 58 -> Test Accuracy: 85.1\n",
      "[59, 60] loss: 0.201\n",
      "[59, 120] loss: 0.213\n",
      "[59, 180] loss: 0.215\n",
      "[59, 240] loss: 0.215\n",
      "[59, 300] loss: 0.230\n",
      "[59, 360] loss: 0.240\n",
      "Epoch: 59 -> Loss: 0.249312072992\n",
      "Epoch: 59 -> Test Accuracy: 84.6\n",
      "[60, 60] loss: 0.204\n",
      "[60, 120] loss: 0.210\n",
      "[60, 180] loss: 0.227\n",
      "[60, 240] loss: 0.216\n",
      "[60, 300] loss: 0.232\n",
      "[60, 360] loss: 0.230\n",
      "Epoch: 60 -> Loss: 0.230688303709\n",
      "Epoch: 60 -> Test Accuracy: 84.76\n",
      "[61, 60] loss: 0.213\n",
      "[61, 120] loss: 0.213\n",
      "[61, 180] loss: 0.206\n",
      "[61, 240] loss: 0.222\n",
      "[61, 300] loss: 0.223\n",
      "[61, 360] loss: 0.226\n",
      "Epoch: 61 -> Loss: 0.335576206446\n",
      "Epoch: 61 -> Test Accuracy: 84.13\n",
      "[62, 60] loss: 0.208\n",
      "[62, 120] loss: 0.205\n",
      "[62, 180] loss: 0.214\n",
      "[62, 240] loss: 0.219\n",
      "[62, 300] loss: 0.225\n",
      "[62, 360] loss: 0.211\n",
      "Epoch: 62 -> Loss: 0.244224503636\n",
      "Epoch: 62 -> Test Accuracy: 84.42\n",
      "[63, 60] loss: 0.198\n",
      "[63, 120] loss: 0.202\n",
      "[63, 180] loss: 0.215\n",
      "[63, 240] loss: 0.219\n",
      "[63, 300] loss: 0.220\n",
      "[63, 360] loss: 0.232\n",
      "Epoch: 63 -> Loss: 0.219964593649\n",
      "Epoch: 63 -> Test Accuracy: 84.83\n",
      "[64, 60] loss: 0.209\n",
      "[64, 120] loss: 0.215\n",
      "[64, 180] loss: 0.218\n",
      "[64, 240] loss: 0.230\n",
      "[64, 300] loss: 0.218\n",
      "[64, 360] loss: 0.220\n",
      "Epoch: 64 -> Loss: 0.20256690681\n",
      "Epoch: 64 -> Test Accuracy: 84.47\n",
      "[65, 60] loss: 0.196\n",
      "[65, 120] loss: 0.213\n",
      "[65, 180] loss: 0.212\n",
      "[65, 240] loss: 0.222\n",
      "[65, 300] loss: 0.213\n",
      "[65, 360] loss: 0.236\n",
      "Epoch: 65 -> Loss: 0.231282040477\n",
      "Epoch: 65 -> Test Accuracy: 84.86\n",
      "[66, 60] loss: 0.202\n",
      "[66, 120] loss: 0.211\n",
      "[66, 180] loss: 0.214\n",
      "[66, 240] loss: 0.211\n",
      "[66, 300] loss: 0.214\n",
      "[66, 360] loss: 0.226\n",
      "Epoch: 66 -> Loss: 0.213897675276\n",
      "Epoch: 66 -> Test Accuracy: 84.53\n",
      "[67, 60] loss: 0.197\n",
      "[67, 120] loss: 0.202\n",
      "[67, 180] loss: 0.211\n",
      "[67, 240] loss: 0.204\n",
      "[67, 300] loss: 0.218\n",
      "[67, 360] loss: 0.217\n",
      "Epoch: 67 -> Loss: 0.367658287287\n",
      "Epoch: 67 -> Test Accuracy: 84.76\n",
      "[68, 60] loss: 0.196\n",
      "[68, 120] loss: 0.195\n",
      "[68, 180] loss: 0.216\n",
      "[68, 240] loss: 0.213\n",
      "[68, 300] loss: 0.226\n",
      "[68, 360] loss: 0.236\n",
      "Epoch: 68 -> Loss: 0.295179605484\n",
      "Epoch: 68 -> Test Accuracy: 84.29\n",
      "[69, 60] loss: 0.208\n",
      "[69, 120] loss: 0.213\n",
      "[69, 180] loss: 0.210\n",
      "[69, 240] loss: 0.209\n",
      "[69, 300] loss: 0.228\n",
      "[69, 360] loss: 0.230\n",
      "Epoch: 69 -> Loss: 0.3180128932\n",
      "Epoch: 69 -> Test Accuracy: 84.45\n",
      "[70, 60] loss: 0.201\n",
      "[70, 120] loss: 0.197\n",
      "[70, 180] loss: 0.209\n",
      "[70, 240] loss: 0.216\n",
      "[70, 300] loss: 0.221\n",
      "[70, 360] loss: 0.216\n",
      "Epoch: 70 -> Loss: 0.296522915363\n",
      "Epoch: 70 -> Test Accuracy: 84.55\n",
      "[71, 60] loss: 0.162\n",
      "[71, 120] loss: 0.153\n",
      "[71, 180] loss: 0.152\n",
      "[71, 240] loss: 0.145\n",
      "[71, 300] loss: 0.141\n",
      "[71, 360] loss: 0.140\n",
      "Epoch: 71 -> Loss: 0.134018704295\n",
      "Epoch: 71 -> Test Accuracy: 86.84\n",
      "[72, 60] loss: 0.123\n",
      "[72, 120] loss: 0.131\n",
      "[72, 180] loss: 0.129\n",
      "[72, 240] loss: 0.127\n",
      "[72, 300] loss: 0.130\n",
      "[72, 360] loss: 0.132\n",
      "Epoch: 72 -> Loss: 0.112323902547\n",
      "Epoch: 72 -> Test Accuracy: 86.9\n",
      "[73, 60] loss: 0.120\n",
      "[73, 120] loss: 0.125\n",
      "[73, 180] loss: 0.128\n",
      "[73, 240] loss: 0.117\n",
      "[73, 300] loss: 0.125\n",
      "[73, 360] loss: 0.124\n",
      "Epoch: 73 -> Loss: 0.0758163630962\n",
      "Epoch: 73 -> Test Accuracy: 86.4\n",
      "[74, 60] loss: 0.123\n",
      "[74, 120] loss: 0.122\n",
      "[74, 180] loss: 0.117\n",
      "[74, 240] loss: 0.110\n",
      "[74, 300] loss: 0.125\n",
      "[74, 360] loss: 0.123\n",
      "Epoch: 74 -> Loss: 0.0992770791054\n",
      "Epoch: 74 -> Test Accuracy: 86.68\n",
      "[75, 60] loss: 0.113\n",
      "[75, 120] loss: 0.117\n",
      "[75, 180] loss: 0.115\n",
      "[75, 240] loss: 0.108\n",
      "[75, 300] loss: 0.121\n",
      "[75, 360] loss: 0.121\n",
      "Epoch: 75 -> Loss: 0.104397788644\n",
      "Epoch: 75 -> Test Accuracy: 86.72\n",
      "[76, 60] loss: 0.108\n",
      "[76, 120] loss: 0.106\n",
      "[76, 180] loss: 0.108\n",
      "[76, 240] loss: 0.117\n",
      "[76, 300] loss: 0.114\n",
      "[76, 360] loss: 0.110\n",
      "Epoch: 76 -> Loss: 0.125298842788\n",
      "Epoch: 76 -> Test Accuracy: 86.62\n",
      "[77, 60] loss: 0.106\n",
      "[77, 120] loss: 0.114\n",
      "[77, 180] loss: 0.107\n",
      "[77, 240] loss: 0.105\n",
      "[77, 300] loss: 0.105\n",
      "[77, 360] loss: 0.114\n",
      "Epoch: 77 -> Loss: 0.0719127133489\n",
      "Epoch: 77 -> Test Accuracy: 86.59\n",
      "[78, 60] loss: 0.103\n",
      "[78, 120] loss: 0.104\n",
      "[78, 180] loss: 0.112\n",
      "[78, 240] loss: 0.108\n",
      "[78, 300] loss: 0.109\n",
      "[78, 360] loss: 0.112\n",
      "Epoch: 78 -> Loss: 0.139738544822\n",
      "Epoch: 78 -> Test Accuracy: 86.83\n",
      "[79, 60] loss: 0.107\n",
      "[79, 120] loss: 0.098\n",
      "[79, 180] loss: 0.104\n",
      "[79, 240] loss: 0.101\n",
      "[79, 300] loss: 0.111\n",
      "[79, 360] loss: 0.108\n",
      "Epoch: 79 -> Loss: 0.180777490139\n",
      "Epoch: 79 -> Test Accuracy: 86.46\n",
      "[80, 60] loss: 0.094\n",
      "[80, 120] loss: 0.105\n",
      "[80, 180] loss: 0.103\n",
      "[80, 240] loss: 0.111\n",
      "[80, 300] loss: 0.101\n",
      "[80, 360] loss: 0.106\n",
      "Epoch: 80 -> Loss: 0.0891397446394\n",
      "Epoch: 80 -> Test Accuracy: 86.45\n",
      "[81, 60] loss: 0.103\n",
      "[81, 120] loss: 0.096\n",
      "[81, 180] loss: 0.105\n",
      "[81, 240] loss: 0.100\n",
      "[81, 300] loss: 0.103\n",
      "[81, 360] loss: 0.114\n",
      "Epoch: 81 -> Loss: 0.0596901290119\n",
      "Epoch: 81 -> Test Accuracy: 86.46\n",
      "[82, 60] loss: 0.095\n",
      "[82, 120] loss: 0.100\n",
      "[82, 180] loss: 0.096\n",
      "[82, 240] loss: 0.101\n",
      "[82, 300] loss: 0.107\n",
      "[82, 360] loss: 0.100\n",
      "Epoch: 82 -> Loss: 0.0934002250433\n",
      "Epoch: 82 -> Test Accuracy: 86.61\n",
      "[83, 60] loss: 0.096\n",
      "[83, 120] loss: 0.096\n",
      "[83, 180] loss: 0.102\n",
      "[83, 240] loss: 0.101\n",
      "[83, 300] loss: 0.103\n",
      "[83, 360] loss: 0.107\n",
      "Epoch: 83 -> Loss: 0.0633608102798\n",
      "Epoch: 83 -> Test Accuracy: 86.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.092\n",
      "[84, 120] loss: 0.094\n",
      "[84, 180] loss: 0.094\n",
      "[84, 240] loss: 0.102\n",
      "[84, 300] loss: 0.101\n",
      "[84, 360] loss: 0.102\n",
      "Epoch: 84 -> Loss: 0.0867945104837\n",
      "Epoch: 84 -> Test Accuracy: 86.39\n",
      "[85, 60] loss: 0.092\n",
      "[85, 120] loss: 0.094\n",
      "[85, 180] loss: 0.094\n",
      "[85, 240] loss: 0.098\n",
      "[85, 300] loss: 0.104\n",
      "[85, 360] loss: 0.100\n",
      "Epoch: 85 -> Loss: 0.117959477007\n",
      "Epoch: 85 -> Test Accuracy: 86.49\n",
      "[86, 60] loss: 0.090\n",
      "[86, 120] loss: 0.085\n",
      "[86, 180] loss: 0.086\n",
      "[86, 240] loss: 0.085\n",
      "[86, 300] loss: 0.087\n",
      "[86, 360] loss: 0.083\n",
      "Epoch: 86 -> Loss: 0.0792475938797\n",
      "Epoch: 86 -> Test Accuracy: 87.01\n",
      "[87, 60] loss: 0.082\n",
      "[87, 120] loss: 0.083\n",
      "[87, 180] loss: 0.085\n",
      "[87, 240] loss: 0.083\n",
      "[87, 300] loss: 0.083\n",
      "[87, 360] loss: 0.086\n",
      "Epoch: 87 -> Loss: 0.15290915966\n",
      "Epoch: 87 -> Test Accuracy: 86.88\n",
      "[88, 60] loss: 0.077\n",
      "[88, 120] loss: 0.084\n",
      "[88, 180] loss: 0.079\n",
      "[88, 240] loss: 0.084\n",
      "[88, 300] loss: 0.083\n",
      "[88, 360] loss: 0.089\n",
      "Epoch: 88 -> Loss: 0.134406417608\n",
      "Epoch: 88 -> Test Accuracy: 86.91\n",
      "[89, 60] loss: 0.076\n",
      "[89, 120] loss: 0.080\n",
      "[89, 180] loss: 0.084\n",
      "[89, 240] loss: 0.084\n",
      "[89, 300] loss: 0.081\n",
      "[89, 360] loss: 0.084\n",
      "Epoch: 89 -> Loss: 0.0592026524246\n",
      "Epoch: 89 -> Test Accuracy: 86.87\n",
      "[90, 60] loss: 0.081\n",
      "[90, 120] loss: 0.082\n",
      "[90, 180] loss: 0.082\n",
      "[90, 240] loss: 0.077\n",
      "[90, 300] loss: 0.081\n",
      "[90, 360] loss: 0.078\n",
      "Epoch: 90 -> Loss: 0.0686319023371\n",
      "Epoch: 90 -> Test Accuracy: 86.7\n",
      "[91, 60] loss: 0.083\n",
      "[91, 120] loss: 0.082\n",
      "[91, 180] loss: 0.078\n",
      "[91, 240] loss: 0.079\n",
      "[91, 300] loss: 0.084\n",
      "[91, 360] loss: 0.083\n",
      "Epoch: 91 -> Loss: 0.103925727308\n",
      "Epoch: 91 -> Test Accuracy: 86.82\n",
      "[92, 60] loss: 0.075\n",
      "[92, 120] loss: 0.081\n",
      "[92, 180] loss: 0.081\n",
      "[92, 240] loss: 0.081\n",
      "[92, 300] loss: 0.082\n",
      "[92, 360] loss: 0.080\n",
      "Epoch: 92 -> Loss: 0.104175940156\n",
      "Epoch: 92 -> Test Accuracy: 86.89\n",
      "[93, 60] loss: 0.077\n",
      "[93, 120] loss: 0.080\n",
      "[93, 180] loss: 0.079\n",
      "[93, 240] loss: 0.078\n",
      "[93, 300] loss: 0.080\n",
      "[93, 360] loss: 0.080\n",
      "Epoch: 93 -> Loss: 0.0745078623295\n",
      "Epoch: 93 -> Test Accuracy: 86.61\n",
      "[94, 60] loss: 0.075\n",
      "[94, 120] loss: 0.081\n",
      "[94, 180] loss: 0.080\n",
      "[94, 240] loss: 0.081\n",
      "[94, 300] loss: 0.079\n",
      "[94, 360] loss: 0.082\n",
      "Epoch: 94 -> Loss: 0.097018815577\n",
      "Epoch: 94 -> Test Accuracy: 86.81\n",
      "[95, 60] loss: 0.075\n",
      "[95, 120] loss: 0.077\n",
      "[95, 180] loss: 0.082\n",
      "[95, 240] loss: 0.078\n",
      "[95, 300] loss: 0.077\n",
      "[95, 360] loss: 0.083\n",
      "Epoch: 95 -> Loss: 0.145569384098\n",
      "Epoch: 95 -> Test Accuracy: 86.71\n",
      "[96, 60] loss: 0.079\n",
      "[96, 120] loss: 0.079\n",
      "[96, 180] loss: 0.078\n",
      "[96, 240] loss: 0.077\n",
      "[96, 300] loss: 0.085\n",
      "[96, 360] loss: 0.079\n",
      "Epoch: 96 -> Loss: 0.0722751244903\n",
      "Epoch: 96 -> Test Accuracy: 86.78\n",
      "[97, 60] loss: 0.075\n",
      "[97, 120] loss: 0.076\n",
      "[97, 180] loss: 0.080\n",
      "[97, 240] loss: 0.081\n",
      "[97, 300] loss: 0.080\n",
      "[97, 360] loss: 0.078\n",
      "Epoch: 97 -> Loss: 0.0967514067888\n",
      "Epoch: 97 -> Test Accuracy: 86.98\n",
      "[98, 60] loss: 0.077\n",
      "[98, 120] loss: 0.085\n",
      "[98, 180] loss: 0.075\n",
      "[98, 240] loss: 0.077\n",
      "[98, 300] loss: 0.079\n",
      "[98, 360] loss: 0.078\n",
      "Epoch: 98 -> Loss: 0.0820809081197\n",
      "Epoch: 98 -> Test Accuracy: 86.69\n",
      "[99, 60] loss: 0.073\n",
      "[99, 120] loss: 0.072\n",
      "[99, 180] loss: 0.079\n",
      "[99, 240] loss: 0.077\n",
      "[99, 300] loss: 0.078\n",
      "[99, 360] loss: 0.078\n",
      "Epoch: 99 -> Loss: 0.0729169100523\n",
      "Epoch: 99 -> Test Accuracy: 86.7\n",
      "[100, 60] loss: 0.073\n",
      "[100, 120] loss: 0.078\n",
      "[100, 180] loss: 0.077\n",
      "[100, 240] loss: 0.076\n",
      "[100, 300] loss: 0.077\n",
      "[100, 360] loss: 0.079\n",
      "Epoch: 100 -> Loss: 0.0744745582342\n",
      "Epoch: 100 -> Test Accuracy: 86.52\n",
      "Finished Training\n",
      "[1, 60] loss: 0.941\n",
      "[1, 120] loss: 0.643\n",
      "[1, 180] loss: 0.600\n",
      "[1, 240] loss: 0.536\n",
      "[1, 300] loss: 0.523\n",
      "[1, 360] loss: 0.504\n",
      "Epoch: 1 -> Loss: 0.411749303341\n",
      "Epoch: 1 -> Test Accuracy: 80.82\n",
      "[2, 60] loss: 0.456\n",
      "[2, 120] loss: 0.445\n",
      "[2, 180] loss: 0.449\n",
      "[2, 240] loss: 0.429\n",
      "[2, 300] loss: 0.442\n",
      "[2, 360] loss: 0.427\n",
      "Epoch: 2 -> Loss: 0.40788435936\n",
      "Epoch: 2 -> Test Accuracy: 82.56\n",
      "[3, 60] loss: 0.391\n",
      "[3, 120] loss: 0.384\n",
      "[3, 180] loss: 0.386\n",
      "[3, 240] loss: 0.406\n",
      "[3, 300] loss: 0.382\n",
      "[3, 360] loss: 0.380\n",
      "Epoch: 3 -> Loss: 0.252618968487\n",
      "Epoch: 3 -> Test Accuracy: 83.47\n",
      "[4, 60] loss: 0.353\n",
      "[4, 120] loss: 0.359\n",
      "[4, 180] loss: 0.364\n",
      "[4, 240] loss: 0.387\n",
      "[4, 300] loss: 0.378\n",
      "[4, 360] loss: 0.360\n",
      "Epoch: 4 -> Loss: 0.430550098419\n",
      "Epoch: 4 -> Test Accuracy: 84.38\n",
      "[5, 60] loss: 0.330\n",
      "[5, 120] loss: 0.336\n",
      "[5, 180] loss: 0.368\n",
      "[5, 240] loss: 0.360\n",
      "[5, 300] loss: 0.341\n",
      "[5, 360] loss: 0.345\n",
      "Epoch: 5 -> Loss: 0.406462281942\n",
      "Epoch: 5 -> Test Accuracy: 83.78\n",
      "[6, 60] loss: 0.305\n",
      "[6, 120] loss: 0.335\n",
      "[6, 180] loss: 0.348\n",
      "[6, 240] loss: 0.331\n",
      "[6, 300] loss: 0.336\n",
      "[6, 360] loss: 0.341\n",
      "Epoch: 6 -> Loss: 0.134215891361\n",
      "Epoch: 6 -> Test Accuracy: 84.86\n",
      "[7, 60] loss: 0.312\n",
      "[7, 120] loss: 0.328\n",
      "[7, 180] loss: 0.320\n",
      "[7, 240] loss: 0.327\n",
      "[7, 300] loss: 0.316\n",
      "[7, 360] loss: 0.335\n",
      "Epoch: 7 -> Loss: 0.399147003889\n",
      "Epoch: 7 -> Test Accuracy: 84.93\n",
      "[8, 60] loss: 0.297\n",
      "[8, 120] loss: 0.301\n",
      "[8, 180] loss: 0.329\n",
      "[8, 240] loss: 0.310\n",
      "[8, 300] loss: 0.320\n",
      "[8, 360] loss: 0.321\n",
      "Epoch: 8 -> Loss: 0.293857485056\n",
      "Epoch: 8 -> Test Accuracy: 84.62\n",
      "[9, 60] loss: 0.277\n",
      "[9, 120] loss: 0.286\n",
      "[9, 180] loss: 0.317\n",
      "[9, 240] loss: 0.309\n",
      "[9, 300] loss: 0.314\n",
      "[9, 360] loss: 0.335\n",
      "Epoch: 9 -> Loss: 0.274699389935\n",
      "Epoch: 9 -> Test Accuracy: 85.4\n",
      "[10, 60] loss: 0.270\n",
      "[10, 120] loss: 0.302\n",
      "[10, 180] loss: 0.307\n",
      "[10, 240] loss: 0.301\n",
      "[10, 300] loss: 0.312\n",
      "[10, 360] loss: 0.317\n",
      "Epoch: 10 -> Loss: 0.239750862122\n",
      "Epoch: 10 -> Test Accuracy: 85.41\n",
      "[11, 60] loss: 0.282\n",
      "[11, 120] loss: 0.281\n",
      "[11, 180] loss: 0.293\n",
      "[11, 240] loss: 0.300\n",
      "[11, 300] loss: 0.302\n",
      "[11, 360] loss: 0.306\n",
      "Epoch: 11 -> Loss: 0.288686662912\n",
      "Epoch: 11 -> Test Accuracy: 84.41\n",
      "[12, 60] loss: 0.285\n",
      "[12, 120] loss: 0.281\n",
      "[12, 180] loss: 0.284\n",
      "[12, 240] loss: 0.303\n",
      "[12, 300] loss: 0.317\n",
      "[12, 360] loss: 0.304\n",
      "Epoch: 12 -> Loss: 0.401671499014\n",
      "Epoch: 12 -> Test Accuracy: 85.2\n",
      "[13, 60] loss: 0.274\n",
      "[13, 120] loss: 0.299\n",
      "[13, 180] loss: 0.294\n",
      "[13, 240] loss: 0.296\n",
      "[13, 300] loss: 0.295\n",
      "[13, 360] loss: 0.300\n",
      "Epoch: 13 -> Loss: 0.314610183239\n",
      "Epoch: 13 -> Test Accuracy: 84.19\n",
      "[14, 60] loss: 0.267\n",
      "[14, 120] loss: 0.284\n",
      "[14, 180] loss: 0.278\n",
      "[14, 240] loss: 0.279\n",
      "[14, 300] loss: 0.302\n",
      "[14, 360] loss: 0.295\n",
      "Epoch: 14 -> Loss: 0.265098422766\n",
      "Epoch: 14 -> Test Accuracy: 85.43\n",
      "[15, 60] loss: 0.256\n",
      "[15, 120] loss: 0.278\n",
      "[15, 180] loss: 0.275\n",
      "[15, 240] loss: 0.278\n",
      "[15, 300] loss: 0.309\n",
      "[15, 360] loss: 0.298\n",
      "Epoch: 15 -> Loss: 0.242483302951\n",
      "Epoch: 15 -> Test Accuracy: 85.0\n",
      "[16, 60] loss: 0.250\n",
      "[16, 120] loss: 0.264\n",
      "[16, 180] loss: 0.274\n",
      "[16, 240] loss: 0.284\n",
      "[16, 300] loss: 0.284\n",
      "[16, 360] loss: 0.297\n",
      "Epoch: 16 -> Loss: 0.153274387121\n",
      "Epoch: 16 -> Test Accuracy: 85.11\n",
      "[17, 60] loss: 0.278\n",
      "[17, 120] loss: 0.254\n",
      "[17, 180] loss: 0.279\n",
      "[17, 240] loss: 0.275\n",
      "[17, 300] loss: 0.271\n",
      "[17, 360] loss: 0.289\n",
      "Epoch: 17 -> Loss: 0.326265364885\n",
      "Epoch: 17 -> Test Accuracy: 84.86\n",
      "[18, 60] loss: 0.263\n",
      "[18, 120] loss: 0.270\n",
      "[18, 180] loss: 0.286\n",
      "[18, 240] loss: 0.277\n",
      "[18, 300] loss: 0.279\n",
      "[18, 360] loss: 0.297\n",
      "Epoch: 18 -> Loss: 0.311122059822\n",
      "Epoch: 18 -> Test Accuracy: 85.58\n",
      "[19, 60] loss: 0.271\n",
      "[19, 120] loss: 0.258\n",
      "[19, 180] loss: 0.269\n",
      "[19, 240] loss: 0.290\n",
      "[19, 300] loss: 0.278\n",
      "[19, 360] loss: 0.283\n",
      "Epoch: 19 -> Loss: 0.272586166859\n",
      "Epoch: 19 -> Test Accuracy: 85.8\n",
      "[20, 60] loss: 0.244\n",
      "[20, 120] loss: 0.276\n",
      "[20, 180] loss: 0.287\n",
      "[20, 240] loss: 0.277\n",
      "[20, 300] loss: 0.294\n",
      "[20, 360] loss: 0.285\n",
      "Epoch: 20 -> Loss: 0.235443621874\n",
      "Epoch: 20 -> Test Accuracy: 85.7\n",
      "[21, 60] loss: 0.250\n",
      "[21, 120] loss: 0.259\n",
      "[21, 180] loss: 0.272\n",
      "[21, 240] loss: 0.278\n",
      "[21, 300] loss: 0.284\n",
      "[21, 360] loss: 0.275\n",
      "Epoch: 21 -> Loss: 0.254230856895\n",
      "Epoch: 21 -> Test Accuracy: 85.06\n",
      "[22, 60] loss: 0.257\n",
      "[22, 120] loss: 0.254\n",
      "[22, 180] loss: 0.280\n",
      "[22, 240] loss: 0.272\n",
      "[22, 300] loss: 0.287\n",
      "[22, 360] loss: 0.282\n",
      "Epoch: 22 -> Loss: 0.194549113512\n",
      "Epoch: 22 -> Test Accuracy: 84.82\n",
      "[23, 60] loss: 0.251\n",
      "[23, 120] loss: 0.261\n",
      "[23, 180] loss: 0.265\n",
      "[23, 240] loss: 0.276\n",
      "[23, 300] loss: 0.278\n",
      "[23, 360] loss: 0.286\n",
      "Epoch: 23 -> Loss: 0.284343332052\n",
      "Epoch: 23 -> Test Accuracy: 85.45\n",
      "[24, 60] loss: 0.241\n",
      "[24, 120] loss: 0.262\n",
      "[24, 180] loss: 0.249\n",
      "[24, 240] loss: 0.280\n",
      "[24, 300] loss: 0.280\n",
      "[24, 360] loss: 0.274\n",
      "Epoch: 24 -> Loss: 0.250973165035\n",
      "Epoch: 24 -> Test Accuracy: 85.4\n",
      "[25, 60] loss: 0.252\n",
      "[25, 120] loss: 0.243\n",
      "[25, 180] loss: 0.267\n",
      "[25, 240] loss: 0.272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 300] loss: 0.278\n",
      "[25, 360] loss: 0.282\n",
      "Epoch: 25 -> Loss: 0.261974692345\n",
      "Epoch: 25 -> Test Accuracy: 85.07\n",
      "[26, 60] loss: 0.236\n",
      "[26, 120] loss: 0.250\n",
      "[26, 180] loss: 0.268\n",
      "[26, 240] loss: 0.261\n",
      "[26, 300] loss: 0.278\n",
      "[26, 360] loss: 0.286\n",
      "Epoch: 26 -> Loss: 0.161418631673\n",
      "Epoch: 26 -> Test Accuracy: 85.58\n",
      "[27, 60] loss: 0.241\n",
      "[27, 120] loss: 0.252\n",
      "[27, 180] loss: 0.268\n",
      "[27, 240] loss: 0.261\n",
      "[27, 300] loss: 0.285\n",
      "[27, 360] loss: 0.273\n",
      "Epoch: 27 -> Loss: 0.258738934994\n",
      "Epoch: 27 -> Test Accuracy: 85.28\n",
      "[28, 60] loss: 0.234\n",
      "[28, 120] loss: 0.246\n",
      "[28, 180] loss: 0.274\n",
      "[28, 240] loss: 0.277\n",
      "[28, 300] loss: 0.267\n",
      "[28, 360] loss: 0.265\n",
      "Epoch: 28 -> Loss: 0.292721509933\n",
      "Epoch: 28 -> Test Accuracy: 85.9\n",
      "[29, 60] loss: 0.249\n",
      "[29, 120] loss: 0.262\n",
      "[29, 180] loss: 0.263\n",
      "[29, 240] loss: 0.270\n",
      "[29, 300] loss: 0.265\n",
      "[29, 360] loss: 0.274\n",
      "Epoch: 29 -> Loss: 0.304261267185\n",
      "Epoch: 29 -> Test Accuracy: 85.96\n",
      "[30, 60] loss: 0.230\n",
      "[30, 120] loss: 0.264\n",
      "[30, 180] loss: 0.266\n",
      "[30, 240] loss: 0.275\n",
      "[30, 300] loss: 0.255\n",
      "[30, 360] loss: 0.284\n",
      "Epoch: 30 -> Loss: 0.324707955122\n",
      "Epoch: 30 -> Test Accuracy: 86.03\n",
      "[31, 60] loss: 0.228\n",
      "[31, 120] loss: 0.249\n",
      "[31, 180] loss: 0.261\n",
      "[31, 240] loss: 0.266\n",
      "[31, 300] loss: 0.264\n",
      "[31, 360] loss: 0.286\n",
      "Epoch: 31 -> Loss: 0.270886361599\n",
      "Epoch: 31 -> Test Accuracy: 86.28\n",
      "[32, 60] loss: 0.230\n",
      "[32, 120] loss: 0.249\n",
      "[32, 180] loss: 0.265\n",
      "[32, 240] loss: 0.261\n",
      "[32, 300] loss: 0.270\n",
      "[32, 360] loss: 0.263\n",
      "Epoch: 32 -> Loss: 0.437976211309\n",
      "Epoch: 32 -> Test Accuracy: 85.36\n",
      "[33, 60] loss: 0.261\n",
      "[33, 120] loss: 0.254\n",
      "[33, 180] loss: 0.243\n",
      "[33, 240] loss: 0.269\n",
      "[33, 300] loss: 0.268\n",
      "[33, 360] loss: 0.264\n",
      "Epoch: 33 -> Loss: 0.279589027166\n",
      "Epoch: 33 -> Test Accuracy: 85.21\n",
      "[34, 60] loss: 0.235\n",
      "[34, 120] loss: 0.253\n",
      "[34, 180] loss: 0.259\n",
      "[34, 240] loss: 0.265\n",
      "[34, 300] loss: 0.274\n",
      "[34, 360] loss: 0.286\n",
      "Epoch: 34 -> Loss: 0.241185635328\n",
      "Epoch: 34 -> Test Accuracy: 85.08\n",
      "[35, 60] loss: 0.240\n",
      "[35, 120] loss: 0.245\n",
      "[35, 180] loss: 0.268\n",
      "[35, 240] loss: 0.267\n",
      "[35, 300] loss: 0.274\n",
      "[35, 360] loss: 0.279\n",
      "Epoch: 35 -> Loss: 0.214202567935\n",
      "Epoch: 35 -> Test Accuracy: 85.6\n",
      "[36, 60] loss: 0.192\n",
      "[36, 120] loss: 0.177\n",
      "[36, 180] loss: 0.162\n",
      "[36, 240] loss: 0.167\n",
      "[36, 300] loss: 0.167\n",
      "[36, 360] loss: 0.161\n",
      "Epoch: 36 -> Loss: 0.204687982798\n",
      "Epoch: 36 -> Test Accuracy: 88.25\n",
      "[37, 60] loss: 0.141\n",
      "[37, 120] loss: 0.145\n",
      "[37, 180] loss: 0.144\n",
      "[37, 240] loss: 0.131\n",
      "[37, 300] loss: 0.141\n",
      "[37, 360] loss: 0.150\n",
      "Epoch: 37 -> Loss: 0.1615203619\n",
      "Epoch: 37 -> Test Accuracy: 88.01\n",
      "[38, 60] loss: 0.130\n",
      "[38, 120] loss: 0.139\n",
      "[38, 180] loss: 0.138\n",
      "[38, 240] loss: 0.135\n",
      "[38, 300] loss: 0.121\n",
      "[38, 360] loss: 0.128\n",
      "Epoch: 38 -> Loss: 0.13487675786\n",
      "Epoch: 38 -> Test Accuracy: 87.98\n",
      "[39, 60] loss: 0.102\n",
      "[39, 120] loss: 0.115\n",
      "[39, 180] loss: 0.124\n",
      "[39, 240] loss: 0.127\n",
      "[39, 300] loss: 0.120\n",
      "[39, 360] loss: 0.128\n",
      "Epoch: 39 -> Loss: 0.198577746749\n",
      "Epoch: 39 -> Test Accuracy: 87.98\n",
      "[40, 60] loss: 0.098\n",
      "[40, 120] loss: 0.107\n",
      "[40, 180] loss: 0.113\n",
      "[40, 240] loss: 0.113\n",
      "[40, 300] loss: 0.119\n",
      "[40, 360] loss: 0.121\n",
      "Epoch: 40 -> Loss: 0.141193538904\n",
      "Epoch: 40 -> Test Accuracy: 87.95\n",
      "[41, 60] loss: 0.105\n",
      "[41, 120] loss: 0.108\n",
      "[41, 180] loss: 0.105\n",
      "[41, 240] loss: 0.119\n",
      "[41, 300] loss: 0.109\n",
      "[41, 360] loss: 0.121\n",
      "Epoch: 41 -> Loss: 0.206341713667\n",
      "Epoch: 41 -> Test Accuracy: 87.94\n",
      "[42, 60] loss: 0.101\n",
      "[42, 120] loss: 0.099\n",
      "[42, 180] loss: 0.102\n",
      "[42, 240] loss: 0.110\n",
      "[42, 300] loss: 0.116\n",
      "[42, 360] loss: 0.120\n",
      "Epoch: 42 -> Loss: 0.12574544549\n",
      "Epoch: 42 -> Test Accuracy: 87.96\n",
      "[43, 60] loss: 0.098\n",
      "[43, 120] loss: 0.097\n",
      "[43, 180] loss: 0.107\n",
      "[43, 240] loss: 0.108\n",
      "[43, 300] loss: 0.104\n",
      "[43, 360] loss: 0.114\n",
      "Epoch: 43 -> Loss: 0.102039895952\n",
      "Epoch: 43 -> Test Accuracy: 87.93\n",
      "[44, 60] loss: 0.101\n",
      "[44, 120] loss: 0.098\n",
      "[44, 180] loss: 0.098\n",
      "[44, 240] loss: 0.111\n",
      "[44, 300] loss: 0.116\n",
      "[44, 360] loss: 0.117\n",
      "Epoch: 44 -> Loss: 0.126026436687\n",
      "Epoch: 44 -> Test Accuracy: 87.57\n",
      "[45, 60] loss: 0.091\n",
      "[45, 120] loss: 0.098\n",
      "[45, 180] loss: 0.110\n",
      "[45, 240] loss: 0.112\n",
      "[45, 300] loss: 0.109\n",
      "[45, 360] loss: 0.107\n",
      "Epoch: 45 -> Loss: 0.139022737741\n",
      "Epoch: 45 -> Test Accuracy: 87.58\n",
      "[46, 60] loss: 0.088\n",
      "[46, 120] loss: 0.098\n",
      "[46, 180] loss: 0.104\n",
      "[46, 240] loss: 0.104\n",
      "[46, 300] loss: 0.109\n",
      "[46, 360] loss: 0.109\n",
      "Epoch: 46 -> Loss: 0.170051783323\n",
      "Epoch: 46 -> Test Accuracy: 87.78\n",
      "[47, 60] loss: 0.087\n",
      "[47, 120] loss: 0.102\n",
      "[47, 180] loss: 0.103\n",
      "[47, 240] loss: 0.104\n",
      "[47, 300] loss: 0.100\n",
      "[47, 360] loss: 0.106\n",
      "Epoch: 47 -> Loss: 0.0802823156118\n",
      "Epoch: 47 -> Test Accuracy: 87.15\n",
      "[48, 60] loss: 0.099\n",
      "[48, 120] loss: 0.090\n",
      "[48, 180] loss: 0.112\n",
      "[48, 240] loss: 0.108\n",
      "[48, 300] loss: 0.110\n",
      "[48, 360] loss: 0.110\n",
      "Epoch: 48 -> Loss: 0.157356515527\n",
      "Epoch: 48 -> Test Accuracy: 87.32\n",
      "[49, 60] loss: 0.095\n",
      "[49, 120] loss: 0.097\n",
      "[49, 180] loss: 0.104\n",
      "[49, 240] loss: 0.100\n",
      "[49, 300] loss: 0.104\n",
      "[49, 360] loss: 0.111\n",
      "Epoch: 49 -> Loss: 0.140545010567\n",
      "Epoch: 49 -> Test Accuracy: 87.26\n",
      "[50, 60] loss: 0.093\n",
      "[50, 120] loss: 0.096\n",
      "[50, 180] loss: 0.101\n",
      "[50, 240] loss: 0.109\n",
      "[50, 300] loss: 0.113\n",
      "[50, 360] loss: 0.111\n",
      "Epoch: 50 -> Loss: 0.177434131503\n",
      "Epoch: 50 -> Test Accuracy: 86.67\n",
      "[51, 60] loss: 0.093\n",
      "[51, 120] loss: 0.093\n",
      "[51, 180] loss: 0.102\n",
      "[51, 240] loss: 0.108\n",
      "[51, 300] loss: 0.112\n",
      "[51, 360] loss: 0.120\n",
      "Epoch: 51 -> Loss: 0.219500020146\n",
      "Epoch: 51 -> Test Accuracy: 87.13\n",
      "[52, 60] loss: 0.100\n",
      "[52, 120] loss: 0.106\n",
      "[52, 180] loss: 0.104\n",
      "[52, 240] loss: 0.108\n",
      "[52, 300] loss: 0.117\n",
      "[52, 360] loss: 0.112\n",
      "Epoch: 52 -> Loss: 0.115397915244\n",
      "Epoch: 52 -> Test Accuracy: 87.09\n",
      "[53, 60] loss: 0.095\n",
      "[53, 120] loss: 0.099\n",
      "[53, 180] loss: 0.102\n",
      "[53, 240] loss: 0.107\n",
      "[53, 300] loss: 0.113\n",
      "[53, 360] loss: 0.122\n",
      "Epoch: 53 -> Loss: 0.26332321763\n",
      "Epoch: 53 -> Test Accuracy: 86.55\n",
      "[54, 60] loss: 0.098\n",
      "[54, 120] loss: 0.108\n",
      "[54, 180] loss: 0.095\n",
      "[54, 240] loss: 0.099\n",
      "[54, 300] loss: 0.110\n",
      "[54, 360] loss: 0.111\n",
      "Epoch: 54 -> Loss: 0.0591621100903\n",
      "Epoch: 54 -> Test Accuracy: 86.91\n",
      "[55, 60] loss: 0.096\n",
      "[55, 120] loss: 0.106\n",
      "[55, 180] loss: 0.104\n",
      "[55, 240] loss: 0.103\n",
      "[55, 300] loss: 0.114\n",
      "[55, 360] loss: 0.120\n",
      "Epoch: 55 -> Loss: 0.0664670616388\n",
      "Epoch: 55 -> Test Accuracy: 87.62\n",
      "[56, 60] loss: 0.099\n",
      "[56, 120] loss: 0.106\n",
      "[56, 180] loss: 0.105\n",
      "[56, 240] loss: 0.107\n",
      "[56, 300] loss: 0.111\n",
      "[56, 360] loss: 0.110\n",
      "Epoch: 56 -> Loss: 0.142997562885\n",
      "Epoch: 56 -> Test Accuracy: 86.52\n",
      "[57, 60] loss: 0.100\n",
      "[57, 120] loss: 0.107\n",
      "[57, 180] loss: 0.109\n",
      "[57, 240] loss: 0.106\n",
      "[57, 300] loss: 0.102\n",
      "[57, 360] loss: 0.111\n",
      "Epoch: 57 -> Loss: 0.133001327515\n",
      "Epoch: 57 -> Test Accuracy: 87.23\n",
      "[58, 60] loss: 0.090\n",
      "[58, 120] loss: 0.089\n",
      "[58, 180] loss: 0.094\n",
      "[58, 240] loss: 0.112\n",
      "[58, 300] loss: 0.122\n",
      "[58, 360] loss: 0.110\n",
      "Epoch: 58 -> Loss: 0.121993757784\n",
      "Epoch: 58 -> Test Accuracy: 87.18\n",
      "[59, 60] loss: 0.094\n",
      "[59, 120] loss: 0.097\n",
      "[59, 180] loss: 0.103\n",
      "[59, 240] loss: 0.102\n",
      "[59, 300] loss: 0.110\n",
      "[59, 360] loss: 0.108\n",
      "Epoch: 59 -> Loss: 0.176214590669\n",
      "Epoch: 59 -> Test Accuracy: 87.4\n",
      "[60, 60] loss: 0.100\n",
      "[60, 120] loss: 0.104\n",
      "[60, 180] loss: 0.112\n",
      "[60, 240] loss: 0.100\n",
      "[60, 300] loss: 0.107\n",
      "[60, 360] loss: 0.107\n",
      "Epoch: 60 -> Loss: 0.0793611928821\n",
      "Epoch: 60 -> Test Accuracy: 87.36\n",
      "[61, 60] loss: 0.099\n",
      "[61, 120] loss: 0.092\n",
      "[61, 180] loss: 0.092\n",
      "[61, 240] loss: 0.106\n",
      "[61, 300] loss: 0.096\n",
      "[61, 360] loss: 0.109\n",
      "Epoch: 61 -> Loss: 0.130202144384\n",
      "Epoch: 61 -> Test Accuracy: 87.27\n",
      "[62, 60] loss: 0.094\n",
      "[62, 120] loss: 0.092\n",
      "[62, 180] loss: 0.097\n",
      "[62, 240] loss: 0.107\n",
      "[62, 300] loss: 0.100\n",
      "[62, 360] loss: 0.112\n",
      "Epoch: 62 -> Loss: 0.126755595207\n",
      "Epoch: 62 -> Test Accuracy: 87.23\n",
      "[63, 60] loss: 0.102\n",
      "[63, 120] loss: 0.091\n",
      "[63, 180] loss: 0.093\n",
      "[63, 240] loss: 0.101\n",
      "[63, 300] loss: 0.101\n",
      "[63, 360] loss: 0.110\n",
      "Epoch: 63 -> Loss: 0.13495656848\n",
      "Epoch: 63 -> Test Accuracy: 87.06\n",
      "[64, 60] loss: 0.099\n",
      "[64, 120] loss: 0.098\n",
      "[64, 180] loss: 0.095\n",
      "[64, 240] loss: 0.103\n",
      "[64, 300] loss: 0.105\n",
      "[64, 360] loss: 0.117\n",
      "Epoch: 64 -> Loss: 0.171970874071\n",
      "Epoch: 64 -> Test Accuracy: 87.7\n",
      "[65, 60] loss: 0.097\n",
      "[65, 120] loss: 0.097\n",
      "[65, 180] loss: 0.102\n",
      "[65, 240] loss: 0.102\n",
      "[65, 300] loss: 0.104\n",
      "[65, 360] loss: 0.114\n",
      "Epoch: 65 -> Loss: 0.0998637601733\n",
      "Epoch: 65 -> Test Accuracy: 87.68\n",
      "[66, 60] loss: 0.097\n",
      "[66, 120] loss: 0.090\n",
      "[66, 180] loss: 0.091\n",
      "[66, 240] loss: 0.111\n",
      "[66, 300] loss: 0.107\n",
      "[66, 360] loss: 0.104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Loss: 0.100741550326\n",
      "Epoch: 66 -> Test Accuracy: 87.39\n",
      "[67, 60] loss: 0.095\n",
      "[67, 120] loss: 0.102\n",
      "[67, 180] loss: 0.110\n",
      "[67, 240] loss: 0.102\n",
      "[67, 300] loss: 0.104\n",
      "[67, 360] loss: 0.107\n",
      "Epoch: 67 -> Loss: 0.16820526123\n",
      "Epoch: 67 -> Test Accuracy: 88.05\n",
      "[68, 60] loss: 0.088\n",
      "[68, 120] loss: 0.093\n",
      "[68, 180] loss: 0.097\n",
      "[68, 240] loss: 0.098\n",
      "[68, 300] loss: 0.108\n",
      "[68, 360] loss: 0.101\n",
      "Epoch: 68 -> Loss: 0.156906187534\n",
      "Epoch: 68 -> Test Accuracy: 87.15\n",
      "[69, 60] loss: 0.091\n",
      "[69, 120] loss: 0.093\n",
      "[69, 180] loss: 0.094\n",
      "[69, 240] loss: 0.099\n",
      "[69, 300] loss: 0.099\n",
      "[69, 360] loss: 0.105\n",
      "Epoch: 69 -> Loss: 0.179960131645\n",
      "Epoch: 69 -> Test Accuracy: 86.58\n",
      "[70, 60] loss: 0.094\n",
      "[70, 120] loss: 0.100\n",
      "[70, 180] loss: 0.098\n",
      "[70, 240] loss: 0.098\n",
      "[70, 300] loss: 0.108\n",
      "[70, 360] loss: 0.113\n",
      "Epoch: 70 -> Loss: 0.143979474902\n",
      "Epoch: 70 -> Test Accuracy: 87.44\n",
      "[71, 60] loss: 0.079\n",
      "[71, 120] loss: 0.069\n",
      "[71, 180] loss: 0.063\n",
      "[71, 240] loss: 0.063\n",
      "[71, 300] loss: 0.059\n",
      "[71, 360] loss: 0.061\n",
      "Epoch: 71 -> Loss: 0.100793719292\n",
      "Epoch: 71 -> Test Accuracy: 88.22\n",
      "[72, 60] loss: 0.052\n",
      "[72, 120] loss: 0.052\n",
      "[72, 180] loss: 0.050\n",
      "[72, 240] loss: 0.056\n",
      "[72, 300] loss: 0.050\n",
      "[72, 360] loss: 0.051\n",
      "Epoch: 72 -> Loss: 0.109249308705\n",
      "Epoch: 72 -> Test Accuracy: 88.48\n",
      "[73, 60] loss: 0.049\n",
      "[73, 120] loss: 0.049\n",
      "[73, 180] loss: 0.043\n",
      "[73, 240] loss: 0.043\n",
      "[73, 300] loss: 0.049\n",
      "[73, 360] loss: 0.046\n",
      "Epoch: 73 -> Loss: 0.0355228558183\n",
      "Epoch: 73 -> Test Accuracy: 88.42\n",
      "[74, 60] loss: 0.042\n",
      "[74, 120] loss: 0.045\n",
      "[74, 180] loss: 0.042\n",
      "[74, 240] loss: 0.046\n",
      "[74, 300] loss: 0.046\n",
      "[74, 360] loss: 0.048\n",
      "Epoch: 74 -> Loss: 0.0719350427389\n",
      "Epoch: 74 -> Test Accuracy: 88.55\n",
      "[75, 60] loss: 0.043\n",
      "[75, 120] loss: 0.039\n",
      "[75, 180] loss: 0.042\n",
      "[75, 240] loss: 0.039\n",
      "[75, 300] loss: 0.044\n",
      "[75, 360] loss: 0.043\n",
      "Epoch: 75 -> Loss: 0.0216642320156\n",
      "Epoch: 75 -> Test Accuracy: 88.69\n",
      "[76, 60] loss: 0.039\n",
      "[76, 120] loss: 0.040\n",
      "[76, 180] loss: 0.038\n",
      "[76, 240] loss: 0.040\n",
      "[76, 300] loss: 0.037\n",
      "[76, 360] loss: 0.040\n",
      "Epoch: 76 -> Loss: 0.0428475812078\n",
      "Epoch: 76 -> Test Accuracy: 88.63\n",
      "[77, 60] loss: 0.038\n",
      "[77, 120] loss: 0.037\n",
      "[77, 180] loss: 0.036\n",
      "[77, 240] loss: 0.037\n",
      "[77, 300] loss: 0.038\n",
      "[77, 360] loss: 0.041\n",
      "Epoch: 77 -> Loss: 0.0563524290919\n",
      "Epoch: 77 -> Test Accuracy: 88.53\n",
      "[78, 60] loss: 0.039\n",
      "[78, 120] loss: 0.032\n",
      "[78, 180] loss: 0.036\n",
      "[78, 240] loss: 0.036\n",
      "[78, 300] loss: 0.036\n",
      "[78, 360] loss: 0.037\n",
      "Epoch: 78 -> Loss: 0.0421336069703\n",
      "Epoch: 78 -> Test Accuracy: 88.27\n",
      "[79, 60] loss: 0.036\n",
      "[79, 120] loss: 0.031\n",
      "[79, 180] loss: 0.032\n",
      "[79, 240] loss: 0.038\n",
      "[79, 300] loss: 0.033\n",
      "[79, 360] loss: 0.035\n",
      "Epoch: 79 -> Loss: 0.0749538242817\n",
      "Epoch: 79 -> Test Accuracy: 88.65\n",
      "[80, 60] loss: 0.033\n",
      "[80, 120] loss: 0.031\n",
      "[80, 180] loss: 0.034\n",
      "[80, 240] loss: 0.035\n",
      "[80, 300] loss: 0.031\n",
      "[80, 360] loss: 0.035\n",
      "Epoch: 80 -> Loss: 0.0384834185243\n",
      "Epoch: 80 -> Test Accuracy: 88.47\n",
      "[81, 60] loss: 0.032\n",
      "[81, 120] loss: 0.034\n",
      "[81, 180] loss: 0.032\n",
      "[81, 240] loss: 0.031\n",
      "[81, 300] loss: 0.032\n",
      "[81, 360] loss: 0.034\n",
      "Epoch: 81 -> Loss: 0.0344153270125\n",
      "Epoch: 81 -> Test Accuracy: 88.63\n",
      "[82, 60] loss: 0.032\n",
      "[82, 120] loss: 0.032\n",
      "[82, 180] loss: 0.031\n",
      "[82, 240] loss: 0.029\n",
      "[82, 300] loss: 0.031\n",
      "[82, 360] loss: 0.032\n",
      "Epoch: 82 -> Loss: 0.0333477072418\n",
      "Epoch: 82 -> Test Accuracy: 88.73\n",
      "[83, 60] loss: 0.031\n",
      "[83, 120] loss: 0.030\n",
      "[83, 180] loss: 0.029\n",
      "[83, 240] loss: 0.030\n",
      "[83, 300] loss: 0.034\n",
      "[83, 360] loss: 0.033\n",
      "Epoch: 83 -> Loss: 0.0415653772652\n",
      "Epoch: 83 -> Test Accuracy: 88.65\n",
      "[84, 60] loss: 0.029\n",
      "[84, 120] loss: 0.030\n",
      "[84, 180] loss: 0.027\n",
      "[84, 240] loss: 0.029\n",
      "[84, 300] loss: 0.032\n",
      "[84, 360] loss: 0.034\n",
      "Epoch: 84 -> Loss: 0.0167433768511\n",
      "Epoch: 84 -> Test Accuracy: 88.8\n",
      "[85, 60] loss: 0.027\n",
      "[85, 120] loss: 0.029\n",
      "[85, 180] loss: 0.032\n",
      "[85, 240] loss: 0.031\n",
      "[85, 300] loss: 0.028\n",
      "[85, 360] loss: 0.033\n",
      "Epoch: 85 -> Loss: 0.0238991435617\n",
      "Epoch: 85 -> Test Accuracy: 88.63\n",
      "[86, 60] loss: 0.028\n",
      "[86, 120] loss: 0.024\n",
      "[86, 180] loss: 0.029\n",
      "[86, 240] loss: 0.028\n",
      "[86, 300] loss: 0.024\n",
      "[86, 360] loss: 0.030\n",
      "Epoch: 86 -> Loss: 0.0182694084942\n",
      "Epoch: 86 -> Test Accuracy: 88.65\n",
      "[87, 60] loss: 0.024\n",
      "[87, 120] loss: 0.026\n",
      "[87, 180] loss: 0.026\n",
      "[87, 240] loss: 0.024\n",
      "[87, 300] loss: 0.029\n",
      "[87, 360] loss: 0.025\n",
      "Epoch: 87 -> Loss: 0.0301135070622\n",
      "Epoch: 87 -> Test Accuracy: 88.92\n",
      "[88, 60] loss: 0.026\n",
      "[88, 120] loss: 0.025\n",
      "[88, 180] loss: 0.028\n",
      "[88, 240] loss: 0.026\n",
      "[88, 300] loss: 0.028\n",
      "[88, 360] loss: 0.027\n",
      "Epoch: 88 -> Loss: 0.038382165134\n",
      "Epoch: 88 -> Test Accuracy: 88.76\n",
      "[89, 60] loss: 0.024\n",
      "[89, 120] loss: 0.029\n",
      "[89, 180] loss: 0.025\n",
      "[89, 240] loss: 0.027\n",
      "[89, 300] loss: 0.025\n",
      "[89, 360] loss: 0.024\n",
      "Epoch: 89 -> Loss: 0.0435271784663\n",
      "Epoch: 89 -> Test Accuracy: 88.7\n",
      "[90, 60] loss: 0.028\n",
      "[90, 120] loss: 0.025\n",
      "[90, 180] loss: 0.027\n",
      "[90, 240] loss: 0.026\n",
      "[90, 300] loss: 0.023\n",
      "[90, 360] loss: 0.027\n",
      "Epoch: 90 -> Loss: 0.0247162170708\n",
      "Epoch: 90 -> Test Accuracy: 88.75\n",
      "[91, 60] loss: 0.024\n",
      "[91, 120] loss: 0.026\n",
      "[91, 180] loss: 0.025\n",
      "[91, 240] loss: 0.025\n",
      "[91, 300] loss: 0.024\n",
      "[91, 360] loss: 0.025\n",
      "Epoch: 91 -> Loss: 0.0171284079552\n",
      "Epoch: 91 -> Test Accuracy: 88.63\n",
      "[92, 60] loss: 0.024\n",
      "[92, 120] loss: 0.024\n",
      "[92, 180] loss: 0.025\n",
      "[92, 240] loss: 0.026\n",
      "[92, 300] loss: 0.026\n",
      "[92, 360] loss: 0.026\n",
      "Epoch: 92 -> Loss: 0.0156457424164\n",
      "Epoch: 92 -> Test Accuracy: 88.78\n",
      "[93, 60] loss: 0.025\n",
      "[93, 120] loss: 0.025\n",
      "[93, 180] loss: 0.024\n",
      "[93, 240] loss: 0.026\n",
      "[93, 300] loss: 0.025\n",
      "[93, 360] loss: 0.026\n",
      "Epoch: 93 -> Loss: 0.0210891421884\n",
      "Epoch: 93 -> Test Accuracy: 88.75\n",
      "[94, 60] loss: 0.026\n",
      "[94, 120] loss: 0.024\n",
      "[94, 180] loss: 0.024\n",
      "[94, 240] loss: 0.024\n",
      "[94, 300] loss: 0.025\n",
      "[94, 360] loss: 0.023\n",
      "Epoch: 94 -> Loss: 0.0299513526261\n",
      "Epoch: 94 -> Test Accuracy: 88.75\n",
      "[95, 60] loss: 0.024\n",
      "[95, 120] loss: 0.024\n",
      "[95, 180] loss: 0.026\n",
      "[95, 240] loss: 0.025\n",
      "[95, 300] loss: 0.026\n",
      "[95, 360] loss: 0.022\n",
      "Epoch: 95 -> Loss: 0.0225901659578\n",
      "Epoch: 95 -> Test Accuracy: 88.7\n",
      "[96, 60] loss: 0.024\n",
      "[96, 120] loss: 0.023\n",
      "[96, 180] loss: 0.022\n",
      "[96, 240] loss: 0.025\n",
      "[96, 300] loss: 0.024\n",
      "[96, 360] loss: 0.024\n",
      "Epoch: 96 -> Loss: 0.028734376654\n",
      "Epoch: 96 -> Test Accuracy: 88.71\n",
      "[97, 60] loss: 0.023\n",
      "[97, 120] loss: 0.024\n",
      "[97, 180] loss: 0.023\n",
      "[97, 240] loss: 0.024\n",
      "[97, 300] loss: 0.023\n",
      "[97, 360] loss: 0.024\n",
      "Epoch: 97 -> Loss: 0.0340820476413\n",
      "Epoch: 97 -> Test Accuracy: 88.71\n",
      "[98, 60] loss: 0.025\n",
      "[98, 120] loss: 0.025\n",
      "[98, 180] loss: 0.025\n",
      "[98, 240] loss: 0.024\n",
      "[98, 300] loss: 0.023\n",
      "[98, 360] loss: 0.024\n",
      "Epoch: 98 -> Loss: 0.0562968365848\n",
      "Epoch: 98 -> Test Accuracy: 88.8\n",
      "[99, 60] loss: 0.024\n",
      "[99, 120] loss: 0.023\n",
      "[99, 180] loss: 0.024\n",
      "[99, 240] loss: 0.025\n",
      "[99, 300] loss: 0.026\n",
      "[99, 360] loss: 0.024\n",
      "Epoch: 99 -> Loss: 0.0362644158304\n",
      "Epoch: 99 -> Test Accuracy: 88.78\n",
      "[100, 60] loss: 0.025\n",
      "[100, 120] loss: 0.026\n",
      "[100, 180] loss: 0.024\n",
      "[100, 240] loss: 0.023\n",
      "[100, 300] loss: 0.022\n",
      "[100, 360] loss: 0.024\n",
      "Epoch: 100 -> Loss: 0.020210120827\n",
      "Epoch: 100 -> Test Accuracy: 88.86\n",
      "Finished Training\n",
      "[1, 60] loss: 0.957\n",
      "[1, 120] loss: 0.680\n",
      "[1, 180] loss: 0.618\n",
      "[1, 240] loss: 0.611\n",
      "[1, 300] loss: 0.590\n",
      "[1, 360] loss: 0.574\n",
      "Epoch: 1 -> Loss: 0.650100827217\n",
      "Epoch: 1 -> Test Accuracy: 77.96\n",
      "[2, 60] loss: 0.534\n",
      "[2, 120] loss: 0.549\n",
      "[2, 180] loss: 0.538\n",
      "[2, 240] loss: 0.515\n",
      "[2, 300] loss: 0.514\n",
      "[2, 360] loss: 0.513\n",
      "Epoch: 2 -> Loss: 0.554166615009\n",
      "Epoch: 2 -> Test Accuracy: 78.42\n",
      "[3, 60] loss: 0.487\n",
      "[3, 120] loss: 0.503\n",
      "[3, 180] loss: 0.498\n",
      "[3, 240] loss: 0.490\n",
      "[3, 300] loss: 0.503\n",
      "[3, 360] loss: 0.472\n",
      "Epoch: 3 -> Loss: 0.477858006954\n",
      "Epoch: 3 -> Test Accuracy: 78.43\n",
      "[4, 60] loss: 0.479\n",
      "[4, 120] loss: 0.475\n",
      "[4, 180] loss: 0.476\n",
      "[4, 240] loss: 0.474\n",
      "[4, 300] loss: 0.474\n",
      "[4, 360] loss: 0.465\n",
      "Epoch: 4 -> Loss: 0.367161691189\n",
      "Epoch: 4 -> Test Accuracy: 79.82\n",
      "[5, 60] loss: 0.460\n",
      "[5, 120] loss: 0.450\n",
      "[5, 180] loss: 0.476\n",
      "[5, 240] loss: 0.462\n",
      "[5, 300] loss: 0.458\n",
      "[5, 360] loss: 0.464\n",
      "Epoch: 5 -> Loss: 0.481704413891\n",
      "Epoch: 5 -> Test Accuracy: 80.36\n",
      "[6, 60] loss: 0.432\n",
      "[6, 120] loss: 0.427\n",
      "[6, 180] loss: 0.444\n",
      "[6, 240] loss: 0.458\n",
      "[6, 300] loss: 0.449\n",
      "[6, 360] loss: 0.466\n",
      "Epoch: 6 -> Loss: 0.519784629345\n",
      "Epoch: 6 -> Test Accuracy: 80.16\n",
      "[7, 60] loss: 0.419\n",
      "[7, 120] loss: 0.414\n",
      "[7, 180] loss: 0.446\n",
      "[7, 240] loss: 0.448\n",
      "[7, 300] loss: 0.454\n",
      "[7, 360] loss: 0.437\n",
      "Epoch: 7 -> Loss: 0.711985230446\n",
      "Epoch: 7 -> Test Accuracy: 80.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 60] loss: 0.416\n",
      "[8, 120] loss: 0.433\n",
      "[8, 180] loss: 0.437\n",
      "[8, 240] loss: 0.443\n",
      "[8, 300] loss: 0.437\n",
      "[8, 360] loss: 0.450\n",
      "Epoch: 8 -> Loss: 0.285523176193\n",
      "Epoch: 8 -> Test Accuracy: 80.85\n",
      "[9, 60] loss: 0.416\n",
      "[9, 120] loss: 0.410\n",
      "[9, 180] loss: 0.438\n",
      "[9, 240] loss: 0.454\n",
      "[9, 300] loss: 0.436\n",
      "[9, 360] loss: 0.440\n",
      "Epoch: 9 -> Loss: 0.382233202457\n",
      "Epoch: 9 -> Test Accuracy: 80.56\n",
      "[10, 60] loss: 0.405\n",
      "[10, 120] loss: 0.416\n",
      "[10, 180] loss: 0.423\n",
      "[10, 240] loss: 0.438\n",
      "[10, 300] loss: 0.439\n",
      "[10, 360] loss: 0.426\n",
      "Epoch: 10 -> Loss: 0.463271319866\n",
      "Epoch: 10 -> Test Accuracy: 79.85\n",
      "[11, 60] loss: 0.403\n",
      "[11, 120] loss: 0.418\n",
      "[11, 180] loss: 0.409\n",
      "[11, 240] loss: 0.423\n",
      "[11, 300] loss: 0.435\n",
      "[11, 360] loss: 0.438\n",
      "Epoch: 11 -> Loss: 0.295358091593\n",
      "Epoch: 11 -> Test Accuracy: 80.56\n",
      "[12, 60] loss: 0.407\n",
      "[12, 120] loss: 0.412\n",
      "[12, 180] loss: 0.409\n",
      "[12, 240] loss: 0.426\n",
      "[12, 300] loss: 0.421\n",
      "[12, 360] loss: 0.440\n",
      "Epoch: 12 -> Loss: 0.383598327637\n",
      "Epoch: 12 -> Test Accuracy: 80.6\n",
      "[13, 60] loss: 0.418\n",
      "[13, 120] loss: 0.417\n",
      "[13, 180] loss: 0.405\n",
      "[13, 240] loss: 0.423\n",
      "[13, 300] loss: 0.407\n",
      "[13, 360] loss: 0.426\n",
      "Epoch: 13 -> Loss: 0.614787220955\n",
      "Epoch: 13 -> Test Accuracy: 80.81\n",
      "[14, 60] loss: 0.400\n",
      "[14, 120] loss: 0.405\n",
      "[14, 180] loss: 0.413\n",
      "[14, 240] loss: 0.411\n",
      "[14, 300] loss: 0.437\n",
      "[14, 360] loss: 0.413\n",
      "Epoch: 14 -> Loss: 0.261682808399\n",
      "Epoch: 14 -> Test Accuracy: 80.78\n",
      "[15, 60] loss: 0.413\n",
      "[15, 120] loss: 0.400\n",
      "[15, 180] loss: 0.395\n",
      "[15, 240] loss: 0.431\n",
      "[15, 300] loss: 0.398\n",
      "[15, 360] loss: 0.427\n",
      "Epoch: 15 -> Loss: 0.427803099155\n",
      "Epoch: 15 -> Test Accuracy: 80.52\n",
      "[16, 60] loss: 0.381\n",
      "[16, 120] loss: 0.421\n",
      "[16, 180] loss: 0.403\n",
      "[16, 240] loss: 0.428\n",
      "[16, 300] loss: 0.413\n",
      "[16, 360] loss: 0.433\n",
      "Epoch: 16 -> Loss: 0.402526080608\n",
      "Epoch: 16 -> Test Accuracy: 80.71\n",
      "[17, 60] loss: 0.387\n",
      "[17, 120] loss: 0.419\n",
      "[17, 180] loss: 0.401\n",
      "[17, 240] loss: 0.412\n",
      "[17, 300] loss: 0.418\n",
      "[17, 360] loss: 0.422\n",
      "Epoch: 17 -> Loss: 0.438110440969\n",
      "Epoch: 17 -> Test Accuracy: 81.61\n",
      "[18, 60] loss: 0.392\n",
      "[18, 120] loss: 0.397\n",
      "[18, 180] loss: 0.416\n",
      "[18, 240] loss: 0.416\n",
      "[18, 300] loss: 0.409\n",
      "[18, 360] loss: 0.396\n",
      "Epoch: 18 -> Loss: 0.40813985467\n",
      "Epoch: 18 -> Test Accuracy: 80.81\n",
      "[19, 60] loss: 0.386\n",
      "[19, 120] loss: 0.390\n",
      "[19, 180] loss: 0.398\n",
      "[19, 240] loss: 0.409\n",
      "[19, 300] loss: 0.419\n",
      "[19, 360] loss: 0.421\n",
      "Epoch: 19 -> Loss: 0.562666773796\n",
      "Epoch: 19 -> Test Accuracy: 82.37\n",
      "[20, 60] loss: 0.389\n",
      "[20, 120] loss: 0.407\n",
      "[20, 180] loss: 0.404\n",
      "[20, 240] loss: 0.394\n",
      "[20, 300] loss: 0.399\n",
      "[20, 360] loss: 0.407\n",
      "Epoch: 20 -> Loss: 0.354996144772\n",
      "Epoch: 20 -> Test Accuracy: 80.93\n",
      "[21, 60] loss: 0.395\n",
      "[21, 120] loss: 0.403\n",
      "[21, 180] loss: 0.399\n",
      "[21, 240] loss: 0.394\n",
      "[21, 300] loss: 0.413\n",
      "[21, 360] loss: 0.422\n",
      "Epoch: 21 -> Loss: 0.3987621665\n",
      "Epoch: 21 -> Test Accuracy: 81.37\n",
      "[22, 60] loss: 0.392\n",
      "[22, 120] loss: 0.399\n",
      "[22, 180] loss: 0.400\n",
      "[22, 240] loss: 0.397\n",
      "[22, 300] loss: 0.420\n",
      "[22, 360] loss: 0.405\n",
      "Epoch: 22 -> Loss: 0.412439644337\n",
      "Epoch: 22 -> Test Accuracy: 81.74\n",
      "[23, 60] loss: 0.389\n",
      "[23, 120] loss: 0.400\n",
      "[23, 180] loss: 0.400\n",
      "[23, 240] loss: 0.391\n",
      "[23, 300] loss: 0.410\n",
      "[23, 360] loss: 0.403\n",
      "Epoch: 23 -> Loss: 0.353263437748\n",
      "Epoch: 23 -> Test Accuracy: 81.62\n",
      "[24, 60] loss: 0.396\n",
      "[24, 120] loss: 0.399\n",
      "[24, 180] loss: 0.381\n",
      "[24, 240] loss: 0.401\n",
      "[24, 300] loss: 0.404\n",
      "[24, 360] loss: 0.422\n",
      "Epoch: 24 -> Loss: 0.49288597703\n",
      "Epoch: 24 -> Test Accuracy: 81.88\n",
      "[25, 60] loss: 0.362\n",
      "[25, 120] loss: 0.410\n",
      "[25, 180] loss: 0.404\n",
      "[25, 240] loss: 0.404\n",
      "[25, 300] loss: 0.405\n",
      "[25, 360] loss: 0.409\n",
      "Epoch: 25 -> Loss: 0.318581491709\n",
      "Epoch: 25 -> Test Accuracy: 79.98\n",
      "[26, 60] loss: 0.386\n",
      "[26, 120] loss: 0.371\n",
      "[26, 180] loss: 0.385\n",
      "[26, 240] loss: 0.391\n",
      "[26, 300] loss: 0.398\n",
      "[26, 360] loss: 0.413\n",
      "Epoch: 26 -> Loss: 0.387553662062\n",
      "Epoch: 26 -> Test Accuracy: 81.61\n",
      "[27, 60] loss: 0.385\n",
      "[27, 120] loss: 0.393\n",
      "[27, 180] loss: 0.391\n",
      "[27, 240] loss: 0.403\n",
      "[27, 300] loss: 0.398\n",
      "[27, 360] loss: 0.400\n",
      "Epoch: 27 -> Loss: 0.386849492788\n",
      "Epoch: 27 -> Test Accuracy: 80.71\n",
      "[28, 60] loss: 0.393\n",
      "[28, 120] loss: 0.397\n",
      "[28, 180] loss: 0.399\n",
      "[28, 240] loss: 0.393\n",
      "[28, 300] loss: 0.418\n",
      "[28, 360] loss: 0.397\n",
      "Epoch: 28 -> Loss: 0.4328815341\n",
      "Epoch: 28 -> Test Accuracy: 82.31\n",
      "[29, 60] loss: 0.377\n",
      "[29, 120] loss: 0.392\n",
      "[29, 180] loss: 0.378\n",
      "[29, 240] loss: 0.399\n",
      "[29, 300] loss: 0.408\n",
      "[29, 360] loss: 0.409\n",
      "Epoch: 29 -> Loss: 0.526964187622\n",
      "Epoch: 29 -> Test Accuracy: 81.34\n",
      "[30, 60] loss: 0.382\n",
      "[30, 120] loss: 0.388\n",
      "[30, 180] loss: 0.390\n",
      "[30, 240] loss: 0.389\n",
      "[30, 300] loss: 0.412\n",
      "[30, 360] loss: 0.402\n",
      "Epoch: 30 -> Loss: 0.330455482006\n",
      "Epoch: 30 -> Test Accuracy: 81.39\n",
      "[31, 60] loss: 0.376\n",
      "[31, 120] loss: 0.376\n",
      "[31, 180] loss: 0.376\n",
      "[31, 240] loss: 0.399\n",
      "[31, 300] loss: 0.405\n",
      "[31, 360] loss: 0.413\n",
      "Epoch: 31 -> Loss: 0.514693856239\n",
      "Epoch: 31 -> Test Accuracy: 80.88\n",
      "[32, 60] loss: 0.385\n",
      "[32, 120] loss: 0.379\n",
      "[32, 180] loss: 0.396\n",
      "[32, 240] loss: 0.406\n",
      "[32, 300] loss: 0.391\n",
      "[32, 360] loss: 0.395\n",
      "Epoch: 32 -> Loss: 0.369208753109\n",
      "Epoch: 32 -> Test Accuracy: 81.54\n",
      "[33, 60] loss: 0.376\n",
      "[33, 120] loss: 0.384\n",
      "[33, 180] loss: 0.388\n",
      "[33, 240] loss: 0.394\n",
      "[33, 300] loss: 0.394\n",
      "[33, 360] loss: 0.396\n",
      "Epoch: 33 -> Loss: 0.290953606367\n",
      "Epoch: 33 -> Test Accuracy: 82.16\n",
      "[34, 60] loss: 0.381\n",
      "[34, 120] loss: 0.384\n",
      "[34, 180] loss: 0.381\n",
      "[34, 240] loss: 0.397\n",
      "[34, 300] loss: 0.415\n",
      "[34, 360] loss: 0.404\n",
      "Epoch: 34 -> Loss: 0.331588089466\n",
      "Epoch: 34 -> Test Accuracy: 81.1\n",
      "[35, 60] loss: 0.372\n",
      "[35, 120] loss: 0.380\n",
      "[35, 180] loss: 0.413\n",
      "[35, 240] loss: 0.383\n",
      "[35, 300] loss: 0.403\n",
      "[35, 360] loss: 0.401\n",
      "Epoch: 35 -> Loss: 0.268140435219\n",
      "Epoch: 35 -> Test Accuracy: 80.67\n",
      "[36, 60] loss: 0.344\n",
      "[36, 120] loss: 0.327\n",
      "[36, 180] loss: 0.314\n",
      "[36, 240] loss: 0.303\n",
      "[36, 300] loss: 0.294\n",
      "[36, 360] loss: 0.313\n",
      "Epoch: 36 -> Loss: 0.292270362377\n",
      "Epoch: 36 -> Test Accuracy: 83.99\n",
      "[37, 60] loss: 0.283\n",
      "[37, 120] loss: 0.285\n",
      "[37, 180] loss: 0.290\n",
      "[37, 240] loss: 0.298\n",
      "[37, 300] loss: 0.291\n",
      "[37, 360] loss: 0.299\n",
      "Epoch: 37 -> Loss: 0.370492488146\n",
      "Epoch: 37 -> Test Accuracy: 84.06\n",
      "[38, 60] loss: 0.264\n",
      "[38, 120] loss: 0.278\n",
      "[38, 180] loss: 0.277\n",
      "[38, 240] loss: 0.277\n",
      "[38, 300] loss: 0.295\n",
      "[38, 360] loss: 0.288\n",
      "Epoch: 38 -> Loss: 0.285365045071\n",
      "Epoch: 38 -> Test Accuracy: 84.22\n",
      "[39, 60] loss: 0.276\n",
      "[39, 120] loss: 0.280\n",
      "[39, 180] loss: 0.271\n",
      "[39, 240] loss: 0.270\n",
      "[39, 300] loss: 0.277\n",
      "[39, 360] loss: 0.284\n",
      "Epoch: 39 -> Loss: 0.304337084293\n",
      "Epoch: 39 -> Test Accuracy: 84.44\n",
      "[40, 60] loss: 0.263\n",
      "[40, 120] loss: 0.276\n",
      "[40, 180] loss: 0.260\n",
      "[40, 240] loss: 0.266\n",
      "[40, 300] loss: 0.267\n",
      "[40, 360] loss: 0.286\n",
      "Epoch: 40 -> Loss: 0.279685884714\n",
      "Epoch: 40 -> Test Accuracy: 84.26\n",
      "[41, 60] loss: 0.265\n",
      "[41, 120] loss: 0.273\n",
      "[41, 180] loss: 0.269\n",
      "[41, 240] loss: 0.261\n",
      "[41, 300] loss: 0.292\n",
      "[41, 360] loss: 0.261\n",
      "Epoch: 41 -> Loss: 0.368755578995\n",
      "Epoch: 41 -> Test Accuracy: 84.58\n",
      "[42, 60] loss: 0.259\n",
      "[42, 120] loss: 0.246\n",
      "[42, 180] loss: 0.268\n",
      "[42, 240] loss: 0.260\n",
      "[42, 300] loss: 0.264\n",
      "[42, 360] loss: 0.265\n",
      "Epoch: 42 -> Loss: 0.2299361974\n",
      "Epoch: 42 -> Test Accuracy: 84.12\n",
      "[43, 60] loss: 0.264\n",
      "[43, 120] loss: 0.255\n",
      "[43, 180] loss: 0.259\n",
      "[43, 240] loss: 0.266\n",
      "[43, 300] loss: 0.265\n",
      "[43, 360] loss: 0.270\n",
      "Epoch: 43 -> Loss: 0.255645334721\n",
      "Epoch: 43 -> Test Accuracy: 84.49\n",
      "[44, 60] loss: 0.254\n",
      "[44, 120] loss: 0.245\n",
      "[44, 180] loss: 0.257\n",
      "[44, 240] loss: 0.269\n",
      "[44, 300] loss: 0.267\n",
      "[44, 360] loss: 0.262\n",
      "Epoch: 44 -> Loss: 0.280582517385\n",
      "Epoch: 44 -> Test Accuracy: 83.87\n",
      "[45, 60] loss: 0.253\n",
      "[45, 120] loss: 0.250\n",
      "[45, 180] loss: 0.248\n",
      "[45, 240] loss: 0.264\n",
      "[45, 300] loss: 0.277\n",
      "[45, 360] loss: 0.253\n",
      "Epoch: 45 -> Loss: 0.309578031301\n",
      "Epoch: 45 -> Test Accuracy: 83.91\n",
      "[46, 60] loss: 0.245\n",
      "[46, 120] loss: 0.250\n",
      "[46, 180] loss: 0.268\n",
      "[46, 240] loss: 0.268\n",
      "[46, 300] loss: 0.264\n",
      "[46, 360] loss: 0.264\n",
      "Epoch: 46 -> Loss: 0.428700506687\n",
      "Epoch: 46 -> Test Accuracy: 83.35\n",
      "[47, 60] loss: 0.240\n",
      "[47, 120] loss: 0.256\n",
      "[47, 180] loss: 0.249\n",
      "[47, 240] loss: 0.263\n",
      "[47, 300] loss: 0.263\n",
      "[47, 360] loss: 0.261\n",
      "Epoch: 47 -> Loss: 0.382960319519\n",
      "Epoch: 47 -> Test Accuracy: 83.48\n",
      "[48, 60] loss: 0.254\n",
      "[48, 120] loss: 0.252\n",
      "[48, 180] loss: 0.255\n",
      "[48, 240] loss: 0.265\n",
      "[48, 300] loss: 0.265\n",
      "[48, 360] loss: 0.268\n",
      "Epoch: 48 -> Loss: 0.210324972868\n",
      "Epoch: 48 -> Test Accuracy: 83.16\n",
      "[49, 60] loss: 0.229\n",
      "[49, 120] loss: 0.253\n",
      "[49, 180] loss: 0.255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 240] loss: 0.267\n",
      "[49, 300] loss: 0.274\n",
      "[49, 360] loss: 0.268\n",
      "Epoch: 49 -> Loss: 0.38631978631\n",
      "Epoch: 49 -> Test Accuracy: 83.49\n",
      "[50, 60] loss: 0.244\n",
      "[50, 120] loss: 0.244\n",
      "[50, 180] loss: 0.246\n",
      "[50, 240] loss: 0.267\n",
      "[50, 300] loss: 0.265\n",
      "[50, 360] loss: 0.266\n",
      "Epoch: 50 -> Loss: 0.228906154633\n",
      "Epoch: 50 -> Test Accuracy: 83.82\n",
      "[51, 60] loss: 0.239\n",
      "[51, 120] loss: 0.242\n",
      "[51, 180] loss: 0.251\n",
      "[51, 240] loss: 0.271\n",
      "[51, 300] loss: 0.260\n",
      "[51, 360] loss: 0.262\n",
      "Epoch: 51 -> Loss: 0.178298205137\n",
      "Epoch: 51 -> Test Accuracy: 83.75\n",
      "[52, 60] loss: 0.242\n",
      "[52, 120] loss: 0.245\n",
      "[52, 180] loss: 0.253\n",
      "[52, 240] loss: 0.254\n",
      "[52, 300] loss: 0.266\n",
      "[52, 360] loss: 0.261\n",
      "Epoch: 52 -> Loss: 0.211387902498\n",
      "Epoch: 52 -> Test Accuracy: 82.98\n",
      "[53, 60] loss: 0.235\n",
      "[53, 120] loss: 0.244\n",
      "[53, 180] loss: 0.256\n",
      "[53, 240] loss: 0.248\n",
      "[53, 300] loss: 0.268\n",
      "[53, 360] loss: 0.252\n",
      "Epoch: 53 -> Loss: 0.484629869461\n",
      "Epoch: 53 -> Test Accuracy: 83.45\n",
      "[54, 60] loss: 0.231\n",
      "[54, 120] loss: 0.255\n",
      "[54, 180] loss: 0.256\n",
      "[54, 240] loss: 0.260\n",
      "[54, 300] loss: 0.252\n",
      "[54, 360] loss: 0.257\n",
      "Epoch: 54 -> Loss: 0.348413079977\n",
      "Epoch: 54 -> Test Accuracy: 83.18\n",
      "[55, 60] loss: 0.240\n",
      "[55, 120] loss: 0.238\n",
      "[55, 180] loss: 0.255\n",
      "[55, 240] loss: 0.259\n",
      "[55, 300] loss: 0.254\n",
      "[55, 360] loss: 0.253\n",
      "Epoch: 55 -> Loss: 0.260227203369\n",
      "Epoch: 55 -> Test Accuracy: 82.62\n",
      "[56, 60] loss: 0.233\n",
      "[56, 120] loss: 0.238\n",
      "[56, 180] loss: 0.253\n",
      "[56, 240] loss: 0.259\n",
      "[56, 300] loss: 0.264\n",
      "[56, 360] loss: 0.251\n",
      "Epoch: 56 -> Loss: 0.232816487551\n",
      "Epoch: 56 -> Test Accuracy: 82.93\n",
      "[57, 60] loss: 0.234\n",
      "[57, 120] loss: 0.243\n",
      "[57, 180] loss: 0.260\n",
      "[57, 240] loss: 0.249\n",
      "[57, 300] loss: 0.258\n",
      "[57, 360] loss: 0.249\n",
      "Epoch: 57 -> Loss: 0.250714898109\n",
      "Epoch: 57 -> Test Accuracy: 83.13\n",
      "[58, 60] loss: 0.233\n",
      "[58, 120] loss: 0.234\n",
      "[58, 180] loss: 0.248\n",
      "[58, 240] loss: 0.239\n",
      "[58, 300] loss: 0.254\n",
      "[58, 360] loss: 0.258\n",
      "Epoch: 58 -> Loss: 0.223855942488\n",
      "Epoch: 58 -> Test Accuracy: 83.36\n",
      "[59, 60] loss: 0.230\n",
      "[59, 120] loss: 0.236\n",
      "[59, 180] loss: 0.246\n",
      "[59, 240] loss: 0.242\n",
      "[59, 300] loss: 0.270\n",
      "[59, 360] loss: 0.250\n",
      "Epoch: 59 -> Loss: 0.252308309078\n",
      "Epoch: 59 -> Test Accuracy: 83.05\n",
      "[60, 60] loss: 0.227\n",
      "[60, 120] loss: 0.237\n",
      "[60, 180] loss: 0.252\n",
      "[60, 240] loss: 0.251\n",
      "[60, 300] loss: 0.248\n",
      "[60, 360] loss: 0.252\n",
      "Epoch: 60 -> Loss: 0.424685388803\n",
      "Epoch: 60 -> Test Accuracy: 83.11\n",
      "[61, 60] loss: 0.227\n",
      "[61, 120] loss: 0.241\n",
      "[61, 180] loss: 0.244\n",
      "[61, 240] loss: 0.247\n",
      "[61, 300] loss: 0.245\n",
      "[61, 360] loss: 0.246\n",
      "Epoch: 61 -> Loss: 0.193751126528\n",
      "Epoch: 61 -> Test Accuracy: 83.85\n",
      "[62, 60] loss: 0.237\n",
      "[62, 120] loss: 0.245\n",
      "[62, 180] loss: 0.237\n",
      "[62, 240] loss: 0.243\n",
      "[62, 300] loss: 0.258\n",
      "[62, 360] loss: 0.251\n",
      "Epoch: 62 -> Loss: 0.194198340178\n",
      "Epoch: 62 -> Test Accuracy: 83.23\n",
      "[63, 60] loss: 0.236\n",
      "[63, 120] loss: 0.248\n",
      "[63, 180] loss: 0.253\n",
      "[63, 240] loss: 0.246\n",
      "[63, 300] loss: 0.246\n",
      "[63, 360] loss: 0.246\n",
      "Epoch: 63 -> Loss: 0.139353066683\n",
      "Epoch: 63 -> Test Accuracy: 82.96\n",
      "[64, 60] loss: 0.224\n",
      "[64, 120] loss: 0.245\n",
      "[64, 180] loss: 0.242\n",
      "[64, 240] loss: 0.242\n",
      "[64, 300] loss: 0.250\n",
      "[64, 360] loss: 0.265\n",
      "Epoch: 64 -> Loss: 0.22633831203\n",
      "Epoch: 64 -> Test Accuracy: 82.71\n",
      "[65, 60] loss: 0.224\n",
      "[65, 120] loss: 0.232\n",
      "[65, 180] loss: 0.255\n",
      "[65, 240] loss: 0.251\n",
      "[65, 300] loss: 0.264\n",
      "[65, 360] loss: 0.243\n",
      "Epoch: 65 -> Loss: 0.235838055611\n",
      "Epoch: 65 -> Test Accuracy: 83.38\n",
      "[66, 60] loss: 0.232\n",
      "[66, 120] loss: 0.241\n",
      "[66, 180] loss: 0.239\n",
      "[66, 240] loss: 0.258\n",
      "[66, 300] loss: 0.247\n",
      "[66, 360] loss: 0.246\n",
      "Epoch: 66 -> Loss: 0.223426431417\n",
      "Epoch: 66 -> Test Accuracy: 83.25\n",
      "[67, 60] loss: 0.245\n",
      "[67, 120] loss: 0.238\n",
      "[67, 180] loss: 0.254\n",
      "[67, 240] loss: 0.254\n",
      "[67, 300] loss: 0.249\n",
      "[67, 360] loss: 0.249\n",
      "Epoch: 67 -> Loss: 0.174415424466\n",
      "Epoch: 67 -> Test Accuracy: 83.34\n",
      "[68, 60] loss: 0.229\n",
      "[68, 120] loss: 0.239\n",
      "[68, 180] loss: 0.249\n",
      "[68, 240] loss: 0.244\n",
      "[68, 300] loss: 0.236\n",
      "[68, 360] loss: 0.244\n",
      "Epoch: 68 -> Loss: 0.260427296162\n",
      "Epoch: 68 -> Test Accuracy: 83.53\n",
      "[69, 60] loss: 0.223\n",
      "[69, 120] loss: 0.244\n",
      "[69, 180] loss: 0.240\n",
      "[69, 240] loss: 0.240\n",
      "[69, 300] loss: 0.249\n",
      "[69, 360] loss: 0.255\n",
      "Epoch: 69 -> Loss: 0.232325837016\n",
      "Epoch: 69 -> Test Accuracy: 82.9\n",
      "[70, 60] loss: 0.232\n",
      "[70, 120] loss: 0.230\n",
      "[70, 180] loss: 0.227\n",
      "[70, 240] loss: 0.239\n",
      "[70, 300] loss: 0.250\n",
      "[70, 360] loss: 0.240\n",
      "Epoch: 70 -> Loss: 0.263529211283\n",
      "Epoch: 70 -> Test Accuracy: 83.6\n",
      "[71, 60] loss: 0.213\n",
      "[71, 120] loss: 0.194\n",
      "[71, 180] loss: 0.191\n",
      "[71, 240] loss: 0.183\n",
      "[71, 300] loss: 0.190\n",
      "[71, 360] loss: 0.182\n",
      "Epoch: 71 -> Loss: 0.203422278166\n",
      "Epoch: 71 -> Test Accuracy: 84.69\n",
      "[72, 60] loss: 0.179\n",
      "[72, 120] loss: 0.177\n",
      "[72, 180] loss: 0.171\n",
      "[72, 240] loss: 0.167\n",
      "[72, 300] loss: 0.176\n",
      "[72, 360] loss: 0.166\n",
      "Epoch: 72 -> Loss: 0.187134116888\n",
      "Epoch: 72 -> Test Accuracy: 84.78\n",
      "[73, 60] loss: 0.172\n",
      "[73, 120] loss: 0.162\n",
      "[73, 180] loss: 0.171\n",
      "[73, 240] loss: 0.172\n",
      "[73, 300] loss: 0.167\n",
      "[73, 360] loss: 0.168\n",
      "Epoch: 73 -> Loss: 0.188408568501\n",
      "Epoch: 73 -> Test Accuracy: 84.85\n",
      "[74, 60] loss: 0.168\n",
      "[74, 120] loss: 0.157\n",
      "[74, 180] loss: 0.161\n",
      "[74, 240] loss: 0.163\n",
      "[74, 300] loss: 0.169\n",
      "[74, 360] loss: 0.165\n",
      "Epoch: 74 -> Loss: 0.150333806872\n",
      "Epoch: 74 -> Test Accuracy: 84.74\n",
      "[75, 60] loss: 0.156\n",
      "[75, 120] loss: 0.154\n",
      "[75, 180] loss: 0.154\n",
      "[75, 240] loss: 0.155\n",
      "[75, 300] loss: 0.162\n",
      "[75, 360] loss: 0.166\n",
      "Epoch: 75 -> Loss: 0.191275909543\n",
      "Epoch: 75 -> Test Accuracy: 84.97\n",
      "[76, 60] loss: 0.147\n",
      "[76, 120] loss: 0.145\n",
      "[76, 180] loss: 0.149\n",
      "[76, 240] loss: 0.163\n",
      "[76, 300] loss: 0.153\n",
      "[76, 360] loss: 0.161\n",
      "Epoch: 76 -> Loss: 0.213903933764\n",
      "Epoch: 76 -> Test Accuracy: 84.82\n",
      "[77, 60] loss: 0.144\n",
      "[77, 120] loss: 0.149\n",
      "[77, 180] loss: 0.153\n",
      "[77, 240] loss: 0.152\n",
      "[77, 300] loss: 0.150\n",
      "[77, 360] loss: 0.144\n",
      "Epoch: 77 -> Loss: 0.121599197388\n",
      "Epoch: 77 -> Test Accuracy: 84.91\n",
      "[78, 60] loss: 0.150\n",
      "[78, 120] loss: 0.149\n",
      "[78, 180] loss: 0.140\n",
      "[78, 240] loss: 0.162\n",
      "[78, 300] loss: 0.150\n",
      "[78, 360] loss: 0.149\n",
      "Epoch: 78 -> Loss: 0.250136554241\n",
      "Epoch: 78 -> Test Accuracy: 84.56\n",
      "[79, 60] loss: 0.152\n",
      "[79, 120] loss: 0.140\n",
      "[79, 180] loss: 0.149\n",
      "[79, 240] loss: 0.143\n",
      "[79, 300] loss: 0.147\n",
      "[79, 360] loss: 0.150\n",
      "Epoch: 79 -> Loss: 0.141052931547\n",
      "Epoch: 79 -> Test Accuracy: 84.84\n",
      "[80, 60] loss: 0.138\n",
      "[80, 120] loss: 0.144\n",
      "[80, 180] loss: 0.144\n",
      "[80, 240] loss: 0.151\n",
      "[80, 300] loss: 0.141\n",
      "[80, 360] loss: 0.149\n",
      "Epoch: 80 -> Loss: 0.133011013269\n",
      "Epoch: 80 -> Test Accuracy: 84.87\n",
      "[81, 60] loss: 0.139\n",
      "[81, 120] loss: 0.141\n",
      "[81, 180] loss: 0.140\n",
      "[81, 240] loss: 0.147\n",
      "[81, 300] loss: 0.141\n",
      "[81, 360] loss: 0.147\n",
      "Epoch: 81 -> Loss: 0.0947454124689\n",
      "Epoch: 81 -> Test Accuracy: 84.62\n",
      "[82, 60] loss: 0.134\n",
      "[82, 120] loss: 0.139\n",
      "[82, 180] loss: 0.138\n",
      "[82, 240] loss: 0.139\n",
      "[82, 300] loss: 0.140\n",
      "[82, 360] loss: 0.148\n",
      "Epoch: 82 -> Loss: 0.0995164215565\n",
      "Epoch: 82 -> Test Accuracy: 84.61\n",
      "[83, 60] loss: 0.130\n",
      "[83, 120] loss: 0.137\n",
      "[83, 180] loss: 0.132\n",
      "[83, 240] loss: 0.147\n",
      "[83, 300] loss: 0.149\n",
      "[83, 360] loss: 0.136\n",
      "Epoch: 83 -> Loss: 0.155322238803\n",
      "Epoch: 83 -> Test Accuracy: 84.81\n",
      "[84, 60] loss: 0.136\n",
      "[84, 120] loss: 0.137\n",
      "[84, 180] loss: 0.137\n",
      "[84, 240] loss: 0.142\n",
      "[84, 300] loss: 0.135\n",
      "[84, 360] loss: 0.136\n",
      "Epoch: 84 -> Loss: 0.189928561449\n",
      "Epoch: 84 -> Test Accuracy: 84.93\n",
      "[85, 60] loss: 0.132\n",
      "[85, 120] loss: 0.123\n",
      "[85, 180] loss: 0.140\n",
      "[85, 240] loss: 0.133\n",
      "[85, 300] loss: 0.136\n",
      "[85, 360] loss: 0.141\n",
      "Epoch: 85 -> Loss: 0.133604809642\n",
      "Epoch: 85 -> Test Accuracy: 84.78\n",
      "[86, 60] loss: 0.139\n",
      "[86, 120] loss: 0.125\n",
      "[86, 180] loss: 0.119\n",
      "[86, 240] loss: 0.124\n",
      "[86, 300] loss: 0.123\n",
      "[86, 360] loss: 0.119\n",
      "Epoch: 86 -> Loss: 0.120556369424\n",
      "Epoch: 86 -> Test Accuracy: 84.92\n",
      "[87, 60] loss: 0.116\n",
      "[87, 120] loss: 0.120\n",
      "[87, 180] loss: 0.121\n",
      "[87, 240] loss: 0.125\n",
      "[87, 300] loss: 0.117\n",
      "[87, 360] loss: 0.114\n",
      "Epoch: 87 -> Loss: 0.105588242412\n",
      "Epoch: 87 -> Test Accuracy: 84.85\n",
      "[88, 60] loss: 0.120\n",
      "[88, 120] loss: 0.115\n",
      "[88, 180] loss: 0.124\n",
      "[88, 240] loss: 0.119\n",
      "[88, 300] loss: 0.117\n",
      "[88, 360] loss: 0.126\n",
      "Epoch: 88 -> Loss: 0.151596993208\n",
      "Epoch: 88 -> Test Accuracy: 85.09\n",
      "[89, 60] loss: 0.118\n",
      "[89, 120] loss: 0.114\n",
      "[89, 180] loss: 0.117\n",
      "[89, 240] loss: 0.121\n",
      "[89, 300] loss: 0.121\n",
      "[89, 360] loss: 0.120\n",
      "Epoch: 89 -> Loss: 0.0770740360022\n",
      "Epoch: 89 -> Test Accuracy: 85.12\n",
      "[90, 60] loss: 0.119\n",
      "[90, 120] loss: 0.114\n",
      "[90, 180] loss: 0.112\n",
      "[90, 240] loss: 0.117\n",
      "[90, 300] loss: 0.114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90, 360] loss: 0.120\n",
      "Epoch: 90 -> Loss: 0.0678593143821\n",
      "Epoch: 90 -> Test Accuracy: 85.11\n",
      "[91, 60] loss: 0.116\n",
      "[91, 120] loss: 0.117\n",
      "[91, 180] loss: 0.114\n",
      "[91, 240] loss: 0.117\n",
      "[91, 300] loss: 0.116\n",
      "[91, 360] loss: 0.110\n",
      "Epoch: 91 -> Loss: 0.16958065331\n",
      "Epoch: 91 -> Test Accuracy: 85.16\n",
      "[92, 60] loss: 0.112\n",
      "[92, 120] loss: 0.120\n",
      "[92, 180] loss: 0.115\n",
      "[92, 240] loss: 0.112\n",
      "[92, 300] loss: 0.124\n",
      "[92, 360] loss: 0.112\n",
      "Epoch: 92 -> Loss: 0.181746214628\n",
      "Epoch: 92 -> Test Accuracy: 85.21\n",
      "[93, 60] loss: 0.109\n",
      "[93, 120] loss: 0.112\n",
      "[93, 180] loss: 0.112\n",
      "[93, 240] loss: 0.126\n",
      "[93, 300] loss: 0.115\n",
      "[93, 360] loss: 0.117\n",
      "Epoch: 93 -> Loss: 0.0933094620705\n",
      "Epoch: 93 -> Test Accuracy: 85.11\n",
      "[94, 60] loss: 0.110\n",
      "[94, 120] loss: 0.111\n",
      "[94, 180] loss: 0.109\n",
      "[94, 240] loss: 0.113\n",
      "[94, 300] loss: 0.117\n",
      "[94, 360] loss: 0.123\n",
      "Epoch: 94 -> Loss: 0.124172352254\n",
      "Epoch: 94 -> Test Accuracy: 85.11\n",
      "[95, 60] loss: 0.111\n",
      "[95, 120] loss: 0.116\n",
      "[95, 180] loss: 0.117\n",
      "[95, 240] loss: 0.110\n",
      "[95, 300] loss: 0.112\n",
      "[95, 360] loss: 0.118\n",
      "Epoch: 95 -> Loss: 0.134717732668\n",
      "Epoch: 95 -> Test Accuracy: 85.08\n",
      "[96, 60] loss: 0.117\n",
      "[96, 120] loss: 0.111\n",
      "[96, 180] loss: 0.115\n",
      "[96, 240] loss: 0.107\n",
      "[96, 300] loss: 0.113\n",
      "[96, 360] loss: 0.109\n",
      "Epoch: 96 -> Loss: 0.21071831882\n",
      "Epoch: 96 -> Test Accuracy: 85.12\n",
      "[97, 60] loss: 0.111\n",
      "[97, 120] loss: 0.114\n",
      "[97, 180] loss: 0.115\n",
      "[97, 240] loss: 0.120\n",
      "[97, 300] loss: 0.115\n",
      "[97, 360] loss: 0.112\n",
      "Epoch: 97 -> Loss: 0.115307666361\n",
      "Epoch: 97 -> Test Accuracy: 85.18\n",
      "[98, 60] loss: 0.113\n",
      "[98, 120] loss: 0.115\n",
      "[98, 180] loss: 0.110\n",
      "[98, 240] loss: 0.112\n",
      "[98, 300] loss: 0.108\n",
      "[98, 360] loss: 0.115\n",
      "Epoch: 98 -> Loss: 0.0778320357203\n",
      "Epoch: 98 -> Test Accuracy: 85.07\n",
      "[99, 60] loss: 0.107\n",
      "[99, 120] loss: 0.117\n",
      "[99, 180] loss: 0.107\n",
      "[99, 240] loss: 0.111\n",
      "[99, 300] loss: 0.112\n",
      "[99, 360] loss: 0.111\n",
      "Epoch: 99 -> Loss: 0.0812774002552\n",
      "Epoch: 99 -> Test Accuracy: 85.19\n",
      "[100, 60] loss: 0.105\n",
      "[100, 120] loss: 0.109\n",
      "[100, 180] loss: 0.110\n",
      "[100, 240] loss: 0.107\n",
      "[100, 300] loss: 0.110\n",
      "[100, 360] loss: 0.112\n",
      "Epoch: 100 -> Loss: 0.079749956727\n",
      "Epoch: 100 -> Test Accuracy: 85.24\n",
      "Finished Training\n",
      "[1, 60] loss: 1.551\n",
      "[1, 120] loss: 1.247\n",
      "[1, 180] loss: 1.185\n",
      "[1, 240] loss: 1.140\n",
      "[1, 300] loss: 1.102\n",
      "[1, 360] loss: 1.079\n",
      "Epoch: 1 -> Loss: 1.15667521954\n",
      "Epoch: 1 -> Test Accuracy: 55.76\n",
      "[2, 60] loss: 1.062\n",
      "[2, 120] loss: 1.036\n",
      "[2, 180] loss: 1.032\n",
      "[2, 240] loss: 1.039\n",
      "[2, 300] loss: 1.027\n",
      "[2, 360] loss: 1.006\n",
      "Epoch: 2 -> Loss: 0.997324168682\n",
      "Epoch: 2 -> Test Accuracy: 57.16\n",
      "[3, 60] loss: 1.005\n",
      "[3, 120] loss: 0.995\n",
      "[3, 180] loss: 0.973\n",
      "[3, 240] loss: 0.984\n",
      "[3, 300] loss: 0.975\n",
      "[3, 360] loss: 0.994\n",
      "Epoch: 3 -> Loss: 1.03563868999\n",
      "Epoch: 3 -> Test Accuracy: 59.29\n",
      "[4, 60] loss: 0.988\n",
      "[4, 120] loss: 0.973\n",
      "[4, 180] loss: 0.942\n",
      "[4, 240] loss: 0.946\n",
      "[4, 300] loss: 0.965\n",
      "[4, 360] loss: 0.954\n",
      "Epoch: 4 -> Loss: 0.989939808846\n",
      "Epoch: 4 -> Test Accuracy: 59.49\n",
      "[5, 60] loss: 0.955\n",
      "[5, 120] loss: 0.930\n",
      "[5, 180] loss: 0.950\n",
      "[5, 240] loss: 0.956\n",
      "[5, 300] loss: 0.937\n",
      "[5, 360] loss: 0.952\n",
      "Epoch: 5 -> Loss: 0.925399303436\n",
      "Epoch: 5 -> Test Accuracy: 57.81\n",
      "[6, 60] loss: 0.943\n",
      "[6, 120] loss: 0.941\n",
      "[6, 180] loss: 0.931\n",
      "[6, 240] loss: 0.927\n",
      "[6, 300] loss: 0.923\n",
      "[6, 360] loss: 0.931\n",
      "Epoch: 6 -> Loss: 1.24036431313\n",
      "Epoch: 6 -> Test Accuracy: 60.1\n",
      "[7, 60] loss: 0.911\n",
      "[7, 120] loss: 0.911\n",
      "[7, 180] loss: 0.928\n",
      "[7, 240] loss: 0.950\n",
      "[7, 300] loss: 0.949\n",
      "[7, 360] loss: 0.925\n",
      "Epoch: 7 -> Loss: 0.986806690693\n",
      "Epoch: 7 -> Test Accuracy: 60.02\n",
      "[8, 60] loss: 0.915\n",
      "[8, 120] loss: 0.906\n",
      "[8, 180] loss: 0.918\n",
      "[8, 240] loss: 0.925\n",
      "[8, 300] loss: 0.932\n",
      "[8, 360] loss: 0.921\n",
      "Epoch: 8 -> Loss: 0.818997502327\n",
      "Epoch: 8 -> Test Accuracy: 60.8\n",
      "[9, 60] loss: 0.899\n",
      "[9, 120] loss: 0.929\n",
      "[9, 180] loss: 0.929\n",
      "[9, 240] loss: 0.907\n",
      "[9, 300] loss: 0.904\n",
      "[9, 360] loss: 0.908\n",
      "Epoch: 9 -> Loss: 0.931921601295\n",
      "Epoch: 9 -> Test Accuracy: 61.17\n",
      "[10, 60] loss: 0.917\n",
      "[10, 120] loss: 0.902\n",
      "[10, 180] loss: 0.930\n",
      "[10, 240] loss: 0.887\n",
      "[10, 300] loss: 0.910\n",
      "[10, 360] loss: 0.908\n",
      "Epoch: 10 -> Loss: 0.800303161144\n",
      "Epoch: 10 -> Test Accuracy: 62.21\n",
      "[11, 60] loss: 0.882\n",
      "[11, 120] loss: 0.913\n",
      "[11, 180] loss: 0.906\n",
      "[11, 240] loss: 0.915\n",
      "[11, 300] loss: 0.900\n",
      "[11, 360] loss: 0.907\n",
      "Epoch: 11 -> Loss: 0.960480868816\n",
      "Epoch: 11 -> Test Accuracy: 62.35\n",
      "[12, 60] loss: 0.890\n",
      "[12, 120] loss: 0.918\n",
      "[12, 180] loss: 0.907\n",
      "[12, 240] loss: 0.901\n",
      "[12, 300] loss: 0.913\n",
      "[12, 360] loss: 0.898\n",
      "Epoch: 12 -> Loss: 0.880030155182\n",
      "Epoch: 12 -> Test Accuracy: 61.82\n",
      "[13, 60] loss: 0.885\n",
      "[13, 120] loss: 0.891\n",
      "[13, 180] loss: 0.920\n",
      "[13, 240] loss: 0.896\n",
      "[13, 300] loss: 0.901\n",
      "[13, 360] loss: 0.920\n",
      "Epoch: 13 -> Loss: 0.804981529713\n",
      "Epoch: 13 -> Test Accuracy: 61.88\n",
      "[14, 60] loss: 0.885\n",
      "[14, 120] loss: 0.891\n",
      "[14, 180] loss: 0.890\n",
      "[14, 240] loss: 0.880\n",
      "[14, 300] loss: 0.916\n",
      "[14, 360] loss: 0.899\n",
      "Epoch: 14 -> Loss: 0.739347815514\n",
      "Epoch: 14 -> Test Accuracy: 63.58\n",
      "[15, 60] loss: 0.889\n",
      "[15, 120] loss: 0.873\n",
      "[15, 180] loss: 0.890\n",
      "[15, 240] loss: 0.890\n",
      "[15, 300] loss: 0.899\n",
      "[15, 360] loss: 0.911\n",
      "Epoch: 15 -> Loss: 0.988699793816\n",
      "Epoch: 15 -> Test Accuracy: 62.81\n",
      "[16, 60] loss: 0.889\n",
      "[16, 120] loss: 0.873\n",
      "[16, 180] loss: 0.898\n",
      "[16, 240] loss: 0.884\n",
      "[16, 300] loss: 0.885\n",
      "[16, 360] loss: 0.911\n",
      "Epoch: 16 -> Loss: 0.69017636776\n",
      "Epoch: 16 -> Test Accuracy: 60.97\n",
      "[17, 60] loss: 0.875\n",
      "[17, 120] loss: 0.884\n",
      "[17, 180] loss: 0.895\n",
      "[17, 240] loss: 0.900\n",
      "[17, 300] loss: 0.888\n",
      "[17, 360] loss: 0.899\n",
      "Epoch: 17 -> Loss: 0.863917052746\n",
      "Epoch: 17 -> Test Accuracy: 62.65\n",
      "[18, 60] loss: 0.878\n",
      "[18, 120] loss: 0.898\n",
      "[18, 180] loss: 0.875\n",
      "[18, 240] loss: 0.879\n",
      "[18, 300] loss: 0.889\n",
      "[18, 360] loss: 0.875\n",
      "Epoch: 18 -> Loss: 1.04585194588\n",
      "Epoch: 18 -> Test Accuracy: 62.23\n",
      "[19, 60] loss: 0.877\n",
      "[19, 120] loss: 0.864\n",
      "[19, 180] loss: 0.906\n",
      "[19, 240] loss: 0.898\n",
      "[19, 300] loss: 0.888\n",
      "[19, 360] loss: 0.893\n",
      "Epoch: 19 -> Loss: 0.813482761383\n",
      "Epoch: 19 -> Test Accuracy: 61.5\n",
      "[20, 60] loss: 0.893\n",
      "[20, 120] loss: 0.896\n",
      "[20, 180] loss: 0.905\n",
      "[20, 240] loss: 0.874\n",
      "[20, 300] loss: 0.870\n",
      "[20, 360] loss: 0.890\n",
      "Epoch: 20 -> Loss: 0.915753543377\n",
      "Epoch: 20 -> Test Accuracy: 61.13\n",
      "[21, 60] loss: 0.895\n",
      "[21, 120] loss: 0.895\n",
      "[21, 180] loss: 0.871\n",
      "[21, 240] loss: 0.858\n",
      "[21, 300] loss: 0.893\n",
      "[21, 360] loss: 0.878\n",
      "Epoch: 21 -> Loss: 0.801992118359\n",
      "Epoch: 21 -> Test Accuracy: 62.04\n",
      "[22, 60] loss: 0.877\n",
      "[22, 120] loss: 0.868\n",
      "[22, 180] loss: 0.888\n",
      "[22, 240] loss: 0.892\n",
      "[22, 300] loss: 0.866\n",
      "[22, 360] loss: 0.879\n",
      "Epoch: 22 -> Loss: 0.933538615704\n",
      "Epoch: 22 -> Test Accuracy: 61.7\n",
      "[23, 60] loss: 0.868\n",
      "[23, 120] loss: 0.885\n",
      "[23, 180] loss: 0.893\n",
      "[23, 240] loss: 0.895\n",
      "[23, 300] loss: 0.877\n",
      "[23, 360] loss: 0.882\n",
      "Epoch: 23 -> Loss: 1.105681777\n",
      "Epoch: 23 -> Test Accuracy: 63.47\n",
      "[24, 60] loss: 0.872\n",
      "[24, 120] loss: 0.879\n",
      "[24, 180] loss: 0.893\n",
      "[24, 240] loss: 0.873\n",
      "[24, 300] loss: 0.888\n",
      "[24, 360] loss: 0.884\n",
      "Epoch: 24 -> Loss: 0.769816815853\n",
      "Epoch: 24 -> Test Accuracy: 62.28\n",
      "[25, 60] loss: 0.898\n",
      "[25, 120] loss: 0.879\n",
      "[25, 180] loss: 0.857\n",
      "[25, 240] loss: 0.878\n",
      "[25, 300] loss: 0.871\n",
      "[25, 360] loss: 0.880\n",
      "Epoch: 25 -> Loss: 0.756554365158\n",
      "Epoch: 25 -> Test Accuracy: 62.7\n",
      "[26, 60] loss: 0.872\n",
      "[26, 120] loss: 0.896\n",
      "[26, 180] loss: 0.873\n",
      "[26, 240] loss: 0.866\n",
      "[26, 300] loss: 0.873\n",
      "[26, 360] loss: 0.880\n",
      "Epoch: 26 -> Loss: 0.90589094162\n",
      "Epoch: 26 -> Test Accuracy: 61.7\n",
      "[27, 60] loss: 0.866\n",
      "[27, 120] loss: 0.887\n",
      "[27, 180] loss: 0.880\n",
      "[27, 240] loss: 0.897\n",
      "[27, 300] loss: 0.886\n",
      "[27, 360] loss: 0.877\n",
      "Epoch: 27 -> Loss: 1.02044630051\n",
      "Epoch: 27 -> Test Accuracy: 63.26\n",
      "[28, 60] loss: 0.865\n",
      "[28, 120] loss: 0.863\n",
      "[28, 180] loss: 0.880\n",
      "[28, 240] loss: 0.869\n",
      "[28, 300] loss: 0.888\n",
      "[28, 360] loss: 0.890\n",
      "Epoch: 28 -> Loss: 0.930733859539\n",
      "Epoch: 28 -> Test Accuracy: 63.14\n",
      "[29, 60] loss: 0.872\n",
      "[29, 120] loss: 0.871\n",
      "[29, 180] loss: 0.875\n",
      "[29, 240] loss: 0.880\n",
      "[29, 300] loss: 0.886\n",
      "[29, 360] loss: 0.881\n",
      "Epoch: 29 -> Loss: 0.798794388771\n",
      "Epoch: 29 -> Test Accuracy: 62.19\n",
      "[30, 60] loss: 0.867\n",
      "[30, 120] loss: 0.868\n",
      "[30, 180] loss: 0.877\n",
      "[30, 240] loss: 0.881\n",
      "[30, 300] loss: 0.903\n",
      "[30, 360] loss: 0.867\n",
      "Epoch: 30 -> Loss: 1.03073787689\n",
      "Epoch: 30 -> Test Accuracy: 62.89\n",
      "[31, 60] loss: 0.861\n",
      "[31, 120] loss: 0.859\n",
      "[31, 180] loss: 0.895\n",
      "[31, 240] loss: 0.877\n",
      "[31, 300] loss: 0.887\n",
      "[31, 360] loss: 0.884\n",
      "Epoch: 31 -> Loss: 0.732952356339\n",
      "Epoch: 31 -> Test Accuracy: 63.83\n",
      "[32, 60] loss: 0.891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 120] loss: 0.857\n",
      "[32, 180] loss: 0.865\n",
      "[32, 240] loss: 0.893\n",
      "[32, 300] loss: 0.865\n",
      "[32, 360] loss: 0.868\n",
      "Epoch: 32 -> Loss: 0.782016634941\n",
      "Epoch: 32 -> Test Accuracy: 62.05\n",
      "[33, 60] loss: 0.851\n",
      "[33, 120] loss: 0.870\n",
      "[33, 180] loss: 0.877\n",
      "[33, 240] loss: 0.900\n",
      "[33, 300] loss: 0.882\n",
      "[33, 360] loss: 0.871\n",
      "Epoch: 33 -> Loss: 0.80281573534\n",
      "Epoch: 33 -> Test Accuracy: 62.73\n",
      "[34, 60] loss: 0.863\n",
      "[34, 120] loss: 0.875\n",
      "[34, 180] loss: 0.878\n",
      "[34, 240] loss: 0.886\n",
      "[34, 300] loss: 0.879\n",
      "[34, 360] loss: 0.876\n",
      "Epoch: 34 -> Loss: 0.847474217415\n",
      "Epoch: 34 -> Test Accuracy: 62.22\n",
      "[35, 60] loss: 0.866\n",
      "[35, 120] loss: 0.875\n",
      "[35, 180] loss: 0.866\n",
      "[35, 240] loss: 0.870\n",
      "[35, 300] loss: 0.873\n",
      "[35, 360] loss: 0.890\n",
      "Epoch: 35 -> Loss: 0.79876947403\n",
      "Epoch: 35 -> Test Accuracy: 62.44\n",
      "[36, 60] loss: 0.811\n",
      "[36, 120] loss: 0.778\n",
      "[36, 180] loss: 0.758\n",
      "[36, 240] loss: 0.763\n",
      "[36, 300] loss: 0.766\n",
      "[36, 360] loss: 0.773\n",
      "Epoch: 36 -> Loss: 0.747051179409\n",
      "Epoch: 36 -> Test Accuracy: 66.69\n",
      "[37, 60] loss: 0.759\n",
      "[37, 120] loss: 0.742\n",
      "[37, 180] loss: 0.759\n",
      "[37, 240] loss: 0.762\n",
      "[37, 300] loss: 0.749\n",
      "[37, 360] loss: 0.759\n",
      "Epoch: 37 -> Loss: 0.810419201851\n",
      "Epoch: 37 -> Test Accuracy: 66.76\n",
      "[38, 60] loss: 0.733\n",
      "[38, 120] loss: 0.741\n",
      "[38, 180] loss: 0.758\n",
      "[38, 240] loss: 0.758\n",
      "[38, 300] loss: 0.753\n",
      "[38, 360] loss: 0.750\n",
      "Epoch: 38 -> Loss: 0.994201958179\n",
      "Epoch: 38 -> Test Accuracy: 66.61\n",
      "[39, 60] loss: 0.748\n",
      "[39, 120] loss: 0.733\n",
      "[39, 180] loss: 0.749\n",
      "[39, 240] loss: 0.745\n",
      "[39, 300] loss: 0.757\n",
      "[39, 360] loss: 0.741\n",
      "Epoch: 39 -> Loss: 0.762360930443\n",
      "Epoch: 39 -> Test Accuracy: 67.01\n",
      "[40, 60] loss: 0.736\n",
      "[40, 120] loss: 0.749\n",
      "[40, 180] loss: 0.739\n",
      "[40, 240] loss: 0.735\n",
      "[40, 300] loss: 0.759\n",
      "[40, 360] loss: 0.732\n",
      "Epoch: 40 -> Loss: 0.715035915375\n",
      "Epoch: 40 -> Test Accuracy: 67.13\n",
      "[41, 60] loss: 0.735\n",
      "[41, 120] loss: 0.745\n",
      "[41, 180] loss: 0.730\n",
      "[41, 240] loss: 0.768\n",
      "[41, 300] loss: 0.733\n",
      "[41, 360] loss: 0.748\n",
      "Epoch: 41 -> Loss: 0.931696712971\n",
      "Epoch: 41 -> Test Accuracy: 66.34\n",
      "[42, 60] loss: 0.748\n",
      "[42, 120] loss: 0.727\n",
      "[42, 180] loss: 0.715\n",
      "[42, 240] loss: 0.748\n",
      "[42, 300] loss: 0.745\n",
      "[42, 360] loss: 0.728\n",
      "Epoch: 42 -> Loss: 0.838461220264\n",
      "Epoch: 42 -> Test Accuracy: 66.67\n",
      "[43, 60] loss: 0.749\n",
      "[43, 120] loss: 0.755\n",
      "[43, 180] loss: 0.756\n",
      "[43, 240] loss: 0.747\n",
      "[43, 300] loss: 0.733\n",
      "[43, 360] loss: 0.748\n",
      "Epoch: 43 -> Loss: 0.706151604652\n",
      "Epoch: 43 -> Test Accuracy: 66.69\n",
      "[44, 60] loss: 0.745\n",
      "[44, 120] loss: 0.706\n",
      "[44, 180] loss: 0.750\n",
      "[44, 240] loss: 0.763\n",
      "[44, 300] loss: 0.757\n",
      "[44, 360] loss: 0.739\n",
      "Epoch: 44 -> Loss: 0.655267179012\n",
      "Epoch: 44 -> Test Accuracy: 66.24\n",
      "[45, 60] loss: 0.746\n",
      "[45, 120] loss: 0.730\n",
      "[45, 180] loss: 0.731\n",
      "[45, 240] loss: 0.753\n",
      "[45, 300] loss: 0.747\n",
      "[45, 360] loss: 0.731\n",
      "Epoch: 45 -> Loss: 0.683117806911\n",
      "Epoch: 45 -> Test Accuracy: 66.64\n",
      "[46, 60] loss: 0.725\n",
      "[46, 120] loss: 0.752\n",
      "[46, 180] loss: 0.754\n",
      "[46, 240] loss: 0.749\n",
      "[46, 300] loss: 0.741\n",
      "[46, 360] loss: 0.760\n",
      "Epoch: 46 -> Loss: 0.593613266945\n",
      "Epoch: 46 -> Test Accuracy: 66.15\n",
      "[47, 60] loss: 0.747\n",
      "[47, 120] loss: 0.727\n",
      "[47, 180] loss: 0.748\n",
      "[47, 240] loss: 0.736\n",
      "[47, 300] loss: 0.743\n",
      "[47, 360] loss: 0.738\n",
      "Epoch: 47 -> Loss: 0.845849335194\n",
      "Epoch: 47 -> Test Accuracy: 67.31\n",
      "[48, 60] loss: 0.718\n",
      "[48, 120] loss: 0.730\n",
      "[48, 180] loss: 0.742\n",
      "[48, 240] loss: 0.732\n",
      "[48, 300] loss: 0.758\n",
      "[48, 360] loss: 0.764\n",
      "Epoch: 48 -> Loss: 0.755238294601\n",
      "Epoch: 48 -> Test Accuracy: 66.91\n",
      "[49, 60] loss: 0.732\n",
      "[49, 120] loss: 0.735\n",
      "[49, 180] loss: 0.735\n",
      "[49, 240] loss: 0.752\n",
      "[49, 300] loss: 0.739\n",
      "[49, 360] loss: 0.737\n",
      "Epoch: 49 -> Loss: 0.59497576952\n",
      "Epoch: 49 -> Test Accuracy: 67.26\n",
      "[50, 60] loss: 0.732\n",
      "[50, 120] loss: 0.739\n",
      "[50, 180] loss: 0.736\n",
      "[50, 240] loss: 0.718\n",
      "[50, 300] loss: 0.733\n",
      "[50, 360] loss: 0.766\n",
      "Epoch: 50 -> Loss: 0.884231567383\n",
      "Epoch: 50 -> Test Accuracy: 66.57\n",
      "[51, 60] loss: 0.740\n",
      "[51, 120] loss: 0.736\n",
      "[51, 180] loss: 0.739\n",
      "[51, 240] loss: 0.766\n",
      "[51, 300] loss: 0.733\n",
      "[51, 360] loss: 0.744\n",
      "Epoch: 51 -> Loss: 0.7527333498\n",
      "Epoch: 51 -> Test Accuracy: 66.82\n",
      "[52, 60] loss: 0.748\n",
      "[52, 120] loss: 0.745\n",
      "[52, 180] loss: 0.736\n",
      "[52, 240] loss: 0.731\n",
      "[52, 300] loss: 0.725\n",
      "[52, 360] loss: 0.758\n",
      "Epoch: 52 -> Loss: 0.668799459934\n",
      "Epoch: 52 -> Test Accuracy: 67.36\n",
      "[53, 60] loss: 0.745\n",
      "[53, 120] loss: 0.744\n",
      "[53, 180] loss: 0.723\n",
      "[53, 240] loss: 0.737\n",
      "[53, 300] loss: 0.760\n",
      "[53, 360] loss: 0.740\n",
      "Epoch: 53 -> Loss: 0.688467681408\n",
      "Epoch: 53 -> Test Accuracy: 66.75\n",
      "[54, 60] loss: 0.712\n",
      "[54, 120] loss: 0.733\n",
      "[54, 180] loss: 0.746\n",
      "[54, 240] loss: 0.762\n",
      "[54, 300] loss: 0.740\n",
      "[54, 360] loss: 0.731\n",
      "Epoch: 54 -> Loss: 0.76734149456\n",
      "Epoch: 54 -> Test Accuracy: 66.83\n",
      "[55, 60] loss: 0.718\n",
      "[55, 120] loss: 0.750\n",
      "[55, 180] loss: 0.743\n",
      "[55, 240] loss: 0.729\n",
      "[55, 300] loss: 0.746\n",
      "[55, 360] loss: 0.771\n",
      "Epoch: 55 -> Loss: 0.802051246166\n",
      "Epoch: 55 -> Test Accuracy: 66.13\n",
      "[56, 60] loss: 0.727\n",
      "[56, 120] loss: 0.738\n",
      "[56, 180] loss: 0.744\n",
      "[56, 240] loss: 0.734\n",
      "[56, 300] loss: 0.754\n",
      "[56, 360] loss: 0.745\n",
      "Epoch: 56 -> Loss: 0.62401342392\n",
      "Epoch: 56 -> Test Accuracy: 66.29\n",
      "[57, 60] loss: 0.722\n",
      "[57, 120] loss: 0.738\n",
      "[57, 180] loss: 0.735\n",
      "[57, 240] loss: 0.743\n",
      "[57, 300] loss: 0.741\n",
      "[57, 360] loss: 0.740\n",
      "Epoch: 57 -> Loss: 0.688408374786\n",
      "Epoch: 57 -> Test Accuracy: 66.96\n",
      "[58, 60] loss: 0.748\n",
      "[58, 120] loss: 0.742\n",
      "[58, 180] loss: 0.735\n",
      "[58, 240] loss: 0.722\n",
      "[58, 300] loss: 0.766\n",
      "[58, 360] loss: 0.757\n",
      "Epoch: 58 -> Loss: 0.719470322132\n",
      "Epoch: 58 -> Test Accuracy: 67.01\n",
      "[59, 60] loss: 0.730\n",
      "[59, 120] loss: 0.724\n",
      "[59, 180] loss: 0.724\n",
      "[59, 240] loss: 0.744\n",
      "[59, 300] loss: 0.744\n",
      "[59, 360] loss: 0.734\n",
      "Epoch: 59 -> Loss: 0.826263129711\n",
      "Epoch: 59 -> Test Accuracy: 66.89\n",
      "[60, 60] loss: 0.739\n",
      "[60, 120] loss: 0.748\n",
      "[60, 180] loss: 0.746\n",
      "[60, 240] loss: 0.741\n",
      "[60, 300] loss: 0.751\n",
      "[60, 360] loss: 0.726\n",
      "Epoch: 60 -> Loss: 0.790526926517\n",
      "Epoch: 60 -> Test Accuracy: 66.89\n",
      "[61, 60] loss: 0.745\n",
      "[61, 120] loss: 0.723\n",
      "[61, 180] loss: 0.730\n",
      "[61, 240] loss: 0.740\n",
      "[61, 300] loss: 0.729\n",
      "[61, 360] loss: 0.738\n",
      "Epoch: 61 -> Loss: 0.740551710129\n",
      "Epoch: 61 -> Test Accuracy: 67.25\n",
      "[62, 60] loss: 0.738\n",
      "[62, 120] loss: 0.710\n",
      "[62, 180] loss: 0.742\n",
      "[62, 240] loss: 0.726\n",
      "[62, 300] loss: 0.759\n",
      "[62, 360] loss: 0.733\n",
      "Epoch: 62 -> Loss: 0.587323784828\n",
      "Epoch: 62 -> Test Accuracy: 66.67\n",
      "[63, 60] loss: 0.735\n",
      "[63, 120] loss: 0.742\n",
      "[63, 180] loss: 0.724\n",
      "[63, 240] loss: 0.741\n",
      "[63, 300] loss: 0.746\n",
      "[63, 360] loss: 0.742\n",
      "Epoch: 63 -> Loss: 0.634421050549\n",
      "Epoch: 63 -> Test Accuracy: 67.04\n",
      "[64, 60] loss: 0.727\n",
      "[64, 120] loss: 0.726\n",
      "[64, 180] loss: 0.725\n",
      "[64, 240] loss: 0.744\n",
      "[64, 300] loss: 0.741\n",
      "[64, 360] loss: 0.752\n",
      "Epoch: 64 -> Loss: 0.702078044415\n",
      "Epoch: 64 -> Test Accuracy: 67.79\n",
      "[65, 60] loss: 0.730\n",
      "[65, 120] loss: 0.745\n",
      "[65, 180] loss: 0.740\n",
      "[65, 240] loss: 0.734\n",
      "[65, 300] loss: 0.734\n",
      "[65, 360] loss: 0.747\n",
      "Epoch: 65 -> Loss: 0.861592590809\n",
      "Epoch: 65 -> Test Accuracy: 66.72\n",
      "[66, 60] loss: 0.738\n",
      "[66, 120] loss: 0.734\n",
      "[66, 180] loss: 0.724\n",
      "[66, 240] loss: 0.746\n",
      "[66, 300] loss: 0.709\n",
      "[66, 360] loss: 0.765\n",
      "Epoch: 66 -> Loss: 0.599300563335\n",
      "Epoch: 66 -> Test Accuracy: 66.43\n",
      "[67, 60] loss: 0.731\n",
      "[67, 120] loss: 0.723\n",
      "[67, 180] loss: 0.730\n",
      "[67, 240] loss: 0.746\n",
      "[67, 300] loss: 0.738\n",
      "[67, 360] loss: 0.747\n",
      "Epoch: 67 -> Loss: 0.554769158363\n",
      "Epoch: 67 -> Test Accuracy: 67.13\n",
      "[68, 60] loss: 0.734\n",
      "[68, 120] loss: 0.746\n",
      "[68, 180] loss: 0.727\n",
      "[68, 240] loss: 0.717\n",
      "[68, 300] loss: 0.732\n",
      "[68, 360] loss: 0.753\n",
      "Epoch: 68 -> Loss: 0.709643602371\n",
      "Epoch: 68 -> Test Accuracy: 67.17\n",
      "[69, 60] loss: 0.734\n",
      "[69, 120] loss: 0.742\n",
      "[69, 180] loss: 0.736\n",
      "[69, 240] loss: 0.732\n",
      "[69, 300] loss: 0.734\n",
      "[69, 360] loss: 0.725\n",
      "Epoch: 69 -> Loss: 0.664801299572\n",
      "Epoch: 69 -> Test Accuracy: 67.78\n",
      "[70, 60] loss: 0.721\n",
      "[70, 120] loss: 0.740\n",
      "[70, 180] loss: 0.760\n",
      "[70, 240] loss: 0.726\n",
      "[70, 300] loss: 0.743\n",
      "[70, 360] loss: 0.708\n",
      "Epoch: 70 -> Loss: 0.948633551598\n",
      "Epoch: 70 -> Test Accuracy: 66.93\n",
      "[71, 60] loss: 0.696\n",
      "[71, 120] loss: 0.678\n",
      "[71, 180] loss: 0.666\n",
      "[71, 240] loss: 0.656\n",
      "[71, 300] loss: 0.646\n",
      "[71, 360] loss: 0.671\n",
      "Epoch: 71 -> Loss: 0.668537318707\n",
      "Epoch: 71 -> Test Accuracy: 69.58\n",
      "[72, 60] loss: 0.663\n",
      "[72, 120] loss: 0.655\n",
      "[72, 180] loss: 0.650\n",
      "[72, 240] loss: 0.666\n",
      "[72, 300] loss: 0.645\n",
      "[72, 360] loss: 0.644\n",
      "Epoch: 72 -> Loss: 0.627806663513\n",
      "Epoch: 72 -> Test Accuracy: 69.59\n",
      "[73, 60] loss: 0.664\n",
      "[73, 120] loss: 0.656\n",
      "[73, 180] loss: 0.639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73, 240] loss: 0.655\n",
      "[73, 300] loss: 0.648\n",
      "[73, 360] loss: 0.655\n",
      "Epoch: 73 -> Loss: 0.552500426769\n",
      "Epoch: 73 -> Test Accuracy: 69.76\n",
      "[74, 60] loss: 0.642\n",
      "[74, 120] loss: 0.653\n",
      "[74, 180] loss: 0.640\n",
      "[74, 240] loss: 0.647\n",
      "[74, 300] loss: 0.657\n",
      "[74, 360] loss: 0.652\n",
      "Epoch: 74 -> Loss: 0.73958170414\n",
      "Epoch: 74 -> Test Accuracy: 69.96\n",
      "[75, 60] loss: 0.659\n",
      "[75, 120] loss: 0.647\n",
      "[75, 180] loss: 0.645\n",
      "[75, 240] loss: 0.632\n",
      "[75, 300] loss: 0.645\n",
      "[75, 360] loss: 0.651\n",
      "Epoch: 75 -> Loss: 0.78001922369\n",
      "Epoch: 75 -> Test Accuracy: 69.99\n",
      "[76, 60] loss: 0.645\n",
      "[76, 120] loss: 0.658\n",
      "[76, 180] loss: 0.647\n",
      "[76, 240] loss: 0.638\n",
      "[76, 300] loss: 0.628\n",
      "[76, 360] loss: 0.641\n",
      "Epoch: 76 -> Loss: 0.495900690556\n",
      "Epoch: 76 -> Test Accuracy: 69.73\n",
      "[77, 60] loss: 0.654\n",
      "[77, 120] loss: 0.656\n",
      "[77, 180] loss: 0.645\n",
      "[77, 240] loss: 0.634\n",
      "[77, 300] loss: 0.629\n",
      "[77, 360] loss: 0.654\n",
      "Epoch: 77 -> Loss: 0.716141700745\n",
      "Epoch: 77 -> Test Accuracy: 69.81\n",
      "[78, 60] loss: 0.650\n",
      "[78, 120] loss: 0.643\n",
      "[78, 180] loss: 0.638\n",
      "[78, 240] loss: 0.640\n",
      "[78, 300] loss: 0.638\n",
      "[78, 360] loss: 0.630\n",
      "Epoch: 78 -> Loss: 0.833547115326\n",
      "Epoch: 78 -> Test Accuracy: 69.68\n",
      "[79, 60] loss: 0.645\n",
      "[79, 120] loss: 0.622\n",
      "[79, 180] loss: 0.656\n",
      "[79, 240] loss: 0.641\n",
      "[79, 300] loss: 0.655\n",
      "[79, 360] loss: 0.619\n",
      "Epoch: 79 -> Loss: 0.851258635521\n",
      "Epoch: 79 -> Test Accuracy: 69.04\n",
      "[80, 60] loss: 0.636\n",
      "[80, 120] loss: 0.630\n",
      "[80, 180] loss: 0.628\n",
      "[80, 240] loss: 0.628\n",
      "[80, 300] loss: 0.641\n",
      "[80, 360] loss: 0.656\n",
      "Epoch: 80 -> Loss: 0.691383183002\n",
      "Epoch: 80 -> Test Accuracy: 69.2\n",
      "[81, 60] loss: 0.621\n",
      "[81, 120] loss: 0.640\n",
      "[81, 180] loss: 0.634\n",
      "[81, 240] loss: 0.628\n",
      "[81, 300] loss: 0.644\n",
      "[81, 360] loss: 0.653\n",
      "Epoch: 81 -> Loss: 0.55288875103\n",
      "Epoch: 81 -> Test Accuracy: 69.6\n",
      "[82, 60] loss: 0.632\n",
      "[82, 120] loss: 0.632\n",
      "[82, 180] loss: 0.637\n",
      "[82, 240] loss: 0.635\n",
      "[82, 300] loss: 0.636\n",
      "[82, 360] loss: 0.620\n",
      "Epoch: 82 -> Loss: 0.559693932533\n",
      "Epoch: 82 -> Test Accuracy: 69.46\n",
      "[83, 60] loss: 0.621\n",
      "[83, 120] loss: 0.636\n",
      "[83, 180] loss: 0.641\n",
      "[83, 240] loss: 0.634\n",
      "[83, 300] loss: 0.638\n",
      "[83, 360] loss: 0.636\n",
      "Epoch: 83 -> Loss: 0.759265065193\n",
      "Epoch: 83 -> Test Accuracy: 70.2\n",
      "[84, 60] loss: 0.622\n",
      "[84, 120] loss: 0.608\n",
      "[84, 180] loss: 0.630\n",
      "[84, 240] loss: 0.650\n",
      "[84, 300] loss: 0.642\n",
      "[84, 360] loss: 0.657\n",
      "Epoch: 84 -> Loss: 0.465485274792\n",
      "Epoch: 84 -> Test Accuracy: 69.55\n",
      "[85, 60] loss: 0.633\n",
      "[85, 120] loss: 0.639\n",
      "[85, 180] loss: 0.628\n",
      "[85, 240] loss: 0.619\n",
      "[85, 300] loss: 0.636\n",
      "[85, 360] loss: 0.647\n",
      "Epoch: 85 -> Loss: 0.601129412651\n",
      "Epoch: 85 -> Test Accuracy: 69.55\n",
      "[86, 60] loss: 0.628\n",
      "[86, 120] loss: 0.623\n",
      "[86, 180] loss: 0.617\n",
      "[86, 240] loss: 0.627\n",
      "[86, 300] loss: 0.602\n",
      "[86, 360] loss: 0.616\n",
      "Epoch: 86 -> Loss: 0.667302727699\n",
      "Epoch: 86 -> Test Accuracy: 70.29\n",
      "[87, 60] loss: 0.583\n",
      "[87, 120] loss: 0.611\n",
      "[87, 180] loss: 0.601\n",
      "[87, 240] loss: 0.624\n",
      "[87, 300] loss: 0.612\n",
      "[87, 360] loss: 0.607\n",
      "Epoch: 87 -> Loss: 0.71167576313\n",
      "Epoch: 87 -> Test Accuracy: 70.71\n",
      "[88, 60] loss: 0.593\n",
      "[88, 120] loss: 0.604\n",
      "[88, 180] loss: 0.610\n",
      "[88, 240] loss: 0.609\n",
      "[88, 300] loss: 0.613\n",
      "[88, 360] loss: 0.598\n",
      "Epoch: 88 -> Loss: 0.665674388409\n",
      "Epoch: 88 -> Test Accuracy: 70.65\n",
      "[89, 60] loss: 0.603\n",
      "[89, 120] loss: 0.599\n",
      "[89, 180] loss: 0.615\n",
      "[89, 240] loss: 0.595\n",
      "[89, 300] loss: 0.603\n",
      "[89, 360] loss: 0.607\n",
      "Epoch: 89 -> Loss: 0.581292688847\n",
      "Epoch: 89 -> Test Accuracy: 70.47\n",
      "[90, 60] loss: 0.604\n",
      "[90, 120] loss: 0.582\n",
      "[90, 180] loss: 0.598\n",
      "[90, 240] loss: 0.594\n",
      "[90, 300] loss: 0.615\n",
      "[90, 360] loss: 0.605\n",
      "Epoch: 90 -> Loss: 0.592544436455\n",
      "Epoch: 90 -> Test Accuracy: 70.63\n",
      "[91, 60] loss: 0.588\n",
      "[91, 120] loss: 0.617\n",
      "[91, 180] loss: 0.611\n",
      "[91, 240] loss: 0.596\n",
      "[91, 300] loss: 0.612\n",
      "[91, 360] loss: 0.607\n",
      "Epoch: 91 -> Loss: 0.50401955843\n",
      "Epoch: 91 -> Test Accuracy: 70.54\n",
      "[92, 60] loss: 0.598\n",
      "[92, 120] loss: 0.599\n",
      "[92, 180] loss: 0.617\n",
      "[92, 240] loss: 0.593\n",
      "[92, 300] loss: 0.591\n",
      "[92, 360] loss: 0.613\n",
      "Epoch: 92 -> Loss: 0.902883708477\n",
      "Epoch: 92 -> Test Accuracy: 70.31\n",
      "[93, 60] loss: 0.594\n",
      "[93, 120] loss: 0.593\n",
      "[93, 180] loss: 0.599\n",
      "[93, 240] loss: 0.591\n",
      "[93, 300] loss: 0.599\n",
      "[93, 360] loss: 0.609\n",
      "Epoch: 93 -> Loss: 0.404916703701\n",
      "Epoch: 93 -> Test Accuracy: 70.7\n",
      "[94, 60] loss: 0.603\n",
      "[94, 120] loss: 0.597\n",
      "[94, 180] loss: 0.595\n",
      "[94, 240] loss: 0.606\n",
      "[94, 300] loss: 0.595\n",
      "[94, 360] loss: 0.594\n",
      "Epoch: 94 -> Loss: 0.679506182671\n",
      "Epoch: 94 -> Test Accuracy: 70.42\n",
      "[95, 60] loss: 0.594\n",
      "[95, 120] loss: 0.588\n",
      "[95, 180] loss: 0.594\n",
      "[95, 240] loss: 0.609\n",
      "[95, 300] loss: 0.597\n",
      "[95, 360] loss: 0.593\n",
      "Epoch: 95 -> Loss: 0.673249721527\n",
      "Epoch: 95 -> Test Accuracy: 70.47\n",
      "[96, 60] loss: 0.620\n",
      "[96, 120] loss: 0.600\n",
      "[96, 180] loss: 0.592\n",
      "[96, 240] loss: 0.599\n",
      "[96, 300] loss: 0.588\n",
      "[96, 360] loss: 0.601\n",
      "Epoch: 96 -> Loss: 0.730581820011\n",
      "Epoch: 96 -> Test Accuracy: 70.72\n",
      "[97, 60] loss: 0.614\n",
      "[97, 120] loss: 0.587\n",
      "[97, 180] loss: 0.607\n",
      "[97, 240] loss: 0.588\n",
      "[97, 300] loss: 0.593\n",
      "[97, 360] loss: 0.591\n",
      "Epoch: 97 -> Loss: 0.729669570923\n",
      "Epoch: 97 -> Test Accuracy: 70.33\n",
      "[98, 60] loss: 0.595\n",
      "[98, 120] loss: 0.582\n",
      "[98, 180] loss: 0.591\n",
      "[98, 240] loss: 0.611\n",
      "[98, 300] loss: 0.583\n",
      "[98, 360] loss: 0.602\n",
      "Epoch: 98 -> Loss: 0.569603741169\n",
      "Epoch: 98 -> Test Accuracy: 70.58\n",
      "[99, 60] loss: 0.593\n",
      "[99, 120] loss: 0.613\n",
      "[99, 180] loss: 0.582\n",
      "[99, 240] loss: 0.591\n",
      "[99, 300] loss: 0.584\n",
      "[99, 360] loss: 0.585\n",
      "Epoch: 99 -> Loss: 0.541732549667\n",
      "Epoch: 99 -> Test Accuracy: 70.52\n",
      "[100, 60] loss: 0.592\n",
      "[100, 120] loss: 0.580\n",
      "[100, 180] loss: 0.604\n",
      "[100, 240] loss: 0.612\n",
      "[100, 300] loss: 0.586\n",
      "[100, 360] loss: 0.589\n",
      "Epoch: 100 -> Loss: 0.797972559929\n",
      "Epoch: 100 -> Test Accuracy: 70.44\n",
      "Finished Training\n",
      "[1, 60] loss: 2.189\n",
      "[1, 120] loss: 2.046\n",
      "[1, 180] loss: 1.999\n",
      "[1, 240] loss: 1.964\n",
      "[1, 300] loss: 1.937\n",
      "[1, 360] loss: 1.923\n",
      "Epoch: 1 -> Loss: 1.88249337673\n",
      "Epoch: 1 -> Test Accuracy: 27.38\n",
      "[2, 60] loss: 1.903\n",
      "[2, 120] loss: 1.902\n",
      "[2, 180] loss: 1.883\n",
      "[2, 240] loss: 1.880\n",
      "[2, 300] loss: 1.868\n",
      "[2, 360] loss: 1.879\n",
      "Epoch: 2 -> Loss: 1.80979859829\n",
      "Epoch: 2 -> Test Accuracy: 29.06\n",
      "[3, 60] loss: 1.853\n",
      "[3, 120] loss: 1.854\n",
      "[3, 180] loss: 1.844\n",
      "[3, 240] loss: 1.844\n",
      "[3, 300] loss: 1.848\n",
      "[3, 360] loss: 1.844\n",
      "Epoch: 3 -> Loss: 1.88934612274\n",
      "Epoch: 3 -> Test Accuracy: 29.42\n",
      "[4, 60] loss: 1.830\n",
      "[4, 120] loss: 1.844\n",
      "[4, 180] loss: 1.817\n",
      "[4, 240] loss: 1.813\n",
      "[4, 300] loss: 1.827\n",
      "[4, 360] loss: 1.807\n",
      "Epoch: 4 -> Loss: 1.80609321594\n",
      "Epoch: 4 -> Test Accuracy: 31.01\n",
      "[5, 60] loss: 1.830\n",
      "[5, 120] loss: 1.800\n",
      "[5, 180] loss: 1.801\n",
      "[5, 240] loss: 1.798\n",
      "[5, 300] loss: 1.823\n",
      "[5, 360] loss: 1.801\n",
      "Epoch: 5 -> Loss: 1.90677320957\n",
      "Epoch: 5 -> Test Accuracy: 30.58\n",
      "[6, 60] loss: 1.812\n",
      "[6, 120] loss: 1.805\n",
      "[6, 180] loss: 1.802\n",
      "[6, 240] loss: 1.802\n",
      "[6, 300] loss: 1.792\n",
      "[6, 360] loss: 1.814\n",
      "Epoch: 6 -> Loss: 1.84435176849\n",
      "Epoch: 6 -> Test Accuracy: 29.8\n",
      "[7, 60] loss: 1.792\n",
      "[7, 120] loss: 1.788\n",
      "[7, 180] loss: 1.792\n",
      "[7, 240] loss: 1.797\n",
      "[7, 300] loss: 1.777\n",
      "[7, 360] loss: 1.796\n",
      "Epoch: 7 -> Loss: 1.92452585697\n",
      "Epoch: 7 -> Test Accuracy: 29.71\n",
      "[8, 60] loss: 1.782\n",
      "[8, 120] loss: 1.776\n",
      "[8, 180] loss: 1.776\n",
      "[8, 240] loss: 1.775\n",
      "[8, 300] loss: 1.780\n",
      "[8, 360] loss: 1.776\n",
      "Epoch: 8 -> Loss: 1.73509061337\n",
      "Epoch: 8 -> Test Accuracy: 29.99\n",
      "[9, 60] loss: 1.768\n",
      "[9, 120] loss: 1.780\n",
      "[9, 180] loss: 1.777\n",
      "[9, 240] loss: 1.782\n",
      "[9, 300] loss: 1.780\n",
      "[9, 360] loss: 1.782\n",
      "Epoch: 9 -> Loss: 1.89953935146\n",
      "Epoch: 9 -> Test Accuracy: 31.22\n",
      "[10, 60] loss: 1.766\n",
      "[10, 120] loss: 1.776\n",
      "[10, 180] loss: 1.763\n",
      "[10, 240] loss: 1.763\n",
      "[10, 300] loss: 1.787\n",
      "[10, 360] loss: 1.770\n",
      "Epoch: 10 -> Loss: 1.68875849247\n",
      "Epoch: 10 -> Test Accuracy: 33.64\n",
      "[11, 60] loss: 1.769\n",
      "[11, 120] loss: 1.784\n",
      "[11, 180] loss: 1.776\n",
      "[11, 240] loss: 1.747\n",
      "[11, 300] loss: 1.774\n",
      "[11, 360] loss: 1.763\n",
      "Epoch: 11 -> Loss: 1.69922375679\n",
      "Epoch: 11 -> Test Accuracy: 32.03\n",
      "[12, 60] loss: 1.760\n",
      "[12, 120] loss: 1.776\n",
      "[12, 180] loss: 1.765\n",
      "[12, 240] loss: 1.763\n",
      "[12, 300] loss: 1.745\n",
      "[12, 360] loss: 1.771\n",
      "Epoch: 12 -> Loss: 1.68302345276\n",
      "Epoch: 12 -> Test Accuracy: 31.9\n",
      "[13, 60] loss: 1.756\n",
      "[13, 120] loss: 1.771\n",
      "[13, 180] loss: 1.754\n",
      "[13, 240] loss: 1.749\n",
      "[13, 300] loss: 1.756\n",
      "[13, 360] loss: 1.747\n",
      "Epoch: 13 -> Loss: 1.89141499996\n",
      "Epoch: 13 -> Test Accuracy: 33.06\n",
      "[14, 60] loss: 1.764\n",
      "[14, 120] loss: 1.749\n",
      "[14, 180] loss: 1.771\n",
      "[14, 240] loss: 1.769\n",
      "[14, 300] loss: 1.745\n",
      "[14, 360] loss: 1.754\n",
      "Epoch: 14 -> Loss: 1.79553639889\n",
      "Epoch: 14 -> Test Accuracy: 33.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 60] loss: 1.738\n",
      "[15, 120] loss: 1.762\n",
      "[15, 180] loss: 1.744\n",
      "[15, 240] loss: 1.766\n",
      "[15, 300] loss: 1.744\n",
      "[15, 360] loss: 1.760\n",
      "Epoch: 15 -> Loss: 1.63150048256\n",
      "Epoch: 15 -> Test Accuracy: 30.85\n",
      "[16, 60] loss: 1.738\n",
      "[16, 120] loss: 1.755\n",
      "[16, 180] loss: 1.754\n",
      "[16, 240] loss: 1.741\n",
      "[16, 300] loss: 1.751\n",
      "[16, 360] loss: 1.742\n",
      "Epoch: 16 -> Loss: 1.6545650959\n",
      "Epoch: 16 -> Test Accuracy: 33.1\n",
      "[17, 60] loss: 1.751\n",
      "[17, 120] loss: 1.744\n",
      "[17, 180] loss: 1.738\n",
      "[17, 240] loss: 1.754\n",
      "[17, 300] loss: 1.748\n",
      "[17, 360] loss: 1.735\n",
      "Epoch: 17 -> Loss: 1.86130905151\n",
      "Epoch: 17 -> Test Accuracy: 32.88\n",
      "[18, 60] loss: 1.753\n",
      "[18, 120] loss: 1.755\n",
      "[18, 180] loss: 1.744\n",
      "[18, 240] loss: 1.749\n",
      "[18, 300] loss: 1.743\n",
      "[18, 360] loss: 1.744\n",
      "Epoch: 18 -> Loss: 1.78378236294\n",
      "Epoch: 18 -> Test Accuracy: 32.81\n",
      "[19, 60] loss: 1.746\n",
      "[19, 120] loss: 1.720\n",
      "[19, 180] loss: 1.755\n",
      "[19, 240] loss: 1.719\n",
      "[19, 300] loss: 1.747\n",
      "[19, 360] loss: 1.732\n",
      "Epoch: 19 -> Loss: 1.83909916878\n",
      "Epoch: 19 -> Test Accuracy: 33.77\n",
      "[20, 60] loss: 1.725\n",
      "[20, 120] loss: 1.750\n",
      "[20, 180] loss: 1.729\n",
      "[20, 240] loss: 1.754\n",
      "[20, 300] loss: 1.747\n",
      "[20, 360] loss: 1.756\n",
      "Epoch: 20 -> Loss: 1.69642293453\n",
      "Epoch: 20 -> Test Accuracy: 33.36\n",
      "[21, 60] loss: 1.739\n",
      "[21, 120] loss: 1.742\n",
      "[21, 180] loss: 1.754\n",
      "[21, 240] loss: 1.744\n",
      "[21, 300] loss: 1.736\n",
      "[21, 360] loss: 1.757\n",
      "Epoch: 21 -> Loss: 1.77270853519\n",
      "Epoch: 21 -> Test Accuracy: 33.15\n",
      "[22, 60] loss: 1.733\n",
      "[22, 120] loss: 1.746\n",
      "[22, 180] loss: 1.744\n",
      "[22, 240] loss: 1.709\n",
      "[22, 300] loss: 1.741\n",
      "[22, 360] loss: 1.741\n",
      "Epoch: 22 -> Loss: 1.8559896946\n",
      "Epoch: 22 -> Test Accuracy: 32.48\n",
      "[23, 60] loss: 1.734\n",
      "[23, 120] loss: 1.736\n",
      "[23, 180] loss: 1.744\n",
      "[23, 240] loss: 1.734\n",
      "[23, 300] loss: 1.742\n",
      "[23, 360] loss: 1.735\n",
      "Epoch: 23 -> Loss: 1.64544773102\n",
      "Epoch: 23 -> Test Accuracy: 33.35\n",
      "[24, 60] loss: 1.744\n",
      "[24, 120] loss: 1.732\n",
      "[24, 180] loss: 1.732\n",
      "[24, 240] loss: 1.747\n",
      "[24, 300] loss: 1.737\n",
      "[24, 360] loss: 1.729\n",
      "Epoch: 24 -> Loss: 1.67332649231\n",
      "Epoch: 24 -> Test Accuracy: 32.57\n",
      "[25, 60] loss: 1.727\n",
      "[25, 120] loss: 1.729\n",
      "[25, 180] loss: 1.722\n",
      "[25, 240] loss: 1.743\n",
      "[25, 300] loss: 1.738\n",
      "[25, 360] loss: 1.748\n",
      "Epoch: 25 -> Loss: 1.68940126896\n",
      "Epoch: 25 -> Test Accuracy: 33.03\n",
      "[26, 60] loss: 1.736\n",
      "[26, 120] loss: 1.725\n",
      "[26, 180] loss: 1.735\n",
      "[26, 240] loss: 1.738\n",
      "[26, 300] loss: 1.732\n",
      "[26, 360] loss: 1.747\n",
      "Epoch: 26 -> Loss: 1.70334219933\n",
      "Epoch: 26 -> Test Accuracy: 33.7\n",
      "[27, 60] loss: 1.741\n",
      "[27, 120] loss: 1.714\n",
      "[27, 180] loss: 1.742\n",
      "[27, 240] loss: 1.723\n",
      "[27, 300] loss: 1.735\n",
      "[27, 360] loss: 1.732\n",
      "Epoch: 27 -> Loss: 1.79622244835\n",
      "Epoch: 27 -> Test Accuracy: 33.2\n",
      "[28, 60] loss: 1.730\n",
      "[28, 120] loss: 1.732\n",
      "[28, 180] loss: 1.732\n",
      "[28, 240] loss: 1.724\n",
      "[28, 300] loss: 1.734\n",
      "[28, 360] loss: 1.740\n",
      "Epoch: 28 -> Loss: 1.70780348778\n",
      "Epoch: 28 -> Test Accuracy: 32.67\n",
      "[29, 60] loss: 1.722\n",
      "[29, 120] loss: 1.748\n",
      "[29, 180] loss: 1.734\n",
      "[29, 240] loss: 1.723\n",
      "[29, 300] loss: 1.746\n",
      "[29, 360] loss: 1.716\n",
      "Epoch: 29 -> Loss: 1.76461672783\n",
      "Epoch: 29 -> Test Accuracy: 33.36\n",
      "[30, 60] loss: 1.727\n",
      "[30, 120] loss: 1.737\n",
      "[30, 180] loss: 1.749\n",
      "[30, 240] loss: 1.733\n",
      "[30, 300] loss: 1.725\n",
      "[30, 360] loss: 1.719\n",
      "Epoch: 30 -> Loss: 1.72890532017\n",
      "Epoch: 30 -> Test Accuracy: 32.97\n",
      "[31, 60] loss: 1.737\n",
      "[31, 120] loss: 1.724\n",
      "[31, 180] loss: 1.738\n",
      "[31, 240] loss: 1.723\n",
      "[31, 300] loss: 1.731\n",
      "[31, 360] loss: 1.718\n",
      "Epoch: 31 -> Loss: 1.71867501736\n",
      "Epoch: 31 -> Test Accuracy: 32.19\n",
      "[32, 60] loss: 1.718\n",
      "[32, 120] loss: 1.744\n",
      "[32, 180] loss: 1.719\n",
      "[32, 240] loss: 1.722\n",
      "[32, 300] loss: 1.734\n",
      "[32, 360] loss: 1.744\n",
      "Epoch: 32 -> Loss: 1.68186891079\n",
      "Epoch: 32 -> Test Accuracy: 33.12\n",
      "[33, 60] loss: 1.707\n",
      "[33, 120] loss: 1.714\n",
      "[33, 180] loss: 1.735\n",
      "[33, 240] loss: 1.723\n",
      "[33, 300] loss: 1.743\n",
      "[33, 360] loss: 1.744\n",
      "Epoch: 33 -> Loss: 1.66867995262\n",
      "Epoch: 33 -> Test Accuracy: 31.47\n",
      "[34, 60] loss: 1.730\n",
      "[34, 120] loss: 1.734\n",
      "[34, 180] loss: 1.718\n",
      "[34, 240] loss: 1.720\n",
      "[34, 300] loss: 1.735\n",
      "[34, 360] loss: 1.720\n",
      "Epoch: 34 -> Loss: 1.69770205021\n",
      "Epoch: 34 -> Test Accuracy: 34.31\n",
      "[35, 60] loss: 1.732\n",
      "[35, 120] loss: 1.711\n",
      "[35, 180] loss: 1.727\n",
      "[35, 240] loss: 1.729\n",
      "[35, 300] loss: 1.734\n",
      "[35, 360] loss: 1.741\n",
      "Epoch: 35 -> Loss: 1.6693341732\n",
      "Epoch: 35 -> Test Accuracy: 32.28\n",
      "[36, 60] loss: 1.681\n",
      "[36, 120] loss: 1.650\n",
      "[36, 180] loss: 1.654\n",
      "[36, 240] loss: 1.626\n",
      "[36, 300] loss: 1.642\n",
      "[36, 360] loss: 1.636\n",
      "Epoch: 36 -> Loss: 1.72770571709\n",
      "Epoch: 36 -> Test Accuracy: 36.28\n",
      "[37, 60] loss: 1.609\n",
      "[37, 120] loss: 1.638\n",
      "[37, 180] loss: 1.624\n",
      "[37, 240] loss: 1.611\n",
      "[37, 300] loss: 1.630\n",
      "[37, 360] loss: 1.626\n",
      "Epoch: 37 -> Loss: 1.76350688934\n",
      "Epoch: 37 -> Test Accuracy: 37.0\n",
      "[38, 60] loss: 1.611\n",
      "[38, 120] loss: 1.616\n",
      "[38, 180] loss: 1.642\n",
      "[38, 240] loss: 1.611\n",
      "[38, 300] loss: 1.615\n",
      "[38, 360] loss: 1.631\n",
      "Epoch: 38 -> Loss: 1.62778508663\n",
      "Epoch: 38 -> Test Accuracy: 37.14\n",
      "[39, 60] loss: 1.601\n",
      "[39, 120] loss: 1.622\n",
      "[39, 180] loss: 1.628\n",
      "[39, 240] loss: 1.614\n",
      "[39, 300] loss: 1.615\n",
      "[39, 360] loss: 1.618\n",
      "Epoch: 39 -> Loss: 1.67052018642\n",
      "Epoch: 39 -> Test Accuracy: 37.38\n",
      "[40, 60] loss: 1.595\n",
      "[40, 120] loss: 1.620\n",
      "[40, 180] loss: 1.617\n",
      "[40, 240] loss: 1.617\n",
      "[40, 300] loss: 1.622\n",
      "[40, 360] loss: 1.622\n",
      "Epoch: 40 -> Loss: 1.67618441582\n",
      "Epoch: 40 -> Test Accuracy: 36.96\n",
      "[41, 60] loss: 1.619\n",
      "[41, 120] loss: 1.614\n",
      "[41, 180] loss: 1.616\n",
      "[41, 240] loss: 1.612\n",
      "[41, 300] loss: 1.610\n",
      "[41, 360] loss: 1.610\n",
      "Epoch: 41 -> Loss: 1.46029174328\n",
      "Epoch: 41 -> Test Accuracy: 37.72\n",
      "[42, 60] loss: 1.596\n",
      "[42, 120] loss: 1.594\n",
      "[42, 180] loss: 1.625\n",
      "[42, 240] loss: 1.608\n",
      "[42, 300] loss: 1.614\n",
      "[42, 360] loss: 1.619\n",
      "Epoch: 42 -> Loss: 1.61785030365\n",
      "Epoch: 42 -> Test Accuracy: 37.11\n",
      "[43, 60] loss: 1.629\n",
      "[43, 120] loss: 1.593\n",
      "[43, 180] loss: 1.615\n",
      "[43, 240] loss: 1.629\n",
      "[43, 300] loss: 1.601\n",
      "[43, 360] loss: 1.592\n",
      "Epoch: 43 -> Loss: 1.36876475811\n",
      "Epoch: 43 -> Test Accuracy: 37.99\n",
      "[44, 60] loss: 1.615\n",
      "[44, 120] loss: 1.619\n",
      "[44, 180] loss: 1.613\n",
      "[44, 240] loss: 1.603\n",
      "[44, 300] loss: 1.600\n",
      "[44, 360] loss: 1.626\n",
      "Epoch: 44 -> Loss: 1.47089362144\n",
      "Epoch: 44 -> Test Accuracy: 36.78\n",
      "[45, 60] loss: 1.612\n",
      "[45, 120] loss: 1.613\n",
      "[45, 180] loss: 1.608\n",
      "[45, 240] loss: 1.616\n",
      "[45, 300] loss: 1.615\n",
      "[45, 360] loss: 1.620\n",
      "Epoch: 45 -> Loss: 1.5445663929\n",
      "Epoch: 45 -> Test Accuracy: 37.93\n",
      "[46, 60] loss: 1.611\n",
      "[46, 120] loss: 1.602\n",
      "[46, 180] loss: 1.614\n",
      "[46, 240] loss: 1.615\n",
      "[46, 300] loss: 1.622\n",
      "[46, 360] loss: 1.625\n",
      "Epoch: 46 -> Loss: 1.67028582096\n",
      "Epoch: 46 -> Test Accuracy: 36.1\n",
      "[47, 60] loss: 1.598\n",
      "[47, 120] loss: 1.606\n",
      "[47, 180] loss: 1.616\n",
      "[47, 240] loss: 1.610\n",
      "[47, 300] loss: 1.624\n",
      "[47, 360] loss: 1.610\n",
      "Epoch: 47 -> Loss: 1.64715349674\n",
      "Epoch: 47 -> Test Accuracy: 36.98\n",
      "[48, 60] loss: 1.606\n",
      "[48, 120] loss: 1.600\n",
      "[48, 180] loss: 1.625\n",
      "[48, 240] loss: 1.609\n",
      "[48, 300] loss: 1.620\n",
      "[48, 360] loss: 1.620\n",
      "Epoch: 48 -> Loss: 1.56003057957\n",
      "Epoch: 48 -> Test Accuracy: 37.58\n",
      "[49, 60] loss: 1.598\n",
      "[49, 120] loss: 1.609\n",
      "[49, 180] loss: 1.603\n",
      "[49, 240] loss: 1.634\n",
      "[49, 300] loss: 1.623\n",
      "[49, 360] loss: 1.597\n",
      "Epoch: 49 -> Loss: 1.72079348564\n",
      "Epoch: 49 -> Test Accuracy: 37.41\n",
      "[50, 60] loss: 1.614\n",
      "[50, 120] loss: 1.622\n",
      "[50, 180] loss: 1.607\n",
      "[50, 240] loss: 1.612\n",
      "[50, 300] loss: 1.595\n",
      "[50, 360] loss: 1.600\n",
      "Epoch: 50 -> Loss: 1.54881215096\n",
      "Epoch: 50 -> Test Accuracy: 37.91\n",
      "[51, 60] loss: 1.595\n",
      "[51, 120] loss: 1.621\n",
      "[51, 180] loss: 1.612\n",
      "[51, 240] loss: 1.613\n",
      "[51, 300] loss: 1.614\n",
      "[51, 360] loss: 1.609\n",
      "Epoch: 51 -> Loss: 1.60657954216\n",
      "Epoch: 51 -> Test Accuracy: 36.79\n",
      "[52, 60] loss: 1.612\n",
      "[52, 120] loss: 1.602\n",
      "[52, 180] loss: 1.605\n",
      "[52, 240] loss: 1.612\n",
      "[52, 300] loss: 1.626\n",
      "[52, 360] loss: 1.600\n",
      "Epoch: 52 -> Loss: 1.70801830292\n",
      "Epoch: 52 -> Test Accuracy: 37.13\n",
      "[53, 60] loss: 1.609\n",
      "[53, 120] loss: 1.605\n",
      "[53, 180] loss: 1.616\n",
      "[53, 240] loss: 1.626\n",
      "[53, 300] loss: 1.625\n",
      "[53, 360] loss: 1.629\n",
      "Epoch: 53 -> Loss: 1.46061682701\n",
      "Epoch: 53 -> Test Accuracy: 37.26\n",
      "[54, 60] loss: 1.593\n",
      "[54, 120] loss: 1.627\n",
      "[54, 180] loss: 1.589\n",
      "[54, 240] loss: 1.619\n",
      "[54, 300] loss: 1.604\n",
      "[54, 360] loss: 1.617\n",
      "Epoch: 54 -> Loss: 1.83787369728\n",
      "Epoch: 54 -> Test Accuracy: 36.78\n",
      "[55, 60] loss: 1.611\n",
      "[55, 120] loss: 1.611\n",
      "[55, 180] loss: 1.631\n",
      "[55, 240] loss: 1.594\n",
      "[55, 300] loss: 1.585\n",
      "[55, 360] loss: 1.619\n",
      "Epoch: 55 -> Loss: 1.72789216042\n",
      "Epoch: 55 -> Test Accuracy: 37.25\n",
      "[56, 60] loss: 1.601\n",
      "[56, 120] loss: 1.612\n",
      "[56, 180] loss: 1.604\n",
      "[56, 240] loss: 1.606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56, 300] loss: 1.599\n",
      "[56, 360] loss: 1.624\n",
      "Epoch: 56 -> Loss: 1.63798499107\n",
      "Epoch: 56 -> Test Accuracy: 37.71\n",
      "[57, 60] loss: 1.608\n",
      "[57, 120] loss: 1.610\n",
      "[57, 180] loss: 1.597\n",
      "[57, 240] loss: 1.602\n",
      "[57, 300] loss: 1.597\n",
      "[57, 360] loss: 1.610\n",
      "Epoch: 57 -> Loss: 1.68780684471\n",
      "Epoch: 57 -> Test Accuracy: 37.23\n",
      "[58, 60] loss: 1.602\n",
      "[58, 120] loss: 1.597\n",
      "[58, 180] loss: 1.611\n",
      "[58, 240] loss: 1.611\n",
      "[58, 300] loss: 1.606\n",
      "[58, 360] loss: 1.603\n",
      "Epoch: 58 -> Loss: 1.83146572113\n",
      "Epoch: 58 -> Test Accuracy: 37.49\n",
      "[59, 60] loss: 1.617\n",
      "[59, 120] loss: 1.606\n",
      "[59, 180] loss: 1.600\n",
      "[59, 240] loss: 1.610\n",
      "[59, 300] loss: 1.600\n",
      "[59, 360] loss: 1.604\n",
      "Epoch: 59 -> Loss: 1.7534917593\n",
      "Epoch: 59 -> Test Accuracy: 37.59\n",
      "[60, 60] loss: 1.588\n",
      "[60, 120] loss: 1.603\n",
      "[60, 180] loss: 1.600\n",
      "[60, 240] loss: 1.599\n",
      "[60, 300] loss: 1.597\n",
      "[60, 360] loss: 1.604\n",
      "Epoch: 60 -> Loss: 1.67918455601\n",
      "Epoch: 60 -> Test Accuracy: 37.13\n",
      "[61, 60] loss: 1.586\n",
      "[61, 120] loss: 1.605\n",
      "[61, 180] loss: 1.600\n",
      "[61, 240] loss: 1.615\n",
      "[61, 300] loss: 1.589\n",
      "[61, 360] loss: 1.618\n",
      "Epoch: 61 -> Loss: 1.60233998299\n",
      "Epoch: 61 -> Test Accuracy: 36.64\n",
      "[62, 60] loss: 1.609\n",
      "[62, 120] loss: 1.582\n",
      "[62, 180] loss: 1.626\n",
      "[62, 240] loss: 1.597\n",
      "[62, 300] loss: 1.602\n",
      "[62, 360] loss: 1.604\n",
      "Epoch: 62 -> Loss: 1.60793805122\n",
      "Epoch: 62 -> Test Accuracy: 37.01\n",
      "[63, 60] loss: 1.603\n",
      "[63, 120] loss: 1.602\n",
      "[63, 180] loss: 1.601\n",
      "[63, 240] loss: 1.601\n",
      "[63, 300] loss: 1.607\n",
      "[63, 360] loss: 1.587\n",
      "Epoch: 63 -> Loss: 1.6692006588\n",
      "Epoch: 63 -> Test Accuracy: 37.36\n",
      "[64, 60] loss: 1.603\n",
      "[64, 120] loss: 1.605\n",
      "[64, 180] loss: 1.608\n",
      "[64, 240] loss: 1.602\n",
      "[64, 300] loss: 1.614\n",
      "[64, 360] loss: 1.593\n",
      "Epoch: 64 -> Loss: 1.81000781059\n",
      "Epoch: 64 -> Test Accuracy: 37.62\n",
      "[65, 60] loss: 1.606\n",
      "[65, 120] loss: 1.605\n",
      "[65, 180] loss: 1.610\n",
      "[65, 240] loss: 1.581\n",
      "[65, 300] loss: 1.608\n",
      "[65, 360] loss: 1.596\n",
      "Epoch: 65 -> Loss: 1.55412745476\n",
      "Epoch: 65 -> Test Accuracy: 36.97\n",
      "[66, 60] loss: 1.602\n",
      "[66, 120] loss: 1.575\n",
      "[66, 180] loss: 1.606\n",
      "[66, 240] loss: 1.614\n",
      "[66, 300] loss: 1.581\n",
      "[66, 360] loss: 1.582\n",
      "Epoch: 66 -> Loss: 1.64800012112\n",
      "Epoch: 66 -> Test Accuracy: 37.94\n",
      "[67, 60] loss: 1.615\n",
      "[67, 120] loss: 1.595\n",
      "[67, 180] loss: 1.607\n",
      "[67, 240] loss: 1.609\n",
      "[67, 300] loss: 1.600\n",
      "[67, 360] loss: 1.605\n",
      "Epoch: 67 -> Loss: 1.56780862808\n",
      "Epoch: 67 -> Test Accuracy: 38.46\n",
      "[68, 60] loss: 1.583\n",
      "[68, 120] loss: 1.600\n",
      "[68, 180] loss: 1.600\n",
      "[68, 240] loss: 1.597\n",
      "[68, 300] loss: 1.596\n",
      "[68, 360] loss: 1.596\n",
      "Epoch: 68 -> Loss: 1.65425896645\n",
      "Epoch: 68 -> Test Accuracy: 37.79\n",
      "[69, 60] loss: 1.582\n",
      "[69, 120] loss: 1.617\n",
      "[69, 180] loss: 1.602\n",
      "[69, 240] loss: 1.596\n",
      "[69, 300] loss: 1.592\n",
      "[69, 360] loss: 1.600\n",
      "Epoch: 69 -> Loss: 1.79065299034\n",
      "Epoch: 69 -> Test Accuracy: 37.24\n",
      "[70, 60] loss: 1.591\n",
      "[70, 120] loss: 1.598\n",
      "[70, 180] loss: 1.607\n",
      "[70, 240] loss: 1.596\n",
      "[70, 300] loss: 1.592\n",
      "[70, 360] loss: 1.597\n",
      "Epoch: 70 -> Loss: 1.69364714622\n",
      "Epoch: 70 -> Test Accuracy: 36.97\n",
      "[71, 60] loss: 1.574\n",
      "[71, 120] loss: 1.555\n",
      "[71, 180] loss: 1.545\n",
      "[71, 240] loss: 1.536\n",
      "[71, 300] loss: 1.551\n",
      "[71, 360] loss: 1.531\n",
      "Epoch: 71 -> Loss: 1.52729034424\n",
      "Epoch: 71 -> Test Accuracy: 39.88\n",
      "[72, 60] loss: 1.528\n",
      "[72, 120] loss: 1.535\n",
      "[72, 180] loss: 1.521\n",
      "[72, 240] loss: 1.539\n",
      "[72, 300] loss: 1.540\n",
      "[72, 360] loss: 1.526\n",
      "Epoch: 72 -> Loss: 1.59483361244\n",
      "Epoch: 72 -> Test Accuracy: 40.37\n",
      "[73, 60] loss: 1.530\n",
      "[73, 120] loss: 1.540\n",
      "[73, 180] loss: 1.531\n",
      "[73, 240] loss: 1.514\n",
      "[73, 300] loss: 1.530\n",
      "[73, 360] loss: 1.523\n",
      "Epoch: 73 -> Loss: 1.63550508022\n",
      "Epoch: 73 -> Test Accuracy: 40.35\n",
      "[74, 60] loss: 1.536\n",
      "[74, 120] loss: 1.522\n",
      "[74, 180] loss: 1.533\n",
      "[74, 240] loss: 1.523\n",
      "[74, 300] loss: 1.509\n",
      "[74, 360] loss: 1.536\n",
      "Epoch: 74 -> Loss: 1.57332181931\n",
      "Epoch: 74 -> Test Accuracy: 40.9\n",
      "[75, 60] loss: 1.511\n",
      "[75, 120] loss: 1.523\n",
      "[75, 180] loss: 1.532\n",
      "[75, 240] loss: 1.527\n",
      "[75, 300] loss: 1.507\n",
      "[75, 360] loss: 1.500\n",
      "Epoch: 75 -> Loss: 1.35932803154\n",
      "Epoch: 75 -> Test Accuracy: 40.26\n",
      "[76, 60] loss: 1.510\n",
      "[76, 120] loss: 1.521\n",
      "[76, 180] loss: 1.528\n",
      "[76, 240] loss: 1.526\n",
      "[76, 300] loss: 1.518\n",
      "[76, 360] loss: 1.518\n",
      "Epoch: 76 -> Loss: 1.43418467045\n",
      "Epoch: 76 -> Test Accuracy: 40.04\n",
      "[77, 60] loss: 1.522\n",
      "[77, 120] loss: 1.519\n",
      "[77, 180] loss: 1.531\n",
      "[77, 240] loss: 1.502\n",
      "[77, 300] loss: 1.510\n",
      "[77, 360] loss: 1.502\n",
      "Epoch: 77 -> Loss: 1.55506539345\n",
      "Epoch: 77 -> Test Accuracy: 39.91\n",
      "[78, 60] loss: 1.522\n",
      "[78, 120] loss: 1.517\n",
      "[78, 180] loss: 1.516\n",
      "[78, 240] loss: 1.490\n",
      "[78, 300] loss: 1.511\n",
      "[78, 360] loss: 1.524\n",
      "Epoch: 78 -> Loss: 1.40043187141\n",
      "Epoch: 78 -> Test Accuracy: 40.86\n",
      "[79, 60] loss: 1.517\n",
      "[79, 120] loss: 1.523\n",
      "[79, 180] loss: 1.501\n",
      "[79, 240] loss: 1.526\n",
      "[79, 300] loss: 1.515\n",
      "[79, 360] loss: 1.514\n",
      "Epoch: 79 -> Loss: 1.50434327126\n",
      "Epoch: 79 -> Test Accuracy: 40.46\n",
      "[80, 60] loss: 1.522\n",
      "[80, 120] loss: 1.521\n",
      "[80, 180] loss: 1.532\n",
      "[80, 240] loss: 1.485\n",
      "[80, 300] loss: 1.526\n",
      "[80, 360] loss: 1.510\n",
      "Epoch: 80 -> Loss: 1.36194777489\n",
      "Epoch: 80 -> Test Accuracy: 40.27\n",
      "[81, 60] loss: 1.519\n",
      "[81, 120] loss: 1.518\n",
      "[81, 180] loss: 1.500\n",
      "[81, 240] loss: 1.530\n",
      "[81, 300] loss: 1.499\n",
      "[81, 360] loss: 1.516\n",
      "Epoch: 81 -> Loss: 1.69014286995\n",
      "Epoch: 81 -> Test Accuracy: 40.33\n",
      "[82, 60] loss: 1.492\n",
      "[82, 120] loss: 1.491\n",
      "[82, 180] loss: 1.519\n",
      "[82, 240] loss: 1.524\n",
      "[82, 300] loss: 1.528\n",
      "[82, 360] loss: 1.511\n",
      "Epoch: 82 -> Loss: 1.58668267727\n",
      "Epoch: 82 -> Test Accuracy: 40.18\n",
      "[83, 60] loss: 1.515\n",
      "[83, 120] loss: 1.494\n",
      "[83, 180] loss: 1.505\n",
      "[83, 240] loss: 1.501\n",
      "[83, 300] loss: 1.520\n",
      "[83, 360] loss: 1.515\n",
      "Epoch: 83 -> Loss: 1.30659306049\n",
      "Epoch: 83 -> Test Accuracy: 40.35\n",
      "[84, 60] loss: 1.526\n",
      "[84, 120] loss: 1.527\n",
      "[84, 180] loss: 1.519\n",
      "[84, 240] loss: 1.492\n",
      "[84, 300] loss: 1.534\n",
      "[84, 360] loss: 1.502\n",
      "Epoch: 84 -> Loss: 1.46986293793\n",
      "Epoch: 84 -> Test Accuracy: 40.04\n",
      "[85, 60] loss: 1.530\n",
      "[85, 120] loss: 1.517\n",
      "[85, 180] loss: 1.501\n",
      "[85, 240] loss: 1.507\n",
      "[85, 300] loss: 1.503\n",
      "[85, 360] loss: 1.514\n",
      "Epoch: 85 -> Loss: 1.57070541382\n",
      "Epoch: 85 -> Test Accuracy: 40.07\n",
      "[86, 60] loss: 1.483\n",
      "[86, 120] loss: 1.487\n",
      "[86, 180] loss: 1.492\n",
      "[86, 240] loss: 1.483\n",
      "[86, 300] loss: 1.484\n",
      "[86, 360] loss: 1.472\n",
      "Epoch: 86 -> Loss: 1.52420806885\n",
      "Epoch: 86 -> Test Accuracy: 41.43\n",
      "[87, 60] loss: 1.472\n",
      "[87, 120] loss: 1.474\n",
      "[87, 180] loss: 1.471\n",
      "[87, 240] loss: 1.484\n",
      "[87, 300] loss: 1.479\n",
      "[87, 360] loss: 1.496\n",
      "Epoch: 87 -> Loss: 1.37038350105\n",
      "Epoch: 87 -> Test Accuracy: 41.78\n",
      "[88, 60] loss: 1.475\n",
      "[88, 120] loss: 1.463\n",
      "[88, 180] loss: 1.483\n",
      "[88, 240] loss: 1.490\n",
      "[88, 300] loss: 1.468\n",
      "[88, 360] loss: 1.485\n",
      "Epoch: 88 -> Loss: 1.63173544407\n",
      "Epoch: 88 -> Test Accuracy: 41.55\n",
      "[89, 60] loss: 1.487\n",
      "[89, 120] loss: 1.473\n",
      "[89, 180] loss: 1.475\n",
      "[89, 240] loss: 1.467\n",
      "[89, 300] loss: 1.481\n",
      "[89, 360] loss: 1.472\n",
      "Epoch: 89 -> Loss: 1.53713822365\n",
      "Epoch: 89 -> Test Accuracy: 41.91\n",
      "[90, 60] loss: 1.468\n",
      "[90, 120] loss: 1.472\n",
      "[90, 180] loss: 1.471\n",
      "[90, 240] loss: 1.468\n",
      "[90, 300] loss: 1.491\n",
      "[90, 360] loss: 1.478\n",
      "Epoch: 90 -> Loss: 1.56074130535\n",
      "Epoch: 90 -> Test Accuracy: 41.48\n",
      "[91, 60] loss: 1.474\n",
      "[91, 120] loss: 1.473\n",
      "[91, 180] loss: 1.468\n",
      "[91, 240] loss: 1.474\n",
      "[91, 300] loss: 1.479\n",
      "[91, 360] loss: 1.463\n",
      "Epoch: 91 -> Loss: 1.29111409187\n",
      "Epoch: 91 -> Test Accuracy: 41.86\n",
      "[92, 60] loss: 1.494\n",
      "[92, 120] loss: 1.488\n",
      "[92, 180] loss: 1.469\n",
      "[92, 240] loss: 1.475\n",
      "[92, 300] loss: 1.487\n",
      "[92, 360] loss: 1.474\n",
      "Epoch: 92 -> Loss: 1.41899752617\n",
      "Epoch: 92 -> Test Accuracy: 41.81\n",
      "[93, 60] loss: 1.471\n",
      "[93, 120] loss: 1.467\n",
      "[93, 180] loss: 1.475\n",
      "[93, 240] loss: 1.478\n",
      "[93, 300] loss: 1.476\n",
      "[93, 360] loss: 1.479\n",
      "Epoch: 93 -> Loss: 1.68551921844\n",
      "Epoch: 93 -> Test Accuracy: 41.78\n",
      "[94, 60] loss: 1.482\n",
      "[94, 120] loss: 1.489\n",
      "[94, 180] loss: 1.466\n",
      "[94, 240] loss: 1.464\n",
      "[94, 300] loss: 1.486\n",
      "[94, 360] loss: 1.469\n",
      "Epoch: 94 -> Loss: 1.45995700359\n",
      "Epoch: 94 -> Test Accuracy: 41.96\n",
      "[95, 60] loss: 1.468\n",
      "[95, 120] loss: 1.463\n",
      "[95, 180] loss: 1.472\n",
      "[95, 240] loss: 1.479\n",
      "[95, 300] loss: 1.468\n",
      "[95, 360] loss: 1.481\n",
      "Epoch: 95 -> Loss: 1.47538530827\n",
      "Epoch: 95 -> Test Accuracy: 41.73\n",
      "[96, 60] loss: 1.473\n",
      "[96, 120] loss: 1.475\n",
      "[96, 180] loss: 1.476\n",
      "[96, 240] loss: 1.469\n",
      "[96, 300] loss: 1.474\n",
      "[96, 360] loss: 1.458\n",
      "Epoch: 96 -> Loss: 1.40561211109\n",
      "Epoch: 96 -> Test Accuracy: 41.7\n",
      "[97, 60] loss: 1.475\n",
      "[97, 120] loss: 1.455\n",
      "[97, 180] loss: 1.473\n",
      "[97, 240] loss: 1.471\n",
      "[97, 300] loss: 1.474\n",
      "[97, 360] loss: 1.458\n",
      "Epoch: 97 -> Loss: 1.56781208515\n",
      "Epoch: 97 -> Test Accuracy: 41.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98, 60] loss: 1.483\n",
      "[98, 120] loss: 1.476\n",
      "[98, 180] loss: 1.477\n",
      "[98, 240] loss: 1.456\n",
      "[98, 300] loss: 1.473\n",
      "[98, 360] loss: 1.471\n",
      "Epoch: 98 -> Loss: 1.40951383114\n",
      "Epoch: 98 -> Test Accuracy: 41.67\n",
      "[99, 60] loss: 1.477\n",
      "[99, 120] loss: 1.471\n",
      "[99, 180] loss: 1.476\n",
      "[99, 240] loss: 1.463\n",
      "[99, 300] loss: 1.480\n",
      "[99, 360] loss: 1.460\n",
      "Epoch: 99 -> Loss: 1.40275323391\n",
      "Epoch: 99 -> Test Accuracy: 41.83\n",
      "[100, 60] loss: 1.474\n",
      "[100, 120] loss: 1.475\n",
      "[100, 180] loss: 1.461\n",
      "[100, 240] loss: 1.476\n",
      "[100, 300] loss: 1.475\n",
      "[100, 360] loss: 1.465\n",
      "Epoch: 100 -> Loss: 1.54256558418\n",
      "Epoch: 100 -> Test Accuracy: 42.1\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train ConvClassifiers on feature map of net_3block\n",
    "conv_block5_loss_log, conv_block5_valid_accuracy_log, conv_block5_test_accuracy_log, conv_block5_max_accuracy, \\\n",
    "conv_block5_best_epoch = tr.train_all_blocks(5, 10, [0.1, 0.02, 0.004, 0.0008], [35, 70, 85, 100], 0.9, 5e-4, net_block5, \n",
    "                                            criterion, trainloader, None, testloader, use_ConvClassifier=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./variables/RotNet_classification_100_paper.pkl\n",
      "./variables/RotNet_classification_200_paper.pkl\n",
      "./variables/RotNet_classification_100.pkl\n",
      "./variables/RotNet_classification_200.pkl\n",
      "./variables/Classifier_block_1_epoch_100_paper.pkl\n",
      "./variables/Classifier_block_1_epoch_200_paper.pkl\n",
      "./variables/Classifier_block_2_epoch_100_paper.pkl\n",
      "./variables/Classifier_block_2_epoch_200_paper.pkl\n",
      "./variables/Classifier_block_3_epoch_100_paper.pkl\n",
      "./variables/Classifier_block_3_epoch_200_paper.pkl\n",
      "./variables/Classifier_block_4_epoch_100_paper.pkl\n",
      "./variables/Classifier_block_4_epoch_200_paper.pkl\n",
      "./variables/Classifier_block_5_epoch_100_paper.pkl\n",
      "./variables/Classifier_block_5_epoch_200_paper.pkl\n",
      "./variables/ConvClassifier_block_1_epoch_100_paper.pkl\n",
      "./variables/ConvClassifier_block_1_epoch_200_paper.pkl\n",
      "./variables/ConvClassifier_block_2_epoch_100_paper.pkl\n",
      "./variables/ConvClassifier_block_2_epoch_200_paper.pkl\n",
      "./variables/ConvClassifier_block_3_epoch_100_paper.pkl\n",
      "./variables/ConvClassifier_block_3_epoch_200_paper.pkl\n",
      "./variables/ConvClassifier_block_4_epoch_100_paper.pkl\n",
      "./variables/ConvClassifier_block_4_epoch_200_paper.pkl\n",
      "./variables/ConvClassifier_block_5_epoch_100_paper.pkl\n",
      "./variables/ConvClassifier_block_5_epoch_200_paper.pkl\n",
      "./variables/Classifier_block_1_epoch_100.pkl\n",
      "./variables/Classifier_block_1_epoch_200.pkl\n",
      "./variables/Classifier_block_2_epoch_100.pkl\n",
      "./variables/Classifier_block_2_epoch_200.pkl\n",
      "./variables/Classifier_block_3_epoch_100.pkl\n",
      "./variables/Classifier_block_3_epoch_200.pkl\n",
      "./variables/Classifier_block_4_epoch_100.pkl\n",
      "./variables/Classifier_block_4_epoch_200.pkl\n",
      "./variables/Classifier_block_5_epoch_100.pkl\n",
      "./variables/Classifier_block_5_epoch_200.pkl\n",
      "./variables/ConvClassifier_block_1_epoch_100.pkl\n",
      "./variables/ConvClassifier_block_1_epoch_200.pkl\n",
      "./variables/ConvClassifier_block_2_epoch_100.pkl\n",
      "./variables/ConvClassifier_block_2_epoch_200.pkl\n",
      "./variables/ConvClassifier_block_3_epoch_100.pkl\n",
      "./variables/ConvClassifier_block_3_epoch_200.pkl\n",
      "./variables/ConvClassifier_block_4_epoch_100.pkl\n",
      "./variables/ConvClassifier_block_4_epoch_200.pkl\n",
      "./variables/ConvClassifier_block_5_epoch_100.pkl\n",
      "./variables/ConvClassifier_block_5_epoch_200.pkl\n",
      "./variables/RotNet_rotation_100_paper.pkl\n",
      "./variables/RotNet_rotation_200_paper.pkl\n",
      "./variables/RotNet_rotation_100.pkl\n",
      "./variables/RotNet_rotation_200.pkl\n"
     ]
    }
   ],
   "source": [
    "# rename files\n",
    "fm.add_block_to_name(5, [100, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Block RotNet with Average Pooling after ConvBlock 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "net_block5_avg = RN.RotNet(num_classes=4, num_conv_block=5, add_avg_pool=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.140\n",
      "[1, 120] loss: 1.015\n",
      "[1, 180] loss: 0.916\n",
      "[1, 240] loss: 0.874\n",
      "[1, 300] loss: 0.824\n",
      "[1, 360] loss: 0.799\n",
      "Epoch: 1 -> Loss: 0.821996212006\n",
      "Epoch: 1 -> Test Accuracy: 68.9275\n",
      "[2, 60] loss: 0.750\n",
      "[2, 120] loss: 0.714\n",
      "[2, 180] loss: 0.716\n",
      "[2, 240] loss: 0.695\n",
      "[2, 300] loss: 0.653\n",
      "[2, 360] loss: 0.649\n",
      "Epoch: 2 -> Loss: 0.565248370171\n",
      "Epoch: 2 -> Test Accuracy: 75.47\n",
      "[3, 60] loss: 0.628\n",
      "[3, 120] loss: 0.624\n",
      "[3, 180] loss: 0.621\n",
      "[3, 240] loss: 0.604\n",
      "[3, 300] loss: 0.582\n",
      "[3, 360] loss: 0.585\n",
      "Epoch: 3 -> Loss: 0.557309269905\n",
      "Epoch: 3 -> Test Accuracy: 76.825\n",
      "[4, 60] loss: 0.560\n",
      "[4, 120] loss: 0.557\n",
      "[4, 180] loss: 0.552\n",
      "[4, 240] loss: 0.541\n",
      "[4, 300] loss: 0.537\n",
      "[4, 360] loss: 0.537\n",
      "Epoch: 4 -> Loss: 0.586250424385\n",
      "Epoch: 4 -> Test Accuracy: 79.635\n",
      "[5, 60] loss: 0.517\n",
      "[5, 120] loss: 0.508\n",
      "[5, 180] loss: 0.506\n",
      "[5, 240] loss: 0.508\n",
      "[5, 300] loss: 0.503\n",
      "[5, 360] loss: 0.505\n",
      "Epoch: 5 -> Loss: 0.458298116922\n",
      "Epoch: 5 -> Test Accuracy: 81.01\n",
      "[6, 60] loss: 0.482\n",
      "[6, 120] loss: 0.471\n",
      "[6, 180] loss: 0.496\n",
      "[6, 240] loss: 0.480\n",
      "[6, 300] loss: 0.466\n",
      "[6, 360] loss: 0.485\n",
      "Epoch: 6 -> Loss: 0.468902766705\n",
      "Epoch: 6 -> Test Accuracy: 80.87\n",
      "[7, 60] loss: 0.460\n",
      "[7, 120] loss: 0.457\n",
      "[7, 180] loss: 0.454\n",
      "[7, 240] loss: 0.457\n",
      "[7, 300] loss: 0.460\n",
      "[7, 360] loss: 0.465\n",
      "Epoch: 7 -> Loss: 0.411553680897\n",
      "Epoch: 7 -> Test Accuracy: 81.465\n",
      "[8, 60] loss: 0.442\n",
      "[8, 120] loss: 0.443\n",
      "[8, 180] loss: 0.429\n",
      "[8, 240] loss: 0.440\n",
      "[8, 300] loss: 0.440\n",
      "[8, 360] loss: 0.452\n",
      "Epoch: 8 -> Loss: 0.529140591621\n",
      "Epoch: 8 -> Test Accuracy: 82.0125\n",
      "[9, 60] loss: 0.437\n",
      "[9, 120] loss: 0.421\n",
      "[9, 180] loss: 0.432\n",
      "[9, 240] loss: 0.425\n",
      "[9, 300] loss: 0.437\n",
      "[9, 360] loss: 0.418\n",
      "Epoch: 9 -> Loss: 0.490080922842\n",
      "Epoch: 9 -> Test Accuracy: 82.2375\n",
      "[10, 60] loss: 0.429\n",
      "[10, 120] loss: 0.402\n",
      "[10, 180] loss: 0.419\n",
      "[10, 240] loss: 0.411\n",
      "[10, 300] loss: 0.418\n",
      "[10, 360] loss: 0.419\n",
      "Epoch: 10 -> Loss: 0.44647321105\n",
      "Epoch: 10 -> Test Accuracy: 82.78\n",
      "[11, 60] loss: 0.411\n",
      "[11, 120] loss: 0.414\n",
      "[11, 180] loss: 0.392\n",
      "[11, 240] loss: 0.405\n",
      "[11, 300] loss: 0.405\n",
      "[11, 360] loss: 0.401\n",
      "Epoch: 11 -> Loss: 0.499173223972\n",
      "Epoch: 11 -> Test Accuracy: 83.7725\n",
      "[12, 60] loss: 0.390\n",
      "[12, 120] loss: 0.400\n",
      "[12, 180] loss: 0.396\n",
      "[12, 240] loss: 0.405\n",
      "[12, 300] loss: 0.394\n",
      "[12, 360] loss: 0.398\n",
      "Epoch: 12 -> Loss: 0.423077762127\n",
      "Epoch: 12 -> Test Accuracy: 84.15\n",
      "[13, 60] loss: 0.380\n",
      "[13, 120] loss: 0.378\n",
      "[13, 180] loss: 0.383\n",
      "[13, 240] loss: 0.396\n",
      "[13, 300] loss: 0.388\n",
      "[13, 360] loss: 0.399\n",
      "Epoch: 13 -> Loss: 0.416935682297\n",
      "Epoch: 13 -> Test Accuracy: 83.8075\n",
      "[14, 60] loss: 0.378\n",
      "[14, 120] loss: 0.387\n",
      "[14, 180] loss: 0.369\n",
      "[14, 240] loss: 0.379\n",
      "[14, 300] loss: 0.388\n",
      "[14, 360] loss: 0.372\n",
      "Epoch: 14 -> Loss: 0.374095439911\n",
      "Epoch: 14 -> Test Accuracy: 84.275\n",
      "[15, 60] loss: 0.369\n",
      "[15, 120] loss: 0.366\n",
      "[15, 180] loss: 0.379\n",
      "[15, 240] loss: 0.378\n",
      "[15, 300] loss: 0.379\n",
      "[15, 360] loss: 0.375\n",
      "Epoch: 15 -> Loss: 0.38996103406\n",
      "Epoch: 15 -> Test Accuracy: 84.6475\n",
      "[16, 60] loss: 0.362\n",
      "[16, 120] loss: 0.371\n",
      "[16, 180] loss: 0.384\n",
      "[16, 240] loss: 0.363\n",
      "[16, 300] loss: 0.373\n",
      "[16, 360] loss: 0.371\n",
      "Epoch: 16 -> Loss: 0.350888490677\n",
      "Epoch: 16 -> Test Accuracy: 85.0475\n",
      "[17, 60] loss: 0.370\n",
      "[17, 120] loss: 0.365\n",
      "[17, 180] loss: 0.365\n",
      "[17, 240] loss: 0.361\n",
      "[17, 300] loss: 0.357\n",
      "[17, 360] loss: 0.373\n",
      "Epoch: 17 -> Loss: 0.304714649916\n",
      "Epoch: 17 -> Test Accuracy: 83.7675\n",
      "[18, 60] loss: 0.348\n",
      "[18, 120] loss: 0.353\n",
      "[18, 180] loss: 0.356\n",
      "[18, 240] loss: 0.365\n",
      "[18, 300] loss: 0.362\n",
      "[18, 360] loss: 0.374\n",
      "Epoch: 18 -> Loss: 0.409136384726\n",
      "Epoch: 18 -> Test Accuracy: 84.54\n",
      "[19, 60] loss: 0.344\n",
      "[19, 120] loss: 0.353\n",
      "[19, 180] loss: 0.360\n",
      "[19, 240] loss: 0.362\n",
      "[19, 300] loss: 0.350\n",
      "[19, 360] loss: 0.352\n",
      "Epoch: 19 -> Loss: 0.310668170452\n",
      "Epoch: 19 -> Test Accuracy: 84.5675\n",
      "[20, 60] loss: 0.348\n",
      "[20, 120] loss: 0.361\n",
      "[20, 180] loss: 0.349\n",
      "[20, 240] loss: 0.351\n",
      "[20, 300] loss: 0.352\n",
      "[20, 360] loss: 0.350\n",
      "Epoch: 20 -> Loss: 0.247974082828\n",
      "Epoch: 20 -> Test Accuracy: 85.775\n",
      "[21, 60] loss: 0.339\n",
      "[21, 120] loss: 0.341\n",
      "[21, 180] loss: 0.340\n",
      "[21, 240] loss: 0.355\n",
      "[21, 300] loss: 0.346\n",
      "[21, 360] loss: 0.348\n",
      "Epoch: 21 -> Loss: 0.296412885189\n",
      "Epoch: 21 -> Test Accuracy: 85.0075\n",
      "[22, 60] loss: 0.341\n",
      "[22, 120] loss: 0.342\n",
      "[22, 180] loss: 0.338\n",
      "[22, 240] loss: 0.359\n",
      "[22, 300] loss: 0.341\n",
      "[22, 360] loss: 0.347\n",
      "Epoch: 22 -> Loss: 0.324581831694\n",
      "Epoch: 22 -> Test Accuracy: 85.085\n",
      "[23, 60] loss: 0.329\n",
      "[23, 120] loss: 0.334\n",
      "[23, 180] loss: 0.354\n",
      "[23, 240] loss: 0.343\n",
      "[23, 300] loss: 0.336\n",
      "[23, 360] loss: 0.346\n",
      "Epoch: 23 -> Loss: 0.419653177261\n",
      "Epoch: 23 -> Test Accuracy: 85.7725\n",
      "[24, 60] loss: 0.339\n",
      "[24, 120] loss: 0.331\n",
      "[24, 180] loss: 0.345\n",
      "[24, 240] loss: 0.342\n",
      "[24, 300] loss: 0.337\n",
      "[24, 360] loss: 0.339\n",
      "Epoch: 24 -> Loss: 0.205176830292\n",
      "Epoch: 24 -> Test Accuracy: 85.9575\n",
      "[25, 60] loss: 0.324\n",
      "[25, 120] loss: 0.332\n",
      "[25, 180] loss: 0.346\n",
      "[25, 240] loss: 0.329\n",
      "[25, 300] loss: 0.334\n",
      "[25, 360] loss: 0.341\n",
      "Epoch: 25 -> Loss: 0.426267206669\n",
      "Epoch: 25 -> Test Accuracy: 85.035\n",
      "[26, 60] loss: 0.321\n",
      "[26, 120] loss: 0.327\n",
      "[26, 180] loss: 0.333\n",
      "[26, 240] loss: 0.333\n",
      "[26, 300] loss: 0.338\n",
      "[26, 360] loss: 0.340\n",
      "Epoch: 26 -> Loss: 0.471595227718\n",
      "Epoch: 26 -> Test Accuracy: 85.42\n",
      "[27, 60] loss: 0.327\n",
      "[27, 120] loss: 0.325\n",
      "[27, 180] loss: 0.324\n",
      "[27, 240] loss: 0.325\n",
      "[27, 300] loss: 0.348\n",
      "[27, 360] loss: 0.316\n",
      "Epoch: 27 -> Loss: 0.505860686302\n",
      "Epoch: 27 -> Test Accuracy: 85.8125\n",
      "[28, 60] loss: 0.325\n",
      "[28, 120] loss: 0.327\n",
      "[28, 180] loss: 0.339\n",
      "[28, 240] loss: 0.314\n",
      "[28, 300] loss: 0.343\n",
      "[28, 360] loss: 0.336\n",
      "Epoch: 28 -> Loss: 0.324965238571\n",
      "Epoch: 28 -> Test Accuracy: 85.76\n",
      "[29, 60] loss: 0.313\n",
      "[29, 120] loss: 0.318\n",
      "[29, 180] loss: 0.326\n",
      "[29, 240] loss: 0.337\n",
      "[29, 300] loss: 0.325\n",
      "[29, 360] loss: 0.330\n",
      "Epoch: 29 -> Loss: 0.259606033564\n",
      "Epoch: 29 -> Test Accuracy: 86.1525\n",
      "[30, 60] loss: 0.315\n",
      "[30, 120] loss: 0.320\n",
      "[30, 180] loss: 0.334\n",
      "[30, 240] loss: 0.322\n",
      "[30, 300] loss: 0.338\n",
      "[30, 360] loss: 0.322\n",
      "Epoch: 30 -> Loss: 0.374001562595\n",
      "Epoch: 30 -> Test Accuracy: 85.6325\n",
      "[31, 60] loss: 0.316\n",
      "[31, 120] loss: 0.323\n",
      "[31, 180] loss: 0.319\n",
      "[31, 240] loss: 0.322\n",
      "[31, 300] loss: 0.323\n",
      "[31, 360] loss: 0.329\n",
      "Epoch: 31 -> Loss: 0.254198759794\n",
      "Epoch: 31 -> Test Accuracy: 84.7425\n",
      "[32, 60] loss: 0.324\n",
      "[32, 120] loss: 0.337\n",
      "[32, 180] loss: 0.322\n",
      "[32, 240] loss: 0.328\n",
      "[32, 300] loss: 0.320\n",
      "[32, 360] loss: 0.321\n",
      "Epoch: 32 -> Loss: 0.226287811995\n",
      "Epoch: 32 -> Test Accuracy: 85.9575\n",
      "[33, 60] loss: 0.312\n",
      "[33, 120] loss: 0.320\n",
      "[33, 180] loss: 0.325\n",
      "[33, 240] loss: 0.321\n",
      "[33, 300] loss: 0.317\n",
      "[33, 360] loss: 0.340\n",
      "Epoch: 33 -> Loss: 0.300990432501\n",
      "Epoch: 33 -> Test Accuracy: 85.6525\n",
      "[34, 60] loss: 0.323\n",
      "[34, 120] loss: 0.324\n",
      "[34, 180] loss: 0.322\n",
      "[34, 240] loss: 0.317\n",
      "[34, 300] loss: 0.317\n",
      "[34, 360] loss: 0.329\n",
      "Epoch: 34 -> Loss: 0.424574077129\n",
      "Epoch: 34 -> Test Accuracy: 86.0125\n",
      "[35, 60] loss: 0.311\n",
      "[35, 120] loss: 0.321\n",
      "[35, 180] loss: 0.319\n",
      "[35, 240] loss: 0.319\n",
      "[35, 300] loss: 0.325\n",
      "[35, 360] loss: 0.320\n",
      "Epoch: 35 -> Loss: 0.359104603529\n",
      "Epoch: 35 -> Test Accuracy: 85.85\n",
      "[36, 60] loss: 0.302\n",
      "[36, 120] loss: 0.314\n",
      "[36, 180] loss: 0.306\n",
      "[36, 240] loss: 0.319\n",
      "[36, 300] loss: 0.328\n",
      "[36, 360] loss: 0.318\n",
      "Epoch: 36 -> Loss: 0.212027519941\n",
      "Epoch: 36 -> Test Accuracy: 86.485\n",
      "[37, 60] loss: 0.307\n",
      "[37, 120] loss: 0.318\n",
      "[37, 180] loss: 0.317\n",
      "[37, 240] loss: 0.313\n",
      "[37, 300] loss: 0.328\n",
      "[37, 360] loss: 0.327\n",
      "Epoch: 37 -> Loss: 0.315726876259\n",
      "Epoch: 37 -> Test Accuracy: 85.79\n",
      "[38, 60] loss: 0.301\n",
      "[38, 120] loss: 0.326\n",
      "[38, 180] loss: 0.313\n",
      "[38, 240] loss: 0.317\n",
      "[38, 300] loss: 0.312\n",
      "[38, 360] loss: 0.315\n",
      "Epoch: 38 -> Loss: 0.301502794027\n",
      "Epoch: 38 -> Test Accuracy: 87.1325\n",
      "[39, 60] loss: 0.299\n",
      "[39, 120] loss: 0.325\n",
      "[39, 180] loss: 0.303\n",
      "[39, 240] loss: 0.313\n",
      "[39, 300] loss: 0.313\n",
      "[39, 360] loss: 0.310\n",
      "Epoch: 39 -> Loss: 0.316458046436\n",
      "Epoch: 39 -> Test Accuracy: 86.37\n",
      "[40, 60] loss: 0.301\n",
      "[40, 120] loss: 0.316\n",
      "[40, 180] loss: 0.312\n",
      "[40, 240] loss: 0.313\n",
      "[40, 300] loss: 0.317\n",
      "[40, 360] loss: 0.324\n",
      "Epoch: 40 -> Loss: 0.424786269665\n",
      "Epoch: 40 -> Test Accuracy: 86.2775\n",
      "[41, 60] loss: 0.304\n",
      "[41, 120] loss: 0.299\n",
      "[41, 180] loss: 0.320\n",
      "[41, 240] loss: 0.306\n",
      "[41, 300] loss: 0.332\n",
      "[41, 360] loss: 0.312\n",
      "Epoch: 41 -> Loss: 0.201461315155\n",
      "Epoch: 41 -> Test Accuracy: 86.065\n",
      "[42, 60] loss: 0.299\n",
      "[42, 120] loss: 0.306\n",
      "[42, 180] loss: 0.310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 240] loss: 0.316\n",
      "[42, 300] loss: 0.325\n",
      "[42, 360] loss: 0.310\n",
      "Epoch: 42 -> Loss: 0.344524085522\n",
      "Epoch: 42 -> Test Accuracy: 87.235\n",
      "[43, 60] loss: 0.301\n",
      "[43, 120] loss: 0.305\n",
      "[43, 180] loss: 0.312\n",
      "[43, 240] loss: 0.317\n",
      "[43, 300] loss: 0.315\n",
      "[43, 360] loss: 0.323\n",
      "Epoch: 43 -> Loss: 0.274034440517\n",
      "Epoch: 43 -> Test Accuracy: 86.305\n",
      "[44, 60] loss: 0.298\n",
      "[44, 120] loss: 0.305\n",
      "[44, 180] loss: 0.307\n",
      "[44, 240] loss: 0.322\n",
      "[44, 300] loss: 0.310\n",
      "[44, 360] loss: 0.303\n",
      "Epoch: 44 -> Loss: 0.309718489647\n",
      "Epoch: 44 -> Test Accuracy: 85.6475\n",
      "[45, 60] loss: 0.305\n",
      "[45, 120] loss: 0.291\n",
      "[45, 180] loss: 0.320\n",
      "[45, 240] loss: 0.315\n",
      "[45, 300] loss: 0.302\n",
      "[45, 360] loss: 0.313\n",
      "Epoch: 45 -> Loss: 0.414474904537\n",
      "Epoch: 45 -> Test Accuracy: 87.8075\n",
      "[46, 60] loss: 0.305\n",
      "[46, 120] loss: 0.304\n",
      "[46, 180] loss: 0.313\n",
      "[46, 240] loss: 0.306\n",
      "[46, 300] loss: 0.307\n",
      "[46, 360] loss: 0.306\n",
      "Epoch: 46 -> Loss: 0.344443976879\n",
      "Epoch: 46 -> Test Accuracy: 85.685\n",
      "[47, 60] loss: 0.297\n",
      "[47, 120] loss: 0.312\n",
      "[47, 180] loss: 0.318\n",
      "[47, 240] loss: 0.284\n",
      "[47, 300] loss: 0.314\n",
      "[47, 360] loss: 0.317\n",
      "Epoch: 47 -> Loss: 0.403633832932\n",
      "Epoch: 47 -> Test Accuracy: 86.3975\n",
      "[48, 60] loss: 0.288\n",
      "[48, 120] loss: 0.307\n",
      "[48, 180] loss: 0.315\n",
      "[48, 240] loss: 0.307\n",
      "[48, 300] loss: 0.320\n",
      "[48, 360] loss: 0.311\n",
      "Epoch: 48 -> Loss: 0.310635685921\n",
      "Epoch: 48 -> Test Accuracy: 86.93\n",
      "[49, 60] loss: 0.294\n",
      "[49, 120] loss: 0.301\n",
      "[49, 180] loss: 0.298\n",
      "[49, 240] loss: 0.305\n",
      "[49, 300] loss: 0.309\n",
      "[49, 360] loss: 0.312\n",
      "Epoch: 49 -> Loss: 0.251498758793\n",
      "Epoch: 49 -> Test Accuracy: 87.0925\n",
      "[50, 60] loss: 0.293\n",
      "[50, 120] loss: 0.302\n",
      "[50, 180] loss: 0.318\n",
      "[50, 240] loss: 0.301\n",
      "[50, 300] loss: 0.305\n",
      "[50, 360] loss: 0.318\n",
      "Epoch: 50 -> Loss: 0.321485817432\n",
      "Epoch: 50 -> Test Accuracy: 86.7075\n",
      "[51, 60] loss: 0.290\n",
      "[51, 120] loss: 0.306\n",
      "[51, 180] loss: 0.308\n",
      "[51, 240] loss: 0.305\n",
      "[51, 300] loss: 0.313\n",
      "[51, 360] loss: 0.306\n",
      "Epoch: 51 -> Loss: 0.344902276993\n",
      "Epoch: 51 -> Test Accuracy: 87.2925\n",
      "[52, 60] loss: 0.293\n",
      "[52, 120] loss: 0.306\n",
      "[52, 180] loss: 0.305\n",
      "[52, 240] loss: 0.308\n",
      "[52, 300] loss: 0.312\n",
      "[52, 360] loss: 0.307\n",
      "Epoch: 52 -> Loss: 0.305567920208\n",
      "Epoch: 52 -> Test Accuracy: 86.29\n",
      "[53, 60] loss: 0.284\n",
      "[53, 120] loss: 0.295\n",
      "[53, 180] loss: 0.303\n",
      "[53, 240] loss: 0.314\n",
      "[53, 300] loss: 0.302\n",
      "[53, 360] loss: 0.310\n",
      "Epoch: 53 -> Loss: 0.262182295322\n",
      "Epoch: 53 -> Test Accuracy: 86.5275\n",
      "[54, 60] loss: 0.295\n",
      "[54, 120] loss: 0.302\n",
      "[54, 180] loss: 0.305\n",
      "[54, 240] loss: 0.295\n",
      "[54, 300] loss: 0.313\n",
      "[54, 360] loss: 0.310\n",
      "Epoch: 54 -> Loss: 0.281718194485\n",
      "Epoch: 54 -> Test Accuracy: 86.11\n",
      "[55, 60] loss: 0.294\n",
      "[55, 120] loss: 0.305\n",
      "[55, 180] loss: 0.306\n",
      "[55, 240] loss: 0.307\n",
      "[55, 300] loss: 0.301\n",
      "[55, 360] loss: 0.301\n",
      "Epoch: 55 -> Loss: 0.396410048008\n",
      "Epoch: 55 -> Test Accuracy: 86.5725\n",
      "[56, 60] loss: 0.292\n",
      "[56, 120] loss: 0.302\n",
      "[56, 180] loss: 0.301\n",
      "[56, 240] loss: 0.296\n",
      "[56, 300] loss: 0.310\n",
      "[56, 360] loss: 0.310\n",
      "Epoch: 56 -> Loss: 0.269189685583\n",
      "Epoch: 56 -> Test Accuracy: 87.3475\n",
      "[57, 60] loss: 0.300\n",
      "[57, 120] loss: 0.293\n",
      "[57, 180] loss: 0.298\n",
      "[57, 240] loss: 0.303\n",
      "[57, 300] loss: 0.302\n",
      "[57, 360] loss: 0.309\n",
      "Epoch: 57 -> Loss: 0.357944667339\n",
      "Epoch: 57 -> Test Accuracy: 86.75\n",
      "[58, 60] loss: 0.288\n",
      "[58, 120] loss: 0.292\n",
      "[58, 180] loss: 0.302\n",
      "[58, 240] loss: 0.303\n",
      "[58, 300] loss: 0.305\n",
      "[58, 360] loss: 0.309\n",
      "Epoch: 58 -> Loss: 0.330335080624\n",
      "Epoch: 58 -> Test Accuracy: 87.495\n",
      "[59, 60] loss: 0.299\n",
      "[59, 120] loss: 0.292\n",
      "[59, 180] loss: 0.293\n",
      "[59, 240] loss: 0.305\n",
      "[59, 300] loss: 0.308\n",
      "[59, 360] loss: 0.310\n",
      "Epoch: 59 -> Loss: 0.344086498022\n",
      "Epoch: 59 -> Test Accuracy: 86.4625\n",
      "[60, 60] loss: 0.290\n",
      "[60, 120] loss: 0.301\n",
      "[60, 180] loss: 0.299\n",
      "[60, 240] loss: 0.308\n",
      "[60, 300] loss: 0.305\n",
      "[60, 360] loss: 0.305\n",
      "Epoch: 60 -> Loss: 0.322983086109\n",
      "Epoch: 60 -> Test Accuracy: 86.1425\n",
      "[61, 60] loss: 0.232\n",
      "[61, 120] loss: 0.197\n",
      "[61, 180] loss: 0.172\n",
      "[61, 240] loss: 0.191\n",
      "[61, 300] loss: 0.191\n",
      "[61, 360] loss: 0.186\n",
      "Epoch: 61 -> Loss: 0.257293850183\n",
      "Epoch: 61 -> Test Accuracy: 90.735\n",
      "[62, 60] loss: 0.165\n",
      "[62, 120] loss: 0.151\n",
      "[62, 180] loss: 0.165\n",
      "[62, 240] loss: 0.167\n",
      "[62, 300] loss: 0.170\n",
      "[62, 360] loss: 0.165\n",
      "Epoch: 62 -> Loss: 0.167596042156\n",
      "Epoch: 62 -> Test Accuracy: 90.9375\n",
      "[63, 60] loss: 0.156\n",
      "[63, 120] loss: 0.151\n",
      "[63, 180] loss: 0.156\n",
      "[63, 240] loss: 0.158\n",
      "[63, 300] loss: 0.155\n",
      "[63, 360] loss: 0.161\n",
      "Epoch: 63 -> Loss: 0.238503962755\n",
      "Epoch: 63 -> Test Accuracy: 90.9525\n",
      "[64, 60] loss: 0.150\n",
      "[64, 120] loss: 0.148\n",
      "[64, 180] loss: 0.153\n",
      "[64, 240] loss: 0.147\n",
      "[64, 300] loss: 0.149\n",
      "[64, 360] loss: 0.164\n",
      "Epoch: 64 -> Loss: 0.173420518637\n",
      "Epoch: 64 -> Test Accuracy: 91.08\n",
      "[65, 60] loss: 0.140\n",
      "[65, 120] loss: 0.135\n",
      "[65, 180] loss: 0.154\n",
      "[65, 240] loss: 0.147\n",
      "[65, 300] loss: 0.157\n",
      "[65, 360] loss: 0.154\n",
      "Epoch: 65 -> Loss: 0.11444093287\n",
      "Epoch: 65 -> Test Accuracy: 91.1675\n",
      "[66, 60] loss: 0.132\n",
      "[66, 120] loss: 0.153\n",
      "[66, 180] loss: 0.146\n",
      "[66, 240] loss: 0.143\n",
      "[66, 300] loss: 0.157\n",
      "[66, 360] loss: 0.144\n",
      "Epoch: 66 -> Loss: 0.257296413183\n",
      "Epoch: 66 -> Test Accuracy: 90.5825\n",
      "[67, 60] loss: 0.134\n",
      "[67, 120] loss: 0.138\n",
      "[67, 180] loss: 0.147\n",
      "[67, 240] loss: 0.147\n",
      "[67, 300] loss: 0.144\n",
      "[67, 360] loss: 0.155\n",
      "Epoch: 67 -> Loss: 0.178671851754\n",
      "Epoch: 67 -> Test Accuracy: 90.8225\n",
      "[68, 60] loss: 0.139\n",
      "[68, 120] loss: 0.137\n",
      "[68, 180] loss: 0.146\n",
      "[68, 240] loss: 0.142\n",
      "[68, 300] loss: 0.147\n",
      "[68, 360] loss: 0.149\n",
      "Epoch: 68 -> Loss: 0.215051367879\n",
      "Epoch: 68 -> Test Accuracy: 90.925\n",
      "[69, 60] loss: 0.142\n",
      "[69, 120] loss: 0.132\n",
      "[69, 180] loss: 0.142\n",
      "[69, 240] loss: 0.151\n",
      "[69, 300] loss: 0.152\n",
      "[69, 360] loss: 0.155\n",
      "Epoch: 69 -> Loss: 0.145891875029\n",
      "Epoch: 69 -> Test Accuracy: 90.4775\n",
      "[70, 60] loss: 0.134\n",
      "[70, 120] loss: 0.143\n",
      "[70, 180] loss: 0.145\n",
      "[70, 240] loss: 0.148\n",
      "[70, 300] loss: 0.144\n",
      "[70, 360] loss: 0.149\n",
      "Epoch: 70 -> Loss: 0.0573669448495\n",
      "Epoch: 70 -> Test Accuracy: 90.445\n",
      "[71, 60] loss: 0.139\n",
      "[71, 120] loss: 0.137\n",
      "[71, 180] loss: 0.150\n",
      "[71, 240] loss: 0.144\n",
      "[71, 300] loss: 0.149\n",
      "[71, 360] loss: 0.158\n",
      "Epoch: 71 -> Loss: 0.175349369645\n",
      "Epoch: 71 -> Test Accuracy: 90.7925\n",
      "[72, 60] loss: 0.140\n",
      "[72, 120] loss: 0.135\n",
      "[72, 180] loss: 0.142\n",
      "[72, 240] loss: 0.144\n",
      "[72, 300] loss: 0.144\n",
      "[72, 360] loss: 0.151\n",
      "Epoch: 72 -> Loss: 0.0833158567548\n",
      "Epoch: 72 -> Test Accuracy: 90.3925\n",
      "[73, 60] loss: 0.142\n",
      "[73, 120] loss: 0.141\n",
      "[73, 180] loss: 0.147\n",
      "[73, 240] loss: 0.146\n",
      "[73, 300] loss: 0.142\n",
      "[73, 360] loss: 0.161\n",
      "Epoch: 73 -> Loss: 0.157102793455\n",
      "Epoch: 73 -> Test Accuracy: 90.39\n",
      "[74, 60] loss: 0.134\n",
      "[74, 120] loss: 0.143\n",
      "[74, 180] loss: 0.148\n",
      "[74, 240] loss: 0.146\n",
      "[74, 300] loss: 0.154\n",
      "[74, 360] loss: 0.148\n",
      "Epoch: 74 -> Loss: 0.108751915395\n",
      "Epoch: 74 -> Test Accuracy: 90.47\n",
      "[75, 60] loss: 0.137\n",
      "[75, 120] loss: 0.141\n",
      "[75, 180] loss: 0.146\n",
      "[75, 240] loss: 0.143\n",
      "[75, 300] loss: 0.146\n",
      "[75, 360] loss: 0.156\n",
      "Epoch: 75 -> Loss: 0.124328389764\n",
      "Epoch: 75 -> Test Accuracy: 90.5725\n",
      "[76, 60] loss: 0.139\n",
      "[76, 120] loss: 0.144\n",
      "[76, 180] loss: 0.144\n",
      "[76, 240] loss: 0.149\n",
      "[76, 300] loss: 0.152\n",
      "[76, 360] loss: 0.152\n",
      "Epoch: 76 -> Loss: 0.129401057959\n",
      "Epoch: 76 -> Test Accuracy: 90.565\n",
      "[77, 60] loss: 0.143\n",
      "[77, 120] loss: 0.149\n",
      "[77, 180] loss: 0.140\n",
      "[77, 240] loss: 0.147\n",
      "[77, 300] loss: 0.149\n",
      "[77, 360] loss: 0.147\n",
      "Epoch: 77 -> Loss: 0.0918925926089\n",
      "Epoch: 77 -> Test Accuracy: 90.5375\n",
      "[78, 60] loss: 0.137\n",
      "[78, 120] loss: 0.144\n",
      "[78, 180] loss: 0.147\n",
      "[78, 240] loss: 0.149\n",
      "[78, 300] loss: 0.144\n",
      "[78, 360] loss: 0.146\n",
      "Epoch: 78 -> Loss: 0.140269756317\n",
      "Epoch: 78 -> Test Accuracy: 89.93\n",
      "[79, 60] loss: 0.138\n",
      "[79, 120] loss: 0.140\n",
      "[79, 180] loss: 0.146\n",
      "[79, 240] loss: 0.159\n",
      "[79, 300] loss: 0.152\n",
      "[79, 360] loss: 0.148\n",
      "Epoch: 79 -> Loss: 0.178274378181\n",
      "Epoch: 79 -> Test Accuracy: 90.145\n",
      "[80, 60] loss: 0.131\n",
      "[80, 120] loss: 0.144\n",
      "[80, 180] loss: 0.155\n",
      "[80, 240] loss: 0.151\n",
      "[80, 300] loss: 0.144\n",
      "[80, 360] loss: 0.158\n",
      "Epoch: 80 -> Loss: 0.201250076294\n",
      "Epoch: 80 -> Test Accuracy: 90.335\n",
      "[81, 60] loss: 0.133\n",
      "[81, 120] loss: 0.145\n",
      "[81, 180] loss: 0.140\n",
      "[81, 240] loss: 0.143\n",
      "[81, 300] loss: 0.155\n",
      "[81, 360] loss: 0.144\n",
      "Epoch: 81 -> Loss: 0.212723046541\n",
      "Epoch: 81 -> Test Accuracy: 90.245\n",
      "[82, 60] loss: 0.129\n",
      "[82, 120] loss: 0.142\n",
      "[82, 180] loss: 0.138\n",
      "[82, 240] loss: 0.151\n",
      "[82, 300] loss: 0.145\n",
      "[82, 360] loss: 0.161\n",
      "Epoch: 82 -> Loss: 0.091594286263\n",
      "Epoch: 82 -> Test Accuracy: 90.465\n",
      "[83, 60] loss: 0.136\n",
      "[83, 120] loss: 0.144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83, 180] loss: 0.142\n",
      "[83, 240] loss: 0.146\n",
      "[83, 300] loss: 0.144\n",
      "[83, 360] loss: 0.158\n",
      "Epoch: 83 -> Loss: 0.120340168476\n",
      "Epoch: 83 -> Test Accuracy: 90.565\n",
      "[84, 60] loss: 0.138\n",
      "[84, 120] loss: 0.134\n",
      "[84, 180] loss: 0.147\n",
      "[84, 240] loss: 0.149\n",
      "[84, 300] loss: 0.149\n",
      "[84, 360] loss: 0.144\n",
      "Epoch: 84 -> Loss: 0.236386463046\n",
      "Epoch: 84 -> Test Accuracy: 90.3075\n",
      "[85, 60] loss: 0.136\n",
      "[85, 120] loss: 0.149\n",
      "[85, 180] loss: 0.141\n",
      "[85, 240] loss: 0.141\n",
      "[85, 300] loss: 0.144\n",
      "[85, 360] loss: 0.159\n",
      "Epoch: 85 -> Loss: 0.12108206749\n",
      "Epoch: 85 -> Test Accuracy: 89.45\n",
      "[86, 60] loss: 0.136\n",
      "[86, 120] loss: 0.145\n",
      "[86, 180] loss: 0.135\n",
      "[86, 240] loss: 0.143\n",
      "[86, 300] loss: 0.149\n",
      "[86, 360] loss: 0.148\n",
      "Epoch: 86 -> Loss: 0.16421481967\n",
      "Epoch: 86 -> Test Accuracy: 90.3675\n",
      "[87, 60] loss: 0.136\n",
      "[87, 120] loss: 0.139\n",
      "[87, 180] loss: 0.140\n",
      "[87, 240] loss: 0.142\n",
      "[87, 300] loss: 0.148\n",
      "[87, 360] loss: 0.151\n",
      "Epoch: 87 -> Loss: 0.271573841572\n",
      "Epoch: 87 -> Test Accuracy: 90.4\n",
      "[88, 60] loss: 0.137\n",
      "[88, 120] loss: 0.143\n",
      "[88, 180] loss: 0.141\n",
      "[88, 240] loss: 0.139\n",
      "[88, 300] loss: 0.143\n",
      "[88, 360] loss: 0.156\n",
      "Epoch: 88 -> Loss: 0.138141661882\n",
      "Epoch: 88 -> Test Accuracy: 90.57\n",
      "[89, 60] loss: 0.123\n",
      "[89, 120] loss: 0.135\n",
      "[89, 180] loss: 0.149\n",
      "[89, 240] loss: 0.142\n",
      "[89, 300] loss: 0.156\n",
      "[89, 360] loss: 0.143\n",
      "Epoch: 89 -> Loss: 0.153934255242\n",
      "Epoch: 89 -> Test Accuracy: 90.7975\n",
      "[90, 60] loss: 0.135\n",
      "[90, 120] loss: 0.143\n",
      "[90, 180] loss: 0.140\n",
      "[90, 240] loss: 0.145\n",
      "[90, 300] loss: 0.143\n",
      "[90, 360] loss: 0.141\n",
      "Epoch: 90 -> Loss: 0.0949671491981\n",
      "Epoch: 90 -> Test Accuracy: 90.2425\n",
      "[91, 60] loss: 0.134\n",
      "[91, 120] loss: 0.146\n",
      "[91, 180] loss: 0.144\n",
      "[91, 240] loss: 0.142\n",
      "[91, 300] loss: 0.143\n",
      "[91, 360] loss: 0.150\n",
      "Epoch: 91 -> Loss: 0.240709543228\n",
      "Epoch: 91 -> Test Accuracy: 90.27\n",
      "[92, 60] loss: 0.134\n",
      "[92, 120] loss: 0.140\n",
      "[92, 180] loss: 0.139\n",
      "[92, 240] loss: 0.143\n",
      "[92, 300] loss: 0.152\n",
      "[92, 360] loss: 0.144\n",
      "Epoch: 92 -> Loss: 0.259555369616\n",
      "Epoch: 92 -> Test Accuracy: 89.865\n",
      "[93, 60] loss: 0.131\n",
      "[93, 120] loss: 0.134\n",
      "[93, 180] loss: 0.134\n",
      "[93, 240] loss: 0.142\n",
      "[93, 300] loss: 0.153\n",
      "[93, 360] loss: 0.141\n",
      "Epoch: 93 -> Loss: 0.141395926476\n",
      "Epoch: 93 -> Test Accuracy: 90.1175\n",
      "[94, 60] loss: 0.133\n",
      "[94, 120] loss: 0.134\n",
      "[94, 180] loss: 0.145\n",
      "[94, 240] loss: 0.139\n",
      "[94, 300] loss: 0.140\n",
      "[94, 360] loss: 0.142\n",
      "Epoch: 94 -> Loss: 0.148937612772\n",
      "Epoch: 94 -> Test Accuracy: 90.2725\n",
      "[95, 60] loss: 0.128\n",
      "[95, 120] loss: 0.135\n",
      "[95, 180] loss: 0.143\n",
      "[95, 240] loss: 0.148\n",
      "[95, 300] loss: 0.141\n",
      "[95, 360] loss: 0.147\n",
      "Epoch: 95 -> Loss: 0.10280264914\n",
      "Epoch: 95 -> Test Accuracy: 89.9325\n",
      "[96, 60] loss: 0.133\n",
      "[96, 120] loss: 0.133\n",
      "[96, 180] loss: 0.134\n",
      "[96, 240] loss: 0.148\n",
      "[96, 300] loss: 0.131\n",
      "[96, 360] loss: 0.140\n",
      "Epoch: 96 -> Loss: 0.157193273306\n",
      "Epoch: 96 -> Test Accuracy: 90.27\n",
      "[97, 60] loss: 0.128\n",
      "[97, 120] loss: 0.144\n",
      "[97, 180] loss: 0.137\n",
      "[97, 240] loss: 0.137\n",
      "[97, 300] loss: 0.139\n",
      "[97, 360] loss: 0.146\n",
      "Epoch: 97 -> Loss: 0.137650832534\n",
      "Epoch: 97 -> Test Accuracy: 90.0525\n",
      "[98, 60] loss: 0.149\n",
      "[98, 120] loss: 0.132\n",
      "[98, 180] loss: 0.135\n",
      "[98, 240] loss: 0.148\n",
      "[98, 300] loss: 0.142\n",
      "[98, 360] loss: 0.135\n",
      "Epoch: 98 -> Loss: 0.187325179577\n",
      "Epoch: 98 -> Test Accuracy: 90.39\n",
      "[99, 60] loss: 0.131\n",
      "[99, 120] loss: 0.133\n",
      "[99, 180] loss: 0.143\n",
      "[99, 240] loss: 0.147\n",
      "[99, 300] loss: 0.135\n",
      "[99, 360] loss: 0.147\n",
      "Epoch: 99 -> Loss: 0.0945948511362\n",
      "Epoch: 99 -> Test Accuracy: 90.8475\n",
      "[100, 60] loss: 0.128\n",
      "[100, 120] loss: 0.132\n",
      "[100, 180] loss: 0.137\n",
      "[100, 240] loss: 0.140\n",
      "[100, 300] loss: 0.144\n",
      "[100, 360] loss: 0.140\n",
      "Epoch: 100 -> Loss: 0.212231323123\n",
      "Epoch: 100 -> Test Accuracy: 90.7325\n",
      "[101, 60] loss: 0.118\n",
      "[101, 120] loss: 0.134\n",
      "[101, 180] loss: 0.142\n",
      "[101, 240] loss: 0.146\n",
      "[101, 300] loss: 0.140\n",
      "[101, 360] loss: 0.137\n",
      "Epoch: 101 -> Loss: 0.129624143243\n",
      "Epoch: 101 -> Test Accuracy: 90.6525\n",
      "[102, 60] loss: 0.129\n",
      "[102, 120] loss: 0.136\n",
      "[102, 180] loss: 0.132\n",
      "[102, 240] loss: 0.140\n",
      "[102, 300] loss: 0.135\n",
      "[102, 360] loss: 0.138\n",
      "Epoch: 102 -> Loss: 0.20277158916\n",
      "Epoch: 102 -> Test Accuracy: 90.555\n",
      "[103, 60] loss: 0.127\n",
      "[103, 120] loss: 0.133\n",
      "[103, 180] loss: 0.136\n",
      "[103, 240] loss: 0.137\n",
      "[103, 300] loss: 0.141\n",
      "[103, 360] loss: 0.138\n",
      "Epoch: 103 -> Loss: 0.175592064857\n",
      "Epoch: 103 -> Test Accuracy: 90.3425\n",
      "[104, 60] loss: 0.126\n",
      "[104, 120] loss: 0.131\n",
      "[104, 180] loss: 0.140\n",
      "[104, 240] loss: 0.137\n",
      "[104, 300] loss: 0.143\n",
      "[104, 360] loss: 0.145\n",
      "Epoch: 104 -> Loss: 0.193200305104\n",
      "Epoch: 104 -> Test Accuracy: 90.7975\n",
      "[105, 60] loss: 0.119\n",
      "[105, 120] loss: 0.138\n",
      "[105, 180] loss: 0.132\n",
      "[105, 240] loss: 0.146\n",
      "[105, 300] loss: 0.139\n",
      "[105, 360] loss: 0.141\n",
      "Epoch: 105 -> Loss: 0.138365909457\n",
      "Epoch: 105 -> Test Accuracy: 90.5675\n",
      "[106, 60] loss: 0.124\n",
      "[106, 120] loss: 0.132\n",
      "[106, 180] loss: 0.139\n",
      "[106, 240] loss: 0.138\n",
      "[106, 300] loss: 0.142\n",
      "[106, 360] loss: 0.138\n",
      "Epoch: 106 -> Loss: 0.25565597415\n",
      "Epoch: 106 -> Test Accuracy: 90.7475\n",
      "[107, 60] loss: 0.128\n",
      "[107, 120] loss: 0.125\n",
      "[107, 180] loss: 0.137\n",
      "[107, 240] loss: 0.144\n",
      "[107, 300] loss: 0.137\n",
      "[107, 360] loss: 0.137\n",
      "Epoch: 107 -> Loss: 0.173066794872\n",
      "Epoch: 107 -> Test Accuracy: 90.2825\n",
      "[108, 60] loss: 0.120\n",
      "[108, 120] loss: 0.132\n",
      "[108, 180] loss: 0.139\n",
      "[108, 240] loss: 0.133\n",
      "[108, 300] loss: 0.139\n",
      "[108, 360] loss: 0.139\n",
      "Epoch: 108 -> Loss: 0.180064558983\n",
      "Epoch: 108 -> Test Accuracy: 89.75\n",
      "[109, 60] loss: 0.125\n",
      "[109, 120] loss: 0.128\n",
      "[109, 180] loss: 0.132\n",
      "[109, 240] loss: 0.137\n",
      "[109, 300] loss: 0.142\n",
      "[109, 360] loss: 0.135\n",
      "Epoch: 109 -> Loss: 0.232370138168\n",
      "Epoch: 109 -> Test Accuracy: 90.5725\n",
      "[110, 60] loss: 0.124\n",
      "[110, 120] loss: 0.128\n",
      "[110, 180] loss: 0.131\n",
      "[110, 240] loss: 0.135\n",
      "[110, 300] loss: 0.140\n",
      "[110, 360] loss: 0.145\n",
      "Epoch: 110 -> Loss: 0.151858717203\n",
      "Epoch: 110 -> Test Accuracy: 90.5025\n",
      "[111, 60] loss: 0.133\n",
      "[111, 120] loss: 0.134\n",
      "[111, 180] loss: 0.127\n",
      "[111, 240] loss: 0.139\n",
      "[111, 300] loss: 0.132\n",
      "[111, 360] loss: 0.135\n",
      "Epoch: 111 -> Loss: 0.0806073993444\n",
      "Epoch: 111 -> Test Accuracy: 90.74\n",
      "[112, 60] loss: 0.128\n",
      "[112, 120] loss: 0.127\n",
      "[112, 180] loss: 0.138\n",
      "[112, 240] loss: 0.132\n",
      "[112, 300] loss: 0.130\n",
      "[112, 360] loss: 0.138\n",
      "Epoch: 112 -> Loss: 0.205824777484\n",
      "Epoch: 112 -> Test Accuracy: 90.8275\n",
      "[113, 60] loss: 0.127\n",
      "[113, 120] loss: 0.124\n",
      "[113, 180] loss: 0.132\n",
      "[113, 240] loss: 0.136\n",
      "[113, 300] loss: 0.136\n",
      "[113, 360] loss: 0.135\n",
      "Epoch: 113 -> Loss: 0.129717409611\n",
      "Epoch: 113 -> Test Accuracy: 90.77\n",
      "[114, 60] loss: 0.121\n",
      "[114, 120] loss: 0.133\n",
      "[114, 180] loss: 0.127\n",
      "[114, 240] loss: 0.136\n",
      "[114, 300] loss: 0.138\n",
      "[114, 360] loss: 0.141\n",
      "Epoch: 114 -> Loss: 0.102893613279\n",
      "Epoch: 114 -> Test Accuracy: 90.55\n",
      "[115, 60] loss: 0.125\n",
      "[115, 120] loss: 0.140\n",
      "[115, 180] loss: 0.132\n",
      "[115, 240] loss: 0.131\n",
      "[115, 300] loss: 0.131\n",
      "[115, 360] loss: 0.135\n",
      "Epoch: 115 -> Loss: 0.130635172129\n",
      "Epoch: 115 -> Test Accuracy: 90.2425\n",
      "[116, 60] loss: 0.125\n",
      "[116, 120] loss: 0.136\n",
      "[116, 180] loss: 0.130\n",
      "[116, 240] loss: 0.142\n",
      "[116, 300] loss: 0.133\n",
      "[116, 360] loss: 0.137\n",
      "Epoch: 116 -> Loss: 0.102799974382\n",
      "Epoch: 116 -> Test Accuracy: 90.9425\n",
      "[117, 60] loss: 0.117\n",
      "[117, 120] loss: 0.134\n",
      "[117, 180] loss: 0.131\n",
      "[117, 240] loss: 0.134\n",
      "[117, 300] loss: 0.130\n",
      "[117, 360] loss: 0.135\n",
      "Epoch: 117 -> Loss: 0.146823644638\n",
      "Epoch: 117 -> Test Accuracy: 91.1075\n",
      "[118, 60] loss: 0.122\n",
      "[118, 120] loss: 0.131\n",
      "[118, 180] loss: 0.129\n",
      "[118, 240] loss: 0.128\n",
      "[118, 300] loss: 0.133\n",
      "[118, 360] loss: 0.138\n",
      "Epoch: 118 -> Loss: 0.0832188278437\n",
      "Epoch: 118 -> Test Accuracy: 90.4925\n",
      "[119, 60] loss: 0.125\n",
      "[119, 120] loss: 0.126\n",
      "[119, 180] loss: 0.128\n",
      "[119, 240] loss: 0.132\n",
      "[119, 300] loss: 0.137\n",
      "[119, 360] loss: 0.137\n",
      "Epoch: 119 -> Loss: 0.0917651355267\n",
      "Epoch: 119 -> Test Accuracy: 89.96\n",
      "[120, 60] loss: 0.123\n",
      "[120, 120] loss: 0.122\n",
      "[120, 180] loss: 0.128\n",
      "[120, 240] loss: 0.128\n",
      "[120, 300] loss: 0.133\n",
      "[120, 360] loss: 0.144\n",
      "Epoch: 120 -> Loss: 0.257605493069\n",
      "Epoch: 120 -> Test Accuracy: 90.84\n",
      "[121, 60] loss: 0.093\n",
      "[121, 120] loss: 0.072\n",
      "[121, 180] loss: 0.073\n",
      "[121, 240] loss: 0.065\n",
      "[121, 300] loss: 0.067\n",
      "[121, 360] loss: 0.066\n",
      "Epoch: 121 -> Loss: 0.0559394136071\n",
      "Epoch: 121 -> Test Accuracy: 92.1725\n",
      "[122, 60] loss: 0.057\n",
      "[122, 120] loss: 0.054\n",
      "[122, 180] loss: 0.052\n",
      "[122, 240] loss: 0.052\n",
      "[122, 300] loss: 0.051\n",
      "[122, 360] loss: 0.056\n",
      "Epoch: 122 -> Loss: 0.0560631379485\n",
      "Epoch: 122 -> Test Accuracy: 92.2875\n",
      "[123, 60] loss: 0.043\n",
      "[123, 120] loss: 0.047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123, 180] loss: 0.048\n",
      "[123, 240] loss: 0.052\n",
      "[123, 300] loss: 0.052\n",
      "[123, 360] loss: 0.051\n",
      "Epoch: 123 -> Loss: 0.0148330880329\n",
      "Epoch: 123 -> Test Accuracy: 91.9825\n",
      "[124, 60] loss: 0.041\n",
      "[124, 120] loss: 0.042\n",
      "[124, 180] loss: 0.045\n",
      "[124, 240] loss: 0.046\n",
      "[124, 300] loss: 0.052\n",
      "[124, 360] loss: 0.047\n",
      "Epoch: 124 -> Loss: 0.0377366840839\n",
      "Epoch: 124 -> Test Accuracy: 92.2075\n",
      "[125, 60] loss: 0.040\n",
      "[125, 120] loss: 0.041\n",
      "[125, 180] loss: 0.044\n",
      "[125, 240] loss: 0.045\n",
      "[125, 300] loss: 0.044\n",
      "[125, 360] loss: 0.038\n",
      "Epoch: 125 -> Loss: 0.0206672232598\n",
      "Epoch: 125 -> Test Accuracy: 92.155\n",
      "[126, 60] loss: 0.042\n",
      "[126, 120] loss: 0.042\n",
      "[126, 180] loss: 0.041\n",
      "[126, 240] loss: 0.036\n",
      "[126, 300] loss: 0.041\n",
      "[126, 360] loss: 0.045\n",
      "Epoch: 126 -> Loss: 0.0411295220256\n",
      "Epoch: 126 -> Test Accuracy: 92.0525\n",
      "[127, 60] loss: 0.036\n",
      "[127, 120] loss: 0.039\n",
      "[127, 180] loss: 0.035\n",
      "[127, 240] loss: 0.040\n",
      "[127, 300] loss: 0.039\n",
      "[127, 360] loss: 0.037\n",
      "Epoch: 127 -> Loss: 0.0752921774983\n",
      "Epoch: 127 -> Test Accuracy: 92.095\n",
      "[128, 60] loss: 0.034\n",
      "[128, 120] loss: 0.036\n",
      "[128, 180] loss: 0.035\n",
      "[128, 240] loss: 0.035\n",
      "[128, 300] loss: 0.039\n",
      "[128, 360] loss: 0.039\n",
      "Epoch: 128 -> Loss: 0.0362565517426\n",
      "Epoch: 128 -> Test Accuracy: 91.875\n",
      "[129, 60] loss: 0.036\n",
      "[129, 120] loss: 0.036\n",
      "[129, 180] loss: 0.031\n",
      "[129, 240] loss: 0.035\n",
      "[129, 300] loss: 0.036\n",
      "[129, 360] loss: 0.043\n",
      "Epoch: 129 -> Loss: 0.0492194481194\n",
      "Epoch: 129 -> Test Accuracy: 91.925\n",
      "[130, 60] loss: 0.027\n",
      "[130, 120] loss: 0.032\n",
      "[130, 180] loss: 0.033\n",
      "[130, 240] loss: 0.034\n",
      "[130, 300] loss: 0.034\n",
      "[130, 360] loss: 0.036\n",
      "Epoch: 130 -> Loss: 0.0460752211511\n",
      "Epoch: 130 -> Test Accuracy: 91.9775\n",
      "[131, 60] loss: 0.031\n",
      "[131, 120] loss: 0.033\n",
      "[131, 180] loss: 0.037\n",
      "[131, 240] loss: 0.034\n",
      "[131, 300] loss: 0.033\n",
      "[131, 360] loss: 0.032\n",
      "Epoch: 131 -> Loss: 0.0284233689308\n",
      "Epoch: 131 -> Test Accuracy: 91.8175\n",
      "[132, 60] loss: 0.031\n",
      "[132, 120] loss: 0.035\n",
      "[132, 180] loss: 0.035\n",
      "[132, 240] loss: 0.036\n",
      "[132, 300] loss: 0.036\n",
      "[132, 360] loss: 0.032\n",
      "Epoch: 132 -> Loss: 0.0425770096481\n",
      "Epoch: 132 -> Test Accuracy: 91.84\n",
      "[133, 60] loss: 0.030\n",
      "[133, 120] loss: 0.031\n",
      "[133, 180] loss: 0.034\n",
      "[133, 240] loss: 0.032\n",
      "[133, 300] loss: 0.032\n",
      "[133, 360] loss: 0.032\n",
      "Epoch: 133 -> Loss: 0.0169217176735\n",
      "Epoch: 133 -> Test Accuracy: 92.11\n",
      "[134, 60] loss: 0.033\n",
      "[134, 120] loss: 0.032\n",
      "[134, 180] loss: 0.030\n",
      "[134, 240] loss: 0.032\n",
      "[134, 300] loss: 0.031\n",
      "[134, 360] loss: 0.031\n",
      "Epoch: 134 -> Loss: 0.0274030622095\n",
      "Epoch: 134 -> Test Accuracy: 92.165\n",
      "[135, 60] loss: 0.029\n",
      "[135, 120] loss: 0.030\n",
      "[135, 180] loss: 0.030\n",
      "[135, 240] loss: 0.029\n",
      "[135, 300] loss: 0.034\n",
      "[135, 360] loss: 0.035\n",
      "Epoch: 135 -> Loss: 0.0400777235627\n",
      "Epoch: 135 -> Test Accuracy: 91.825\n",
      "[136, 60] loss: 0.028\n",
      "[136, 120] loss: 0.032\n",
      "[136, 180] loss: 0.032\n",
      "[136, 240] loss: 0.032\n",
      "[136, 300] loss: 0.031\n",
      "[136, 360] loss: 0.030\n",
      "Epoch: 136 -> Loss: 0.0360038354993\n",
      "Epoch: 136 -> Test Accuracy: 92.1\n",
      "[137, 60] loss: 0.027\n",
      "[137, 120] loss: 0.029\n",
      "[137, 180] loss: 0.028\n",
      "[137, 240] loss: 0.031\n",
      "[137, 300] loss: 0.033\n",
      "[137, 360] loss: 0.032\n",
      "Epoch: 137 -> Loss: 0.02445705235\n",
      "Epoch: 137 -> Test Accuracy: 92.1125\n",
      "[138, 60] loss: 0.030\n",
      "[138, 120] loss: 0.028\n",
      "[138, 180] loss: 0.028\n",
      "[138, 240] loss: 0.031\n",
      "[138, 300] loss: 0.031\n",
      "[138, 360] loss: 0.033\n",
      "Epoch: 138 -> Loss: 0.0338713750243\n",
      "Epoch: 138 -> Test Accuracy: 91.465\n",
      "[139, 60] loss: 0.030\n",
      "[139, 120] loss: 0.031\n",
      "[139, 180] loss: 0.029\n",
      "[139, 240] loss: 0.030\n",
      "[139, 300] loss: 0.032\n",
      "[139, 360] loss: 0.028\n",
      "Epoch: 139 -> Loss: 0.0201532226056\n",
      "Epoch: 139 -> Test Accuracy: 91.9725\n",
      "[140, 60] loss: 0.029\n",
      "[140, 120] loss: 0.030\n",
      "[140, 180] loss: 0.029\n",
      "[140, 240] loss: 0.028\n",
      "[140, 300] loss: 0.031\n",
      "[140, 360] loss: 0.033\n",
      "Epoch: 140 -> Loss: 0.00533206481487\n",
      "Epoch: 140 -> Test Accuracy: 92.09\n",
      "[141, 60] loss: 0.029\n",
      "[141, 120] loss: 0.029\n",
      "[141, 180] loss: 0.029\n",
      "[141, 240] loss: 0.031\n",
      "[141, 300] loss: 0.027\n",
      "[141, 360] loss: 0.033\n",
      "Epoch: 141 -> Loss: 0.0281459782273\n",
      "Epoch: 141 -> Test Accuracy: 91.965\n",
      "[142, 60] loss: 0.027\n",
      "[142, 120] loss: 0.025\n",
      "[142, 180] loss: 0.028\n",
      "[142, 240] loss: 0.030\n",
      "[142, 300] loss: 0.030\n",
      "[142, 360] loss: 0.036\n",
      "Epoch: 142 -> Loss: 0.0171778351068\n",
      "Epoch: 142 -> Test Accuracy: 91.78\n",
      "[143, 60] loss: 0.032\n",
      "[143, 120] loss: 0.026\n",
      "[143, 180] loss: 0.026\n",
      "[143, 240] loss: 0.029\n",
      "[143, 300] loss: 0.030\n",
      "[143, 360] loss: 0.032\n",
      "Epoch: 143 -> Loss: 0.0225059371442\n",
      "Epoch: 143 -> Test Accuracy: 91.78\n",
      "[144, 60] loss: 0.027\n",
      "[144, 120] loss: 0.029\n",
      "[144, 180] loss: 0.029\n",
      "[144, 240] loss: 0.031\n",
      "[144, 300] loss: 0.031\n",
      "[144, 360] loss: 0.030\n",
      "Epoch: 144 -> Loss: 0.0142978597432\n",
      "Epoch: 144 -> Test Accuracy: 92.0075\n",
      "[145, 60] loss: 0.026\n",
      "[145, 120] loss: 0.027\n",
      "[145, 180] loss: 0.032\n",
      "[145, 240] loss: 0.030\n",
      "[145, 300] loss: 0.029\n",
      "[145, 360] loss: 0.030\n",
      "Epoch: 145 -> Loss: 0.0535159409046\n",
      "Epoch: 145 -> Test Accuracy: 91.88\n",
      "[146, 60] loss: 0.027\n",
      "[146, 120] loss: 0.029\n",
      "[146, 180] loss: 0.030\n",
      "[146, 240] loss: 0.029\n",
      "[146, 300] loss: 0.030\n",
      "[146, 360] loss: 0.033\n",
      "Epoch: 146 -> Loss: 0.0269024260342\n",
      "Epoch: 146 -> Test Accuracy: 91.7575\n",
      "[147, 60] loss: 0.028\n",
      "[147, 120] loss: 0.030\n",
      "[147, 180] loss: 0.030\n",
      "[147, 240] loss: 0.031\n",
      "[147, 300] loss: 0.033\n",
      "[147, 360] loss: 0.027\n",
      "Epoch: 147 -> Loss: 0.0294453147799\n",
      "Epoch: 147 -> Test Accuracy: 91.7875\n",
      "[148, 60] loss: 0.026\n",
      "[148, 120] loss: 0.027\n",
      "[148, 180] loss: 0.030\n",
      "[148, 240] loss: 0.033\n",
      "[148, 300] loss: 0.032\n",
      "[148, 360] loss: 0.035\n",
      "Epoch: 148 -> Loss: 0.0133654130623\n",
      "Epoch: 148 -> Test Accuracy: 91.7375\n",
      "[149, 60] loss: 0.024\n",
      "[149, 120] loss: 0.028\n",
      "[149, 180] loss: 0.030\n",
      "[149, 240] loss: 0.031\n",
      "[149, 300] loss: 0.030\n",
      "[149, 360] loss: 0.032\n",
      "Epoch: 149 -> Loss: 0.0263340882957\n",
      "Epoch: 149 -> Test Accuracy: 91.665\n",
      "[150, 60] loss: 0.025\n",
      "[150, 120] loss: 0.025\n",
      "[150, 180] loss: 0.032\n",
      "[150, 240] loss: 0.029\n",
      "[150, 300] loss: 0.027\n",
      "[150, 360] loss: 0.032\n",
      "Epoch: 150 -> Loss: 0.0236299447715\n",
      "Epoch: 150 -> Test Accuracy: 91.7425\n",
      "[151, 60] loss: 0.028\n",
      "[151, 120] loss: 0.028\n",
      "[151, 180] loss: 0.032\n",
      "[151, 240] loss: 0.029\n",
      "[151, 300] loss: 0.031\n",
      "[151, 360] loss: 0.029\n",
      "Epoch: 151 -> Loss: 0.00984872318804\n",
      "Epoch: 151 -> Test Accuracy: 91.6275\n",
      "[152, 60] loss: 0.032\n",
      "[152, 120] loss: 0.029\n",
      "[152, 180] loss: 0.030\n",
      "[152, 240] loss: 0.031\n",
      "[152, 300] loss: 0.033\n",
      "[152, 360] loss: 0.030\n",
      "Epoch: 152 -> Loss: 0.0473557561636\n",
      "Epoch: 152 -> Test Accuracy: 91.9175\n",
      "[153, 60] loss: 0.026\n",
      "[153, 120] loss: 0.027\n",
      "[153, 180] loss: 0.031\n",
      "[153, 240] loss: 0.030\n",
      "[153, 300] loss: 0.032\n",
      "[153, 360] loss: 0.030\n",
      "Epoch: 153 -> Loss: 0.0603126883507\n",
      "Epoch: 153 -> Test Accuracy: 91.8225\n",
      "[154, 60] loss: 0.032\n",
      "[154, 120] loss: 0.029\n",
      "[154, 180] loss: 0.028\n",
      "[154, 240] loss: 0.031\n",
      "[154, 300] loss: 0.031\n",
      "[154, 360] loss: 0.032\n",
      "Epoch: 154 -> Loss: 0.0681094676256\n",
      "Epoch: 154 -> Test Accuracy: 91.76\n",
      "[155, 60] loss: 0.032\n",
      "[155, 120] loss: 0.028\n",
      "[155, 180] loss: 0.029\n",
      "[155, 240] loss: 0.033\n",
      "[155, 300] loss: 0.032\n",
      "[155, 360] loss: 0.031\n",
      "Epoch: 155 -> Loss: 0.0616619810462\n",
      "Epoch: 155 -> Test Accuracy: 91.565\n",
      "[156, 60] loss: 0.028\n",
      "[156, 120] loss: 0.031\n",
      "[156, 180] loss: 0.028\n",
      "[156, 240] loss: 0.031\n",
      "[156, 300] loss: 0.030\n",
      "[156, 360] loss: 0.031\n",
      "Epoch: 156 -> Loss: 0.0144073693082\n",
      "Epoch: 156 -> Test Accuracy: 91.815\n",
      "[157, 60] loss: 0.025\n",
      "[157, 120] loss: 0.029\n",
      "[157, 180] loss: 0.031\n",
      "[157, 240] loss: 0.029\n",
      "[157, 300] loss: 0.030\n",
      "[157, 360] loss: 0.034\n",
      "Epoch: 157 -> Loss: 0.0463943704963\n",
      "Epoch: 157 -> Test Accuracy: 91.8575\n",
      "[158, 60] loss: 0.027\n",
      "[158, 120] loss: 0.029\n",
      "[158, 180] loss: 0.029\n",
      "[158, 240] loss: 0.030\n",
      "[158, 300] loss: 0.034\n",
      "[158, 360] loss: 0.032\n",
      "Epoch: 158 -> Loss: 0.0265532322228\n",
      "Epoch: 158 -> Test Accuracy: 91.7175\n",
      "[159, 60] loss: 0.026\n",
      "[159, 120] loss: 0.030\n",
      "[159, 180] loss: 0.028\n",
      "[159, 240] loss: 0.027\n",
      "[159, 300] loss: 0.034\n",
      "[159, 360] loss: 0.034\n",
      "Epoch: 159 -> Loss: 0.0398187860847\n",
      "Epoch: 159 -> Test Accuracy: 91.6725\n",
      "[160, 60] loss: 0.032\n",
      "[160, 120] loss: 0.027\n",
      "[160, 180] loss: 0.032\n",
      "[160, 240] loss: 0.034\n",
      "[160, 300] loss: 0.032\n",
      "[160, 360] loss: 0.031\n",
      "Epoch: 160 -> Loss: 0.0200711917132\n",
      "Epoch: 160 -> Test Accuracy: 91.755\n",
      "[161, 60] loss: 0.023\n",
      "[161, 120] loss: 0.020\n",
      "[161, 180] loss: 0.017\n",
      "[161, 240] loss: 0.017\n",
      "[161, 300] loss: 0.017\n",
      "[161, 360] loss: 0.017\n",
      "Epoch: 161 -> Loss: 0.0184059329331\n",
      "Epoch: 161 -> Test Accuracy: 92.31\n",
      "[162, 60] loss: 0.013\n",
      "[162, 120] loss: 0.013\n",
      "[162, 180] loss: 0.013\n",
      "[162, 240] loss: 0.013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[162, 300] loss: 0.012\n",
      "[162, 360] loss: 0.012\n",
      "Epoch: 162 -> Loss: 0.00314091285691\n",
      "Epoch: 162 -> Test Accuracy: 92.435\n",
      "[163, 60] loss: 0.011\n",
      "[163, 120] loss: 0.011\n",
      "[163, 180] loss: 0.011\n",
      "[163, 240] loss: 0.012\n",
      "[163, 300] loss: 0.010\n",
      "[163, 360] loss: 0.011\n",
      "Epoch: 163 -> Loss: 0.00350856408477\n",
      "Epoch: 163 -> Test Accuracy: 92.4125\n",
      "[164, 60] loss: 0.011\n",
      "[164, 120] loss: 0.011\n",
      "[164, 180] loss: 0.009\n",
      "[164, 240] loss: 0.009\n",
      "[164, 300] loss: 0.010\n",
      "[164, 360] loss: 0.010\n",
      "Epoch: 164 -> Loss: 0.0169294569641\n",
      "Epoch: 164 -> Test Accuracy: 92.4475\n",
      "[165, 60] loss: 0.010\n",
      "[165, 120] loss: 0.009\n",
      "[165, 180] loss: 0.009\n",
      "[165, 240] loss: 0.010\n",
      "[165, 300] loss: 0.009\n",
      "[165, 360] loss: 0.009\n",
      "Epoch: 165 -> Loss: 0.00823862664402\n",
      "Epoch: 165 -> Test Accuracy: 92.4475\n",
      "[166, 60] loss: 0.009\n",
      "[166, 120] loss: 0.008\n",
      "[166, 180] loss: 0.011\n",
      "[166, 240] loss: 0.010\n",
      "[166, 300] loss: 0.009\n",
      "[166, 360] loss: 0.009\n",
      "Epoch: 166 -> Loss: 0.0194574482739\n",
      "Epoch: 166 -> Test Accuracy: 92.49\n",
      "[167, 60] loss: 0.008\n",
      "[167, 120] loss: 0.010\n",
      "[167, 180] loss: 0.008\n",
      "[167, 240] loss: 0.009\n",
      "[167, 300] loss: 0.008\n",
      "[167, 360] loss: 0.009\n",
      "Epoch: 167 -> Loss: 0.00510756904259\n",
      "Epoch: 167 -> Test Accuracy: 92.48\n",
      "[168, 60] loss: 0.009\n",
      "[168, 120] loss: 0.008\n",
      "[168, 180] loss: 0.007\n",
      "[168, 240] loss: 0.009\n",
      "[168, 300] loss: 0.008\n",
      "[168, 360] loss: 0.008\n",
      "Epoch: 168 -> Loss: 0.0255584828556\n",
      "Epoch: 168 -> Test Accuracy: 92.38\n",
      "[169, 60] loss: 0.007\n",
      "[169, 120] loss: 0.007\n",
      "[169, 180] loss: 0.007\n",
      "[169, 240] loss: 0.007\n",
      "[169, 300] loss: 0.008\n",
      "[169, 360] loss: 0.007\n",
      "Epoch: 169 -> Loss: 0.00378001178615\n",
      "Epoch: 169 -> Test Accuracy: 92.305\n",
      "[170, 60] loss: 0.007\n",
      "[170, 120] loss: 0.007\n",
      "[170, 180] loss: 0.008\n",
      "[170, 240] loss: 0.007\n",
      "[170, 300] loss: 0.007\n",
      "[170, 360] loss: 0.008\n",
      "Epoch: 170 -> Loss: 0.0335389263928\n",
      "Epoch: 170 -> Test Accuracy: 92.43\n",
      "[171, 60] loss: 0.006\n",
      "[171, 120] loss: 0.007\n",
      "[171, 180] loss: 0.007\n",
      "[171, 240] loss: 0.007\n",
      "[171, 300] loss: 0.007\n",
      "[171, 360] loss: 0.008\n",
      "Epoch: 171 -> Loss: 0.00844862498343\n",
      "Epoch: 171 -> Test Accuracy: 92.3275\n",
      "[172, 60] loss: 0.007\n",
      "[172, 120] loss: 0.006\n",
      "[172, 180] loss: 0.008\n",
      "[172, 240] loss: 0.006\n",
      "[172, 300] loss: 0.007\n",
      "[172, 360] loss: 0.006\n",
      "Epoch: 172 -> Loss: 0.0095981284976\n",
      "Epoch: 172 -> Test Accuracy: 92.45\n",
      "[173, 60] loss: 0.006\n",
      "[173, 120] loss: 0.008\n",
      "[173, 180] loss: 0.006\n",
      "[173, 240] loss: 0.006\n",
      "[173, 300] loss: 0.007\n",
      "[173, 360] loss: 0.006\n",
      "Epoch: 173 -> Loss: 0.00520492205396\n",
      "Epoch: 173 -> Test Accuracy: 92.39\n",
      "[174, 60] loss: 0.006\n",
      "[174, 120] loss: 0.008\n",
      "[174, 180] loss: 0.007\n",
      "[174, 240] loss: 0.006\n",
      "[174, 300] loss: 0.006\n",
      "[174, 360] loss: 0.006\n",
      "Epoch: 174 -> Loss: 0.00190228072461\n",
      "Epoch: 174 -> Test Accuracy: 92.335\n",
      "[175, 60] loss: 0.006\n",
      "[175, 120] loss: 0.006\n",
      "[175, 180] loss: 0.007\n",
      "[175, 240] loss: 0.007\n",
      "[175, 300] loss: 0.006\n",
      "[175, 360] loss: 0.007\n",
      "Epoch: 175 -> Loss: 0.00364995817654\n",
      "Epoch: 175 -> Test Accuracy: 92.325\n",
      "[176, 60] loss: 0.007\n",
      "[176, 120] loss: 0.005\n",
      "[176, 180] loss: 0.006\n",
      "[176, 240] loss: 0.006\n",
      "[176, 300] loss: 0.006\n",
      "[176, 360] loss: 0.006\n",
      "Epoch: 176 -> Loss: 0.00270276074298\n",
      "Epoch: 176 -> Test Accuracy: 92.43\n",
      "[177, 60] loss: 0.007\n",
      "[177, 120] loss: 0.006\n",
      "[177, 180] loss: 0.006\n",
      "[177, 240] loss: 0.006\n",
      "[177, 300] loss: 0.006\n",
      "[177, 360] loss: 0.006\n",
      "Epoch: 177 -> Loss: 0.0037223151885\n",
      "Epoch: 177 -> Test Accuracy: 92.5525\n",
      "[178, 60] loss: 0.006\n",
      "[178, 120] loss: 0.007\n",
      "[178, 180] loss: 0.007\n",
      "[178, 240] loss: 0.006\n",
      "[178, 300] loss: 0.006\n",
      "[178, 360] loss: 0.006\n",
      "Epoch: 178 -> Loss: 0.0108317798004\n",
      "Epoch: 178 -> Test Accuracy: 92.485\n",
      "[179, 60] loss: 0.006\n",
      "[179, 120] loss: 0.006\n",
      "[179, 180] loss: 0.006\n",
      "[179, 240] loss: 0.005\n",
      "[179, 300] loss: 0.006\n",
      "[179, 360] loss: 0.006\n",
      "Epoch: 179 -> Loss: 0.00263622542843\n",
      "Epoch: 179 -> Test Accuracy: 92.395\n",
      "[180, 60] loss: 0.005\n",
      "[180, 120] loss: 0.005\n",
      "[180, 180] loss: 0.006\n",
      "[180, 240] loss: 0.006\n",
      "[180, 300] loss: 0.005\n",
      "[180, 360] loss: 0.006\n",
      "Epoch: 180 -> Loss: 0.00789317674935\n",
      "Epoch: 180 -> Test Accuracy: 92.3275\n",
      "[181, 60] loss: 0.006\n",
      "[181, 120] loss: 0.005\n",
      "[181, 180] loss: 0.005\n",
      "[181, 240] loss: 0.005\n",
      "[181, 300] loss: 0.008\n",
      "[181, 360] loss: 0.006\n",
      "Epoch: 181 -> Loss: 0.00496423570439\n",
      "Epoch: 181 -> Test Accuracy: 92.375\n",
      "[182, 60] loss: 0.005\n",
      "[182, 120] loss: 0.006\n",
      "[182, 180] loss: 0.005\n",
      "[182, 240] loss: 0.005\n",
      "[182, 300] loss: 0.006\n",
      "[182, 360] loss: 0.006\n",
      "Epoch: 182 -> Loss: 0.00954132713377\n",
      "Epoch: 182 -> Test Accuracy: 92.32\n",
      "[183, 60] loss: 0.006\n",
      "[183, 120] loss: 0.005\n",
      "[183, 180] loss: 0.007\n",
      "[183, 240] loss: 0.005\n",
      "[183, 300] loss: 0.006\n",
      "[183, 360] loss: 0.006\n",
      "Epoch: 183 -> Loss: 0.00245546246879\n",
      "Epoch: 183 -> Test Accuracy: 92.3675\n",
      "[184, 60] loss: 0.005\n",
      "[184, 120] loss: 0.006\n",
      "[184, 180] loss: 0.006\n",
      "[184, 240] loss: 0.005\n",
      "[184, 300] loss: 0.006\n",
      "[184, 360] loss: 0.005\n",
      "Epoch: 184 -> Loss: 0.0033136960119\n",
      "Epoch: 184 -> Test Accuracy: 92.2575\n",
      "[185, 60] loss: 0.006\n",
      "[185, 120] loss: 0.005\n",
      "[185, 180] loss: 0.006\n",
      "[185, 240] loss: 0.005\n",
      "[185, 300] loss: 0.005\n",
      "[185, 360] loss: 0.005\n",
      "Epoch: 185 -> Loss: 0.00749422470108\n",
      "Epoch: 185 -> Test Accuracy: 92.3525\n",
      "[186, 60] loss: 0.005\n",
      "[186, 120] loss: 0.005\n",
      "[186, 180] loss: 0.004\n",
      "[186, 240] loss: 0.004\n",
      "[186, 300] loss: 0.005\n",
      "[186, 360] loss: 0.006\n",
      "Epoch: 186 -> Loss: 0.0159677267075\n",
      "Epoch: 186 -> Test Accuracy: 92.185\n",
      "[187, 60] loss: 0.005\n",
      "[187, 120] loss: 0.005\n",
      "[187, 180] loss: 0.006\n",
      "[187, 240] loss: 0.005\n",
      "[187, 300] loss: 0.004\n",
      "[187, 360] loss: 0.006\n",
      "Epoch: 187 -> Loss: 0.00295832124539\n",
      "Epoch: 187 -> Test Accuracy: 92.3325\n",
      "[188, 60] loss: 0.005\n",
      "[188, 120] loss: 0.004\n",
      "[188, 180] loss: 0.005\n",
      "[188, 240] loss: 0.006\n",
      "[188, 300] loss: 0.005\n",
      "[188, 360] loss: 0.004\n",
      "Epoch: 188 -> Loss: 0.00300142844208\n",
      "Epoch: 188 -> Test Accuracy: 92.305\n",
      "[189, 60] loss: 0.004\n",
      "[189, 120] loss: 0.005\n",
      "[189, 180] loss: 0.005\n",
      "[189, 240] loss: 0.005\n",
      "[189, 300] loss: 0.007\n",
      "[189, 360] loss: 0.005\n",
      "Epoch: 189 -> Loss: 0.00213392218575\n",
      "Epoch: 189 -> Test Accuracy: 92.2825\n",
      "[190, 60] loss: 0.005\n",
      "[190, 120] loss: 0.005\n",
      "[190, 180] loss: 0.005\n",
      "[190, 240] loss: 0.005\n",
      "[190, 300] loss: 0.005\n",
      "[190, 360] loss: 0.005\n",
      "Epoch: 190 -> Loss: 0.00541072711349\n",
      "Epoch: 190 -> Test Accuracy: 92.235\n",
      "[191, 60] loss: 0.004\n",
      "[191, 120] loss: 0.007\n",
      "[191, 180] loss: 0.005\n",
      "[191, 240] loss: 0.006\n",
      "[191, 300] loss: 0.005\n",
      "[191, 360] loss: 0.005\n",
      "Epoch: 191 -> Loss: 0.00112933665514\n",
      "Epoch: 191 -> Test Accuracy: 92.2325\n",
      "[192, 60] loss: 0.006\n",
      "[192, 120] loss: 0.005\n",
      "[192, 180] loss: 0.004\n",
      "[192, 240] loss: 0.005\n",
      "[192, 300] loss: 0.005\n",
      "[192, 360] loss: 0.004\n",
      "Epoch: 192 -> Loss: 0.0258069634438\n",
      "Epoch: 192 -> Test Accuracy: 92.24\n",
      "[193, 60] loss: 0.005\n",
      "[193, 120] loss: 0.004\n",
      "[193, 180] loss: 0.006\n",
      "[193, 240] loss: 0.004\n",
      "[193, 300] loss: 0.005\n",
      "[193, 360] loss: 0.006\n",
      "Epoch: 193 -> Loss: 0.0157705880702\n",
      "Epoch: 193 -> Test Accuracy: 92.3475\n",
      "[194, 60] loss: 0.005\n",
      "[194, 120] loss: 0.004\n",
      "[194, 180] loss: 0.005\n",
      "[194, 240] loss: 0.004\n",
      "[194, 300] loss: 0.005\n",
      "[194, 360] loss: 0.005\n",
      "Epoch: 194 -> Loss: 0.00097395631019\n",
      "Epoch: 194 -> Test Accuracy: 92.2675\n",
      "[195, 60] loss: 0.005\n",
      "[195, 120] loss: 0.005\n",
      "[195, 180] loss: 0.005\n",
      "[195, 240] loss: 0.004\n",
      "[195, 300] loss: 0.005\n",
      "[195, 360] loss: 0.006\n",
      "Epoch: 195 -> Loss: 0.00141228293069\n",
      "Epoch: 195 -> Test Accuracy: 92.195\n",
      "[196, 60] loss: 0.004\n",
      "[196, 120] loss: 0.005\n",
      "[196, 180] loss: 0.005\n",
      "[196, 240] loss: 0.005\n",
      "[196, 300] loss: 0.005\n",
      "[196, 360] loss: 0.003\n",
      "Epoch: 196 -> Loss: 0.00159400771372\n",
      "Epoch: 196 -> Test Accuracy: 92.325\n",
      "[197, 60] loss: 0.005\n",
      "[197, 120] loss: 0.004\n",
      "[197, 180] loss: 0.005\n",
      "[197, 240] loss: 0.005\n",
      "[197, 300] loss: 0.005\n",
      "[197, 360] loss: 0.004\n",
      "Epoch: 197 -> Loss: 0.0204265844077\n",
      "Epoch: 197 -> Test Accuracy: 92.32\n",
      "[198, 60] loss: 0.005\n",
      "[198, 120] loss: 0.005\n",
      "[198, 180] loss: 0.005\n",
      "[198, 240] loss: 0.004\n",
      "[198, 300] loss: 0.004\n",
      "[198, 360] loss: 0.006\n",
      "Epoch: 198 -> Loss: 0.00392080005258\n",
      "Epoch: 198 -> Test Accuracy: 92.3\n",
      "[199, 60] loss: 0.004\n",
      "[199, 120] loss: 0.005\n",
      "[199, 180] loss: 0.005\n",
      "[199, 240] loss: 0.005\n",
      "[199, 300] loss: 0.004\n",
      "[199, 360] loss: 0.005\n",
      "Epoch: 199 -> Loss: 0.00468687713146\n",
      "Epoch: 199 -> Test Accuracy: 92.38\n",
      "[200, 60] loss: 0.005\n",
      "[200, 120] loss: 0.004\n",
      "[200, 180] loss: 0.004\n",
      "[200, 240] loss: 0.005\n",
      "[200, 300] loss: 0.005\n",
      "[200, 360] loss: 0.005\n",
      "Epoch: 200 -> Loss: 0.00210832129233\n",
      "Epoch: 200 -> Test Accuracy: 92.37\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "rot_block5_avg_loss_log, rot_block5_avg_valid_accuracy_log, rot_block5_avg_test_accuracy_log, \\\n",
    "rot_block5_avg_max_accuracy, rot_block5_avg_best_epoch = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], \n",
    "    [60, 120, 160, 200], 0.9, 5e-4, net_block5_avg, criterion, trainloader, None, testloader, rot=['90', '180', '270'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 2.214\n",
      "[1, 120] loss: 1.257\n",
      "[1, 180] loss: 1.145\n",
      "[1, 240] loss: 1.084\n",
      "[1, 300] loss: 1.035\n",
      "[1, 360] loss: 1.019\n",
      "Epoch: 1 -> Loss: 0.866351306438\n",
      "Epoch: 1 -> Test Accuracy: 67.59\n",
      "[2, 60] loss: 0.956\n",
      "[2, 120] loss: 0.944\n",
      "[2, 180] loss: 0.926\n",
      "[2, 240] loss: 0.905\n",
      "[2, 300] loss: 0.868\n",
      "[2, 360] loss: 0.856\n",
      "Epoch: 2 -> Loss: 0.943861186504\n",
      "Epoch: 2 -> Test Accuracy: 70.2\n",
      "[3, 60] loss: 0.840\n",
      "[3, 120] loss: 0.833\n",
      "[3, 180] loss: 0.825\n",
      "[3, 240] loss: 0.821\n",
      "[3, 300] loss: 0.818\n",
      "[3, 360] loss: 0.804\n",
      "Epoch: 3 -> Loss: 0.877188980579\n",
      "Epoch: 3 -> Test Accuracy: 72.59\n",
      "[4, 60] loss: 0.767\n",
      "[4, 120] loss: 0.798\n",
      "[4, 180] loss: 0.772\n",
      "[4, 240] loss: 0.751\n",
      "[4, 300] loss: 0.763\n",
      "[4, 360] loss: 0.757\n",
      "Epoch: 4 -> Loss: 0.643299341202\n",
      "Epoch: 4 -> Test Accuracy: 73.74\n",
      "[5, 60] loss: 0.744\n",
      "[5, 120] loss: 0.756\n",
      "[5, 180] loss: 0.737\n",
      "[5, 240] loss: 0.735\n",
      "[5, 300] loss: 0.715\n",
      "[5, 360] loss: 0.736\n",
      "Epoch: 5 -> Loss: 0.882134616375\n",
      "Epoch: 5 -> Test Accuracy: 74.77\n",
      "[6, 60] loss: 0.705\n",
      "[6, 120] loss: 0.717\n",
      "[6, 180] loss: 0.713\n",
      "[6, 240] loss: 0.711\n",
      "[6, 300] loss: 0.703\n",
      "[6, 360] loss: 0.711\n",
      "Epoch: 6 -> Loss: 0.826748549938\n",
      "Epoch: 6 -> Test Accuracy: 75.13\n",
      "[7, 60] loss: 0.682\n",
      "[7, 120] loss: 0.689\n",
      "[7, 180] loss: 0.695\n",
      "[7, 240] loss: 0.710\n",
      "[7, 300] loss: 0.691\n",
      "[7, 360] loss: 0.705\n",
      "Epoch: 7 -> Loss: 0.664484798908\n",
      "Epoch: 7 -> Test Accuracy: 75.6\n",
      "[8, 60] loss: 0.656\n",
      "[8, 120] loss: 0.664\n",
      "[8, 180] loss: 0.670\n",
      "[8, 240] loss: 0.656\n",
      "[8, 300] loss: 0.688\n",
      "[8, 360] loss: 0.715\n",
      "Epoch: 8 -> Loss: 0.671104073524\n",
      "Epoch: 8 -> Test Accuracy: 76.01\n",
      "[9, 60] loss: 0.649\n",
      "[9, 120] loss: 0.655\n",
      "[9, 180] loss: 0.675\n",
      "[9, 240] loss: 0.661\n",
      "[9, 300] loss: 0.686\n",
      "[9, 360] loss: 0.665\n",
      "Epoch: 9 -> Loss: 0.650269150734\n",
      "Epoch: 9 -> Test Accuracy: 76.01\n",
      "[10, 60] loss: 0.653\n",
      "[10, 120] loss: 0.634\n",
      "[10, 180] loss: 0.677\n",
      "[10, 240] loss: 0.685\n",
      "[10, 300] loss: 0.656\n",
      "[10, 360] loss: 0.658\n",
      "Epoch: 10 -> Loss: 0.764312148094\n",
      "Epoch: 10 -> Test Accuracy: 77.31\n",
      "[11, 60] loss: 0.645\n",
      "[11, 120] loss: 0.635\n",
      "[11, 180] loss: 0.641\n",
      "[11, 240] loss: 0.640\n",
      "[11, 300] loss: 0.664\n",
      "[11, 360] loss: 0.655\n",
      "Epoch: 11 -> Loss: 0.61246329546\n",
      "Epoch: 11 -> Test Accuracy: 77.19\n",
      "[12, 60] loss: 0.621\n",
      "[12, 120] loss: 0.636\n",
      "[12, 180] loss: 0.634\n",
      "[12, 240] loss: 0.653\n",
      "[12, 300] loss: 0.634\n",
      "[12, 360] loss: 0.646\n",
      "Epoch: 12 -> Loss: 0.733856499195\n",
      "Epoch: 12 -> Test Accuracy: 77.06\n",
      "[13, 60] loss: 0.617\n",
      "[13, 120] loss: 0.626\n",
      "[13, 180] loss: 0.635\n",
      "[13, 240] loss: 0.632\n",
      "[13, 300] loss: 0.634\n",
      "[13, 360] loss: 0.648\n",
      "Epoch: 13 -> Loss: 0.529784500599\n",
      "Epoch: 13 -> Test Accuracy: 77.5\n",
      "[14, 60] loss: 0.625\n",
      "[14, 120] loss: 0.618\n",
      "[14, 180] loss: 0.607\n",
      "[14, 240] loss: 0.621\n",
      "[14, 300] loss: 0.640\n",
      "[14, 360] loss: 0.643\n",
      "Epoch: 14 -> Loss: 0.624111294746\n",
      "Epoch: 14 -> Test Accuracy: 77.93\n",
      "[15, 60] loss: 0.607\n",
      "[15, 120] loss: 0.621\n",
      "[15, 180] loss: 0.617\n",
      "[15, 240] loss: 0.628\n",
      "[15, 300] loss: 0.633\n",
      "[15, 360] loss: 0.630\n",
      "Epoch: 15 -> Loss: 0.650629341602\n",
      "Epoch: 15 -> Test Accuracy: 77.41\n",
      "[16, 60] loss: 0.585\n",
      "[16, 120] loss: 0.595\n",
      "[16, 180] loss: 0.644\n",
      "[16, 240] loss: 0.639\n",
      "[16, 300] loss: 0.627\n",
      "[16, 360] loss: 0.611\n",
      "Epoch: 16 -> Loss: 0.602886080742\n",
      "Epoch: 16 -> Test Accuracy: 77.55\n",
      "[17, 60] loss: 0.590\n",
      "[17, 120] loss: 0.613\n",
      "[17, 180] loss: 0.628\n",
      "[17, 240] loss: 0.618\n",
      "[17, 300] loss: 0.622\n",
      "[17, 360] loss: 0.629\n",
      "Epoch: 17 -> Loss: 0.768774211407\n",
      "Epoch: 17 -> Test Accuracy: 77.94\n",
      "[18, 60] loss: 0.576\n",
      "[18, 120] loss: 0.584\n",
      "[18, 180] loss: 0.634\n",
      "[18, 240] loss: 0.612\n",
      "[18, 300] loss: 0.653\n",
      "[18, 360] loss: 0.625\n",
      "Epoch: 18 -> Loss: 0.860778689384\n",
      "Epoch: 18 -> Test Accuracy: 77.65\n",
      "[19, 60] loss: 0.586\n",
      "[19, 120] loss: 0.621\n",
      "[19, 180] loss: 0.612\n",
      "[19, 240] loss: 0.600\n",
      "[19, 300] loss: 0.625\n",
      "[19, 360] loss: 0.617\n",
      "Epoch: 19 -> Loss: 0.473187834024\n",
      "Epoch: 19 -> Test Accuracy: 77.83\n",
      "[20, 60] loss: 0.606\n",
      "[20, 120] loss: 0.610\n",
      "[20, 180] loss: 0.606\n",
      "[20, 240] loss: 0.625\n",
      "[20, 300] loss: 0.605\n",
      "[20, 360] loss: 0.604\n",
      "Epoch: 20 -> Loss: 0.591773271561\n",
      "Epoch: 20 -> Test Accuracy: 78.14\n",
      "[21, 60] loss: 0.547\n",
      "[21, 120] loss: 0.508\n",
      "[21, 180] loss: 0.512\n",
      "[21, 240] loss: 0.530\n",
      "[21, 300] loss: 0.504\n",
      "[21, 360] loss: 0.503\n",
      "Epoch: 21 -> Loss: 0.526536107063\n",
      "Epoch: 21 -> Test Accuracy: 79.98\n",
      "[22, 60] loss: 0.485\n",
      "[22, 120] loss: 0.484\n",
      "[22, 180] loss: 0.466\n",
      "[22, 240] loss: 0.480\n",
      "[22, 300] loss: 0.479\n",
      "[22, 360] loss: 0.461\n",
      "Epoch: 22 -> Loss: 0.328367590904\n",
      "Epoch: 22 -> Test Accuracy: 80.84\n",
      "[23, 60] loss: 0.461\n",
      "[23, 120] loss: 0.463\n",
      "[23, 180] loss: 0.458\n",
      "[23, 240] loss: 0.474\n",
      "[23, 300] loss: 0.467\n",
      "[23, 360] loss: 0.449\n",
      "Epoch: 23 -> Loss: 0.449536323547\n",
      "Epoch: 23 -> Test Accuracy: 81.26\n",
      "[24, 60] loss: 0.441\n",
      "[24, 120] loss: 0.439\n",
      "[24, 180] loss: 0.435\n",
      "[24, 240] loss: 0.441\n",
      "[24, 300] loss: 0.456\n",
      "[24, 360] loss: 0.456\n",
      "Epoch: 24 -> Loss: 0.308011829853\n",
      "Epoch: 24 -> Test Accuracy: 81.22\n",
      "[25, 60] loss: 0.439\n",
      "[25, 120] loss: 0.444\n",
      "[25, 180] loss: 0.436\n",
      "[25, 240] loss: 0.419\n",
      "[25, 300] loss: 0.436\n",
      "[25, 360] loss: 0.432\n",
      "Epoch: 25 -> Loss: 0.355364859104\n",
      "Epoch: 25 -> Test Accuracy: 81.2\n",
      "[26, 60] loss: 0.439\n",
      "[26, 120] loss: 0.421\n",
      "[26, 180] loss: 0.440\n",
      "[26, 240] loss: 0.417\n",
      "[26, 300] loss: 0.427\n",
      "[26, 360] loss: 0.430\n",
      "Epoch: 26 -> Loss: 0.387684434652\n",
      "Epoch: 26 -> Test Accuracy: 81.23\n",
      "[27, 60] loss: 0.418\n",
      "[27, 120] loss: 0.422\n",
      "[27, 180] loss: 0.409\n",
      "[27, 240] loss: 0.420\n",
      "[27, 300] loss: 0.410\n",
      "[27, 360] loss: 0.431\n",
      "Epoch: 27 -> Loss: 0.43676289916\n",
      "Epoch: 27 -> Test Accuracy: 81.08\n",
      "[28, 60] loss: 0.416\n",
      "[28, 120] loss: 0.414\n",
      "[28, 180] loss: 0.420\n",
      "[28, 240] loss: 0.428\n",
      "[28, 300] loss: 0.402\n",
      "[28, 360] loss: 0.439\n",
      "Epoch: 28 -> Loss: 0.542002558708\n",
      "Epoch: 28 -> Test Accuracy: 80.92\n",
      "[29, 60] loss: 0.420\n",
      "[29, 120] loss: 0.410\n",
      "[29, 180] loss: 0.401\n",
      "[29, 240] loss: 0.424\n",
      "[29, 300] loss: 0.424\n",
      "[29, 360] loss: 0.411\n",
      "Epoch: 29 -> Loss: 0.327830016613\n",
      "Epoch: 29 -> Test Accuracy: 80.93\n",
      "[30, 60] loss: 0.407\n",
      "[30, 120] loss: 0.409\n",
      "[30, 180] loss: 0.416\n",
      "[30, 240] loss: 0.395\n",
      "[30, 300] loss: 0.415\n",
      "[30, 360] loss: 0.420\n",
      "Epoch: 30 -> Loss: 0.365093708038\n",
      "Epoch: 30 -> Test Accuracy: 81.15\n",
      "[31, 60] loss: 0.402\n",
      "[31, 120] loss: 0.407\n",
      "[31, 180] loss: 0.424\n",
      "[31, 240] loss: 0.416\n",
      "[31, 300] loss: 0.392\n",
      "[31, 360] loss: 0.417\n",
      "Epoch: 31 -> Loss: 0.614003241062\n",
      "Epoch: 31 -> Test Accuracy: 81.15\n",
      "[32, 60] loss: 0.395\n",
      "[32, 120] loss: 0.399\n",
      "[32, 180] loss: 0.414\n",
      "[32, 240] loss: 0.420\n",
      "[32, 300] loss: 0.420\n",
      "[32, 360] loss: 0.422\n",
      "Epoch: 32 -> Loss: 0.447226911783\n",
      "Epoch: 32 -> Test Accuracy: 81.07\n",
      "[33, 60] loss: 0.376\n",
      "[33, 120] loss: 0.416\n",
      "[33, 180] loss: 0.404\n",
      "[33, 240] loss: 0.414\n",
      "[33, 300] loss: 0.408\n",
      "[33, 360] loss: 0.420\n",
      "Epoch: 33 -> Loss: 0.383516728878\n",
      "Epoch: 33 -> Test Accuracy: 81.61\n",
      "[34, 60] loss: 0.391\n",
      "[34, 120] loss: 0.395\n",
      "[34, 180] loss: 0.403\n",
      "[34, 240] loss: 0.404\n",
      "[34, 300] loss: 0.409\n",
      "[34, 360] loss: 0.404\n",
      "Epoch: 34 -> Loss: 0.491423130035\n",
      "Epoch: 34 -> Test Accuracy: 81.63\n",
      "[35, 60] loss: 0.393\n",
      "[35, 120] loss: 0.393\n",
      "[35, 180] loss: 0.389\n",
      "[35, 240] loss: 0.404\n",
      "[35, 300] loss: 0.415\n",
      "[35, 360] loss: 0.424\n",
      "Epoch: 35 -> Loss: 0.603465378284\n",
      "Epoch: 35 -> Test Accuracy: 81.4\n",
      "[36, 60] loss: 0.389\n",
      "[36, 120] loss: 0.378\n",
      "[36, 180] loss: 0.392\n",
      "[36, 240] loss: 0.411\n",
      "[36, 300] loss: 0.418\n",
      "[36, 360] loss: 0.407\n",
      "Epoch: 36 -> Loss: 0.336241602898\n",
      "Epoch: 36 -> Test Accuracy: 81.05\n",
      "[37, 60] loss: 0.380\n",
      "[37, 120] loss: 0.394\n",
      "[37, 180] loss: 0.418\n",
      "[37, 240] loss: 0.403\n",
      "[37, 300] loss: 0.408\n",
      "[37, 360] loss: 0.403\n",
      "Epoch: 37 -> Loss: 0.397206038237\n",
      "Epoch: 37 -> Test Accuracy: 81.45\n",
      "[38, 60] loss: 0.390\n",
      "[38, 120] loss: 0.379\n",
      "[38, 180] loss: 0.392\n",
      "[38, 240] loss: 0.406\n",
      "[38, 300] loss: 0.410\n",
      "[38, 360] loss: 0.413\n",
      "Epoch: 38 -> Loss: 0.379726797342\n",
      "Epoch: 38 -> Test Accuracy: 81.03\n",
      "[39, 60] loss: 0.391\n",
      "[39, 120] loss: 0.387\n",
      "[39, 180] loss: 0.399\n",
      "[39, 240] loss: 0.399\n",
      "[39, 300] loss: 0.419\n",
      "[39, 360] loss: 0.412\n",
      "Epoch: 39 -> Loss: 0.409207642078\n",
      "Epoch: 39 -> Test Accuracy: 81.0\n",
      "[40, 60] loss: 0.395\n",
      "[40, 120] loss: 0.391\n",
      "[40, 180] loss: 0.400\n",
      "[40, 240] loss: 0.397\n",
      "[40, 300] loss: 0.389\n",
      "[40, 360] loss: 0.409\n",
      "Epoch: 40 -> Loss: 0.702057778835\n",
      "Epoch: 40 -> Test Accuracy: 81.23\n",
      "[41, 60] loss: 0.374\n",
      "[41, 120] loss: 0.362\n",
      "[41, 180] loss: 0.354\n",
      "[41, 240] loss: 0.348\n",
      "[41, 300] loss: 0.342\n",
      "[41, 360] loss: 0.333\n",
      "Epoch: 41 -> Loss: 0.202545359731\n",
      "Epoch: 41 -> Test Accuracy: 81.96\n",
      "[42, 60] loss: 0.334\n",
      "[42, 120] loss: 0.326\n",
      "[42, 180] loss: 0.338\n",
      "[42, 240] loss: 0.334\n",
      "[42, 300] loss: 0.332\n",
      "[42, 360] loss: 0.327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.369499891996\n",
      "Epoch: 42 -> Test Accuracy: 82.14\n",
      "[43, 60] loss: 0.329\n",
      "[43, 120] loss: 0.315\n",
      "[43, 180] loss: 0.314\n",
      "[43, 240] loss: 0.306\n",
      "[43, 300] loss: 0.327\n",
      "[43, 360] loss: 0.323\n"
     ]
    }
   ],
   "source": [
    "# train NonLinearClassifiers on feature map of net_3block\n",
    "block5_avg_loss_log, block5_avg_valid_accuracy_log, block5_avg_test_accuracy_log, block5_avg_max_accuracy, \\\n",
    "block5_best_epoch = tr.train_all_blocks(5, 10, [0.1, 0.02, 0.004, 0.0008], [20, 40, 45, 100], 0.9, 5e-4, net_block5_avg, \n",
    "                                        criterion, trainloader, None, testloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train ConvClassifiers on feature map of net_3block\n",
    "conv_block5_avg_loss_log, conv_block5_avg_valid_accuracy_log, conv_block5_avg_test_accuracy_log, \\\n",
    "conv_block5_avg_max_accuracy, conv_block5_avg_best_epoch = tr.train_all_blocks(5, 10, [0.1, 0.02, 0.004, 0.0008], \\\n",
    "    [35, 70, 85, 100], 0.9, 5e-4, net_block5_avg, criterion, trainloader, None, testloader, use_ConvClassifier=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename files\n",
    "fm.add_block_to_name(5, [100, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised NIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In the code of the paper a 3 convolutional block RotNet was used for the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize networks\n",
    "net_class = RN.RotNet(num_classes=10, num_conv_block=3, add_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.794\n",
      "[1, 120] loss: 1.453\n",
      "[1, 180] loss: 1.334\n",
      "[1, 240] loss: 1.226\n",
      "[1, 300] loss: 1.148\n",
      "[1, 360] loss: 1.098\n",
      "Epoch: 1 -> Loss: 0.989088892937\n",
      "Epoch: 1 -> Test Accuracy: 60.22\n",
      "[2, 60] loss: 1.020\n",
      "[2, 120] loss: 1.000\n",
      "[2, 180] loss: 0.975\n",
      "[2, 240] loss: 0.921\n",
      "[2, 300] loss: 0.931\n",
      "[2, 360] loss: 0.870\n",
      "Epoch: 2 -> Loss: 0.792598664761\n",
      "Epoch: 2 -> Test Accuracy: 68.92\n",
      "[3, 60] loss: 0.849\n",
      "[3, 120] loss: 0.823\n",
      "[3, 180] loss: 0.795\n",
      "[3, 240] loss: 0.764\n",
      "[3, 300] loss: 0.785\n",
      "[3, 360] loss: 0.769\n",
      "Epoch: 3 -> Loss: 0.676234722137\n",
      "Epoch: 3 -> Test Accuracy: 72.56\n",
      "[4, 60] loss: 0.740\n",
      "[4, 120] loss: 0.716\n",
      "[4, 180] loss: 0.709\n",
      "[4, 240] loss: 0.706\n",
      "[4, 300] loss: 0.695\n",
      "[4, 360] loss: 0.700\n",
      "Epoch: 4 -> Loss: 0.625342488289\n",
      "Epoch: 4 -> Test Accuracy: 74.46\n",
      "[5, 60] loss: 0.668\n",
      "[5, 120] loss: 0.656\n",
      "[5, 180] loss: 0.656\n",
      "[5, 240] loss: 0.651\n",
      "[5, 300] loss: 0.664\n",
      "[5, 360] loss: 0.661\n",
      "Epoch: 5 -> Loss: 0.504440784454\n",
      "Epoch: 5 -> Test Accuracy: 75.3\n",
      "[6, 60] loss: 0.629\n",
      "[6, 120] loss: 0.618\n",
      "[6, 180] loss: 0.629\n",
      "[6, 240] loss: 0.628\n",
      "[6, 300] loss: 0.602\n",
      "[6, 360] loss: 0.634\n",
      "Epoch: 6 -> Loss: 0.620152413845\n",
      "Epoch: 6 -> Test Accuracy: 75.91\n",
      "[7, 60] loss: 0.584\n",
      "[7, 120] loss: 0.583\n",
      "[7, 180] loss: 0.603\n",
      "[7, 240] loss: 0.593\n",
      "[7, 300] loss: 0.585\n",
      "[7, 360] loss: 0.593\n",
      "Epoch: 7 -> Loss: 0.640753090382\n",
      "Epoch: 7 -> Test Accuracy: 78.39\n",
      "[8, 60] loss: 0.569\n",
      "[8, 120] loss: 0.564\n",
      "[8, 180] loss: 0.559\n",
      "[8, 240] loss: 0.564\n",
      "[8, 300] loss: 0.592\n",
      "[8, 360] loss: 0.575\n",
      "Epoch: 8 -> Loss: 0.802178680897\n",
      "Epoch: 8 -> Test Accuracy: 77.16\n",
      "[9, 60] loss: 0.552\n",
      "[9, 120] loss: 0.550\n",
      "[9, 180] loss: 0.534\n",
      "[9, 240] loss: 0.546\n",
      "[9, 300] loss: 0.558\n",
      "[9, 360] loss: 0.534\n",
      "Epoch: 9 -> Loss: 0.793254971504\n",
      "Epoch: 9 -> Test Accuracy: 78.88\n",
      "[10, 60] loss: 0.517\n",
      "[10, 120] loss: 0.534\n",
      "[10, 180] loss: 0.543\n",
      "[10, 240] loss: 0.521\n",
      "[10, 300] loss: 0.534\n",
      "[10, 360] loss: 0.545\n",
      "Epoch: 10 -> Loss: 0.384285777807\n",
      "Epoch: 10 -> Test Accuracy: 79.33\n",
      "[11, 60] loss: 0.500\n",
      "[11, 120] loss: 0.522\n",
      "[11, 180] loss: 0.508\n",
      "[11, 240] loss: 0.522\n",
      "[11, 300] loss: 0.536\n",
      "[11, 360] loss: 0.504\n",
      "Epoch: 11 -> Loss: 0.577188074589\n",
      "Epoch: 11 -> Test Accuracy: 79.07\n",
      "[12, 60] loss: 0.501\n",
      "[12, 120] loss: 0.494\n",
      "[12, 180] loss: 0.503\n",
      "[12, 240] loss: 0.528\n",
      "[12, 300] loss: 0.514\n",
      "[12, 360] loss: 0.514\n",
      "Epoch: 12 -> Loss: 0.561318576336\n",
      "Epoch: 12 -> Test Accuracy: 80.7\n",
      "[13, 60] loss: 0.487\n",
      "[13, 120] loss: 0.518\n",
      "[13, 180] loss: 0.500\n",
      "[13, 240] loss: 0.490\n",
      "[13, 300] loss: 0.502\n",
      "[13, 360] loss: 0.487\n",
      "Epoch: 13 -> Loss: 0.579890489578\n",
      "Epoch: 13 -> Test Accuracy: 80.58\n",
      "[14, 60] loss: 0.492\n",
      "[14, 120] loss: 0.473\n",
      "[14, 180] loss: 0.484\n",
      "[14, 240] loss: 0.475\n",
      "[14, 300] loss: 0.507\n",
      "[14, 360] loss: 0.490\n",
      "Epoch: 14 -> Loss: 0.641694128513\n",
      "Epoch: 14 -> Test Accuracy: 80.56\n",
      "[15, 60] loss: 0.470\n",
      "[15, 120] loss: 0.459\n",
      "[15, 180] loss: 0.502\n",
      "[15, 240] loss: 0.486\n",
      "[15, 300] loss: 0.479\n",
      "[15, 360] loss: 0.482\n",
      "Epoch: 15 -> Loss: 0.55553150177\n",
      "Epoch: 15 -> Test Accuracy: 79.93\n",
      "[16, 60] loss: 0.443\n",
      "[16, 120] loss: 0.457\n",
      "[16, 180] loss: 0.486\n",
      "[16, 240] loss: 0.480\n",
      "[16, 300] loss: 0.504\n",
      "[16, 360] loss: 0.477\n",
      "Epoch: 16 -> Loss: 0.673222005367\n",
      "Epoch: 16 -> Test Accuracy: 81.29\n",
      "[17, 60] loss: 0.454\n",
      "[17, 120] loss: 0.491\n",
      "[17, 180] loss: 0.458\n",
      "[17, 240] loss: 0.457\n",
      "[17, 300] loss: 0.486\n",
      "[17, 360] loss: 0.464\n",
      "Epoch: 17 -> Loss: 0.517729103565\n",
      "Epoch: 17 -> Test Accuracy: 81.51\n",
      "[18, 60] loss: 0.455\n",
      "[18, 120] loss: 0.456\n",
      "[18, 180] loss: 0.452\n",
      "[18, 240] loss: 0.494\n",
      "[18, 300] loss: 0.462\n",
      "[18, 360] loss: 0.443\n",
      "Epoch: 18 -> Loss: 0.497783750296\n",
      "Epoch: 18 -> Test Accuracy: 81.62\n",
      "[19, 60] loss: 0.443\n",
      "[19, 120] loss: 0.465\n",
      "[19, 180] loss: 0.441\n",
      "[19, 240] loss: 0.459\n",
      "[19, 300] loss: 0.473\n",
      "[19, 360] loss: 0.457\n",
      "Epoch: 19 -> Loss: 0.445433288813\n",
      "Epoch: 19 -> Test Accuracy: 81.64\n",
      "[20, 60] loss: 0.455\n",
      "[20, 120] loss: 0.422\n",
      "[20, 180] loss: 0.454\n",
      "[20, 240] loss: 0.440\n",
      "[20, 300] loss: 0.467\n",
      "[20, 360] loss: 0.463\n",
      "Epoch: 20 -> Loss: 0.599771082401\n",
      "Epoch: 20 -> Test Accuracy: 81.75\n",
      "[21, 60] loss: 0.428\n",
      "[21, 120] loss: 0.448\n",
      "[21, 180] loss: 0.433\n",
      "[21, 240] loss: 0.460\n",
      "[21, 300] loss: 0.464\n",
      "[21, 360] loss: 0.456\n",
      "Epoch: 21 -> Loss: 0.415910393\n",
      "Epoch: 21 -> Test Accuracy: 81.77\n",
      "[22, 60] loss: 0.441\n",
      "[22, 120] loss: 0.449\n",
      "[22, 180] loss: 0.431\n",
      "[22, 240] loss: 0.432\n",
      "[22, 300] loss: 0.439\n",
      "[22, 360] loss: 0.435\n",
      "Epoch: 22 -> Loss: 0.205844804645\n",
      "Epoch: 22 -> Test Accuracy: 81.33\n",
      "[23, 60] loss: 0.428\n",
      "[23, 120] loss: 0.417\n",
      "[23, 180] loss: 0.434\n",
      "[23, 240] loss: 0.432\n",
      "[23, 300] loss: 0.441\n",
      "[23, 360] loss: 0.465\n",
      "Epoch: 23 -> Loss: 0.48451513052\n",
      "Epoch: 23 -> Test Accuracy: 80.55\n",
      "[24, 60] loss: 0.406\n",
      "[24, 120] loss: 0.428\n",
      "[24, 180] loss: 0.450\n",
      "[24, 240] loss: 0.451\n",
      "[24, 300] loss: 0.430\n",
      "[24, 360] loss: 0.451\n",
      "Epoch: 24 -> Loss: 0.43328088522\n",
      "Epoch: 24 -> Test Accuracy: 82.17\n",
      "[25, 60] loss: 0.417\n",
      "[25, 120] loss: 0.440\n",
      "[25, 180] loss: 0.422\n",
      "[25, 240] loss: 0.437\n",
      "[25, 300] loss: 0.449\n",
      "[25, 360] loss: 0.450\n",
      "Epoch: 25 -> Loss: 0.226140528917\n",
      "Epoch: 25 -> Test Accuracy: 80.97\n",
      "[26, 60] loss: 0.412\n",
      "[26, 120] loss: 0.419\n",
      "[26, 180] loss: 0.433\n",
      "[26, 240] loss: 0.421\n",
      "[26, 300] loss: 0.447\n",
      "[26, 360] loss: 0.441\n",
      "Epoch: 26 -> Loss: 0.505807638168\n",
      "Epoch: 26 -> Test Accuracy: 82.8\n",
      "[27, 60] loss: 0.408\n",
      "[27, 120] loss: 0.418\n",
      "[27, 180] loss: 0.416\n",
      "[27, 240] loss: 0.434\n",
      "[27, 300] loss: 0.433\n",
      "[27, 360] loss: 0.422\n",
      "Epoch: 27 -> Loss: 0.539763748646\n",
      "Epoch: 27 -> Test Accuracy: 83.15\n",
      "[28, 60] loss: 0.399\n",
      "[28, 120] loss: 0.407\n",
      "[28, 180] loss: 0.448\n",
      "[28, 240] loss: 0.406\n",
      "[28, 300] loss: 0.418\n",
      "[28, 360] loss: 0.449\n",
      "Epoch: 28 -> Loss: 0.402915149927\n",
      "Epoch: 28 -> Test Accuracy: 82.85\n",
      "[29, 60] loss: 0.394\n",
      "[29, 120] loss: 0.402\n",
      "[29, 180] loss: 0.411\n",
      "[29, 240] loss: 0.430\n",
      "[29, 300] loss: 0.433\n",
      "[29, 360] loss: 0.416\n",
      "Epoch: 29 -> Loss: 0.382785618305\n",
      "Epoch: 29 -> Test Accuracy: 81.72\n",
      "[30, 60] loss: 0.423\n",
      "[30, 120] loss: 0.403\n",
      "[30, 180] loss: 0.393\n",
      "[30, 240] loss: 0.420\n",
      "[30, 300] loss: 0.449\n",
      "[30, 360] loss: 0.430\n",
      "Epoch: 30 -> Loss: 0.528232634068\n",
      "Epoch: 30 -> Test Accuracy: 82.87\n",
      "[31, 60] loss: 0.403\n",
      "[31, 120] loss: 0.387\n",
      "[31, 180] loss: 0.404\n",
      "[31, 240] loss: 0.423\n",
      "[31, 300] loss: 0.420\n",
      "[31, 360] loss: 0.429\n",
      "Epoch: 31 -> Loss: 0.445465147495\n",
      "Epoch: 31 -> Test Accuracy: 82.0\n",
      "[32, 60] loss: 0.382\n",
      "[32, 120] loss: 0.402\n",
      "[32, 180] loss: 0.403\n",
      "[32, 240] loss: 0.435\n",
      "[32, 300] loss: 0.420\n",
      "[32, 360] loss: 0.419\n",
      "Epoch: 32 -> Loss: 0.393837422132\n",
      "Epoch: 32 -> Test Accuracy: 83.07\n",
      "[33, 60] loss: 0.394\n",
      "[33, 120] loss: 0.389\n",
      "[33, 180] loss: 0.414\n",
      "[33, 240] loss: 0.423\n",
      "[33, 300] loss: 0.400\n",
      "[33, 360] loss: 0.421\n",
      "Epoch: 33 -> Loss: 0.501782536507\n",
      "Epoch: 33 -> Test Accuracy: 81.18\n",
      "[34, 60] loss: 0.394\n",
      "[34, 120] loss: 0.415\n",
      "[34, 180] loss: 0.414\n",
      "[34, 240] loss: 0.428\n",
      "[34, 300] loss: 0.402\n",
      "[34, 360] loss: 0.426\n",
      "Epoch: 34 -> Loss: 0.531346440315\n",
      "Epoch: 34 -> Test Accuracy: 82.19\n",
      "[35, 60] loss: 0.380\n",
      "[35, 120] loss: 0.398\n",
      "[35, 180] loss: 0.414\n",
      "[35, 240] loss: 0.435\n",
      "[35, 300] loss: 0.408\n",
      "[35, 360] loss: 0.416\n",
      "Epoch: 35 -> Loss: 0.330902278423\n",
      "Epoch: 35 -> Test Accuracy: 83.77\n",
      "[36, 60] loss: 0.388\n",
      "[36, 120] loss: 0.414\n",
      "[36, 180] loss: 0.404\n",
      "[36, 240] loss: 0.402\n",
      "[36, 300] loss: 0.408\n",
      "[36, 360] loss: 0.414\n",
      "Epoch: 36 -> Loss: 0.44836807251\n",
      "Epoch: 36 -> Test Accuracy: 83.2\n",
      "[37, 60] loss: 0.399\n",
      "[37, 120] loss: 0.410\n",
      "[37, 180] loss: 0.411\n",
      "[37, 240] loss: 0.419\n",
      "[37, 300] loss: 0.413\n",
      "[37, 360] loss: 0.404\n",
      "Epoch: 37 -> Loss: 0.530152797699\n",
      "Epoch: 37 -> Test Accuracy: 82.51\n",
      "[38, 60] loss: 0.401\n",
      "[38, 120] loss: 0.377\n",
      "[38, 180] loss: 0.393\n",
      "[38, 240] loss: 0.411\n",
      "[38, 300] loss: 0.413\n",
      "[38, 360] loss: 0.401\n",
      "Epoch: 38 -> Loss: 0.288441091776\n",
      "Epoch: 38 -> Test Accuracy: 82.86\n",
      "[39, 60] loss: 0.402\n",
      "[39, 120] loss: 0.394\n",
      "[39, 180] loss: 0.398\n",
      "[39, 240] loss: 0.402\n",
      "[39, 300] loss: 0.406\n",
      "[39, 360] loss: 0.435\n",
      "Epoch: 39 -> Loss: 0.561746239662\n",
      "Epoch: 39 -> Test Accuracy: 84.04\n",
      "[40, 60] loss: 0.373\n",
      "[40, 120] loss: 0.382\n",
      "[40, 180] loss: 0.410\n",
      "[40, 240] loss: 0.420\n",
      "[40, 300] loss: 0.390\n",
      "[40, 360] loss: 0.396\n",
      "Epoch: 40 -> Loss: 0.34759286046\n",
      "Epoch: 40 -> Test Accuracy: 83.12\n",
      "[41, 60] loss: 0.383\n",
      "[41, 120] loss: 0.390\n",
      "[41, 180] loss: 0.397\n",
      "[41, 240] loss: 0.416\n",
      "[41, 300] loss: 0.414\n",
      "[41, 360] loss: 0.415\n",
      "Epoch: 41 -> Loss: 0.417120069265\n",
      "Epoch: 41 -> Test Accuracy: 83.1\n",
      "[42, 60] loss: 0.371\n",
      "[42, 120] loss: 0.375\n",
      "[42, 180] loss: 0.408\n",
      "[42, 240] loss: 0.415\n",
      "[42, 300] loss: 0.421\n",
      "[42, 360] loss: 0.412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.324781596661\n",
      "Epoch: 42 -> Test Accuracy: 83.55\n",
      "[43, 60] loss: 0.372\n",
      "[43, 120] loss: 0.379\n",
      "[43, 180] loss: 0.407\n",
      "[43, 240] loss: 0.411\n",
      "[43, 300] loss: 0.412\n",
      "[43, 360] loss: 0.419\n",
      "Epoch: 43 -> Loss: 0.386346638203\n",
      "Epoch: 43 -> Test Accuracy: 81.11\n",
      "[44, 60] loss: 0.386\n",
      "[44, 120] loss: 0.376\n",
      "[44, 180] loss: 0.389\n",
      "[44, 240] loss: 0.392\n",
      "[44, 300] loss: 0.404\n",
      "[44, 360] loss: 0.400\n",
      "Epoch: 44 -> Loss: 0.373041033745\n",
      "Epoch: 44 -> Test Accuracy: 83.11\n",
      "[45, 60] loss: 0.370\n",
      "[45, 120] loss: 0.371\n",
      "[45, 180] loss: 0.393\n",
      "[45, 240] loss: 0.400\n",
      "[45, 300] loss: 0.395\n",
      "[45, 360] loss: 0.422\n",
      "Epoch: 45 -> Loss: 0.541353464127\n",
      "Epoch: 45 -> Test Accuracy: 82.71\n",
      "[46, 60] loss: 0.379\n",
      "[46, 120] loss: 0.372\n",
      "[46, 180] loss: 0.397\n",
      "[46, 240] loss: 0.412\n",
      "[46, 300] loss: 0.394\n",
      "[46, 360] loss: 0.413\n",
      "Epoch: 46 -> Loss: 0.397569149733\n",
      "Epoch: 46 -> Test Accuracy: 83.12\n",
      "[47, 60] loss: 0.363\n",
      "[47, 120] loss: 0.409\n",
      "[47, 180] loss: 0.402\n",
      "[47, 240] loss: 0.380\n",
      "[47, 300] loss: 0.394\n",
      "[47, 360] loss: 0.415\n",
      "Epoch: 47 -> Loss: 0.331615746021\n",
      "Epoch: 47 -> Test Accuracy: 82.31\n",
      "[48, 60] loss: 0.379\n",
      "[48, 120] loss: 0.370\n",
      "[48, 180] loss: 0.387\n",
      "[48, 240] loss: 0.399\n",
      "[48, 300] loss: 0.387\n",
      "[48, 360] loss: 0.399\n",
      "Epoch: 48 -> Loss: 0.42289981246\n",
      "Epoch: 48 -> Test Accuracy: 83.83\n",
      "[49, 60] loss: 0.370\n",
      "[49, 120] loss: 0.376\n",
      "[49, 180] loss: 0.379\n",
      "[49, 240] loss: 0.397\n",
      "[49, 300] loss: 0.418\n",
      "[49, 360] loss: 0.386\n",
      "Epoch: 49 -> Loss: 0.470990568399\n",
      "Epoch: 49 -> Test Accuracy: 82.75\n",
      "[50, 60] loss: 0.370\n",
      "[50, 120] loss: 0.410\n",
      "[50, 180] loss: 0.364\n",
      "[50, 240] loss: 0.396\n",
      "[50, 300] loss: 0.410\n",
      "[50, 360] loss: 0.402\n",
      "Epoch: 50 -> Loss: 0.246995657682\n",
      "Epoch: 50 -> Test Accuracy: 83.25\n",
      "[51, 60] loss: 0.382\n",
      "[51, 120] loss: 0.399\n",
      "[51, 180] loss: 0.375\n",
      "[51, 240] loss: 0.374\n",
      "[51, 300] loss: 0.403\n",
      "[51, 360] loss: 0.387\n",
      "Epoch: 51 -> Loss: 0.45343080163\n",
      "Epoch: 51 -> Test Accuracy: 82.63\n",
      "[52, 60] loss: 0.365\n",
      "[52, 120] loss: 0.377\n",
      "[52, 180] loss: 0.379\n",
      "[52, 240] loss: 0.402\n",
      "[52, 300] loss: 0.401\n",
      "[52, 360] loss: 0.396\n",
      "Epoch: 52 -> Loss: 0.358422338963\n",
      "Epoch: 52 -> Test Accuracy: 84.48\n",
      "[53, 60] loss: 0.362\n",
      "[53, 120] loss: 0.385\n",
      "[53, 180] loss: 0.405\n",
      "[53, 240] loss: 0.399\n",
      "[53, 300] loss: 0.393\n",
      "[53, 360] loss: 0.419\n",
      "Epoch: 53 -> Loss: 0.625765562057\n",
      "Epoch: 53 -> Test Accuracy: 83.89\n",
      "[54, 60] loss: 0.345\n",
      "[54, 120] loss: 0.383\n",
      "[54, 180] loss: 0.376\n",
      "[54, 240] loss: 0.373\n",
      "[54, 300] loss: 0.411\n",
      "[54, 360] loss: 0.417\n",
      "Epoch: 54 -> Loss: 0.538621306419\n",
      "Epoch: 54 -> Test Accuracy: 82.97\n",
      "[55, 60] loss: 0.361\n",
      "[55, 120] loss: 0.364\n",
      "[55, 180] loss: 0.394\n",
      "[55, 240] loss: 0.391\n",
      "[55, 300] loss: 0.396\n",
      "[55, 360] loss: 0.380\n",
      "Epoch: 55 -> Loss: 0.473729521036\n",
      "Epoch: 55 -> Test Accuracy: 84.12\n",
      "[56, 60] loss: 0.361\n",
      "[56, 120] loss: 0.383\n",
      "[56, 180] loss: 0.387\n",
      "[56, 240] loss: 0.395\n",
      "[56, 300] loss: 0.411\n",
      "[56, 360] loss: 0.390\n",
      "Epoch: 56 -> Loss: 0.514081537724\n",
      "Epoch: 56 -> Test Accuracy: 83.6\n",
      "[57, 60] loss: 0.369\n",
      "[57, 120] loss: 0.383\n",
      "[57, 180] loss: 0.379\n",
      "[57, 240] loss: 0.384\n",
      "[57, 300] loss: 0.406\n",
      "[57, 360] loss: 0.380\n",
      "Epoch: 57 -> Loss: 0.378554314375\n",
      "Epoch: 57 -> Test Accuracy: 83.53\n",
      "[58, 60] loss: 0.358\n",
      "[58, 120] loss: 0.377\n",
      "[58, 180] loss: 0.394\n",
      "[58, 240] loss: 0.404\n",
      "[58, 300] loss: 0.382\n",
      "[58, 360] loss: 0.385\n",
      "Epoch: 58 -> Loss: 0.273430883884\n",
      "Epoch: 58 -> Test Accuracy: 83.73\n",
      "[59, 60] loss: 0.356\n",
      "[59, 120] loss: 0.416\n",
      "[59, 180] loss: 0.374\n",
      "[59, 240] loss: 0.394\n",
      "[59, 300] loss: 0.382\n",
      "[59, 360] loss: 0.417\n",
      "Epoch: 59 -> Loss: 0.561969876289\n",
      "Epoch: 59 -> Test Accuracy: 83.73\n",
      "[60, 60] loss: 0.370\n",
      "[60, 120] loss: 0.377\n",
      "[60, 180] loss: 0.373\n",
      "[60, 240] loss: 0.389\n",
      "[60, 300] loss: 0.396\n",
      "[60, 360] loss: 0.401\n",
      "Epoch: 60 -> Loss: 0.352978587151\n",
      "Epoch: 60 -> Test Accuracy: 83.45\n",
      "[61, 60] loss: 0.283\n",
      "[61, 120] loss: 0.221\n",
      "[61, 180] loss: 0.222\n",
      "[61, 240] loss: 0.217\n",
      "[61, 300] loss: 0.185\n",
      "[61, 360] loss: 0.206\n",
      "Epoch: 61 -> Loss: 0.150876551867\n",
      "Epoch: 61 -> Test Accuracy: 89.13\n",
      "[62, 60] loss: 0.173\n",
      "[62, 120] loss: 0.173\n",
      "[62, 180] loss: 0.174\n",
      "[62, 240] loss: 0.169\n",
      "[62, 300] loss: 0.174\n",
      "[62, 360] loss: 0.185\n",
      "Epoch: 62 -> Loss: 0.173810645938\n",
      "Epoch: 62 -> Test Accuracy: 89.75\n",
      "[63, 60] loss: 0.143\n",
      "[63, 120] loss: 0.150\n",
      "[63, 180] loss: 0.165\n",
      "[63, 240] loss: 0.167\n",
      "[63, 300] loss: 0.161\n",
      "[63, 360] loss: 0.167\n",
      "Epoch: 63 -> Loss: 0.216121867299\n",
      "Epoch: 63 -> Test Accuracy: 89.62\n",
      "[64, 60] loss: 0.141\n",
      "[64, 120] loss: 0.142\n",
      "[64, 180] loss: 0.142\n",
      "[64, 240] loss: 0.158\n",
      "[64, 300] loss: 0.159\n",
      "[64, 360] loss: 0.143\n",
      "Epoch: 64 -> Loss: 0.192062705755\n",
      "Epoch: 64 -> Test Accuracy: 89.76\n",
      "[65, 60] loss: 0.132\n",
      "[65, 120] loss: 0.125\n",
      "[65, 180] loss: 0.131\n",
      "[65, 240] loss: 0.142\n",
      "[65, 300] loss: 0.152\n",
      "[65, 360] loss: 0.146\n",
      "Epoch: 65 -> Loss: 0.0942428261042\n",
      "Epoch: 65 -> Test Accuracy: 89.37\n",
      "[66, 60] loss: 0.122\n",
      "[66, 120] loss: 0.126\n",
      "[66, 180] loss: 0.121\n",
      "[66, 240] loss: 0.127\n",
      "[66, 300] loss: 0.134\n",
      "[66, 360] loss: 0.138\n",
      "Epoch: 66 -> Loss: 0.14484423399\n",
      "Epoch: 66 -> Test Accuracy: 89.04\n",
      "[67, 60] loss: 0.122\n",
      "[67, 120] loss: 0.126\n",
      "[67, 180] loss: 0.128\n",
      "[67, 240] loss: 0.129\n",
      "[67, 300] loss: 0.128\n",
      "[67, 360] loss: 0.146\n",
      "Epoch: 67 -> Loss: 0.101023696363\n",
      "Epoch: 67 -> Test Accuracy: 89.13\n",
      "[68, 60] loss: 0.116\n",
      "[68, 120] loss: 0.112\n",
      "[68, 180] loss: 0.124\n",
      "[68, 240] loss: 0.141\n",
      "[68, 300] loss: 0.136\n",
      "[68, 360] loss: 0.130\n",
      "Epoch: 68 -> Loss: 0.138984620571\n",
      "Epoch: 68 -> Test Accuracy: 89.25\n",
      "[69, 60] loss: 0.112\n",
      "[69, 120] loss: 0.124\n",
      "[69, 180] loss: 0.120\n",
      "[69, 240] loss: 0.130\n",
      "[69, 300] loss: 0.137\n",
      "[69, 360] loss: 0.143\n",
      "Epoch: 69 -> Loss: 0.120225608349\n",
      "Epoch: 69 -> Test Accuracy: 88.41\n",
      "[70, 60] loss: 0.114\n",
      "[70, 120] loss: 0.121\n",
      "[70, 180] loss: 0.150\n",
      "[70, 240] loss: 0.135\n",
      "[70, 300] loss: 0.150\n",
      "[70, 360] loss: 0.142\n",
      "Epoch: 70 -> Loss: 0.0975787416101\n",
      "Epoch: 70 -> Test Accuracy: 89.0\n",
      "[71, 60] loss: 0.115\n",
      "[71, 120] loss: 0.125\n",
      "[71, 180] loss: 0.121\n",
      "[71, 240] loss: 0.136\n",
      "[71, 300] loss: 0.140\n",
      "[71, 360] loss: 0.141\n",
      "Epoch: 71 -> Loss: 0.266739428043\n",
      "Epoch: 71 -> Test Accuracy: 88.97\n",
      "[72, 60] loss: 0.127\n",
      "[72, 120] loss: 0.136\n",
      "[72, 180] loss: 0.147\n",
      "[72, 240] loss: 0.147\n",
      "[72, 300] loss: 0.128\n",
      "[72, 360] loss: 0.127\n",
      "Epoch: 72 -> Loss: 0.192725881934\n",
      "Epoch: 72 -> Test Accuracy: 88.83\n",
      "[73, 60] loss: 0.125\n",
      "[73, 120] loss: 0.121\n",
      "[73, 180] loss: 0.124\n",
      "[73, 240] loss: 0.134\n",
      "[73, 300] loss: 0.149\n",
      "[73, 360] loss: 0.164\n",
      "Epoch: 73 -> Loss: 0.166150122881\n",
      "Epoch: 73 -> Test Accuracy: 88.43\n",
      "[74, 60] loss: 0.121\n",
      "[74, 120] loss: 0.123\n",
      "[74, 180] loss: 0.114\n",
      "[74, 240] loss: 0.125\n",
      "[74, 300] loss: 0.144\n",
      "[74, 360] loss: 0.152\n",
      "Epoch: 74 -> Loss: 0.105919376016\n",
      "Epoch: 74 -> Test Accuracy: 88.18\n",
      "[75, 60] loss: 0.123\n",
      "[75, 120] loss: 0.125\n",
      "[75, 180] loss: 0.132\n",
      "[75, 240] loss: 0.137\n",
      "[75, 300] loss: 0.151\n",
      "[75, 360] loss: 0.149\n",
      "Epoch: 75 -> Loss: 0.184201315045\n",
      "Epoch: 75 -> Test Accuracy: 88.44\n",
      "[76, 60] loss: 0.129\n",
      "[76, 120] loss: 0.114\n",
      "[76, 180] loss: 0.142\n",
      "[76, 240] loss: 0.144\n",
      "[76, 300] loss: 0.145\n",
      "[76, 360] loss: 0.154\n",
      "Epoch: 76 -> Loss: 0.0975792780519\n",
      "Epoch: 76 -> Test Accuracy: 88.3\n",
      "[77, 60] loss: 0.127\n",
      "[77, 120] loss: 0.131\n",
      "[77, 180] loss: 0.135\n",
      "[77, 240] loss: 0.142\n",
      "[77, 300] loss: 0.139\n",
      "[77, 360] loss: 0.144\n",
      "Epoch: 77 -> Loss: 0.121199890971\n",
      "Epoch: 77 -> Test Accuracy: 88.31\n",
      "[78, 60] loss: 0.120\n",
      "[78, 120] loss: 0.128\n",
      "[78, 180] loss: 0.144\n",
      "[78, 240] loss: 0.143\n",
      "[78, 300] loss: 0.144\n",
      "[78, 360] loss: 0.146\n",
      "Epoch: 78 -> Loss: 0.194299593568\n",
      "Epoch: 78 -> Test Accuracy: 88.02\n",
      "[79, 60] loss: 0.141\n",
      "[79, 120] loss: 0.125\n",
      "[79, 180] loss: 0.129\n",
      "[79, 240] loss: 0.137\n",
      "[79, 300] loss: 0.148\n",
      "[79, 360] loss: 0.132\n",
      "Epoch: 79 -> Loss: 0.107095241547\n",
      "Epoch: 79 -> Test Accuracy: 88.47\n",
      "[80, 60] loss: 0.114\n",
      "[80, 120] loss: 0.120\n",
      "[80, 180] loss: 0.131\n",
      "[80, 240] loss: 0.130\n",
      "[80, 300] loss: 0.152\n",
      "[80, 360] loss: 0.141\n",
      "Epoch: 80 -> Loss: 0.244767993689\n",
      "Epoch: 80 -> Test Accuracy: 88.45\n",
      "[81, 60] loss: 0.125\n",
      "[81, 120] loss: 0.125\n",
      "[81, 180] loss: 0.120\n",
      "[81, 240] loss: 0.151\n",
      "[81, 300] loss: 0.155\n",
      "[81, 360] loss: 0.133\n",
      "Epoch: 81 -> Loss: 0.113862551749\n",
      "Epoch: 81 -> Test Accuracy: 88.41\n",
      "[82, 60] loss: 0.128\n",
      "[82, 120] loss: 0.132\n",
      "[82, 180] loss: 0.140\n",
      "[82, 240] loss: 0.141\n",
      "[82, 300] loss: 0.134\n",
      "[82, 360] loss: 0.160\n",
      "Epoch: 82 -> Loss: 0.13775447011\n",
      "Epoch: 82 -> Test Accuracy: 87.97\n",
      "[83, 60] loss: 0.125\n",
      "[83, 120] loss: 0.128\n",
      "[83, 180] loss: 0.133\n",
      "[83, 240] loss: 0.141\n",
      "[83, 300] loss: 0.138\n",
      "[83, 360] loss: 0.138\n",
      "Epoch: 83 -> Loss: 0.0760831236839\n",
      "Epoch: 83 -> Test Accuracy: 87.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.112\n",
      "[84, 120] loss: 0.122\n",
      "[84, 180] loss: 0.123\n",
      "[84, 240] loss: 0.126\n",
      "[84, 300] loss: 0.133\n",
      "[84, 360] loss: 0.151\n",
      "Epoch: 84 -> Loss: 0.127449959517\n",
      "Epoch: 84 -> Test Accuracy: 88.31\n",
      "[85, 60] loss: 0.120\n",
      "[85, 120] loss: 0.125\n",
      "[85, 180] loss: 0.129\n",
      "[85, 240] loss: 0.138\n",
      "[85, 300] loss: 0.130\n",
      "[85, 360] loss: 0.150\n",
      "Epoch: 85 -> Loss: 0.136907219887\n",
      "Epoch: 85 -> Test Accuracy: 88.29\n",
      "[86, 60] loss: 0.119\n",
      "[86, 120] loss: 0.129\n",
      "[86, 180] loss: 0.129\n",
      "[86, 240] loss: 0.136\n",
      "[86, 300] loss: 0.124\n",
      "[86, 360] loss: 0.136\n",
      "Epoch: 86 -> Loss: 0.203608512878\n",
      "Epoch: 86 -> Test Accuracy: 88.7\n",
      "[87, 60] loss: 0.132\n",
      "[87, 120] loss: 0.133\n",
      "[87, 180] loss: 0.119\n",
      "[87, 240] loss: 0.141\n",
      "[87, 300] loss: 0.141\n",
      "[87, 360] loss: 0.143\n",
      "Epoch: 87 -> Loss: 0.186554715037\n",
      "Epoch: 87 -> Test Accuracy: 88.05\n",
      "[88, 60] loss: 0.121\n",
      "[88, 120] loss: 0.128\n",
      "[88, 180] loss: 0.122\n",
      "[88, 240] loss: 0.132\n",
      "[88, 300] loss: 0.135\n",
      "[88, 360] loss: 0.139\n",
      "Epoch: 88 -> Loss: 0.16848936677\n",
      "Epoch: 88 -> Test Accuracy: 88.09\n",
      "[89, 60] loss: 0.128\n",
      "[89, 120] loss: 0.123\n",
      "[89, 180] loss: 0.120\n",
      "[89, 240] loss: 0.133\n",
      "[89, 300] loss: 0.128\n",
      "[89, 360] loss: 0.141\n",
      "Epoch: 89 -> Loss: 0.171915084124\n",
      "Epoch: 89 -> Test Accuracy: 88.06\n",
      "[90, 60] loss: 0.123\n",
      "[90, 120] loss: 0.121\n",
      "[90, 180] loss: 0.121\n",
      "[90, 240] loss: 0.146\n",
      "[90, 300] loss: 0.148\n",
      "[90, 360] loss: 0.147\n",
      "Epoch: 90 -> Loss: 0.140754237771\n",
      "Epoch: 90 -> Test Accuracy: 88.52\n",
      "[91, 60] loss: 0.122\n",
      "[91, 120] loss: 0.132\n",
      "[91, 180] loss: 0.123\n",
      "[91, 240] loss: 0.118\n",
      "[91, 300] loss: 0.135\n",
      "[91, 360] loss: 0.137\n",
      "Epoch: 91 -> Loss: 0.0354556366801\n",
      "Epoch: 91 -> Test Accuracy: 87.85\n",
      "[92, 60] loss: 0.111\n",
      "[92, 120] loss: 0.118\n",
      "[92, 180] loss: 0.120\n",
      "[92, 240] loss: 0.128\n",
      "[92, 300] loss: 0.131\n",
      "[92, 360] loss: 0.142\n",
      "Epoch: 92 -> Loss: 0.154803663492\n",
      "Epoch: 92 -> Test Accuracy: 88.46\n",
      "[93, 60] loss: 0.117\n",
      "[93, 120] loss: 0.121\n",
      "[93, 180] loss: 0.112\n",
      "[93, 240] loss: 0.138\n",
      "[93, 300] loss: 0.140\n",
      "[93, 360] loss: 0.147\n",
      "Epoch: 93 -> Loss: 0.124383784831\n",
      "Epoch: 93 -> Test Accuracy: 88.71\n",
      "[94, 60] loss: 0.124\n",
      "[94, 120] loss: 0.120\n",
      "[94, 180] loss: 0.122\n",
      "[94, 240] loss: 0.137\n",
      "[94, 300] loss: 0.140\n",
      "[94, 360] loss: 0.130\n",
      "Epoch: 94 -> Loss: 0.139553830028\n",
      "Epoch: 94 -> Test Accuracy: 88.72\n",
      "[95, 60] loss: 0.115\n",
      "[95, 120] loss: 0.112\n",
      "[95, 180] loss: 0.124\n",
      "[95, 240] loss: 0.121\n",
      "[95, 300] loss: 0.128\n",
      "[95, 360] loss: 0.134\n",
      "Epoch: 95 -> Loss: 0.114479422569\n",
      "Epoch: 95 -> Test Accuracy: 88.83\n",
      "[96, 60] loss: 0.113\n",
      "[96, 120] loss: 0.121\n",
      "[96, 180] loss: 0.129\n",
      "[96, 240] loss: 0.124\n",
      "[96, 300] loss: 0.124\n",
      "[96, 360] loss: 0.136\n",
      "Epoch: 96 -> Loss: 0.117480203509\n",
      "Epoch: 96 -> Test Accuracy: 88.41\n",
      "[97, 60] loss: 0.121\n",
      "[97, 120] loss: 0.117\n",
      "[97, 180] loss: 0.115\n",
      "[97, 240] loss: 0.121\n",
      "[97, 300] loss: 0.131\n",
      "[97, 360] loss: 0.139\n",
      "Epoch: 97 -> Loss: 0.165293186903\n",
      "Epoch: 97 -> Test Accuracy: 88.6\n",
      "[98, 60] loss: 0.104\n",
      "[98, 120] loss: 0.114\n",
      "[98, 180] loss: 0.113\n",
      "[98, 240] loss: 0.121\n",
      "[98, 300] loss: 0.138\n",
      "[98, 360] loss: 0.134\n",
      "Epoch: 98 -> Loss: 0.0770029500127\n",
      "Epoch: 98 -> Test Accuracy: 88.53\n",
      "[99, 60] loss: 0.106\n",
      "[99, 120] loss: 0.114\n",
      "[99, 180] loss: 0.115\n",
      "[99, 240] loss: 0.126\n",
      "[99, 300] loss: 0.120\n",
      "[99, 360] loss: 0.129\n",
      "Epoch: 99 -> Loss: 0.206289798021\n",
      "Epoch: 99 -> Test Accuracy: 87.94\n",
      "[100, 60] loss: 0.106\n",
      "[100, 120] loss: 0.098\n",
      "[100, 180] loss: 0.116\n",
      "[100, 240] loss: 0.114\n",
      "[100, 300] loss: 0.128\n",
      "[100, 360] loss: 0.141\n",
      "Epoch: 100 -> Loss: 0.164075702429\n",
      "Epoch: 100 -> Test Accuracy: 87.85\n",
      "[101, 60] loss: 0.121\n",
      "[101, 120] loss: 0.121\n",
      "[101, 180] loss: 0.113\n",
      "[101, 240] loss: 0.114\n",
      "[101, 300] loss: 0.123\n",
      "[101, 360] loss: 0.130\n",
      "Epoch: 101 -> Loss: 0.177345186472\n",
      "Epoch: 101 -> Test Accuracy: 88.27\n",
      "[102, 60] loss: 0.116\n",
      "[102, 120] loss: 0.111\n",
      "[102, 180] loss: 0.114\n",
      "[102, 240] loss: 0.134\n",
      "[102, 300] loss: 0.122\n",
      "[102, 360] loss: 0.139\n",
      "Epoch: 102 -> Loss: 0.392570436001\n",
      "Epoch: 102 -> Test Accuracy: 87.64\n",
      "[103, 60] loss: 0.123\n",
      "[103, 120] loss: 0.111\n",
      "[103, 180] loss: 0.110\n",
      "[103, 240] loss: 0.129\n",
      "[103, 300] loss: 0.128\n",
      "[103, 360] loss: 0.150\n",
      "Epoch: 103 -> Loss: 0.242449074984\n",
      "Epoch: 103 -> Test Accuracy: 88.51\n",
      "[104, 60] loss: 0.111\n",
      "[104, 120] loss: 0.121\n",
      "[104, 180] loss: 0.113\n",
      "[104, 240] loss: 0.115\n",
      "[104, 300] loss: 0.125\n",
      "[104, 360] loss: 0.143\n",
      "Epoch: 104 -> Loss: 0.0710851401091\n",
      "Epoch: 104 -> Test Accuracy: 88.1\n",
      "[105, 60] loss: 0.104\n",
      "[105, 120] loss: 0.098\n",
      "[105, 180] loss: 0.118\n",
      "[105, 240] loss: 0.115\n",
      "[105, 300] loss: 0.138\n",
      "[105, 360] loss: 0.146\n",
      "Epoch: 105 -> Loss: 0.192751646042\n",
      "Epoch: 105 -> Test Accuracy: 88.25\n",
      "[106, 60] loss: 0.107\n",
      "[106, 120] loss: 0.120\n",
      "[106, 180] loss: 0.121\n",
      "[106, 240] loss: 0.126\n",
      "[106, 300] loss: 0.118\n",
      "[106, 360] loss: 0.122\n",
      "Epoch: 106 -> Loss: 0.173643916845\n",
      "Epoch: 106 -> Test Accuracy: 86.81\n",
      "[107, 60] loss: 0.105\n",
      "[107, 120] loss: 0.107\n",
      "[107, 180] loss: 0.108\n",
      "[107, 240] loss: 0.124\n",
      "[107, 300] loss: 0.121\n",
      "[107, 360] loss: 0.122\n",
      "Epoch: 107 -> Loss: 0.153318792582\n",
      "Epoch: 107 -> Test Accuracy: 88.16\n",
      "[108, 60] loss: 0.109\n",
      "[108, 120] loss: 0.112\n",
      "[108, 180] loss: 0.121\n",
      "[108, 240] loss: 0.117\n",
      "[108, 300] loss: 0.128\n",
      "[108, 360] loss: 0.136\n",
      "Epoch: 108 -> Loss: 0.133110269904\n",
      "Epoch: 108 -> Test Accuracy: 88.12\n",
      "[109, 60] loss: 0.115\n",
      "[109, 120] loss: 0.120\n",
      "[109, 180] loss: 0.110\n",
      "[109, 240] loss: 0.118\n",
      "[109, 300] loss: 0.122\n",
      "[109, 360] loss: 0.124\n",
      "Epoch: 109 -> Loss: 0.22077088058\n",
      "Epoch: 109 -> Test Accuracy: 87.62\n",
      "[110, 60] loss: 0.116\n",
      "[110, 120] loss: 0.112\n",
      "[110, 180] loss: 0.108\n",
      "[110, 240] loss: 0.132\n",
      "[110, 300] loss: 0.127\n",
      "[110, 360] loss: 0.128\n",
      "Epoch: 110 -> Loss: 0.148302406073\n",
      "Epoch: 110 -> Test Accuracy: 88.28\n",
      "[111, 60] loss: 0.106\n",
      "[111, 120] loss: 0.114\n",
      "[111, 180] loss: 0.127\n",
      "[111, 240] loss: 0.116\n",
      "[111, 300] loss: 0.122\n",
      "[111, 360] loss: 0.116\n",
      "Epoch: 111 -> Loss: 0.101910591125\n",
      "Epoch: 111 -> Test Accuracy: 88.74\n",
      "[112, 60] loss: 0.102\n",
      "[112, 120] loss: 0.103\n",
      "[112, 180] loss: 0.110\n",
      "[112, 240] loss: 0.114\n",
      "[112, 300] loss: 0.136\n",
      "[112, 360] loss: 0.134\n",
      "Epoch: 112 -> Loss: 0.139820635319\n",
      "Epoch: 112 -> Test Accuracy: 88.33\n",
      "[113, 60] loss: 0.106\n",
      "[113, 120] loss: 0.104\n",
      "[113, 180] loss: 0.106\n",
      "[113, 240] loss: 0.115\n",
      "[113, 300] loss: 0.119\n",
      "[113, 360] loss: 0.127\n",
      "Epoch: 113 -> Loss: 0.0812459290028\n",
      "Epoch: 113 -> Test Accuracy: 88.11\n",
      "[114, 60] loss: 0.114\n",
      "[114, 120] loss: 0.103\n",
      "[114, 180] loss: 0.110\n",
      "[114, 240] loss: 0.127\n",
      "[114, 300] loss: 0.120\n",
      "[114, 360] loss: 0.131\n",
      "Epoch: 114 -> Loss: 0.241338014603\n",
      "Epoch: 114 -> Test Accuracy: 88.53\n",
      "[115, 60] loss: 0.106\n",
      "[115, 120] loss: 0.107\n",
      "[115, 180] loss: 0.108\n",
      "[115, 240] loss: 0.117\n",
      "[115, 300] loss: 0.115\n",
      "[115, 360] loss: 0.118\n",
      "Epoch: 115 -> Loss: 0.159904807806\n",
      "Epoch: 115 -> Test Accuracy: 88.51\n",
      "[116, 60] loss: 0.113\n",
      "[116, 120] loss: 0.113\n",
      "[116, 180] loss: 0.125\n",
      "[116, 240] loss: 0.135\n",
      "[116, 300] loss: 0.123\n",
      "[116, 360] loss: 0.125\n",
      "Epoch: 116 -> Loss: 0.11884085834\n",
      "Epoch: 116 -> Test Accuracy: 88.47\n",
      "[117, 60] loss: 0.099\n",
      "[117, 120] loss: 0.107\n",
      "[117, 180] loss: 0.122\n",
      "[117, 240] loss: 0.128\n",
      "[117, 300] loss: 0.121\n",
      "[117, 360] loss: 0.126\n",
      "Epoch: 117 -> Loss: 0.0420174226165\n",
      "Epoch: 117 -> Test Accuracy: 88.24\n",
      "[118, 60] loss: 0.098\n",
      "[118, 120] loss: 0.094\n",
      "[118, 180] loss: 0.103\n",
      "[118, 240] loss: 0.119\n",
      "[118, 300] loss: 0.120\n",
      "[118, 360] loss: 0.122\n",
      "Epoch: 118 -> Loss: 0.116893291473\n",
      "Epoch: 118 -> Test Accuracy: 87.91\n",
      "[119, 60] loss: 0.114\n",
      "[119, 120] loss: 0.108\n",
      "[119, 180] loss: 0.105\n",
      "[119, 240] loss: 0.098\n",
      "[119, 300] loss: 0.109\n",
      "[119, 360] loss: 0.119\n",
      "Epoch: 119 -> Loss: 0.0944111347198\n",
      "Epoch: 119 -> Test Accuracy: 88.47\n",
      "[120, 60] loss: 0.100\n",
      "[120, 120] loss: 0.101\n",
      "[120, 180] loss: 0.108\n",
      "[120, 240] loss: 0.107\n",
      "[120, 300] loss: 0.115\n",
      "[120, 360] loss: 0.122\n",
      "Epoch: 120 -> Loss: 0.0781654268503\n",
      "Epoch: 120 -> Test Accuracy: 88.68\n",
      "[121, 60] loss: 0.076\n",
      "[121, 120] loss: 0.053\n",
      "[121, 180] loss: 0.046\n",
      "[121, 240] loss: 0.044\n",
      "[121, 300] loss: 0.039\n",
      "[121, 360] loss: 0.038\n",
      "Epoch: 121 -> Loss: 0.0565217845142\n",
      "Epoch: 121 -> Test Accuracy: 91.0\n",
      "[122, 60] loss: 0.030\n",
      "[122, 120] loss: 0.030\n",
      "[122, 180] loss: 0.028\n",
      "[122, 240] loss: 0.026\n",
      "[122, 300] loss: 0.033\n",
      "[122, 360] loss: 0.033\n",
      "Epoch: 122 -> Loss: 0.040603466332\n",
      "Epoch: 122 -> Test Accuracy: 91.14\n",
      "[123, 60] loss: 0.025\n",
      "[123, 120] loss: 0.024\n",
      "[123, 180] loss: 0.023\n",
      "[123, 240] loss: 0.021\n",
      "[123, 300] loss: 0.024\n",
      "[123, 360] loss: 0.023\n",
      "Epoch: 123 -> Loss: 0.0392349287868\n",
      "Epoch: 123 -> Test Accuracy: 91.23\n",
      "[124, 60] loss: 0.022\n",
      "[124, 120] loss: 0.021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[124, 180] loss: 0.019\n",
      "[124, 240] loss: 0.019\n",
      "[124, 300] loss: 0.023\n",
      "[124, 360] loss: 0.020\n",
      "Epoch: 124 -> Loss: 0.014781457372\n",
      "Epoch: 124 -> Test Accuracy: 91.12\n",
      "[125, 60] loss: 0.018\n",
      "[125, 120] loss: 0.018\n",
      "[125, 180] loss: 0.021\n",
      "[125, 240] loss: 0.019\n",
      "[125, 300] loss: 0.019\n",
      "[125, 360] loss: 0.018\n",
      "Epoch: 125 -> Loss: 0.0167721323669\n",
      "Epoch: 125 -> Test Accuracy: 91.34\n",
      "[126, 60] loss: 0.017\n",
      "[126, 120] loss: 0.016\n",
      "[126, 180] loss: 0.017\n",
      "[126, 240] loss: 0.017\n",
      "[126, 300] loss: 0.019\n",
      "[126, 360] loss: 0.017\n",
      "Epoch: 126 -> Loss: 0.0848335027695\n",
      "Epoch: 126 -> Test Accuracy: 91.11\n",
      "[127, 60] loss: 0.015\n",
      "[127, 120] loss: 0.016\n",
      "[127, 180] loss: 0.016\n",
      "[127, 240] loss: 0.017\n",
      "[127, 300] loss: 0.017\n",
      "[127, 360] loss: 0.017\n",
      "Epoch: 127 -> Loss: 0.0125324781984\n",
      "Epoch: 127 -> Test Accuracy: 91.08\n",
      "[128, 60] loss: 0.015\n",
      "[128, 120] loss: 0.012\n",
      "[128, 180] loss: 0.014\n",
      "[128, 240] loss: 0.015\n",
      "[128, 300] loss: 0.015\n",
      "[128, 360] loss: 0.016\n",
      "Epoch: 128 -> Loss: 0.0312589555979\n",
      "Epoch: 128 -> Test Accuracy: 91.4\n",
      "[129, 60] loss: 0.015\n",
      "[129, 120] loss: 0.014\n",
      "[129, 180] loss: 0.015\n",
      "[129, 240] loss: 0.014\n",
      "[129, 300] loss: 0.013\n",
      "[129, 360] loss: 0.015\n",
      "Epoch: 129 -> Loss: 0.0130217969418\n",
      "Epoch: 129 -> Test Accuracy: 91.35\n",
      "[130, 60] loss: 0.013\n",
      "[130, 120] loss: 0.013\n",
      "[130, 180] loss: 0.014\n",
      "[130, 240] loss: 0.013\n",
      "[130, 300] loss: 0.014\n",
      "[130, 360] loss: 0.015\n",
      "Epoch: 130 -> Loss: 0.0347522571683\n",
      "Epoch: 130 -> Test Accuracy: 91.44\n",
      "[131, 60] loss: 0.013\n",
      "[131, 120] loss: 0.012\n",
      "[131, 180] loss: 0.013\n",
      "[131, 240] loss: 0.013\n",
      "[131, 300] loss: 0.012\n",
      "[131, 360] loss: 0.013\n",
      "Epoch: 131 -> Loss: 0.0206875987351\n",
      "Epoch: 131 -> Test Accuracy: 91.39\n",
      "[132, 60] loss: 0.012\n",
      "[132, 120] loss: 0.013\n",
      "[132, 180] loss: 0.012\n",
      "[132, 240] loss: 0.011\n",
      "[132, 300] loss: 0.015\n",
      "[132, 360] loss: 0.013\n",
      "Epoch: 132 -> Loss: 0.0230661574751\n",
      "Epoch: 132 -> Test Accuracy: 91.58\n",
      "[133, 60] loss: 0.012\n",
      "[133, 120] loss: 0.011\n",
      "[133, 180] loss: 0.012\n",
      "[133, 240] loss: 0.013\n",
      "[133, 300] loss: 0.012\n",
      "[133, 360] loss: 0.012\n",
      "Epoch: 133 -> Loss: 0.0413665995002\n",
      "Epoch: 133 -> Test Accuracy: 91.43\n",
      "[134, 60] loss: 0.010\n",
      "[134, 120] loss: 0.011\n",
      "[134, 180] loss: 0.012\n",
      "[134, 240] loss: 0.010\n",
      "[134, 300] loss: 0.011\n",
      "[134, 360] loss: 0.011\n",
      "Epoch: 134 -> Loss: 0.0186693780124\n",
      "Epoch: 134 -> Test Accuracy: 91.19\n",
      "[135, 60] loss: 0.010\n",
      "[135, 120] loss: 0.011\n",
      "[135, 180] loss: 0.011\n",
      "[135, 240] loss: 0.011\n",
      "[135, 300] loss: 0.011\n",
      "[135, 360] loss: 0.011\n",
      "Epoch: 135 -> Loss: 0.0119986953214\n",
      "Epoch: 135 -> Test Accuracy: 91.6\n",
      "[136, 60] loss: 0.011\n",
      "[136, 120] loss: 0.011\n",
      "[136, 180] loss: 0.011\n",
      "[136, 240] loss: 0.010\n",
      "[136, 300] loss: 0.012\n",
      "[136, 360] loss: 0.010\n",
      "Epoch: 136 -> Loss: 0.00918613933027\n",
      "Epoch: 136 -> Test Accuracy: 91.38\n",
      "[137, 60] loss: 0.009\n",
      "[137, 120] loss: 0.011\n",
      "[137, 180] loss: 0.011\n",
      "[137, 240] loss: 0.011\n",
      "[137, 300] loss: 0.010\n",
      "[137, 360] loss: 0.013\n",
      "Epoch: 137 -> Loss: 0.00561661738902\n",
      "Epoch: 137 -> Test Accuracy: 91.41\n",
      "[138, 60] loss: 0.011\n",
      "[138, 120] loss: 0.009\n",
      "[138, 180] loss: 0.009\n",
      "[138, 240] loss: 0.011\n",
      "[138, 300] loss: 0.011\n",
      "[138, 360] loss: 0.010\n",
      "Epoch: 138 -> Loss: 0.0108347414061\n",
      "Epoch: 138 -> Test Accuracy: 91.08\n",
      "[139, 60] loss: 0.010\n",
      "[139, 120] loss: 0.010\n",
      "[139, 180] loss: 0.011\n",
      "[139, 240] loss: 0.011\n",
      "[139, 300] loss: 0.010\n",
      "[139, 360] loss: 0.011\n",
      "Epoch: 139 -> Loss: 0.003296548035\n",
      "Epoch: 139 -> Test Accuracy: 91.25\n",
      "[140, 60] loss: 0.009\n",
      "[140, 120] loss: 0.009\n",
      "[140, 180] loss: 0.010\n",
      "[140, 240] loss: 0.009\n",
      "[140, 300] loss: 0.011\n",
      "[140, 360] loss: 0.011\n",
      "Epoch: 140 -> Loss: 0.0081768091768\n",
      "Epoch: 140 -> Test Accuracy: 91.33\n",
      "[141, 60] loss: 0.010\n",
      "[141, 120] loss: 0.009\n",
      "[141, 180] loss: 0.010\n",
      "[141, 240] loss: 0.011\n",
      "[141, 300] loss: 0.011\n",
      "[141, 360] loss: 0.010\n",
      "Epoch: 141 -> Loss: 0.0161631368101\n",
      "Epoch: 141 -> Test Accuracy: 91.49\n",
      "[142, 60] loss: 0.010\n",
      "[142, 120] loss: 0.009\n",
      "[142, 180] loss: 0.010\n",
      "[142, 240] loss: 0.010\n",
      "[142, 300] loss: 0.009\n",
      "[142, 360] loss: 0.010\n",
      "Epoch: 142 -> Loss: 0.00730358948931\n",
      "Epoch: 142 -> Test Accuracy: 91.35\n",
      "[143, 60] loss: 0.009\n",
      "[143, 120] loss: 0.009\n",
      "[143, 180] loss: 0.009\n",
      "[143, 240] loss: 0.008\n",
      "[143, 300] loss: 0.010\n",
      "[143, 360] loss: 0.011\n",
      "Epoch: 143 -> Loss: 0.0156547427177\n",
      "Epoch: 143 -> Test Accuracy: 91.55\n",
      "[144, 60] loss: 0.009\n",
      "[144, 120] loss: 0.010\n",
      "[144, 180] loss: 0.011\n",
      "[144, 240] loss: 0.010\n",
      "[144, 300] loss: 0.010\n",
      "[144, 360] loss: 0.009\n",
      "Epoch: 144 -> Loss: 0.00534783583134\n",
      "Epoch: 144 -> Test Accuracy: 91.28\n",
      "[145, 60] loss: 0.009\n",
      "[145, 120] loss: 0.009\n",
      "[145, 180] loss: 0.009\n",
      "[145, 240] loss: 0.009\n",
      "[145, 300] loss: 0.010\n",
      "[145, 360] loss: 0.010\n",
      "Epoch: 145 -> Loss: 0.0170316882432\n",
      "Epoch: 145 -> Test Accuracy: 91.53\n",
      "[146, 60] loss: 0.009\n",
      "[146, 120] loss: 0.009\n",
      "[146, 180] loss: 0.009\n",
      "[146, 240] loss: 0.009\n",
      "[146, 300] loss: 0.011\n",
      "[146, 360] loss: 0.009\n",
      "Epoch: 146 -> Loss: 0.0199759565294\n",
      "Epoch: 146 -> Test Accuracy: 91.44\n",
      "[147, 60] loss: 0.008\n",
      "[147, 120] loss: 0.009\n",
      "[147, 180] loss: 0.008\n",
      "[147, 240] loss: 0.009\n",
      "[147, 300] loss: 0.008\n",
      "[147, 360] loss: 0.008\n",
      "Epoch: 147 -> Loss: 0.00666918139905\n",
      "Epoch: 147 -> Test Accuracy: 91.42\n",
      "[148, 60] loss: 0.008\n",
      "[148, 120] loss: 0.008\n",
      "[148, 180] loss: 0.009\n",
      "[148, 240] loss: 0.009\n",
      "[148, 300] loss: 0.008\n",
      "[148, 360] loss: 0.009\n",
      "Epoch: 148 -> Loss: 0.00498628616333\n",
      "Epoch: 148 -> Test Accuracy: 91.48\n",
      "[149, 60] loss: 0.008\n",
      "[149, 120] loss: 0.009\n",
      "[149, 180] loss: 0.008\n",
      "[149, 240] loss: 0.009\n",
      "[149, 300] loss: 0.009\n",
      "[149, 360] loss: 0.009\n",
      "Epoch: 149 -> Loss: 0.0043837307021\n",
      "Epoch: 149 -> Test Accuracy: 91.55\n",
      "[150, 60] loss: 0.008\n",
      "[150, 120] loss: 0.009\n",
      "[150, 180] loss: 0.009\n",
      "[150, 240] loss: 0.010\n",
      "[150, 300] loss: 0.008\n",
      "[150, 360] loss: 0.008\n",
      "Epoch: 150 -> Loss: 0.013131255284\n",
      "Epoch: 150 -> Test Accuracy: 91.41\n",
      "[151, 60] loss: 0.008\n",
      "[151, 120] loss: 0.008\n",
      "[151, 180] loss: 0.009\n",
      "[151, 240] loss: 0.009\n",
      "[151, 300] loss: 0.009\n",
      "[151, 360] loss: 0.010\n",
      "Epoch: 151 -> Loss: 0.00664518494159\n",
      "Epoch: 151 -> Test Accuracy: 91.22\n",
      "[152, 60] loss: 0.008\n",
      "[152, 120] loss: 0.008\n",
      "[152, 180] loss: 0.008\n",
      "[152, 240] loss: 0.009\n",
      "[152, 300] loss: 0.009\n",
      "[152, 360] loss: 0.009\n",
      "Epoch: 152 -> Loss: 0.0107824262232\n",
      "Epoch: 152 -> Test Accuracy: 91.28\n",
      "[153, 60] loss: 0.009\n",
      "[153, 120] loss: 0.008\n",
      "[153, 180] loss: 0.009\n",
      "[153, 240] loss: 0.008\n",
      "[153, 300] loss: 0.009\n",
      "[153, 360] loss: 0.009\n",
      "Epoch: 153 -> Loss: 0.0158017966896\n",
      "Epoch: 153 -> Test Accuracy: 91.48\n",
      "[154, 60] loss: 0.008\n",
      "[154, 120] loss: 0.009\n",
      "[154, 180] loss: 0.008\n",
      "[154, 240] loss: 0.009\n",
      "[154, 300] loss: 0.009\n",
      "[154, 360] loss: 0.010\n",
      "Epoch: 154 -> Loss: 0.00430523138493\n",
      "Epoch: 154 -> Test Accuracy: 91.37\n",
      "[155, 60] loss: 0.008\n",
      "[155, 120] loss: 0.009\n",
      "[155, 180] loss: 0.009\n",
      "[155, 240] loss: 0.008\n",
      "[155, 300] loss: 0.008\n",
      "[155, 360] loss: 0.009\n",
      "Epoch: 155 -> Loss: 0.00885029695928\n",
      "Epoch: 155 -> Test Accuracy: 91.34\n",
      "[156, 60] loss: 0.009\n",
      "[156, 120] loss: 0.008\n",
      "[156, 180] loss: 0.009\n",
      "[156, 240] loss: 0.009\n",
      "[156, 300] loss: 0.008\n",
      "[156, 360] loss: 0.008\n",
      "Epoch: 156 -> Loss: 0.00787709373981\n",
      "Epoch: 156 -> Test Accuracy: 91.24\n",
      "[157, 60] loss: 0.007\n",
      "[157, 120] loss: 0.008\n",
      "[157, 180] loss: 0.009\n",
      "[157, 240] loss: 0.009\n",
      "[157, 300] loss: 0.009\n",
      "[157, 360] loss: 0.009\n",
      "Epoch: 157 -> Loss: 0.0151769965887\n",
      "Epoch: 157 -> Test Accuracy: 91.1\n",
      "[158, 60] loss: 0.007\n",
      "[158, 120] loss: 0.009\n",
      "[158, 180] loss: 0.008\n",
      "[158, 240] loss: 0.008\n",
      "[158, 300] loss: 0.008\n",
      "[158, 360] loss: 0.008\n",
      "Epoch: 158 -> Loss: 0.0158641636372\n",
      "Epoch: 158 -> Test Accuracy: 91.31\n",
      "[159, 60] loss: 0.008\n",
      "[159, 120] loss: 0.008\n",
      "[159, 180] loss: 0.008\n",
      "[159, 240] loss: 0.009\n",
      "[159, 300] loss: 0.008\n",
      "[159, 360] loss: 0.008\n",
      "Epoch: 159 -> Loss: 0.015289997682\n",
      "Epoch: 159 -> Test Accuracy: 91.5\n",
      "[160, 60] loss: 0.007\n",
      "[160, 120] loss: 0.008\n",
      "[160, 180] loss: 0.008\n",
      "[160, 240] loss: 0.009\n",
      "[160, 300] loss: 0.008\n",
      "[160, 360] loss: 0.008\n",
      "Epoch: 160 -> Loss: 0.00746633391827\n",
      "Epoch: 160 -> Test Accuracy: 91.26\n",
      "[161, 60] loss: 0.007\n",
      "[161, 120] loss: 0.008\n",
      "[161, 180] loss: 0.007\n",
      "[161, 240] loss: 0.008\n",
      "[161, 300] loss: 0.007\n",
      "[161, 360] loss: 0.008\n",
      "Epoch: 161 -> Loss: 0.00252706999891\n",
      "Epoch: 161 -> Test Accuracy: 91.49\n",
      "[162, 60] loss: 0.008\n",
      "[162, 120] loss: 0.006\n",
      "[162, 180] loss: 0.006\n",
      "[162, 240] loss: 0.007\n",
      "[162, 300] loss: 0.007\n",
      "[162, 360] loss: 0.007\n",
      "Epoch: 162 -> Loss: 0.00587472319603\n",
      "Epoch: 162 -> Test Accuracy: 91.42\n",
      "[163, 60] loss: 0.006\n",
      "[163, 120] loss: 0.006\n",
      "[163, 180] loss: 0.006\n",
      "[163, 240] loss: 0.007\n",
      "[163, 300] loss: 0.007\n",
      "[163, 360] loss: 0.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 163 -> Loss: 0.0217232648283\n",
      "Epoch: 163 -> Test Accuracy: 91.34\n",
      "[164, 60] loss: 0.007\n",
      "[164, 120] loss: 0.006\n",
      "[164, 180] loss: 0.007\n",
      "[164, 240] loss: 0.007\n",
      "[164, 300] loss: 0.008\n",
      "[164, 360] loss: 0.007\n",
      "Epoch: 164 -> Loss: 0.00491287698969\n",
      "Epoch: 164 -> Test Accuracy: 91.43\n",
      "[165, 60] loss: 0.007\n",
      "[165, 120] loss: 0.006\n",
      "[165, 180] loss: 0.007\n",
      "[165, 240] loss: 0.007\n",
      "[165, 300] loss: 0.007\n",
      "[165, 360] loss: 0.006\n",
      "Epoch: 165 -> Loss: 0.00755018601194\n",
      "Epoch: 165 -> Test Accuracy: 91.38\n",
      "[166, 60] loss: 0.007\n",
      "[166, 120] loss: 0.007\n",
      "[166, 180] loss: 0.006\n",
      "[166, 240] loss: 0.006\n",
      "[166, 300] loss: 0.008\n",
      "[166, 360] loss: 0.007\n",
      "Epoch: 166 -> Loss: 0.00747720012441\n",
      "Epoch: 166 -> Test Accuracy: 91.35\n",
      "[167, 60] loss: 0.007\n",
      "[167, 120] loss: 0.007\n",
      "[167, 180] loss: 0.006\n",
      "[167, 240] loss: 0.006\n",
      "[167, 300] loss: 0.007\n",
      "[167, 360] loss: 0.007\n",
      "Epoch: 167 -> Loss: 0.00682920822874\n",
      "Epoch: 167 -> Test Accuracy: 91.36\n",
      "[168, 60] loss: 0.007\n",
      "[168, 120] loss: 0.006\n",
      "[168, 180] loss: 0.006\n",
      "[168, 240] loss: 0.007\n",
      "[168, 300] loss: 0.007\n",
      "[168, 360] loss: 0.007\n",
      "Epoch: 168 -> Loss: 0.00664998311549\n",
      "Epoch: 168 -> Test Accuracy: 91.37\n",
      "[169, 60] loss: 0.006\n",
      "[169, 120] loss: 0.006\n",
      "[169, 180] loss: 0.007\n",
      "[169, 240] loss: 0.007\n",
      "[169, 300] loss: 0.006\n",
      "[169, 360] loss: 0.007\n",
      "Epoch: 169 -> Loss: 0.00578779587522\n",
      "Epoch: 169 -> Test Accuracy: 91.43\n",
      "[170, 60] loss: 0.006\n",
      "[170, 120] loss: 0.006\n",
      "[170, 180] loss: 0.006\n",
      "[170, 240] loss: 0.006\n",
      "[170, 300] loss: 0.007\n",
      "[170, 360] loss: 0.007\n",
      "Epoch: 170 -> Loss: 0.00725095858797\n",
      "Epoch: 170 -> Test Accuracy: 91.37\n",
      "[171, 60] loss: 0.006\n",
      "[171, 120] loss: 0.007\n",
      "[171, 180] loss: 0.006\n",
      "[171, 240] loss: 0.007\n",
      "[171, 300] loss: 0.007\n",
      "[171, 360] loss: 0.006\n",
      "Epoch: 171 -> Loss: 0.00789576210082\n",
      "Epoch: 171 -> Test Accuracy: 91.38\n",
      "[172, 60] loss: 0.006\n",
      "[172, 120] loss: 0.007\n",
      "[172, 180] loss: 0.007\n",
      "[172, 240] loss: 0.007\n",
      "[172, 300] loss: 0.007\n",
      "[172, 360] loss: 0.007\n",
      "Epoch: 172 -> Loss: 0.00631002197042\n",
      "Epoch: 172 -> Test Accuracy: 91.42\n",
      "[173, 60] loss: 0.007\n",
      "[173, 120] loss: 0.006\n",
      "[173, 180] loss: 0.007\n",
      "[173, 240] loss: 0.007\n",
      "[173, 300] loss: 0.007\n",
      "[173, 360] loss: 0.007\n",
      "Epoch: 173 -> Loss: 0.0154507216066\n",
      "Epoch: 173 -> Test Accuracy: 91.54\n",
      "[174, 60] loss: 0.006\n",
      "[174, 120] loss: 0.007\n",
      "[174, 180] loss: 0.006\n",
      "[174, 240] loss: 0.007\n",
      "[174, 300] loss: 0.006\n",
      "[174, 360] loss: 0.007\n",
      "Epoch: 174 -> Loss: 0.00718631735072\n",
      "Epoch: 174 -> Test Accuracy: 91.48\n",
      "[175, 60] loss: 0.007\n",
      "[175, 120] loss: 0.006\n",
      "[175, 180] loss: 0.007\n",
      "[175, 240] loss: 0.007\n",
      "[175, 300] loss: 0.006\n",
      "[175, 360] loss: 0.006\n",
      "Epoch: 175 -> Loss: 0.0066727520898\n",
      "Epoch: 175 -> Test Accuracy: 91.52\n",
      "[176, 60] loss: 0.006\n",
      "[176, 120] loss: 0.007\n",
      "[176, 180] loss: 0.006\n",
      "[176, 240] loss: 0.006\n",
      "[176, 300] loss: 0.006\n",
      "[176, 360] loss: 0.006\n",
      "Epoch: 176 -> Loss: 0.0105314943939\n",
      "Epoch: 176 -> Test Accuracy: 91.52\n",
      "[177, 60] loss: 0.006\n",
      "[177, 120] loss: 0.005\n",
      "[177, 180] loss: 0.006\n",
      "[177, 240] loss: 0.006\n",
      "[177, 300] loss: 0.007\n",
      "[177, 360] loss: 0.006\n",
      "Epoch: 177 -> Loss: 0.00541695347056\n",
      "Epoch: 177 -> Test Accuracy: 91.43\n",
      "[178, 60] loss: 0.006\n",
      "[178, 120] loss: 0.006\n",
      "[178, 180] loss: 0.007\n",
      "[178, 240] loss: 0.007\n",
      "[178, 300] loss: 0.006\n",
      "[178, 360] loss: 0.006\n",
      "Epoch: 178 -> Loss: 0.00672669429332\n",
      "Epoch: 178 -> Test Accuracy: 91.49\n",
      "[179, 60] loss: 0.006\n",
      "[179, 120] loss: 0.006\n",
      "[179, 180] loss: 0.006\n",
      "[179, 240] loss: 0.008\n",
      "[179, 300] loss: 0.006\n",
      "[179, 360] loss: 0.006\n",
      "Epoch: 179 -> Loss: 0.0129056693986\n",
      "Epoch: 179 -> Test Accuracy: 91.43\n",
      "[180, 60] loss: 0.006\n",
      "[180, 120] loss: 0.006\n",
      "[180, 180] loss: 0.006\n",
      "[180, 240] loss: 0.006\n",
      "[180, 300] loss: 0.006\n",
      "[180, 360] loss: 0.007\n",
      "Epoch: 180 -> Loss: 0.0073016048409\n",
      "Epoch: 180 -> Test Accuracy: 91.45\n",
      "[181, 60] loss: 0.006\n",
      "[181, 120] loss: 0.006\n",
      "[181, 180] loss: 0.006\n",
      "[181, 240] loss: 0.006\n",
      "[181, 300] loss: 0.006\n",
      "[181, 360] loss: 0.006\n",
      "Epoch: 181 -> Loss: 0.0107027534395\n",
      "Epoch: 181 -> Test Accuracy: 91.41\n",
      "[182, 60] loss: 0.006\n",
      "[182, 120] loss: 0.006\n",
      "[182, 180] loss: 0.007\n",
      "[182, 240] loss: 0.006\n",
      "[182, 300] loss: 0.006\n",
      "[182, 360] loss: 0.007\n",
      "Epoch: 182 -> Loss: 0.00626089563593\n",
      "Epoch: 182 -> Test Accuracy: 91.52\n",
      "[183, 60] loss: 0.006\n",
      "[183, 120] loss: 0.006\n",
      "[183, 180] loss: 0.007\n",
      "[183, 240] loss: 0.006\n",
      "[183, 300] loss: 0.007\n",
      "[183, 360] loss: 0.007\n",
      "Epoch: 183 -> Loss: 0.00553894042969\n",
      "Epoch: 183 -> Test Accuracy: 91.59\n",
      "[184, 60] loss: 0.006\n",
      "[184, 120] loss: 0.007\n",
      "[184, 180] loss: 0.006\n",
      "[184, 240] loss: 0.007\n",
      "[184, 300] loss: 0.006\n",
      "[184, 360] loss: 0.006\n",
      "Epoch: 184 -> Loss: 0.00829513091594\n",
      "Epoch: 184 -> Test Accuracy: 91.62\n",
      "[185, 60] loss: 0.006\n",
      "[185, 120] loss: 0.006\n",
      "[185, 180] loss: 0.006\n",
      "[185, 240] loss: 0.006\n",
      "[185, 300] loss: 0.007\n",
      "[185, 360] loss: 0.006\n",
      "Epoch: 185 -> Loss: 0.00739532709122\n",
      "Epoch: 185 -> Test Accuracy: 91.5\n",
      "[186, 60] loss: 0.006\n",
      "[186, 120] loss: 0.006\n",
      "[186, 180] loss: 0.006\n",
      "[186, 240] loss: 0.006\n",
      "[186, 300] loss: 0.006\n",
      "[186, 360] loss: 0.006\n",
      "Epoch: 186 -> Loss: 0.00641471147537\n",
      "Epoch: 186 -> Test Accuracy: 91.56\n",
      "[187, 60] loss: 0.007\n",
      "[187, 120] loss: 0.007\n",
      "[187, 180] loss: 0.006\n",
      "[187, 240] loss: 0.006\n",
      "[187, 300] loss: 0.006\n",
      "[187, 360] loss: 0.007\n",
      "Epoch: 187 -> Loss: 0.00623005628586\n",
      "Epoch: 187 -> Test Accuracy: 91.47\n",
      "[188, 60] loss: 0.007\n",
      "[188, 120] loss: 0.006\n",
      "[188, 180] loss: 0.006\n",
      "[188, 240] loss: 0.007\n",
      "[188, 300] loss: 0.007\n",
      "[188, 360] loss: 0.007\n",
      "Epoch: 188 -> Loss: 0.00677263131365\n",
      "Epoch: 188 -> Test Accuracy: 91.44\n",
      "[189, 60] loss: 0.006\n",
      "[189, 120] loss: 0.007\n",
      "[189, 180] loss: 0.006\n",
      "[189, 240] loss: 0.007\n",
      "[189, 300] loss: 0.006\n",
      "[189, 360] loss: 0.006\n",
      "Epoch: 189 -> Loss: 0.00439889449626\n",
      "Epoch: 189 -> Test Accuracy: 91.42\n",
      "[190, 60] loss: 0.007\n",
      "[190, 120] loss: 0.006\n",
      "[190, 180] loss: 0.006\n",
      "[190, 240] loss: 0.006\n",
      "[190, 300] loss: 0.006\n",
      "[190, 360] loss: 0.006\n",
      "Epoch: 190 -> Loss: 0.00561082968488\n",
      "Epoch: 190 -> Test Accuracy: 91.44\n",
      "[191, 60] loss: 0.007\n",
      "[191, 120] loss: 0.006\n",
      "[191, 180] loss: 0.007\n",
      "[191, 240] loss: 0.007\n",
      "[191, 300] loss: 0.006\n",
      "[191, 360] loss: 0.006\n",
      "Epoch: 191 -> Loss: 0.00696980347857\n",
      "Epoch: 191 -> Test Accuracy: 91.36\n",
      "[192, 60] loss: 0.006\n",
      "[192, 120] loss: 0.006\n",
      "[192, 180] loss: 0.006\n",
      "[192, 240] loss: 0.006\n",
      "[192, 300] loss: 0.007\n",
      "[192, 360] loss: 0.006\n",
      "Epoch: 192 -> Loss: 0.00658121705055\n",
      "Epoch: 192 -> Test Accuracy: 91.4\n",
      "[193, 60] loss: 0.007\n",
      "[193, 120] loss: 0.006\n",
      "[193, 180] loss: 0.007\n",
      "[193, 240] loss: 0.007\n",
      "[193, 300] loss: 0.006\n",
      "[193, 360] loss: 0.006\n",
      "Epoch: 193 -> Loss: 0.0159955378622\n",
      "Epoch: 193 -> Test Accuracy: 91.53\n",
      "[194, 60] loss: 0.006\n",
      "[194, 120] loss: 0.006\n",
      "[194, 180] loss: 0.006\n",
      "[194, 240] loss: 0.006\n",
      "[194, 300] loss: 0.006\n",
      "[194, 360] loss: 0.007\n",
      "Epoch: 194 -> Loss: 0.00327979330905\n",
      "Epoch: 194 -> Test Accuracy: 91.44\n",
      "[195, 60] loss: 0.007\n",
      "[195, 120] loss: 0.007\n",
      "[195, 180] loss: 0.006\n",
      "[195, 240] loss: 0.006\n",
      "[195, 300] loss: 0.006\n",
      "[195, 360] loss: 0.006\n",
      "Epoch: 195 -> Loss: 0.0070840716362\n",
      "Epoch: 195 -> Test Accuracy: 91.49\n",
      "[196, 60] loss: 0.006\n",
      "[196, 120] loss: 0.007\n",
      "[196, 180] loss: 0.006\n",
      "[196, 240] loss: 0.006\n",
      "[196, 300] loss: 0.006\n",
      "[196, 360] loss: 0.006\n",
      "Epoch: 196 -> Loss: 0.00568947196007\n",
      "Epoch: 196 -> Test Accuracy: 91.44\n",
      "[197, 60] loss: 0.006\n",
      "[197, 120] loss: 0.007\n",
      "[197, 180] loss: 0.006\n",
      "[197, 240] loss: 0.006\n",
      "[197, 300] loss: 0.006\n",
      "[197, 360] loss: 0.006\n",
      "Epoch: 197 -> Loss: 0.0105060217902\n",
      "Epoch: 197 -> Test Accuracy: 91.39\n",
      "[198, 60] loss: 0.006\n",
      "[198, 120] loss: 0.007\n",
      "[198, 180] loss: 0.006\n",
      "[198, 240] loss: 0.006\n",
      "[198, 300] loss: 0.006\n",
      "[198, 360] loss: 0.006\n",
      "Epoch: 198 -> Loss: 0.00440440187231\n",
      "Epoch: 198 -> Test Accuracy: 91.48\n",
      "[199, 60] loss: 0.006\n",
      "[199, 120] loss: 0.006\n",
      "[199, 180] loss: 0.006\n",
      "[199, 240] loss: 0.006\n",
      "[199, 300] loss: 0.006\n",
      "[199, 360] loss: 0.005\n",
      "Epoch: 199 -> Loss: 0.0178160853684\n",
      "Epoch: 199 -> Test Accuracy: 91.4\n",
      "[200, 60] loss: 0.006\n",
      "[200, 120] loss: 0.007\n",
      "[200, 180] loss: 0.006\n",
      "[200, 240] loss: 0.006\n",
      "[200, 300] loss: 0.006\n",
      "[200, 360] loss: 0.006\n",
      "Epoch: 200 -> Loss: 0.00646641850471\n",
      "Epoch: 200 -> Test Accuracy: 91.44\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train 3 block RotNet on classification task\n",
    "class_NIN_loss_log, class_NIN_valid_accuracy_log, class_NIN_test_accuracy_log, class_NIN_max_accuracy, \\\n",
    "class_NIN_best_epoch = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], [60, 120, 160, 200], 0.9, 5e-4, net_class, \n",
    "                                            criterion, trainloader, None, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RotNet with 3 convolutional blocks\n",
    "net_block3 = fm.load_net()\n",
    "\n",
    "clf_1_block3 = fm.load_net()\n",
    "clf_2_block3 = fm.load_net()\n",
    "clf_3_block3 = fm.load_net()\n",
    "\n",
    "conv_clf_1_block3 = fm.load_net()\n",
    "conv_clf_2_block3 = fm.load_net()\n",
    "conv_clf_3_block3 = fm.load_net()\n",
    "\n",
    "print(\"RotNet model with 3 ConvBlocks\")\n",
    "\n",
    "print()\n",
    "print(\"Rotation Task:\")\n",
    "rot_acc_block3 = get_accuracy(testloader, net_block3, ['90', '180', '270'])\n",
    "rot_class_acc_block3 = get_class_accuracy(4, testloader, net_block3, rot_classes, ['90', '180', '270'])\n",
    "\n",
    "print()\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "print(\"Non-Linear Classifier on ConvBlock 1:\")\n",
    "clf_1_acc_block3 = get_accuracy(testloader, net_block3, classifier=clf_1_block3, conv_block_num=1)\n",
    "clf_1_class_acc_block3 = get_class_accuracy(10, testloader, net_block3, classes, classifier=clf_1_block3, \n",
    "                                            conv_block_num=1)\n",
    "\n",
    "print()\n",
    "print(\"Non-Linear Classifier on ConvBlock 2:\")\n",
    "clf_2_acc_block3 = get_accuracy(testloader, net_block3, classifier=clf_2_block3, conv_block_num=2)\n",
    "clf_2_class_acc_block3 = get_class_accuracy(10, testloader, net_block3, classes, classifier=clf_2_block3, \n",
    "                                            conv_block_num=2)\n",
    "\n",
    "print()\n",
    "print(\"Non-Linear Classifier on ConvBlock 3:\")\n",
    "clf_3_acc_block3 = get_accuracy(testloader, net_block3, classifier=clf_3_block3, conv_block_num=3)\n",
    "clf_3_class_acc_block3 = get_class_accuracy(10, testloader, net_block3, classes, classifier=clf_3_block3, \n",
    "                                            conv_block_num=3)\n",
    "\n",
    "print()\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "print(\"Convolutional Classifier on ConvBlock 1:\")\n",
    "conv_clf_1_acc_block3 = get_accuracy(testloader, net_block3, classifier=conv_clf_1_block3, conv_block_num=1)\n",
    "conv_clf_1_class_acc_block3 = get_class_accuracy(10, testloader, net_block3, classes, classifier=conv_clf_1_block3, \n",
    "                                            conv_block_num=1)\n",
    "\n",
    "print()\n",
    "print(\"Convolutional Classifier on ConvBlock 2:\")\n",
    "conv_clf_2_acc_block3 = get_accuracy(testloader, net_block3, classifier=conv_clf_2_block3, conv_block_num=2)\n",
    "conv_clf_2_class_acc_block3 = get_class_accuracy(10, testloader, net_block3, classes, classifier=conv_clf_2_block3, \n",
    "                                            conv_block_num=2)\n",
    "\n",
    "print()\n",
    "print(\"Convolutional Classifier on ConvBlock 3:\")\n",
    "conv_clf_3_acc_block3 = get_accuracy(testloader, net_block3, classifier=conv_clf_3_block3, conv_block_num=3)\n",
    "conv_clf_3_class_acc_block3 = get_class_accuracy(10, testloader, net_block3, classes, classifier=conv_clf_3_block3, \n",
    "                                            conv_block_num=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RotNet with 4 convolutional blocks\n",
    "net_block4 = fm.load_net()\n",
    "\n",
    "clf_1_block4 = fm.load_net()\n",
    "clf_2_block4 = fm.load_net()\n",
    "clf_3_block4 = fm.load_net()\n",
    "clf_4_block4 = fm.load_net()\n",
    "\n",
    "conv_clf_1_block4 = fm.load_net()\n",
    "conv_clf_2_block4 = fm.load_net()\n",
    "conv_clf_3_block4 = fm.load_net()\n",
    "conv_clf_4_block4 = fm.load_net()\n",
    "\n",
    "print(\"RotNet model with 4 ConvBlocks\")\n",
    "\n",
    "print()\n",
    "print(\"Rotation Task:\")\n",
    "rot_acc_block4 = get_accuracy(testloader, net_block4, ['90', '180', '270'])\n",
    "rot_class_acc_block4 = get_class_accuracy(4, testloader, net_block4, rot_classes, ['90', '180', '270'])\n",
    "\n",
    "print()\n",
    "print(\"-\" * 80)\n",
    "print()\n",
    "print(\"Non-Linear Classifier on ConvBlock 1:\")\n",
    "clf_1_acc_block4 = get_accuracy(testloader, net_block4, classifier=clf_1_block3, conv_block_num=1)\n",
    "clf_1_class_acc_block4 = get_class_accuracy(10, testloader, net_block3, classes, classifier=clf_1_block3, \n",
    "                                            conv_block_num=1)\n",
    "\n",
    "print()\n",
    "print(\"Non-Linear Classifier on ConvBlock 2:\")\n",
    "clf_2_acc_block3 = get_accuracy(testloader, net_block3, classifier=clf_2_block3, conv_block_num=2)\n",
    "clf_2_class_acc_block3 = get_class_accuracy(10, testloader, net_block3, classes, classifier=clf_2_block3, \n",
    "                                            conv_block_num=2)\n",
    "\n",
    "print()\n",
    "print(\"Non-Linear Classifier on ConvBlock 3:\")\n",
    "clf_3_acc_block3 = get_accuracy(testloader, net_block3, classifier=clf_3_block3, conv_block_num=3)\n",
    "clf_3_class_acc_block3 = get_class_accuracy(10, testloader, net_block3, classes, classifier=clf_3_block3, \n",
    "                                            conv_block_num=3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
