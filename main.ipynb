{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from functionalities import dataloader as dl\n",
    "from functionalities import evaluater as ev\n",
    "from functionalities import filemanager as fm\n",
    "from functionalities import trainer as tr\n",
    "from functionalities import plot as p\n",
    "from architecture import RotNet as RN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset, testset, classes = dl.load_cifar(\"./datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, validloader, testloader = dl.make_dataloaders(trainset, testset, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Loss Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RotNet for Rotation Task and Classifiers on Feature Maps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set rot classes\n",
    "rot_classes = ['original', '90 rotation', '180 rotation', '270 rotation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Block RotNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "net_block3 = RN.RotNet(num_classes=4, num_conv_block=3, add_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.141\n",
      "[1, 120] loss: 0.999\n",
      "[1, 180] loss: 0.920\n",
      "[1, 240] loss: 0.851\n",
      "[1, 300] loss: 0.790\n",
      "[1, 360] loss: 0.759\n",
      "Epoch: 1 -> Loss: 0.787678480148\n",
      "Epoch: 1 -> Test Accuracy: 69.21\n",
      "[2, 60] loss: 0.701\n",
      "[2, 120] loss: 0.696\n",
      "[2, 180] loss: 0.677\n",
      "[2, 240] loss: 0.648\n",
      "[2, 300] loss: 0.647\n",
      "[2, 360] loss: 0.616\n",
      "Epoch: 2 -> Loss: 0.662011623383\n",
      "Epoch: 2 -> Test Accuracy: 76.055\n",
      "[3, 60] loss: 0.596\n",
      "[3, 120] loss: 0.581\n",
      "[3, 180] loss: 0.577\n",
      "[3, 240] loss: 0.583\n",
      "[3, 300] loss: 0.557\n",
      "[3, 360] loss: 0.566\n",
      "Epoch: 3 -> Loss: 0.581205248833\n",
      "Epoch: 3 -> Test Accuracy: 78.8075\n",
      "[4, 60] loss: 0.544\n",
      "[4, 120] loss: 0.519\n",
      "[4, 180] loss: 0.517\n",
      "[4, 240] loss: 0.537\n",
      "[4, 300] loss: 0.507\n",
      "[4, 360] loss: 0.507\n",
      "Epoch: 4 -> Loss: 0.558216452599\n",
      "Epoch: 4 -> Test Accuracy: 79.01\n",
      "[5, 60] loss: 0.496\n",
      "[5, 120] loss: 0.497\n",
      "[5, 180] loss: 0.486\n",
      "[5, 240] loss: 0.495\n",
      "[5, 300] loss: 0.473\n",
      "[5, 360] loss: 0.472\n",
      "Epoch: 5 -> Loss: 0.537355840206\n",
      "Epoch: 5 -> Test Accuracy: 81.725\n",
      "[6, 60] loss: 0.449\n",
      "[6, 120] loss: 0.464\n",
      "[6, 180] loss: 0.462\n",
      "[6, 240] loss: 0.465\n",
      "[6, 300] loss: 0.466\n",
      "[6, 360] loss: 0.452\n",
      "Epoch: 6 -> Loss: 0.470865309238\n",
      "Epoch: 6 -> Test Accuracy: 81.4725\n",
      "[7, 60] loss: 0.439\n",
      "[7, 120] loss: 0.433\n",
      "[7, 180] loss: 0.429\n",
      "[7, 240] loss: 0.451\n",
      "[7, 300] loss: 0.439\n",
      "[7, 360] loss: 0.450\n",
      "Epoch: 7 -> Loss: 0.556775391102\n",
      "Epoch: 7 -> Test Accuracy: 83.0\n",
      "[8, 60] loss: 0.432\n",
      "[8, 120] loss: 0.434\n",
      "[8, 180] loss: 0.416\n",
      "[8, 240] loss: 0.422\n",
      "[8, 300] loss: 0.417\n",
      "[8, 360] loss: 0.429\n",
      "Epoch: 8 -> Loss: 0.499394506216\n",
      "Epoch: 8 -> Test Accuracy: 82.2925\n",
      "[9, 60] loss: 0.406\n",
      "[9, 120] loss: 0.397\n",
      "[9, 180] loss: 0.410\n",
      "[9, 240] loss: 0.417\n",
      "[9, 300] loss: 0.413\n",
      "[9, 360] loss: 0.406\n",
      "Epoch: 9 -> Loss: 0.406752169132\n",
      "Epoch: 9 -> Test Accuracy: 82.8125\n",
      "[10, 60] loss: 0.386\n",
      "[10, 120] loss: 0.398\n",
      "[10, 180] loss: 0.404\n",
      "[10, 240] loss: 0.402\n",
      "[10, 300] loss: 0.401\n",
      "[10, 360] loss: 0.402\n",
      "Epoch: 10 -> Loss: 0.341294229031\n",
      "Epoch: 10 -> Test Accuracy: 84.595\n",
      "[11, 60] loss: 0.385\n",
      "[11, 120] loss: 0.395\n",
      "[11, 180] loss: 0.400\n",
      "[11, 240] loss: 0.379\n",
      "[11, 300] loss: 0.391\n",
      "[11, 360] loss: 0.401\n",
      "Epoch: 11 -> Loss: 0.273233801126\n",
      "Epoch: 11 -> Test Accuracy: 84.7425\n",
      "[12, 60] loss: 0.388\n",
      "[12, 120] loss: 0.380\n",
      "[12, 180] loss: 0.389\n",
      "[12, 240] loss: 0.374\n",
      "[12, 300] loss: 0.375\n",
      "[12, 360] loss: 0.389\n",
      "Epoch: 12 -> Loss: 0.283909648657\n",
      "Epoch: 12 -> Test Accuracy: 84.285\n",
      "[13, 60] loss: 0.380\n",
      "[13, 120] loss: 0.366\n",
      "[13, 180] loss: 0.369\n",
      "[13, 240] loss: 0.375\n",
      "[13, 300] loss: 0.378\n",
      "[13, 360] loss: 0.368\n",
      "Epoch: 13 -> Loss: 0.423889309168\n",
      "Epoch: 13 -> Test Accuracy: 84.8575\n",
      "[14, 60] loss: 0.345\n",
      "[14, 120] loss: 0.374\n",
      "[14, 180] loss: 0.375\n",
      "[14, 240] loss: 0.373\n",
      "[14, 300] loss: 0.385\n",
      "[14, 360] loss: 0.377\n",
      "Epoch: 14 -> Loss: 0.427053511143\n",
      "Epoch: 14 -> Test Accuracy: 85.68\n",
      "[15, 60] loss: 0.357\n",
      "[15, 120] loss: 0.350\n",
      "[15, 180] loss: 0.352\n",
      "[15, 240] loss: 0.354\n",
      "[15, 300] loss: 0.373\n",
      "[15, 360] loss: 0.377\n",
      "Epoch: 15 -> Loss: 0.273929357529\n",
      "Epoch: 15 -> Test Accuracy: 85.0625\n",
      "[16, 60] loss: 0.342\n",
      "[16, 120] loss: 0.355\n",
      "[16, 180] loss: 0.359\n",
      "[16, 240] loss: 0.362\n",
      "[16, 300] loss: 0.356\n",
      "[16, 360] loss: 0.351\n",
      "Epoch: 16 -> Loss: 0.370511502028\n",
      "Epoch: 16 -> Test Accuracy: 85.84\n",
      "[17, 60] loss: 0.340\n",
      "[17, 120] loss: 0.351\n",
      "[17, 180] loss: 0.350\n",
      "[17, 240] loss: 0.339\n",
      "[17, 300] loss: 0.372\n",
      "[17, 360] loss: 0.364\n",
      "Epoch: 17 -> Loss: 0.440175831318\n",
      "Epoch: 17 -> Test Accuracy: 85.1375\n",
      "[18, 60] loss: 0.346\n",
      "[18, 120] loss: 0.324\n",
      "[18, 180] loss: 0.364\n",
      "[18, 240] loss: 0.361\n",
      "[18, 300] loss: 0.339\n",
      "[18, 360] loss: 0.349\n",
      "Epoch: 18 -> Loss: 0.436338275671\n",
      "Epoch: 18 -> Test Accuracy: 84.84\n",
      "[19, 60] loss: 0.345\n",
      "[19, 120] loss: 0.332\n",
      "[19, 180] loss: 0.351\n",
      "[19, 240] loss: 0.348\n",
      "[19, 300] loss: 0.347\n",
      "[19, 360] loss: 0.353\n",
      "Epoch: 19 -> Loss: 0.369504094124\n",
      "Epoch: 19 -> Test Accuracy: 85.5425\n",
      "[20, 60] loss: 0.332\n",
      "[20, 120] loss: 0.338\n",
      "[20, 180] loss: 0.358\n",
      "[20, 240] loss: 0.338\n",
      "[20, 300] loss: 0.341\n",
      "[20, 360] loss: 0.350\n",
      "Epoch: 20 -> Loss: 0.225799173117\n",
      "Epoch: 20 -> Test Accuracy: 86.325\n",
      "[21, 60] loss: 0.337\n",
      "[21, 120] loss: 0.341\n",
      "[21, 180] loss: 0.337\n",
      "[21, 240] loss: 0.341\n",
      "[21, 300] loss: 0.334\n",
      "[21, 360] loss: 0.337\n",
      "Epoch: 21 -> Loss: 0.392786115408\n",
      "Epoch: 21 -> Test Accuracy: 86.0875\n",
      "[22, 60] loss: 0.336\n",
      "[22, 120] loss: 0.334\n",
      "[22, 180] loss: 0.334\n",
      "[22, 240] loss: 0.339\n",
      "[22, 300] loss: 0.337\n",
      "[22, 360] loss: 0.330\n",
      "Epoch: 22 -> Loss: 0.356912195683\n",
      "Epoch: 22 -> Test Accuracy: 85.8025\n",
      "[23, 60] loss: 0.309\n",
      "[23, 120] loss: 0.337\n",
      "[23, 180] loss: 0.343\n",
      "[23, 240] loss: 0.327\n",
      "[23, 300] loss: 0.342\n",
      "[23, 360] loss: 0.333\n",
      "Epoch: 23 -> Loss: 0.468298614025\n",
      "Epoch: 23 -> Test Accuracy: 85.7675\n",
      "[24, 60] loss: 0.332\n",
      "[24, 120] loss: 0.321\n",
      "[24, 180] loss: 0.338\n",
      "[24, 240] loss: 0.338\n",
      "[24, 300] loss: 0.337\n",
      "[24, 360] loss: 0.332\n",
      "Epoch: 24 -> Loss: 0.208731681108\n",
      "Epoch: 24 -> Test Accuracy: 86.345\n",
      "[25, 60] loss: 0.330\n",
      "[25, 120] loss: 0.324\n",
      "[25, 180] loss: 0.336\n",
      "[25, 240] loss: 0.326\n",
      "[25, 300] loss: 0.336\n",
      "[25, 360] loss: 0.329\n",
      "Epoch: 25 -> Loss: 0.385006994009\n",
      "Epoch: 25 -> Test Accuracy: 85.9125\n",
      "[26, 60] loss: 0.318\n",
      "[26, 120] loss: 0.318\n",
      "[26, 180] loss: 0.328\n",
      "[26, 240] loss: 0.324\n",
      "[26, 300] loss: 0.331\n",
      "[26, 360] loss: 0.334\n",
      "Epoch: 26 -> Loss: 0.294116735458\n",
      "Epoch: 26 -> Test Accuracy: 86.9775\n",
      "[27, 60] loss: 0.305\n",
      "[27, 120] loss: 0.330\n",
      "[27, 180] loss: 0.327\n",
      "[27, 240] loss: 0.331\n",
      "[27, 300] loss: 0.339\n",
      "[27, 360] loss: 0.319\n",
      "Epoch: 27 -> Loss: 0.295988678932\n",
      "Epoch: 27 -> Test Accuracy: 86.8975\n",
      "[28, 60] loss: 0.330\n",
      "[28, 120] loss: 0.316\n",
      "[28, 180] loss: 0.325\n",
      "[28, 240] loss: 0.324\n",
      "[28, 300] loss: 0.318\n",
      "[28, 360] loss: 0.342\n",
      "Epoch: 28 -> Loss: 0.233337074518\n",
      "Epoch: 28 -> Test Accuracy: 86.135\n",
      "[29, 60] loss: 0.317\n",
      "[29, 120] loss: 0.330\n",
      "[29, 180] loss: 0.321\n",
      "[29, 240] loss: 0.322\n",
      "[29, 300] loss: 0.332\n",
      "[29, 360] loss: 0.313\n",
      "Epoch: 29 -> Loss: 0.352734535933\n",
      "Epoch: 29 -> Test Accuracy: 86.1825\n",
      "[30, 60] loss: 0.299\n",
      "[30, 120] loss: 0.326\n",
      "[30, 180] loss: 0.321\n",
      "[30, 240] loss: 0.328\n",
      "[30, 300] loss: 0.327\n",
      "[30, 360] loss: 0.329\n",
      "Epoch: 30 -> Loss: 0.335489243269\n",
      "Epoch: 30 -> Test Accuracy: 86.6575\n",
      "[31, 60] loss: 0.306\n",
      "[31, 120] loss: 0.327\n",
      "[31, 180] loss: 0.323\n",
      "[31, 240] loss: 0.322\n",
      "[31, 300] loss: 0.326\n",
      "[31, 360] loss: 0.315\n",
      "Epoch: 31 -> Loss: 0.512306988239\n",
      "Epoch: 31 -> Test Accuracy: 85.37\n",
      "[32, 60] loss: 0.297\n",
      "[32, 120] loss: 0.316\n",
      "[32, 180] loss: 0.340\n",
      "[32, 240] loss: 0.321\n",
      "[32, 300] loss: 0.310\n",
      "[32, 360] loss: 0.321\n",
      "Epoch: 32 -> Loss: 0.35365241766\n",
      "Epoch: 32 -> Test Accuracy: 86.9825\n",
      "[33, 60] loss: 0.319\n",
      "[33, 120] loss: 0.318\n",
      "[33, 180] loss: 0.328\n",
      "[33, 240] loss: 0.319\n",
      "[33, 300] loss: 0.313\n",
      "[33, 360] loss: 0.321\n",
      "Epoch: 33 -> Loss: 0.385478198528\n",
      "Epoch: 33 -> Test Accuracy: 86.2025\n",
      "[34, 60] loss: 0.318\n",
      "[34, 120] loss: 0.316\n",
      "[34, 180] loss: 0.300\n",
      "[34, 240] loss: 0.324\n",
      "[34, 300] loss: 0.319\n",
      "[34, 360] loss: 0.311\n",
      "Epoch: 34 -> Loss: 0.343362241983\n",
      "Epoch: 34 -> Test Accuracy: 85.1975\n",
      "[35, 60] loss: 0.309\n",
      "[35, 120] loss: 0.325\n",
      "[35, 180] loss: 0.327\n",
      "[35, 240] loss: 0.322\n",
      "[35, 300] loss: 0.320\n",
      "[35, 360] loss: 0.320\n",
      "Epoch: 35 -> Loss: 0.272876352072\n",
      "Epoch: 35 -> Test Accuracy: 86.99\n",
      "[36, 60] loss: 0.307\n",
      "[36, 120] loss: 0.308\n",
      "[36, 180] loss: 0.311\n",
      "[36, 240] loss: 0.322\n",
      "[36, 300] loss: 0.314\n",
      "[36, 360] loss: 0.322\n",
      "Epoch: 36 -> Loss: 0.267319113016\n",
      "Epoch: 36 -> Test Accuracy: 86.2175\n",
      "[37, 60] loss: 0.304\n",
      "[37, 120] loss: 0.319\n",
      "[37, 180] loss: 0.311\n",
      "[37, 240] loss: 0.317\n",
      "[37, 300] loss: 0.317\n",
      "[37, 360] loss: 0.314\n",
      "Epoch: 37 -> Loss: 0.215385004878\n",
      "Epoch: 37 -> Test Accuracy: 87.205\n",
      "[38, 60] loss: 0.300\n",
      "[38, 120] loss: 0.300\n",
      "[38, 180] loss: 0.300\n",
      "[38, 240] loss: 0.317\n",
      "[38, 300] loss: 0.318\n",
      "[38, 360] loss: 0.315\n",
      "Epoch: 38 -> Loss: 0.333074420691\n",
      "Epoch: 38 -> Test Accuracy: 86.69\n",
      "[39, 60] loss: 0.298\n",
      "[39, 120] loss: 0.313\n",
      "[39, 180] loss: 0.312\n",
      "[39, 240] loss: 0.314\n",
      "[39, 300] loss: 0.312\n",
      "[39, 360] loss: 0.322\n",
      "Epoch: 39 -> Loss: 0.329833418131\n",
      "Epoch: 39 -> Test Accuracy: 87.2125\n",
      "[40, 60] loss: 0.298\n",
      "[40, 120] loss: 0.299\n",
      "[40, 180] loss: 0.309\n",
      "[40, 240] loss: 0.317\n",
      "[40, 300] loss: 0.317\n",
      "[40, 360] loss: 0.316\n",
      "Epoch: 40 -> Loss: 0.324939012527\n",
      "Epoch: 40 -> Test Accuracy: 87.0475\n",
      "[41, 60] loss: 0.303\n",
      "[41, 120] loss: 0.304\n",
      "[41, 180] loss: 0.305\n",
      "[41, 240] loss: 0.304\n",
      "[41, 300] loss: 0.327\n",
      "[41, 360] loss: 0.309\n",
      "Epoch: 41 -> Loss: 0.334853470325\n",
      "Epoch: 41 -> Test Accuracy: 86.5025\n",
      "[42, 60] loss: 0.309\n",
      "[42, 120] loss: 0.306\n",
      "[42, 180] loss: 0.314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 240] loss: 0.322\n",
      "[42, 300] loss: 0.311\n",
      "[42, 360] loss: 0.313\n",
      "Epoch: 42 -> Loss: 0.318148314953\n",
      "Epoch: 42 -> Test Accuracy: 87.27\n",
      "[43, 60] loss: 0.284\n",
      "[43, 120] loss: 0.312\n",
      "[43, 180] loss: 0.322\n",
      "[43, 240] loss: 0.291\n",
      "[43, 300] loss: 0.321\n",
      "[43, 360] loss: 0.304\n",
      "Epoch: 43 -> Loss: 0.382598012686\n",
      "Epoch: 43 -> Test Accuracy: 83.9325\n",
      "[44, 60] loss: 0.311\n",
      "[44, 120] loss: 0.305\n",
      "[44, 180] loss: 0.303\n",
      "[44, 240] loss: 0.298\n",
      "[44, 300] loss: 0.310\n",
      "[44, 360] loss: 0.330\n",
      "Epoch: 44 -> Loss: 0.220706671476\n",
      "Epoch: 44 -> Test Accuracy: 87.075\n",
      "[45, 60] loss: 0.298\n",
      "[45, 120] loss: 0.296\n",
      "[45, 180] loss: 0.313\n",
      "[45, 240] loss: 0.317\n",
      "[45, 300] loss: 0.302\n",
      "[45, 360] loss: 0.308\n",
      "Epoch: 45 -> Loss: 0.32049909234\n",
      "Epoch: 45 -> Test Accuracy: 87.4575\n",
      "[46, 60] loss: 0.290\n",
      "[46, 120] loss: 0.306\n",
      "[46, 180] loss: 0.302\n",
      "[46, 240] loss: 0.307\n",
      "[46, 300] loss: 0.309\n",
      "[46, 360] loss: 0.316\n",
      "Epoch: 46 -> Loss: 0.323618233204\n",
      "Epoch: 46 -> Test Accuracy: 87.1525\n",
      "[47, 60] loss: 0.294\n",
      "[47, 120] loss: 0.285\n",
      "[47, 180] loss: 0.300\n",
      "[47, 240] loss: 0.322\n",
      "[47, 300] loss: 0.311\n",
      "[47, 360] loss: 0.307\n",
      "Epoch: 47 -> Loss: 0.383451044559\n",
      "Epoch: 47 -> Test Accuracy: 86.2075\n",
      "[48, 60] loss: 0.297\n",
      "[48, 120] loss: 0.300\n",
      "[48, 180] loss: 0.293\n",
      "[48, 240] loss: 0.324\n",
      "[48, 300] loss: 0.312\n",
      "[48, 360] loss: 0.307\n",
      "Epoch: 48 -> Loss: 0.247455790639\n",
      "Epoch: 48 -> Test Accuracy: 87.21\n",
      "[49, 60] loss: 0.280\n",
      "[49, 120] loss: 0.305\n",
      "[49, 180] loss: 0.303\n",
      "[49, 240] loss: 0.310\n",
      "[49, 300] loss: 0.311\n",
      "[49, 360] loss: 0.316\n",
      "Epoch: 49 -> Loss: 0.177563875914\n",
      "Epoch: 49 -> Test Accuracy: 86.7775\n",
      "[50, 60] loss: 0.310\n",
      "[50, 120] loss: 0.299\n",
      "[50, 180] loss: 0.295\n",
      "[50, 240] loss: 0.303\n",
      "[50, 300] loss: 0.308\n",
      "[50, 360] loss: 0.317\n",
      "Epoch: 50 -> Loss: 0.344310581684\n",
      "Epoch: 50 -> Test Accuracy: 87.055\n",
      "[51, 60] loss: 0.287\n",
      "[51, 120] loss: 0.293\n",
      "[51, 180] loss: 0.309\n",
      "[51, 240] loss: 0.303\n",
      "[51, 300] loss: 0.308\n",
      "[51, 360] loss: 0.311\n",
      "Epoch: 51 -> Loss: 0.226258903742\n",
      "Epoch: 51 -> Test Accuracy: 87.18\n",
      "[52, 60] loss: 0.288\n",
      "[52, 120] loss: 0.309\n",
      "[52, 180] loss: 0.302\n",
      "[52, 240] loss: 0.311\n",
      "[52, 300] loss: 0.306\n",
      "[52, 360] loss: 0.306\n",
      "Epoch: 52 -> Loss: 0.207420393825\n",
      "Epoch: 52 -> Test Accuracy: 85.79\n",
      "[53, 60] loss: 0.296\n",
      "[53, 120] loss: 0.301\n",
      "[53, 180] loss: 0.297\n",
      "[53, 240] loss: 0.297\n",
      "[53, 300] loss: 0.304\n",
      "[53, 360] loss: 0.310\n",
      "Epoch: 53 -> Loss: 0.364464432001\n",
      "Epoch: 53 -> Test Accuracy: 87.105\n",
      "[54, 60] loss: 0.300\n",
      "[54, 120] loss: 0.304\n",
      "[54, 180] loss: 0.313\n",
      "[54, 240] loss: 0.303\n",
      "[54, 300] loss: 0.302\n",
      "[54, 360] loss: 0.298\n",
      "Epoch: 54 -> Loss: 0.423810869455\n",
      "Epoch: 54 -> Test Accuracy: 86.735\n",
      "[55, 60] loss: 0.292\n",
      "[55, 120] loss: 0.302\n",
      "[55, 180] loss: 0.307\n",
      "[55, 240] loss: 0.300\n",
      "[55, 300] loss: 0.294\n",
      "[55, 360] loss: 0.310\n",
      "Epoch: 55 -> Loss: 0.418384850025\n",
      "Epoch: 55 -> Test Accuracy: 87.13\n",
      "[56, 60] loss: 0.289\n",
      "[56, 120] loss: 0.310\n",
      "[56, 180] loss: 0.288\n",
      "[56, 240] loss: 0.301\n",
      "[56, 300] loss: 0.298\n",
      "[56, 360] loss: 0.308\n",
      "Epoch: 56 -> Loss: 0.383456289768\n",
      "Epoch: 56 -> Test Accuracy: 86.5475\n",
      "[57, 60] loss: 0.295\n",
      "[57, 120] loss: 0.302\n",
      "[57, 180] loss: 0.305\n",
      "[57, 240] loss: 0.306\n",
      "[57, 300] loss: 0.297\n",
      "[57, 360] loss: 0.298\n",
      "Epoch: 57 -> Loss: 0.171087294817\n",
      "Epoch: 57 -> Test Accuracy: 87.1125\n",
      "[58, 60] loss: 0.280\n",
      "[58, 120] loss: 0.290\n",
      "[58, 180] loss: 0.306\n",
      "[58, 240] loss: 0.300\n",
      "[58, 300] loss: 0.307\n",
      "[58, 360] loss: 0.291\n",
      "Epoch: 58 -> Loss: 0.33591324091\n",
      "Epoch: 58 -> Test Accuracy: 86.4525\n",
      "[59, 60] loss: 0.285\n",
      "[59, 120] loss: 0.292\n",
      "[59, 180] loss: 0.299\n",
      "[59, 240] loss: 0.301\n",
      "[59, 300] loss: 0.307\n",
      "[59, 360] loss: 0.308\n",
      "Epoch: 59 -> Loss: 0.359701931477\n",
      "Epoch: 59 -> Test Accuracy: 86.6825\n",
      "[60, 60] loss: 0.296\n",
      "[60, 120] loss: 0.296\n",
      "[60, 180] loss: 0.294\n",
      "[60, 240] loss: 0.295\n",
      "[60, 300] loss: 0.304\n",
      "[60, 360] loss: 0.283\n",
      "Epoch: 60 -> Loss: 0.189138680696\n",
      "Epoch: 60 -> Test Accuracy: 86.9475\n",
      "[61, 60] loss: 0.233\n",
      "[61, 120] loss: 0.200\n",
      "[61, 180] loss: 0.192\n",
      "[61, 240] loss: 0.179\n",
      "[61, 300] loss: 0.185\n",
      "[61, 360] loss: 0.176\n",
      "Epoch: 61 -> Loss: 0.169828921556\n",
      "Epoch: 61 -> Test Accuracy: 91.1325\n",
      "[62, 60] loss: 0.152\n",
      "[62, 120] loss: 0.171\n",
      "[62, 180] loss: 0.173\n",
      "[62, 240] loss: 0.170\n",
      "[62, 300] loss: 0.175\n",
      "[62, 360] loss: 0.172\n",
      "Epoch: 62 -> Loss: 0.253974795341\n",
      "Epoch: 62 -> Test Accuracy: 91.3325\n",
      "[63, 60] loss: 0.144\n",
      "[63, 120] loss: 0.151\n",
      "[63, 180] loss: 0.154\n",
      "[63, 240] loss: 0.161\n",
      "[63, 300] loss: 0.159\n",
      "[63, 360] loss: 0.156\n",
      "Epoch: 63 -> Loss: 0.121799066663\n",
      "Epoch: 63 -> Test Accuracy: 91.0675\n",
      "[64, 60] loss: 0.147\n",
      "[64, 120] loss: 0.150\n",
      "[64, 180] loss: 0.157\n",
      "[64, 240] loss: 0.149\n",
      "[64, 300] loss: 0.159\n",
      "[64, 360] loss: 0.152\n",
      "Epoch: 64 -> Loss: 0.203890949488\n",
      "Epoch: 64 -> Test Accuracy: 91.1125\n",
      "[65, 60] loss: 0.148\n",
      "[65, 120] loss: 0.141\n",
      "[65, 180] loss: 0.142\n",
      "[65, 240] loss: 0.159\n",
      "[65, 300] loss: 0.150\n",
      "[65, 360] loss: 0.143\n",
      "Epoch: 65 -> Loss: 0.0973534584045\n",
      "Epoch: 65 -> Test Accuracy: 91.3175\n",
      "[66, 60] loss: 0.138\n",
      "[66, 120] loss: 0.137\n",
      "[66, 180] loss: 0.146\n",
      "[66, 240] loss: 0.144\n",
      "[66, 300] loss: 0.156\n",
      "[66, 360] loss: 0.154\n",
      "Epoch: 66 -> Loss: 0.157145500183\n",
      "Epoch: 66 -> Test Accuracy: 90.9675\n",
      "[67, 60] loss: 0.140\n",
      "[67, 120] loss: 0.142\n",
      "[67, 180] loss: 0.138\n",
      "[67, 240] loss: 0.143\n",
      "[67, 300] loss: 0.155\n",
      "[67, 360] loss: 0.150\n",
      "Epoch: 67 -> Loss: 0.144269049168\n",
      "Epoch: 67 -> Test Accuracy: 91.22\n",
      "[68, 60] loss: 0.138\n",
      "[68, 120] loss: 0.141\n",
      "[68, 180] loss: 0.138\n",
      "[68, 240] loss: 0.142\n",
      "[68, 300] loss: 0.149\n",
      "[68, 360] loss: 0.156\n",
      "Epoch: 68 -> Loss: 0.115117274225\n",
      "Epoch: 68 -> Test Accuracy: 90.9275\n",
      "[69, 60] loss: 0.130\n",
      "[69, 120] loss: 0.150\n",
      "[69, 180] loss: 0.140\n",
      "[69, 240] loss: 0.147\n",
      "[69, 300] loss: 0.149\n",
      "[69, 360] loss: 0.151\n",
      "Epoch: 69 -> Loss: 0.166590347886\n",
      "Epoch: 69 -> Test Accuracy: 91.17\n",
      "[70, 60] loss: 0.134\n",
      "[70, 120] loss: 0.135\n",
      "[70, 180] loss: 0.146\n",
      "[70, 240] loss: 0.142\n",
      "[70, 300] loss: 0.153\n",
      "[70, 360] loss: 0.151\n",
      "Epoch: 70 -> Loss: 0.12411685288\n",
      "Epoch: 70 -> Test Accuracy: 91.2375\n",
      "[71, 60] loss: 0.135\n",
      "[71, 120] loss: 0.138\n",
      "[71, 180] loss: 0.142\n",
      "[71, 240] loss: 0.148\n",
      "[71, 300] loss: 0.149\n",
      "[71, 360] loss: 0.150\n",
      "Epoch: 71 -> Loss: 0.111194655299\n",
      "Epoch: 71 -> Test Accuracy: 90.845\n",
      "[72, 60] loss: 0.138\n",
      "[72, 120] loss: 0.142\n",
      "[72, 180] loss: 0.139\n",
      "[72, 240] loss: 0.145\n",
      "[72, 300] loss: 0.151\n",
      "[72, 360] loss: 0.158\n",
      "Epoch: 72 -> Loss: 0.115612111986\n",
      "Epoch: 72 -> Test Accuracy: 90.725\n",
      "[73, 60] loss: 0.136\n",
      "[73, 120] loss: 0.148\n",
      "[73, 180] loss: 0.146\n",
      "[73, 240] loss: 0.137\n",
      "[73, 300] loss: 0.145\n",
      "[73, 360] loss: 0.153\n",
      "Epoch: 73 -> Loss: 0.173922792077\n",
      "Epoch: 73 -> Test Accuracy: 90.495\n",
      "[74, 60] loss: 0.137\n",
      "[74, 120] loss: 0.132\n",
      "[74, 180] loss: 0.148\n",
      "[74, 240] loss: 0.156\n",
      "[74, 300] loss: 0.160\n",
      "[74, 360] loss: 0.153\n",
      "Epoch: 74 -> Loss: 0.161368072033\n",
      "Epoch: 74 -> Test Accuracy: 90.6275\n",
      "[75, 60] loss: 0.137\n",
      "[75, 120] loss: 0.132\n",
      "[75, 180] loss: 0.149\n",
      "[75, 240] loss: 0.152\n",
      "[75, 300] loss: 0.149\n",
      "[75, 360] loss: 0.144\n",
      "Epoch: 75 -> Loss: 0.264967113733\n",
      "Epoch: 75 -> Test Accuracy: 90.45\n",
      "[76, 60] loss: 0.135\n",
      "[76, 120] loss: 0.142\n",
      "[76, 180] loss: 0.146\n",
      "[76, 240] loss: 0.158\n",
      "[76, 300] loss: 0.145\n",
      "[76, 360] loss: 0.151\n",
      "Epoch: 76 -> Loss: 0.18966922164\n",
      "Epoch: 76 -> Test Accuracy: 90.3475\n",
      "[77, 60] loss: 0.134\n",
      "[77, 120] loss: 0.135\n",
      "[77, 180] loss: 0.137\n",
      "[77, 240] loss: 0.144\n",
      "[77, 300] loss: 0.159\n",
      "[77, 360] loss: 0.164\n",
      "Epoch: 77 -> Loss: 0.165032312274\n",
      "Epoch: 77 -> Test Accuracy: 89.9725\n",
      "[78, 60] loss: 0.137\n",
      "[78, 120] loss: 0.137\n",
      "[78, 180] loss: 0.150\n",
      "[78, 240] loss: 0.148\n",
      "[78, 300] loss: 0.148\n",
      "[78, 360] loss: 0.147\n",
      "Epoch: 78 -> Loss: 0.118702635169\n",
      "Epoch: 78 -> Test Accuracy: 90.21\n",
      "[79, 60] loss: 0.142\n",
      "[79, 120] loss: 0.139\n",
      "[79, 180] loss: 0.141\n",
      "[79, 240] loss: 0.145\n",
      "[79, 300] loss: 0.145\n",
      "[79, 360] loss: 0.157\n",
      "Epoch: 79 -> Loss: 0.200592786074\n",
      "Epoch: 79 -> Test Accuracy: 90.805\n",
      "[80, 60] loss: 0.146\n",
      "[80, 120] loss: 0.140\n",
      "[80, 180] loss: 0.146\n",
      "[80, 240] loss: 0.144\n",
      "[80, 300] loss: 0.146\n",
      "[80, 360] loss: 0.163\n",
      "Epoch: 80 -> Loss: 0.0748644471169\n",
      "Epoch: 80 -> Test Accuracy: 90.3125\n",
      "[81, 60] loss: 0.147\n",
      "[81, 120] loss: 0.146\n",
      "[81, 180] loss: 0.151\n",
      "[81, 240] loss: 0.139\n",
      "[81, 300] loss: 0.150\n",
      "[81, 360] loss: 0.157\n",
      "Epoch: 81 -> Loss: 0.112988092005\n",
      "Epoch: 81 -> Test Accuracy: 90.3075\n",
      "[82, 60] loss: 0.138\n",
      "[82, 120] loss: 0.138\n",
      "[82, 180] loss: 0.152\n",
      "[82, 240] loss: 0.144\n",
      "[82, 300] loss: 0.144\n",
      "[82, 360] loss: 0.154\n",
      "Epoch: 82 -> Loss: 0.0915526524186\n",
      "Epoch: 82 -> Test Accuracy: 90.405\n",
      "[83, 60] loss: 0.130\n",
      "[83, 120] loss: 0.140\n",
      "[83, 180] loss: 0.146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83, 240] loss: 0.145\n",
      "[83, 300] loss: 0.153\n",
      "[83, 360] loss: 0.158\n",
      "Epoch: 83 -> Loss: 0.156742066145\n",
      "Epoch: 83 -> Test Accuracy: 90.6825\n",
      "[84, 60] loss: 0.135\n",
      "[84, 120] loss: 0.139\n",
      "[84, 180] loss: 0.137\n",
      "[84, 240] loss: 0.145\n",
      "[84, 300] loss: 0.158\n",
      "[84, 360] loss: 0.149\n",
      "Epoch: 84 -> Loss: 0.114132240415\n",
      "Epoch: 84 -> Test Accuracy: 90.4775\n",
      "[85, 60] loss: 0.129\n",
      "[85, 120] loss: 0.129\n",
      "[85, 180] loss: 0.137\n",
      "[85, 240] loss: 0.145\n",
      "[85, 300] loss: 0.148\n",
      "[85, 360] loss: 0.152\n",
      "Epoch: 85 -> Loss: 0.170121192932\n",
      "Epoch: 85 -> Test Accuracy: 90.3325\n",
      "[86, 60] loss: 0.132\n",
      "[86, 120] loss: 0.145\n",
      "[86, 180] loss: 0.141\n",
      "[86, 240] loss: 0.146\n",
      "[86, 300] loss: 0.144\n",
      "[86, 360] loss: 0.155\n",
      "Epoch: 86 -> Loss: 0.139373719692\n",
      "Epoch: 86 -> Test Accuracy: 90.41\n",
      "[87, 60] loss: 0.136\n",
      "[87, 120] loss: 0.136\n",
      "[87, 180] loss: 0.147\n",
      "[87, 240] loss: 0.148\n",
      "[87, 300] loss: 0.145\n",
      "[87, 360] loss: 0.157\n",
      "Epoch: 87 -> Loss: 0.234496861696\n",
      "Epoch: 87 -> Test Accuracy: 89.7625\n",
      "[88, 60] loss: 0.134\n",
      "[88, 120] loss: 0.139\n",
      "[88, 180] loss: 0.140\n",
      "[88, 240] loss: 0.139\n",
      "[88, 300] loss: 0.155\n",
      "[88, 360] loss: 0.162\n",
      "Epoch: 88 -> Loss: 0.169020205736\n",
      "Epoch: 88 -> Test Accuracy: 90.3625\n",
      "[89, 60] loss: 0.132\n",
      "[89, 120] loss: 0.142\n",
      "[89, 180] loss: 0.144\n",
      "[89, 240] loss: 0.148\n",
      "[89, 300] loss: 0.141\n",
      "[89, 360] loss: 0.141\n",
      "Epoch: 89 -> Loss: 0.257692873478\n",
      "Epoch: 89 -> Test Accuracy: 90.35\n",
      "[90, 60] loss: 0.135\n",
      "[90, 120] loss: 0.136\n",
      "[90, 180] loss: 0.148\n",
      "[90, 240] loss: 0.139\n",
      "[90, 300] loss: 0.152\n",
      "[90, 360] loss: 0.150\n",
      "Epoch: 90 -> Loss: 0.183051347733\n",
      "Epoch: 90 -> Test Accuracy: 90.4525\n",
      "[91, 60] loss: 0.127\n",
      "[91, 120] loss: 0.136\n",
      "[91, 180] loss: 0.146\n",
      "[91, 240] loss: 0.146\n",
      "[91, 300] loss: 0.143\n",
      "[91, 360] loss: 0.146\n",
      "Epoch: 91 -> Loss: 0.230325505137\n",
      "Epoch: 91 -> Test Accuracy: 90.575\n",
      "[92, 60] loss: 0.137\n",
      "[92, 120] loss: 0.130\n",
      "[92, 180] loss: 0.133\n",
      "[92, 240] loss: 0.142\n",
      "[92, 300] loss: 0.144\n",
      "[92, 360] loss: 0.150\n",
      "Epoch: 92 -> Loss: 0.177278190851\n",
      "Epoch: 92 -> Test Accuracy: 90.1125\n",
      "[93, 60] loss: 0.124\n",
      "[93, 120] loss: 0.132\n",
      "[93, 180] loss: 0.143\n",
      "[93, 240] loss: 0.145\n",
      "[93, 300] loss: 0.138\n",
      "[93, 360] loss: 0.150\n",
      "Epoch: 93 -> Loss: 0.115009739995\n",
      "Epoch: 93 -> Test Accuracy: 90.295\n",
      "[94, 60] loss: 0.132\n",
      "[94, 120] loss: 0.133\n",
      "[94, 180] loss: 0.134\n",
      "[94, 240] loss: 0.152\n",
      "[94, 300] loss: 0.152\n",
      "[94, 360] loss: 0.144\n",
      "Epoch: 94 -> Loss: 0.123808979988\n",
      "Epoch: 94 -> Test Accuracy: 90.675\n",
      "[95, 60] loss: 0.140\n",
      "[95, 120] loss: 0.130\n",
      "[95, 180] loss: 0.147\n",
      "[95, 240] loss: 0.143\n",
      "[95, 300] loss: 0.146\n",
      "[95, 360] loss: 0.145\n",
      "Epoch: 95 -> Loss: 0.0961346998811\n",
      "Epoch: 95 -> Test Accuracy: 90.2625\n",
      "[96, 60] loss: 0.130\n",
      "[96, 120] loss: 0.129\n",
      "[96, 180] loss: 0.139\n",
      "[96, 240] loss: 0.147\n",
      "[96, 300] loss: 0.152\n",
      "[96, 360] loss: 0.144\n",
      "Epoch: 96 -> Loss: 0.0893204286695\n",
      "Epoch: 96 -> Test Accuracy: 90.52\n",
      "[97, 60] loss: 0.124\n",
      "[97, 120] loss: 0.135\n",
      "[97, 180] loss: 0.141\n",
      "[97, 240] loss: 0.137\n",
      "[97, 300] loss: 0.133\n",
      "[97, 360] loss: 0.146\n",
      "Epoch: 97 -> Loss: 0.141617566347\n",
      "Epoch: 97 -> Test Accuracy: 91.06\n",
      "[98, 60] loss: 0.125\n",
      "[98, 120] loss: 0.140\n",
      "[98, 180] loss: 0.143\n",
      "[98, 240] loss: 0.136\n",
      "[98, 300] loss: 0.143\n",
      "[98, 360] loss: 0.150\n",
      "Epoch: 98 -> Loss: 0.166911140084\n",
      "Epoch: 98 -> Test Accuracy: 90.305\n",
      "[99, 60] loss: 0.129\n",
      "[99, 120] loss: 0.130\n",
      "[99, 180] loss: 0.136\n",
      "[99, 240] loss: 0.139\n",
      "[99, 300] loss: 0.149\n",
      "[99, 360] loss: 0.140\n",
      "Epoch: 99 -> Loss: 0.151396125555\n",
      "Epoch: 99 -> Test Accuracy: 89.95\n",
      "[100, 60] loss: 0.130\n",
      "[100, 120] loss: 0.133\n",
      "[100, 180] loss: 0.135\n",
      "[100, 240] loss: 0.144\n",
      "[100, 300] loss: 0.147\n",
      "[100, 360] loss: 0.154\n",
      "Epoch: 100 -> Loss: 0.127764731646\n",
      "Epoch: 100 -> Test Accuracy: 90.2675\n",
      "[101, 60] loss: 0.135\n",
      "[101, 120] loss: 0.125\n",
      "[101, 180] loss: 0.139\n",
      "[101, 240] loss: 0.136\n",
      "[101, 300] loss: 0.151\n",
      "[101, 360] loss: 0.141\n",
      "Epoch: 101 -> Loss: 0.155829519033\n",
      "Epoch: 101 -> Test Accuracy: 90.58\n",
      "[102, 60] loss: 0.127\n",
      "[102, 120] loss: 0.132\n",
      "[102, 180] loss: 0.140\n",
      "[102, 240] loss: 0.142\n",
      "[102, 300] loss: 0.142\n",
      "[102, 360] loss: 0.148\n",
      "Epoch: 102 -> Loss: 0.149779215455\n",
      "Epoch: 102 -> Test Accuracy: 90.5275\n",
      "[103, 60] loss: 0.123\n",
      "[103, 120] loss: 0.132\n",
      "[103, 180] loss: 0.137\n",
      "[103, 240] loss: 0.136\n",
      "[103, 300] loss: 0.139\n",
      "[103, 360] loss: 0.144\n",
      "Epoch: 103 -> Loss: 0.143297225237\n",
      "Epoch: 103 -> Test Accuracy: 89.9525\n",
      "[104, 60] loss: 0.137\n",
      "[104, 120] loss: 0.121\n",
      "[104, 180] loss: 0.140\n",
      "[104, 240] loss: 0.140\n",
      "[104, 300] loss: 0.133\n",
      "[104, 360] loss: 0.147\n",
      "Epoch: 104 -> Loss: 0.165147423744\n",
      "Epoch: 104 -> Test Accuracy: 90.55\n",
      "[105, 60] loss: 0.127\n",
      "[105, 120] loss: 0.120\n",
      "[105, 180] loss: 0.136\n",
      "[105, 240] loss: 0.147\n",
      "[105, 300] loss: 0.143\n",
      "[105, 360] loss: 0.145\n",
      "Epoch: 105 -> Loss: 0.153953403234\n",
      "Epoch: 105 -> Test Accuracy: 90.44\n",
      "[106, 60] loss: 0.120\n",
      "[106, 120] loss: 0.128\n",
      "[106, 180] loss: 0.131\n",
      "[106, 240] loss: 0.136\n",
      "[106, 300] loss: 0.137\n",
      "[106, 360] loss: 0.139\n",
      "Epoch: 106 -> Loss: 0.160528451204\n",
      "Epoch: 106 -> Test Accuracy: 91.0075\n",
      "[107, 60] loss: 0.127\n",
      "[107, 120] loss: 0.121\n",
      "[107, 180] loss: 0.132\n",
      "[107, 240] loss: 0.139\n",
      "[107, 300] loss: 0.142\n",
      "[107, 360] loss: 0.142\n",
      "Epoch: 107 -> Loss: 0.0822361558676\n",
      "Epoch: 107 -> Test Accuracy: 90.775\n",
      "[108, 60] loss: 0.134\n",
      "[108, 120] loss: 0.134\n",
      "[108, 180] loss: 0.135\n",
      "[108, 240] loss: 0.143\n",
      "[108, 300] loss: 0.129\n",
      "[108, 360] loss: 0.143\n",
      "Epoch: 108 -> Loss: 0.14577370882\n",
      "Epoch: 108 -> Test Accuracy: 90.03\n",
      "[109, 60] loss: 0.122\n",
      "[109, 120] loss: 0.129\n",
      "[109, 180] loss: 0.130\n",
      "[109, 240] loss: 0.133\n",
      "[109, 300] loss: 0.133\n",
      "[109, 360] loss: 0.149\n",
      "Epoch: 109 -> Loss: 0.171248614788\n",
      "Epoch: 109 -> Test Accuracy: 90.3875\n",
      "[110, 60] loss: 0.128\n",
      "[110, 120] loss: 0.130\n",
      "[110, 180] loss: 0.142\n",
      "[110, 240] loss: 0.139\n",
      "[110, 300] loss: 0.136\n",
      "[110, 360] loss: 0.143\n",
      "Epoch: 110 -> Loss: 0.190067365766\n",
      "Epoch: 110 -> Test Accuracy: 90.57\n",
      "[111, 60] loss: 0.121\n",
      "[111, 120] loss: 0.133\n",
      "[111, 180] loss: 0.132\n",
      "[111, 240] loss: 0.138\n",
      "[111, 300] loss: 0.141\n",
      "[111, 360] loss: 0.134\n",
      "Epoch: 111 -> Loss: 0.136060848832\n",
      "Epoch: 111 -> Test Accuracy: 90.3075\n",
      "[112, 60] loss: 0.129\n",
      "[112, 120] loss: 0.127\n",
      "[112, 180] loss: 0.136\n",
      "[112, 240] loss: 0.134\n",
      "[112, 300] loss: 0.141\n",
      "[112, 360] loss: 0.135\n",
      "Epoch: 112 -> Loss: 0.13542817533\n",
      "Epoch: 112 -> Test Accuracy: 90.8225\n",
      "[113, 60] loss: 0.117\n",
      "[113, 120] loss: 0.127\n",
      "[113, 180] loss: 0.133\n",
      "[113, 240] loss: 0.142\n",
      "[113, 300] loss: 0.142\n",
      "[113, 360] loss: 0.131\n",
      "Epoch: 113 -> Loss: 0.221937775612\n",
      "Epoch: 113 -> Test Accuracy: 89.9675\n",
      "[114, 60] loss: 0.129\n",
      "[114, 120] loss: 0.131\n",
      "[114, 180] loss: 0.135\n",
      "[114, 240] loss: 0.133\n",
      "[114, 300] loss: 0.139\n",
      "[114, 360] loss: 0.143\n",
      "Epoch: 114 -> Loss: 0.0751198902726\n",
      "Epoch: 114 -> Test Accuracy: 90.23\n",
      "[115, 60] loss: 0.126\n",
      "[115, 120] loss: 0.116\n",
      "[115, 180] loss: 0.129\n",
      "[115, 240] loss: 0.137\n",
      "[115, 300] loss: 0.134\n",
      "[115, 360] loss: 0.141\n",
      "Epoch: 115 -> Loss: 0.137918055058\n",
      "Epoch: 115 -> Test Accuracy: 90.8375\n",
      "[116, 60] loss: 0.124\n",
      "[116, 120] loss: 0.134\n",
      "[116, 180] loss: 0.136\n",
      "[116, 240] loss: 0.128\n",
      "[116, 300] loss: 0.131\n",
      "[116, 360] loss: 0.139\n",
      "Epoch: 116 -> Loss: 0.073376826942\n",
      "Epoch: 116 -> Test Accuracy: 90.7075\n",
      "[117, 60] loss: 0.121\n",
      "[117, 120] loss: 0.128\n",
      "[117, 180] loss: 0.124\n",
      "[117, 240] loss: 0.139\n",
      "[117, 300] loss: 0.137\n",
      "[117, 360] loss: 0.143\n",
      "Epoch: 117 -> Loss: 0.135540992022\n",
      "Epoch: 117 -> Test Accuracy: 90.095\n",
      "[118, 60] loss: 0.130\n",
      "[118, 120] loss: 0.129\n",
      "[118, 180] loss: 0.127\n",
      "[118, 240] loss: 0.135\n",
      "[118, 300] loss: 0.140\n",
      "[118, 360] loss: 0.138\n",
      "Epoch: 118 -> Loss: 0.0981592684984\n",
      "Epoch: 118 -> Test Accuracy: 90.3075\n",
      "[119, 60] loss: 0.130\n",
      "[119, 120] loss: 0.132\n",
      "[119, 180] loss: 0.130\n",
      "[119, 240] loss: 0.127\n",
      "[119, 300] loss: 0.137\n",
      "[119, 360] loss: 0.133\n",
      "Epoch: 119 -> Loss: 0.136474281549\n",
      "Epoch: 119 -> Test Accuracy: 90.315\n",
      "[120, 60] loss: 0.121\n",
      "[120, 120] loss: 0.132\n",
      "[120, 180] loss: 0.125\n",
      "[120, 240] loss: 0.141\n",
      "[120, 300] loss: 0.133\n",
      "[120, 360] loss: 0.128\n",
      "Epoch: 120 -> Loss: 0.0627753213048\n",
      "Epoch: 120 -> Test Accuracy: 90.1825\n",
      "[121, 60] loss: 0.096\n",
      "[121, 120] loss: 0.081\n",
      "[121, 180] loss: 0.072\n",
      "[121, 240] loss: 0.071\n",
      "[121, 300] loss: 0.069\n",
      "[121, 360] loss: 0.075\n",
      "Epoch: 121 -> Loss: 0.0725773051381\n",
      "Epoch: 121 -> Test Accuracy: 92.2175\n",
      "[122, 60] loss: 0.064\n",
      "[122, 120] loss: 0.059\n",
      "[122, 180] loss: 0.062\n",
      "[122, 240] loss: 0.062\n",
      "[122, 300] loss: 0.055\n",
      "[122, 360] loss: 0.059\n",
      "Epoch: 122 -> Loss: 0.0669576302171\n",
      "Epoch: 122 -> Test Accuracy: 92.225\n",
      "[123, 60] loss: 0.053\n",
      "[123, 120] loss: 0.055\n",
      "[123, 180] loss: 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123, 240] loss: 0.050\n",
      "[123, 300] loss: 0.053\n",
      "[123, 360] loss: 0.053\n",
      "Epoch: 123 -> Loss: 0.0238902159035\n",
      "Epoch: 123 -> Test Accuracy: 92.405\n",
      "[124, 60] loss: 0.047\n",
      "[124, 120] loss: 0.048\n",
      "[124, 180] loss: 0.047\n",
      "[124, 240] loss: 0.051\n",
      "[124, 300] loss: 0.050\n",
      "[124, 360] loss: 0.052\n",
      "Epoch: 124 -> Loss: 0.0751750022173\n",
      "Epoch: 124 -> Test Accuracy: 92.46\n",
      "[125, 60] loss: 0.043\n",
      "[125, 120] loss: 0.044\n",
      "[125, 180] loss: 0.046\n",
      "[125, 240] loss: 0.046\n",
      "[125, 300] loss: 0.050\n",
      "[125, 360] loss: 0.045\n",
      "Epoch: 125 -> Loss: 0.0497423000634\n",
      "Epoch: 125 -> Test Accuracy: 92.345\n",
      "[126, 60] loss: 0.039\n",
      "[126, 120] loss: 0.044\n",
      "[126, 180] loss: 0.041\n",
      "[126, 240] loss: 0.044\n",
      "[126, 300] loss: 0.045\n",
      "[126, 360] loss: 0.044\n",
      "Epoch: 126 -> Loss: 0.0285705067217\n",
      "Epoch: 126 -> Test Accuracy: 92.0975\n",
      "[127, 60] loss: 0.040\n",
      "[127, 120] loss: 0.041\n",
      "[127, 180] loss: 0.038\n",
      "[127, 240] loss: 0.040\n",
      "[127, 300] loss: 0.042\n",
      "[127, 360] loss: 0.044\n",
      "Epoch: 127 -> Loss: 0.0293492916971\n",
      "Epoch: 127 -> Test Accuracy: 92.2325\n",
      "[128, 60] loss: 0.038\n",
      "[128, 120] loss: 0.039\n",
      "[128, 180] loss: 0.036\n",
      "[128, 240] loss: 0.039\n",
      "[128, 300] loss: 0.037\n",
      "[128, 360] loss: 0.041\n",
      "Epoch: 128 -> Loss: 0.0484538264573\n",
      "Epoch: 128 -> Test Accuracy: 92.2175\n",
      "[129, 60] loss: 0.038\n",
      "[129, 120] loss: 0.038\n",
      "[129, 180] loss: 0.038\n",
      "[129, 240] loss: 0.037\n",
      "[129, 300] loss: 0.038\n",
      "[129, 360] loss: 0.038\n",
      "Epoch: 129 -> Loss: 0.0514101460576\n",
      "Epoch: 129 -> Test Accuracy: 92.2875\n",
      "[130, 60] loss: 0.036\n",
      "[130, 120] loss: 0.038\n",
      "[130, 180] loss: 0.032\n",
      "[130, 240] loss: 0.037\n",
      "[130, 300] loss: 0.037\n",
      "[130, 360] loss: 0.037\n",
      "Epoch: 130 -> Loss: 0.0424250736833\n",
      "Epoch: 130 -> Test Accuracy: 92.1325\n",
      "[131, 60] loss: 0.032\n",
      "[131, 120] loss: 0.034\n",
      "[131, 180] loss: 0.034\n",
      "[131, 240] loss: 0.033\n",
      "[131, 300] loss: 0.033\n",
      "[131, 360] loss: 0.033\n",
      "Epoch: 131 -> Loss: 0.0391034409404\n",
      "Epoch: 131 -> Test Accuracy: 92.2525\n",
      "[132, 60] loss: 0.033\n",
      "[132, 120] loss: 0.033\n",
      "[132, 180] loss: 0.035\n",
      "[132, 240] loss: 0.036\n",
      "[132, 300] loss: 0.032\n",
      "[132, 360] loss: 0.036\n",
      "Epoch: 132 -> Loss: 0.0384169593453\n",
      "Epoch: 132 -> Test Accuracy: 92.165\n",
      "[133, 60] loss: 0.029\n",
      "[133, 120] loss: 0.030\n",
      "[133, 180] loss: 0.031\n",
      "[133, 240] loss: 0.031\n",
      "[133, 300] loss: 0.032\n",
      "[133, 360] loss: 0.037\n",
      "Epoch: 133 -> Loss: 0.014396908693\n",
      "Epoch: 133 -> Test Accuracy: 92.16\n",
      "[134, 60] loss: 0.033\n",
      "[134, 120] loss: 0.031\n",
      "[134, 180] loss: 0.032\n",
      "[134, 240] loss: 0.033\n",
      "[134, 300] loss: 0.033\n",
      "[134, 360] loss: 0.033\n",
      "Epoch: 134 -> Loss: 0.0565491244197\n",
      "Epoch: 134 -> Test Accuracy: 92.0725\n",
      "[135, 60] loss: 0.030\n",
      "[135, 120] loss: 0.029\n",
      "[135, 180] loss: 0.031\n",
      "[135, 240] loss: 0.031\n",
      "[135, 300] loss: 0.030\n",
      "[135, 360] loss: 0.031\n",
      "Epoch: 135 -> Loss: 0.0157452970743\n",
      "Epoch: 135 -> Test Accuracy: 92.22\n",
      "[136, 60] loss: 0.030\n",
      "[136, 120] loss: 0.031\n",
      "[136, 180] loss: 0.029\n",
      "[136, 240] loss: 0.030\n",
      "[136, 300] loss: 0.030\n",
      "[136, 360] loss: 0.029\n",
      "Epoch: 136 -> Loss: 0.0522452518344\n",
      "Epoch: 136 -> Test Accuracy: 92.26\n",
      "[137, 60] loss: 0.028\n",
      "[137, 120] loss: 0.027\n",
      "[137, 180] loss: 0.029\n",
      "[137, 240] loss: 0.031\n",
      "[137, 300] loss: 0.031\n",
      "[137, 360] loss: 0.032\n",
      "Epoch: 137 -> Loss: 0.0168153364211\n",
      "Epoch: 137 -> Test Accuracy: 92.0925\n",
      "[138, 60] loss: 0.026\n",
      "[138, 120] loss: 0.025\n",
      "[138, 180] loss: 0.028\n",
      "[138, 240] loss: 0.032\n",
      "[138, 300] loss: 0.029\n",
      "[138, 360] loss: 0.029\n",
      "Epoch: 138 -> Loss: 0.0144899655133\n",
      "Epoch: 138 -> Test Accuracy: 92.1325\n",
      "[139, 60] loss: 0.030\n",
      "[139, 120] loss: 0.030\n",
      "[139, 180] loss: 0.028\n",
      "[139, 240] loss: 0.029\n",
      "[139, 300] loss: 0.029\n",
      "[139, 360] loss: 0.029\n",
      "Epoch: 139 -> Loss: 0.0294731017202\n",
      "Epoch: 139 -> Test Accuracy: 92.0575\n",
      "[140, 60] loss: 0.028\n",
      "[140, 120] loss: 0.027\n",
      "[140, 180] loss: 0.025\n",
      "[140, 240] loss: 0.030\n",
      "[140, 300] loss: 0.029\n",
      "[140, 360] loss: 0.030\n",
      "Epoch: 140 -> Loss: 0.0386446416378\n",
      "Epoch: 140 -> Test Accuracy: 92.1675\n",
      "[141, 60] loss: 0.026\n",
      "[141, 120] loss: 0.026\n",
      "[141, 180] loss: 0.027\n",
      "[141, 240] loss: 0.029\n",
      "[141, 300] loss: 0.025\n",
      "[141, 360] loss: 0.026\n",
      "Epoch: 141 -> Loss: 0.0462640114129\n",
      "Epoch: 141 -> Test Accuracy: 92.0175\n",
      "[142, 60] loss: 0.024\n",
      "[142, 120] loss: 0.026\n",
      "[142, 180] loss: 0.023\n",
      "[142, 240] loss: 0.026\n",
      "[142, 300] loss: 0.028\n",
      "[142, 360] loss: 0.027\n",
      "Epoch: 142 -> Loss: 0.0198109000921\n",
      "Epoch: 142 -> Test Accuracy: 92.19\n",
      "[143, 60] loss: 0.025\n",
      "[143, 120] loss: 0.026\n",
      "[143, 180] loss: 0.029\n",
      "[143, 240] loss: 0.028\n",
      "[143, 300] loss: 0.026\n",
      "[143, 360] loss: 0.027\n",
      "Epoch: 143 -> Loss: 0.0327403433621\n",
      "Epoch: 143 -> Test Accuracy: 92.03\n",
      "[144, 60] loss: 0.024\n",
      "[144, 120] loss: 0.026\n",
      "[144, 180] loss: 0.027\n",
      "[144, 240] loss: 0.025\n",
      "[144, 300] loss: 0.027\n",
      "[144, 360] loss: 0.027\n",
      "Epoch: 144 -> Loss: 0.0148653211072\n",
      "Epoch: 144 -> Test Accuracy: 91.95\n",
      "[145, 60] loss: 0.024\n",
      "[145, 120] loss: 0.023\n",
      "[145, 180] loss: 0.024\n",
      "[145, 240] loss: 0.026\n",
      "[145, 300] loss: 0.024\n",
      "[145, 360] loss: 0.028\n",
      "Epoch: 145 -> Loss: 0.0257855504751\n",
      "Epoch: 145 -> Test Accuracy: 92.075\n",
      "[146, 60] loss: 0.025\n",
      "[146, 120] loss: 0.025\n",
      "[146, 180] loss: 0.024\n",
      "[146, 240] loss: 0.025\n",
      "[146, 300] loss: 0.026\n",
      "[146, 360] loss: 0.024\n",
      "Epoch: 146 -> Loss: 0.0358236059546\n",
      "Epoch: 146 -> Test Accuracy: 92.0125\n",
      "[147, 60] loss: 0.025\n",
      "[147, 120] loss: 0.023\n",
      "[147, 180] loss: 0.025\n",
      "[147, 240] loss: 0.026\n",
      "[147, 300] loss: 0.026\n",
      "[147, 360] loss: 0.028\n",
      "Epoch: 147 -> Loss: 0.0306266844273\n",
      "Epoch: 147 -> Test Accuracy: 91.9525\n",
      "[148, 60] loss: 0.023\n",
      "[148, 120] loss: 0.023\n",
      "[148, 180] loss: 0.025\n",
      "[148, 240] loss: 0.023\n",
      "[148, 300] loss: 0.029\n",
      "[148, 360] loss: 0.027\n",
      "Epoch: 148 -> Loss: 0.0236614309251\n",
      "Epoch: 148 -> Test Accuracy: 92.1275\n",
      "[149, 60] loss: 0.025\n",
      "[149, 120] loss: 0.023\n",
      "[149, 180] loss: 0.024\n",
      "[149, 240] loss: 0.025\n",
      "[149, 300] loss: 0.028\n",
      "[149, 360] loss: 0.027\n",
      "Epoch: 149 -> Loss: 0.013561449945\n",
      "Epoch: 149 -> Test Accuracy: 91.935\n",
      "[150, 60] loss: 0.024\n",
      "[150, 120] loss: 0.024\n",
      "[150, 180] loss: 0.025\n",
      "[150, 240] loss: 0.025\n",
      "[150, 300] loss: 0.026\n",
      "[150, 360] loss: 0.025\n",
      "Epoch: 150 -> Loss: 0.0366351529956\n",
      "Epoch: 150 -> Test Accuracy: 92.0575\n",
      "[151, 60] loss: 0.022\n",
      "[151, 120] loss: 0.024\n",
      "[151, 180] loss: 0.023\n",
      "[151, 240] loss: 0.025\n",
      "[151, 300] loss: 0.025\n",
      "[151, 360] loss: 0.027\n",
      "Epoch: 151 -> Loss: 0.0221746247262\n",
      "Epoch: 151 -> Test Accuracy: 92.03\n",
      "[152, 60] loss: 0.022\n",
      "[152, 120] loss: 0.024\n",
      "[152, 180] loss: 0.025\n",
      "[152, 240] loss: 0.022\n",
      "[152, 300] loss: 0.026\n",
      "[152, 360] loss: 0.024\n",
      "Epoch: 152 -> Loss: 0.0234043058008\n",
      "Epoch: 152 -> Test Accuracy: 91.7625\n",
      "[153, 60] loss: 0.023\n",
      "[153, 120] loss: 0.022\n",
      "[153, 180] loss: 0.023\n",
      "[153, 240] loss: 0.025\n",
      "[153, 300] loss: 0.023\n",
      "[153, 360] loss: 0.026\n",
      "Epoch: 153 -> Loss: 0.0341323800385\n",
      "Epoch: 153 -> Test Accuracy: 91.845\n",
      "[154, 60] loss: 0.023\n",
      "[154, 120] loss: 0.023\n",
      "[154, 180] loss: 0.024\n",
      "[154, 240] loss: 0.025\n",
      "[154, 300] loss: 0.024\n",
      "[154, 360] loss: 0.024\n",
      "Epoch: 154 -> Loss: 0.0257519632578\n",
      "Epoch: 154 -> Test Accuracy: 91.755\n",
      "[155, 60] loss: 0.022\n",
      "[155, 120] loss: 0.023\n",
      "[155, 180] loss: 0.026\n",
      "[155, 240] loss: 0.024\n",
      "[155, 300] loss: 0.025\n",
      "[155, 360] loss: 0.026\n",
      "Epoch: 155 -> Loss: 0.0171002503484\n",
      "Epoch: 155 -> Test Accuracy: 91.93\n",
      "[156, 60] loss: 0.021\n",
      "[156, 120] loss: 0.021\n",
      "[156, 180] loss: 0.024\n",
      "[156, 240] loss: 0.024\n",
      "[156, 300] loss: 0.023\n",
      "[156, 360] loss: 0.026\n",
      "Epoch: 156 -> Loss: 0.0187948737293\n",
      "Epoch: 156 -> Test Accuracy: 91.6375\n",
      "[157, 60] loss: 0.021\n",
      "[157, 120] loss: 0.022\n",
      "[157, 180] loss: 0.023\n",
      "[157, 240] loss: 0.022\n",
      "[157, 300] loss: 0.025\n",
      "[157, 360] loss: 0.025\n",
      "Epoch: 157 -> Loss: 0.0213442686945\n",
      "Epoch: 157 -> Test Accuracy: 91.82\n",
      "[158, 60] loss: 0.025\n",
      "[158, 120] loss: 0.025\n",
      "[158, 180] loss: 0.025\n",
      "[158, 240] loss: 0.026\n",
      "[158, 300] loss: 0.025\n",
      "[158, 360] loss: 0.028\n",
      "Epoch: 158 -> Loss: 0.0364259406924\n",
      "Epoch: 158 -> Test Accuracy: 92.09\n",
      "[159, 60] loss: 0.023\n",
      "[159, 120] loss: 0.025\n",
      "[159, 180] loss: 0.024\n",
      "[159, 240] loss: 0.023\n",
      "[159, 300] loss: 0.024\n",
      "[159, 360] loss: 0.026\n",
      "Epoch: 159 -> Loss: 0.0178028680384\n",
      "Epoch: 159 -> Test Accuracy: 91.6875\n",
      "[160, 60] loss: 0.024\n",
      "[160, 120] loss: 0.023\n",
      "[160, 180] loss: 0.023\n",
      "[160, 240] loss: 0.025\n",
      "[160, 300] loss: 0.027\n",
      "[160, 360] loss: 0.026\n",
      "Epoch: 160 -> Loss: 0.0754204690456\n",
      "Epoch: 160 -> Test Accuracy: 91.7\n",
      "[161, 60] loss: 0.021\n",
      "[161, 120] loss: 0.019\n",
      "[161, 180] loss: 0.019\n",
      "[161, 240] loss: 0.017\n",
      "[161, 300] loss: 0.017\n",
      "[161, 360] loss: 0.016\n",
      "Epoch: 161 -> Loss: 0.0247515030205\n",
      "Epoch: 161 -> Test Accuracy: 92.1075\n",
      "[162, 60] loss: 0.013\n",
      "[162, 120] loss: 0.015\n",
      "[162, 180] loss: 0.016\n",
      "[162, 240] loss: 0.015\n",
      "[162, 300] loss: 0.015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[162, 360] loss: 0.014\n",
      "Epoch: 162 -> Loss: 0.0142389312387\n",
      "Epoch: 162 -> Test Accuracy: 92.19\n",
      "[163, 60] loss: 0.014\n",
      "[163, 120] loss: 0.014\n",
      "[163, 180] loss: 0.014\n",
      "[163, 240] loss: 0.014\n",
      "[163, 300] loss: 0.015\n",
      "[163, 360] loss: 0.013\n",
      "Epoch: 163 -> Loss: 0.0101729640737\n",
      "Epoch: 163 -> Test Accuracy: 92.195\n",
      "[164, 60] loss: 0.013\n",
      "[164, 120] loss: 0.013\n",
      "[164, 180] loss: 0.013\n",
      "[164, 240] loss: 0.013\n",
      "[164, 300] loss: 0.013\n",
      "[164, 360] loss: 0.014\n",
      "Epoch: 164 -> Loss: 0.0181327145547\n",
      "Epoch: 164 -> Test Accuracy: 92.16\n",
      "[165, 60] loss: 0.013\n",
      "[165, 120] loss: 0.013\n",
      "[165, 180] loss: 0.013\n",
      "[165, 240] loss: 0.012\n",
      "[165, 300] loss: 0.012\n",
      "[165, 360] loss: 0.013\n",
      "Epoch: 165 -> Loss: 0.00228249793872\n",
      "Epoch: 165 -> Test Accuracy: 92.2325\n",
      "[166, 60] loss: 0.013\n",
      "[166, 120] loss: 0.012\n",
      "[166, 180] loss: 0.012\n",
      "[166, 240] loss: 0.013\n",
      "[166, 300] loss: 0.013\n",
      "[166, 360] loss: 0.012\n",
      "Epoch: 166 -> Loss: 0.00735792284831\n",
      "Epoch: 166 -> Test Accuracy: 92.18\n",
      "[167, 60] loss: 0.012\n",
      "[167, 120] loss: 0.011\n",
      "[167, 180] loss: 0.013\n",
      "[167, 240] loss: 0.012\n",
      "[167, 300] loss: 0.013\n",
      "[167, 360] loss: 0.012\n",
      "Epoch: 167 -> Loss: 0.00716293137521\n",
      "Epoch: 167 -> Test Accuracy: 92.15\n",
      "[168, 60] loss: 0.012\n",
      "[168, 120] loss: 0.010\n",
      "[168, 180] loss: 0.012\n",
      "[168, 240] loss: 0.012\n",
      "[168, 300] loss: 0.012\n",
      "[168, 360] loss: 0.013\n",
      "Epoch: 168 -> Loss: 0.0218465216458\n",
      "Epoch: 168 -> Test Accuracy: 92.205\n",
      "[169, 60] loss: 0.012\n",
      "[169, 120] loss: 0.010\n",
      "[169, 180] loss: 0.011\n",
      "[169, 240] loss: 0.012\n",
      "[169, 300] loss: 0.011\n",
      "[169, 360] loss: 0.011\n",
      "Epoch: 169 -> Loss: 0.0141726005822\n",
      "Epoch: 169 -> Test Accuracy: 92.3075\n",
      "[170, 60] loss: 0.012\n",
      "[170, 120] loss: 0.012\n",
      "[170, 180] loss: 0.012\n",
      "[170, 240] loss: 0.011\n",
      "[170, 300] loss: 0.012\n",
      "[170, 360] loss: 0.011\n",
      "Epoch: 170 -> Loss: 0.0133976582438\n",
      "Epoch: 170 -> Test Accuracy: 92.21\n",
      "[171, 60] loss: 0.011\n",
      "[171, 120] loss: 0.011\n",
      "[171, 180] loss: 0.012\n",
      "[171, 240] loss: 0.011\n",
      "[171, 300] loss: 0.011\n",
      "[171, 360] loss: 0.012\n",
      "Epoch: 171 -> Loss: 0.0172377824783\n",
      "Epoch: 171 -> Test Accuracy: 92.2825\n",
      "[172, 60] loss: 0.010\n",
      "[172, 120] loss: 0.011\n",
      "[172, 180] loss: 0.011\n",
      "[172, 240] loss: 0.011\n",
      "[172, 300] loss: 0.011\n",
      "[172, 360] loss: 0.012\n",
      "Epoch: 172 -> Loss: 0.00986809376627\n",
      "Epoch: 172 -> Test Accuracy: 92.2425\n",
      "[173, 60] loss: 0.010\n",
      "[173, 120] loss: 0.010\n",
      "[173, 180] loss: 0.011\n",
      "[173, 240] loss: 0.012\n",
      "[173, 300] loss: 0.010\n",
      "[173, 360] loss: 0.011\n",
      "Epoch: 173 -> Loss: 0.0149984331802\n",
      "Epoch: 173 -> Test Accuracy: 92.2925\n",
      "[174, 60] loss: 0.011\n",
      "[174, 120] loss: 0.011\n",
      "[174, 180] loss: 0.011\n",
      "[174, 240] loss: 0.011\n",
      "[174, 300] loss: 0.010\n",
      "[174, 360] loss: 0.011\n",
      "Epoch: 174 -> Loss: 0.00998050533235\n",
      "Epoch: 174 -> Test Accuracy: 92.2625\n",
      "[175, 60] loss: 0.010\n",
      "[175, 120] loss: 0.011\n",
      "[175, 180] loss: 0.012\n",
      "[175, 240] loss: 0.011\n",
      "[175, 300] loss: 0.010\n",
      "[175, 360] loss: 0.010\n",
      "Epoch: 175 -> Loss: 0.0101813357323\n",
      "Epoch: 175 -> Test Accuracy: 92.215\n",
      "[176, 60] loss: 0.010\n",
      "[176, 120] loss: 0.010\n",
      "[176, 180] loss: 0.011\n",
      "[176, 240] loss: 0.011\n",
      "[176, 300] loss: 0.010\n",
      "[176, 360] loss: 0.011\n",
      "Epoch: 176 -> Loss: 0.011940584518\n",
      "Epoch: 176 -> Test Accuracy: 92.2125\n",
      "[177, 60] loss: 0.010\n",
      "[177, 120] loss: 0.011\n",
      "[177, 180] loss: 0.010\n",
      "[177, 240] loss: 0.011\n",
      "[177, 300] loss: 0.010\n",
      "[177, 360] loss: 0.010\n",
      "Epoch: 177 -> Loss: 0.00595696875826\n",
      "Epoch: 177 -> Test Accuracy: 92.25\n",
      "[178, 60] loss: 0.011\n",
      "[178, 120] loss: 0.011\n",
      "[178, 180] loss: 0.010\n",
      "[178, 240] loss: 0.010\n",
      "[178, 300] loss: 0.010\n",
      "[178, 360] loss: 0.010\n",
      "Epoch: 178 -> Loss: 0.00822608359158\n",
      "Epoch: 178 -> Test Accuracy: 92.2025\n",
      "[179, 60] loss: 0.010\n",
      "[179, 120] loss: 0.010\n",
      "[179, 180] loss: 0.010\n",
      "[179, 240] loss: 0.011\n",
      "[179, 300] loss: 0.010\n",
      "[179, 360] loss: 0.010\n",
      "Epoch: 179 -> Loss: 0.00978438556194\n",
      "Epoch: 179 -> Test Accuracy: 92.21\n",
      "[180, 60] loss: 0.010\n",
      "[180, 120] loss: 0.010\n",
      "[180, 180] loss: 0.010\n",
      "[180, 240] loss: 0.010\n",
      "[180, 300] loss: 0.011\n",
      "[180, 360] loss: 0.010\n",
      "Epoch: 180 -> Loss: 0.00779106328264\n",
      "Epoch: 180 -> Test Accuracy: 92.2375\n",
      "[181, 60] loss: 0.010\n",
      "[181, 120] loss: 0.010\n",
      "[181, 180] loss: 0.011\n",
      "[181, 240] loss: 0.010\n",
      "[181, 300] loss: 0.010\n",
      "[181, 360] loss: 0.010\n",
      "Epoch: 181 -> Loss: 0.00954251550138\n",
      "Epoch: 181 -> Test Accuracy: 92.25\n",
      "[182, 60] loss: 0.010\n",
      "[182, 120] loss: 0.010\n",
      "[182, 180] loss: 0.011\n",
      "[182, 240] loss: 0.010\n",
      "[182, 300] loss: 0.010\n",
      "[182, 360] loss: 0.011\n",
      "Epoch: 182 -> Loss: 0.00503360107541\n",
      "Epoch: 182 -> Test Accuracy: 92.2475\n",
      "[183, 60] loss: 0.011\n",
      "[183, 120] loss: 0.010\n",
      "[183, 180] loss: 0.009\n",
      "[183, 240] loss: 0.010\n",
      "[183, 300] loss: 0.011\n",
      "[183, 360] loss: 0.011\n",
      "Epoch: 183 -> Loss: 0.0226580798626\n",
      "Epoch: 183 -> Test Accuracy: 92.21\n",
      "[184, 60] loss: 0.009\n",
      "[184, 120] loss: 0.010\n",
      "[184, 180] loss: 0.010\n",
      "[184, 240] loss: 0.010\n",
      "[184, 300] loss: 0.009\n",
      "[184, 360] loss: 0.010\n",
      "Epoch: 184 -> Loss: 0.0174920354038\n",
      "Epoch: 184 -> Test Accuracy: 92.275\n",
      "[185, 60] loss: 0.010\n",
      "[185, 120] loss: 0.009\n",
      "[185, 180] loss: 0.010\n",
      "[185, 240] loss: 0.010\n",
      "[185, 300] loss: 0.010\n",
      "[185, 360] loss: 0.010\n",
      "Epoch: 185 -> Loss: 0.00887467432767\n",
      "Epoch: 185 -> Test Accuracy: 92.2\n",
      "[186, 60] loss: 0.009\n",
      "[186, 120] loss: 0.009\n",
      "[186, 180] loss: 0.010\n",
      "[186, 240] loss: 0.010\n",
      "[186, 300] loss: 0.010\n",
      "[186, 360] loss: 0.011\n",
      "Epoch: 186 -> Loss: 0.0100764958188\n",
      "Epoch: 186 -> Test Accuracy: 92.2775\n",
      "[187, 60] loss: 0.009\n",
      "[187, 120] loss: 0.009\n",
      "[187, 180] loss: 0.010\n",
      "[187, 240] loss: 0.010\n",
      "[187, 300] loss: 0.010\n",
      "[187, 360] loss: 0.010\n",
      "Epoch: 187 -> Loss: 0.00767189497128\n",
      "Epoch: 187 -> Test Accuracy: 92.2925\n",
      "[188, 60] loss: 0.009\n",
      "[188, 120] loss: 0.011\n",
      "[188, 180] loss: 0.009\n",
      "[188, 240] loss: 0.009\n",
      "[188, 300] loss: 0.009\n",
      "[188, 360] loss: 0.010\n",
      "Epoch: 188 -> Loss: 0.0170344524086\n",
      "Epoch: 188 -> Test Accuracy: 92.23\n",
      "[189, 60] loss: 0.009\n",
      "[189, 120] loss: 0.009\n",
      "[189, 180] loss: 0.010\n",
      "[189, 240] loss: 0.010\n",
      "[189, 300] loss: 0.010\n",
      "[189, 360] loss: 0.010\n",
      "Epoch: 189 -> Loss: 0.0175261907279\n",
      "Epoch: 189 -> Test Accuracy: 92.2\n",
      "[190, 60] loss: 0.010\n",
      "[190, 120] loss: 0.010\n",
      "[190, 180] loss: 0.009\n",
      "[190, 240] loss: 0.009\n",
      "[190, 300] loss: 0.009\n",
      "[190, 360] loss: 0.010\n",
      "Epoch: 190 -> Loss: 0.0128434095532\n",
      "Epoch: 190 -> Test Accuracy: 92.21\n",
      "[191, 60] loss: 0.010\n",
      "[191, 120] loss: 0.010\n",
      "[191, 180] loss: 0.009\n",
      "[191, 240] loss: 0.010\n",
      "[191, 300] loss: 0.010\n",
      "[191, 360] loss: 0.009\n",
      "Epoch: 191 -> Loss: 0.0104228034616\n",
      "Epoch: 191 -> Test Accuracy: 92.185\n",
      "[192, 60] loss: 0.010\n",
      "[192, 120] loss: 0.010\n",
      "[192, 180] loss: 0.010\n",
      "[192, 240] loss: 0.010\n",
      "[192, 300] loss: 0.010\n",
      "[192, 360] loss: 0.009\n",
      "Epoch: 192 -> Loss: 0.00403060019016\n",
      "Epoch: 192 -> Test Accuracy: 92.1775\n",
      "[193, 60] loss: 0.009\n",
      "[193, 120] loss: 0.010\n",
      "[193, 180] loss: 0.010\n",
      "[193, 240] loss: 0.009\n",
      "[193, 300] loss: 0.009\n",
      "[193, 360] loss: 0.009\n",
      "Epoch: 193 -> Loss: 0.0098797082901\n",
      "Epoch: 193 -> Test Accuracy: 92.1575\n",
      "[194, 60] loss: 0.009\n",
      "[194, 120] loss: 0.009\n",
      "[194, 180] loss: 0.010\n",
      "[194, 240] loss: 0.010\n",
      "[194, 300] loss: 0.009\n",
      "[194, 360] loss: 0.010\n",
      "Epoch: 194 -> Loss: 0.00674241501838\n",
      "Epoch: 194 -> Test Accuracy: 92.1775\n",
      "[195, 60] loss: 0.010\n",
      "[195, 120] loss: 0.009\n",
      "[195, 180] loss: 0.009\n",
      "[195, 240] loss: 0.010\n",
      "[195, 300] loss: 0.009\n",
      "[195, 360] loss: 0.009\n",
      "Epoch: 195 -> Loss: 0.00723540503532\n",
      "Epoch: 195 -> Test Accuracy: 92.145\n",
      "[196, 60] loss: 0.009\n",
      "[196, 120] loss: 0.009\n",
      "[196, 180] loss: 0.009\n",
      "[196, 240] loss: 0.009\n",
      "[196, 300] loss: 0.010\n",
      "[196, 360] loss: 0.010\n",
      "Epoch: 196 -> Loss: 0.00891743786633\n",
      "Epoch: 196 -> Test Accuracy: 92.1725\n",
      "[197, 60] loss: 0.009\n",
      "[197, 120] loss: 0.009\n",
      "[197, 180] loss: 0.009\n",
      "[197, 240] loss: 0.010\n",
      "[197, 300] loss: 0.009\n",
      "[197, 360] loss: 0.010\n",
      "Epoch: 197 -> Loss: 0.0150486528873\n",
      "Epoch: 197 -> Test Accuracy: 92.1625\n",
      "[198, 60] loss: 0.008\n",
      "[198, 120] loss: 0.009\n",
      "[198, 180] loss: 0.009\n",
      "[198, 240] loss: 0.010\n",
      "[198, 300] loss: 0.009\n",
      "[198, 360] loss: 0.009\n",
      "Epoch: 198 -> Loss: 0.00717498268932\n",
      "Epoch: 198 -> Test Accuracy: 92.175\n",
      "[199, 60] loss: 0.009\n",
      "[199, 120] loss: 0.009\n",
      "[199, 180] loss: 0.009\n",
      "[199, 240] loss: 0.010\n",
      "[199, 300] loss: 0.009\n",
      "[199, 360] loss: 0.010\n",
      "Epoch: 199 -> Loss: 0.00609672721475\n",
      "Epoch: 199 -> Test Accuracy: 92.165\n",
      "[200, 60] loss: 0.009\n",
      "[200, 120] loss: 0.009\n",
      "[200, 180] loss: 0.009\n",
      "[200, 240] loss: 0.010\n",
      "[200, 300] loss: 0.009\n",
      "[200, 360] loss: 0.009\n",
      "Epoch: 200 -> Loss: 0.00567238777876\n",
      "Epoch: 200 -> Test Accuracy: 92.19\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "rot_block3_loss_log, _, rot_block3_test_accuracy_log, _, _ = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], \n",
    "    [60, 120, 160, 200], 0.9, 5e-4, net_block3, criterion, trainloader, None, testloader, rot=['90', '180', '270'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 2.135\n",
      "[1, 120] loss: 1.237\n",
      "[1, 180] loss: 1.118\n",
      "[1, 240] loss: 1.054\n",
      "[1, 300] loss: 1.027\n",
      "[1, 360] loss: 0.987\n",
      "Epoch: 1 -> Loss: 1.02406382561\n",
      "Epoch: 1 -> Test Accuracy: 68.73\n",
      "[2, 60] loss: 0.908\n",
      "[2, 120] loss: 0.900\n",
      "[2, 180] loss: 0.892\n",
      "[2, 240] loss: 0.870\n",
      "[2, 300] loss: 0.870\n",
      "[2, 360] loss: 0.830\n",
      "Epoch: 2 -> Loss: 0.819397449493\n",
      "Epoch: 2 -> Test Accuracy: 72.48\n",
      "[3, 60] loss: 0.808\n",
      "[3, 120] loss: 0.809\n",
      "[3, 180] loss: 0.789\n",
      "[3, 240] loss: 0.807\n",
      "[3, 300] loss: 0.777\n",
      "[3, 360] loss: 0.760\n",
      "Epoch: 3 -> Loss: 0.705734670162\n",
      "Epoch: 3 -> Test Accuracy: 74.34\n",
      "[4, 60] loss: 0.757\n",
      "[4, 120] loss: 0.763\n",
      "[4, 180] loss: 0.744\n",
      "[4, 240] loss: 0.729\n",
      "[4, 300] loss: 0.732\n",
      "[4, 360] loss: 0.722\n",
      "Epoch: 4 -> Loss: 0.572060704231\n",
      "Epoch: 4 -> Test Accuracy: 75.96\n",
      "[5, 60] loss: 0.705\n",
      "[5, 120] loss: 0.700\n",
      "[5, 180] loss: 0.710\n",
      "[5, 240] loss: 0.693\n",
      "[5, 300] loss: 0.706\n",
      "[5, 360] loss: 0.720\n",
      "Epoch: 5 -> Loss: 0.530122101307\n",
      "Epoch: 5 -> Test Accuracy: 76.62\n",
      "[6, 60] loss: 0.681\n",
      "[6, 120] loss: 0.698\n",
      "[6, 180] loss: 0.682\n",
      "[6, 240] loss: 0.688\n",
      "[6, 300] loss: 0.689\n",
      "[6, 360] loss: 0.684\n",
      "Epoch: 6 -> Loss: 0.762083053589\n",
      "Epoch: 6 -> Test Accuracy: 77.13\n",
      "[7, 60] loss: 0.647\n",
      "[7, 120] loss: 0.658\n",
      "[7, 180] loss: 0.682\n",
      "[7, 240] loss: 0.670\n",
      "[7, 300] loss: 0.683\n",
      "[7, 360] loss: 0.668\n",
      "Epoch: 7 -> Loss: 0.561828672886\n",
      "Epoch: 7 -> Test Accuracy: 76.95\n",
      "[8, 60] loss: 0.643\n",
      "[8, 120] loss: 0.646\n",
      "[8, 180] loss: 0.652\n",
      "[8, 240] loss: 0.667\n",
      "[8, 300] loss: 0.651\n",
      "[8, 360] loss: 0.660\n",
      "Epoch: 8 -> Loss: 0.631638646126\n",
      "Epoch: 8 -> Test Accuracy: 77.92\n",
      "[9, 60] loss: 0.617\n",
      "[9, 120] loss: 0.627\n",
      "[9, 180] loss: 0.632\n",
      "[9, 240] loss: 0.663\n",
      "[9, 300] loss: 0.652\n",
      "[9, 360] loss: 0.653\n",
      "Epoch: 9 -> Loss: 0.601558744907\n",
      "Epoch: 9 -> Test Accuracy: 77.99\n",
      "[10, 60] loss: 0.607\n",
      "[10, 120] loss: 0.628\n",
      "[10, 180] loss: 0.627\n",
      "[10, 240] loss: 0.632\n",
      "[10, 300] loss: 0.629\n",
      "[10, 360] loss: 0.639\n",
      "Epoch: 10 -> Loss: 0.69752061367\n",
      "Epoch: 10 -> Test Accuracy: 77.83\n",
      "[11, 60] loss: 0.615\n",
      "[11, 120] loss: 0.618\n",
      "[11, 180] loss: 0.613\n",
      "[11, 240] loss: 0.626\n",
      "[11, 300] loss: 0.623\n",
      "[11, 360] loss: 0.626\n",
      "Epoch: 11 -> Loss: 0.627347946167\n",
      "Epoch: 11 -> Test Accuracy: 78.23\n",
      "[12, 60] loss: 0.615\n",
      "[12, 120] loss: 0.603\n",
      "[12, 180] loss: 0.591\n",
      "[12, 240] loss: 0.627\n",
      "[12, 300] loss: 0.607\n",
      "[12, 360] loss: 0.641\n",
      "Epoch: 12 -> Loss: 0.440225422382\n",
      "Epoch: 12 -> Test Accuracy: 78.78\n",
      "[13, 60] loss: 0.601\n",
      "[13, 120] loss: 0.604\n",
      "[13, 180] loss: 0.606\n",
      "[13, 240] loss: 0.617\n",
      "[13, 300] loss: 0.617\n",
      "[13, 360] loss: 0.624\n",
      "Epoch: 13 -> Loss: 0.530610501766\n",
      "Epoch: 13 -> Test Accuracy: 78.81\n",
      "[14, 60] loss: 0.568\n",
      "[14, 120] loss: 0.587\n",
      "[14, 180] loss: 0.621\n",
      "[14, 240] loss: 0.614\n",
      "[14, 300] loss: 0.617\n",
      "[14, 360] loss: 0.612\n",
      "Epoch: 14 -> Loss: 0.864044070244\n",
      "Epoch: 14 -> Test Accuracy: 78.74\n",
      "[15, 60] loss: 0.597\n",
      "[15, 120] loss: 0.594\n",
      "[15, 180] loss: 0.586\n",
      "[15, 240] loss: 0.598\n",
      "[15, 300] loss: 0.578\n",
      "[15, 360] loss: 0.624\n",
      "Epoch: 15 -> Loss: 0.784435331821\n",
      "Epoch: 15 -> Test Accuracy: 78.56\n",
      "[16, 60] loss: 0.594\n",
      "[16, 120] loss: 0.591\n",
      "[16, 180] loss: 0.584\n",
      "[16, 240] loss: 0.606\n",
      "[16, 300] loss: 0.626\n",
      "[16, 360] loss: 0.591\n",
      "Epoch: 16 -> Loss: 0.565725684166\n",
      "Epoch: 16 -> Test Accuracy: 78.61\n",
      "[17, 60] loss: 0.573\n",
      "[17, 120] loss: 0.581\n",
      "[17, 180] loss: 0.611\n",
      "[17, 240] loss: 0.597\n",
      "[17, 300] loss: 0.590\n",
      "[17, 360] loss: 0.621\n",
      "Epoch: 17 -> Loss: 0.595977246761\n",
      "Epoch: 17 -> Test Accuracy: 78.18\n",
      "[18, 60] loss: 0.570\n",
      "[18, 120] loss: 0.588\n",
      "[18, 180] loss: 0.570\n",
      "[18, 240] loss: 0.595\n",
      "[18, 300] loss: 0.614\n",
      "[18, 360] loss: 0.604\n",
      "Epoch: 18 -> Loss: 0.599996745586\n",
      "Epoch: 18 -> Test Accuracy: 78.87\n",
      "[19, 60] loss: 0.558\n",
      "[19, 120] loss: 0.578\n",
      "[19, 180] loss: 0.579\n",
      "[19, 240] loss: 0.604\n",
      "[19, 300] loss: 0.611\n",
      "[19, 360] loss: 0.589\n",
      "Epoch: 19 -> Loss: 0.615851283073\n",
      "Epoch: 19 -> Test Accuracy: 78.81\n",
      "[20, 60] loss: 0.558\n",
      "[20, 120] loss: 0.579\n",
      "[20, 180] loss: 0.583\n",
      "[20, 240] loss: 0.590\n",
      "[20, 300] loss: 0.596\n",
      "[20, 360] loss: 0.610\n",
      "Epoch: 20 -> Loss: 0.605484127998\n",
      "Epoch: 20 -> Test Accuracy: 79.39\n",
      "[21, 60] loss: 0.538\n",
      "[21, 120] loss: 0.491\n",
      "[21, 180] loss: 0.480\n",
      "[21, 240] loss: 0.500\n",
      "[21, 300] loss: 0.482\n",
      "[21, 360] loss: 0.483\n",
      "Epoch: 21 -> Loss: 0.56816971302\n",
      "Epoch: 21 -> Test Accuracy: 81.5\n",
      "[22, 60] loss: 0.441\n",
      "[22, 120] loss: 0.454\n",
      "[22, 180] loss: 0.459\n",
      "[22, 240] loss: 0.450\n",
      "[22, 300] loss: 0.442\n",
      "[22, 360] loss: 0.451\n",
      "Epoch: 22 -> Loss: 0.40216255188\n",
      "Epoch: 22 -> Test Accuracy: 81.47\n",
      "[23, 60] loss: 0.421\n",
      "[23, 120] loss: 0.454\n",
      "[23, 180] loss: 0.422\n",
      "[23, 240] loss: 0.433\n",
      "[23, 300] loss: 0.426\n",
      "[23, 360] loss: 0.438\n",
      "Epoch: 23 -> Loss: 0.486105382442\n",
      "Epoch: 23 -> Test Accuracy: 82.19\n",
      "[24, 60] loss: 0.420\n",
      "[24, 120] loss: 0.432\n",
      "[24, 180] loss: 0.421\n",
      "[24, 240] loss: 0.428\n",
      "[24, 300] loss: 0.409\n",
      "[24, 360] loss: 0.417\n",
      "Epoch: 24 -> Loss: 0.365364342928\n",
      "Epoch: 24 -> Test Accuracy: 82.21\n",
      "[25, 60] loss: 0.403\n",
      "[25, 120] loss: 0.411\n",
      "[25, 180] loss: 0.400\n",
      "[25, 240] loss: 0.418\n",
      "[25, 300] loss: 0.423\n",
      "[25, 360] loss: 0.421\n",
      "Epoch: 25 -> Loss: 0.491146504879\n",
      "Epoch: 25 -> Test Accuracy: 82.11\n",
      "[26, 60] loss: 0.414\n",
      "[26, 120] loss: 0.407\n",
      "[26, 180] loss: 0.422\n",
      "[26, 240] loss: 0.406\n",
      "[26, 300] loss: 0.424\n",
      "[26, 360] loss: 0.397\n",
      "Epoch: 26 -> Loss: 0.56111395359\n",
      "Epoch: 26 -> Test Accuracy: 82.16\n",
      "[27, 60] loss: 0.391\n",
      "[27, 120] loss: 0.405\n",
      "[27, 180] loss: 0.395\n",
      "[27, 240] loss: 0.395\n",
      "[27, 300] loss: 0.404\n",
      "[27, 360] loss: 0.401\n",
      "Epoch: 27 -> Loss: 0.438163995743\n",
      "Epoch: 27 -> Test Accuracy: 82.31\n",
      "[28, 60] loss: 0.393\n",
      "[28, 120] loss: 0.385\n",
      "[28, 180] loss: 0.393\n",
      "[28, 240] loss: 0.382\n",
      "[28, 300] loss: 0.408\n",
      "[28, 360] loss: 0.407\n",
      "Epoch: 28 -> Loss: 0.282507956028\n",
      "Epoch: 28 -> Test Accuracy: 82.44\n",
      "[29, 60] loss: 0.390\n",
      "[29, 120] loss: 0.374\n",
      "[29, 180] loss: 0.378\n",
      "[29, 240] loss: 0.403\n",
      "[29, 300] loss: 0.394\n",
      "[29, 360] loss: 0.404\n",
      "Epoch: 29 -> Loss: 0.281484305859\n",
      "Epoch: 29 -> Test Accuracy: 82.13\n",
      "[30, 60] loss: 0.381\n",
      "[30, 120] loss: 0.370\n",
      "[30, 180] loss: 0.401\n",
      "[30, 240] loss: 0.381\n",
      "[30, 300] loss: 0.384\n",
      "[30, 360] loss: 0.404\n",
      "Epoch: 30 -> Loss: 0.277964651585\n",
      "Epoch: 30 -> Test Accuracy: 81.73\n",
      "[31, 60] loss: 0.382\n",
      "[31, 120] loss: 0.378\n",
      "[31, 180] loss: 0.388\n",
      "[31, 240] loss: 0.387\n",
      "[31, 300] loss: 0.392\n",
      "[31, 360] loss: 0.378\n",
      "Epoch: 31 -> Loss: 0.347091972828\n",
      "Epoch: 31 -> Test Accuracy: 82.47\n",
      "[32, 60] loss: 0.390\n",
      "[32, 120] loss: 0.366\n",
      "[32, 180] loss: 0.377\n",
      "[32, 240] loss: 0.386\n",
      "[32, 300] loss: 0.382\n",
      "[32, 360] loss: 0.396\n",
      "Epoch: 32 -> Loss: 0.42511588335\n",
      "Epoch: 32 -> Test Accuracy: 81.95\n",
      "[33, 60] loss: 0.371\n",
      "[33, 120] loss: 0.368\n",
      "[33, 180] loss: 0.377\n",
      "[33, 240] loss: 0.384\n",
      "[33, 300] loss: 0.388\n",
      "[33, 360] loss: 0.378\n",
      "Epoch: 33 -> Loss: 0.391119420528\n",
      "Epoch: 33 -> Test Accuracy: 81.62\n",
      "[34, 60] loss: 0.377\n",
      "[34, 120] loss: 0.355\n",
      "[34, 180] loss: 0.373\n",
      "[34, 240] loss: 0.394\n",
      "[34, 300] loss: 0.390\n",
      "[34, 360] loss: 0.394\n",
      "Epoch: 34 -> Loss: 0.403971672058\n",
      "Epoch: 34 -> Test Accuracy: 82.03\n",
      "[35, 60] loss: 0.379\n",
      "[35, 120] loss: 0.371\n",
      "[35, 180] loss: 0.377\n",
      "[35, 240] loss: 0.385\n",
      "[35, 300] loss: 0.393\n",
      "[35, 360] loss: 0.386\n",
      "Epoch: 35 -> Loss: 0.37564048171\n",
      "Epoch: 35 -> Test Accuracy: 82.11\n",
      "[36, 60] loss: 0.372\n",
      "[36, 120] loss: 0.369\n",
      "[36, 180] loss: 0.385\n",
      "[36, 240] loss: 0.383\n",
      "[36, 300] loss: 0.367\n",
      "[36, 360] loss: 0.384\n",
      "Epoch: 36 -> Loss: 0.331483066082\n",
      "Epoch: 36 -> Test Accuracy: 81.55\n",
      "[37, 60] loss: 0.365\n",
      "[37, 120] loss: 0.376\n",
      "[37, 180] loss: 0.365\n",
      "[37, 240] loss: 0.372\n",
      "[37, 300] loss: 0.384\n",
      "[37, 360] loss: 0.388\n",
      "Epoch: 37 -> Loss: 0.326968252659\n",
      "Epoch: 37 -> Test Accuracy: 82.09\n",
      "[38, 60] loss: 0.372\n",
      "[38, 120] loss: 0.373\n",
      "[38, 180] loss: 0.386\n",
      "[38, 240] loss: 0.368\n",
      "[38, 300] loss: 0.375\n",
      "[38, 360] loss: 0.385\n",
      "Epoch: 38 -> Loss: 0.287506878376\n",
      "Epoch: 38 -> Test Accuracy: 82.01\n",
      "[39, 60] loss: 0.361\n",
      "[39, 120] loss: 0.375\n",
      "[39, 180] loss: 0.358\n",
      "[39, 240] loss: 0.384\n",
      "[39, 300] loss: 0.375\n",
      "[39, 360] loss: 0.362\n",
      "Epoch: 39 -> Loss: 0.385202825069\n",
      "Epoch: 39 -> Test Accuracy: 81.53\n",
      "[40, 60] loss: 0.348\n",
      "[40, 120] loss: 0.369\n",
      "[40, 180] loss: 0.376\n",
      "[40, 240] loss: 0.391\n",
      "[40, 300] loss: 0.361\n",
      "[40, 360] loss: 0.381\n",
      "Epoch: 40 -> Loss: 0.411934942007\n",
      "Epoch: 40 -> Test Accuracy: 82.03\n",
      "[41, 60] loss: 0.352\n",
      "[41, 120] loss: 0.322\n",
      "[41, 180] loss: 0.322\n",
      "[41, 240] loss: 0.336\n",
      "[41, 300] loss: 0.333\n",
      "[41, 360] loss: 0.323\n",
      "Epoch: 41 -> Loss: 0.234177619219\n",
      "Epoch: 41 -> Test Accuracy: 82.78\n",
      "[42, 60] loss: 0.307\n",
      "[42, 120] loss: 0.310\n",
      "[42, 180] loss: 0.319\n",
      "[42, 240] loss: 0.307\n",
      "[42, 300] loss: 0.315\n",
      "[42, 360] loss: 0.308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.332994103432\n",
      "Epoch: 42 -> Test Accuracy: 82.73\n",
      "[43, 60] loss: 0.294\n",
      "[43, 120] loss: 0.293\n",
      "[43, 180] loss: 0.297\n",
      "[43, 240] loss: 0.304\n",
      "[43, 300] loss: 0.298\n",
      "[43, 360] loss: 0.299\n",
      "Epoch: 43 -> Loss: 0.326020866632\n",
      "Epoch: 43 -> Test Accuracy: 83.09\n",
      "[44, 60] loss: 0.295\n",
      "[44, 120] loss: 0.292\n",
      "[44, 180] loss: 0.283\n",
      "[44, 240] loss: 0.294\n",
      "[44, 300] loss: 0.293\n",
      "[44, 360] loss: 0.282\n",
      "Epoch: 44 -> Loss: 0.404775053263\n",
      "Epoch: 44 -> Test Accuracy: 82.88\n",
      "[45, 60] loss: 0.272\n",
      "[45, 120] loss: 0.282\n",
      "[45, 180] loss: 0.285\n",
      "[45, 240] loss: 0.288\n",
      "[45, 300] loss: 0.278\n",
      "[45, 360] loss: 0.299\n",
      "Epoch: 45 -> Loss: 0.15308393538\n",
      "Epoch: 45 -> Test Accuracy: 82.92\n",
      "[46, 60] loss: 0.275\n",
      "[46, 120] loss: 0.268\n",
      "[46, 180] loss: 0.283\n",
      "[46, 240] loss: 0.278\n",
      "[46, 300] loss: 0.278\n",
      "[46, 360] loss: 0.270\n",
      "Epoch: 46 -> Loss: 0.262244164944\n",
      "Epoch: 46 -> Test Accuracy: 83.05\n",
      "[47, 60] loss: 0.276\n",
      "[47, 120] loss: 0.267\n",
      "[47, 180] loss: 0.275\n",
      "[47, 240] loss: 0.279\n",
      "[47, 300] loss: 0.266\n",
      "[47, 360] loss: 0.262\n",
      "Epoch: 47 -> Loss: 0.361472249031\n",
      "Epoch: 47 -> Test Accuracy: 83.08\n",
      "[48, 60] loss: 0.270\n",
      "[48, 120] loss: 0.271\n",
      "[48, 180] loss: 0.268\n",
      "[48, 240] loss: 0.265\n",
      "[48, 300] loss: 0.285\n",
      "[48, 360] loss: 0.286\n",
      "Epoch: 48 -> Loss: 0.355505049229\n",
      "Epoch: 48 -> Test Accuracy: 83.16\n",
      "[49, 60] loss: 0.272\n",
      "[49, 120] loss: 0.270\n",
      "[49, 180] loss: 0.271\n",
      "[49, 240] loss: 0.268\n",
      "[49, 300] loss: 0.257\n",
      "[49, 360] loss: 0.266\n",
      "Epoch: 49 -> Loss: 0.208222582936\n",
      "Epoch: 49 -> Test Accuracy: 83.07\n",
      "[50, 60] loss: 0.264\n",
      "[50, 120] loss: 0.266\n",
      "[50, 180] loss: 0.266\n",
      "[50, 240] loss: 0.277\n",
      "[50, 300] loss: 0.265\n",
      "[50, 360] loss: 0.255\n",
      "Epoch: 50 -> Loss: 0.365976423025\n",
      "Epoch: 50 -> Test Accuracy: 82.99\n",
      "[51, 60] loss: 0.264\n",
      "[51, 120] loss: 0.262\n",
      "[51, 180] loss: 0.250\n",
      "[51, 240] loss: 0.259\n",
      "[51, 300] loss: 0.263\n",
      "[51, 360] loss: 0.264\n",
      "Epoch: 51 -> Loss: 0.314839750528\n",
      "Epoch: 51 -> Test Accuracy: 82.98\n",
      "[52, 60] loss: 0.262\n",
      "[52, 120] loss: 0.259\n",
      "[52, 180] loss: 0.260\n",
      "[52, 240] loss: 0.252\n",
      "[52, 300] loss: 0.252\n",
      "[52, 360] loss: 0.275\n",
      "Epoch: 52 -> Loss: 0.206320613623\n",
      "Epoch: 52 -> Test Accuracy: 83.04\n",
      "[53, 60] loss: 0.267\n",
      "[53, 120] loss: 0.260\n",
      "[53, 180] loss: 0.267\n",
      "[53, 240] loss: 0.255\n",
      "[53, 300] loss: 0.267\n",
      "[53, 360] loss: 0.263\n",
      "Epoch: 53 -> Loss: 0.397431999445\n",
      "Epoch: 53 -> Test Accuracy: 82.94\n",
      "[54, 60] loss: 0.250\n",
      "[54, 120] loss: 0.260\n",
      "[54, 180] loss: 0.260\n",
      "[54, 240] loss: 0.259\n",
      "[54, 300] loss: 0.261\n",
      "[54, 360] loss: 0.251\n",
      "Epoch: 54 -> Loss: 0.355315774679\n",
      "Epoch: 54 -> Test Accuracy: 83.27\n",
      "[55, 60] loss: 0.255\n",
      "[55, 120] loss: 0.270\n",
      "[55, 180] loss: 0.253\n",
      "[55, 240] loss: 0.236\n",
      "[55, 300] loss: 0.264\n",
      "[55, 360] loss: 0.265\n",
      "Epoch: 55 -> Loss: 0.358705937862\n",
      "Epoch: 55 -> Test Accuracy: 83.2\n",
      "[56, 60] loss: 0.253\n",
      "[56, 120] loss: 0.256\n",
      "[56, 180] loss: 0.246\n",
      "[56, 240] loss: 0.245\n",
      "[56, 300] loss: 0.253\n",
      "[56, 360] loss: 0.262\n",
      "Epoch: 56 -> Loss: 0.272285223007\n",
      "Epoch: 56 -> Test Accuracy: 83.1\n",
      "[57, 60] loss: 0.252\n",
      "[57, 120] loss: 0.262\n",
      "[57, 180] loss: 0.251\n",
      "[57, 240] loss: 0.253\n",
      "[57, 300] loss: 0.249\n",
      "[57, 360] loss: 0.263\n",
      "Epoch: 57 -> Loss: 0.406624853611\n",
      "Epoch: 57 -> Test Accuracy: 83.08\n",
      "[58, 60] loss: 0.256\n",
      "[58, 120] loss: 0.242\n",
      "[58, 180] loss: 0.259\n",
      "[58, 240] loss: 0.256\n",
      "[58, 300] loss: 0.251\n",
      "[58, 360] loss: 0.254\n",
      "Epoch: 58 -> Loss: 0.246799662709\n",
      "Epoch: 58 -> Test Accuracy: 83.04\n",
      "[59, 60] loss: 0.252\n",
      "[59, 120] loss: 0.276\n",
      "[59, 180] loss: 0.243\n",
      "[59, 240] loss: 0.263\n",
      "[59, 300] loss: 0.249\n",
      "[59, 360] loss: 0.257\n",
      "Epoch: 59 -> Loss: 0.279025554657\n",
      "Epoch: 59 -> Test Accuracy: 83.19\n",
      "[60, 60] loss: 0.249\n",
      "[60, 120] loss: 0.249\n",
      "[60, 180] loss: 0.259\n",
      "[60, 240] loss: 0.247\n",
      "[60, 300] loss: 0.257\n",
      "[60, 360] loss: 0.252\n",
      "Epoch: 60 -> Loss: 0.197952821851\n",
      "Epoch: 60 -> Test Accuracy: 83.1\n",
      "[61, 60] loss: 0.253\n",
      "[61, 120] loss: 0.248\n",
      "[61, 180] loss: 0.253\n",
      "[61, 240] loss: 0.250\n",
      "[61, 300] loss: 0.253\n",
      "[61, 360] loss: 0.255\n",
      "Epoch: 61 -> Loss: 0.305834472179\n",
      "Epoch: 61 -> Test Accuracy: 83.24\n",
      "[62, 60] loss: 0.244\n",
      "[62, 120] loss: 0.255\n",
      "[62, 180] loss: 0.263\n",
      "[62, 240] loss: 0.252\n",
      "[62, 300] loss: 0.246\n",
      "[62, 360] loss: 0.239\n",
      "Epoch: 62 -> Loss: 0.430526345968\n",
      "Epoch: 62 -> Test Accuracy: 83.12\n",
      "[63, 60] loss: 0.255\n",
      "[63, 120] loss: 0.251\n",
      "[63, 180] loss: 0.248\n",
      "[63, 240] loss: 0.235\n",
      "[63, 300] loss: 0.248\n",
      "[63, 360] loss: 0.258\n",
      "Epoch: 63 -> Loss: 0.179082587361\n",
      "Epoch: 63 -> Test Accuracy: 83.29\n",
      "[64, 60] loss: 0.249\n",
      "[64, 120] loss: 0.246\n",
      "[64, 180] loss: 0.244\n",
      "[64, 240] loss: 0.243\n",
      "[64, 300] loss: 0.242\n",
      "[64, 360] loss: 0.241\n",
      "Epoch: 64 -> Loss: 0.266464024782\n",
      "Epoch: 64 -> Test Accuracy: 83.21\n",
      "[65, 60] loss: 0.243\n",
      "[65, 120] loss: 0.246\n",
      "[65, 180] loss: 0.247\n",
      "[65, 240] loss: 0.250\n",
      "[65, 300] loss: 0.249\n",
      "[65, 360] loss: 0.247\n",
      "Epoch: 65 -> Loss: 0.241675049067\n",
      "Epoch: 65 -> Test Accuracy: 83.28\n",
      "[66, 60] loss: 0.229\n",
      "[66, 120] loss: 0.246\n",
      "[66, 180] loss: 0.255\n",
      "[66, 240] loss: 0.251\n",
      "[66, 300] loss: 0.235\n",
      "[66, 360] loss: 0.250\n",
      "Epoch: 66 -> Loss: 0.264233797789\n",
      "Epoch: 66 -> Test Accuracy: 83.12\n",
      "[67, 60] loss: 0.248\n",
      "[67, 120] loss: 0.244\n",
      "[67, 180] loss: 0.242\n",
      "[67, 240] loss: 0.238\n",
      "[67, 300] loss: 0.246\n",
      "[67, 360] loss: 0.243\n",
      "Epoch: 67 -> Loss: 0.289677709341\n",
      "Epoch: 67 -> Test Accuracy: 83.22\n",
      "[68, 60] loss: 0.256\n",
      "[68, 120] loss: 0.247\n",
      "[68, 180] loss: 0.243\n",
      "[68, 240] loss: 0.241\n",
      "[68, 300] loss: 0.239\n",
      "[68, 360] loss: 0.234\n",
      "Epoch: 68 -> Loss: 0.230375498533\n",
      "Epoch: 68 -> Test Accuracy: 83.08\n",
      "[69, 60] loss: 0.234\n",
      "[69, 120] loss: 0.239\n",
      "[69, 180] loss: 0.242\n",
      "[69, 240] loss: 0.251\n",
      "[69, 300] loss: 0.233\n",
      "[69, 360] loss: 0.250\n",
      "Epoch: 69 -> Loss: 0.277349829674\n",
      "Epoch: 69 -> Test Accuracy: 83.27\n",
      "[70, 60] loss: 0.244\n",
      "[70, 120] loss: 0.243\n",
      "[70, 180] loss: 0.244\n",
      "[70, 240] loss: 0.245\n",
      "[70, 300] loss: 0.246\n",
      "[70, 360] loss: 0.237\n",
      "Epoch: 70 -> Loss: 0.296507179737\n",
      "Epoch: 70 -> Test Accuracy: 83.14\n",
      "[71, 60] loss: 0.240\n",
      "[71, 120] loss: 0.230\n",
      "[71, 180] loss: 0.244\n",
      "[71, 240] loss: 0.235\n",
      "[71, 300] loss: 0.245\n",
      "[71, 360] loss: 0.230\n",
      "Epoch: 71 -> Loss: 0.157645359635\n",
      "Epoch: 71 -> Test Accuracy: 83.04\n",
      "[72, 60] loss: 0.242\n",
      "[72, 120] loss: 0.229\n",
      "[72, 180] loss: 0.225\n",
      "[72, 240] loss: 0.238\n",
      "[72, 300] loss: 0.250\n",
      "[72, 360] loss: 0.234\n",
      "Epoch: 72 -> Loss: 0.279527008533\n",
      "Epoch: 72 -> Test Accuracy: 83.14\n",
      "[73, 60] loss: 0.234\n",
      "[73, 120] loss: 0.236\n",
      "[73, 180] loss: 0.227\n",
      "[73, 240] loss: 0.246\n",
      "[73, 300] loss: 0.242\n",
      "[73, 360] loss: 0.234\n",
      "Epoch: 73 -> Loss: 0.251714527607\n",
      "Epoch: 73 -> Test Accuracy: 83.15\n",
      "[74, 60] loss: 0.231\n",
      "[74, 120] loss: 0.244\n",
      "[74, 180] loss: 0.247\n",
      "[74, 240] loss: 0.236\n",
      "[74, 300] loss: 0.242\n",
      "[74, 360] loss: 0.246\n",
      "Epoch: 74 -> Loss: 0.219133019447\n",
      "Epoch: 74 -> Test Accuracy: 83.16\n",
      "[75, 60] loss: 0.227\n",
      "[75, 120] loss: 0.242\n",
      "[75, 180] loss: 0.238\n",
      "[75, 240] loss: 0.234\n",
      "[75, 300] loss: 0.241\n",
      "[75, 360] loss: 0.244\n",
      "Epoch: 75 -> Loss: 0.160952612758\n",
      "Epoch: 75 -> Test Accuracy: 83.21\n",
      "[76, 60] loss: 0.234\n",
      "[76, 120] loss: 0.231\n",
      "[76, 180] loss: 0.234\n",
      "[76, 240] loss: 0.241\n",
      "[76, 300] loss: 0.233\n",
      "[76, 360] loss: 0.233\n",
      "Epoch: 76 -> Loss: 0.194017440081\n",
      "Epoch: 76 -> Test Accuracy: 83.21\n",
      "[77, 60] loss: 0.225\n",
      "[77, 120] loss: 0.231\n",
      "[77, 180] loss: 0.235\n",
      "[77, 240] loss: 0.233\n",
      "[77, 300] loss: 0.233\n",
      "[77, 360] loss: 0.232\n",
      "Epoch: 77 -> Loss: 0.230169251561\n",
      "Epoch: 77 -> Test Accuracy: 83.19\n",
      "[78, 60] loss: 0.231\n",
      "[78, 120] loss: 0.229\n",
      "[78, 180] loss: 0.233\n",
      "[78, 240] loss: 0.231\n",
      "[78, 300] loss: 0.236\n",
      "[78, 360] loss: 0.225\n",
      "Epoch: 78 -> Loss: 0.356003493071\n",
      "Epoch: 78 -> Test Accuracy: 83.28\n",
      "[79, 60] loss: 0.235\n",
      "[79, 120] loss: 0.230\n",
      "[79, 180] loss: 0.221\n",
      "[79, 240] loss: 0.235\n",
      "[79, 300] loss: 0.230\n",
      "[79, 360] loss: 0.237\n",
      "Epoch: 79 -> Loss: 0.526965022087\n",
      "Epoch: 79 -> Test Accuracy: 83.32\n",
      "[80, 60] loss: 0.236\n",
      "[80, 120] loss: 0.234\n",
      "[80, 180] loss: 0.222\n",
      "[80, 240] loss: 0.233\n",
      "[80, 300] loss: 0.230\n",
      "[80, 360] loss: 0.227\n",
      "Epoch: 80 -> Loss: 0.198395565152\n",
      "Epoch: 80 -> Test Accuracy: 83.23\n",
      "[81, 60] loss: 0.223\n",
      "[81, 120] loss: 0.233\n",
      "[81, 180] loss: 0.238\n",
      "[81, 240] loss: 0.228\n",
      "[81, 300] loss: 0.224\n",
      "[81, 360] loss: 0.228\n",
      "Epoch: 81 -> Loss: 0.368765324354\n",
      "Epoch: 81 -> Test Accuracy: 83.18\n",
      "[82, 60] loss: 0.227\n",
      "[82, 120] loss: 0.234\n",
      "[82, 180] loss: 0.230\n",
      "[82, 240] loss: 0.237\n",
      "[82, 300] loss: 0.225\n",
      "[82, 360] loss: 0.226\n",
      "Epoch: 82 -> Loss: 0.178824096918\n",
      "Epoch: 82 -> Test Accuracy: 83.09\n",
      "[83, 60] loss: 0.230\n",
      "[83, 120] loss: 0.235\n",
      "[83, 180] loss: 0.228\n",
      "[83, 240] loss: 0.231\n",
      "[83, 300] loss: 0.228\n",
      "[83, 360] loss: 0.235\n",
      "Epoch: 83 -> Loss: 0.249970510602\n",
      "Epoch: 83 -> Test Accuracy: 83.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.230\n",
      "[84, 120] loss: 0.223\n",
      "[84, 180] loss: 0.220\n",
      "[84, 240] loss: 0.232\n",
      "[84, 300] loss: 0.232\n",
      "[84, 360] loss: 0.223\n",
      "Epoch: 84 -> Loss: 0.275760382414\n",
      "Epoch: 84 -> Test Accuracy: 83.1\n",
      "[85, 60] loss: 0.224\n",
      "[85, 120] loss: 0.223\n",
      "[85, 180] loss: 0.217\n",
      "[85, 240] loss: 0.229\n",
      "[85, 300] loss: 0.232\n",
      "[85, 360] loss: 0.239\n",
      "Epoch: 85 -> Loss: 0.303332418203\n",
      "Epoch: 85 -> Test Accuracy: 83.29\n",
      "[86, 60] loss: 0.220\n",
      "[86, 120] loss: 0.225\n",
      "[86, 180] loss: 0.224\n",
      "[86, 240] loss: 0.231\n",
      "[86, 300] loss: 0.228\n",
      "[86, 360] loss: 0.229\n",
      "Epoch: 86 -> Loss: 0.361538261175\n",
      "Epoch: 86 -> Test Accuracy: 83.19\n",
      "[87, 60] loss: 0.221\n",
      "[87, 120] loss: 0.224\n",
      "[87, 180] loss: 0.223\n",
      "[87, 240] loss: 0.225\n",
      "[87, 300] loss: 0.224\n",
      "[87, 360] loss: 0.215\n",
      "Epoch: 87 -> Loss: 0.120859101415\n",
      "Epoch: 87 -> Test Accuracy: 83.2\n",
      "[88, 60] loss: 0.234\n",
      "[88, 120] loss: 0.215\n",
      "[88, 180] loss: 0.226\n",
      "[88, 240] loss: 0.217\n",
      "[88, 300] loss: 0.228\n",
      "[88, 360] loss: 0.231\n",
      "Epoch: 88 -> Loss: 0.202250763774\n",
      "Epoch: 88 -> Test Accuracy: 83.17\n",
      "[89, 60] loss: 0.220\n",
      "[89, 120] loss: 0.219\n",
      "[89, 180] loss: 0.231\n",
      "[89, 240] loss: 0.234\n",
      "[89, 300] loss: 0.223\n",
      "[89, 360] loss: 0.226\n",
      "Epoch: 89 -> Loss: 0.243361517787\n",
      "Epoch: 89 -> Test Accuracy: 83.33\n",
      "[90, 60] loss: 0.227\n",
      "[90, 120] loss: 0.202\n",
      "[90, 180] loss: 0.225\n",
      "[90, 240] loss: 0.222\n",
      "[90, 300] loss: 0.221\n",
      "[90, 360] loss: 0.217\n",
      "Epoch: 90 -> Loss: 0.182889983058\n",
      "Epoch: 90 -> Test Accuracy: 83.38\n",
      "[91, 60] loss: 0.224\n",
      "[91, 120] loss: 0.221\n",
      "[91, 180] loss: 0.222\n",
      "[91, 240] loss: 0.217\n",
      "[91, 300] loss: 0.221\n",
      "[91, 360] loss: 0.235\n",
      "Epoch: 91 -> Loss: 0.237830594182\n",
      "Epoch: 91 -> Test Accuracy: 83.29\n",
      "[92, 60] loss: 0.223\n",
      "[92, 120] loss: 0.225\n",
      "[92, 180] loss: 0.212\n",
      "[92, 240] loss: 0.226\n",
      "[92, 300] loss: 0.216\n",
      "[92, 360] loss: 0.229\n",
      "Epoch: 92 -> Loss: 0.118292652071\n",
      "Epoch: 92 -> Test Accuracy: 83.4\n",
      "[93, 60] loss: 0.218\n",
      "[93, 120] loss: 0.222\n",
      "[93, 180] loss: 0.212\n",
      "[93, 240] loss: 0.215\n",
      "[93, 300] loss: 0.228\n",
      "[93, 360] loss: 0.216\n",
      "Epoch: 93 -> Loss: 0.167962044477\n",
      "Epoch: 93 -> Test Accuracy: 83.36\n",
      "[94, 60] loss: 0.222\n",
      "[94, 120] loss: 0.211\n",
      "[94, 180] loss: 0.213\n",
      "[94, 240] loss: 0.221\n",
      "[94, 300] loss: 0.217\n",
      "[94, 360] loss: 0.229\n",
      "Epoch: 94 -> Loss: 0.265777915716\n",
      "Epoch: 94 -> Test Accuracy: 83.24\n",
      "[95, 60] loss: 0.226\n",
      "[95, 120] loss: 0.206\n",
      "[95, 180] loss: 0.213\n",
      "[95, 240] loss: 0.223\n",
      "[95, 300] loss: 0.214\n",
      "[95, 360] loss: 0.221\n",
      "Epoch: 95 -> Loss: 0.231031134725\n",
      "Epoch: 95 -> Test Accuracy: 83.35\n",
      "[96, 60] loss: 0.216\n",
      "[96, 120] loss: 0.219\n",
      "[96, 180] loss: 0.221\n",
      "[96, 240] loss: 0.214\n",
      "[96, 300] loss: 0.219\n",
      "[96, 360] loss: 0.219\n",
      "Epoch: 96 -> Loss: 0.162611573935\n",
      "Epoch: 96 -> Test Accuracy: 83.43\n",
      "[97, 60] loss: 0.216\n",
      "[97, 120] loss: 0.224\n",
      "[97, 180] loss: 0.215\n",
      "[97, 240] loss: 0.217\n",
      "[97, 300] loss: 0.215\n",
      "[97, 360] loss: 0.212\n",
      "Epoch: 97 -> Loss: 0.159254923463\n",
      "Epoch: 97 -> Test Accuracy: 83.26\n",
      "[98, 60] loss: 0.206\n",
      "[98, 120] loss: 0.212\n",
      "[98, 180] loss: 0.214\n",
      "[98, 240] loss: 0.216\n",
      "[98, 300] loss: 0.223\n",
      "[98, 360] loss: 0.207\n",
      "Epoch: 98 -> Loss: 0.2572067976\n",
      "Epoch: 98 -> Test Accuracy: 83.34\n",
      "[99, 60] loss: 0.210\n",
      "[99, 120] loss: 0.203\n",
      "[99, 180] loss: 0.217\n",
      "[99, 240] loss: 0.219\n",
      "[99, 300] loss: 0.218\n",
      "[99, 360] loss: 0.214\n",
      "Epoch: 99 -> Loss: 0.2847032547\n",
      "Epoch: 99 -> Test Accuracy: 83.26\n",
      "[100, 60] loss: 0.207\n",
      "[100, 120] loss: 0.225\n",
      "[100, 180] loss: 0.211\n",
      "[100, 240] loss: 0.217\n",
      "[100, 300] loss: 0.219\n",
      "[100, 360] loss: 0.223\n",
      "Epoch: 100 -> Loss: 0.204636290669\n",
      "Epoch: 100 -> Test Accuracy: 83.28\n",
      "Finished Training\n",
      "[1, 60] loss: 1.644\n",
      "[1, 120] loss: 0.821\n",
      "[1, 180] loss: 0.744\n",
      "[1, 240] loss: 0.710\n",
      "[1, 300] loss: 0.679\n",
      "[1, 360] loss: 0.649\n",
      "Epoch: 1 -> Loss: 0.701272428036\n",
      "Epoch: 1 -> Test Accuracy: 78.65\n",
      "[2, 60] loss: 0.597\n",
      "[2, 120] loss: 0.585\n",
      "[2, 180] loss: 0.572\n",
      "[2, 240] loss: 0.545\n",
      "[2, 300] loss: 0.565\n",
      "[2, 360] loss: 0.560\n",
      "Epoch: 2 -> Loss: 0.561306715012\n",
      "Epoch: 2 -> Test Accuracy: 80.37\n",
      "[3, 60] loss: 0.513\n",
      "[3, 120] loss: 0.520\n",
      "[3, 180] loss: 0.511\n",
      "[3, 240] loss: 0.508\n",
      "[3, 300] loss: 0.510\n",
      "[3, 360] loss: 0.508\n",
      "Epoch: 3 -> Loss: 0.586759090424\n",
      "Epoch: 3 -> Test Accuracy: 81.28\n",
      "[4, 60] loss: 0.494\n",
      "[4, 120] loss: 0.475\n",
      "[4, 180] loss: 0.473\n",
      "[4, 240] loss: 0.491\n",
      "[4, 300] loss: 0.462\n",
      "[4, 360] loss: 0.490\n",
      "Epoch: 4 -> Loss: 0.434667438269\n",
      "Epoch: 4 -> Test Accuracy: 81.58\n",
      "[5, 60] loss: 0.442\n",
      "[5, 120] loss: 0.460\n",
      "[5, 180] loss: 0.451\n",
      "[5, 240] loss: 0.461\n",
      "[5, 300] loss: 0.440\n",
      "[5, 360] loss: 0.465\n",
      "Epoch: 5 -> Loss: 0.457592815161\n",
      "Epoch: 5 -> Test Accuracy: 81.89\n",
      "[6, 60] loss: 0.423\n",
      "[6, 120] loss: 0.434\n",
      "[6, 180] loss: 0.416\n",
      "[6, 240] loss: 0.449\n",
      "[6, 300] loss: 0.448\n",
      "[6, 360] loss: 0.448\n",
      "Epoch: 6 -> Loss: 0.407326281071\n",
      "Epoch: 6 -> Test Accuracy: 83.07\n",
      "[7, 60] loss: 0.428\n",
      "[7, 120] loss: 0.404\n",
      "[7, 180] loss: 0.411\n",
      "[7, 240] loss: 0.436\n",
      "[7, 300] loss: 0.428\n",
      "[7, 360] loss: 0.439\n",
      "Epoch: 7 -> Loss: 0.390617400408\n",
      "Epoch: 7 -> Test Accuracy: 82.82\n",
      "[8, 60] loss: 0.395\n",
      "[8, 120] loss: 0.398\n",
      "[8, 180] loss: 0.412\n",
      "[8, 240] loss: 0.411\n",
      "[8, 300] loss: 0.425\n",
      "[8, 360] loss: 0.438\n",
      "Epoch: 8 -> Loss: 0.387452274561\n",
      "Epoch: 8 -> Test Accuracy: 83.57\n",
      "[9, 60] loss: 0.402\n",
      "[9, 120] loss: 0.409\n",
      "[9, 180] loss: 0.389\n",
      "[9, 240] loss: 0.402\n",
      "[9, 300] loss: 0.417\n",
      "[9, 360] loss: 0.426\n",
      "Epoch: 9 -> Loss: 0.486477464437\n",
      "Epoch: 9 -> Test Accuracy: 82.97\n",
      "[10, 60] loss: 0.388\n",
      "[10, 120] loss: 0.388\n",
      "[10, 180] loss: 0.393\n",
      "[10, 240] loss: 0.412\n",
      "[10, 300] loss: 0.391\n",
      "[10, 360] loss: 0.421\n",
      "Epoch: 10 -> Loss: 0.426252067089\n",
      "Epoch: 10 -> Test Accuracy: 84.33\n",
      "[11, 60] loss: 0.380\n",
      "[11, 120] loss: 0.385\n",
      "[11, 180] loss: 0.388\n",
      "[11, 240] loss: 0.404\n",
      "[11, 300] loss: 0.397\n",
      "[11, 360] loss: 0.404\n",
      "Epoch: 11 -> Loss: 0.693639338017\n",
      "Epoch: 11 -> Test Accuracy: 83.25\n",
      "[12, 60] loss: 0.362\n",
      "[12, 120] loss: 0.360\n",
      "[12, 180] loss: 0.378\n",
      "[12, 240] loss: 0.404\n",
      "[12, 300] loss: 0.396\n",
      "[12, 360] loss: 0.400\n",
      "Epoch: 12 -> Loss: 0.53497749567\n",
      "Epoch: 12 -> Test Accuracy: 83.23\n",
      "[13, 60] loss: 0.369\n",
      "[13, 120] loss: 0.372\n",
      "[13, 180] loss: 0.364\n",
      "[13, 240] loss: 0.381\n",
      "[13, 300] loss: 0.404\n",
      "[13, 360] loss: 0.414\n",
      "Epoch: 13 -> Loss: 0.437541097403\n",
      "Epoch: 13 -> Test Accuracy: 84.03\n",
      "[14, 60] loss: 0.378\n",
      "[14, 120] loss: 0.374\n",
      "[14, 180] loss: 0.376\n",
      "[14, 240] loss: 0.391\n",
      "[14, 300] loss: 0.373\n",
      "[14, 360] loss: 0.397\n",
      "Epoch: 14 -> Loss: 0.38378995657\n",
      "Epoch: 14 -> Test Accuracy: 83.58\n",
      "[15, 60] loss: 0.370\n",
      "[15, 120] loss: 0.372\n",
      "[15, 180] loss: 0.377\n",
      "[15, 240] loss: 0.386\n",
      "[15, 300] loss: 0.364\n",
      "[15, 360] loss: 0.381\n",
      "Epoch: 15 -> Loss: 0.310917705297\n",
      "Epoch: 15 -> Test Accuracy: 83.59\n",
      "[16, 60] loss: 0.371\n",
      "[16, 120] loss: 0.357\n",
      "[16, 180] loss: 0.366\n",
      "[16, 240] loss: 0.375\n",
      "[16, 300] loss: 0.372\n",
      "[16, 360] loss: 0.393\n",
      "Epoch: 16 -> Loss: 0.276065915823\n",
      "Epoch: 16 -> Test Accuracy: 83.46\n",
      "[17, 60] loss: 0.357\n",
      "[17, 120] loss: 0.356\n",
      "[17, 180] loss: 0.381\n",
      "[17, 240] loss: 0.373\n",
      "[17, 300] loss: 0.382\n",
      "[17, 360] loss: 0.379\n",
      "Epoch: 17 -> Loss: 0.250696003437\n",
      "Epoch: 17 -> Test Accuracy: 83.86\n",
      "[18, 60] loss: 0.358\n",
      "[18, 120] loss: 0.374\n",
      "[18, 180] loss: 0.379\n",
      "[18, 240] loss: 0.371\n",
      "[18, 300] loss: 0.387\n",
      "[18, 360] loss: 0.371\n",
      "Epoch: 18 -> Loss: 0.264555454254\n",
      "Epoch: 18 -> Test Accuracy: 83.73\n",
      "[19, 60] loss: 0.344\n",
      "[19, 120] loss: 0.359\n",
      "[19, 180] loss: 0.371\n",
      "[19, 240] loss: 0.373\n",
      "[19, 300] loss: 0.379\n",
      "[19, 360] loss: 0.382\n",
      "Epoch: 19 -> Loss: 0.384335100651\n",
      "Epoch: 19 -> Test Accuracy: 84.08\n",
      "[20, 60] loss: 0.340\n",
      "[20, 120] loss: 0.364\n",
      "[20, 180] loss: 0.350\n",
      "[20, 240] loss: 0.376\n",
      "[20, 300] loss: 0.377\n",
      "[20, 360] loss: 0.365\n",
      "Epoch: 20 -> Loss: 0.480647653341\n",
      "Epoch: 20 -> Test Accuracy: 83.36\n",
      "[21, 60] loss: 0.303\n",
      "[21, 120] loss: 0.312\n",
      "[21, 180] loss: 0.289\n",
      "[21, 240] loss: 0.288\n",
      "[21, 300] loss: 0.295\n",
      "[21, 360] loss: 0.273\n",
      "Epoch: 21 -> Loss: 0.234928324819\n",
      "Epoch: 21 -> Test Accuracy: 85.6\n",
      "[22, 60] loss: 0.270\n",
      "[22, 120] loss: 0.271\n",
      "[22, 180] loss: 0.268\n",
      "[22, 240] loss: 0.258\n",
      "[22, 300] loss: 0.254\n",
      "[22, 360] loss: 0.256\n",
      "Epoch: 22 -> Loss: 0.315085470676\n",
      "Epoch: 22 -> Test Accuracy: 85.78\n",
      "[23, 60] loss: 0.243\n",
      "[23, 120] loss: 0.246\n",
      "[23, 180] loss: 0.241\n",
      "[23, 240] loss: 0.244\n",
      "[23, 300] loss: 0.248\n",
      "[23, 360] loss: 0.240\n",
      "Epoch: 23 -> Loss: 0.207869812846\n",
      "Epoch: 23 -> Test Accuracy: 85.97\n",
      "[24, 60] loss: 0.223\n",
      "[24, 120] loss: 0.228\n",
      "[24, 180] loss: 0.231\n",
      "[24, 240] loss: 0.219\n",
      "[24, 300] loss: 0.237\n",
      "[24, 360] loss: 0.247\n",
      "Epoch: 24 -> Loss: 0.22454893589\n",
      "Epoch: 24 -> Test Accuracy: 86.11\n",
      "[25, 60] loss: 0.215\n",
      "[25, 120] loss: 0.224\n",
      "[25, 180] loss: 0.227\n",
      "[25, 240] loss: 0.216\n",
      "[25, 300] loss: 0.225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 360] loss: 0.228\n",
      "Epoch: 25 -> Loss: 0.151886552572\n",
      "Epoch: 25 -> Test Accuracy: 86.24\n",
      "[26, 60] loss: 0.218\n",
      "[26, 120] loss: 0.219\n",
      "[26, 180] loss: 0.215\n",
      "[26, 240] loss: 0.233\n",
      "[26, 300] loss: 0.231\n",
      "[26, 360] loss: 0.212\n",
      "Epoch: 26 -> Loss: 0.146667078137\n",
      "Epoch: 26 -> Test Accuracy: 86.05\n",
      "[27, 60] loss: 0.197\n",
      "[27, 120] loss: 0.212\n",
      "[27, 180] loss: 0.211\n",
      "[27, 240] loss: 0.213\n",
      "[27, 300] loss: 0.216\n",
      "[27, 360] loss: 0.221\n",
      "Epoch: 27 -> Loss: 0.311142802238\n",
      "Epoch: 27 -> Test Accuracy: 85.84\n",
      "[28, 60] loss: 0.195\n",
      "[28, 120] loss: 0.207\n",
      "[28, 180] loss: 0.207\n",
      "[28, 240] loss: 0.218\n",
      "[28, 300] loss: 0.200\n",
      "[28, 360] loss: 0.209\n",
      "Epoch: 28 -> Loss: 0.142397254705\n",
      "Epoch: 28 -> Test Accuracy: 85.58\n",
      "[29, 60] loss: 0.192\n",
      "[29, 120] loss: 0.209\n",
      "[29, 180] loss: 0.199\n",
      "[29, 240] loss: 0.206\n",
      "[29, 300] loss: 0.199\n",
      "[29, 360] loss: 0.204\n",
      "Epoch: 29 -> Loss: 0.286255061626\n",
      "Epoch: 29 -> Test Accuracy: 85.57\n",
      "[30, 60] loss: 0.196\n",
      "[30, 120] loss: 0.197\n",
      "[30, 180] loss: 0.198\n",
      "[30, 240] loss: 0.204\n",
      "[30, 300] loss: 0.196\n",
      "[30, 360] loss: 0.205\n",
      "Epoch: 30 -> Loss: 0.151985600591\n",
      "Epoch: 30 -> Test Accuracy: 85.61\n",
      "[31, 60] loss: 0.185\n",
      "[31, 120] loss: 0.205\n",
      "[31, 180] loss: 0.200\n",
      "[31, 240] loss: 0.197\n",
      "[31, 300] loss: 0.200\n",
      "[31, 360] loss: 0.219\n",
      "Epoch: 31 -> Loss: 0.199593648314\n",
      "Epoch: 31 -> Test Accuracy: 85.99\n",
      "[32, 60] loss: 0.192\n",
      "[32, 120] loss: 0.210\n",
      "[32, 180] loss: 0.209\n",
      "[32, 240] loss: 0.206\n",
      "[32, 300] loss: 0.199\n",
      "[32, 360] loss: 0.209\n",
      "Epoch: 32 -> Loss: 0.191033646464\n",
      "Epoch: 32 -> Test Accuracy: 85.83\n",
      "[33, 60] loss: 0.194\n",
      "[33, 120] loss: 0.191\n",
      "[33, 180] loss: 0.190\n",
      "[33, 240] loss: 0.189\n",
      "[33, 300] loss: 0.195\n",
      "[33, 360] loss: 0.201\n",
      "Epoch: 33 -> Loss: 0.201527312398\n",
      "Epoch: 33 -> Test Accuracy: 85.09\n",
      "[34, 60] loss: 0.186\n",
      "[34, 120] loss: 0.198\n",
      "[34, 180] loss: 0.195\n",
      "[34, 240] loss: 0.194\n",
      "[34, 300] loss: 0.208\n",
      "[34, 360] loss: 0.210\n",
      "Epoch: 34 -> Loss: 0.233592748642\n",
      "Epoch: 34 -> Test Accuracy: 85.53\n",
      "[35, 60] loss: 0.181\n",
      "[35, 120] loss: 0.179\n",
      "[35, 180] loss: 0.187\n",
      "[35, 240] loss: 0.201\n",
      "[35, 300] loss: 0.206\n",
      "[35, 360] loss: 0.201\n",
      "Epoch: 35 -> Loss: 0.152111202478\n",
      "Epoch: 35 -> Test Accuracy: 85.55\n",
      "[36, 60] loss: 0.195\n",
      "[36, 120] loss: 0.195\n",
      "[36, 180] loss: 0.190\n",
      "[36, 240] loss: 0.200\n",
      "[36, 300] loss: 0.198\n",
      "[36, 360] loss: 0.214\n",
      "Epoch: 36 -> Loss: 0.131010040641\n",
      "Epoch: 36 -> Test Accuracy: 85.71\n",
      "[37, 60] loss: 0.189\n",
      "[37, 120] loss: 0.182\n",
      "[37, 180] loss: 0.182\n",
      "[37, 240] loss: 0.190\n",
      "[37, 300] loss: 0.198\n",
      "[37, 360] loss: 0.203\n",
      "Epoch: 37 -> Loss: 0.173107802868\n",
      "Epoch: 37 -> Test Accuracy: 85.54\n",
      "[38, 60] loss: 0.185\n",
      "[38, 120] loss: 0.193\n",
      "[38, 180] loss: 0.193\n",
      "[38, 240] loss: 0.193\n",
      "[38, 300] loss: 0.188\n",
      "[38, 360] loss: 0.186\n",
      "Epoch: 38 -> Loss: 0.176717355847\n",
      "Epoch: 38 -> Test Accuracy: 85.57\n",
      "[39, 60] loss: 0.180\n",
      "[39, 120] loss: 0.182\n",
      "[39, 180] loss: 0.195\n",
      "[39, 240] loss: 0.185\n",
      "[39, 300] loss: 0.198\n",
      "[39, 360] loss: 0.210\n",
      "Epoch: 39 -> Loss: 0.266058504581\n",
      "Epoch: 39 -> Test Accuracy: 85.68\n",
      "[40, 60] loss: 0.176\n",
      "[40, 120] loss: 0.173\n",
      "[40, 180] loss: 0.196\n",
      "[40, 240] loss: 0.192\n",
      "[40, 300] loss: 0.194\n",
      "[40, 360] loss: 0.197\n",
      "Epoch: 40 -> Loss: 0.314575463533\n",
      "Epoch: 40 -> Test Accuracy: 85.45\n",
      "[41, 60] loss: 0.163\n",
      "[41, 120] loss: 0.159\n",
      "[41, 180] loss: 0.164\n",
      "[41, 240] loss: 0.152\n",
      "[41, 300] loss: 0.157\n",
      "[41, 360] loss: 0.145\n",
      "Epoch: 41 -> Loss: 0.162493079901\n",
      "Epoch: 41 -> Test Accuracy: 85.91\n",
      "[42, 60] loss: 0.142\n",
      "[42, 120] loss: 0.137\n",
      "[42, 180] loss: 0.145\n",
      "[42, 240] loss: 0.141\n",
      "[42, 300] loss: 0.145\n",
      "[42, 360] loss: 0.139\n",
      "Epoch: 42 -> Loss: 0.162816256285\n",
      "Epoch: 42 -> Test Accuracy: 86.22\n",
      "[43, 60] loss: 0.125\n",
      "[43, 120] loss: 0.131\n",
      "[43, 180] loss: 0.131\n",
      "[43, 240] loss: 0.138\n",
      "[43, 300] loss: 0.141\n",
      "[43, 360] loss: 0.142\n",
      "Epoch: 43 -> Loss: 0.157318085432\n",
      "Epoch: 43 -> Test Accuracy: 86.57\n",
      "[44, 60] loss: 0.124\n",
      "[44, 120] loss: 0.121\n",
      "[44, 180] loss: 0.129\n",
      "[44, 240] loss: 0.127\n",
      "[44, 300] loss: 0.138\n",
      "[44, 360] loss: 0.129\n",
      "Epoch: 44 -> Loss: 0.0897534042597\n",
      "Epoch: 44 -> Test Accuracy: 86.6\n",
      "[45, 60] loss: 0.131\n",
      "[45, 120] loss: 0.122\n",
      "[45, 180] loss: 0.126\n",
      "[45, 240] loss: 0.119\n",
      "[45, 300] loss: 0.134\n",
      "[45, 360] loss: 0.127\n",
      "Epoch: 45 -> Loss: 0.0621313527226\n",
      "Epoch: 45 -> Test Accuracy: 86.34\n",
      "[46, 60] loss: 0.123\n",
      "[46, 120] loss: 0.111\n",
      "[46, 180] loss: 0.116\n",
      "[46, 240] loss: 0.116\n",
      "[46, 300] loss: 0.119\n",
      "[46, 360] loss: 0.122\n",
      "Epoch: 46 -> Loss: 0.121094107628\n",
      "Epoch: 46 -> Test Accuracy: 86.45\n",
      "[47, 60] loss: 0.116\n",
      "[47, 120] loss: 0.119\n",
      "[47, 180] loss: 0.114\n",
      "[47, 240] loss: 0.115\n",
      "[47, 300] loss: 0.116\n",
      "[47, 360] loss: 0.115\n",
      "Epoch: 47 -> Loss: 0.111577153206\n",
      "Epoch: 47 -> Test Accuracy: 86.57\n",
      "[48, 60] loss: 0.120\n",
      "[48, 120] loss: 0.116\n",
      "[48, 180] loss: 0.112\n",
      "[48, 240] loss: 0.111\n",
      "[48, 300] loss: 0.111\n",
      "[48, 360] loss: 0.108\n",
      "Epoch: 48 -> Loss: 0.214693546295\n",
      "Epoch: 48 -> Test Accuracy: 86.52\n",
      "[49, 60] loss: 0.105\n",
      "[49, 120] loss: 0.112\n",
      "[49, 180] loss: 0.111\n",
      "[49, 240] loss: 0.111\n",
      "[49, 300] loss: 0.114\n",
      "[49, 360] loss: 0.110\n",
      "Epoch: 49 -> Loss: 0.0762288421392\n",
      "Epoch: 49 -> Test Accuracy: 86.5\n",
      "[50, 60] loss: 0.110\n",
      "[50, 120] loss: 0.109\n",
      "[50, 180] loss: 0.112\n",
      "[50, 240] loss: 0.114\n",
      "[50, 300] loss: 0.107\n",
      "[50, 360] loss: 0.112\n",
      "Epoch: 50 -> Loss: 0.135717004538\n",
      "Epoch: 50 -> Test Accuracy: 86.55\n",
      "[51, 60] loss: 0.108\n",
      "[51, 120] loss: 0.114\n",
      "[51, 180] loss: 0.107\n",
      "[51, 240] loss: 0.106\n",
      "[51, 300] loss: 0.112\n",
      "[51, 360] loss: 0.112\n",
      "Epoch: 51 -> Loss: 0.0814069435\n",
      "Epoch: 51 -> Test Accuracy: 86.54\n",
      "[52, 60] loss: 0.111\n",
      "[52, 120] loss: 0.111\n",
      "[52, 180] loss: 0.107\n",
      "[52, 240] loss: 0.108\n",
      "[52, 300] loss: 0.108\n",
      "[52, 360] loss: 0.114\n",
      "Epoch: 52 -> Loss: 0.183041721582\n",
      "Epoch: 52 -> Test Accuracy: 86.56\n",
      "[53, 60] loss: 0.105\n",
      "[53, 120] loss: 0.110\n",
      "[53, 180] loss: 0.100\n",
      "[53, 240] loss: 0.111\n",
      "[53, 300] loss: 0.098\n",
      "[53, 360] loss: 0.107\n",
      "Epoch: 53 -> Loss: 0.111024282873\n",
      "Epoch: 53 -> Test Accuracy: 86.5\n",
      "[54, 60] loss: 0.102\n",
      "[54, 120] loss: 0.109\n",
      "[54, 180] loss: 0.099\n",
      "[54, 240] loss: 0.106\n",
      "[54, 300] loss: 0.105\n",
      "[54, 360] loss: 0.109\n",
      "Epoch: 54 -> Loss: 0.17025090754\n",
      "Epoch: 54 -> Test Accuracy: 86.5\n",
      "[55, 60] loss: 0.107\n",
      "[55, 120] loss: 0.104\n",
      "[55, 180] loss: 0.106\n",
      "[55, 240] loss: 0.106\n",
      "[55, 300] loss: 0.105\n",
      "[55, 360] loss: 0.105\n",
      "Epoch: 55 -> Loss: 0.123021617532\n",
      "Epoch: 55 -> Test Accuracy: 86.49\n",
      "[56, 60] loss: 0.099\n",
      "[56, 120] loss: 0.101\n",
      "[56, 180] loss: 0.105\n",
      "[56, 240] loss: 0.100\n",
      "[56, 300] loss: 0.105\n",
      "[56, 360] loss: 0.102\n",
      "Epoch: 56 -> Loss: 0.0429081134498\n",
      "Epoch: 56 -> Test Accuracy: 86.66\n",
      "[57, 60] loss: 0.099\n",
      "[57, 120] loss: 0.100\n",
      "[57, 180] loss: 0.097\n",
      "[57, 240] loss: 0.102\n",
      "[57, 300] loss: 0.099\n",
      "[57, 360] loss: 0.101\n",
      "Epoch: 57 -> Loss: 0.085507825017\n",
      "Epoch: 57 -> Test Accuracy: 86.43\n",
      "[58, 60] loss: 0.105\n",
      "[58, 120] loss: 0.102\n",
      "[58, 180] loss: 0.107\n",
      "[58, 240] loss: 0.095\n",
      "[58, 300] loss: 0.094\n",
      "[58, 360] loss: 0.101\n",
      "Epoch: 58 -> Loss: 0.186266377568\n",
      "Epoch: 58 -> Test Accuracy: 86.62\n",
      "[59, 60] loss: 0.101\n",
      "[59, 120] loss: 0.105\n",
      "[59, 180] loss: 0.098\n",
      "[59, 240] loss: 0.099\n",
      "[59, 300] loss: 0.102\n",
      "[59, 360] loss: 0.102\n",
      "Epoch: 59 -> Loss: 0.116454288363\n",
      "Epoch: 59 -> Test Accuracy: 86.42\n",
      "[60, 60] loss: 0.110\n",
      "[60, 120] loss: 0.096\n",
      "[60, 180] loss: 0.101\n",
      "[60, 240] loss: 0.101\n",
      "[60, 300] loss: 0.101\n",
      "[60, 360] loss: 0.101\n",
      "Epoch: 60 -> Loss: 0.199208289385\n",
      "Epoch: 60 -> Test Accuracy: 86.56\n",
      "[61, 60] loss: 0.099\n",
      "[61, 120] loss: 0.089\n",
      "[61, 180] loss: 0.101\n",
      "[61, 240] loss: 0.097\n",
      "[61, 300] loss: 0.100\n",
      "[61, 360] loss: 0.096\n",
      "Epoch: 61 -> Loss: 0.229684591293\n",
      "Epoch: 61 -> Test Accuracy: 86.53\n",
      "[62, 60] loss: 0.093\n",
      "[62, 120] loss: 0.100\n",
      "[62, 180] loss: 0.096\n",
      "[62, 240] loss: 0.091\n",
      "[62, 300] loss: 0.105\n",
      "[62, 360] loss: 0.101\n",
      "Epoch: 62 -> Loss: 0.0992732420564\n",
      "Epoch: 62 -> Test Accuracy: 86.34\n",
      "[63, 60] loss: 0.098\n",
      "[63, 120] loss: 0.092\n",
      "[63, 180] loss: 0.096\n",
      "[63, 240] loss: 0.095\n",
      "[63, 300] loss: 0.097\n",
      "[63, 360] loss: 0.093\n",
      "Epoch: 63 -> Loss: 0.107236407697\n",
      "Epoch: 63 -> Test Accuracy: 86.44\n",
      "[64, 60] loss: 0.093\n",
      "[64, 120] loss: 0.096\n",
      "[64, 180] loss: 0.097\n",
      "[64, 240] loss: 0.096\n",
      "[64, 300] loss: 0.095\n",
      "[64, 360] loss: 0.099\n",
      "Epoch: 64 -> Loss: 0.141364723444\n",
      "Epoch: 64 -> Test Accuracy: 86.53\n",
      "[65, 60] loss: 0.097\n",
      "[65, 120] loss: 0.094\n",
      "[65, 180] loss: 0.103\n",
      "[65, 240] loss: 0.086\n",
      "[65, 300] loss: 0.089\n",
      "[65, 360] loss: 0.107\n",
      "Epoch: 65 -> Loss: 0.11465189606\n",
      "Epoch: 65 -> Test Accuracy: 86.36\n",
      "[66, 60] loss: 0.099\n",
      "[66, 120] loss: 0.098\n",
      "[66, 180] loss: 0.092\n",
      "[66, 240] loss: 0.088\n",
      "[66, 300] loss: 0.097\n",
      "[66, 360] loss: 0.091\n",
      "Epoch: 66 -> Loss: 0.126636952162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Test Accuracy: 86.49\n",
      "[67, 60] loss: 0.090\n",
      "[67, 120] loss: 0.089\n",
      "[67, 180] loss: 0.094\n",
      "[67, 240] loss: 0.091\n",
      "[67, 300] loss: 0.091\n",
      "[67, 360] loss: 0.097\n",
      "Epoch: 67 -> Loss: 0.0722390115261\n",
      "Epoch: 67 -> Test Accuracy: 86.52\n",
      "[68, 60] loss: 0.093\n",
      "[68, 120] loss: 0.090\n",
      "[68, 180] loss: 0.093\n",
      "[68, 240] loss: 0.095\n",
      "[68, 300] loss: 0.094\n",
      "[68, 360] loss: 0.097\n",
      "Epoch: 68 -> Loss: 0.0976048186421\n",
      "Epoch: 68 -> Test Accuracy: 86.5\n",
      "[69, 60] loss: 0.090\n",
      "[69, 120] loss: 0.094\n",
      "[69, 180] loss: 0.090\n",
      "[69, 240] loss: 0.098\n",
      "[69, 300] loss: 0.087\n",
      "[69, 360] loss: 0.090\n",
      "Epoch: 69 -> Loss: 0.124031342566\n",
      "Epoch: 69 -> Test Accuracy: 86.45\n",
      "[70, 60] loss: 0.094\n",
      "[70, 120] loss: 0.088\n",
      "[70, 180] loss: 0.090\n",
      "[70, 240] loss: 0.087\n",
      "[70, 300] loss: 0.089\n",
      "[70, 360] loss: 0.091\n",
      "Epoch: 70 -> Loss: 0.0749558657408\n",
      "Epoch: 70 -> Test Accuracy: 86.42\n",
      "[71, 60] loss: 0.092\n",
      "[71, 120] loss: 0.093\n",
      "[71, 180] loss: 0.086\n",
      "[71, 240] loss: 0.088\n",
      "[71, 300] loss: 0.084\n",
      "[71, 360] loss: 0.094\n",
      "Epoch: 71 -> Loss: 0.264926105738\n",
      "Epoch: 71 -> Test Accuracy: 86.61\n",
      "[72, 60] loss: 0.092\n",
      "[72, 120] loss: 0.083\n",
      "[72, 180] loss: 0.090\n",
      "[72, 240] loss: 0.089\n",
      "[72, 300] loss: 0.087\n",
      "[72, 360] loss: 0.090\n",
      "Epoch: 72 -> Loss: 0.0532714352012\n",
      "Epoch: 72 -> Test Accuracy: 86.57\n",
      "[73, 60] loss: 0.094\n",
      "[73, 120] loss: 0.092\n",
      "[73, 180] loss: 0.088\n",
      "[73, 240] loss: 0.092\n",
      "[73, 300] loss: 0.083\n",
      "[73, 360] loss: 0.090\n",
      "Epoch: 73 -> Loss: 0.0466169789433\n",
      "Epoch: 73 -> Test Accuracy: 86.54\n",
      "[74, 60] loss: 0.090\n",
      "[74, 120] loss: 0.087\n",
      "[74, 180] loss: 0.086\n",
      "[74, 240] loss: 0.092\n",
      "[74, 300] loss: 0.086\n",
      "[74, 360] loss: 0.088\n",
      "Epoch: 74 -> Loss: 0.0855236947536\n",
      "Epoch: 74 -> Test Accuracy: 86.55\n",
      "[75, 60] loss: 0.086\n",
      "[75, 120] loss: 0.088\n",
      "[75, 180] loss: 0.084\n",
      "[75, 240] loss: 0.090\n",
      "[75, 300] loss: 0.084\n",
      "[75, 360] loss: 0.087\n",
      "Epoch: 75 -> Loss: 0.0465160682797\n",
      "Epoch: 75 -> Test Accuracy: 86.55\n",
      "[76, 60] loss: 0.094\n",
      "[76, 120] loss: 0.088\n",
      "[76, 180] loss: 0.081\n",
      "[76, 240] loss: 0.087\n",
      "[76, 300] loss: 0.090\n",
      "[76, 360] loss: 0.093\n",
      "Epoch: 76 -> Loss: 0.0497290790081\n",
      "Epoch: 76 -> Test Accuracy: 86.56\n",
      "[77, 60] loss: 0.084\n",
      "[77, 120] loss: 0.089\n",
      "[77, 180] loss: 0.088\n",
      "[77, 240] loss: 0.080\n",
      "[77, 300] loss: 0.088\n",
      "[77, 360] loss: 0.088\n",
      "Epoch: 77 -> Loss: 0.0906545221806\n",
      "Epoch: 77 -> Test Accuracy: 86.48\n",
      "[78, 60] loss: 0.084\n",
      "[78, 120] loss: 0.084\n",
      "[78, 180] loss: 0.085\n",
      "[78, 240] loss: 0.083\n",
      "[78, 300] loss: 0.085\n",
      "[78, 360] loss: 0.094\n",
      "Epoch: 78 -> Loss: 0.121591173112\n",
      "Epoch: 78 -> Test Accuracy: 86.69\n",
      "[79, 60] loss: 0.078\n",
      "[79, 120] loss: 0.084\n",
      "[79, 180] loss: 0.083\n",
      "[79, 240] loss: 0.087\n",
      "[79, 300] loss: 0.094\n",
      "[79, 360] loss: 0.086\n",
      "Epoch: 79 -> Loss: 0.142673268914\n",
      "Epoch: 79 -> Test Accuracy: 86.56\n",
      "[80, 60] loss: 0.088\n",
      "[80, 120] loss: 0.083\n",
      "[80, 180] loss: 0.086\n",
      "[80, 240] loss: 0.090\n",
      "[80, 300] loss: 0.079\n",
      "[80, 360] loss: 0.082\n",
      "Epoch: 80 -> Loss: 0.0883778780699\n",
      "Epoch: 80 -> Test Accuracy: 86.63\n",
      "[81, 60] loss: 0.084\n",
      "[81, 120] loss: 0.085\n",
      "[81, 180] loss: 0.081\n",
      "[81, 240] loss: 0.085\n",
      "[81, 300] loss: 0.083\n",
      "[81, 360] loss: 0.087\n",
      "Epoch: 81 -> Loss: 0.0469513982534\n",
      "Epoch: 81 -> Test Accuracy: 86.6\n",
      "[82, 60] loss: 0.088\n",
      "[82, 120] loss: 0.083\n",
      "[82, 180] loss: 0.082\n",
      "[82, 240] loss: 0.088\n",
      "[82, 300] loss: 0.083\n",
      "[82, 360] loss: 0.087\n",
      "Epoch: 82 -> Loss: 0.0524021983147\n",
      "Epoch: 82 -> Test Accuracy: 86.54\n",
      "[83, 60] loss: 0.086\n",
      "[83, 120] loss: 0.086\n",
      "[83, 180] loss: 0.084\n",
      "[83, 240] loss: 0.079\n",
      "[83, 300] loss: 0.078\n",
      "[83, 360] loss: 0.088\n",
      "Epoch: 83 -> Loss: 0.116114482284\n",
      "Epoch: 83 -> Test Accuracy: 86.54\n",
      "[84, 60] loss: 0.075\n",
      "[84, 120] loss: 0.085\n",
      "[84, 180] loss: 0.078\n",
      "[84, 240] loss: 0.078\n",
      "[84, 300] loss: 0.085\n",
      "[84, 360] loss: 0.081\n",
      "Epoch: 84 -> Loss: 0.0494220852852\n",
      "Epoch: 84 -> Test Accuracy: 86.39\n",
      "[85, 60] loss: 0.085\n",
      "[85, 120] loss: 0.080\n",
      "[85, 180] loss: 0.085\n",
      "[85, 240] loss: 0.081\n",
      "[85, 300] loss: 0.085\n",
      "[85, 360] loss: 0.085\n",
      "Epoch: 85 -> Loss: 0.0958910509944\n",
      "Epoch: 85 -> Test Accuracy: 86.6\n",
      "[86, 60] loss: 0.074\n",
      "[86, 120] loss: 0.083\n",
      "[86, 180] loss: 0.081\n",
      "[86, 240] loss: 0.083\n",
      "[86, 300] loss: 0.080\n",
      "[86, 360] loss: 0.086\n",
      "Epoch: 86 -> Loss: 0.0433759093285\n",
      "Epoch: 86 -> Test Accuracy: 86.43\n",
      "[87, 60] loss: 0.079\n",
      "[87, 120] loss: 0.084\n",
      "[87, 180] loss: 0.083\n",
      "[87, 240] loss: 0.088\n",
      "[87, 300] loss: 0.080\n",
      "[87, 360] loss: 0.080\n",
      "Epoch: 87 -> Loss: 0.0512029603124\n",
      "Epoch: 87 -> Test Accuracy: 86.61\n",
      "[88, 60] loss: 0.077\n",
      "[88, 120] loss: 0.082\n",
      "[88, 180] loss: 0.082\n",
      "[88, 240] loss: 0.079\n",
      "[88, 300] loss: 0.079\n",
      "[88, 360] loss: 0.081\n",
      "Epoch: 88 -> Loss: 0.142117246985\n",
      "Epoch: 88 -> Test Accuracy: 86.45\n",
      "[89, 60] loss: 0.082\n",
      "[89, 120] loss: 0.078\n",
      "[89, 180] loss: 0.077\n",
      "[89, 240] loss: 0.078\n",
      "[89, 300] loss: 0.080\n",
      "[89, 360] loss: 0.078\n",
      "Epoch: 89 -> Loss: 0.0750356838107\n",
      "Epoch: 89 -> Test Accuracy: 86.61\n",
      "[90, 60] loss: 0.078\n",
      "[90, 120] loss: 0.077\n",
      "[90, 180] loss: 0.079\n",
      "[90, 240] loss: 0.079\n",
      "[90, 300] loss: 0.076\n",
      "[90, 360] loss: 0.075\n",
      "Epoch: 90 -> Loss: 0.0498711057007\n",
      "Epoch: 90 -> Test Accuracy: 86.61\n",
      "[91, 60] loss: 0.080\n",
      "[91, 120] loss: 0.077\n",
      "[91, 180] loss: 0.077\n",
      "[91, 240] loss: 0.077\n",
      "[91, 300] loss: 0.075\n",
      "[91, 360] loss: 0.080\n",
      "Epoch: 91 -> Loss: 0.189132228494\n",
      "Epoch: 91 -> Test Accuracy: 86.5\n",
      "[92, 60] loss: 0.075\n",
      "[92, 120] loss: 0.074\n",
      "[92, 180] loss: 0.075\n",
      "[92, 240] loss: 0.076\n",
      "[92, 300] loss: 0.085\n",
      "[92, 360] loss: 0.076\n",
      "Epoch: 92 -> Loss: 0.0656943097711\n",
      "Epoch: 92 -> Test Accuracy: 86.42\n",
      "[93, 60] loss: 0.075\n",
      "[93, 120] loss: 0.071\n",
      "[93, 180] loss: 0.076\n",
      "[93, 240] loss: 0.076\n",
      "[93, 300] loss: 0.076\n",
      "[93, 360] loss: 0.075\n",
      "Epoch: 93 -> Loss: 0.106649264693\n",
      "Epoch: 93 -> Test Accuracy: 86.51\n",
      "[94, 60] loss: 0.088\n",
      "[94, 120] loss: 0.072\n",
      "[94, 180] loss: 0.072\n",
      "[94, 240] loss: 0.074\n",
      "[94, 300] loss: 0.071\n",
      "[94, 360] loss: 0.081\n",
      "Epoch: 94 -> Loss: 0.119260944426\n",
      "Epoch: 94 -> Test Accuracy: 86.52\n",
      "[95, 60] loss: 0.076\n",
      "[95, 120] loss: 0.074\n",
      "[95, 180] loss: 0.078\n",
      "[95, 240] loss: 0.073\n",
      "[95, 300] loss: 0.076\n",
      "[95, 360] loss: 0.076\n",
      "Epoch: 95 -> Loss: 0.0358727164567\n",
      "Epoch: 95 -> Test Accuracy: 86.48\n",
      "[96, 60] loss: 0.077\n",
      "[96, 120] loss: 0.069\n",
      "[96, 180] loss: 0.074\n",
      "[96, 240] loss: 0.079\n",
      "[96, 300] loss: 0.075\n",
      "[96, 360] loss: 0.071\n",
      "Epoch: 96 -> Loss: 0.103197000921\n",
      "Epoch: 96 -> Test Accuracy: 86.7\n",
      "[97, 60] loss: 0.074\n",
      "[97, 120] loss: 0.075\n",
      "[97, 180] loss: 0.071\n",
      "[97, 240] loss: 0.079\n",
      "[97, 300] loss: 0.073\n",
      "[97, 360] loss: 0.076\n",
      "Epoch: 97 -> Loss: 0.157634466887\n",
      "Epoch: 97 -> Test Accuracy: 86.58\n",
      "[98, 60] loss: 0.078\n",
      "[98, 120] loss: 0.073\n",
      "[98, 180] loss: 0.066\n",
      "[98, 240] loss: 0.077\n",
      "[98, 300] loss: 0.078\n",
      "[98, 360] loss: 0.071\n",
      "Epoch: 98 -> Loss: 0.107171714306\n",
      "Epoch: 98 -> Test Accuracy: 86.53\n",
      "[99, 60] loss: 0.069\n",
      "[99, 120] loss: 0.075\n",
      "[99, 180] loss: 0.081\n",
      "[99, 240] loss: 0.074\n",
      "[99, 300] loss: 0.077\n",
      "[99, 360] loss: 0.068\n",
      "Epoch: 99 -> Loss: 0.254891574383\n",
      "Epoch: 99 -> Test Accuracy: 86.6\n",
      "[100, 60] loss: 0.074\n",
      "[100, 120] loss: 0.073\n",
      "[100, 180] loss: 0.076\n",
      "[100, 240] loss: 0.077\n",
      "[100, 300] loss: 0.078\n",
      "[100, 360] loss: 0.078\n",
      "Epoch: 100 -> Loss: 0.0800180584192\n",
      "Epoch: 100 -> Test Accuracy: 86.51\n",
      "Finished Training\n",
      "[1, 60] loss: 2.728\n",
      "[1, 120] loss: 1.803\n",
      "[1, 180] loss: 1.762\n",
      "[1, 240] loss: 1.721\n",
      "[1, 300] loss: 1.705\n",
      "[1, 360] loss: 1.687\n",
      "Epoch: 1 -> Loss: 1.52180790901\n",
      "Epoch: 1 -> Test Accuracy: 37.26\n",
      "[2, 60] loss: 1.664\n",
      "[2, 120] loss: 1.644\n",
      "[2, 180] loss: 1.637\n",
      "[2, 240] loss: 1.625\n",
      "[2, 300] loss: 1.591\n",
      "[2, 360] loss: 1.606\n",
      "Epoch: 2 -> Loss: 1.53919839859\n",
      "Epoch: 2 -> Test Accuracy: 40.21\n",
      "[3, 60] loss: 1.565\n",
      "[3, 120] loss: 1.564\n",
      "[3, 180] loss: 1.590\n",
      "[3, 240] loss: 1.567\n",
      "[3, 300] loss: 1.561\n",
      "[3, 360] loss: 1.553\n",
      "Epoch: 3 -> Loss: 1.50751459599\n",
      "Epoch: 3 -> Test Accuracy: 40.98\n",
      "[4, 60] loss: 1.559\n",
      "[4, 120] loss: 1.531\n",
      "[4, 180] loss: 1.526\n",
      "[4, 240] loss: 1.527\n",
      "[4, 300] loss: 1.523\n",
      "[4, 360] loss: 1.516\n",
      "Epoch: 4 -> Loss: 1.84346234798\n",
      "Epoch: 4 -> Test Accuracy: 42.62\n",
      "[5, 60] loss: 1.516\n",
      "[5, 120] loss: 1.522\n",
      "[5, 180] loss: 1.520\n",
      "[5, 240] loss: 1.507\n",
      "[5, 300] loss: 1.493\n",
      "[5, 360] loss: 1.504\n",
      "Epoch: 5 -> Loss: 1.55798828602\n",
      "Epoch: 5 -> Test Accuracy: 43.2\n",
      "[6, 60] loss: 1.506\n",
      "[6, 120] loss: 1.501\n",
      "[6, 180] loss: 1.493\n",
      "[6, 240] loss: 1.502\n",
      "[6, 300] loss: 1.496\n",
      "[6, 360] loss: 1.489\n",
      "Epoch: 6 -> Loss: 1.55128777027\n",
      "Epoch: 6 -> Test Accuracy: 44.04\n",
      "[7, 60] loss: 1.484\n",
      "[7, 120] loss: 1.479\n",
      "[7, 180] loss: 1.480\n",
      "[7, 240] loss: 1.489\n",
      "[7, 300] loss: 1.490\n",
      "[7, 360] loss: 1.497\n",
      "Epoch: 7 -> Loss: 1.38384413719\n",
      "Epoch: 7 -> Test Accuracy: 43.72\n",
      "[8, 60] loss: 1.477\n",
      "[8, 120] loss: 1.487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 180] loss: 1.476\n",
      "[8, 240] loss: 1.464\n",
      "[8, 300] loss: 1.475\n",
      "[8, 360] loss: 1.473\n",
      "Epoch: 8 -> Loss: 1.44293642044\n",
      "Epoch: 8 -> Test Accuracy: 43.53\n",
      "[9, 60] loss: 1.465\n",
      "[9, 120] loss: 1.465\n",
      "[9, 180] loss: 1.478\n",
      "[9, 240] loss: 1.463\n",
      "[9, 300] loss: 1.478\n",
      "[9, 360] loss: 1.462\n",
      "Epoch: 9 -> Loss: 1.58194768429\n",
      "Epoch: 9 -> Test Accuracy: 44.31\n",
      "[10, 60] loss: 1.480\n",
      "[10, 120] loss: 1.461\n",
      "[10, 180] loss: 1.447\n",
      "[10, 240] loss: 1.470\n",
      "[10, 300] loss: 1.470\n",
      "[10, 360] loss: 1.457\n",
      "Epoch: 10 -> Loss: 1.58967161179\n",
      "Epoch: 10 -> Test Accuracy: 44.39\n",
      "[11, 60] loss: 1.453\n",
      "[11, 120] loss: 1.458\n",
      "[11, 180] loss: 1.471\n",
      "[11, 240] loss: 1.458\n",
      "[11, 300] loss: 1.453\n",
      "[11, 360] loss: 1.481\n",
      "Epoch: 11 -> Loss: 1.41367149353\n",
      "Epoch: 11 -> Test Accuracy: 43.93\n",
      "[12, 60] loss: 1.469\n",
      "[12, 120] loss: 1.442\n",
      "[12, 180] loss: 1.453\n",
      "[12, 240] loss: 1.462\n",
      "[12, 300] loss: 1.472\n",
      "[12, 360] loss: 1.448\n",
      "Epoch: 12 -> Loss: 1.50912034512\n",
      "Epoch: 12 -> Test Accuracy: 45.51\n",
      "[13, 60] loss: 1.460\n",
      "[13, 120] loss: 1.454\n",
      "[13, 180] loss: 1.432\n",
      "[13, 240] loss: 1.463\n",
      "[13, 300] loss: 1.443\n",
      "[13, 360] loss: 1.472\n",
      "Epoch: 13 -> Loss: 1.46690046787\n",
      "Epoch: 13 -> Test Accuracy: 44.22\n",
      "[14, 60] loss: 1.442\n",
      "[14, 120] loss: 1.456\n",
      "[14, 180] loss: 1.473\n",
      "[14, 240] loss: 1.452\n",
      "[14, 300] loss: 1.442\n",
      "[14, 360] loss: 1.444\n",
      "Epoch: 14 -> Loss: 1.42689204216\n",
      "Epoch: 14 -> Test Accuracy: 44.5\n",
      "[15, 60] loss: 1.440\n",
      "[15, 120] loss: 1.459\n",
      "[15, 180] loss: 1.451\n",
      "[15, 240] loss: 1.440\n",
      "[15, 300] loss: 1.465\n",
      "[15, 360] loss: 1.448\n",
      "Epoch: 15 -> Loss: 1.5370644331\n",
      "Epoch: 15 -> Test Accuracy: 45.04\n",
      "[16, 60] loss: 1.444\n",
      "[16, 120] loss: 1.434\n",
      "[16, 180] loss: 1.449\n",
      "[16, 240] loss: 1.461\n",
      "[16, 300] loss: 1.434\n",
      "[16, 360] loss: 1.467\n",
      "Epoch: 16 -> Loss: 1.54545843601\n",
      "Epoch: 16 -> Test Accuracy: 45.42\n",
      "[17, 60] loss: 1.467\n",
      "[17, 120] loss: 1.426\n",
      "[17, 180] loss: 1.440\n",
      "[17, 240] loss: 1.458\n",
      "[17, 300] loss: 1.439\n",
      "[17, 360] loss: 1.445\n",
      "Epoch: 17 -> Loss: 1.40365207195\n",
      "Epoch: 17 -> Test Accuracy: 45.07\n",
      "[18, 60] loss: 1.464\n",
      "[18, 120] loss: 1.444\n",
      "[18, 180] loss: 1.432\n",
      "[18, 240] loss: 1.442\n",
      "[18, 300] loss: 1.439\n",
      "[18, 360] loss: 1.430\n",
      "Epoch: 18 -> Loss: 1.54345631599\n",
      "Epoch: 18 -> Test Accuracy: 45.02\n",
      "[19, 60] loss: 1.436\n",
      "[19, 120] loss: 1.438\n",
      "[19, 180] loss: 1.449\n",
      "[19, 240] loss: 1.448\n",
      "[19, 300] loss: 1.452\n",
      "[19, 360] loss: 1.458\n",
      "Epoch: 19 -> Loss: 1.54569327831\n",
      "Epoch: 19 -> Test Accuracy: 44.76\n",
      "[20, 60] loss: 1.443\n",
      "[20, 120] loss: 1.439\n",
      "[20, 180] loss: 1.439\n",
      "[20, 240] loss: 1.440\n",
      "[20, 300] loss: 1.434\n",
      "[20, 360] loss: 1.445\n",
      "Epoch: 20 -> Loss: 1.4499450922\n",
      "Epoch: 20 -> Test Accuracy: 44.51\n",
      "[21, 60] loss: 1.390\n",
      "[21, 120] loss: 1.365\n",
      "[21, 180] loss: 1.379\n",
      "[21, 240] loss: 1.349\n",
      "[21, 300] loss: 1.343\n",
      "[21, 360] loss: 1.330\n",
      "Epoch: 21 -> Loss: 1.20579361916\n",
      "Epoch: 21 -> Test Accuracy: 48.52\n",
      "[22, 60] loss: 1.311\n",
      "[22, 120] loss: 1.325\n",
      "[22, 180] loss: 1.327\n",
      "[22, 240] loss: 1.327\n",
      "[22, 300] loss: 1.317\n",
      "[22, 360] loss: 1.318\n",
      "Epoch: 22 -> Loss: 1.28634214401\n",
      "Epoch: 22 -> Test Accuracy: 49.25\n",
      "[23, 60] loss: 1.311\n",
      "[23, 120] loss: 1.300\n",
      "[23, 180] loss: 1.323\n",
      "[23, 240] loss: 1.301\n",
      "[23, 300] loss: 1.323\n",
      "[23, 360] loss: 1.313\n",
      "Epoch: 23 -> Loss: 1.2557246685\n",
      "Epoch: 23 -> Test Accuracy: 48.96\n",
      "[24, 60] loss: 1.288\n",
      "[24, 120] loss: 1.296\n",
      "[24, 180] loss: 1.312\n",
      "[24, 240] loss: 1.288\n",
      "[24, 300] loss: 1.303\n",
      "[24, 360] loss: 1.276\n",
      "Epoch: 24 -> Loss: 1.45214509964\n",
      "Epoch: 24 -> Test Accuracy: 49.58\n",
      "[25, 60] loss: 1.285\n",
      "[25, 120] loss: 1.310\n",
      "[25, 180] loss: 1.301\n",
      "[25, 240] loss: 1.305\n",
      "[25, 300] loss: 1.289\n",
      "[25, 360] loss: 1.311\n",
      "Epoch: 25 -> Loss: 1.18165540695\n",
      "Epoch: 25 -> Test Accuracy: 49.85\n",
      "[26, 60] loss: 1.289\n",
      "[26, 120] loss: 1.295\n",
      "[26, 180] loss: 1.272\n",
      "[26, 240] loss: 1.297\n",
      "[26, 300] loss: 1.296\n",
      "[26, 360] loss: 1.305\n",
      "Epoch: 26 -> Loss: 1.342638731\n",
      "Epoch: 26 -> Test Accuracy: 49.52\n",
      "[27, 60] loss: 1.299\n",
      "[27, 120] loss: 1.287\n",
      "[27, 180] loss: 1.279\n",
      "[27, 240] loss: 1.294\n",
      "[27, 300] loss: 1.299\n",
      "[27, 360] loss: 1.288\n",
      "Epoch: 27 -> Loss: 1.19322669506\n",
      "Epoch: 27 -> Test Accuracy: 49.5\n",
      "[28, 60] loss: 1.267\n",
      "[28, 120] loss: 1.301\n",
      "[28, 180] loss: 1.282\n",
      "[28, 240] loss: 1.282\n",
      "[28, 300] loss: 1.300\n",
      "[28, 360] loss: 1.298\n",
      "Epoch: 28 -> Loss: 1.40955781937\n",
      "Epoch: 28 -> Test Accuracy: 48.96\n",
      "[29, 60] loss: 1.263\n",
      "[29, 120] loss: 1.296\n",
      "[29, 180] loss: 1.287\n",
      "[29, 240] loss: 1.306\n",
      "[29, 300] loss: 1.296\n",
      "[29, 360] loss: 1.284\n",
      "Epoch: 29 -> Loss: 1.24729180336\n",
      "Epoch: 29 -> Test Accuracy: 49.11\n",
      "[30, 60] loss: 1.292\n",
      "[30, 120] loss: 1.310\n",
      "[30, 180] loss: 1.291\n",
      "[30, 240] loss: 1.283\n",
      "[30, 300] loss: 1.289\n",
      "[30, 360] loss: 1.281\n",
      "Epoch: 30 -> Loss: 1.07997095585\n",
      "Epoch: 30 -> Test Accuracy: 49.38\n",
      "[31, 60] loss: 1.292\n",
      "[31, 120] loss: 1.283\n",
      "[31, 180] loss: 1.282\n",
      "[31, 240] loss: 1.289\n",
      "[31, 300] loss: 1.289\n",
      "[31, 360] loss: 1.290\n",
      "Epoch: 31 -> Loss: 1.2045545578\n",
      "Epoch: 31 -> Test Accuracy: 50.4\n",
      "[32, 60] loss: 1.290\n",
      "[32, 120] loss: 1.273\n",
      "[32, 180] loss: 1.266\n",
      "[32, 240] loss: 1.285\n",
      "[32, 300] loss: 1.307\n",
      "[32, 360] loss: 1.281\n",
      "Epoch: 32 -> Loss: 1.08216369152\n",
      "Epoch: 32 -> Test Accuracy: 49.56\n",
      "[33, 60] loss: 1.251\n",
      "[33, 120] loss: 1.296\n",
      "[33, 180] loss: 1.269\n",
      "[33, 240] loss: 1.302\n",
      "[33, 300] loss: 1.294\n",
      "[33, 360] loss: 1.298\n",
      "Epoch: 33 -> Loss: 1.24276268482\n",
      "Epoch: 33 -> Test Accuracy: 49.55\n",
      "[34, 60] loss: 1.265\n",
      "[34, 120] loss: 1.276\n",
      "[34, 180] loss: 1.285\n",
      "[34, 240] loss: 1.277\n",
      "[34, 300] loss: 1.275\n",
      "[34, 360] loss: 1.284\n",
      "Epoch: 34 -> Loss: 1.29300177097\n",
      "Epoch: 34 -> Test Accuracy: 50.31\n",
      "[35, 60] loss: 1.271\n",
      "[35, 120] loss: 1.293\n",
      "[35, 180] loss: 1.297\n",
      "[35, 240] loss: 1.288\n",
      "[35, 300] loss: 1.273\n",
      "[35, 360] loss: 1.282\n",
      "Epoch: 35 -> Loss: 1.3820245266\n",
      "Epoch: 35 -> Test Accuracy: 49.5\n",
      "[36, 60] loss: 1.278\n",
      "[36, 120] loss: 1.281\n",
      "[36, 180] loss: 1.269\n",
      "[36, 240] loss: 1.286\n",
      "[36, 300] loss: 1.298\n",
      "[36, 360] loss: 1.284\n",
      "Epoch: 36 -> Loss: 1.44006991386\n",
      "Epoch: 36 -> Test Accuracy: 49.84\n",
      "[37, 60] loss: 1.275\n",
      "[37, 120] loss: 1.285\n",
      "[37, 180] loss: 1.307\n",
      "[37, 240] loss: 1.279\n",
      "[37, 300] loss: 1.267\n",
      "[37, 360] loss: 1.281\n",
      "Epoch: 37 -> Loss: 1.30595421791\n",
      "Epoch: 37 -> Test Accuracy: 49.44\n",
      "[38, 60] loss: 1.291\n",
      "[38, 120] loss: 1.258\n",
      "[38, 180] loss: 1.266\n",
      "[38, 240] loss: 1.292\n",
      "[38, 300] loss: 1.259\n",
      "[38, 360] loss: 1.290\n",
      "Epoch: 38 -> Loss: 1.15272068977\n",
      "Epoch: 38 -> Test Accuracy: 48.94\n",
      "[39, 60] loss: 1.287\n",
      "[39, 120] loss: 1.297\n",
      "[39, 180] loss: 1.273\n",
      "[39, 240] loss: 1.272\n",
      "[39, 300] loss: 1.260\n",
      "[39, 360] loss: 1.288\n",
      "Epoch: 39 -> Loss: 1.43694400787\n",
      "Epoch: 39 -> Test Accuracy: 50.06\n",
      "[40, 60] loss: 1.276\n",
      "[40, 120] loss: 1.264\n",
      "[40, 180] loss: 1.261\n",
      "[40, 240] loss: 1.286\n",
      "[40, 300] loss: 1.279\n",
      "[40, 360] loss: 1.279\n",
      "Epoch: 40 -> Loss: 1.37329339981\n",
      "Epoch: 40 -> Test Accuracy: 49.91\n",
      "[41, 60] loss: 1.243\n",
      "[41, 120] loss: 1.235\n",
      "[41, 180] loss: 1.220\n",
      "[41, 240] loss: 1.211\n",
      "[41, 300] loss: 1.230\n",
      "[41, 360] loss: 1.229\n",
      "Epoch: 41 -> Loss: 1.22143793106\n",
      "Epoch: 41 -> Test Accuracy: 52.09\n",
      "[42, 60] loss: 1.219\n",
      "[42, 120] loss: 1.216\n",
      "[42, 180] loss: 1.210\n",
      "[42, 240] loss: 1.188\n",
      "[42, 300] loss: 1.198\n",
      "[42, 360] loss: 1.196\n",
      "Epoch: 42 -> Loss: 1.20635735989\n",
      "Epoch: 42 -> Test Accuracy: 52.29\n",
      "[43, 60] loss: 1.213\n",
      "[43, 120] loss: 1.209\n",
      "[43, 180] loss: 1.196\n",
      "[43, 240] loss: 1.181\n",
      "[43, 300] loss: 1.180\n",
      "[43, 360] loss: 1.197\n",
      "Epoch: 43 -> Loss: 1.05017518997\n",
      "Epoch: 43 -> Test Accuracy: 52.48\n",
      "[44, 60] loss: 1.185\n",
      "[44, 120] loss: 1.188\n",
      "[44, 180] loss: 1.186\n",
      "[44, 240] loss: 1.203\n",
      "[44, 300] loss: 1.192\n",
      "[44, 360] loss: 1.204\n",
      "Epoch: 44 -> Loss: 1.16620528698\n",
      "Epoch: 44 -> Test Accuracy: 52.36\n",
      "[45, 60] loss: 1.197\n",
      "[45, 120] loss: 1.202\n",
      "[45, 180] loss: 1.183\n",
      "[45, 240] loss: 1.192\n",
      "[45, 300] loss: 1.181\n",
      "[45, 360] loss: 1.180\n",
      "Epoch: 45 -> Loss: 1.24895977974\n",
      "Epoch: 45 -> Test Accuracy: 52.13\n",
      "[46, 60] loss: 1.174\n",
      "[46, 120] loss: 1.196\n",
      "[46, 180] loss: 1.174\n",
      "[46, 240] loss: 1.178\n",
      "[46, 300] loss: 1.176\n",
      "[46, 360] loss: 1.187\n",
      "Epoch: 46 -> Loss: 1.15635371208\n",
      "Epoch: 46 -> Test Accuracy: 52.73\n",
      "[47, 60] loss: 1.169\n",
      "[47, 120] loss: 1.173\n",
      "[47, 180] loss: 1.158\n",
      "[47, 240] loss: 1.159\n",
      "[47, 300] loss: 1.186\n",
      "[47, 360] loss: 1.170\n",
      "Epoch: 47 -> Loss: 1.25530695915\n",
      "Epoch: 47 -> Test Accuracy: 52.82\n",
      "[48, 60] loss: 1.161\n",
      "[48, 120] loss: 1.172\n",
      "[48, 180] loss: 1.148\n",
      "[48, 240] loss: 1.169\n",
      "[48, 300] loss: 1.155\n",
      "[48, 360] loss: 1.173\n",
      "Epoch: 48 -> Loss: 1.15647470951\n",
      "Epoch: 48 -> Test Accuracy: 53.03\n",
      "[49, 60] loss: 1.180\n",
      "[49, 120] loss: 1.167\n",
      "[49, 180] loss: 1.144\n",
      "[49, 240] loss: 1.184\n",
      "[49, 300] loss: 1.153\n",
      "[49, 360] loss: 1.154\n",
      "Epoch: 49 -> Loss: 1.02462029457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49 -> Test Accuracy: 53.06\n",
      "[50, 60] loss: 1.152\n",
      "[50, 120] loss: 1.154\n",
      "[50, 180] loss: 1.148\n",
      "[50, 240] loss: 1.178\n",
      "[50, 300] loss: 1.159\n",
      "[50, 360] loss: 1.159\n",
      "Epoch: 50 -> Loss: 1.01887559891\n",
      "Epoch: 50 -> Test Accuracy: 53.1\n",
      "[51, 60] loss: 1.158\n",
      "[51, 120] loss: 1.145\n",
      "[51, 180] loss: 1.157\n",
      "[51, 240] loss: 1.177\n",
      "[51, 300] loss: 1.156\n",
      "[51, 360] loss: 1.163\n",
      "Epoch: 51 -> Loss: 1.36545753479\n",
      "Epoch: 51 -> Test Accuracy: 53.01\n",
      "[52, 60] loss: 1.170\n",
      "[52, 120] loss: 1.165\n",
      "[52, 180] loss: 1.155\n",
      "[52, 240] loss: 1.168\n",
      "[52, 300] loss: 1.157\n",
      "[52, 360] loss: 1.160\n",
      "Epoch: 52 -> Loss: 1.01275980473\n",
      "Epoch: 52 -> Test Accuracy: 53.23\n",
      "[53, 60] loss: 1.151\n",
      "[53, 120] loss: 1.154\n",
      "[53, 180] loss: 1.165\n",
      "[53, 240] loss: 1.142\n",
      "[53, 300] loss: 1.161\n",
      "[53, 360] loss: 1.172\n",
      "Epoch: 53 -> Loss: 1.24386143684\n",
      "Epoch: 53 -> Test Accuracy: 53.2\n",
      "[54, 60] loss: 1.126\n",
      "[54, 120] loss: 1.158\n",
      "[54, 180] loss: 1.130\n",
      "[54, 240] loss: 1.156\n",
      "[54, 300] loss: 1.164\n",
      "[54, 360] loss: 1.165\n",
      "Epoch: 54 -> Loss: 1.104996562\n",
      "Epoch: 54 -> Test Accuracy: 53.26\n",
      "[55, 60] loss: 1.175\n",
      "[55, 120] loss: 1.154\n",
      "[55, 180] loss: 1.152\n",
      "[55, 240] loss: 1.156\n",
      "[55, 300] loss: 1.136\n",
      "[55, 360] loss: 1.138\n",
      "Epoch: 55 -> Loss: 1.11907505989\n",
      "Epoch: 55 -> Test Accuracy: 53.21\n",
      "[56, 60] loss: 1.147\n",
      "[56, 120] loss: 1.183\n",
      "[56, 180] loss: 1.155\n",
      "[56, 240] loss: 1.149\n",
      "[56, 300] loss: 1.156\n",
      "[56, 360] loss: 1.154\n",
      "Epoch: 56 -> Loss: 1.12735331059\n",
      "Epoch: 56 -> Test Accuracy: 53.32\n",
      "[57, 60] loss: 1.143\n",
      "[57, 120] loss: 1.138\n",
      "[57, 180] loss: 1.153\n",
      "[57, 240] loss: 1.162\n",
      "[57, 300] loss: 1.154\n",
      "[57, 360] loss: 1.143\n",
      "Epoch: 57 -> Loss: 1.07067346573\n",
      "Epoch: 57 -> Test Accuracy: 53.12\n",
      "[58, 60] loss: 1.150\n",
      "[58, 120] loss: 1.152\n",
      "[58, 180] loss: 1.143\n",
      "[58, 240] loss: 1.157\n",
      "[58, 300] loss: 1.154\n",
      "[58, 360] loss: 1.156\n",
      "Epoch: 58 -> Loss: 1.20118761063\n",
      "Epoch: 58 -> Test Accuracy: 53.73\n",
      "[59, 60] loss: 1.155\n",
      "[59, 120] loss: 1.143\n",
      "[59, 180] loss: 1.137\n",
      "[59, 240] loss: 1.162\n",
      "[59, 300] loss: 1.144\n",
      "[59, 360] loss: 1.154\n",
      "Epoch: 59 -> Loss: 1.18427968025\n",
      "Epoch: 59 -> Test Accuracy: 53.41\n",
      "[60, 60] loss: 1.153\n",
      "[60, 120] loss: 1.148\n",
      "[60, 180] loss: 1.152\n",
      "[60, 240] loss: 1.149\n",
      "[60, 300] loss: 1.133\n",
      "[60, 360] loss: 1.184\n",
      "Epoch: 60 -> Loss: 1.13069331646\n",
      "Epoch: 60 -> Test Accuracy: 53.65\n",
      "[61, 60] loss: 1.161\n",
      "[61, 120] loss: 1.144\n",
      "[61, 180] loss: 1.146\n",
      "[61, 240] loss: 1.138\n",
      "[61, 300] loss: 1.159\n",
      "[61, 360] loss: 1.142\n",
      "Epoch: 61 -> Loss: 1.14365255833\n",
      "Epoch: 61 -> Test Accuracy: 53.59\n",
      "[62, 60] loss: 1.143\n",
      "[62, 120] loss: 1.140\n",
      "[62, 180] loss: 1.155\n",
      "[62, 240] loss: 1.138\n",
      "[62, 300] loss: 1.152\n",
      "[62, 360] loss: 1.145\n",
      "Epoch: 62 -> Loss: 1.13571286201\n",
      "Epoch: 62 -> Test Accuracy: 53.6\n",
      "[63, 60] loss: 1.148\n",
      "[63, 120] loss: 1.157\n",
      "[63, 180] loss: 1.155\n",
      "[63, 240] loss: 1.143\n",
      "[63, 300] loss: 1.128\n",
      "[63, 360] loss: 1.150\n",
      "Epoch: 63 -> Loss: 1.21636080742\n",
      "Epoch: 63 -> Test Accuracy: 53.39\n",
      "[64, 60] loss: 1.145\n",
      "[64, 120] loss: 1.160\n",
      "[64, 180] loss: 1.127\n",
      "[64, 240] loss: 1.149\n",
      "[64, 300] loss: 1.145\n",
      "[64, 360] loss: 1.168\n",
      "Epoch: 64 -> Loss: 1.04232823849\n",
      "Epoch: 64 -> Test Accuracy: 53.85\n",
      "[65, 60] loss: 1.141\n",
      "[65, 120] loss: 1.139\n",
      "[65, 180] loss: 1.148\n",
      "[65, 240] loss: 1.135\n",
      "[65, 300] loss: 1.136\n",
      "[65, 360] loss: 1.153\n",
      "Epoch: 65 -> Loss: 1.18509340286\n",
      "Epoch: 65 -> Test Accuracy: 53.51\n",
      "[66, 60] loss: 1.137\n",
      "[66, 120] loss: 1.151\n",
      "[66, 180] loss: 1.158\n",
      "[66, 240] loss: 1.136\n",
      "[66, 300] loss: 1.131\n",
      "[66, 360] loss: 1.143\n",
      "Epoch: 66 -> Loss: 1.11153292656\n",
      "Epoch: 66 -> Test Accuracy: 53.58\n",
      "[67, 60] loss: 1.126\n",
      "[67, 120] loss: 1.166\n",
      "[67, 180] loss: 1.139\n",
      "[67, 240] loss: 1.155\n",
      "[67, 300] loss: 1.129\n",
      "[67, 360] loss: 1.154\n",
      "Epoch: 67 -> Loss: 1.34183907509\n",
      "Epoch: 67 -> Test Accuracy: 53.62\n",
      "[68, 60] loss: 1.153\n",
      "[68, 120] loss: 1.138\n",
      "[68, 180] loss: 1.126\n",
      "[68, 240] loss: 1.159\n",
      "[68, 300] loss: 1.139\n",
      "[68, 360] loss: 1.133\n",
      "Epoch: 68 -> Loss: 1.1199092865\n",
      "Epoch: 68 -> Test Accuracy: 53.69\n",
      "[69, 60] loss: 1.148\n",
      "[69, 120] loss: 1.126\n",
      "[69, 180] loss: 1.155\n",
      "[69, 240] loss: 1.129\n",
      "[69, 300] loss: 1.150\n",
      "[69, 360] loss: 1.146\n",
      "Epoch: 69 -> Loss: 1.30785059929\n",
      "Epoch: 69 -> Test Accuracy: 53.72\n",
      "[70, 60] loss: 1.159\n",
      "[70, 120] loss: 1.147\n",
      "[70, 180] loss: 1.123\n",
      "[70, 240] loss: 1.141\n",
      "[70, 300] loss: 1.126\n",
      "[70, 360] loss: 1.146\n",
      "Epoch: 70 -> Loss: 1.14509820938\n",
      "Epoch: 70 -> Test Accuracy: 53.64\n",
      "[71, 60] loss: 1.130\n",
      "[71, 120] loss: 1.149\n",
      "[71, 180] loss: 1.148\n",
      "[71, 240] loss: 1.131\n",
      "[71, 300] loss: 1.147\n",
      "[71, 360] loss: 1.149\n",
      "Epoch: 71 -> Loss: 1.16714203358\n",
      "Epoch: 71 -> Test Accuracy: 53.67\n",
      "[72, 60] loss: 1.148\n",
      "[72, 120] loss: 1.151\n",
      "[72, 180] loss: 1.148\n",
      "[72, 240] loss: 1.147\n",
      "[72, 300] loss: 1.151\n",
      "[72, 360] loss: 1.129\n",
      "Epoch: 72 -> Loss: 1.25139403343\n",
      "Epoch: 72 -> Test Accuracy: 53.52\n",
      "[73, 60] loss: 1.132\n",
      "[73, 120] loss: 1.132\n",
      "[73, 180] loss: 1.145\n",
      "[73, 240] loss: 1.145\n",
      "[73, 300] loss: 1.155\n",
      "[73, 360] loss: 1.129\n",
      "Epoch: 73 -> Loss: 1.00747525692\n",
      "Epoch: 73 -> Test Accuracy: 53.7\n",
      "[74, 60] loss: 1.147\n",
      "[74, 120] loss: 1.131\n",
      "[74, 180] loss: 1.149\n",
      "[74, 240] loss: 1.129\n",
      "[74, 300] loss: 1.148\n",
      "[74, 360] loss: 1.133\n",
      "Epoch: 74 -> Loss: 1.15051519871\n",
      "Epoch: 74 -> Test Accuracy: 53.53\n",
      "[75, 60] loss: 1.149\n",
      "[75, 120] loss: 1.149\n",
      "[75, 180] loss: 1.135\n",
      "[75, 240] loss: 1.133\n",
      "[75, 300] loss: 1.164\n",
      "[75, 360] loss: 1.124\n",
      "Epoch: 75 -> Loss: 1.25675094128\n",
      "Epoch: 75 -> Test Accuracy: 53.54\n",
      "[76, 60] loss: 1.145\n",
      "[76, 120] loss: 1.133\n",
      "[76, 180] loss: 1.144\n",
      "[76, 240] loss: 1.135\n",
      "[76, 300] loss: 1.127\n",
      "[76, 360] loss: 1.135\n",
      "Epoch: 76 -> Loss: 1.25496768951\n",
      "Epoch: 76 -> Test Accuracy: 53.44\n",
      "[77, 60] loss: 1.115\n",
      "[77, 120] loss: 1.136\n",
      "[77, 180] loss: 1.138\n",
      "[77, 240] loss: 1.126\n",
      "[77, 300] loss: 1.140\n",
      "[77, 360] loss: 1.151\n",
      "Epoch: 77 -> Loss: 1.1774790287\n",
      "Epoch: 77 -> Test Accuracy: 53.59\n",
      "[78, 60] loss: 1.157\n",
      "[78, 120] loss: 1.123\n",
      "[78, 180] loss: 1.119\n",
      "[78, 240] loss: 1.122\n",
      "[78, 300] loss: 1.118\n",
      "[78, 360] loss: 1.147\n",
      "Epoch: 78 -> Loss: 1.1962954998\n",
      "Epoch: 78 -> Test Accuracy: 53.46\n",
      "[79, 60] loss: 1.133\n",
      "[79, 120] loss: 1.137\n",
      "[79, 180] loss: 1.149\n",
      "[79, 240] loss: 1.150\n",
      "[79, 300] loss: 1.124\n",
      "[79, 360] loss: 1.130\n",
      "Epoch: 79 -> Loss: 1.25926578045\n",
      "Epoch: 79 -> Test Accuracy: 53.64\n",
      "[80, 60] loss: 1.127\n",
      "[80, 120] loss: 1.124\n",
      "[80, 180] loss: 1.157\n",
      "[80, 240] loss: 1.112\n",
      "[80, 300] loss: 1.153\n",
      "[80, 360] loss: 1.130\n",
      "Epoch: 80 -> Loss: 1.18208158016\n",
      "Epoch: 80 -> Test Accuracy: 53.63\n",
      "[81, 60] loss: 1.117\n",
      "[81, 120] loss: 1.156\n",
      "[81, 180] loss: 1.124\n",
      "[81, 240] loss: 1.121\n",
      "[81, 300] loss: 1.144\n",
      "[81, 360] loss: 1.134\n",
      "Epoch: 81 -> Loss: 1.16944134235\n",
      "Epoch: 81 -> Test Accuracy: 53.72\n",
      "[82, 60] loss: 1.122\n",
      "[82, 120] loss: 1.111\n",
      "[82, 180] loss: 1.142\n",
      "[82, 240] loss: 1.128\n",
      "[82, 300] loss: 1.127\n",
      "[82, 360] loss: 1.156\n",
      "Epoch: 82 -> Loss: 1.12954199314\n",
      "Epoch: 82 -> Test Accuracy: 53.77\n",
      "[83, 60] loss: 1.146\n",
      "[83, 120] loss: 1.129\n",
      "[83, 180] loss: 1.141\n",
      "[83, 240] loss: 1.145\n",
      "[83, 300] loss: 1.125\n",
      "[83, 360] loss: 1.123\n",
      "Epoch: 83 -> Loss: 1.12353086472\n",
      "Epoch: 83 -> Test Accuracy: 53.68\n",
      "[84, 60] loss: 1.125\n",
      "[84, 120] loss: 1.138\n",
      "[84, 180] loss: 1.117\n",
      "[84, 240] loss: 1.119\n",
      "[84, 300] loss: 1.103\n",
      "[84, 360] loss: 1.155\n",
      "Epoch: 84 -> Loss: 1.06623804569\n",
      "Epoch: 84 -> Test Accuracy: 53.4\n",
      "[85, 60] loss: 1.172\n",
      "[85, 120] loss: 1.140\n",
      "[85, 180] loss: 1.127\n",
      "[85, 240] loss: 1.144\n",
      "[85, 300] loss: 1.121\n",
      "[85, 360] loss: 1.126\n",
      "Epoch: 85 -> Loss: 1.21346509457\n",
      "Epoch: 85 -> Test Accuracy: 53.92\n",
      "[86, 60] loss: 1.119\n",
      "[86, 120] loss: 1.139\n",
      "[86, 180] loss: 1.129\n",
      "[86, 240] loss: 1.126\n",
      "[86, 300] loss: 1.136\n",
      "[86, 360] loss: 1.134\n",
      "Epoch: 86 -> Loss: 1.1310646534\n",
      "Epoch: 86 -> Test Accuracy: 53.52\n",
      "[87, 60] loss: 1.121\n",
      "[87, 120] loss: 1.119\n",
      "[87, 180] loss: 1.146\n",
      "[87, 240] loss: 1.142\n",
      "[87, 300] loss: 1.117\n",
      "[87, 360] loss: 1.149\n",
      "Epoch: 87 -> Loss: 1.17439734936\n",
      "Epoch: 87 -> Test Accuracy: 53.7\n",
      "[88, 60] loss: 1.134\n",
      "[88, 120] loss: 1.140\n",
      "[88, 180] loss: 1.125\n",
      "[88, 240] loss: 1.131\n",
      "[88, 300] loss: 1.134\n",
      "[88, 360] loss: 1.128\n",
      "Epoch: 88 -> Loss: 1.14962530136\n",
      "Epoch: 88 -> Test Accuracy: 54.18\n",
      "[89, 60] loss: 1.120\n",
      "[89, 120] loss: 1.138\n",
      "[89, 180] loss: 1.125\n",
      "[89, 240] loss: 1.129\n",
      "[89, 300] loss: 1.125\n",
      "[89, 360] loss: 1.122\n",
      "Epoch: 89 -> Loss: 1.06909906864\n",
      "Epoch: 89 -> Test Accuracy: 53.87\n",
      "[90, 60] loss: 1.138\n",
      "[90, 120] loss: 1.121\n",
      "[90, 180] loss: 1.117\n",
      "[90, 240] loss: 1.131\n",
      "[90, 300] loss: 1.153\n",
      "[90, 360] loss: 1.127\n",
      "Epoch: 90 -> Loss: 0.968562722206\n",
      "Epoch: 90 -> Test Accuracy: 53.92\n",
      "[91, 60] loss: 1.131\n",
      "[91, 120] loss: 1.122\n",
      "[91, 180] loss: 1.118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[91, 240] loss: 1.140\n",
      "[91, 300] loss: 1.108\n",
      "[91, 360] loss: 1.129\n",
      "Epoch: 91 -> Loss: 1.174051404\n",
      "Epoch: 91 -> Test Accuracy: 53.87\n",
      "[92, 60] loss: 1.144\n",
      "[92, 120] loss: 1.129\n",
      "[92, 180] loss: 1.132\n",
      "[92, 240] loss: 1.123\n",
      "[92, 300] loss: 1.128\n",
      "[92, 360] loss: 1.119\n",
      "Epoch: 92 -> Loss: 1.17889094353\n",
      "Epoch: 92 -> Test Accuracy: 53.6\n",
      "[93, 60] loss: 1.131\n",
      "[93, 120] loss: 1.130\n",
      "[93, 180] loss: 1.109\n",
      "[93, 240] loss: 1.120\n",
      "[93, 300] loss: 1.127\n",
      "[93, 360] loss: 1.142\n",
      "Epoch: 93 -> Loss: 0.920753359795\n",
      "Epoch: 93 -> Test Accuracy: 53.92\n",
      "[94, 60] loss: 1.133\n",
      "[94, 120] loss: 1.138\n",
      "[94, 180] loss: 1.126\n",
      "[94, 240] loss: 1.136\n",
      "[94, 300] loss: 1.139\n",
      "[94, 360] loss: 1.125\n",
      "Epoch: 94 -> Loss: 1.15011847019\n",
      "Epoch: 94 -> Test Accuracy: 53.95\n",
      "[95, 60] loss: 1.127\n",
      "[95, 120] loss: 1.141\n",
      "[95, 180] loss: 1.115\n",
      "[95, 240] loss: 1.126\n",
      "[95, 300] loss: 1.118\n",
      "[95, 360] loss: 1.151\n",
      "Epoch: 95 -> Loss: 1.27565062046\n",
      "Epoch: 95 -> Test Accuracy: 54.02\n",
      "[96, 60] loss: 1.117\n",
      "[96, 120] loss: 1.108\n",
      "[96, 180] loss: 1.125\n",
      "[96, 240] loss: 1.121\n",
      "[96, 300] loss: 1.119\n",
      "[96, 360] loss: 1.129\n",
      "Epoch: 96 -> Loss: 1.32816052437\n",
      "Epoch: 96 -> Test Accuracy: 54.13\n",
      "[97, 60] loss: 1.134\n",
      "[97, 120] loss: 1.155\n",
      "[97, 180] loss: 1.109\n",
      "[97, 240] loss: 1.127\n",
      "[97, 300] loss: 1.130\n",
      "[97, 360] loss: 1.130\n",
      "Epoch: 97 -> Loss: 1.05178713799\n",
      "Epoch: 97 -> Test Accuracy: 54.07\n",
      "[98, 60] loss: 1.100\n",
      "[98, 120] loss: 1.136\n",
      "[98, 180] loss: 1.123\n",
      "[98, 240] loss: 1.109\n",
      "[98, 300] loss: 1.129\n",
      "[98, 360] loss: 1.098\n",
      "Epoch: 98 -> Loss: 1.00269603729\n",
      "Epoch: 98 -> Test Accuracy: 54.09\n",
      "[99, 60] loss: 1.130\n",
      "[99, 120] loss: 1.112\n",
      "[99, 180] loss: 1.125\n",
      "[99, 240] loss: 1.124\n",
      "[99, 300] loss: 1.121\n",
      "[99, 360] loss: 1.140\n",
      "Epoch: 99 -> Loss: 1.08698892593\n",
      "Epoch: 99 -> Test Accuracy: 54.22\n",
      "[100, 60] loss: 1.101\n",
      "[100, 120] loss: 1.119\n",
      "[100, 180] loss: 1.129\n",
      "[100, 240] loss: 1.129\n",
      "[100, 300] loss: 1.136\n",
      "[100, 360] loss: 1.118\n",
      "Epoch: 100 -> Loss: 1.34540462494\n",
      "Epoch: 100 -> Test Accuracy: 54.07\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train NonLinearClassifiers on feature map of net_3block\n",
    "block3_loss_log, _, block3_test_accuracy_log, _, _ = tr.train_all_blocks(3, 10, [0.1, 0.02, 0.004, 0.0008], \n",
    "    [20, 40, 45, 100], 0.9, 5e-4, net_block3, criterion, trainloader, None, testloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.371\n",
      "[1, 120] loss: 1.023\n",
      "[1, 180] loss: 0.913\n",
      "[1, 240] loss: 0.887\n",
      "[1, 300] loss: 0.824\n",
      "[1, 360] loss: 0.783\n",
      "Epoch: 1 -> Loss: 0.617035627365\n",
      "Epoch: 1 -> Test Accuracy: 70.87\n",
      "[2, 60] loss: 0.747\n",
      "[2, 120] loss: 0.703\n",
      "[2, 180] loss: 0.689\n",
      "[2, 240] loss: 0.676\n",
      "[2, 300] loss: 0.673\n",
      "[2, 360] loss: 0.660\n",
      "Epoch: 2 -> Loss: 0.749189436436\n",
      "Epoch: 2 -> Test Accuracy: 74.43\n",
      "[3, 60] loss: 0.627\n",
      "[3, 120] loss: 0.612\n",
      "[3, 180] loss: 0.619\n",
      "[3, 240] loss: 0.611\n",
      "[3, 300] loss: 0.628\n",
      "[3, 360] loss: 0.587\n",
      "Epoch: 3 -> Loss: 0.666461706161\n",
      "Epoch: 3 -> Test Accuracy: 77.75\n",
      "[4, 60] loss: 0.566\n",
      "[4, 120] loss: 0.570\n",
      "[4, 180] loss: 0.566\n",
      "[4, 240] loss: 0.556\n",
      "[4, 300] loss: 0.553\n",
      "[4, 360] loss: 0.576\n",
      "Epoch: 4 -> Loss: 0.634184956551\n",
      "Epoch: 4 -> Test Accuracy: 77.39\n",
      "[5, 60] loss: 0.521\n",
      "[5, 120] loss: 0.541\n",
      "[5, 180] loss: 0.559\n",
      "[5, 240] loss: 0.535\n",
      "[5, 300] loss: 0.520\n",
      "[5, 360] loss: 0.528\n",
      "Epoch: 5 -> Loss: 0.685723721981\n",
      "Epoch: 5 -> Test Accuracy: 78.43\n",
      "[6, 60] loss: 0.509\n",
      "[6, 120] loss: 0.506\n",
      "[6, 180] loss: 0.529\n",
      "[6, 240] loss: 0.504\n",
      "[6, 300] loss: 0.516\n",
      "[6, 360] loss: 0.521\n",
      "Epoch: 6 -> Loss: 0.714321732521\n",
      "Epoch: 6 -> Test Accuracy: 77.98\n",
      "[7, 60] loss: 0.514\n",
      "[7, 120] loss: 0.508\n",
      "[7, 180] loss: 0.497\n",
      "[7, 240] loss: 0.484\n",
      "[7, 300] loss: 0.491\n",
      "[7, 360] loss: 0.506\n",
      "Epoch: 7 -> Loss: 0.479330956936\n",
      "Epoch: 7 -> Test Accuracy: 79.51\n",
      "[8, 60] loss: 0.460\n",
      "[8, 120] loss: 0.470\n",
      "[8, 180] loss: 0.499\n",
      "[8, 240] loss: 0.493\n",
      "[8, 300] loss: 0.505\n",
      "[8, 360] loss: 0.483\n",
      "Epoch: 8 -> Loss: 0.708630979061\n",
      "Epoch: 8 -> Test Accuracy: 79.96\n",
      "[9, 60] loss: 0.445\n",
      "[9, 120] loss: 0.464\n",
      "[9, 180] loss: 0.486\n",
      "[9, 240] loss: 0.468\n",
      "[9, 300] loss: 0.493\n",
      "[9, 360] loss: 0.472\n",
      "Epoch: 9 -> Loss: 0.668149590492\n",
      "Epoch: 9 -> Test Accuracy: 80.27\n",
      "[10, 60] loss: 0.449\n",
      "[10, 120] loss: 0.466\n",
      "[10, 180] loss: 0.485\n",
      "[10, 240] loss: 0.492\n",
      "[10, 300] loss: 0.481\n",
      "[10, 360] loss: 0.469\n",
      "Epoch: 10 -> Loss: 0.470273196697\n",
      "Epoch: 10 -> Test Accuracy: 80.33\n",
      "[11, 60] loss: 0.439\n",
      "[11, 120] loss: 0.468\n",
      "[11, 180] loss: 0.455\n",
      "[11, 240] loss: 0.461\n",
      "[11, 300] loss: 0.471\n",
      "[11, 360] loss: 0.454\n",
      "Epoch: 11 -> Loss: 0.494262129068\n",
      "Epoch: 11 -> Test Accuracy: 80.4\n",
      "[12, 60] loss: 0.447\n",
      "[12, 120] loss: 0.437\n",
      "[12, 180] loss: 0.464\n",
      "[12, 240] loss: 0.447\n",
      "[12, 300] loss: 0.460\n",
      "[12, 360] loss: 0.468\n",
      "Epoch: 12 -> Loss: 0.424614042044\n",
      "Epoch: 12 -> Test Accuracy: 80.15\n",
      "[13, 60] loss: 0.431\n",
      "[13, 120] loss: 0.437\n",
      "[13, 180] loss: 0.458\n",
      "[13, 240] loss: 0.448\n",
      "[13, 300] loss: 0.456\n",
      "[13, 360] loss: 0.459\n",
      "Epoch: 13 -> Loss: 0.420501470566\n",
      "Epoch: 13 -> Test Accuracy: 81.55\n",
      "[14, 60] loss: 0.425\n",
      "[14, 120] loss: 0.447\n",
      "[14, 180] loss: 0.428\n",
      "[14, 240] loss: 0.441\n",
      "[14, 300] loss: 0.462\n",
      "[14, 360] loss: 0.445\n",
      "Epoch: 14 -> Loss: 0.493283182383\n",
      "Epoch: 14 -> Test Accuracy: 80.95\n",
      "[15, 60] loss: 0.415\n",
      "[15, 120] loss: 0.409\n",
      "[15, 180] loss: 0.452\n",
      "[15, 240] loss: 0.435\n",
      "[15, 300] loss: 0.458\n",
      "[15, 360] loss: 0.453\n",
      "Epoch: 15 -> Loss: 0.687053024769\n",
      "Epoch: 15 -> Test Accuracy: 81.13\n",
      "[16, 60] loss: 0.426\n",
      "[16, 120] loss: 0.402\n",
      "[16, 180] loss: 0.449\n",
      "[16, 240] loss: 0.436\n",
      "[16, 300] loss: 0.451\n",
      "[16, 360] loss: 0.433\n",
      "Epoch: 16 -> Loss: 0.525857210159\n",
      "Epoch: 16 -> Test Accuracy: 82.14\n",
      "[17, 60] loss: 0.412\n",
      "[17, 120] loss: 0.425\n",
      "[17, 180] loss: 0.454\n",
      "[17, 240] loss: 0.423\n",
      "[17, 300] loss: 0.433\n",
      "[17, 360] loss: 0.444\n",
      "Epoch: 17 -> Loss: 0.48986697197\n",
      "Epoch: 17 -> Test Accuracy: 81.2\n",
      "[18, 60] loss: 0.416\n",
      "[18, 120] loss: 0.417\n",
      "[18, 180] loss: 0.447\n",
      "[18, 240] loss: 0.436\n",
      "[18, 300] loss: 0.441\n",
      "[18, 360] loss: 0.430\n",
      "Epoch: 18 -> Loss: 0.359789043665\n",
      "Epoch: 18 -> Test Accuracy: 81.58\n",
      "[19, 60] loss: 0.400\n",
      "[19, 120] loss: 0.415\n",
      "[19, 180] loss: 0.427\n",
      "[19, 240] loss: 0.431\n",
      "[19, 300] loss: 0.448\n",
      "[19, 360] loss: 0.434\n",
      "Epoch: 19 -> Loss: 0.476075470448\n",
      "Epoch: 19 -> Test Accuracy: 81.62\n",
      "[20, 60] loss: 0.408\n",
      "[20, 120] loss: 0.411\n",
      "[20, 180] loss: 0.412\n",
      "[20, 240] loss: 0.436\n",
      "[20, 300] loss: 0.436\n",
      "[20, 360] loss: 0.406\n",
      "Epoch: 20 -> Loss: 0.665274560452\n",
      "Epoch: 20 -> Test Accuracy: 80.63\n",
      "[21, 60] loss: 0.413\n",
      "[21, 120] loss: 0.413\n",
      "[21, 180] loss: 0.412\n",
      "[21, 240] loss: 0.431\n",
      "[21, 300] loss: 0.426\n",
      "[21, 360] loss: 0.450\n",
      "Epoch: 21 -> Loss: 0.453517138958\n",
      "Epoch: 21 -> Test Accuracy: 82.28\n",
      "[22, 60] loss: 0.392\n",
      "[22, 120] loss: 0.415\n",
      "[22, 180] loss: 0.409\n",
      "[22, 240] loss: 0.427\n",
      "[22, 300] loss: 0.420\n",
      "[22, 360] loss: 0.428\n",
      "Epoch: 22 -> Loss: 0.365581929684\n",
      "Epoch: 22 -> Test Accuracy: 79.74\n",
      "[23, 60] loss: 0.400\n",
      "[23, 120] loss: 0.415\n",
      "[23, 180] loss: 0.434\n",
      "[23, 240] loss: 0.427\n",
      "[23, 300] loss: 0.427\n",
      "[23, 360] loss: 0.436\n",
      "Epoch: 23 -> Loss: 0.307698786259\n",
      "Epoch: 23 -> Test Accuracy: 80.45\n",
      "[24, 60] loss: 0.403\n",
      "[24, 120] loss: 0.411\n",
      "[24, 180] loss: 0.403\n",
      "[24, 240] loss: 0.418\n",
      "[24, 300] loss: 0.409\n",
      "[24, 360] loss: 0.424\n",
      "Epoch: 24 -> Loss: 0.541094362736\n",
      "Epoch: 24 -> Test Accuracy: 82.16\n",
      "[25, 60] loss: 0.412\n",
      "[25, 120] loss: 0.401\n",
      "[25, 180] loss: 0.421\n",
      "[25, 240] loss: 0.435\n",
      "[25, 300] loss: 0.417\n",
      "[25, 360] loss: 0.424\n",
      "Epoch: 25 -> Loss: 0.558412909508\n",
      "Epoch: 25 -> Test Accuracy: 81.44\n",
      "[26, 60] loss: 0.409\n",
      "[26, 120] loss: 0.408\n",
      "[26, 180] loss: 0.403\n",
      "[26, 240] loss: 0.423\n",
      "[26, 300] loss: 0.421\n",
      "[26, 360] loss: 0.410\n",
      "Epoch: 26 -> Loss: 0.406867265701\n",
      "Epoch: 26 -> Test Accuracy: 81.33\n",
      "[27, 60] loss: 0.391\n",
      "[27, 120] loss: 0.404\n",
      "[27, 180] loss: 0.427\n",
      "[27, 240] loss: 0.406\n",
      "[27, 300] loss: 0.413\n",
      "[27, 360] loss: 0.427\n",
      "Epoch: 27 -> Loss: 0.352363586426\n",
      "Epoch: 27 -> Test Accuracy: 81.67\n",
      "[28, 60] loss: 0.389\n",
      "[28, 120] loss: 0.404\n",
      "[28, 180] loss: 0.415\n",
      "[28, 240] loss: 0.413\n",
      "[28, 300] loss: 0.414\n",
      "[28, 360] loss: 0.421\n",
      "Epoch: 28 -> Loss: 0.485638141632\n",
      "Epoch: 28 -> Test Accuracy: 81.59\n",
      "[29, 60] loss: 0.389\n",
      "[29, 120] loss: 0.400\n",
      "[29, 180] loss: 0.399\n",
      "[29, 240] loss: 0.424\n",
      "[29, 300] loss: 0.408\n",
      "[29, 360] loss: 0.434\n",
      "Epoch: 29 -> Loss: 0.435752779245\n",
      "Epoch: 29 -> Test Accuracy: 82.08\n",
      "[30, 60] loss: 0.392\n",
      "[30, 120] loss: 0.401\n",
      "[30, 180] loss: 0.392\n",
      "[30, 240] loss: 0.415\n",
      "[30, 300] loss: 0.417\n",
      "[30, 360] loss: 0.420\n",
      "Epoch: 30 -> Loss: 0.471777528524\n",
      "Epoch: 30 -> Test Accuracy: 81.43\n",
      "[31, 60] loss: 0.414\n",
      "[31, 120] loss: 0.396\n",
      "[31, 180] loss: 0.409\n",
      "[31, 240] loss: 0.416\n",
      "[31, 300] loss: 0.404\n",
      "[31, 360] loss: 0.416\n",
      "Epoch: 31 -> Loss: 0.586894094944\n",
      "Epoch: 31 -> Test Accuracy: 81.65\n",
      "[32, 60] loss: 0.394\n",
      "[32, 120] loss: 0.389\n",
      "[32, 180] loss: 0.424\n",
      "[32, 240] loss: 0.409\n",
      "[32, 300] loss: 0.413\n",
      "[32, 360] loss: 0.408\n",
      "Epoch: 32 -> Loss: 0.67364937067\n",
      "Epoch: 32 -> Test Accuracy: 81.55\n",
      "[33, 60] loss: 0.387\n",
      "[33, 120] loss: 0.389\n",
      "[33, 180] loss: 0.415\n",
      "[33, 240] loss: 0.418\n",
      "[33, 300] loss: 0.405\n",
      "[33, 360] loss: 0.398\n",
      "Epoch: 33 -> Loss: 0.429774224758\n",
      "Epoch: 33 -> Test Accuracy: 81.84\n",
      "[34, 60] loss: 0.385\n",
      "[34, 120] loss: 0.392\n",
      "[34, 180] loss: 0.420\n",
      "[34, 240] loss: 0.404\n",
      "[34, 300] loss: 0.402\n",
      "[34, 360] loss: 0.434\n",
      "Epoch: 34 -> Loss: 0.351295530796\n",
      "Epoch: 34 -> Test Accuracy: 82.5\n",
      "[35, 60] loss: 0.369\n",
      "[35, 120] loss: 0.407\n",
      "[35, 180] loss: 0.403\n",
      "[35, 240] loss: 0.411\n",
      "[35, 300] loss: 0.416\n",
      "[35, 360] loss: 0.411\n",
      "Epoch: 35 -> Loss: 0.46245008707\n",
      "Epoch: 35 -> Test Accuracy: 81.89\n",
      "[36, 60] loss: 0.307\n",
      "[36, 120] loss: 0.282\n",
      "[36, 180] loss: 0.271\n",
      "[36, 240] loss: 0.284\n",
      "[36, 300] loss: 0.279\n",
      "[36, 360] loss: 0.271\n",
      "Epoch: 36 -> Loss: 0.511943459511\n",
      "Epoch: 36 -> Test Accuracy: 85.62\n",
      "[37, 60] loss: 0.255\n",
      "[37, 120] loss: 0.250\n",
      "[37, 180] loss: 0.244\n",
      "[37, 240] loss: 0.248\n",
      "[37, 300] loss: 0.248\n",
      "[37, 360] loss: 0.251\n",
      "Epoch: 37 -> Loss: 0.307639151812\n",
      "Epoch: 37 -> Test Accuracy: 86.44\n",
      "[38, 60] loss: 0.231\n",
      "[38, 120] loss: 0.237\n",
      "[38, 180] loss: 0.247\n",
      "[38, 240] loss: 0.225\n",
      "[38, 300] loss: 0.230\n",
      "[38, 360] loss: 0.252\n",
      "Epoch: 38 -> Loss: 0.353818029165\n",
      "Epoch: 38 -> Test Accuracy: 85.76\n",
      "[39, 60] loss: 0.223\n",
      "[39, 120] loss: 0.223\n",
      "[39, 180] loss: 0.219\n",
      "[39, 240] loss: 0.231\n",
      "[39, 300] loss: 0.237\n",
      "[39, 360] loss: 0.242\n",
      "Epoch: 39 -> Loss: 0.209128811955\n",
      "Epoch: 39 -> Test Accuracy: 85.6\n",
      "[40, 60] loss: 0.212\n",
      "[40, 120] loss: 0.229\n",
      "[40, 180] loss: 0.229\n",
      "[40, 240] loss: 0.229\n",
      "[40, 300] loss: 0.215\n",
      "[40, 360] loss: 0.229\n",
      "Epoch: 40 -> Loss: 0.214634135365\n",
      "Epoch: 40 -> Test Accuracy: 86.36\n",
      "[41, 60] loss: 0.203\n",
      "[41, 120] loss: 0.227\n",
      "[41, 180] loss: 0.219\n",
      "[41, 240] loss: 0.222\n",
      "[41, 300] loss: 0.232\n",
      "[41, 360] loss: 0.238\n",
      "Epoch: 41 -> Loss: 0.193170338869\n",
      "Epoch: 41 -> Test Accuracy: 85.79\n",
      "[42, 60] loss: 0.210\n",
      "[42, 120] loss: 0.210\n",
      "[42, 180] loss: 0.213\n",
      "[42, 240] loss: 0.220\n",
      "[42, 300] loss: 0.226\n",
      "[42, 360] loss: 0.229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.367429107428\n",
      "Epoch: 42 -> Test Accuracy: 85.27\n",
      "[43, 60] loss: 0.208\n",
      "[43, 120] loss: 0.212\n",
      "[43, 180] loss: 0.223\n",
      "[43, 240] loss: 0.226\n",
      "[43, 300] loss: 0.225\n",
      "[43, 360] loss: 0.230\n",
      "Epoch: 43 -> Loss: 0.246880248189\n",
      "Epoch: 43 -> Test Accuracy: 86.26\n",
      "[44, 60] loss: 0.211\n",
      "[44, 120] loss: 0.199\n",
      "[44, 180] loss: 0.218\n",
      "[44, 240] loss: 0.218\n",
      "[44, 300] loss: 0.224\n",
      "[44, 360] loss: 0.239\n",
      "Epoch: 44 -> Loss: 0.308743089437\n",
      "Epoch: 44 -> Test Accuracy: 85.1\n",
      "[45, 60] loss: 0.207\n",
      "[45, 120] loss: 0.211\n",
      "[45, 180] loss: 0.216\n",
      "[45, 240] loss: 0.227\n",
      "[45, 300] loss: 0.221\n",
      "[45, 360] loss: 0.218\n",
      "Epoch: 45 -> Loss: 0.193989947438\n",
      "Epoch: 45 -> Test Accuracy: 84.7\n",
      "[46, 60] loss: 0.211\n",
      "[46, 120] loss: 0.204\n",
      "[46, 180] loss: 0.213\n",
      "[46, 240] loss: 0.218\n",
      "[46, 300] loss: 0.221\n",
      "[46, 360] loss: 0.237\n",
      "Epoch: 46 -> Loss: 0.173785120249\n",
      "Epoch: 46 -> Test Accuracy: 85.62\n",
      "[47, 60] loss: 0.209\n",
      "[47, 120] loss: 0.213\n",
      "[47, 180] loss: 0.213\n",
      "[47, 240] loss: 0.232\n",
      "[47, 300] loss: 0.227\n",
      "[47, 360] loss: 0.235\n",
      "Epoch: 47 -> Loss: 0.215796589851\n",
      "Epoch: 47 -> Test Accuracy: 85.7\n",
      "[48, 60] loss: 0.197\n",
      "[48, 120] loss: 0.203\n",
      "[48, 180] loss: 0.215\n",
      "[48, 240] loss: 0.224\n",
      "[48, 300] loss: 0.228\n",
      "[48, 360] loss: 0.239\n",
      "Epoch: 48 -> Loss: 0.272399038076\n",
      "Epoch: 48 -> Test Accuracy: 84.95\n",
      "[49, 60] loss: 0.205\n",
      "[49, 120] loss: 0.206\n",
      "[49, 180] loss: 0.222\n",
      "[49, 240] loss: 0.219\n",
      "[49, 300] loss: 0.231\n",
      "[49, 360] loss: 0.235\n",
      "Epoch: 49 -> Loss: 0.123649761081\n",
      "Epoch: 49 -> Test Accuracy: 84.89\n",
      "[50, 60] loss: 0.205\n",
      "[50, 120] loss: 0.210\n",
      "[50, 180] loss: 0.224\n",
      "[50, 240] loss: 0.219\n",
      "[50, 300] loss: 0.220\n",
      "[50, 360] loss: 0.233\n",
      "Epoch: 50 -> Loss: 0.227295681834\n",
      "Epoch: 50 -> Test Accuracy: 85.24\n",
      "[51, 60] loss: 0.205\n",
      "[51, 120] loss: 0.211\n",
      "[51, 180] loss: 0.209\n",
      "[51, 240] loss: 0.217\n",
      "[51, 300] loss: 0.221\n",
      "[51, 360] loss: 0.226\n",
      "Epoch: 51 -> Loss: 0.302188068628\n",
      "Epoch: 51 -> Test Accuracy: 85.78\n",
      "[52, 60] loss: 0.203\n",
      "[52, 120] loss: 0.195\n",
      "[52, 180] loss: 0.214\n",
      "[52, 240] loss: 0.216\n",
      "[52, 300] loss: 0.229\n",
      "[52, 360] loss: 0.228\n",
      "Epoch: 52 -> Loss: 0.26025018096\n",
      "Epoch: 52 -> Test Accuracy: 85.12\n",
      "[53, 60] loss: 0.198\n",
      "[53, 120] loss: 0.201\n",
      "[53, 180] loss: 0.228\n",
      "[53, 240] loss: 0.210\n",
      "[53, 300] loss: 0.228\n",
      "[53, 360] loss: 0.236\n",
      "Epoch: 53 -> Loss: 0.345288306475\n",
      "Epoch: 53 -> Test Accuracy: 85.29\n",
      "[54, 60] loss: 0.199\n",
      "[54, 120] loss: 0.199\n",
      "[54, 180] loss: 0.202\n",
      "[54, 240] loss: 0.231\n",
      "[54, 300] loss: 0.223\n",
      "[54, 360] loss: 0.232\n",
      "Epoch: 54 -> Loss: 0.20453453064\n",
      "Epoch: 54 -> Test Accuracy: 85.02\n",
      "[55, 60] loss: 0.212\n",
      "[55, 120] loss: 0.215\n",
      "[55, 180] loss: 0.216\n",
      "[55, 240] loss: 0.211\n",
      "[55, 300] loss: 0.222\n",
      "[55, 360] loss: 0.232\n",
      "Epoch: 55 -> Loss: 0.144998937845\n",
      "Epoch: 55 -> Test Accuracy: 84.86\n",
      "[56, 60] loss: 0.202\n",
      "[56, 120] loss: 0.198\n",
      "[56, 180] loss: 0.212\n",
      "[56, 240] loss: 0.219\n",
      "[56, 300] loss: 0.236\n",
      "[56, 360] loss: 0.223\n",
      "Epoch: 56 -> Loss: 0.226112693548\n",
      "Epoch: 56 -> Test Accuracy: 84.92\n",
      "[57, 60] loss: 0.195\n",
      "[57, 120] loss: 0.208\n",
      "[57, 180] loss: 0.218\n",
      "[57, 240] loss: 0.213\n",
      "[57, 300] loss: 0.221\n",
      "[57, 360] loss: 0.228\n",
      "Epoch: 57 -> Loss: 0.235637187958\n",
      "Epoch: 57 -> Test Accuracy: 84.86\n",
      "[58, 60] loss: 0.198\n",
      "[58, 120] loss: 0.211\n",
      "[58, 180] loss: 0.207\n",
      "[58, 240] loss: 0.219\n",
      "[58, 300] loss: 0.217\n",
      "[58, 360] loss: 0.224\n",
      "Epoch: 58 -> Loss: 0.234650462866\n",
      "Epoch: 58 -> Test Accuracy: 84.77\n",
      "[59, 60] loss: 0.199\n",
      "[59, 120] loss: 0.198\n",
      "[59, 180] loss: 0.211\n",
      "[59, 240] loss: 0.218\n",
      "[59, 300] loss: 0.219\n",
      "[59, 360] loss: 0.233\n",
      "Epoch: 59 -> Loss: 0.1255761832\n",
      "Epoch: 59 -> Test Accuracy: 84.43\n",
      "[60, 60] loss: 0.197\n",
      "[60, 120] loss: 0.209\n",
      "[60, 180] loss: 0.204\n",
      "[60, 240] loss: 0.217\n",
      "[60, 300] loss: 0.216\n",
      "[60, 360] loss: 0.220\n",
      "Epoch: 60 -> Loss: 0.277145057917\n",
      "Epoch: 60 -> Test Accuracy: 85.29\n",
      "[61, 60] loss: 0.188\n",
      "[61, 120] loss: 0.190\n",
      "[61, 180] loss: 0.207\n",
      "[61, 240] loss: 0.213\n",
      "[61, 300] loss: 0.216\n",
      "[61, 360] loss: 0.226\n",
      "Epoch: 61 -> Loss: 0.139841303229\n",
      "Epoch: 61 -> Test Accuracy: 85.05\n",
      "[62, 60] loss: 0.196\n",
      "[62, 120] loss: 0.213\n",
      "[62, 180] loss: 0.198\n",
      "[62, 240] loss: 0.217\n",
      "[62, 300] loss: 0.217\n",
      "[62, 360] loss: 0.228\n",
      "Epoch: 62 -> Loss: 0.245643734932\n",
      "Epoch: 62 -> Test Accuracy: 85.33\n",
      "[63, 60] loss: 0.193\n",
      "[63, 120] loss: 0.202\n",
      "[63, 180] loss: 0.208\n",
      "[63, 240] loss: 0.200\n",
      "[63, 300] loss: 0.211\n",
      "[63, 360] loss: 0.232\n",
      "Epoch: 63 -> Loss: 0.336574912071\n",
      "Epoch: 63 -> Test Accuracy: 85.29\n",
      "[64, 60] loss: 0.205\n",
      "[64, 120] loss: 0.202\n",
      "[64, 180] loss: 0.214\n",
      "[64, 240] loss: 0.210\n",
      "[64, 300] loss: 0.210\n",
      "[64, 360] loss: 0.222\n",
      "Epoch: 64 -> Loss: 0.157260462642\n",
      "Epoch: 64 -> Test Accuracy: 85.26\n",
      "[65, 60] loss: 0.196\n",
      "[65, 120] loss: 0.200\n",
      "[65, 180] loss: 0.195\n",
      "[65, 240] loss: 0.204\n",
      "[65, 300] loss: 0.212\n",
      "[65, 360] loss: 0.219\n",
      "Epoch: 65 -> Loss: 0.289101332426\n",
      "Epoch: 65 -> Test Accuracy: 84.37\n",
      "[66, 60] loss: 0.190\n",
      "[66, 120] loss: 0.204\n",
      "[66, 180] loss: 0.220\n",
      "[66, 240] loss: 0.210\n",
      "[66, 300] loss: 0.215\n",
      "[66, 360] loss: 0.218\n",
      "Epoch: 66 -> Loss: 0.192337989807\n",
      "Epoch: 66 -> Test Accuracy: 84.95\n",
      "[67, 60] loss: 0.195\n",
      "[67, 120] loss: 0.191\n",
      "[67, 180] loss: 0.213\n",
      "[67, 240] loss: 0.207\n",
      "[67, 300] loss: 0.223\n",
      "[67, 360] loss: 0.218\n",
      "Epoch: 67 -> Loss: 0.191490486264\n",
      "Epoch: 67 -> Test Accuracy: 84.88\n",
      "[68, 60] loss: 0.191\n",
      "[68, 120] loss: 0.189\n",
      "[68, 180] loss: 0.210\n",
      "[68, 240] loss: 0.216\n",
      "[68, 300] loss: 0.226\n",
      "[68, 360] loss: 0.222\n",
      "Epoch: 68 -> Loss: 0.217858999968\n",
      "Epoch: 68 -> Test Accuracy: 83.97\n",
      "[69, 60] loss: 0.194\n",
      "[69, 120] loss: 0.185\n",
      "[69, 180] loss: 0.195\n",
      "[69, 240] loss: 0.211\n",
      "[69, 300] loss: 0.209\n",
      "[69, 360] loss: 0.219\n",
      "Epoch: 69 -> Loss: 0.202600002289\n",
      "Epoch: 69 -> Test Accuracy: 84.85\n",
      "[70, 60] loss: 0.196\n",
      "[70, 120] loss: 0.191\n",
      "[70, 180] loss: 0.199\n",
      "[70, 240] loss: 0.212\n",
      "[70, 300] loss: 0.213\n",
      "[70, 360] loss: 0.214\n",
      "Epoch: 70 -> Loss: 0.217269584537\n",
      "Epoch: 70 -> Test Accuracy: 85.36\n",
      "[71, 60] loss: 0.173\n",
      "[71, 120] loss: 0.144\n",
      "[71, 180] loss: 0.140\n",
      "[71, 240] loss: 0.136\n",
      "[71, 300] loss: 0.140\n",
      "[71, 360] loss: 0.133\n",
      "Epoch: 71 -> Loss: 0.0861133784056\n",
      "Epoch: 71 -> Test Accuracy: 86.88\n",
      "[72, 60] loss: 0.121\n",
      "[72, 120] loss: 0.121\n",
      "[72, 180] loss: 0.122\n",
      "[72, 240] loss: 0.120\n",
      "[72, 300] loss: 0.128\n",
      "[72, 360] loss: 0.124\n",
      "Epoch: 72 -> Loss: 0.152239322662\n",
      "Epoch: 72 -> Test Accuracy: 86.78\n",
      "[73, 60] loss: 0.124\n",
      "[73, 120] loss: 0.119\n",
      "[73, 180] loss: 0.115\n",
      "[73, 240] loss: 0.116\n",
      "[73, 300] loss: 0.124\n",
      "[73, 360] loss: 0.125\n",
      "Epoch: 73 -> Loss: 0.24748647213\n",
      "Epoch: 73 -> Test Accuracy: 86.97\n",
      "[74, 60] loss: 0.112\n",
      "[74, 120] loss: 0.109\n",
      "[74, 180] loss: 0.112\n",
      "[74, 240] loss: 0.122\n",
      "[74, 300] loss: 0.112\n",
      "[74, 360] loss: 0.122\n",
      "Epoch: 74 -> Loss: 0.152580738068\n",
      "Epoch: 74 -> Test Accuracy: 86.8\n",
      "[75, 60] loss: 0.109\n",
      "[75, 120] loss: 0.115\n",
      "[75, 180] loss: 0.109\n",
      "[75, 240] loss: 0.119\n",
      "[75, 300] loss: 0.110\n",
      "[75, 360] loss: 0.109\n",
      "Epoch: 75 -> Loss: 0.0667220279574\n",
      "Epoch: 75 -> Test Accuracy: 86.88\n",
      "[76, 60] loss: 0.103\n",
      "[76, 120] loss: 0.104\n",
      "[76, 180] loss: 0.103\n",
      "[76, 240] loss: 0.110\n",
      "[76, 300] loss: 0.111\n",
      "[76, 360] loss: 0.119\n",
      "Epoch: 76 -> Loss: 0.104675829411\n",
      "Epoch: 76 -> Test Accuracy: 87.01\n",
      "[77, 60] loss: 0.105\n",
      "[77, 120] loss: 0.109\n",
      "[77, 180] loss: 0.105\n",
      "[77, 240] loss: 0.107\n",
      "[77, 300] loss: 0.109\n",
      "[77, 360] loss: 0.112\n",
      "Epoch: 77 -> Loss: 0.0587496869266\n",
      "Epoch: 77 -> Test Accuracy: 86.84\n",
      "[78, 60] loss: 0.104\n",
      "[78, 120] loss: 0.103\n",
      "[78, 180] loss: 0.107\n",
      "[78, 240] loss: 0.102\n",
      "[78, 300] loss: 0.100\n",
      "[78, 360] loss: 0.104\n",
      "Epoch: 78 -> Loss: 0.119968272746\n",
      "Epoch: 78 -> Test Accuracy: 87.15\n",
      "[79, 60] loss: 0.098\n",
      "[79, 120] loss: 0.103\n",
      "[79, 180] loss: 0.099\n",
      "[79, 240] loss: 0.100\n",
      "[79, 300] loss: 0.107\n",
      "[79, 360] loss: 0.110\n",
      "Epoch: 79 -> Loss: 0.148834779859\n",
      "Epoch: 79 -> Test Accuracy: 86.81\n",
      "[80, 60] loss: 0.101\n",
      "[80, 120] loss: 0.109\n",
      "[80, 180] loss: 0.102\n",
      "[80, 240] loss: 0.096\n",
      "[80, 300] loss: 0.102\n",
      "[80, 360] loss: 0.108\n",
      "Epoch: 80 -> Loss: 0.112207576632\n",
      "Epoch: 80 -> Test Accuracy: 86.9\n",
      "[81, 60] loss: 0.092\n",
      "[81, 120] loss: 0.103\n",
      "[81, 180] loss: 0.103\n",
      "[81, 240] loss: 0.101\n",
      "[81, 300] loss: 0.101\n",
      "[81, 360] loss: 0.100\n",
      "Epoch: 81 -> Loss: 0.0783820748329\n",
      "Epoch: 81 -> Test Accuracy: 86.72\n",
      "[82, 60] loss: 0.097\n",
      "[82, 120] loss: 0.098\n",
      "[82, 180] loss: 0.098\n",
      "[82, 240] loss: 0.094\n",
      "[82, 300] loss: 0.096\n",
      "[82, 360] loss: 0.096\n",
      "Epoch: 82 -> Loss: 0.147284641862\n",
      "Epoch: 82 -> Test Accuracy: 86.91\n",
      "[83, 60] loss: 0.097\n",
      "[83, 120] loss: 0.100\n",
      "[83, 180] loss: 0.095\n",
      "[83, 240] loss: 0.105\n",
      "[83, 300] loss: 0.100\n",
      "[83, 360] loss: 0.096\n",
      "Epoch: 83 -> Loss: 0.0895229056478\n",
      "Epoch: 83 -> Test Accuracy: 86.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.093\n",
      "[84, 120] loss: 0.098\n",
      "[84, 180] loss: 0.095\n",
      "[84, 240] loss: 0.098\n",
      "[84, 300] loss: 0.099\n",
      "[84, 360] loss: 0.100\n",
      "Epoch: 84 -> Loss: 0.173047661781\n",
      "Epoch: 84 -> Test Accuracy: 86.94\n",
      "[85, 60] loss: 0.092\n",
      "[85, 120] loss: 0.090\n",
      "[85, 180] loss: 0.095\n",
      "[85, 240] loss: 0.098\n",
      "[85, 300] loss: 0.094\n",
      "[85, 360] loss: 0.098\n",
      "Epoch: 85 -> Loss: 0.0852631404996\n",
      "Epoch: 85 -> Test Accuracy: 87.11\n",
      "[86, 60] loss: 0.092\n",
      "[86, 120] loss: 0.083\n",
      "[86, 180] loss: 0.082\n",
      "[86, 240] loss: 0.079\n",
      "[86, 300] loss: 0.082\n",
      "[86, 360] loss: 0.087\n",
      "Epoch: 86 -> Loss: 0.117199338973\n",
      "Epoch: 86 -> Test Accuracy: 87.23\n",
      "[87, 60] loss: 0.080\n",
      "[87, 120] loss: 0.077\n",
      "[87, 180] loss: 0.080\n",
      "[87, 240] loss: 0.082\n",
      "[87, 300] loss: 0.080\n",
      "[87, 360] loss: 0.081\n",
      "Epoch: 87 -> Loss: 0.0730190724134\n",
      "Epoch: 87 -> Test Accuracy: 87.05\n",
      "[88, 60] loss: 0.080\n",
      "[88, 120] loss: 0.079\n",
      "[88, 180] loss: 0.082\n",
      "[88, 240] loss: 0.077\n",
      "[88, 300] loss: 0.079\n",
      "[88, 360] loss: 0.077\n",
      "Epoch: 88 -> Loss: 0.0719773620367\n",
      "Epoch: 88 -> Test Accuracy: 87.09\n",
      "[89, 60] loss: 0.079\n",
      "[89, 120] loss: 0.081\n",
      "[89, 180] loss: 0.074\n",
      "[89, 240] loss: 0.079\n",
      "[89, 300] loss: 0.074\n",
      "[89, 360] loss: 0.078\n",
      "Epoch: 89 -> Loss: 0.0586576089263\n",
      "Epoch: 89 -> Test Accuracy: 87.1\n",
      "[90, 60] loss: 0.076\n",
      "[90, 120] loss: 0.082\n",
      "[90, 180] loss: 0.081\n",
      "[90, 240] loss: 0.081\n",
      "[90, 300] loss: 0.075\n",
      "[90, 360] loss: 0.080\n",
      "Epoch: 90 -> Loss: 0.068951241672\n",
      "Epoch: 90 -> Test Accuracy: 87.01\n",
      "[91, 60] loss: 0.077\n",
      "[91, 120] loss: 0.075\n",
      "[91, 180] loss: 0.078\n",
      "[91, 240] loss: 0.079\n",
      "[91, 300] loss: 0.082\n",
      "[91, 360] loss: 0.078\n",
      "Epoch: 91 -> Loss: 0.062657892704\n",
      "Epoch: 91 -> Test Accuracy: 87.12\n",
      "[92, 60] loss: 0.079\n",
      "[92, 120] loss: 0.078\n",
      "[92, 180] loss: 0.076\n",
      "[92, 240] loss: 0.078\n",
      "[92, 300] loss: 0.080\n",
      "[92, 360] loss: 0.080\n",
      "Epoch: 92 -> Loss: 0.0748406276107\n",
      "Epoch: 92 -> Test Accuracy: 86.95\n",
      "[93, 60] loss: 0.071\n",
      "[93, 120] loss: 0.076\n",
      "[93, 180] loss: 0.076\n",
      "[93, 240] loss: 0.073\n",
      "[93, 300] loss: 0.082\n",
      "[93, 360] loss: 0.079\n",
      "Epoch: 93 -> Loss: 0.0712976232171\n",
      "Epoch: 93 -> Test Accuracy: 87.08\n",
      "[94, 60] loss: 0.073\n",
      "[94, 120] loss: 0.078\n",
      "[94, 180] loss: 0.079\n",
      "[94, 240] loss: 0.077\n",
      "[94, 300] loss: 0.078\n",
      "[94, 360] loss: 0.077\n",
      "Epoch: 94 -> Loss: 0.136106818914\n",
      "Epoch: 94 -> Test Accuracy: 87.23\n",
      "[95, 60] loss: 0.077\n",
      "[95, 120] loss: 0.079\n",
      "[95, 180] loss: 0.076\n",
      "[95, 240] loss: 0.080\n",
      "[95, 300] loss: 0.079\n",
      "[95, 360] loss: 0.075\n",
      "Epoch: 95 -> Loss: 0.0827887803316\n",
      "Epoch: 95 -> Test Accuracy: 86.9\n",
      "[96, 60] loss: 0.075\n",
      "[96, 120] loss: 0.078\n",
      "[96, 180] loss: 0.075\n",
      "[96, 240] loss: 0.078\n",
      "[96, 300] loss: 0.077\n",
      "[96, 360] loss: 0.075\n",
      "Epoch: 96 -> Loss: 0.074126958847\n",
      "Epoch: 96 -> Test Accuracy: 87.09\n",
      "[97, 60] loss: 0.077\n",
      "[97, 120] loss: 0.073\n",
      "[97, 180] loss: 0.077\n",
      "[97, 240] loss: 0.075\n",
      "[97, 300] loss: 0.077\n",
      "[97, 360] loss: 0.078\n",
      "Epoch: 97 -> Loss: 0.123150423169\n",
      "Epoch: 97 -> Test Accuracy: 86.99\n",
      "[98, 60] loss: 0.076\n",
      "[98, 120] loss: 0.077\n",
      "[98, 180] loss: 0.076\n",
      "[98, 240] loss: 0.071\n",
      "[98, 300] loss: 0.074\n",
      "[98, 360] loss: 0.079\n",
      "Epoch: 98 -> Loss: 0.0828704237938\n",
      "Epoch: 98 -> Test Accuracy: 87.05\n",
      "[99, 60] loss: 0.074\n",
      "[99, 120] loss: 0.075\n",
      "[99, 180] loss: 0.071\n",
      "[99, 240] loss: 0.077\n",
      "[99, 300] loss: 0.078\n",
      "[99, 360] loss: 0.077\n",
      "Epoch: 99 -> Loss: 0.0612016692758\n",
      "Epoch: 99 -> Test Accuracy: 87.13\n",
      "[100, 60] loss: 0.069\n",
      "[100, 120] loss: 0.075\n",
      "[100, 180] loss: 0.073\n",
      "[100, 240] loss: 0.074\n",
      "[100, 300] loss: 0.074\n",
      "[100, 360] loss: 0.075\n",
      "Epoch: 100 -> Loss: 0.038023866713\n",
      "Epoch: 100 -> Test Accuracy: 86.85\n",
      "Finished Training\n",
      "[1, 60] loss: 0.899\n",
      "[1, 120] loss: 0.623\n",
      "[1, 180] loss: 0.573\n",
      "[1, 240] loss: 0.570\n",
      "[1, 300] loss: 0.516\n",
      "[1, 360] loss: 0.494\n",
      "Epoch: 1 -> Loss: 0.527269244194\n",
      "Epoch: 1 -> Test Accuracy: 81.08\n",
      "[2, 60] loss: 0.455\n",
      "[2, 120] loss: 0.454\n",
      "[2, 180] loss: 0.448\n",
      "[2, 240] loss: 0.427\n",
      "[2, 300] loss: 0.435\n",
      "[2, 360] loss: 0.446\n",
      "Epoch: 2 -> Loss: 0.406312793493\n",
      "Epoch: 2 -> Test Accuracy: 83.37\n",
      "[3, 60] loss: 0.394\n",
      "[3, 120] loss: 0.399\n",
      "[3, 180] loss: 0.400\n",
      "[3, 240] loss: 0.399\n",
      "[3, 300] loss: 0.408\n",
      "[3, 360] loss: 0.392\n",
      "Epoch: 3 -> Loss: 0.339932471514\n",
      "Epoch: 3 -> Test Accuracy: 83.35\n",
      "[4, 60] loss: 0.363\n",
      "[4, 120] loss: 0.368\n",
      "[4, 180] loss: 0.360\n",
      "[4, 240] loss: 0.381\n",
      "[4, 300] loss: 0.382\n",
      "[4, 360] loss: 0.384\n",
      "Epoch: 4 -> Loss: 0.269151031971\n",
      "Epoch: 4 -> Test Accuracy: 84.44\n",
      "[5, 60] loss: 0.338\n",
      "[5, 120] loss: 0.354\n",
      "[5, 180] loss: 0.350\n",
      "[5, 240] loss: 0.341\n",
      "[5, 300] loss: 0.366\n",
      "[5, 360] loss: 0.356\n",
      "Epoch: 5 -> Loss: 0.325666487217\n",
      "Epoch: 5 -> Test Accuracy: 84.63\n",
      "[6, 60] loss: 0.314\n",
      "[6, 120] loss: 0.327\n",
      "[6, 180] loss: 0.335\n",
      "[6, 240] loss: 0.342\n",
      "[6, 300] loss: 0.347\n",
      "[6, 360] loss: 0.356\n",
      "Epoch: 6 -> Loss: 0.313348770142\n",
      "Epoch: 6 -> Test Accuracy: 83.96\n",
      "[7, 60] loss: 0.319\n",
      "[7, 120] loss: 0.331\n",
      "[7, 180] loss: 0.324\n",
      "[7, 240] loss: 0.321\n",
      "[7, 300] loss: 0.341\n",
      "[7, 360] loss: 0.336\n",
      "Epoch: 7 -> Loss: 0.443416684866\n",
      "Epoch: 7 -> Test Accuracy: 83.39\n",
      "[8, 60] loss: 0.300\n",
      "[8, 120] loss: 0.310\n",
      "[8, 180] loss: 0.317\n",
      "[8, 240] loss: 0.321\n",
      "[8, 300] loss: 0.342\n",
      "[8, 360] loss: 0.336\n",
      "Epoch: 8 -> Loss: 0.214324861765\n",
      "Epoch: 8 -> Test Accuracy: 85.53\n",
      "[9, 60] loss: 0.305\n",
      "[9, 120] loss: 0.302\n",
      "[9, 180] loss: 0.305\n",
      "[9, 240] loss: 0.325\n",
      "[9, 300] loss: 0.327\n",
      "[9, 360] loss: 0.315\n",
      "Epoch: 9 -> Loss: 0.455975621939\n",
      "Epoch: 9 -> Test Accuracy: 85.41\n",
      "[10, 60] loss: 0.276\n",
      "[10, 120] loss: 0.294\n",
      "[10, 180] loss: 0.309\n",
      "[10, 240] loss: 0.295\n",
      "[10, 300] loss: 0.325\n",
      "[10, 360] loss: 0.320\n",
      "Epoch: 10 -> Loss: 0.491630464792\n",
      "Epoch: 10 -> Test Accuracy: 85.57\n",
      "[11, 60] loss: 0.271\n",
      "[11, 120] loss: 0.285\n",
      "[11, 180] loss: 0.289\n",
      "[11, 240] loss: 0.304\n",
      "[11, 300] loss: 0.339\n",
      "[11, 360] loss: 0.330\n",
      "Epoch: 11 -> Loss: 0.320974588394\n",
      "Epoch: 11 -> Test Accuracy: 86.18\n",
      "[12, 60] loss: 0.280\n",
      "[12, 120] loss: 0.280\n",
      "[12, 180] loss: 0.281\n",
      "[12, 240] loss: 0.292\n",
      "[12, 300] loss: 0.298\n",
      "[12, 360] loss: 0.311\n",
      "Epoch: 12 -> Loss: 0.311203598976\n",
      "Epoch: 12 -> Test Accuracy: 85.38\n",
      "[13, 60] loss: 0.266\n",
      "[13, 120] loss: 0.289\n",
      "[13, 180] loss: 0.293\n",
      "[13, 240] loss: 0.303\n",
      "[13, 300] loss: 0.298\n",
      "[13, 360] loss: 0.304\n",
      "Epoch: 13 -> Loss: 0.38963535428\n",
      "Epoch: 13 -> Test Accuracy: 85.49\n",
      "[14, 60] loss: 0.279\n",
      "[14, 120] loss: 0.287\n",
      "[14, 180] loss: 0.293\n",
      "[14, 240] loss: 0.276\n",
      "[14, 300] loss: 0.309\n",
      "[14, 360] loss: 0.304\n",
      "Epoch: 14 -> Loss: 0.336613625288\n",
      "Epoch: 14 -> Test Accuracy: 85.05\n",
      "[15, 60] loss: 0.260\n",
      "[15, 120] loss: 0.287\n",
      "[15, 180] loss: 0.293\n",
      "[15, 240] loss: 0.281\n",
      "[15, 300] loss: 0.278\n",
      "[15, 360] loss: 0.284\n",
      "Epoch: 15 -> Loss: 0.39779239893\n",
      "Epoch: 15 -> Test Accuracy: 84.99\n",
      "[16, 60] loss: 0.274\n",
      "[16, 120] loss: 0.273\n",
      "[16, 180] loss: 0.269\n",
      "[16, 240] loss: 0.287\n",
      "[16, 300] loss: 0.298\n",
      "[16, 360] loss: 0.305\n",
      "Epoch: 16 -> Loss: 0.339841604233\n",
      "Epoch: 16 -> Test Accuracy: 85.91\n",
      "[17, 60] loss: 0.256\n",
      "[17, 120] loss: 0.273\n",
      "[17, 180] loss: 0.294\n",
      "[17, 240] loss: 0.283\n",
      "[17, 300] loss: 0.304\n",
      "[17, 360] loss: 0.299\n",
      "Epoch: 17 -> Loss: 0.359031558037\n",
      "Epoch: 17 -> Test Accuracy: 85.61\n",
      "[18, 60] loss: 0.258\n",
      "[18, 120] loss: 0.259\n",
      "[18, 180] loss: 0.273\n",
      "[18, 240] loss: 0.285\n",
      "[18, 300] loss: 0.288\n",
      "[18, 360] loss: 0.306\n",
      "Epoch: 18 -> Loss: 0.35723093152\n",
      "Epoch: 18 -> Test Accuracy: 85.08\n",
      "[19, 60] loss: 0.284\n",
      "[19, 120] loss: 0.280\n",
      "[19, 180] loss: 0.278\n",
      "[19, 240] loss: 0.276\n",
      "[19, 300] loss: 0.277\n",
      "[19, 360] loss: 0.288\n",
      "Epoch: 19 -> Loss: 0.2690769732\n",
      "Epoch: 19 -> Test Accuracy: 85.38\n",
      "[20, 60] loss: 0.261\n",
      "[20, 120] loss: 0.256\n",
      "[20, 180] loss: 0.284\n",
      "[20, 240] loss: 0.284\n",
      "[20, 300] loss: 0.278\n",
      "[20, 360] loss: 0.301\n",
      "Epoch: 20 -> Loss: 0.276969313622\n",
      "Epoch: 20 -> Test Accuracy: 86.02\n",
      "[21, 60] loss: 0.264\n",
      "[21, 120] loss: 0.265\n",
      "[21, 180] loss: 0.252\n",
      "[21, 240] loss: 0.278\n",
      "[21, 300] loss: 0.289\n",
      "[21, 360] loss: 0.303\n",
      "Epoch: 21 -> Loss: 0.314692467451\n",
      "Epoch: 21 -> Test Accuracy: 85.43\n",
      "[22, 60] loss: 0.257\n",
      "[22, 120] loss: 0.264\n",
      "[22, 180] loss: 0.274\n",
      "[22, 240] loss: 0.277\n",
      "[22, 300] loss: 0.281\n",
      "[22, 360] loss: 0.284\n",
      "Epoch: 22 -> Loss: 0.241112902761\n",
      "Epoch: 22 -> Test Accuracy: 85.38\n",
      "[23, 60] loss: 0.250\n",
      "[23, 120] loss: 0.259\n",
      "[23, 180] loss: 0.265\n",
      "[23, 240] loss: 0.287\n",
      "[23, 300] loss: 0.267\n",
      "[23, 360] loss: 0.303\n",
      "Epoch: 23 -> Loss: 0.45448166132\n",
      "Epoch: 23 -> Test Accuracy: 85.46\n",
      "[24, 60] loss: 0.241\n",
      "[24, 120] loss: 0.261\n",
      "[24, 180] loss: 0.277\n",
      "[24, 240] loss: 0.274\n",
      "[24, 300] loss: 0.285\n",
      "[24, 360] loss: 0.289\n",
      "Epoch: 24 -> Loss: 0.220754593611\n",
      "Epoch: 24 -> Test Accuracy: 85.4\n",
      "[25, 60] loss: 0.256\n",
      "[25, 120] loss: 0.249\n",
      "[25, 180] loss: 0.258\n",
      "[25, 240] loss: 0.273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 300] loss: 0.278\n",
      "[25, 360] loss: 0.304\n",
      "Epoch: 25 -> Loss: 0.273232907057\n",
      "Epoch: 25 -> Test Accuracy: 85.32\n",
      "[26, 60] loss: 0.250\n",
      "[26, 120] loss: 0.254\n",
      "[26, 180] loss: 0.270\n",
      "[26, 240] loss: 0.270\n",
      "[26, 300] loss: 0.286\n",
      "[26, 360] loss: 0.270\n",
      "Epoch: 26 -> Loss: 0.186416223645\n",
      "Epoch: 26 -> Test Accuracy: 86.0\n",
      "[27, 60] loss: 0.246\n",
      "[27, 120] loss: 0.254\n",
      "[27, 180] loss: 0.262\n",
      "[27, 240] loss: 0.277\n",
      "[27, 300] loss: 0.294\n",
      "[27, 360] loss: 0.298\n",
      "Epoch: 27 -> Loss: 0.315597355366\n",
      "Epoch: 27 -> Test Accuracy: 85.52\n",
      "[28, 60] loss: 0.252\n",
      "[28, 120] loss: 0.255\n",
      "[28, 180] loss: 0.255\n",
      "[28, 240] loss: 0.277\n",
      "[28, 300] loss: 0.280\n",
      "[28, 360] loss: 0.274\n",
      "Epoch: 28 -> Loss: 0.28716173768\n",
      "Epoch: 28 -> Test Accuracy: 86.13\n",
      "[29, 60] loss: 0.251\n",
      "[29, 120] loss: 0.249\n",
      "[29, 180] loss: 0.275\n",
      "[29, 240] loss: 0.275\n",
      "[29, 300] loss: 0.293\n",
      "[29, 360] loss: 0.266\n",
      "Epoch: 29 -> Loss: 0.236902907491\n",
      "Epoch: 29 -> Test Accuracy: 86.14\n",
      "[30, 60] loss: 0.242\n",
      "[30, 120] loss: 0.254\n",
      "[30, 180] loss: 0.268\n",
      "[30, 240] loss: 0.270\n",
      "[30, 300] loss: 0.285\n",
      "[30, 360] loss: 0.262\n",
      "Epoch: 30 -> Loss: 0.310633897781\n",
      "Epoch: 30 -> Test Accuracy: 85.46\n",
      "[31, 60] loss: 0.252\n",
      "[31, 120] loss: 0.249\n",
      "[31, 180] loss: 0.265\n",
      "[31, 240] loss: 0.274\n",
      "[31, 300] loss: 0.278\n",
      "[31, 360] loss: 0.285\n",
      "Epoch: 31 -> Loss: 0.324928581715\n",
      "Epoch: 31 -> Test Accuracy: 86.2\n",
      "[32, 60] loss: 0.248\n",
      "[32, 120] loss: 0.260\n",
      "[32, 180] loss: 0.277\n",
      "[32, 240] loss: 0.266\n",
      "[32, 300] loss: 0.275\n",
      "[32, 360] loss: 0.281\n",
      "Epoch: 32 -> Loss: 0.217931956053\n",
      "Epoch: 32 -> Test Accuracy: 85.69\n",
      "[33, 60] loss: 0.234\n",
      "[33, 120] loss: 0.257\n",
      "[33, 180] loss: 0.261\n",
      "[33, 240] loss: 0.263\n",
      "[33, 300] loss: 0.284\n",
      "[33, 360] loss: 0.290\n",
      "Epoch: 33 -> Loss: 0.226124957204\n",
      "Epoch: 33 -> Test Accuracy: 85.89\n",
      "[34, 60] loss: 0.234\n",
      "[34, 120] loss: 0.247\n",
      "[34, 180] loss: 0.266\n",
      "[34, 240] loss: 0.272\n",
      "[34, 300] loss: 0.284\n",
      "[34, 360] loss: 0.280\n",
      "Epoch: 34 -> Loss: 0.312292128801\n",
      "Epoch: 34 -> Test Accuracy: 85.61\n",
      "[35, 60] loss: 0.239\n",
      "[35, 120] loss: 0.258\n",
      "[35, 180] loss: 0.267\n",
      "[35, 240] loss: 0.266\n",
      "[35, 300] loss: 0.276\n",
      "[35, 360] loss: 0.288\n",
      "Epoch: 35 -> Loss: 0.232284829021\n",
      "Epoch: 35 -> Test Accuracy: 86.26\n",
      "[36, 60] loss: 0.203\n",
      "[36, 120] loss: 0.188\n",
      "[36, 180] loss: 0.181\n",
      "[36, 240] loss: 0.160\n",
      "[36, 300] loss: 0.169\n",
      "[36, 360] loss: 0.176\n",
      "Epoch: 36 -> Loss: 0.147477537394\n",
      "Epoch: 36 -> Test Accuracy: 88.2\n",
      "[37, 60] loss: 0.141\n",
      "[37, 120] loss: 0.147\n",
      "[37, 180] loss: 0.145\n",
      "[37, 240] loss: 0.147\n",
      "[37, 300] loss: 0.150\n",
      "[37, 360] loss: 0.148\n",
      "Epoch: 37 -> Loss: 0.127799779177\n",
      "Epoch: 37 -> Test Accuracy: 88.26\n",
      "[38, 60] loss: 0.130\n",
      "[38, 120] loss: 0.131\n",
      "[38, 180] loss: 0.138\n",
      "[38, 240] loss: 0.145\n",
      "[38, 300] loss: 0.137\n",
      "[38, 360] loss: 0.143\n",
      "Epoch: 38 -> Loss: 0.101877167821\n",
      "Epoch: 38 -> Test Accuracy: 88.04\n",
      "[39, 60] loss: 0.117\n",
      "[39, 120] loss: 0.120\n",
      "[39, 180] loss: 0.125\n",
      "[39, 240] loss: 0.116\n",
      "[39, 300] loss: 0.135\n",
      "[39, 360] loss: 0.136\n",
      "Epoch: 39 -> Loss: 0.118559643626\n",
      "Epoch: 39 -> Test Accuracy: 88.24\n",
      "[40, 60] loss: 0.113\n",
      "[40, 120] loss: 0.117\n",
      "[40, 180] loss: 0.118\n",
      "[40, 240] loss: 0.120\n",
      "[40, 300] loss: 0.124\n",
      "[40, 360] loss: 0.123\n",
      "Epoch: 40 -> Loss: 0.0976566374302\n",
      "Epoch: 40 -> Test Accuracy: 88.12\n",
      "[41, 60] loss: 0.113\n",
      "[41, 120] loss: 0.112\n",
      "[41, 180] loss: 0.115\n",
      "[41, 240] loss: 0.108\n",
      "[41, 300] loss: 0.119\n",
      "[41, 360] loss: 0.122\n",
      "Epoch: 41 -> Loss: 0.0460130013525\n",
      "Epoch: 41 -> Test Accuracy: 87.94\n",
      "[42, 60] loss: 0.100\n",
      "[42, 120] loss: 0.103\n",
      "[42, 180] loss: 0.112\n",
      "[42, 240] loss: 0.111\n",
      "[42, 300] loss: 0.116\n",
      "[42, 360] loss: 0.119\n",
      "Epoch: 42 -> Loss: 0.0915532708168\n",
      "Epoch: 42 -> Test Accuracy: 88.0\n",
      "[43, 60] loss: 0.093\n",
      "[43, 120] loss: 0.104\n",
      "[43, 180] loss: 0.107\n",
      "[43, 240] loss: 0.107\n",
      "[43, 300] loss: 0.120\n",
      "[43, 360] loss: 0.121\n",
      "Epoch: 43 -> Loss: 0.0771202594042\n",
      "Epoch: 43 -> Test Accuracy: 87.67\n",
      "[44, 60] loss: 0.103\n",
      "[44, 120] loss: 0.101\n",
      "[44, 180] loss: 0.104\n",
      "[44, 240] loss: 0.109\n",
      "[44, 300] loss: 0.111\n",
      "[44, 360] loss: 0.122\n",
      "Epoch: 44 -> Loss: 0.1015945822\n",
      "Epoch: 44 -> Test Accuracy: 88.09\n",
      "[45, 60] loss: 0.098\n",
      "[45, 120] loss: 0.104\n",
      "[45, 180] loss: 0.102\n",
      "[45, 240] loss: 0.109\n",
      "[45, 300] loss: 0.119\n",
      "[45, 360] loss: 0.109\n",
      "Epoch: 45 -> Loss: 0.143879905343\n",
      "Epoch: 45 -> Test Accuracy: 88.02\n",
      "[46, 60] loss: 0.092\n",
      "[46, 120] loss: 0.103\n",
      "[46, 180] loss: 0.105\n",
      "[46, 240] loss: 0.113\n",
      "[46, 300] loss: 0.104\n",
      "[46, 360] loss: 0.113\n",
      "Epoch: 46 -> Loss: 0.152754217386\n",
      "Epoch: 46 -> Test Accuracy: 87.93\n",
      "[47, 60] loss: 0.100\n",
      "[47, 120] loss: 0.107\n",
      "[47, 180] loss: 0.110\n",
      "[47, 240] loss: 0.109\n",
      "[47, 300] loss: 0.113\n",
      "[47, 360] loss: 0.117\n",
      "Epoch: 47 -> Loss: 0.180139839649\n",
      "Epoch: 47 -> Test Accuracy: 87.57\n",
      "[48, 60] loss: 0.093\n",
      "[48, 120] loss: 0.100\n",
      "[48, 180] loss: 0.095\n",
      "[48, 240] loss: 0.121\n",
      "[48, 300] loss: 0.111\n",
      "[48, 360] loss: 0.114\n",
      "Epoch: 48 -> Loss: 0.161243930459\n",
      "Epoch: 48 -> Test Accuracy: 87.3\n",
      "[49, 60] loss: 0.095\n",
      "[49, 120] loss: 0.099\n",
      "[49, 180] loss: 0.109\n",
      "[49, 240] loss: 0.107\n",
      "[49, 300] loss: 0.120\n",
      "[49, 360] loss: 0.119\n",
      "Epoch: 49 -> Loss: 0.136429190636\n",
      "Epoch: 49 -> Test Accuracy: 87.67\n",
      "[50, 60] loss: 0.094\n",
      "[50, 120] loss: 0.104\n",
      "[50, 180] loss: 0.102\n",
      "[50, 240] loss: 0.105\n",
      "[50, 300] loss: 0.113\n",
      "[50, 360] loss: 0.120\n",
      "Epoch: 50 -> Loss: 0.105074964464\n",
      "Epoch: 50 -> Test Accuracy: 87.79\n",
      "[51, 60] loss: 0.102\n",
      "[51, 120] loss: 0.106\n",
      "[51, 180] loss: 0.109\n",
      "[51, 240] loss: 0.103\n",
      "[51, 300] loss: 0.108\n",
      "[51, 360] loss: 0.122\n",
      "Epoch: 51 -> Loss: 0.130261033773\n",
      "Epoch: 51 -> Test Accuracy: 87.58\n",
      "[52, 60] loss: 0.099\n",
      "[52, 120] loss: 0.096\n",
      "[52, 180] loss: 0.109\n",
      "[52, 240] loss: 0.105\n",
      "[52, 300] loss: 0.123\n",
      "[52, 360] loss: 0.120\n",
      "Epoch: 52 -> Loss: 0.105667151511\n",
      "Epoch: 52 -> Test Accuracy: 87.7\n",
      "[53, 60] loss: 0.100\n",
      "[53, 120] loss: 0.106\n",
      "[53, 180] loss: 0.101\n",
      "[53, 240] loss: 0.113\n",
      "[53, 300] loss: 0.116\n",
      "[53, 360] loss: 0.127\n",
      "Epoch: 53 -> Loss: 0.101517722011\n",
      "Epoch: 53 -> Test Accuracy: 87.69\n",
      "[54, 60] loss: 0.103\n",
      "[54, 120] loss: 0.101\n",
      "[54, 180] loss: 0.111\n",
      "[54, 240] loss: 0.111\n",
      "[54, 300] loss: 0.115\n",
      "[54, 360] loss: 0.109\n",
      "Epoch: 54 -> Loss: 0.0614903457463\n",
      "Epoch: 54 -> Test Accuracy: 87.23\n",
      "[55, 60] loss: 0.097\n",
      "[55, 120] loss: 0.096\n",
      "[55, 180] loss: 0.104\n",
      "[55, 240] loss: 0.109\n",
      "[55, 300] loss: 0.121\n",
      "[55, 360] loss: 0.121\n",
      "Epoch: 55 -> Loss: 0.0488305650651\n",
      "Epoch: 55 -> Test Accuracy: 87.71\n",
      "[56, 60] loss: 0.106\n",
      "[56, 120] loss: 0.105\n",
      "[56, 180] loss: 0.109\n",
      "[56, 240] loss: 0.105\n",
      "[56, 300] loss: 0.113\n",
      "[56, 360] loss: 0.121\n",
      "Epoch: 56 -> Loss: 0.179651007056\n",
      "Epoch: 56 -> Test Accuracy: 87.39\n",
      "[57, 60] loss: 0.105\n",
      "[57, 120] loss: 0.108\n",
      "[57, 180] loss: 0.112\n",
      "[57, 240] loss: 0.114\n",
      "[57, 300] loss: 0.104\n",
      "[57, 360] loss: 0.107\n",
      "Epoch: 57 -> Loss: 0.133594423532\n",
      "Epoch: 57 -> Test Accuracy: 87.06\n",
      "[58, 60] loss: 0.105\n",
      "[58, 120] loss: 0.103\n",
      "[58, 180] loss: 0.106\n",
      "[58, 240] loss: 0.104\n",
      "[58, 300] loss: 0.116\n",
      "[58, 360] loss: 0.119\n",
      "Epoch: 58 -> Loss: 0.113112285733\n",
      "Epoch: 58 -> Test Accuracy: 87.46\n",
      "[59, 60] loss: 0.100\n",
      "[59, 120] loss: 0.105\n",
      "[59, 180] loss: 0.112\n",
      "[59, 240] loss: 0.110\n",
      "[59, 300] loss: 0.108\n",
      "[59, 360] loss: 0.123\n",
      "Epoch: 59 -> Loss: 0.120920315385\n",
      "Epoch: 59 -> Test Accuracy: 87.41\n",
      "[60, 60] loss: 0.102\n",
      "[60, 120] loss: 0.108\n",
      "[60, 180] loss: 0.110\n",
      "[60, 240] loss: 0.107\n",
      "[60, 300] loss: 0.115\n",
      "[60, 360] loss: 0.113\n",
      "Epoch: 60 -> Loss: 0.128071188927\n",
      "Epoch: 60 -> Test Accuracy: 86.91\n",
      "[61, 60] loss: 0.109\n",
      "[61, 120] loss: 0.100\n",
      "[61, 180] loss: 0.107\n",
      "[61, 240] loss: 0.116\n",
      "[61, 300] loss: 0.110\n",
      "[61, 360] loss: 0.108\n",
      "Epoch: 61 -> Loss: 0.24754679203\n",
      "Epoch: 61 -> Test Accuracy: 87.13\n",
      "[62, 60] loss: 0.099\n",
      "[62, 120] loss: 0.099\n",
      "[62, 180] loss: 0.098\n",
      "[62, 240] loss: 0.107\n",
      "[62, 300] loss: 0.117\n",
      "[62, 360] loss: 0.123\n",
      "Epoch: 62 -> Loss: 0.140629321337\n",
      "Epoch: 62 -> Test Accuracy: 87.19\n",
      "[63, 60] loss: 0.099\n",
      "[63, 120] loss: 0.109\n",
      "[63, 180] loss: 0.096\n",
      "[63, 240] loss: 0.106\n",
      "[63, 300] loss: 0.112\n",
      "[63, 360] loss: 0.113\n",
      "Epoch: 63 -> Loss: 0.116040453315\n",
      "Epoch: 63 -> Test Accuracy: 87.03\n",
      "[64, 60] loss: 0.099\n",
      "[64, 120] loss: 0.091\n",
      "[64, 180] loss: 0.098\n",
      "[64, 240] loss: 0.107\n",
      "[64, 300] loss: 0.116\n",
      "[64, 360] loss: 0.118\n",
      "Epoch: 64 -> Loss: 0.0881711989641\n",
      "Epoch: 64 -> Test Accuracy: 87.67\n",
      "[65, 60] loss: 0.094\n",
      "[65, 120] loss: 0.101\n",
      "[65, 180] loss: 0.103\n",
      "[65, 240] loss: 0.104\n",
      "[65, 300] loss: 0.101\n",
      "[65, 360] loss: 0.114\n",
      "Epoch: 65 -> Loss: 0.0817269459367\n",
      "Epoch: 65 -> Test Accuracy: 87.36\n",
      "[66, 60] loss: 0.097\n",
      "[66, 120] loss: 0.106\n",
      "[66, 180] loss: 0.102\n",
      "[66, 240] loss: 0.109\n",
      "[66, 300] loss: 0.111\n",
      "[66, 360] loss: 0.114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Loss: 0.164013296366\n",
      "Epoch: 66 -> Test Accuracy: 87.58\n",
      "[67, 60] loss: 0.103\n",
      "[67, 120] loss: 0.105\n",
      "[67, 180] loss: 0.103\n",
      "[67, 240] loss: 0.114\n",
      "[67, 300] loss: 0.108\n",
      "[67, 360] loss: 0.114\n",
      "Epoch: 67 -> Loss: 0.0772556811571\n",
      "Epoch: 67 -> Test Accuracy: 86.82\n",
      "[68, 60] loss: 0.100\n",
      "[68, 120] loss: 0.103\n",
      "[68, 180] loss: 0.108\n",
      "[68, 240] loss: 0.100\n",
      "[68, 300] loss: 0.110\n",
      "[68, 360] loss: 0.113\n",
      "Epoch: 68 -> Loss: 0.0822162479162\n",
      "Epoch: 68 -> Test Accuracy: 87.56\n",
      "[69, 60] loss: 0.097\n",
      "[69, 120] loss: 0.098\n",
      "[69, 180] loss: 0.101\n",
      "[69, 240] loss: 0.104\n",
      "[69, 300] loss: 0.116\n",
      "[69, 360] loss: 0.111\n",
      "Epoch: 69 -> Loss: 0.102196291089\n",
      "Epoch: 69 -> Test Accuracy: 87.01\n",
      "[70, 60] loss: 0.100\n",
      "[70, 120] loss: 0.093\n",
      "[70, 180] loss: 0.108\n",
      "[70, 240] loss: 0.109\n",
      "[70, 300] loss: 0.104\n",
      "[70, 360] loss: 0.114\n",
      "Epoch: 70 -> Loss: 0.189903616905\n",
      "Epoch: 70 -> Test Accuracy: 87.45\n",
      "[71, 60] loss: 0.074\n",
      "[71, 120] loss: 0.071\n",
      "[71, 180] loss: 0.068\n",
      "[71, 240] loss: 0.064\n",
      "[71, 300] loss: 0.062\n",
      "[71, 360] loss: 0.062\n",
      "Epoch: 71 -> Loss: 0.0460370704532\n",
      "Epoch: 71 -> Test Accuracy: 88.58\n",
      "[72, 60] loss: 0.054\n",
      "[72, 120] loss: 0.056\n",
      "[72, 180] loss: 0.053\n",
      "[72, 240] loss: 0.050\n",
      "[72, 300] loss: 0.060\n",
      "[72, 360] loss: 0.056\n",
      "Epoch: 72 -> Loss: 0.0404352359474\n",
      "Epoch: 72 -> Test Accuracy: 88.54\n",
      "[73, 60] loss: 0.049\n",
      "[73, 120] loss: 0.044\n",
      "[73, 180] loss: 0.052\n",
      "[73, 240] loss: 0.051\n",
      "[73, 300] loss: 0.051\n",
      "[73, 360] loss: 0.048\n",
      "Epoch: 73 -> Loss: 0.0345988273621\n",
      "Epoch: 73 -> Test Accuracy: 88.76\n",
      "[74, 60] loss: 0.042\n",
      "[74, 120] loss: 0.047\n",
      "[74, 180] loss: 0.045\n",
      "[74, 240] loss: 0.048\n",
      "[74, 300] loss: 0.047\n",
      "[74, 360] loss: 0.042\n",
      "Epoch: 74 -> Loss: 0.020695855841\n",
      "Epoch: 74 -> Test Accuracy: 88.74\n",
      "[75, 60] loss: 0.043\n",
      "[75, 120] loss: 0.044\n",
      "[75, 180] loss: 0.041\n",
      "[75, 240] loss: 0.044\n",
      "[75, 300] loss: 0.044\n",
      "[75, 360] loss: 0.045\n",
      "Epoch: 75 -> Loss: 0.0674355328083\n",
      "Epoch: 75 -> Test Accuracy: 88.52\n",
      "[76, 60] loss: 0.043\n",
      "[76, 120] loss: 0.041\n",
      "[76, 180] loss: 0.038\n",
      "[76, 240] loss: 0.039\n",
      "[76, 300] loss: 0.042\n",
      "[76, 360] loss: 0.043\n",
      "Epoch: 76 -> Loss: 0.0397047698498\n",
      "Epoch: 76 -> Test Accuracy: 88.69\n",
      "[77, 60] loss: 0.041\n",
      "[77, 120] loss: 0.041\n",
      "[77, 180] loss: 0.037\n",
      "[77, 240] loss: 0.041\n",
      "[77, 300] loss: 0.044\n",
      "[77, 360] loss: 0.040\n",
      "Epoch: 77 -> Loss: 0.0739384442568\n",
      "Epoch: 77 -> Test Accuracy: 88.88\n",
      "[78, 60] loss: 0.036\n",
      "[78, 120] loss: 0.038\n",
      "[78, 180] loss: 0.041\n",
      "[78, 240] loss: 0.040\n",
      "[78, 300] loss: 0.039\n",
      "[78, 360] loss: 0.038\n",
      "Epoch: 78 -> Loss: 0.0402158088982\n",
      "Epoch: 78 -> Test Accuracy: 88.58\n",
      "[79, 60] loss: 0.037\n",
      "[79, 120] loss: 0.041\n",
      "[79, 180] loss: 0.035\n",
      "[79, 240] loss: 0.037\n",
      "[79, 300] loss: 0.037\n",
      "[79, 360] loss: 0.037\n",
      "Epoch: 79 -> Loss: 0.0498256273568\n",
      "Epoch: 79 -> Test Accuracy: 88.7\n",
      "[80, 60] loss: 0.037\n",
      "[80, 120] loss: 0.035\n",
      "[80, 180] loss: 0.037\n",
      "[80, 240] loss: 0.035\n",
      "[80, 300] loss: 0.040\n",
      "[80, 360] loss: 0.037\n",
      "Epoch: 80 -> Loss: 0.0296311341226\n",
      "Epoch: 80 -> Test Accuracy: 88.63\n",
      "[81, 60] loss: 0.035\n",
      "[81, 120] loss: 0.036\n",
      "[81, 180] loss: 0.039\n",
      "[81, 240] loss: 0.037\n",
      "[81, 300] loss: 0.034\n",
      "[81, 360] loss: 0.035\n",
      "Epoch: 81 -> Loss: 0.050663150847\n",
      "Epoch: 81 -> Test Accuracy: 88.52\n",
      "[82, 60] loss: 0.033\n",
      "[82, 120] loss: 0.031\n",
      "[82, 180] loss: 0.035\n",
      "[82, 240] loss: 0.035\n",
      "[82, 300] loss: 0.038\n",
      "[82, 360] loss: 0.035\n",
      "Epoch: 82 -> Loss: 0.021719366312\n",
      "Epoch: 82 -> Test Accuracy: 88.72\n",
      "[83, 60] loss: 0.032\n",
      "[83, 120] loss: 0.035\n",
      "[83, 180] loss: 0.037\n",
      "[83, 240] loss: 0.033\n",
      "[83, 300] loss: 0.034\n",
      "[83, 360] loss: 0.034\n",
      "Epoch: 83 -> Loss: 0.021537065506\n",
      "Epoch: 83 -> Test Accuracy: 88.86\n",
      "[84, 60] loss: 0.031\n",
      "[84, 120] loss: 0.034\n",
      "[84, 180] loss: 0.036\n",
      "[84, 240] loss: 0.036\n",
      "[84, 300] loss: 0.034\n",
      "[84, 360] loss: 0.032\n",
      "Epoch: 84 -> Loss: 0.0686306804419\n",
      "Epoch: 84 -> Test Accuracy: 88.78\n",
      "[85, 60] loss: 0.032\n",
      "[85, 120] loss: 0.032\n",
      "[85, 180] loss: 0.032\n",
      "[85, 240] loss: 0.032\n",
      "[85, 300] loss: 0.032\n",
      "[85, 360] loss: 0.032\n",
      "Epoch: 85 -> Loss: 0.038092110306\n",
      "Epoch: 85 -> Test Accuracy: 88.81\n",
      "[86, 60] loss: 0.029\n",
      "[86, 120] loss: 0.030\n",
      "[86, 180] loss: 0.029\n",
      "[86, 240] loss: 0.029\n",
      "[86, 300] loss: 0.029\n",
      "[86, 360] loss: 0.029\n",
      "Epoch: 86 -> Loss: 0.0370008982718\n",
      "Epoch: 86 -> Test Accuracy: 88.88\n",
      "[87, 60] loss: 0.029\n",
      "[87, 120] loss: 0.027\n",
      "[87, 180] loss: 0.028\n",
      "[87, 240] loss: 0.027\n",
      "[87, 300] loss: 0.031\n",
      "[87, 360] loss: 0.030\n",
      "Epoch: 87 -> Loss: 0.0638825148344\n",
      "Epoch: 87 -> Test Accuracy: 88.99\n",
      "[88, 60] loss: 0.030\n",
      "[88, 120] loss: 0.028\n",
      "[88, 180] loss: 0.027\n",
      "[88, 240] loss: 0.028\n",
      "[88, 300] loss: 0.025\n",
      "[88, 360] loss: 0.028\n",
      "Epoch: 88 -> Loss: 0.0306285060942\n",
      "Epoch: 88 -> Test Accuracy: 88.68\n",
      "[89, 60] loss: 0.027\n",
      "[89, 120] loss: 0.027\n",
      "[89, 180] loss: 0.029\n",
      "[89, 240] loss: 0.030\n",
      "[89, 300] loss: 0.028\n",
      "[89, 360] loss: 0.030\n",
      "Epoch: 89 -> Loss: 0.0529460385442\n",
      "Epoch: 89 -> Test Accuracy: 88.88\n",
      "[90, 60] loss: 0.027\n",
      "[90, 120] loss: 0.028\n",
      "[90, 180] loss: 0.029\n",
      "[90, 240] loss: 0.029\n",
      "[90, 300] loss: 0.029\n",
      "[90, 360] loss: 0.025\n",
      "Epoch: 90 -> Loss: 0.0197838954628\n",
      "Epoch: 90 -> Test Accuracy: 88.89\n",
      "[91, 60] loss: 0.026\n",
      "[91, 120] loss: 0.029\n",
      "[91, 180] loss: 0.028\n",
      "[91, 240] loss: 0.028\n",
      "[91, 300] loss: 0.026\n",
      "[91, 360] loss: 0.026\n",
      "Epoch: 91 -> Loss: 0.024331022054\n",
      "Epoch: 91 -> Test Accuracy: 88.9\n",
      "[92, 60] loss: 0.027\n",
      "[92, 120] loss: 0.028\n",
      "[92, 180] loss: 0.026\n",
      "[92, 240] loss: 0.026\n",
      "[92, 300] loss: 0.025\n",
      "[92, 360] loss: 0.029\n",
      "Epoch: 92 -> Loss: 0.0443188846111\n",
      "Epoch: 92 -> Test Accuracy: 88.86\n",
      "[93, 60] loss: 0.025\n",
      "[93, 120] loss: 0.027\n",
      "[93, 180] loss: 0.028\n",
      "[93, 240] loss: 0.027\n",
      "[93, 300] loss: 0.029\n",
      "[93, 360] loss: 0.029\n",
      "Epoch: 93 -> Loss: 0.0265762563795\n",
      "Epoch: 93 -> Test Accuracy: 88.8\n",
      "[94, 60] loss: 0.026\n",
      "[94, 120] loss: 0.027\n",
      "[94, 180] loss: 0.027\n",
      "[94, 240] loss: 0.026\n",
      "[94, 300] loss: 0.027\n",
      "[94, 360] loss: 0.026\n",
      "Epoch: 94 -> Loss: 0.0204644501209\n",
      "Epoch: 94 -> Test Accuracy: 88.72\n",
      "[95, 60] loss: 0.025\n",
      "[95, 120] loss: 0.027\n",
      "[95, 180] loss: 0.028\n",
      "[95, 240] loss: 0.028\n",
      "[95, 300] loss: 0.027\n",
      "[95, 360] loss: 0.027\n",
      "Epoch: 95 -> Loss: 0.0251078605652\n",
      "Epoch: 95 -> Test Accuracy: 88.82\n",
      "[96, 60] loss: 0.025\n",
      "[96, 120] loss: 0.025\n",
      "[96, 180] loss: 0.028\n",
      "[96, 240] loss: 0.025\n",
      "[96, 300] loss: 0.027\n",
      "[96, 360] loss: 0.027\n",
      "Epoch: 96 -> Loss: 0.0565241165459\n",
      "Epoch: 96 -> Test Accuracy: 88.9\n",
      "[97, 60] loss: 0.029\n",
      "[97, 120] loss: 0.026\n",
      "[97, 180] loss: 0.025\n",
      "[97, 240] loss: 0.027\n",
      "[97, 300] loss: 0.027\n",
      "[97, 360] loss: 0.026\n",
      "Epoch: 97 -> Loss: 0.0237293429673\n",
      "Epoch: 97 -> Test Accuracy: 88.82\n",
      "[98, 60] loss: 0.023\n",
      "[98, 120] loss: 0.025\n",
      "[98, 180] loss: 0.027\n",
      "[98, 240] loss: 0.026\n",
      "[98, 300] loss: 0.025\n",
      "[98, 360] loss: 0.027\n",
      "Epoch: 98 -> Loss: 0.0092001138255\n",
      "Epoch: 98 -> Test Accuracy: 88.76\n",
      "[99, 60] loss: 0.024\n",
      "[99, 120] loss: 0.029\n",
      "[99, 180] loss: 0.025\n",
      "[99, 240] loss: 0.025\n",
      "[99, 300] loss: 0.026\n",
      "[99, 360] loss: 0.027\n",
      "Epoch: 99 -> Loss: 0.0157920122147\n",
      "Epoch: 99 -> Test Accuracy: 88.78\n",
      "[100, 60] loss: 0.025\n",
      "[100, 120] loss: 0.025\n",
      "[100, 180] loss: 0.025\n",
      "[100, 240] loss: 0.025\n",
      "[100, 300] loss: 0.026\n",
      "[100, 360] loss: 0.024\n",
      "Epoch: 100 -> Loss: 0.0201563090086\n",
      "Epoch: 100 -> Test Accuracy: 88.82\n",
      "Finished Training\n",
      "[1, 60] loss: 1.863\n",
      "[1, 120] loss: 1.657\n",
      "[1, 180] loss: 1.573\n",
      "[1, 240] loss: 1.547\n",
      "[1, 300] loss: 1.518\n",
      "[1, 360] loss: 1.465\n",
      "Epoch: 1 -> Loss: 1.38100779057\n",
      "Epoch: 1 -> Test Accuracy: 42.51\n",
      "[2, 60] loss: 1.455\n",
      "[2, 120] loss: 1.455\n",
      "[2, 180] loss: 1.424\n",
      "[2, 240] loss: 1.439\n",
      "[2, 300] loss: 1.431\n",
      "[2, 360] loss: 1.394\n",
      "Epoch: 2 -> Loss: 1.57546544075\n",
      "Epoch: 2 -> Test Accuracy: 46.54\n",
      "[3, 60] loss: 1.372\n",
      "[3, 120] loss: 1.386\n",
      "[3, 180] loss: 1.390\n",
      "[3, 240] loss: 1.368\n",
      "[3, 300] loss: 1.359\n",
      "[3, 360] loss: 1.359\n",
      "Epoch: 3 -> Loss: 1.44619822502\n",
      "Epoch: 3 -> Test Accuracy: 46.99\n",
      "[4, 60] loss: 1.343\n",
      "[4, 120] loss: 1.357\n",
      "[4, 180] loss: 1.338\n",
      "[4, 240] loss: 1.347\n",
      "[4, 300] loss: 1.311\n",
      "[4, 360] loss: 1.337\n",
      "Epoch: 4 -> Loss: 1.35329127312\n",
      "Epoch: 4 -> Test Accuracy: 48.98\n",
      "[5, 60] loss: 1.329\n",
      "[5, 120] loss: 1.306\n",
      "[5, 180] loss: 1.312\n",
      "[5, 240] loss: 1.317\n",
      "[5, 300] loss: 1.333\n",
      "[5, 360] loss: 1.317\n",
      "Epoch: 5 -> Loss: 1.33428633213\n",
      "Epoch: 5 -> Test Accuracy: 48.82\n",
      "[6, 60] loss: 1.311\n",
      "[6, 120] loss: 1.305\n",
      "[6, 180] loss: 1.277\n",
      "[6, 240] loss: 1.309\n",
      "[6, 300] loss: 1.308\n",
      "[6, 360] loss: 1.283\n",
      "Epoch: 6 -> Loss: 1.38868832588\n",
      "Epoch: 6 -> Test Accuracy: 48.68\n",
      "[7, 60] loss: 1.287\n",
      "[7, 120] loss: 1.294\n",
      "[7, 180] loss: 1.272\n",
      "[7, 240] loss: 1.288\n",
      "[7, 300] loss: 1.297\n",
      "[7, 360] loss: 1.285\n",
      "Epoch: 7 -> Loss: 1.12669825554\n",
      "Epoch: 7 -> Test Accuracy: 49.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 60] loss: 1.289\n",
      "[8, 120] loss: 1.275\n",
      "[8, 180] loss: 1.278\n",
      "[8, 240] loss: 1.263\n",
      "[8, 300] loss: 1.283\n",
      "[8, 360] loss: 1.283\n",
      "Epoch: 8 -> Loss: 1.37220048904\n",
      "Epoch: 8 -> Test Accuracy: 50.36\n",
      "[9, 60] loss: 1.268\n",
      "[9, 120] loss: 1.257\n",
      "[9, 180] loss: 1.257\n",
      "[9, 240] loss: 1.270\n",
      "[9, 300] loss: 1.275\n",
      "[9, 360] loss: 1.271\n",
      "Epoch: 9 -> Loss: 1.19314074516\n",
      "Epoch: 9 -> Test Accuracy: 49.89\n",
      "[10, 60] loss: 1.278\n",
      "[10, 120] loss: 1.246\n",
      "[10, 180] loss: 1.270\n",
      "[10, 240] loss: 1.252\n",
      "[10, 300] loss: 1.265\n",
      "[10, 360] loss: 1.269\n",
      "Epoch: 10 -> Loss: 1.18051970005\n",
      "Epoch: 10 -> Test Accuracy: 50.67\n",
      "[11, 60] loss: 1.248\n",
      "[11, 120] loss: 1.282\n",
      "[11, 180] loss: 1.244\n",
      "[11, 240] loss: 1.267\n",
      "[11, 300] loss: 1.260\n",
      "[11, 360] loss: 1.241\n",
      "Epoch: 11 -> Loss: 1.45489859581\n",
      "Epoch: 11 -> Test Accuracy: 50.52\n",
      "[12, 60] loss: 1.276\n",
      "[12, 120] loss: 1.252\n",
      "[12, 180] loss: 1.259\n",
      "[12, 240] loss: 1.249\n",
      "[12, 300] loss: 1.243\n",
      "[12, 360] loss: 1.251\n",
      "Epoch: 12 -> Loss: 1.29271221161\n",
      "Epoch: 12 -> Test Accuracy: 49.86\n",
      "[13, 60] loss: 1.252\n",
      "[13, 120] loss: 1.256\n",
      "[13, 180] loss: 1.255\n",
      "[13, 240] loss: 1.249\n",
      "[13, 300] loss: 1.249\n",
      "[13, 360] loss: 1.262\n",
      "Epoch: 13 -> Loss: 1.41856431961\n",
      "Epoch: 13 -> Test Accuracy: 50.32\n",
      "[14, 60] loss: 1.262\n",
      "[14, 120] loss: 1.239\n",
      "[14, 180] loss: 1.260\n",
      "[14, 240] loss: 1.256\n",
      "[14, 300] loss: 1.254\n",
      "[14, 360] loss: 1.233\n",
      "Epoch: 14 -> Loss: 1.20106911659\n",
      "Epoch: 14 -> Test Accuracy: 49.65\n",
      "[15, 60] loss: 1.250\n",
      "[15, 120] loss: 1.250\n",
      "[15, 180] loss: 1.234\n",
      "[15, 240] loss: 1.224\n",
      "[15, 300] loss: 1.250\n",
      "[15, 360] loss: 1.235\n",
      "Epoch: 15 -> Loss: 1.21732747555\n",
      "Epoch: 15 -> Test Accuracy: 51.29\n",
      "[16, 60] loss: 1.247\n",
      "[16, 120] loss: 1.246\n",
      "[16, 180] loss: 1.217\n",
      "[16, 240] loss: 1.224\n",
      "[16, 300] loss: 1.253\n",
      "[16, 360] loss: 1.238\n",
      "Epoch: 16 -> Loss: 1.28469765186\n",
      "Epoch: 16 -> Test Accuracy: 51.23\n",
      "[17, 60] loss: 1.226\n",
      "[17, 120] loss: 1.239\n",
      "[17, 180] loss: 1.248\n",
      "[17, 240] loss: 1.240\n",
      "[17, 300] loss: 1.244\n",
      "[17, 360] loss: 1.251\n",
      "Epoch: 17 -> Loss: 1.24963212013\n",
      "Epoch: 17 -> Test Accuracy: 51.43\n",
      "[18, 60] loss: 1.245\n",
      "[18, 120] loss: 1.241\n",
      "[18, 180] loss: 1.260\n",
      "[18, 240] loss: 1.241\n",
      "[18, 300] loss: 1.249\n",
      "[18, 360] loss: 1.231\n",
      "Epoch: 18 -> Loss: 1.35986924171\n",
      "Epoch: 18 -> Test Accuracy: 50.88\n",
      "[19, 60] loss: 1.251\n",
      "[19, 120] loss: 1.233\n",
      "[19, 180] loss: 1.229\n",
      "[19, 240] loss: 1.237\n",
      "[19, 300] loss: 1.233\n",
      "[19, 360] loss: 1.231\n",
      "Epoch: 19 -> Loss: 1.27556943893\n",
      "Epoch: 19 -> Test Accuracy: 50.71\n",
      "[20, 60] loss: 1.236\n",
      "[20, 120] loss: 1.227\n",
      "[20, 180] loss: 1.237\n",
      "[20, 240] loss: 1.235\n",
      "[20, 300] loss: 1.200\n",
      "[20, 360] loss: 1.246\n",
      "Epoch: 20 -> Loss: 1.04955816269\n",
      "Epoch: 20 -> Test Accuracy: 50.77\n",
      "[21, 60] loss: 1.234\n",
      "[21, 120] loss: 1.219\n",
      "[21, 180] loss: 1.241\n",
      "[21, 240] loss: 1.230\n",
      "[21, 300] loss: 1.253\n",
      "[21, 360] loss: 1.221\n",
      "Epoch: 21 -> Loss: 1.27590477467\n",
      "Epoch: 21 -> Test Accuracy: 51.65\n",
      "[22, 60] loss: 1.239\n",
      "[22, 120] loss: 1.219\n",
      "[22, 180] loss: 1.216\n",
      "[22, 240] loss: 1.223\n",
      "[22, 300] loss: 1.239\n",
      "[22, 360] loss: 1.237\n",
      "Epoch: 22 -> Loss: 1.14897048473\n",
      "Epoch: 22 -> Test Accuracy: 52.7\n",
      "[23, 60] loss: 1.232\n",
      "[23, 120] loss: 1.231\n",
      "[23, 180] loss: 1.215\n",
      "[23, 240] loss: 1.230\n",
      "[23, 300] loss: 1.220\n",
      "[23, 360] loss: 1.253\n",
      "Epoch: 23 -> Loss: 1.38017296791\n",
      "Epoch: 23 -> Test Accuracy: 51.58\n",
      "[24, 60] loss: 1.223\n",
      "[24, 120] loss: 1.242\n",
      "[24, 180] loss: 1.219\n",
      "[24, 240] loss: 1.231\n",
      "[24, 300] loss: 1.230\n",
      "[24, 360] loss: 1.232\n",
      "Epoch: 24 -> Loss: 1.33723008633\n",
      "Epoch: 24 -> Test Accuracy: 50.85\n",
      "[25, 60] loss: 1.218\n",
      "[25, 120] loss: 1.220\n",
      "[25, 180] loss: 1.244\n",
      "[25, 240] loss: 1.210\n",
      "[25, 300] loss: 1.245\n",
      "[25, 360] loss: 1.240\n",
      "Epoch: 25 -> Loss: 1.19878721237\n",
      "Epoch: 25 -> Test Accuracy: 50.58\n",
      "[26, 60] loss: 1.242\n",
      "[26, 120] loss: 1.240\n",
      "[26, 180] loss: 1.208\n",
      "[26, 240] loss: 1.222\n",
      "[26, 300] loss: 1.225\n",
      "[26, 360] loss: 1.220\n",
      "Epoch: 26 -> Loss: 1.30900859833\n",
      "Epoch: 26 -> Test Accuracy: 52.41\n",
      "[27, 60] loss: 1.221\n",
      "[27, 120] loss: 1.225\n",
      "[27, 180] loss: 1.224\n",
      "[27, 240] loss: 1.233\n",
      "[27, 300] loss: 1.218\n",
      "[27, 360] loss: 1.201\n",
      "Epoch: 27 -> Loss: 1.29304289818\n",
      "Epoch: 27 -> Test Accuracy: 51.48\n",
      "[28, 60] loss: 1.235\n",
      "[28, 120] loss: 1.200\n",
      "[28, 180] loss: 1.212\n",
      "[28, 240] loss: 1.229\n",
      "[28, 300] loss: 1.252\n",
      "[28, 360] loss: 1.250\n",
      "Epoch: 28 -> Loss: 1.21757674217\n",
      "Epoch: 28 -> Test Accuracy: 50.61\n",
      "[29, 60] loss: 1.236\n",
      "[29, 120] loss: 1.219\n",
      "[29, 180] loss: 1.221\n",
      "[29, 240] loss: 1.235\n",
      "[29, 300] loss: 1.239\n",
      "[29, 360] loss: 1.212\n",
      "Epoch: 29 -> Loss: 1.29875969887\n",
      "Epoch: 29 -> Test Accuracy: 51.41\n",
      "[30, 60] loss: 1.200\n",
      "[30, 120] loss: 1.228\n",
      "[30, 180] loss: 1.215\n",
      "[30, 240] loss: 1.227\n",
      "[30, 300] loss: 1.237\n",
      "[30, 360] loss: 1.239\n",
      "Epoch: 30 -> Loss: 1.42523491383\n",
      "Epoch: 30 -> Test Accuracy: 52.18\n",
      "[31, 60] loss: 1.216\n",
      "[31, 120] loss: 1.223\n",
      "[31, 180] loss: 1.213\n",
      "[31, 240] loss: 1.239\n",
      "[31, 300] loss: 1.220\n",
      "[31, 360] loss: 1.222\n",
      "Epoch: 31 -> Loss: 1.45415902138\n",
      "Epoch: 31 -> Test Accuracy: 51.43\n",
      "[32, 60] loss: 1.229\n",
      "[32, 120] loss: 1.199\n",
      "[32, 180] loss: 1.220\n",
      "[32, 240] loss: 1.234\n",
      "[32, 300] loss: 1.241\n",
      "[32, 360] loss: 1.227\n",
      "Epoch: 32 -> Loss: 1.24754357338\n",
      "Epoch: 32 -> Test Accuracy: 50.31\n",
      "[33, 60] loss: 1.212\n",
      "[33, 120] loss: 1.217\n",
      "[33, 180] loss: 1.222\n",
      "[33, 240] loss: 1.230\n",
      "[33, 300] loss: 1.222\n",
      "[33, 360] loss: 1.223\n",
      "Epoch: 33 -> Loss: 1.21123230457\n",
      "Epoch: 33 -> Test Accuracy: 52.15\n",
      "[34, 60] loss: 1.231\n",
      "[34, 120] loss: 1.237\n",
      "[34, 180] loss: 1.204\n",
      "[34, 240] loss: 1.231\n",
      "[34, 300] loss: 1.209\n",
      "[34, 360] loss: 1.218\n",
      "Epoch: 34 -> Loss: 1.27467799187\n",
      "Epoch: 34 -> Test Accuracy: 51.37\n",
      "[35, 60] loss: 1.201\n",
      "[35, 120] loss: 1.208\n",
      "[35, 180] loss: 1.224\n",
      "[35, 240] loss: 1.230\n",
      "[35, 300] loss: 1.244\n",
      "[35, 360] loss: 1.226\n",
      "Epoch: 35 -> Loss: 1.30367970467\n",
      "Epoch: 35 -> Test Accuracy: 51.49\n",
      "[36, 60] loss: 1.162\n",
      "[36, 120] loss: 1.125\n",
      "[36, 180] loss: 1.105\n",
      "[36, 240] loss: 1.097\n",
      "[36, 300] loss: 1.100\n",
      "[36, 360] loss: 1.081\n",
      "Epoch: 36 -> Loss: 1.13254475594\n",
      "Epoch: 36 -> Test Accuracy: 56.02\n",
      "[37, 60] loss: 1.088\n",
      "[37, 120] loss: 1.099\n",
      "[37, 180] loss: 1.086\n",
      "[37, 240] loss: 1.068\n",
      "[37, 300] loss: 1.099\n",
      "[37, 360] loss: 1.099\n",
      "Epoch: 37 -> Loss: 1.07157111168\n",
      "Epoch: 37 -> Test Accuracy: 56.53\n",
      "[38, 60] loss: 1.071\n",
      "[38, 120] loss: 1.076\n",
      "[38, 180] loss: 1.077\n",
      "[38, 240] loss: 1.080\n",
      "[38, 300] loss: 1.099\n",
      "[38, 360] loss: 1.079\n",
      "Epoch: 38 -> Loss: 1.01064562798\n",
      "Epoch: 38 -> Test Accuracy: 56.76\n",
      "[39, 60] loss: 1.077\n",
      "[39, 120] loss: 1.070\n",
      "[39, 180] loss: 1.099\n",
      "[39, 240] loss: 1.090\n",
      "[39, 300] loss: 1.065\n",
      "[39, 360] loss: 1.082\n",
      "Epoch: 39 -> Loss: 0.90257537365\n",
      "Epoch: 39 -> Test Accuracy: 56.6\n",
      "[40, 60] loss: 1.070\n",
      "[40, 120] loss: 1.087\n",
      "[40, 180] loss: 1.071\n",
      "[40, 240] loss: 1.080\n",
      "[40, 300] loss: 1.086\n",
      "[40, 360] loss: 1.083\n",
      "Epoch: 40 -> Loss: 0.987020790577\n",
      "Epoch: 40 -> Test Accuracy: 56.6\n",
      "[41, 60] loss: 1.051\n",
      "[41, 120] loss: 1.089\n",
      "[41, 180] loss: 1.086\n",
      "[41, 240] loss: 1.068\n",
      "[41, 300] loss: 1.077\n",
      "[41, 360] loss: 1.081\n",
      "Epoch: 41 -> Loss: 1.08318543434\n",
      "Epoch: 41 -> Test Accuracy: 57.24\n",
      "[42, 60] loss: 1.083\n",
      "[42, 120] loss: 1.054\n",
      "[42, 180] loss: 1.072\n",
      "[42, 240] loss: 1.069\n",
      "[42, 300] loss: 1.075\n",
      "[42, 360] loss: 1.086\n",
      "Epoch: 42 -> Loss: 0.9835947752\n",
      "Epoch: 42 -> Test Accuracy: 56.93\n",
      "[43, 60] loss: 1.056\n",
      "[43, 120] loss: 1.080\n",
      "[43, 180] loss: 1.067\n",
      "[43, 240] loss: 1.095\n",
      "[43, 300] loss: 1.076\n",
      "[43, 360] loss: 1.069\n",
      "Epoch: 43 -> Loss: 1.08890414238\n",
      "Epoch: 43 -> Test Accuracy: 57.08\n",
      "[44, 60] loss: 1.078\n",
      "[44, 120] loss: 1.065\n",
      "[44, 180] loss: 1.072\n",
      "[44, 240] loss: 1.089\n",
      "[44, 300] loss: 1.072\n",
      "[44, 360] loss: 1.075\n",
      "Epoch: 44 -> Loss: 1.07605016232\n",
      "Epoch: 44 -> Test Accuracy: 57.03\n",
      "[45, 60] loss: 1.064\n",
      "[45, 120] loss: 1.074\n",
      "[45, 180] loss: 1.053\n",
      "[45, 240] loss: 1.078\n",
      "[45, 300] loss: 1.051\n",
      "[45, 360] loss: 1.095\n",
      "Epoch: 45 -> Loss: 1.16944479942\n",
      "Epoch: 45 -> Test Accuracy: 57.08\n",
      "[46, 60] loss: 1.057\n",
      "[46, 120] loss: 1.080\n",
      "[46, 180] loss: 1.089\n",
      "[46, 240] loss: 1.065\n",
      "[46, 300] loss: 1.076\n",
      "[46, 360] loss: 1.075\n",
      "Epoch: 46 -> Loss: 1.18470239639\n",
      "Epoch: 46 -> Test Accuracy: 56.55\n",
      "[47, 60] loss: 1.063\n",
      "[47, 120] loss: 1.064\n",
      "[47, 180] loss: 1.067\n",
      "[47, 240] loss: 1.095\n",
      "[47, 300] loss: 1.055\n",
      "[47, 360] loss: 1.070\n",
      "Epoch: 47 -> Loss: 1.24658799171\n",
      "Epoch: 47 -> Test Accuracy: 57.31\n",
      "[48, 60] loss: 1.065\n",
      "[48, 120] loss: 1.077\n",
      "[48, 180] loss: 1.075\n",
      "[48, 240] loss: 1.097\n",
      "[48, 300] loss: 1.085\n",
      "[48, 360] loss: 1.042\n",
      "Epoch: 48 -> Loss: 1.10153579712\n",
      "Epoch: 48 -> Test Accuracy: 57.02\n",
      "[49, 60] loss: 1.071\n",
      "[49, 120] loss: 1.100\n",
      "[49, 180] loss: 1.078\n",
      "[49, 240] loss: 1.088\n",
      "[49, 300] loss: 1.048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 360] loss: 1.077\n",
      "Epoch: 49 -> Loss: 1.06397080421\n",
      "Epoch: 49 -> Test Accuracy: 55.96\n",
      "[50, 60] loss: 1.067\n",
      "[50, 120] loss: 1.063\n",
      "[50, 180] loss: 1.069\n",
      "[50, 240] loss: 1.073\n",
      "[50, 300] loss: 1.082\n",
      "[50, 360] loss: 1.074\n",
      "Epoch: 50 -> Loss: 1.01605772972\n",
      "Epoch: 50 -> Test Accuracy: 56.64\n",
      "[51, 60] loss: 1.076\n",
      "[51, 120] loss: 1.099\n",
      "[51, 180] loss: 1.069\n",
      "[51, 240] loss: 1.062\n",
      "[51, 300] loss: 1.081\n",
      "[51, 360] loss: 1.075\n",
      "Epoch: 51 -> Loss: 0.962502360344\n",
      "Epoch: 51 -> Test Accuracy: 56.47\n",
      "[52, 60] loss: 1.090\n",
      "[52, 120] loss: 1.079\n",
      "[52, 180] loss: 1.045\n",
      "[52, 240] loss: 1.064\n",
      "[52, 300] loss: 1.083\n",
      "[52, 360] loss: 1.047\n",
      "Epoch: 52 -> Loss: 1.1834911108\n",
      "Epoch: 52 -> Test Accuracy: 56.96\n",
      "[53, 60] loss: 1.054\n",
      "[53, 120] loss: 1.051\n",
      "[53, 180] loss: 1.050\n",
      "[53, 240] loss: 1.085\n",
      "[53, 300] loss: 1.069\n",
      "[53, 360] loss: 1.078\n",
      "Epoch: 53 -> Loss: 1.04760217667\n",
      "Epoch: 53 -> Test Accuracy: 57.01\n",
      "[54, 60] loss: 1.051\n",
      "[54, 120] loss: 1.065\n",
      "[54, 180] loss: 1.095\n",
      "[54, 240] loss: 1.070\n",
      "[54, 300] loss: 1.064\n",
      "[54, 360] loss: 1.057\n",
      "Epoch: 54 -> Loss: 1.19820570946\n",
      "Epoch: 54 -> Test Accuracy: 57.88\n",
      "[55, 60] loss: 1.073\n",
      "[55, 120] loss: 1.072\n",
      "[55, 180] loss: 1.066\n",
      "[55, 240] loss: 1.072\n",
      "[55, 300] loss: 1.062\n",
      "[55, 360] loss: 1.043\n",
      "Epoch: 55 -> Loss: 1.05775618553\n",
      "Epoch: 55 -> Test Accuracy: 56.67\n",
      "[56, 60] loss: 1.057\n",
      "[56, 120] loss: 1.084\n",
      "[56, 180] loss: 1.067\n",
      "[56, 240] loss: 1.079\n",
      "[56, 300] loss: 1.062\n",
      "[56, 360] loss: 1.083\n",
      "Epoch: 56 -> Loss: 1.13094699383\n",
      "Epoch: 56 -> Test Accuracy: 57.29\n",
      "[57, 60] loss: 1.074\n",
      "[57, 120] loss: 1.066\n",
      "[57, 180] loss: 1.067\n",
      "[57, 240] loss: 1.046\n",
      "[57, 300] loss: 1.060\n",
      "[57, 360] loss: 1.073\n",
      "Epoch: 57 -> Loss: 1.11085772514\n",
      "Epoch: 57 -> Test Accuracy: 56.35\n",
      "[58, 60] loss: 1.057\n",
      "[58, 120] loss: 1.077\n",
      "[58, 180] loss: 1.072\n",
      "[58, 240] loss: 1.059\n",
      "[58, 300] loss: 1.078\n",
      "[58, 360] loss: 1.051\n",
      "Epoch: 58 -> Loss: 1.01605200768\n",
      "Epoch: 58 -> Test Accuracy: 56.65\n",
      "[59, 60] loss: 1.047\n",
      "[59, 120] loss: 1.072\n",
      "[59, 180] loss: 1.055\n",
      "[59, 240] loss: 1.073\n",
      "[59, 300] loss: 1.057\n",
      "[59, 360] loss: 1.094\n",
      "Epoch: 59 -> Loss: 1.15581321716\n",
      "Epoch: 59 -> Test Accuracy: 57.27\n",
      "[60, 60] loss: 1.054\n",
      "[60, 120] loss: 1.061\n",
      "[60, 180] loss: 1.060\n",
      "[60, 240] loss: 1.056\n",
      "[60, 300] loss: 1.073\n",
      "[60, 360] loss: 1.062\n",
      "Epoch: 60 -> Loss: 1.01332175732\n",
      "Epoch: 60 -> Test Accuracy: 56.89\n",
      "[61, 60] loss: 1.047\n",
      "[61, 120] loss: 1.066\n",
      "[61, 180] loss: 1.069\n",
      "[61, 240] loss: 1.065\n",
      "[61, 300] loss: 1.076\n",
      "[61, 360] loss: 1.091\n",
      "Epoch: 61 -> Loss: 0.988394081593\n",
      "Epoch: 61 -> Test Accuracy: 56.44\n",
      "[62, 60] loss: 1.083\n",
      "[62, 120] loss: 1.070\n",
      "[62, 180] loss: 1.048\n",
      "[62, 240] loss: 1.078\n",
      "[62, 300] loss: 1.059\n",
      "[62, 360] loss: 1.068\n",
      "Epoch: 62 -> Loss: 1.20921587944\n",
      "Epoch: 62 -> Test Accuracy: 57.19\n",
      "[63, 60] loss: 1.033\n",
      "[63, 120] loss: 1.043\n",
      "[63, 180] loss: 1.060\n",
      "[63, 240] loss: 1.058\n",
      "[63, 300] loss: 1.086\n",
      "[63, 360] loss: 1.087\n",
      "Epoch: 63 -> Loss: 1.16820049286\n",
      "Epoch: 63 -> Test Accuracy: 57.68\n",
      "[64, 60] loss: 1.067\n",
      "[64, 120] loss: 1.063\n",
      "[64, 180] loss: 1.053\n",
      "[64, 240] loss: 1.084\n",
      "[64, 300] loss: 1.055\n",
      "[64, 360] loss: 1.076\n",
      "Epoch: 64 -> Loss: 1.00641024113\n",
      "Epoch: 64 -> Test Accuracy: 56.5\n",
      "[65, 60] loss: 1.046\n",
      "[65, 120] loss: 1.086\n",
      "[65, 180] loss: 1.044\n",
      "[65, 240] loss: 1.064\n",
      "[65, 300] loss: 1.075\n",
      "[65, 360] loss: 1.062\n",
      "Epoch: 65 -> Loss: 1.07456374168\n",
      "Epoch: 65 -> Test Accuracy: 57.14\n",
      "[66, 60] loss: 1.066\n",
      "[66, 120] loss: 1.067\n",
      "[66, 180] loss: 1.052\n",
      "[66, 240] loss: 1.064\n",
      "[66, 300] loss: 1.057\n",
      "[66, 360] loss: 1.052\n",
      "Epoch: 66 -> Loss: 1.03426754475\n",
      "Epoch: 66 -> Test Accuracy: 56.79\n",
      "[67, 60] loss: 1.050\n",
      "[67, 120] loss: 1.056\n",
      "[67, 180] loss: 1.062\n",
      "[67, 240] loss: 1.044\n",
      "[67, 300] loss: 1.083\n",
      "[67, 360] loss: 1.075\n",
      "Epoch: 67 -> Loss: 1.13846027851\n",
      "Epoch: 67 -> Test Accuracy: 57.7\n",
      "[68, 60] loss: 1.076\n",
      "[68, 120] loss: 1.053\n",
      "[68, 180] loss: 1.060\n",
      "[68, 240] loss: 1.075\n",
      "[68, 300] loss: 1.052\n",
      "[68, 360] loss: 1.055\n",
      "Epoch: 68 -> Loss: 1.14730751514\n",
      "Epoch: 68 -> Test Accuracy: 56.93\n",
      "[69, 60] loss: 1.043\n",
      "[69, 120] loss: 1.051\n",
      "[69, 180] loss: 1.069\n",
      "[69, 240] loss: 1.047\n",
      "[69, 300] loss: 1.064\n",
      "[69, 360] loss: 1.078\n",
      "Epoch: 69 -> Loss: 1.09532833099\n",
      "Epoch: 69 -> Test Accuracy: 57.55\n",
      "[70, 60] loss: 1.074\n",
      "[70, 120] loss: 1.060\n",
      "[70, 180] loss: 1.069\n",
      "[70, 240] loss: 1.065\n",
      "[70, 300] loss: 1.055\n",
      "[70, 360] loss: 1.057\n",
      "Epoch: 70 -> Loss: 1.0877995491\n",
      "Epoch: 70 -> Test Accuracy: 57.3\n",
      "[71, 60] loss: 1.026\n",
      "[71, 120] loss: 0.990\n",
      "[71, 180] loss: 0.984\n",
      "[71, 240] loss: 0.977\n",
      "[71, 300] loss: 0.987\n",
      "[71, 360] loss: 0.970\n",
      "Epoch: 71 -> Loss: 1.03793370724\n",
      "Epoch: 71 -> Test Accuracy: 60.14\n",
      "[72, 60] loss: 0.962\n",
      "[72, 120] loss: 0.961\n",
      "[72, 180] loss: 0.965\n",
      "[72, 240] loss: 0.972\n",
      "[72, 300] loss: 0.973\n",
      "[72, 360] loss: 0.975\n",
      "Epoch: 72 -> Loss: 0.926759541035\n",
      "Epoch: 72 -> Test Accuracy: 61.0\n",
      "[73, 60] loss: 0.973\n",
      "[73, 120] loss: 0.963\n",
      "[73, 180] loss: 0.976\n",
      "[73, 240] loss: 0.944\n",
      "[73, 300] loss: 0.962\n",
      "[73, 360] loss: 0.968\n",
      "Epoch: 73 -> Loss: 1.03633105755\n",
      "Epoch: 73 -> Test Accuracy: 60.63\n",
      "[74, 60] loss: 0.957\n",
      "[74, 120] loss: 0.953\n",
      "[74, 180] loss: 0.968\n",
      "[74, 240] loss: 0.938\n",
      "[74, 300] loss: 0.959\n",
      "[74, 360] loss: 0.964\n",
      "Epoch: 74 -> Loss: 0.968690276146\n",
      "Epoch: 74 -> Test Accuracy: 60.56\n",
      "[75, 60] loss: 0.942\n",
      "[75, 120] loss: 0.962\n",
      "[75, 180] loss: 0.942\n",
      "[75, 240] loss: 0.951\n",
      "[75, 300] loss: 0.956\n",
      "[75, 360] loss: 0.946\n",
      "Epoch: 75 -> Loss: 0.793680846691\n",
      "Epoch: 75 -> Test Accuracy: 60.38\n",
      "[76, 60] loss: 0.930\n",
      "[76, 120] loss: 0.953\n",
      "[76, 180] loss: 0.942\n",
      "[76, 240] loss: 0.952\n",
      "[76, 300] loss: 0.960\n",
      "[76, 360] loss: 0.956\n",
      "Epoch: 76 -> Loss: 0.90732383728\n",
      "Epoch: 76 -> Test Accuracy: 60.94\n",
      "[77, 60] loss: 0.943\n",
      "[77, 120] loss: 0.951\n",
      "[77, 180] loss: 0.960\n",
      "[77, 240] loss: 0.955\n",
      "[77, 300] loss: 0.956\n",
      "[77, 360] loss: 0.943\n",
      "Epoch: 77 -> Loss: 0.98617619276\n",
      "Epoch: 77 -> Test Accuracy: 61.15\n",
      "[78, 60] loss: 0.948\n",
      "[78, 120] loss: 0.938\n",
      "[78, 180] loss: 0.961\n",
      "[78, 240] loss: 0.957\n",
      "[78, 300] loss: 0.959\n",
      "[78, 360] loss: 0.946\n",
      "Epoch: 78 -> Loss: 0.999989330769\n",
      "Epoch: 78 -> Test Accuracy: 60.75\n",
      "[79, 60] loss: 0.918\n",
      "[79, 120] loss: 0.954\n",
      "[79, 180] loss: 0.962\n",
      "[79, 240] loss: 0.949\n",
      "[79, 300] loss: 0.948\n",
      "[79, 360] loss: 0.980\n",
      "Epoch: 79 -> Loss: 0.876459002495\n",
      "Epoch: 79 -> Test Accuracy: 60.38\n",
      "[80, 60] loss: 0.943\n",
      "[80, 120] loss: 0.929\n",
      "[80, 180] loss: 0.947\n",
      "[80, 240] loss: 0.979\n",
      "[80, 300] loss: 0.953\n",
      "[80, 360] loss: 0.958\n",
      "Epoch: 80 -> Loss: 0.940453529358\n",
      "Epoch: 80 -> Test Accuracy: 60.24\n",
      "[81, 60] loss: 0.949\n",
      "[81, 120] loss: 0.926\n",
      "[81, 180] loss: 0.955\n",
      "[81, 240] loss: 0.954\n",
      "[81, 300] loss: 0.939\n",
      "[81, 360] loss: 0.953\n",
      "Epoch: 81 -> Loss: 1.0682592392\n",
      "Epoch: 81 -> Test Accuracy: 60.5\n",
      "[82, 60] loss: 0.945\n",
      "[82, 120] loss: 0.936\n",
      "[82, 180] loss: 0.953\n",
      "[82, 240] loss: 0.941\n",
      "[82, 300] loss: 0.965\n",
      "[82, 360] loss: 0.955\n",
      "Epoch: 82 -> Loss: 1.0175538063\n",
      "Epoch: 82 -> Test Accuracy: 60.48\n",
      "[83, 60] loss: 0.945\n",
      "[83, 120] loss: 0.948\n",
      "[83, 180] loss: 0.934\n",
      "[83, 240] loss: 0.957\n",
      "[83, 300] loss: 0.932\n",
      "[83, 360] loss: 0.948\n",
      "Epoch: 83 -> Loss: 0.960919976234\n",
      "Epoch: 83 -> Test Accuracy: 60.91\n",
      "[84, 60] loss: 0.947\n",
      "[84, 120] loss: 0.954\n",
      "[84, 180] loss: 0.942\n",
      "[84, 240] loss: 0.930\n",
      "[84, 300] loss: 0.935\n",
      "[84, 360] loss: 0.949\n",
      "Epoch: 84 -> Loss: 0.96836745739\n",
      "Epoch: 84 -> Test Accuracy: 60.92\n",
      "[85, 60] loss: 0.941\n",
      "[85, 120] loss: 0.924\n",
      "[85, 180] loss: 0.941\n",
      "[85, 240] loss: 0.969\n",
      "[85, 300] loss: 0.931\n",
      "[85, 360] loss: 0.955\n",
      "Epoch: 85 -> Loss: 0.838882446289\n",
      "Epoch: 85 -> Test Accuracy: 60.38\n",
      "[86, 60] loss: 0.918\n",
      "[86, 120] loss: 0.921\n",
      "[86, 180] loss: 0.934\n",
      "[86, 240] loss: 0.923\n",
      "[86, 300] loss: 0.895\n",
      "[86, 360] loss: 0.918\n",
      "Epoch: 86 -> Loss: 0.973382174969\n",
      "Epoch: 86 -> Test Accuracy: 61.58\n",
      "[87, 60] loss: 0.917\n",
      "[87, 120] loss: 0.908\n",
      "[87, 180] loss: 0.925\n",
      "[87, 240] loss: 0.900\n",
      "[87, 300] loss: 0.900\n",
      "[87, 360] loss: 0.899\n",
      "Epoch: 87 -> Loss: 0.78806501627\n",
      "Epoch: 87 -> Test Accuracy: 61.5\n",
      "[88, 60] loss: 0.900\n",
      "[88, 120] loss: 0.884\n",
      "[88, 180] loss: 0.924\n",
      "[88, 240] loss: 0.902\n",
      "[88, 300] loss: 0.883\n",
      "[88, 360] loss: 0.911\n",
      "Epoch: 88 -> Loss: 1.02360868454\n",
      "Epoch: 88 -> Test Accuracy: 61.6\n",
      "[89, 60] loss: 0.908\n",
      "[89, 120] loss: 0.915\n",
      "[89, 180] loss: 0.895\n",
      "[89, 240] loss: 0.903\n",
      "[89, 300] loss: 0.900\n",
      "[89, 360] loss: 0.905\n",
      "Epoch: 89 -> Loss: 0.874146580696\n",
      "Epoch: 89 -> Test Accuracy: 61.86\n",
      "[90, 60] loss: 0.884\n",
      "[90, 120] loss: 0.894\n",
      "[90, 180] loss: 0.901\n",
      "[90, 240] loss: 0.902\n",
      "[90, 300] loss: 0.903\n",
      "[90, 360] loss: 0.893\n",
      "Epoch: 90 -> Loss: 1.05563819408\n",
      "Epoch: 90 -> Test Accuracy: 61.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[91, 60] loss: 0.897\n",
      "[91, 120] loss: 0.905\n",
      "[91, 180] loss: 0.898\n",
      "[91, 240] loss: 0.892\n",
      "[91, 300] loss: 0.913\n",
      "[91, 360] loss: 0.901\n",
      "Epoch: 91 -> Loss: 0.829767525196\n",
      "Epoch: 91 -> Test Accuracy: 61.99\n",
      "[92, 60] loss: 0.894\n",
      "[92, 120] loss: 0.921\n",
      "[92, 180] loss: 0.899\n",
      "[92, 240] loss: 0.905\n",
      "[92, 300] loss: 0.905\n",
      "[92, 360] loss: 0.893\n",
      "Epoch: 92 -> Loss: 1.0015989542\n",
      "Epoch: 92 -> Test Accuracy: 61.87\n",
      "[93, 60] loss: 0.892\n",
      "[93, 120] loss: 0.907\n",
      "[93, 180] loss: 0.910\n",
      "[93, 240] loss: 0.913\n",
      "[93, 300] loss: 0.886\n",
      "[93, 360] loss: 0.907\n",
      "Epoch: 93 -> Loss: 0.93932056427\n",
      "Epoch: 93 -> Test Accuracy: 62.14\n",
      "[94, 60] loss: 0.889\n",
      "[94, 120] loss: 0.920\n",
      "[94, 180] loss: 0.905\n",
      "[94, 240] loss: 0.899\n",
      "[94, 300] loss: 0.880\n",
      "[94, 360] loss: 0.887\n",
      "Epoch: 94 -> Loss: 1.04583060741\n",
      "Epoch: 94 -> Test Accuracy: 61.96\n",
      "[95, 60] loss: 0.905\n",
      "[95, 120] loss: 0.894\n",
      "[95, 180] loss: 0.888\n",
      "[95, 240] loss: 0.920\n",
      "[95, 300] loss: 0.913\n",
      "[95, 360] loss: 0.884\n",
      "Epoch: 95 -> Loss: 0.791828036308\n",
      "Epoch: 95 -> Test Accuracy: 61.88\n",
      "[96, 60] loss: 0.888\n",
      "[96, 120] loss: 0.893\n",
      "[96, 180] loss: 0.903\n",
      "[96, 240] loss: 0.905\n",
      "[96, 300] loss: 0.891\n",
      "[96, 360] loss: 0.889\n",
      "Epoch: 96 -> Loss: 0.908858656883\n",
      "Epoch: 96 -> Test Accuracy: 62.08\n",
      "[97, 60] loss: 0.875\n",
      "[97, 120] loss: 0.908\n",
      "[97, 180] loss: 0.913\n",
      "[97, 240] loss: 0.902\n",
      "[97, 300] loss: 0.892\n",
      "[97, 360] loss: 0.905\n",
      "Epoch: 97 -> Loss: 0.757797002792\n",
      "Epoch: 97 -> Test Accuracy: 61.86\n",
      "[98, 60] loss: 0.886\n",
      "[98, 120] loss: 0.902\n",
      "[98, 180] loss: 0.905\n",
      "[98, 240] loss: 0.897\n",
      "[98, 300] loss: 0.903\n",
      "[98, 360] loss: 0.882\n",
      "Epoch: 98 -> Loss: 0.870647132397\n",
      "Epoch: 98 -> Test Accuracy: 61.84\n",
      "[99, 60] loss: 0.908\n",
      "[99, 120] loss: 0.892\n",
      "[99, 180] loss: 0.893\n",
      "[99, 240] loss: 0.900\n",
      "[99, 300] loss: 0.889\n",
      "[99, 360] loss: 0.883\n",
      "Epoch: 99 -> Loss: 0.933106899261\n",
      "Epoch: 99 -> Test Accuracy: 62.03\n",
      "[100, 60] loss: 0.890\n",
      "[100, 120] loss: 0.895\n",
      "[100, 180] loss: 0.881\n",
      "[100, 240] loss: 0.893\n",
      "[100, 300] loss: 0.891\n",
      "[100, 360] loss: 0.896\n",
      "Epoch: 100 -> Loss: 0.887984871864\n",
      "Epoch: 100 -> Test Accuracy: 61.91\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train ConvClassifiers on feature map of net_3block\n",
    "conv_block3_loss_log, _, conv_block3_test_accuracy_log, _, _ = tr.train_all_blocks(3, 10, [0.1, 0.02, 0.004, 0.0008], \n",
    "    [35, 70, 85, 100], 0.9, 5e-4, net_block3, criterion, trainloader, None, testloader, use_ConvClassifier=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save variables\n",
    "fm.save_variable([rot_block3_loss_log, rot_block3_test_accuracy_log, \n",
    "                  block3_loss_log, block3_test_accuracy_log, \n",
    "                  conv_block3_loss_log, conv_block3_test_accuracy_log], \"3_block_net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename files\n",
    "fm.add_block_to_name(3, [100, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Block RotNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "net_block4 = RN.RotNet(num_classes=4, num_conv_block=4, add_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.142\n",
      "[1, 120] loss: 0.990\n",
      "[1, 180] loss: 0.920\n",
      "[1, 240] loss: 0.866\n",
      "[1, 300] loss: 0.836\n",
      "[1, 360] loss: 0.789\n",
      "Epoch: 1 -> Loss: 0.781177341938\n",
      "Epoch: 1 -> Test Accuracy: 68.8525\n",
      "[2, 60] loss: 0.737\n",
      "[2, 120] loss: 0.714\n",
      "[2, 180] loss: 0.688\n",
      "[2, 240] loss: 0.698\n",
      "[2, 300] loss: 0.659\n",
      "[2, 360] loss: 0.658\n",
      "Epoch: 2 -> Loss: 0.628521740437\n",
      "Epoch: 2 -> Test Accuracy: 75.445\n",
      "[3, 60] loss: 0.617\n",
      "[3, 120] loss: 0.613\n",
      "[3, 180] loss: 0.601\n",
      "[3, 240] loss: 0.577\n",
      "[3, 300] loss: 0.589\n",
      "[3, 360] loss: 0.572\n",
      "Epoch: 3 -> Loss: 0.674859523773\n",
      "Epoch: 3 -> Test Accuracy: 78.27\n",
      "[4, 60] loss: 0.546\n",
      "[4, 120] loss: 0.551\n",
      "[4, 180] loss: 0.542\n",
      "[4, 240] loss: 0.534\n",
      "[4, 300] loss: 0.519\n",
      "[4, 360] loss: 0.516\n",
      "Epoch: 4 -> Loss: 0.378356218338\n",
      "Epoch: 4 -> Test Accuracy: 79.4025\n",
      "[5, 60] loss: 0.509\n",
      "[5, 120] loss: 0.504\n",
      "[5, 180] loss: 0.490\n",
      "[5, 240] loss: 0.510\n",
      "[5, 300] loss: 0.492\n",
      "[5, 360] loss: 0.496\n",
      "Epoch: 5 -> Loss: 0.567669272423\n",
      "Epoch: 5 -> Test Accuracy: 80.6875\n",
      "[6, 60] loss: 0.482\n",
      "[6, 120] loss: 0.477\n",
      "[6, 180] loss: 0.474\n",
      "[6, 240] loss: 0.469\n",
      "[6, 300] loss: 0.459\n",
      "[6, 360] loss: 0.471\n",
      "Epoch: 6 -> Loss: 0.394954174757\n",
      "Epoch: 6 -> Test Accuracy: 82.255\n",
      "[7, 60] loss: 0.459\n",
      "[7, 120] loss: 0.439\n",
      "[7, 180] loss: 0.448\n",
      "[7, 240] loss: 0.453\n",
      "[7, 300] loss: 0.451\n",
      "[7, 360] loss: 0.443\n",
      "Epoch: 7 -> Loss: 0.462623596191\n",
      "Epoch: 7 -> Test Accuracy: 82.4775\n",
      "[8, 60] loss: 0.428\n",
      "[8, 120] loss: 0.428\n",
      "[8, 180] loss: 0.436\n",
      "[8, 240] loss: 0.440\n",
      "[8, 300] loss: 0.421\n",
      "[8, 360] loss: 0.435\n",
      "Epoch: 8 -> Loss: 0.415178716183\n",
      "Epoch: 8 -> Test Accuracy: 83.2\n",
      "[9, 60] loss: 0.411\n",
      "[9, 120] loss: 0.414\n",
      "[9, 180] loss: 0.409\n",
      "[9, 240] loss: 0.418\n",
      "[9, 300] loss: 0.432\n",
      "[9, 360] loss: 0.422\n",
      "Epoch: 9 -> Loss: 0.383088469505\n",
      "Epoch: 9 -> Test Accuracy: 83.5625\n",
      "[10, 60] loss: 0.393\n",
      "[10, 120] loss: 0.414\n",
      "[10, 180] loss: 0.416\n",
      "[10, 240] loss: 0.415\n",
      "[10, 300] loss: 0.419\n",
      "[10, 360] loss: 0.398\n",
      "Epoch: 10 -> Loss: 0.48729044199\n",
      "Epoch: 10 -> Test Accuracy: 83.865\n",
      "[11, 60] loss: 0.396\n",
      "[11, 120] loss: 0.402\n",
      "[11, 180] loss: 0.398\n",
      "[11, 240] loss: 0.384\n",
      "[11, 300] loss: 0.400\n",
      "[11, 360] loss: 0.398\n",
      "Epoch: 11 -> Loss: 0.475574582815\n",
      "Epoch: 11 -> Test Accuracy: 84.305\n",
      "[12, 60] loss: 0.387\n",
      "[12, 120] loss: 0.391\n",
      "[12, 180] loss: 0.392\n",
      "[12, 240] loss: 0.382\n",
      "[12, 300] loss: 0.373\n",
      "[12, 360] loss: 0.392\n",
      "Epoch: 12 -> Loss: 0.441366434097\n",
      "Epoch: 12 -> Test Accuracy: 83.58\n",
      "[13, 60] loss: 0.363\n",
      "[13, 120] loss: 0.373\n",
      "[13, 180] loss: 0.381\n",
      "[13, 240] loss: 0.375\n",
      "[13, 300] loss: 0.384\n",
      "[13, 360] loss: 0.387\n",
      "Epoch: 13 -> Loss: 0.38470107317\n",
      "Epoch: 13 -> Test Accuracy: 84.895\n",
      "[14, 60] loss: 0.375\n",
      "[14, 120] loss: 0.376\n",
      "[14, 180] loss: 0.385\n",
      "[14, 240] loss: 0.357\n",
      "[14, 300] loss: 0.368\n",
      "[14, 360] loss: 0.365\n",
      "Epoch: 14 -> Loss: 0.419710725546\n",
      "Epoch: 14 -> Test Accuracy: 84.2025\n",
      "[15, 60] loss: 0.359\n",
      "[15, 120] loss: 0.355\n",
      "[15, 180] loss: 0.372\n",
      "[15, 240] loss: 0.349\n",
      "[15, 300] loss: 0.359\n",
      "[15, 360] loss: 0.392\n",
      "Epoch: 15 -> Loss: 0.38218948245\n",
      "Epoch: 15 -> Test Accuracy: 84.5525\n",
      "[16, 60] loss: 0.355\n",
      "[16, 120] loss: 0.364\n",
      "[16, 180] loss: 0.370\n",
      "[16, 240] loss: 0.356\n",
      "[16, 300] loss: 0.369\n",
      "[16, 360] loss: 0.363\n",
      "Epoch: 16 -> Loss: 0.343030154705\n",
      "Epoch: 16 -> Test Accuracy: 84.46\n",
      "[17, 60] loss: 0.353\n",
      "[17, 120] loss: 0.365\n",
      "[17, 180] loss: 0.358\n",
      "[17, 240] loss: 0.343\n",
      "[17, 300] loss: 0.353\n",
      "[17, 360] loss: 0.361\n",
      "Epoch: 17 -> Loss: 0.262086868286\n",
      "Epoch: 17 -> Test Accuracy: 85.435\n",
      "[18, 60] loss: 0.339\n",
      "[18, 120] loss: 0.342\n",
      "[18, 180] loss: 0.351\n",
      "[18, 240] loss: 0.348\n",
      "[18, 300] loss: 0.362\n",
      "[18, 360] loss: 0.358\n",
      "Epoch: 18 -> Loss: 0.402194827795\n",
      "Epoch: 18 -> Test Accuracy: 85.3925\n",
      "[19, 60] loss: 0.334\n",
      "[19, 120] loss: 0.345\n",
      "[19, 180] loss: 0.356\n",
      "[19, 240] loss: 0.341\n",
      "[19, 300] loss: 0.351\n",
      "[19, 360] loss: 0.351\n",
      "Epoch: 19 -> Loss: 0.369297534227\n",
      "Epoch: 19 -> Test Accuracy: 85.01\n",
      "[20, 60] loss: 0.350\n",
      "[20, 120] loss: 0.340\n",
      "[20, 180] loss: 0.348\n",
      "[20, 240] loss: 0.349\n",
      "[20, 300] loss: 0.342\n",
      "[20, 360] loss: 0.351\n",
      "Epoch: 20 -> Loss: 0.464835941792\n",
      "Epoch: 20 -> Test Accuracy: 85.6\n",
      "[21, 60] loss: 0.328\n",
      "[21, 120] loss: 0.333\n",
      "[21, 180] loss: 0.341\n",
      "[21, 240] loss: 0.341\n",
      "[21, 300] loss: 0.343\n",
      "[21, 360] loss: 0.353\n",
      "Epoch: 21 -> Loss: 0.224211975932\n",
      "Epoch: 21 -> Test Accuracy: 85.1625\n",
      "[22, 60] loss: 0.332\n",
      "[22, 120] loss: 0.333\n",
      "[22, 180] loss: 0.323\n",
      "[22, 240] loss: 0.338\n",
      "[22, 300] loss: 0.349\n",
      "[22, 360] loss: 0.344\n",
      "Epoch: 22 -> Loss: 0.372389703989\n",
      "Epoch: 22 -> Test Accuracy: 86.15\n",
      "[23, 60] loss: 0.329\n",
      "[23, 120] loss: 0.325\n",
      "[23, 180] loss: 0.342\n",
      "[23, 240] loss: 0.343\n",
      "[23, 300] loss: 0.341\n",
      "[23, 360] loss: 0.330\n",
      "Epoch: 23 -> Loss: 0.371145874262\n",
      "Epoch: 23 -> Test Accuracy: 86.0225\n",
      "[24, 60] loss: 0.325\n",
      "[24, 120] loss: 0.325\n",
      "[24, 180] loss: 0.324\n",
      "[24, 240] loss: 0.340\n",
      "[24, 300] loss: 0.328\n",
      "[24, 360] loss: 0.340\n",
      "Epoch: 24 -> Loss: 0.488623946905\n",
      "Epoch: 24 -> Test Accuracy: 85.9475\n",
      "[25, 60] loss: 0.332\n",
      "[25, 120] loss: 0.326\n",
      "[25, 180] loss: 0.336\n",
      "[25, 240] loss: 0.347\n",
      "[25, 300] loss: 0.322\n",
      "[25, 360] loss: 0.330\n",
      "Epoch: 25 -> Loss: 0.314253181219\n",
      "Epoch: 25 -> Test Accuracy: 86.135\n",
      "[26, 60] loss: 0.318\n",
      "[26, 120] loss: 0.325\n",
      "[26, 180] loss: 0.325\n",
      "[26, 240] loss: 0.329\n",
      "[26, 300] loss: 0.329\n",
      "[26, 360] loss: 0.335\n",
      "Epoch: 26 -> Loss: 0.268091291189\n",
      "Epoch: 26 -> Test Accuracy: 86.6925\n",
      "[27, 60] loss: 0.312\n",
      "[27, 120] loss: 0.323\n",
      "[27, 180] loss: 0.330\n",
      "[27, 240] loss: 0.320\n",
      "[27, 300] loss: 0.329\n",
      "[27, 360] loss: 0.337\n",
      "Epoch: 27 -> Loss: 0.297608911991\n",
      "Epoch: 27 -> Test Accuracy: 86.7725\n",
      "[28, 60] loss: 0.308\n",
      "[28, 120] loss: 0.329\n",
      "[28, 180] loss: 0.319\n",
      "[28, 240] loss: 0.326\n",
      "[28, 300] loss: 0.332\n",
      "[28, 360] loss: 0.331\n",
      "Epoch: 28 -> Loss: 0.379402339458\n",
      "Epoch: 28 -> Test Accuracy: 87.185\n",
      "[29, 60] loss: 0.314\n",
      "[29, 120] loss: 0.316\n",
      "[29, 180] loss: 0.313\n",
      "[29, 240] loss: 0.327\n",
      "[29, 300] loss: 0.323\n",
      "[29, 360] loss: 0.340\n",
      "Epoch: 29 -> Loss: 0.362581968307\n",
      "Epoch: 29 -> Test Accuracy: 85.2575\n",
      "[30, 60] loss: 0.325\n",
      "[30, 120] loss: 0.320\n",
      "[30, 180] loss: 0.332\n",
      "[30, 240] loss: 0.324\n",
      "[30, 300] loss: 0.324\n",
      "[30, 360] loss: 0.320\n",
      "Epoch: 30 -> Loss: 0.397025883198\n",
      "Epoch: 30 -> Test Accuracy: 86.0325\n",
      "[31, 60] loss: 0.318\n",
      "[31, 120] loss: 0.309\n",
      "[31, 180] loss: 0.322\n",
      "[31, 240] loss: 0.331\n",
      "[31, 300] loss: 0.321\n",
      "[31, 360] loss: 0.319\n",
      "Epoch: 31 -> Loss: 0.301123738289\n",
      "Epoch: 31 -> Test Accuracy: 86.015\n",
      "[32, 60] loss: 0.308\n",
      "[32, 120] loss: 0.319\n",
      "[32, 180] loss: 0.325\n",
      "[32, 240] loss: 0.316\n",
      "[32, 300] loss: 0.323\n",
      "[32, 360] loss: 0.319\n",
      "Epoch: 32 -> Loss: 0.285244047642\n",
      "Epoch: 32 -> Test Accuracy: 86.9325\n",
      "[33, 60] loss: 0.298\n",
      "[33, 120] loss: 0.307\n",
      "[33, 180] loss: 0.333\n",
      "[33, 240] loss: 0.311\n",
      "[33, 300] loss: 0.324\n",
      "[33, 360] loss: 0.327\n",
      "Epoch: 33 -> Loss: 0.318055659533\n",
      "Epoch: 33 -> Test Accuracy: 85.61\n",
      "[34, 60] loss: 0.308\n",
      "[34, 120] loss: 0.320\n",
      "[34, 180] loss: 0.312\n",
      "[34, 240] loss: 0.320\n",
      "[34, 300] loss: 0.327\n",
      "[34, 360] loss: 0.317\n",
      "Epoch: 34 -> Loss: 0.314479976892\n",
      "Epoch: 34 -> Test Accuracy: 84.655\n",
      "[35, 60] loss: 0.315\n",
      "[35, 120] loss: 0.313\n",
      "[35, 180] loss: 0.305\n",
      "[35, 240] loss: 0.319\n",
      "[35, 300] loss: 0.313\n",
      "[35, 360] loss: 0.324\n",
      "Epoch: 35 -> Loss: 0.321969687939\n",
      "Epoch: 35 -> Test Accuracy: 86.925\n",
      "[36, 60] loss: 0.305\n",
      "[36, 120] loss: 0.311\n",
      "[36, 180] loss: 0.312\n",
      "[36, 240] loss: 0.321\n",
      "[36, 300] loss: 0.313\n",
      "[36, 360] loss: 0.304\n",
      "Epoch: 36 -> Loss: 0.502572178841\n",
      "Epoch: 36 -> Test Accuracy: 85.3575\n",
      "[37, 60] loss: 0.306\n",
      "[37, 120] loss: 0.304\n",
      "[37, 180] loss: 0.302\n",
      "[37, 240] loss: 0.324\n",
      "[37, 300] loss: 0.334\n",
      "[37, 360] loss: 0.321\n",
      "Epoch: 37 -> Loss: 0.384328216314\n",
      "Epoch: 37 -> Test Accuracy: 84.8625\n",
      "[38, 60] loss: 0.301\n",
      "[38, 120] loss: 0.300\n",
      "[38, 180] loss: 0.330\n",
      "[38, 240] loss: 0.309\n",
      "[38, 300] loss: 0.319\n",
      "[38, 360] loss: 0.320\n",
      "Epoch: 38 -> Loss: 0.314231336117\n",
      "Epoch: 38 -> Test Accuracy: 86.0375\n",
      "[39, 60] loss: 0.291\n",
      "[39, 120] loss: 0.302\n",
      "[39, 180] loss: 0.312\n",
      "[39, 240] loss: 0.327\n",
      "[39, 300] loss: 0.323\n",
      "[39, 360] loss: 0.306\n",
      "Epoch: 39 -> Loss: 0.341157138348\n",
      "Epoch: 39 -> Test Accuracy: 87.4375\n",
      "[40, 60] loss: 0.299\n",
      "[40, 120] loss: 0.299\n",
      "[40, 180] loss: 0.321\n",
      "[40, 240] loss: 0.312\n",
      "[40, 300] loss: 0.324\n",
      "[40, 360] loss: 0.307\n",
      "Epoch: 40 -> Loss: 0.250054240227\n",
      "Epoch: 40 -> Test Accuracy: 87.505\n",
      "[41, 60] loss: 0.292\n",
      "[41, 120] loss: 0.308\n",
      "[41, 180] loss: 0.303\n",
      "[41, 240] loss: 0.311\n",
      "[41, 300] loss: 0.316\n",
      "[41, 360] loss: 0.313\n",
      "Epoch: 41 -> Loss: 0.230117529631\n",
      "Epoch: 41 -> Test Accuracy: 86.46\n",
      "[42, 60] loss: 0.306\n",
      "[42, 120] loss: 0.309\n",
      "[42, 180] loss: 0.307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 240] loss: 0.308\n",
      "[42, 300] loss: 0.314\n",
      "[42, 360] loss: 0.301\n",
      "Epoch: 42 -> Loss: 0.282761156559\n",
      "Epoch: 42 -> Test Accuracy: 86.685\n",
      "[43, 60] loss: 0.302\n",
      "[43, 120] loss: 0.300\n",
      "[43, 180] loss: 0.313\n",
      "[43, 240] loss: 0.313\n",
      "[43, 300] loss: 0.297\n",
      "[43, 360] loss: 0.314\n",
      "Epoch: 43 -> Loss: 0.258620709181\n",
      "Epoch: 43 -> Test Accuracy: 86.62\n",
      "[44, 60] loss: 0.307\n",
      "[44, 120] loss: 0.303\n",
      "[44, 180] loss: 0.306\n",
      "[44, 240] loss: 0.305\n",
      "[44, 300] loss: 0.322\n",
      "[44, 360] loss: 0.309\n",
      "Epoch: 44 -> Loss: 0.460937410593\n",
      "Epoch: 44 -> Test Accuracy: 86.7575\n",
      "[45, 60] loss: 0.291\n",
      "[45, 120] loss: 0.311\n",
      "[45, 180] loss: 0.317\n",
      "[45, 240] loss: 0.312\n",
      "[45, 300] loss: 0.293\n",
      "[45, 360] loss: 0.301\n",
      "Epoch: 45 -> Loss: 0.43003988266\n",
      "Epoch: 45 -> Test Accuracy: 85.46\n",
      "[46, 60] loss: 0.300\n",
      "[46, 120] loss: 0.294\n",
      "[46, 180] loss: 0.306\n",
      "[46, 240] loss: 0.312\n",
      "[46, 300] loss: 0.304\n",
      "[46, 360] loss: 0.295\n",
      "Epoch: 46 -> Loss: 0.412907212973\n",
      "Epoch: 46 -> Test Accuracy: 85.6225\n",
      "[47, 60] loss: 0.306\n",
      "[47, 120] loss: 0.292\n",
      "[47, 180] loss: 0.300\n",
      "[47, 240] loss: 0.306\n",
      "[47, 300] loss: 0.317\n",
      "[47, 360] loss: 0.315\n",
      "Epoch: 47 -> Loss: 0.320448249578\n",
      "Epoch: 47 -> Test Accuracy: 86.6075\n",
      "[48, 60] loss: 0.301\n",
      "[48, 120] loss: 0.299\n",
      "[48, 180] loss: 0.314\n",
      "[48, 240] loss: 0.308\n",
      "[48, 300] loss: 0.302\n",
      "[48, 360] loss: 0.312\n",
      "Epoch: 48 -> Loss: 0.287023752928\n",
      "Epoch: 48 -> Test Accuracy: 86.0625\n",
      "[49, 60] loss: 0.286\n",
      "[49, 120] loss: 0.311\n",
      "[49, 180] loss: 0.298\n",
      "[49, 240] loss: 0.312\n",
      "[49, 300] loss: 0.310\n",
      "[49, 360] loss: 0.308\n",
      "Epoch: 49 -> Loss: 0.200493842363\n",
      "Epoch: 49 -> Test Accuracy: 86.3675\n",
      "[50, 60] loss: 0.282\n",
      "[50, 120] loss: 0.299\n",
      "[50, 180] loss: 0.302\n",
      "[50, 240] loss: 0.307\n",
      "[50, 300] loss: 0.305\n",
      "[50, 360] loss: 0.309\n",
      "Epoch: 50 -> Loss: 0.285253047943\n",
      "Epoch: 50 -> Test Accuracy: 86.7875\n",
      "[51, 60] loss: 0.290\n",
      "[51, 120] loss: 0.304\n",
      "[51, 180] loss: 0.290\n",
      "[51, 240] loss: 0.313\n",
      "[51, 300] loss: 0.309\n",
      "[51, 360] loss: 0.308\n",
      "Epoch: 51 -> Loss: 0.305180370808\n",
      "Epoch: 51 -> Test Accuracy: 87.18\n",
      "[52, 60] loss: 0.285\n",
      "[52, 120] loss: 0.307\n",
      "[52, 180] loss: 0.299\n",
      "[52, 240] loss: 0.293\n",
      "[52, 300] loss: 0.307\n",
      "[52, 360] loss: 0.315\n",
      "Epoch: 52 -> Loss: 0.302442342043\n",
      "Epoch: 52 -> Test Accuracy: 87.1875\n",
      "[53, 60] loss: 0.291\n",
      "[53, 120] loss: 0.291\n",
      "[53, 180] loss: 0.285\n",
      "[53, 240] loss: 0.300\n",
      "[53, 300] loss: 0.315\n",
      "[53, 360] loss: 0.312\n",
      "Epoch: 53 -> Loss: 0.197407364845\n",
      "Epoch: 53 -> Test Accuracy: 86.27\n",
      "[54, 60] loss: 0.284\n",
      "[54, 120] loss: 0.296\n",
      "[54, 180] loss: 0.312\n",
      "[54, 240] loss: 0.309\n",
      "[54, 300] loss: 0.306\n",
      "[54, 360] loss: 0.302\n",
      "Epoch: 54 -> Loss: 0.348555117846\n",
      "Epoch: 54 -> Test Accuracy: 85.215\n",
      "[55, 60] loss: 0.300\n",
      "[55, 120] loss: 0.304\n",
      "[55, 180] loss: 0.298\n",
      "[55, 240] loss: 0.300\n",
      "[55, 300] loss: 0.297\n",
      "[55, 360] loss: 0.317\n",
      "Epoch: 55 -> Loss: 0.246483445168\n",
      "Epoch: 55 -> Test Accuracy: 86.5025\n",
      "[56, 60] loss: 0.291\n",
      "[56, 120] loss: 0.286\n",
      "[56, 180] loss: 0.306\n",
      "[56, 240] loss: 0.300\n",
      "[56, 300] loss: 0.296\n",
      "[56, 360] loss: 0.305\n",
      "Epoch: 56 -> Loss: 0.224709838629\n",
      "Epoch: 56 -> Test Accuracy: 86.8875\n",
      "[57, 60] loss: 0.286\n",
      "[57, 120] loss: 0.298\n",
      "[57, 180] loss: 0.300\n",
      "[57, 240] loss: 0.311\n",
      "[57, 300] loss: 0.296\n",
      "[57, 360] loss: 0.314\n",
      "Epoch: 57 -> Loss: 0.315122634172\n",
      "Epoch: 57 -> Test Accuracy: 87.6\n",
      "[58, 60] loss: 0.280\n",
      "[58, 120] loss: 0.298\n",
      "[58, 180] loss: 0.303\n",
      "[58, 240] loss: 0.315\n",
      "[58, 300] loss: 0.293\n",
      "[58, 360] loss: 0.304\n",
      "Epoch: 58 -> Loss: 0.19799515605\n",
      "Epoch: 58 -> Test Accuracy: 86.5125\n",
      "[59, 60] loss: 0.283\n",
      "[59, 120] loss: 0.282\n",
      "[59, 180] loss: 0.297\n",
      "[59, 240] loss: 0.303\n",
      "[59, 300] loss: 0.308\n",
      "[59, 360] loss: 0.316\n",
      "Epoch: 59 -> Loss: 0.306699842215\n",
      "Epoch: 59 -> Test Accuracy: 86.495\n",
      "[60, 60] loss: 0.278\n",
      "[60, 120] loss: 0.304\n",
      "[60, 180] loss: 0.306\n",
      "[60, 240] loss: 0.298\n",
      "[60, 300] loss: 0.299\n",
      "[60, 360] loss: 0.296\n",
      "Epoch: 60 -> Loss: 0.140201374888\n",
      "Epoch: 60 -> Test Accuracy: 86.72\n",
      "[61, 60] loss: 0.224\n",
      "[61, 120] loss: 0.198\n",
      "[61, 180] loss: 0.196\n",
      "[61, 240] loss: 0.173\n",
      "[61, 300] loss: 0.186\n",
      "[61, 360] loss: 0.178\n",
      "Epoch: 61 -> Loss: 0.229852363467\n",
      "Epoch: 61 -> Test Accuracy: 90.8975\n",
      "[62, 60] loss: 0.164\n",
      "[62, 120] loss: 0.170\n",
      "[62, 180] loss: 0.162\n",
      "[62, 240] loss: 0.159\n",
      "[62, 300] loss: 0.168\n",
      "[62, 360] loss: 0.166\n",
      "Epoch: 62 -> Loss: 0.136267066002\n",
      "Epoch: 62 -> Test Accuracy: 90.6625\n",
      "[63, 60] loss: 0.145\n",
      "[63, 120] loss: 0.149\n",
      "[63, 180] loss: 0.156\n",
      "[63, 240] loss: 0.156\n",
      "[63, 300] loss: 0.161\n",
      "[63, 360] loss: 0.167\n",
      "Epoch: 63 -> Loss: 0.178048118949\n",
      "Epoch: 63 -> Test Accuracy: 90.8425\n",
      "[64, 60] loss: 0.151\n",
      "[64, 120] loss: 0.143\n",
      "[64, 180] loss: 0.144\n",
      "[64, 240] loss: 0.148\n",
      "[64, 300] loss: 0.157\n",
      "[64, 360] loss: 0.155\n",
      "Epoch: 64 -> Loss: 0.197825044394\n",
      "Epoch: 64 -> Test Accuracy: 90.6\n",
      "[65, 60] loss: 0.134\n",
      "[65, 120] loss: 0.148\n",
      "[65, 180] loss: 0.154\n",
      "[65, 240] loss: 0.150\n",
      "[65, 300] loss: 0.158\n",
      "[65, 360] loss: 0.148\n",
      "Epoch: 65 -> Loss: 0.207572385669\n",
      "Epoch: 65 -> Test Accuracy: 90.54\n",
      "[66, 60] loss: 0.132\n",
      "[66, 120] loss: 0.138\n",
      "[66, 180] loss: 0.148\n",
      "[66, 240] loss: 0.141\n",
      "[66, 300] loss: 0.156\n",
      "[66, 360] loss: 0.155\n",
      "Epoch: 66 -> Loss: 0.187829434872\n",
      "Epoch: 66 -> Test Accuracy: 90.45\n",
      "[67, 60] loss: 0.137\n",
      "[67, 120] loss: 0.129\n",
      "[67, 180] loss: 0.144\n",
      "[67, 240] loss: 0.146\n",
      "[67, 300] loss: 0.162\n",
      "[67, 360] loss: 0.155\n",
      "Epoch: 67 -> Loss: 0.124498471618\n",
      "Epoch: 67 -> Test Accuracy: 90.1925\n",
      "[68, 60] loss: 0.139\n",
      "[68, 120] loss: 0.139\n",
      "[68, 180] loss: 0.146\n",
      "[68, 240] loss: 0.148\n",
      "[68, 300] loss: 0.145\n",
      "[68, 360] loss: 0.152\n",
      "Epoch: 68 -> Loss: 0.173591449857\n",
      "Epoch: 68 -> Test Accuracy: 90.685\n",
      "[69, 60] loss: 0.139\n",
      "[69, 120] loss: 0.138\n",
      "[69, 180] loss: 0.144\n",
      "[69, 240] loss: 0.154\n",
      "[69, 300] loss: 0.144\n",
      "[69, 360] loss: 0.147\n",
      "Epoch: 69 -> Loss: 0.164247691631\n",
      "Epoch: 69 -> Test Accuracy: 90.605\n",
      "[70, 60] loss: 0.138\n",
      "[70, 120] loss: 0.144\n",
      "[70, 180] loss: 0.144\n",
      "[70, 240] loss: 0.145\n",
      "[70, 300] loss: 0.149\n",
      "[70, 360] loss: 0.143\n",
      "Epoch: 70 -> Loss: 0.0836271122098\n",
      "Epoch: 70 -> Test Accuracy: 90.125\n",
      "[71, 60] loss: 0.137\n",
      "[71, 120] loss: 0.139\n",
      "[71, 180] loss: 0.133\n",
      "[71, 240] loss: 0.147\n",
      "[71, 300] loss: 0.153\n",
      "[71, 360] loss: 0.147\n",
      "Epoch: 71 -> Loss: 0.1349491328\n",
      "Epoch: 71 -> Test Accuracy: 90.3325\n",
      "[72, 60] loss: 0.133\n",
      "[72, 120] loss: 0.142\n",
      "[72, 180] loss: 0.147\n",
      "[72, 240] loss: 0.141\n",
      "[72, 300] loss: 0.146\n",
      "[72, 360] loss: 0.152\n",
      "Epoch: 72 -> Loss: 0.122578106821\n",
      "Epoch: 72 -> Test Accuracy: 90.575\n",
      "[73, 60] loss: 0.131\n",
      "[73, 120] loss: 0.148\n",
      "[73, 180] loss: 0.144\n",
      "[73, 240] loss: 0.150\n",
      "[73, 300] loss: 0.154\n",
      "[73, 360] loss: 0.150\n",
      "Epoch: 73 -> Loss: 0.154401823878\n",
      "Epoch: 73 -> Test Accuracy: 90.1925\n",
      "[74, 60] loss: 0.130\n",
      "[74, 120] loss: 0.141\n",
      "[74, 180] loss: 0.144\n",
      "[74, 240] loss: 0.146\n",
      "[74, 300] loss: 0.156\n",
      "[74, 360] loss: 0.159\n",
      "Epoch: 74 -> Loss: 0.178270816803\n",
      "Epoch: 74 -> Test Accuracy: 90.1975\n",
      "[75, 60] loss: 0.141\n",
      "[75, 120] loss: 0.140\n",
      "[75, 180] loss: 0.148\n",
      "[75, 240] loss: 0.142\n",
      "[75, 300] loss: 0.150\n",
      "[75, 360] loss: 0.150\n",
      "Epoch: 75 -> Loss: 0.117633149028\n",
      "Epoch: 75 -> Test Accuracy: 89.945\n",
      "[76, 60] loss: 0.140\n",
      "[76, 120] loss: 0.137\n",
      "[76, 180] loss: 0.148\n",
      "[76, 240] loss: 0.147\n",
      "[76, 300] loss: 0.159\n",
      "[76, 360] loss: 0.160\n",
      "Epoch: 76 -> Loss: 0.200001806021\n",
      "Epoch: 76 -> Test Accuracy: 90.4275\n",
      "[77, 60] loss: 0.139\n",
      "[77, 120] loss: 0.139\n",
      "[77, 180] loss: 0.154\n",
      "[77, 240] loss: 0.149\n",
      "[77, 300] loss: 0.147\n",
      "[77, 360] loss: 0.151\n",
      "Epoch: 77 -> Loss: 0.175385370851\n",
      "Epoch: 77 -> Test Accuracy: 89.8225\n",
      "[78, 60] loss: 0.138\n",
      "[78, 120] loss: 0.145\n",
      "[78, 180] loss: 0.143\n",
      "[78, 240] loss: 0.149\n",
      "[78, 300] loss: 0.151\n",
      "[78, 360] loss: 0.146\n",
      "Epoch: 78 -> Loss: 0.207535892725\n",
      "Epoch: 78 -> Test Accuracy: 89.915\n",
      "[79, 60] loss: 0.141\n",
      "[79, 120] loss: 0.147\n",
      "[79, 180] loss: 0.146\n",
      "[79, 240] loss: 0.147\n",
      "[79, 300] loss: 0.144\n",
      "[79, 360] loss: 0.149\n",
      "Epoch: 79 -> Loss: 0.0889199823141\n",
      "Epoch: 79 -> Test Accuracy: 90.0225\n",
      "[80, 60] loss: 0.137\n",
      "[80, 120] loss: 0.136\n",
      "[80, 180] loss: 0.146\n",
      "[80, 240] loss: 0.150\n",
      "[80, 300] loss: 0.149\n",
      "[80, 360] loss: 0.152\n",
      "Epoch: 80 -> Loss: 0.19911673665\n",
      "Epoch: 80 -> Test Accuracy: 89.715\n",
      "[81, 60] loss: 0.127\n",
      "[81, 120] loss: 0.140\n",
      "[81, 180] loss: 0.149\n",
      "[81, 240] loss: 0.145\n",
      "[81, 300] loss: 0.154\n",
      "[81, 360] loss: 0.154\n",
      "Epoch: 81 -> Loss: 0.181411266327\n",
      "Epoch: 81 -> Test Accuracy: 90.0575\n",
      "[82, 60] loss: 0.138\n",
      "[82, 120] loss: 0.137\n",
      "[82, 180] loss: 0.144\n",
      "[82, 240] loss: 0.142\n",
      "[82, 300] loss: 0.149\n",
      "[82, 360] loss: 0.154\n",
      "Epoch: 82 -> Loss: 0.224876716733\n",
      "Epoch: 82 -> Test Accuracy: 89.56\n",
      "[83, 60] loss: 0.132\n",
      "[83, 120] loss: 0.147\n",
      "[83, 180] loss: 0.138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83, 240] loss: 0.148\n",
      "[83, 300] loss: 0.159\n",
      "[83, 360] loss: 0.150\n",
      "Epoch: 83 -> Loss: 0.213200852275\n",
      "Epoch: 83 -> Test Accuracy: 89.965\n",
      "[84, 60] loss: 0.130\n",
      "[84, 120] loss: 0.147\n",
      "[84, 180] loss: 0.138\n",
      "[84, 240] loss: 0.149\n",
      "[84, 300] loss: 0.150\n",
      "[84, 360] loss: 0.147\n",
      "Epoch: 84 -> Loss: 0.190491721034\n",
      "Epoch: 84 -> Test Accuracy: 89.765\n",
      "[85, 60] loss: 0.135\n",
      "[85, 120] loss: 0.148\n",
      "[85, 180] loss: 0.141\n",
      "[85, 240] loss: 0.143\n",
      "[85, 300] loss: 0.148\n",
      "[85, 360] loss: 0.146\n",
      "Epoch: 85 -> Loss: 0.108416676521\n",
      "Epoch: 85 -> Test Accuracy: 89.83\n",
      "[86, 60] loss: 0.137\n",
      "[86, 120] loss: 0.136\n",
      "[86, 180] loss: 0.141\n",
      "[86, 240] loss: 0.151\n",
      "[86, 300] loss: 0.146\n",
      "[86, 360] loss: 0.146\n",
      "Epoch: 86 -> Loss: 0.170319244266\n",
      "Epoch: 86 -> Test Accuracy: 90.21\n",
      "[87, 60] loss: 0.138\n",
      "[87, 120] loss: 0.138\n",
      "[87, 180] loss: 0.143\n",
      "[87, 240] loss: 0.156\n",
      "[87, 300] loss: 0.148\n",
      "[87, 360] loss: 0.148\n",
      "Epoch: 87 -> Loss: 0.124249085784\n",
      "Epoch: 87 -> Test Accuracy: 90.3175\n",
      "[88, 60] loss: 0.125\n",
      "[88, 120] loss: 0.139\n",
      "[88, 180] loss: 0.138\n",
      "[88, 240] loss: 0.144\n",
      "[88, 300] loss: 0.157\n",
      "[88, 360] loss: 0.144\n",
      "Epoch: 88 -> Loss: 0.108418688178\n",
      "Epoch: 88 -> Test Accuracy: 89.6475\n",
      "[89, 60] loss: 0.126\n",
      "[89, 120] loss: 0.146\n",
      "[89, 180] loss: 0.142\n",
      "[89, 240] loss: 0.149\n",
      "[89, 300] loss: 0.143\n",
      "[89, 360] loss: 0.152\n",
      "Epoch: 89 -> Loss: 0.146886587143\n",
      "Epoch: 89 -> Test Accuracy: 90.1825\n",
      "[90, 60] loss: 0.124\n",
      "[90, 120] loss: 0.140\n",
      "[90, 180] loss: 0.143\n",
      "[90, 240] loss: 0.149\n",
      "[90, 300] loss: 0.153\n",
      "[90, 360] loss: 0.140\n",
      "Epoch: 90 -> Loss: 0.0958281904459\n",
      "Epoch: 90 -> Test Accuracy: 89.6375\n",
      "[91, 60] loss: 0.129\n",
      "[91, 120] loss: 0.133\n",
      "[91, 180] loss: 0.145\n",
      "[91, 240] loss: 0.138\n",
      "[91, 300] loss: 0.146\n",
      "[91, 360] loss: 0.147\n",
      "Epoch: 91 -> Loss: 0.123503826559\n",
      "Epoch: 91 -> Test Accuracy: 90.1475\n",
      "[92, 60] loss: 0.129\n",
      "[92, 120] loss: 0.136\n",
      "[92, 180] loss: 0.147\n",
      "[92, 240] loss: 0.149\n",
      "[92, 300] loss: 0.143\n",
      "[92, 360] loss: 0.143\n",
      "Epoch: 92 -> Loss: 0.175314813852\n",
      "Epoch: 92 -> Test Accuracy: 90.0275\n",
      "[93, 60] loss: 0.130\n",
      "[93, 120] loss: 0.141\n",
      "[93, 180] loss: 0.139\n",
      "[93, 240] loss: 0.137\n",
      "[93, 300] loss: 0.144\n",
      "[93, 360] loss: 0.142\n",
      "Epoch: 93 -> Loss: 0.137547835708\n",
      "Epoch: 93 -> Test Accuracy: 89.2475\n",
      "[94, 60] loss: 0.127\n",
      "[94, 120] loss: 0.131\n",
      "[94, 180] loss: 0.137\n",
      "[94, 240] loss: 0.143\n",
      "[94, 300] loss: 0.147\n",
      "[94, 360] loss: 0.145\n",
      "Epoch: 94 -> Loss: 0.128542721272\n",
      "Epoch: 94 -> Test Accuracy: 90.375\n",
      "[95, 60] loss: 0.130\n",
      "[95, 120] loss: 0.136\n",
      "[95, 180] loss: 0.140\n",
      "[95, 240] loss: 0.133\n",
      "[95, 300] loss: 0.143\n",
      "[95, 360] loss: 0.147\n",
      "Epoch: 95 -> Loss: 0.227052927017\n",
      "Epoch: 95 -> Test Accuracy: 90.0225\n",
      "[96, 60] loss: 0.127\n",
      "[96, 120] loss: 0.136\n",
      "[96, 180] loss: 0.138\n",
      "[96, 240] loss: 0.141\n",
      "[96, 300] loss: 0.147\n",
      "[96, 360] loss: 0.144\n",
      "Epoch: 96 -> Loss: 0.180620580912\n",
      "Epoch: 96 -> Test Accuracy: 89.835\n",
      "[97, 60] loss: 0.144\n",
      "[97, 120] loss: 0.125\n",
      "[97, 180] loss: 0.128\n",
      "[97, 240] loss: 0.138\n",
      "[97, 300] loss: 0.143\n",
      "[97, 360] loss: 0.141\n",
      "Epoch: 97 -> Loss: 0.166250914335\n",
      "Epoch: 97 -> Test Accuracy: 89.7075\n",
      "[98, 60] loss: 0.130\n",
      "[98, 120] loss: 0.129\n",
      "[98, 180] loss: 0.137\n",
      "[98, 240] loss: 0.132\n",
      "[98, 300] loss: 0.150\n",
      "[98, 360] loss: 0.146\n",
      "Epoch: 98 -> Loss: 0.142242640257\n",
      "Epoch: 98 -> Test Accuracy: 90.1375\n",
      "[99, 60] loss: 0.131\n",
      "[99, 120] loss: 0.126\n",
      "[99, 180] loss: 0.140\n",
      "[99, 240] loss: 0.144\n",
      "[99, 300] loss: 0.147\n",
      "[99, 360] loss: 0.146\n",
      "Epoch: 99 -> Loss: 0.101453080773\n",
      "Epoch: 99 -> Test Accuracy: 90.4275\n",
      "[100, 60] loss: 0.122\n",
      "[100, 120] loss: 0.139\n",
      "[100, 180] loss: 0.138\n",
      "[100, 240] loss: 0.136\n",
      "[100, 300] loss: 0.143\n",
      "[100, 360] loss: 0.137\n",
      "Epoch: 100 -> Loss: 0.150251850486\n",
      "Epoch: 100 -> Test Accuracy: 89.705\n",
      "[101, 60] loss: 0.132\n",
      "[101, 120] loss: 0.127\n",
      "[101, 180] loss: 0.136\n",
      "[101, 240] loss: 0.145\n",
      "[101, 300] loss: 0.141\n",
      "[101, 360] loss: 0.145\n",
      "Epoch: 101 -> Loss: 0.0855104550719\n",
      "Epoch: 101 -> Test Accuracy: 89.6775\n",
      "[102, 60] loss: 0.132\n",
      "[102, 120] loss: 0.125\n",
      "[102, 180] loss: 0.138\n",
      "[102, 240] loss: 0.137\n",
      "[102, 300] loss: 0.147\n",
      "[102, 360] loss: 0.135\n",
      "Epoch: 102 -> Loss: 0.146251231432\n",
      "Epoch: 102 -> Test Accuracy: 89.9575\n",
      "[103, 60] loss: 0.127\n",
      "[103, 120] loss: 0.127\n",
      "[103, 180] loss: 0.127\n",
      "[103, 240] loss: 0.135\n",
      "[103, 300] loss: 0.145\n",
      "[103, 360] loss: 0.140\n",
      "Epoch: 103 -> Loss: 0.185835391283\n",
      "Epoch: 103 -> Test Accuracy: 89.6375\n",
      "[104, 60] loss: 0.123\n",
      "[104, 120] loss: 0.133\n",
      "[104, 180] loss: 0.141\n",
      "[104, 240] loss: 0.143\n",
      "[104, 300] loss: 0.135\n",
      "[104, 360] loss: 0.145\n",
      "Epoch: 104 -> Loss: 0.170086860657\n",
      "Epoch: 104 -> Test Accuracy: 90.34\n",
      "[105, 60] loss: 0.131\n",
      "[105, 120] loss: 0.131\n",
      "[105, 180] loss: 0.142\n",
      "[105, 240] loss: 0.139\n",
      "[105, 300] loss: 0.141\n",
      "[105, 360] loss: 0.137\n",
      "Epoch: 105 -> Loss: 0.184625402093\n",
      "Epoch: 105 -> Test Accuracy: 90.285\n",
      "[106, 60] loss: 0.125\n",
      "[106, 120] loss: 0.129\n",
      "[106, 180] loss: 0.134\n",
      "[106, 240] loss: 0.131\n",
      "[106, 300] loss: 0.135\n",
      "[106, 360] loss: 0.137\n",
      "Epoch: 106 -> Loss: 0.116265915334\n",
      "Epoch: 106 -> Test Accuracy: 89.8725\n",
      "[107, 60] loss: 0.121\n",
      "[107, 120] loss: 0.134\n",
      "[107, 180] loss: 0.133\n",
      "[107, 240] loss: 0.140\n",
      "[107, 300] loss: 0.139\n",
      "[107, 360] loss: 0.142\n",
      "Epoch: 107 -> Loss: 0.0980551093817\n",
      "Epoch: 107 -> Test Accuracy: 89.925\n",
      "[108, 60] loss: 0.126\n",
      "[108, 120] loss: 0.130\n",
      "[108, 180] loss: 0.129\n",
      "[108, 240] loss: 0.136\n",
      "[108, 300] loss: 0.142\n",
      "[108, 360] loss: 0.147\n",
      "Epoch: 108 -> Loss: 0.110716022551\n",
      "Epoch: 108 -> Test Accuracy: 90.16\n",
      "[109, 60] loss: 0.124\n",
      "[109, 120] loss: 0.128\n",
      "[109, 180] loss: 0.133\n",
      "[109, 240] loss: 0.145\n",
      "[109, 300] loss: 0.141\n",
      "[109, 360] loss: 0.142\n",
      "Epoch: 109 -> Loss: 0.139072835445\n",
      "Epoch: 109 -> Test Accuracy: 90.05\n",
      "[110, 60] loss: 0.124\n",
      "[110, 120] loss: 0.122\n",
      "[110, 180] loss: 0.141\n",
      "[110, 240] loss: 0.141\n",
      "[110, 300] loss: 0.131\n",
      "[110, 360] loss: 0.140\n",
      "Epoch: 110 -> Loss: 0.153162866831\n",
      "Epoch: 110 -> Test Accuracy: 90.255\n",
      "[111, 60] loss: 0.127\n",
      "[111, 120] loss: 0.130\n",
      "[111, 180] loss: 0.141\n",
      "[111, 240] loss: 0.136\n",
      "[111, 300] loss: 0.136\n",
      "[111, 360] loss: 0.132\n",
      "Epoch: 111 -> Loss: 0.133611112833\n",
      "Epoch: 111 -> Test Accuracy: 90.2425\n",
      "[112, 60] loss: 0.123\n",
      "[112, 120] loss: 0.127\n",
      "[112, 180] loss: 0.135\n",
      "[112, 240] loss: 0.129\n",
      "[112, 300] loss: 0.134\n",
      "[112, 360] loss: 0.143\n",
      "Epoch: 112 -> Loss: 0.0770377367735\n",
      "Epoch: 112 -> Test Accuracy: 89.805\n",
      "[113, 60] loss: 0.121\n",
      "[113, 120] loss: 0.129\n",
      "[113, 180] loss: 0.135\n",
      "[113, 240] loss: 0.133\n",
      "[113, 300] loss: 0.140\n",
      "[113, 360] loss: 0.135\n",
      "Epoch: 113 -> Loss: 0.147103026509\n",
      "Epoch: 113 -> Test Accuracy: 89.9075\n",
      "[114, 60] loss: 0.125\n",
      "[114, 120] loss: 0.126\n",
      "[114, 180] loss: 0.135\n",
      "[114, 240] loss: 0.129\n",
      "[114, 300] loss: 0.138\n",
      "[114, 360] loss: 0.145\n",
      "Epoch: 114 -> Loss: 0.159369260073\n",
      "Epoch: 114 -> Test Accuracy: 89.8\n",
      "[115, 60] loss: 0.127\n",
      "[115, 120] loss: 0.129\n",
      "[115, 180] loss: 0.134\n",
      "[115, 240] loss: 0.140\n",
      "[115, 300] loss: 0.134\n",
      "[115, 360] loss: 0.134\n",
      "Epoch: 115 -> Loss: 0.116256967187\n",
      "Epoch: 115 -> Test Accuracy: 89.3575\n",
      "[116, 60] loss: 0.128\n",
      "[116, 120] loss: 0.130\n",
      "[116, 180] loss: 0.135\n",
      "[116, 240] loss: 0.127\n",
      "[116, 300] loss: 0.143\n",
      "[116, 360] loss: 0.139\n",
      "Epoch: 116 -> Loss: 0.122795082629\n",
      "Epoch: 116 -> Test Accuracy: 90.145\n",
      "[117, 60] loss: 0.122\n",
      "[117, 120] loss: 0.126\n",
      "[117, 180] loss: 0.137\n",
      "[117, 240] loss: 0.140\n",
      "[117, 300] loss: 0.132\n",
      "[117, 360] loss: 0.134\n",
      "Epoch: 117 -> Loss: 0.1140223369\n",
      "Epoch: 117 -> Test Accuracy: 89.82\n",
      "[118, 60] loss: 0.122\n",
      "[118, 120] loss: 0.130\n",
      "[118, 180] loss: 0.121\n",
      "[118, 240] loss: 0.130\n",
      "[118, 300] loss: 0.140\n",
      "[118, 360] loss: 0.137\n",
      "Epoch: 118 -> Loss: 0.14404591918\n",
      "Epoch: 118 -> Test Accuracy: 90.6275\n",
      "[119, 60] loss: 0.117\n",
      "[119, 120] loss: 0.126\n",
      "[119, 180] loss: 0.129\n",
      "[119, 240] loss: 0.128\n",
      "[119, 300] loss: 0.141\n",
      "[119, 360] loss: 0.140\n",
      "Epoch: 119 -> Loss: 0.153453692794\n",
      "Epoch: 119 -> Test Accuracy: 90.2525\n",
      "[120, 60] loss: 0.126\n",
      "[120, 120] loss: 0.133\n",
      "[120, 180] loss: 0.126\n",
      "[120, 240] loss: 0.127\n",
      "[120, 300] loss: 0.133\n",
      "[120, 360] loss: 0.143\n",
      "Epoch: 120 -> Loss: 0.168333038688\n",
      "Epoch: 120 -> Test Accuracy: 90.135\n",
      "[121, 60] loss: 0.092\n",
      "[121, 120] loss: 0.077\n",
      "[121, 180] loss: 0.072\n",
      "[121, 240] loss: 0.066\n",
      "[121, 300] loss: 0.068\n",
      "[121, 360] loss: 0.068\n",
      "Epoch: 121 -> Loss: 0.0550713837147\n",
      "Epoch: 121 -> Test Accuracy: 91.8975\n",
      "[122, 60] loss: 0.056\n",
      "[122, 120] loss: 0.052\n",
      "[122, 180] loss: 0.060\n",
      "[122, 240] loss: 0.056\n",
      "[122, 300] loss: 0.056\n",
      "[122, 360] loss: 0.052\n",
      "Epoch: 122 -> Loss: 0.0684432461858\n",
      "Epoch: 122 -> Test Accuracy: 91.8975\n",
      "[123, 60] loss: 0.049\n",
      "[123, 120] loss: 0.048\n",
      "[123, 180] loss: 0.049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123, 240] loss: 0.050\n",
      "[123, 300] loss: 0.048\n",
      "[123, 360] loss: 0.047\n",
      "Epoch: 123 -> Loss: 0.0314013287425\n",
      "Epoch: 123 -> Test Accuracy: 91.6725\n",
      "[124, 60] loss: 0.046\n",
      "[124, 120] loss: 0.042\n",
      "[124, 180] loss: 0.047\n",
      "[124, 240] loss: 0.045\n",
      "[124, 300] loss: 0.042\n",
      "[124, 360] loss: 0.049\n",
      "Epoch: 124 -> Loss: 0.0775769203901\n",
      "Epoch: 124 -> Test Accuracy: 91.8775\n",
      "[125, 60] loss: 0.041\n",
      "[125, 120] loss: 0.038\n",
      "[125, 180] loss: 0.044\n",
      "[125, 240] loss: 0.044\n",
      "[125, 300] loss: 0.041\n",
      "[125, 360] loss: 0.043\n",
      "Epoch: 125 -> Loss: 0.075447037816\n",
      "Epoch: 125 -> Test Accuracy: 91.5125\n",
      "[126, 60] loss: 0.036\n",
      "[126, 120] loss: 0.036\n",
      "[126, 180] loss: 0.037\n",
      "[126, 240] loss: 0.038\n",
      "[126, 300] loss: 0.041\n",
      "[126, 360] loss: 0.041\n",
      "Epoch: 126 -> Loss: 0.0122171742842\n",
      "Epoch: 126 -> Test Accuracy: 91.8975\n",
      "[127, 60] loss: 0.034\n",
      "[127, 120] loss: 0.036\n",
      "[127, 180] loss: 0.035\n",
      "[127, 240] loss: 0.038\n",
      "[127, 300] loss: 0.037\n",
      "[127, 360] loss: 0.039\n",
      "Epoch: 127 -> Loss: 0.0458883270621\n",
      "Epoch: 127 -> Test Accuracy: 91.76\n",
      "[128, 60] loss: 0.032\n",
      "[128, 120] loss: 0.035\n",
      "[128, 180] loss: 0.033\n",
      "[128, 240] loss: 0.035\n",
      "[128, 300] loss: 0.035\n",
      "[128, 360] loss: 0.036\n",
      "Epoch: 128 -> Loss: 0.0545563697815\n",
      "Epoch: 128 -> Test Accuracy: 91.71\n",
      "[129, 60] loss: 0.031\n",
      "[129, 120] loss: 0.034\n",
      "[129, 180] loss: 0.031\n",
      "[129, 240] loss: 0.029\n",
      "[129, 300] loss: 0.033\n",
      "[129, 360] loss: 0.032\n",
      "Epoch: 129 -> Loss: 0.0250259842724\n",
      "Epoch: 129 -> Test Accuracy: 91.8075\n",
      "[130, 60] loss: 0.030\n",
      "[130, 120] loss: 0.029\n",
      "[130, 180] loss: 0.030\n",
      "[130, 240] loss: 0.034\n",
      "[130, 300] loss: 0.036\n",
      "[130, 360] loss: 0.034\n",
      "Epoch: 130 -> Loss: 0.0377309024334\n",
      "Epoch: 130 -> Test Accuracy: 91.7475\n",
      "[131, 60] loss: 0.028\n",
      "[131, 120] loss: 0.029\n",
      "[131, 180] loss: 0.029\n",
      "[131, 240] loss: 0.028\n",
      "[131, 300] loss: 0.032\n",
      "[131, 360] loss: 0.034\n",
      "Epoch: 131 -> Loss: 0.0283929761499\n",
      "Epoch: 131 -> Test Accuracy: 91.6775\n",
      "[132, 60] loss: 0.027\n",
      "[132, 120] loss: 0.027\n",
      "[132, 180] loss: 0.028\n",
      "[132, 240] loss: 0.030\n",
      "[132, 300] loss: 0.032\n",
      "[132, 360] loss: 0.032\n",
      "Epoch: 132 -> Loss: 0.0420226939023\n",
      "Epoch: 132 -> Test Accuracy: 91.715\n",
      "[133, 60] loss: 0.030\n",
      "[133, 120] loss: 0.028\n",
      "[133, 180] loss: 0.027\n",
      "[133, 240] loss: 0.029\n",
      "[133, 300] loss: 0.033\n",
      "[133, 360] loss: 0.029\n",
      "Epoch: 133 -> Loss: 0.0640896633267\n",
      "Epoch: 133 -> Test Accuracy: 91.5925\n",
      "[134, 60] loss: 0.026\n",
      "[134, 120] loss: 0.028\n",
      "[134, 180] loss: 0.027\n",
      "[134, 240] loss: 0.028\n",
      "[134, 300] loss: 0.031\n",
      "[134, 360] loss: 0.030\n",
      "Epoch: 134 -> Loss: 0.063131429255\n",
      "Epoch: 134 -> Test Accuracy: 91.5225\n",
      "[135, 60] loss: 0.026\n",
      "[135, 120] loss: 0.025\n",
      "[135, 180] loss: 0.032\n",
      "[135, 240] loss: 0.025\n",
      "[135, 300] loss: 0.028\n",
      "[135, 360] loss: 0.029\n",
      "Epoch: 135 -> Loss: 0.0179896093905\n",
      "Epoch: 135 -> Test Accuracy: 91.3925\n",
      "[136, 60] loss: 0.024\n",
      "[136, 120] loss: 0.027\n",
      "[136, 180] loss: 0.029\n",
      "[136, 240] loss: 0.025\n",
      "[136, 300] loss: 0.027\n",
      "[136, 360] loss: 0.030\n",
      "Epoch: 136 -> Loss: 0.050122987479\n",
      "Epoch: 136 -> Test Accuracy: 91.57\n",
      "[137, 60] loss: 0.026\n",
      "[137, 120] loss: 0.026\n",
      "[137, 180] loss: 0.024\n",
      "[137, 240] loss: 0.026\n",
      "[137, 300] loss: 0.026\n",
      "[137, 360] loss: 0.026\n",
      "Epoch: 137 -> Loss: 0.0336604937911\n",
      "Epoch: 137 -> Test Accuracy: 91.66\n",
      "[138, 60] loss: 0.025\n",
      "[138, 120] loss: 0.024\n",
      "[138, 180] loss: 0.025\n",
      "[138, 240] loss: 0.024\n",
      "[138, 300] loss: 0.027\n",
      "[138, 360] loss: 0.026\n",
      "Epoch: 138 -> Loss: 0.0129658458754\n",
      "Epoch: 138 -> Test Accuracy: 91.675\n",
      "[139, 60] loss: 0.026\n",
      "[139, 120] loss: 0.025\n",
      "[139, 180] loss: 0.027\n",
      "[139, 240] loss: 0.027\n",
      "[139, 300] loss: 0.025\n",
      "[139, 360] loss: 0.025\n",
      "Epoch: 139 -> Loss: 0.0314084365964\n",
      "Epoch: 139 -> Test Accuracy: 91.33\n",
      "[140, 60] loss: 0.023\n",
      "[140, 120] loss: 0.026\n",
      "[140, 180] loss: 0.024\n",
      "[140, 240] loss: 0.024\n",
      "[140, 300] loss: 0.025\n",
      "[140, 360] loss: 0.025\n",
      "Epoch: 140 -> Loss: 0.0443952158093\n",
      "Epoch: 140 -> Test Accuracy: 91.58\n",
      "[141, 60] loss: 0.024\n",
      "[141, 120] loss: 0.023\n",
      "[141, 180] loss: 0.022\n",
      "[141, 240] loss: 0.026\n",
      "[141, 300] loss: 0.022\n",
      "[141, 360] loss: 0.027\n",
      "Epoch: 141 -> Loss: 0.0331480950117\n",
      "Epoch: 141 -> Test Accuracy: 91.2225\n",
      "[142, 60] loss: 0.024\n",
      "[142, 120] loss: 0.023\n",
      "[142, 180] loss: 0.025\n",
      "[142, 240] loss: 0.024\n",
      "[142, 300] loss: 0.023\n",
      "[142, 360] loss: 0.026\n",
      "Epoch: 142 -> Loss: 0.0327328518033\n",
      "Epoch: 142 -> Test Accuracy: 91.2575\n",
      "[143, 60] loss: 0.025\n",
      "[143, 120] loss: 0.025\n",
      "[143, 180] loss: 0.023\n",
      "[143, 240] loss: 0.025\n",
      "[143, 300] loss: 0.027\n",
      "[143, 360] loss: 0.028\n",
      "Epoch: 143 -> Loss: 0.0255203209817\n",
      "Epoch: 143 -> Test Accuracy: 91.5\n",
      "[144, 60] loss: 0.024\n",
      "[144, 120] loss: 0.022\n",
      "[144, 180] loss: 0.027\n",
      "[144, 240] loss: 0.026\n",
      "[144, 300] loss: 0.024\n",
      "[144, 360] loss: 0.026\n",
      "Epoch: 144 -> Loss: 0.00457324180752\n",
      "Epoch: 144 -> Test Accuracy: 91.25\n",
      "[145, 60] loss: 0.021\n",
      "[145, 120] loss: 0.026\n",
      "[145, 180] loss: 0.024\n",
      "[145, 240] loss: 0.024\n",
      "[145, 300] loss: 0.026\n",
      "[145, 360] loss: 0.025\n",
      "Epoch: 145 -> Loss: 0.0246849302202\n",
      "Epoch: 145 -> Test Accuracy: 91.395\n",
      "[146, 60] loss: 0.025\n",
      "[146, 120] loss: 0.023\n",
      "[146, 180] loss: 0.025\n",
      "[146, 240] loss: 0.024\n",
      "[146, 300] loss: 0.026\n",
      "[146, 360] loss: 0.027\n",
      "Epoch: 146 -> Loss: 0.0290240980685\n",
      "Epoch: 146 -> Test Accuracy: 91.1525\n",
      "[147, 60] loss: 0.024\n",
      "[147, 120] loss: 0.025\n",
      "[147, 180] loss: 0.024\n",
      "[147, 240] loss: 0.022\n",
      "[147, 300] loss: 0.025\n",
      "[147, 360] loss: 0.024\n",
      "Epoch: 147 -> Loss: 0.0192519444972\n",
      "Epoch: 147 -> Test Accuracy: 91.34\n",
      "[148, 60] loss: 0.020\n",
      "[148, 120] loss: 0.023\n",
      "[148, 180] loss: 0.024\n",
      "[148, 240] loss: 0.023\n",
      "[148, 300] loss: 0.025\n",
      "[148, 360] loss: 0.027\n",
      "Epoch: 148 -> Loss: 0.0406850650907\n",
      "Epoch: 148 -> Test Accuracy: 91.29\n",
      "[149, 60] loss: 0.024\n",
      "[149, 120] loss: 0.022\n",
      "[149, 180] loss: 0.023\n",
      "[149, 240] loss: 0.024\n",
      "[149, 300] loss: 0.025\n",
      "[149, 360] loss: 0.029\n",
      "Epoch: 149 -> Loss: 0.0148980515078\n",
      "Epoch: 149 -> Test Accuracy: 91.22\n",
      "[150, 60] loss: 0.024\n",
      "[150, 120] loss: 0.025\n",
      "[150, 180] loss: 0.024\n",
      "[150, 240] loss: 0.026\n",
      "[150, 300] loss: 0.025\n",
      "[150, 360] loss: 0.025\n",
      "Epoch: 150 -> Loss: 0.0166861824691\n",
      "Epoch: 150 -> Test Accuracy: 91.39\n",
      "[151, 60] loss: 0.022\n",
      "[151, 120] loss: 0.025\n",
      "[151, 180] loss: 0.023\n",
      "[151, 240] loss: 0.024\n",
      "[151, 300] loss: 0.026\n",
      "[151, 360] loss: 0.025\n",
      "Epoch: 151 -> Loss: 0.0185334794223\n",
      "Epoch: 151 -> Test Accuracy: 91.25\n",
      "[152, 60] loss: 0.022\n",
      "[152, 120] loss: 0.023\n",
      "[152, 180] loss: 0.025\n",
      "[152, 240] loss: 0.028\n",
      "[152, 300] loss: 0.024\n",
      "[152, 360] loss: 0.026\n",
      "Epoch: 152 -> Loss: 0.0528041422367\n",
      "Epoch: 152 -> Test Accuracy: 91.305\n",
      "[153, 60] loss: 0.025\n",
      "[153, 120] loss: 0.027\n",
      "[153, 180] loss: 0.026\n",
      "[153, 240] loss: 0.026\n",
      "[153, 300] loss: 0.028\n",
      "[153, 360] loss: 0.027\n",
      "Epoch: 153 -> Loss: 0.0211244113743\n",
      "Epoch: 153 -> Test Accuracy: 91.375\n",
      "[154, 60] loss: 0.024\n",
      "[154, 120] loss: 0.023\n",
      "[154, 180] loss: 0.026\n",
      "[154, 240] loss: 0.027\n",
      "[154, 300] loss: 0.028\n",
      "[154, 360] loss: 0.029\n",
      "Epoch: 154 -> Loss: 0.013138952665\n",
      "Epoch: 154 -> Test Accuracy: 91.215\n",
      "[155, 60] loss: 0.023\n",
      "[155, 120] loss: 0.025\n",
      "[155, 180] loss: 0.025\n",
      "[155, 240] loss: 0.028\n",
      "[155, 300] loss: 0.028\n",
      "[155, 360] loss: 0.025\n",
      "Epoch: 155 -> Loss: 0.0327915363014\n",
      "Epoch: 155 -> Test Accuracy: 91.3\n",
      "[156, 60] loss: 0.024\n",
      "[156, 120] loss: 0.026\n",
      "[156, 180] loss: 0.027\n",
      "[156, 240] loss: 0.025\n",
      "[156, 300] loss: 0.027\n",
      "[156, 360] loss: 0.027\n",
      "Epoch: 156 -> Loss: 0.0452433787286\n",
      "Epoch: 156 -> Test Accuracy: 91.3525\n",
      "[157, 60] loss: 0.024\n",
      "[157, 120] loss: 0.028\n",
      "[157, 180] loss: 0.027\n",
      "[157, 240] loss: 0.024\n",
      "[157, 300] loss: 0.024\n",
      "[157, 360] loss: 0.028\n",
      "Epoch: 157 -> Loss: 0.0109061850235\n",
      "Epoch: 157 -> Test Accuracy: 91.04\n",
      "[158, 60] loss: 0.024\n",
      "[158, 120] loss: 0.023\n",
      "[158, 180] loss: 0.027\n",
      "[158, 240] loss: 0.027\n",
      "[158, 300] loss: 0.026\n",
      "[158, 360] loss: 0.032\n",
      "Epoch: 158 -> Loss: 0.0437621213496\n",
      "Epoch: 158 -> Test Accuracy: 91.1875\n",
      "[159, 60] loss: 0.026\n",
      "[159, 120] loss: 0.025\n",
      "[159, 180] loss: 0.027\n",
      "[159, 240] loss: 0.026\n",
      "[159, 300] loss: 0.026\n",
      "[159, 360] loss: 0.031\n",
      "Epoch: 159 -> Loss: 0.0345814153552\n",
      "Epoch: 159 -> Test Accuracy: 91.0475\n",
      "[160, 60] loss: 0.029\n",
      "[160, 120] loss: 0.027\n",
      "[160, 180] loss: 0.025\n",
      "[160, 240] loss: 0.030\n",
      "[160, 300] loss: 0.026\n",
      "[160, 360] loss: 0.026\n",
      "Epoch: 160 -> Loss: 0.0568756535649\n",
      "Epoch: 160 -> Test Accuracy: 91.2225\n",
      "[161, 60] loss: 0.022\n",
      "[161, 120] loss: 0.018\n",
      "[161, 180] loss: 0.016\n",
      "[161, 240] loss: 0.015\n",
      "[161, 300] loss: 0.016\n",
      "[161, 360] loss: 0.013\n",
      "Epoch: 161 -> Loss: 0.0316968150437\n",
      "Epoch: 161 -> Test Accuracy: 91.7275\n",
      "[162, 60] loss: 0.014\n",
      "[162, 120] loss: 0.012\n",
      "[162, 180] loss: 0.012\n",
      "[162, 240] loss: 0.012\n",
      "[162, 300] loss: 0.012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[162, 360] loss: 0.012\n",
      "Epoch: 162 -> Loss: 0.0106612304226\n",
      "Epoch: 162 -> Test Accuracy: 91.8225\n",
      "[163, 60] loss: 0.010\n",
      "[163, 120] loss: 0.012\n",
      "[163, 180] loss: 0.011\n",
      "[163, 240] loss: 0.011\n",
      "[163, 300] loss: 0.010\n",
      "[163, 360] loss: 0.011\n",
      "Epoch: 163 -> Loss: 0.0206543244421\n",
      "Epoch: 163 -> Test Accuracy: 91.82\n",
      "[164, 60] loss: 0.009\n",
      "[164, 120] loss: 0.010\n",
      "[164, 180] loss: 0.010\n",
      "[164, 240] loss: 0.010\n",
      "[164, 300] loss: 0.010\n",
      "[164, 360] loss: 0.011\n",
      "Epoch: 164 -> Loss: 0.0153250638396\n",
      "Epoch: 164 -> Test Accuracy: 91.81\n",
      "[165, 60] loss: 0.009\n",
      "[165, 120] loss: 0.010\n",
      "[165, 180] loss: 0.009\n",
      "[165, 240] loss: 0.009\n",
      "[165, 300] loss: 0.009\n",
      "[165, 360] loss: 0.010\n",
      "Epoch: 165 -> Loss: 0.0122531848028\n",
      "Epoch: 165 -> Test Accuracy: 91.8475\n",
      "[166, 60] loss: 0.009\n",
      "[166, 120] loss: 0.009\n",
      "[166, 180] loss: 0.009\n",
      "[166, 240] loss: 0.010\n",
      "[166, 300] loss: 0.009\n",
      "[166, 360] loss: 0.010\n",
      "Epoch: 166 -> Loss: 0.00318783451803\n",
      "Epoch: 166 -> Test Accuracy: 91.765\n",
      "[167, 60] loss: 0.010\n",
      "[167, 120] loss: 0.008\n",
      "[167, 180] loss: 0.008\n",
      "[167, 240] loss: 0.010\n",
      "[167, 300] loss: 0.008\n",
      "[167, 360] loss: 0.008\n",
      "Epoch: 167 -> Loss: 0.00441742222756\n",
      "Epoch: 167 -> Test Accuracy: 91.945\n",
      "[168, 60] loss: 0.008\n",
      "[168, 120] loss: 0.007\n",
      "[168, 180] loss: 0.010\n",
      "[168, 240] loss: 0.008\n",
      "[168, 300] loss: 0.010\n",
      "[168, 360] loss: 0.009\n",
      "Epoch: 168 -> Loss: 0.0169557482004\n",
      "Epoch: 168 -> Test Accuracy: 91.87\n",
      "[169, 60] loss: 0.009\n",
      "[169, 120] loss: 0.008\n",
      "[169, 180] loss: 0.009\n",
      "[169, 240] loss: 0.008\n",
      "[169, 300] loss: 0.008\n",
      "[169, 360] loss: 0.008\n",
      "Epoch: 169 -> Loss: 0.00172856298741\n",
      "Epoch: 169 -> Test Accuracy: 91.845\n",
      "[170, 60] loss: 0.008\n",
      "[170, 120] loss: 0.008\n",
      "[170, 180] loss: 0.009\n",
      "[170, 240] loss: 0.008\n",
      "[170, 300] loss: 0.007\n",
      "[170, 360] loss: 0.008\n",
      "Epoch: 170 -> Loss: 0.0108220214024\n",
      "Epoch: 170 -> Test Accuracy: 91.9325\n",
      "[171, 60] loss: 0.008\n",
      "[171, 120] loss: 0.008\n",
      "[171, 180] loss: 0.008\n",
      "[171, 240] loss: 0.008\n",
      "[171, 300] loss: 0.008\n",
      "[171, 360] loss: 0.008\n",
      "Epoch: 171 -> Loss: 0.00426762923598\n",
      "Epoch: 171 -> Test Accuracy: 91.8675\n",
      "[172, 60] loss: 0.008\n",
      "[172, 120] loss: 0.007\n",
      "[172, 180] loss: 0.007\n",
      "[172, 240] loss: 0.008\n",
      "[172, 300] loss: 0.008\n",
      "[172, 360] loss: 0.007\n",
      "Epoch: 172 -> Loss: 0.00889964587986\n",
      "Epoch: 172 -> Test Accuracy: 91.965\n",
      "[173, 60] loss: 0.007\n",
      "[173, 120] loss: 0.007\n",
      "[173, 180] loss: 0.006\n",
      "[173, 240] loss: 0.008\n",
      "[173, 300] loss: 0.008\n",
      "[173, 360] loss: 0.007\n",
      "Epoch: 173 -> Loss: 0.00603892141953\n",
      "Epoch: 173 -> Test Accuracy: 91.875\n",
      "[174, 60] loss: 0.007\n",
      "[174, 120] loss: 0.007\n",
      "[174, 180] loss: 0.007\n",
      "[174, 240] loss: 0.007\n",
      "[174, 300] loss: 0.007\n",
      "[174, 360] loss: 0.007\n",
      "Epoch: 174 -> Loss: 0.0065567754209\n",
      "Epoch: 174 -> Test Accuracy: 91.9825\n",
      "[175, 60] loss: 0.007\n",
      "[175, 120] loss: 0.006\n",
      "[175, 180] loss: 0.006\n",
      "[175, 240] loss: 0.007\n",
      "[175, 300] loss: 0.007\n",
      "[175, 360] loss: 0.007\n",
      "Epoch: 175 -> Loss: 0.0039096288383\n",
      "Epoch: 175 -> Test Accuracy: 91.9625\n",
      "[176, 60] loss: 0.007\n",
      "[176, 120] loss: 0.007\n",
      "[176, 180] loss: 0.007\n",
      "[176, 240] loss: 0.006\n",
      "[176, 300] loss: 0.007\n",
      "[176, 360] loss: 0.007\n",
      "Epoch: 176 -> Loss: 0.0120218191296\n",
      "Epoch: 176 -> Test Accuracy: 92.0\n",
      "[177, 60] loss: 0.007\n",
      "[177, 120] loss: 0.006\n",
      "[177, 180] loss: 0.007\n",
      "[177, 240] loss: 0.007\n",
      "[177, 300] loss: 0.007\n",
      "[177, 360] loss: 0.006\n",
      "Epoch: 177 -> Loss: 0.00326912850142\n",
      "Epoch: 177 -> Test Accuracy: 92.0025\n",
      "[178, 60] loss: 0.007\n",
      "[178, 120] loss: 0.006\n",
      "[178, 180] loss: 0.007\n",
      "[178, 240] loss: 0.007\n",
      "[178, 300] loss: 0.006\n",
      "[178, 360] loss: 0.007\n",
      "Epoch: 178 -> Loss: 0.00465442473069\n",
      "Epoch: 178 -> Test Accuracy: 92.045\n",
      "[179, 60] loss: 0.008\n",
      "[179, 120] loss: 0.007\n",
      "[179, 180] loss: 0.006\n",
      "[179, 240] loss: 0.007\n",
      "[179, 300] loss: 0.007\n",
      "[179, 360] loss: 0.007\n",
      "Epoch: 179 -> Loss: 0.00910116359591\n",
      "Epoch: 179 -> Test Accuracy: 92.0925\n",
      "[180, 60] loss: 0.007\n",
      "[180, 120] loss: 0.007\n",
      "[180, 180] loss: 0.007\n",
      "[180, 240] loss: 0.006\n",
      "[180, 300] loss: 0.007\n",
      "[180, 360] loss: 0.007\n",
      "Epoch: 180 -> Loss: 0.00352413137443\n",
      "Epoch: 180 -> Test Accuracy: 91.9625\n",
      "[181, 60] loss: 0.006\n",
      "[181, 120] loss: 0.006\n",
      "[181, 180] loss: 0.007\n",
      "[181, 240] loss: 0.007\n",
      "[181, 300] loss: 0.006\n",
      "[181, 360] loss: 0.006\n",
      "Epoch: 181 -> Loss: 0.00995018798858\n",
      "Epoch: 181 -> Test Accuracy: 91.9925\n",
      "[182, 60] loss: 0.006\n",
      "[182, 120] loss: 0.006\n",
      "[182, 180] loss: 0.007\n",
      "[182, 240] loss: 0.006\n",
      "[182, 300] loss: 0.007\n",
      "[182, 360] loss: 0.006\n",
      "Epoch: 182 -> Loss: 0.00619605462998\n",
      "Epoch: 182 -> Test Accuracy: 91.945\n",
      "[183, 60] loss: 0.005\n",
      "[183, 120] loss: 0.006\n",
      "[183, 180] loss: 0.006\n",
      "[183, 240] loss: 0.006\n",
      "[183, 300] loss: 0.006\n",
      "[183, 360] loss: 0.007\n",
      "Epoch: 183 -> Loss: 0.00373314926401\n",
      "Epoch: 183 -> Test Accuracy: 91.935\n",
      "[184, 60] loss: 0.006\n",
      "[184, 120] loss: 0.005\n",
      "[184, 180] loss: 0.006\n",
      "[184, 240] loss: 0.006\n",
      "[184, 300] loss: 0.007\n",
      "[184, 360] loss: 0.006\n",
      "Epoch: 184 -> Loss: 0.00370132923126\n",
      "Epoch: 184 -> Test Accuracy: 91.9425\n",
      "[185, 60] loss: 0.006\n",
      "[185, 120] loss: 0.006\n",
      "[185, 180] loss: 0.006\n",
      "[185, 240] loss: 0.006\n",
      "[185, 300] loss: 0.006\n",
      "[185, 360] loss: 0.007\n",
      "Epoch: 185 -> Loss: 0.00267419964075\n",
      "Epoch: 185 -> Test Accuracy: 91.8425\n",
      "[186, 60] loss: 0.006\n",
      "[186, 120] loss: 0.006\n",
      "[186, 180] loss: 0.006\n",
      "[186, 240] loss: 0.006\n",
      "[186, 300] loss: 0.006\n",
      "[186, 360] loss: 0.006\n",
      "Epoch: 186 -> Loss: 0.00358331506141\n",
      "Epoch: 186 -> Test Accuracy: 91.865\n",
      "[187, 60] loss: 0.006\n",
      "[187, 120] loss: 0.005\n",
      "[187, 180] loss: 0.006\n",
      "[187, 240] loss: 0.006\n",
      "[187, 300] loss: 0.006\n",
      "[187, 360] loss: 0.007\n",
      "Epoch: 187 -> Loss: 0.0104720275849\n",
      "Epoch: 187 -> Test Accuracy: 91.89\n",
      "[188, 60] loss: 0.005\n",
      "[188, 120] loss: 0.005\n",
      "[188, 180] loss: 0.006\n",
      "[188, 240] loss: 0.006\n",
      "[188, 300] loss: 0.006\n",
      "[188, 360] loss: 0.006\n",
      "Epoch: 188 -> Loss: 0.00551014533266\n",
      "Epoch: 188 -> Test Accuracy: 91.8175\n",
      "[189, 60] loss: 0.006\n",
      "[189, 120] loss: 0.006\n",
      "[189, 180] loss: 0.006\n",
      "[189, 240] loss: 0.005\n",
      "[189, 300] loss: 0.006\n",
      "[189, 360] loss: 0.006\n",
      "Epoch: 189 -> Loss: 0.0125435618684\n",
      "Epoch: 189 -> Test Accuracy: 91.9525\n",
      "[190, 60] loss: 0.005\n",
      "[190, 120] loss: 0.006\n",
      "[190, 180] loss: 0.006\n",
      "[190, 240] loss: 0.006\n",
      "[190, 300] loss: 0.005\n",
      "[190, 360] loss: 0.005\n",
      "Epoch: 190 -> Loss: 0.00543540716171\n",
      "Epoch: 190 -> Test Accuracy: 91.93\n",
      "[191, 60] loss: 0.005\n",
      "[191, 120] loss: 0.006\n",
      "[191, 180] loss: 0.005\n",
      "[191, 240] loss: 0.005\n",
      "[191, 300] loss: 0.005\n",
      "[191, 360] loss: 0.005\n",
      "Epoch: 191 -> Loss: 0.00355360284448\n",
      "Epoch: 191 -> Test Accuracy: 91.9225\n",
      "[192, 60] loss: 0.006\n",
      "[192, 120] loss: 0.005\n",
      "[192, 180] loss: 0.006\n",
      "[192, 240] loss: 0.006\n",
      "[192, 300] loss: 0.006\n",
      "[192, 360] loss: 0.006\n",
      "Epoch: 192 -> Loss: 0.00739593291655\n",
      "Epoch: 192 -> Test Accuracy: 92.0225\n",
      "[193, 60] loss: 0.005\n",
      "[193, 120] loss: 0.006\n",
      "[193, 180] loss: 0.005\n",
      "[193, 240] loss: 0.006\n",
      "[193, 300] loss: 0.005\n",
      "[193, 360] loss: 0.006\n",
      "Epoch: 193 -> Loss: 0.00339808082208\n",
      "Epoch: 193 -> Test Accuracy: 91.9525\n",
      "[194, 60] loss: 0.006\n",
      "[194, 120] loss: 0.005\n",
      "[194, 180] loss: 0.006\n",
      "[194, 240] loss: 0.005\n",
      "[194, 300] loss: 0.005\n",
      "[194, 360] loss: 0.006\n",
      "Epoch: 194 -> Loss: 0.00325859780423\n",
      "Epoch: 194 -> Test Accuracy: 91.975\n",
      "[195, 60] loss: 0.005\n",
      "[195, 120] loss: 0.006\n",
      "[195, 180] loss: 0.006\n",
      "[195, 240] loss: 0.006\n",
      "[195, 300] loss: 0.005\n",
      "[195, 360] loss: 0.006\n",
      "Epoch: 195 -> Loss: 0.00344982510433\n",
      "Epoch: 195 -> Test Accuracy: 91.975\n",
      "[196, 60] loss: 0.006\n",
      "[196, 120] loss: 0.006\n",
      "[196, 180] loss: 0.005\n",
      "[196, 240] loss: 0.006\n",
      "[196, 300] loss: 0.005\n",
      "[196, 360] loss: 0.006\n",
      "Epoch: 196 -> Loss: 0.00617140578106\n",
      "Epoch: 196 -> Test Accuracy: 91.9125\n",
      "[197, 60] loss: 0.006\n",
      "[197, 120] loss: 0.005\n",
      "[197, 180] loss: 0.005\n",
      "[197, 240] loss: 0.006\n",
      "[197, 300] loss: 0.006\n",
      "[197, 360] loss: 0.006\n",
      "Epoch: 197 -> Loss: 0.0059173530899\n",
      "Epoch: 197 -> Test Accuracy: 91.8925\n",
      "[198, 60] loss: 0.006\n",
      "[198, 120] loss: 0.005\n",
      "[198, 180] loss: 0.006\n",
      "[198, 240] loss: 0.005\n",
      "[198, 300] loss: 0.005\n",
      "[198, 360] loss: 0.005\n",
      "Epoch: 198 -> Loss: 0.00309433182701\n",
      "Epoch: 198 -> Test Accuracy: 91.985\n",
      "[199, 60] loss: 0.005\n",
      "[199, 120] loss: 0.005\n",
      "[199, 180] loss: 0.005\n",
      "[199, 240] loss: 0.006\n",
      "[199, 300] loss: 0.005\n",
      "[199, 360] loss: 0.005\n",
      "Epoch: 199 -> Loss: 0.00374931609258\n",
      "Epoch: 199 -> Test Accuracy: 91.965\n",
      "[200, 60] loss: 0.004\n",
      "[200, 120] loss: 0.005\n",
      "[200, 180] loss: 0.005\n",
      "[200, 240] loss: 0.006\n",
      "[200, 300] loss: 0.006\n",
      "[200, 360] loss: 0.006\n",
      "Epoch: 200 -> Loss: 0.0085416957736\n",
      "Epoch: 200 -> Test Accuracy: 92.0125\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "rot_block4_loss_log, _, rot_block4_test_accuracy_log, _, _ = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], \n",
    "    [60, 120, 160, 200], 0.9, 5e-4, net_block4, criterion, trainloader, None, testloader, rot=['90', '180', '270'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 2.193\n",
      "[1, 120] loss: 1.210\n",
      "[1, 180] loss: 1.152\n",
      "[1, 240] loss: 1.063\n",
      "[1, 300] loss: 1.022\n",
      "[1, 360] loss: 0.999\n",
      "Epoch: 1 -> Loss: 0.855801939964\n",
      "Epoch: 1 -> Test Accuracy: 66.44\n",
      "[2, 60] loss: 0.934\n",
      "[2, 120] loss: 0.945\n",
      "[2, 180] loss: 0.883\n",
      "[2, 240] loss: 0.879\n",
      "[2, 300] loss: 0.904\n",
      "[2, 360] loss: 0.872\n",
      "Epoch: 2 -> Loss: 0.800943017006\n",
      "Epoch: 2 -> Test Accuracy: 70.93\n",
      "[3, 60] loss: 0.831\n",
      "[3, 120] loss: 0.826\n",
      "[3, 180] loss: 0.833\n",
      "[3, 240] loss: 0.793\n",
      "[3, 300] loss: 0.806\n",
      "[3, 360] loss: 0.801\n",
      "Epoch: 3 -> Loss: 0.897849202156\n",
      "Epoch: 3 -> Test Accuracy: 73.18\n",
      "[4, 60] loss: 0.782\n",
      "[4, 120] loss: 0.751\n",
      "[4, 180] loss: 0.758\n",
      "[4, 240] loss: 0.797\n",
      "[4, 300] loss: 0.741\n",
      "[4, 360] loss: 0.754\n",
      "Epoch: 4 -> Loss: 0.613576591015\n",
      "Epoch: 4 -> Test Accuracy: 74.4\n",
      "[5, 60] loss: 0.734\n",
      "[5, 120] loss: 0.731\n",
      "[5, 180] loss: 0.704\n",
      "[5, 240] loss: 0.724\n",
      "[5, 300] loss: 0.723\n",
      "[5, 360] loss: 0.738\n",
      "Epoch: 5 -> Loss: 0.856733620167\n",
      "Epoch: 5 -> Test Accuracy: 75.34\n",
      "[6, 60] loss: 0.708\n",
      "[6, 120] loss: 0.696\n",
      "[6, 180] loss: 0.707\n",
      "[6, 240] loss: 0.680\n",
      "[6, 300] loss: 0.698\n",
      "[6, 360] loss: 0.703\n",
      "Epoch: 6 -> Loss: 0.856352329254\n",
      "Epoch: 6 -> Test Accuracy: 76.18\n",
      "[7, 60] loss: 0.673\n",
      "[7, 120] loss: 0.674\n",
      "[7, 180] loss: 0.690\n",
      "[7, 240] loss: 0.692\n",
      "[7, 300] loss: 0.673\n",
      "[7, 360] loss: 0.675\n",
      "Epoch: 7 -> Loss: 0.626320719719\n",
      "Epoch: 7 -> Test Accuracy: 75.92\n",
      "[8, 60] loss: 0.652\n",
      "[8, 120] loss: 0.651\n",
      "[8, 180] loss: 0.667\n",
      "[8, 240] loss: 0.655\n",
      "[8, 300] loss: 0.665\n",
      "[8, 360] loss: 0.683\n",
      "Epoch: 8 -> Loss: 0.631165325642\n",
      "Epoch: 8 -> Test Accuracy: 76.92\n",
      "[9, 60] loss: 0.629\n",
      "[9, 120] loss: 0.651\n",
      "[9, 180] loss: 0.659\n",
      "[9, 240] loss: 0.665\n",
      "[9, 300] loss: 0.638\n",
      "[9, 360] loss: 0.669\n",
      "Epoch: 9 -> Loss: 0.694538474083\n",
      "Epoch: 9 -> Test Accuracy: 76.88\n",
      "[10, 60] loss: 0.626\n",
      "[10, 120] loss: 0.643\n",
      "[10, 180] loss: 0.647\n",
      "[10, 240] loss: 0.658\n",
      "[10, 300] loss: 0.655\n",
      "[10, 360] loss: 0.653\n",
      "Epoch: 10 -> Loss: 0.761452019215\n",
      "Epoch: 10 -> Test Accuracy: 77.11\n",
      "[11, 60] loss: 0.628\n",
      "[11, 120] loss: 0.628\n",
      "[11, 180] loss: 0.655\n",
      "[11, 240] loss: 0.633\n",
      "[11, 300] loss: 0.659\n",
      "[11, 360] loss: 0.614\n",
      "Epoch: 11 -> Loss: 0.718149662018\n",
      "Epoch: 11 -> Test Accuracy: 77.36\n",
      "[12, 60] loss: 0.626\n",
      "[12, 120] loss: 0.641\n",
      "[12, 180] loss: 0.640\n",
      "[12, 240] loss: 0.636\n",
      "[12, 300] loss: 0.597\n",
      "[12, 360] loss: 0.633\n",
      "Epoch: 12 -> Loss: 0.82984906435\n",
      "Epoch: 12 -> Test Accuracy: 77.77\n",
      "[13, 60] loss: 0.601\n",
      "[13, 120] loss: 0.616\n",
      "[13, 180] loss: 0.619\n",
      "[13, 240] loss: 0.634\n",
      "[13, 300] loss: 0.624\n",
      "[13, 360] loss: 0.640\n",
      "Epoch: 13 -> Loss: 0.616898059845\n",
      "Epoch: 13 -> Test Accuracy: 77.54\n",
      "[14, 60] loss: 0.609\n",
      "[14, 120] loss: 0.630\n",
      "[14, 180] loss: 0.616\n",
      "[14, 240] loss: 0.631\n",
      "[14, 300] loss: 0.624\n",
      "[14, 360] loss: 0.624\n",
      "Epoch: 14 -> Loss: 0.709586322308\n",
      "Epoch: 14 -> Test Accuracy: 78.36\n",
      "[15, 60] loss: 0.613\n",
      "[15, 120] loss: 0.609\n",
      "[15, 180] loss: 0.613\n",
      "[15, 240] loss: 0.622\n",
      "[15, 300] loss: 0.614\n",
      "[15, 360] loss: 0.642\n",
      "Epoch: 15 -> Loss: 0.708247482777\n",
      "Epoch: 15 -> Test Accuracy: 77.63\n",
      "[16, 60] loss: 0.598\n",
      "[16, 120] loss: 0.604\n",
      "[16, 180] loss: 0.611\n",
      "[16, 240] loss: 0.621\n",
      "[16, 300] loss: 0.624\n",
      "[16, 360] loss: 0.599\n",
      "Epoch: 16 -> Loss: 0.480143606663\n",
      "Epoch: 16 -> Test Accuracy: 77.9\n",
      "[17, 60] loss: 0.585\n",
      "[17, 120] loss: 0.584\n",
      "[17, 180] loss: 0.626\n",
      "[17, 240] loss: 0.619\n",
      "[17, 300] loss: 0.628\n",
      "[17, 360] loss: 0.614\n",
      "Epoch: 17 -> Loss: 0.583816170692\n",
      "Epoch: 17 -> Test Accuracy: 78.14\n",
      "[18, 60] loss: 0.601\n",
      "[18, 120] loss: 0.598\n",
      "[18, 180] loss: 0.602\n",
      "[18, 240] loss: 0.614\n",
      "[18, 300] loss: 0.609\n",
      "[18, 360] loss: 0.612\n",
      "Epoch: 18 -> Loss: 0.447328001261\n",
      "Epoch: 18 -> Test Accuracy: 78.02\n",
      "[19, 60] loss: 0.590\n",
      "[19, 120] loss: 0.591\n",
      "[19, 180] loss: 0.622\n",
      "[19, 240] loss: 0.629\n",
      "[19, 300] loss: 0.596\n",
      "[19, 360] loss: 0.604\n",
      "Epoch: 19 -> Loss: 0.538467049599\n",
      "Epoch: 19 -> Test Accuracy: 78.47\n",
      "[20, 60] loss: 0.594\n",
      "[20, 120] loss: 0.590\n",
      "[20, 180] loss: 0.610\n",
      "[20, 240] loss: 0.614\n",
      "[20, 300] loss: 0.621\n",
      "[20, 360] loss: 0.620\n",
      "Epoch: 20 -> Loss: 0.848935604095\n",
      "Epoch: 20 -> Test Accuracy: 77.97\n",
      "[21, 60] loss: 0.558\n",
      "[21, 120] loss: 0.508\n",
      "[21, 180] loss: 0.515\n",
      "[21, 240] loss: 0.506\n",
      "[21, 300] loss: 0.488\n",
      "[21, 360] loss: 0.485\n",
      "Epoch: 21 -> Loss: 0.489307463169\n",
      "Epoch: 21 -> Test Accuracy: 80.26\n",
      "[22, 60] loss: 0.482\n",
      "[22, 120] loss: 0.453\n",
      "[22, 180] loss: 0.482\n",
      "[22, 240] loss: 0.458\n",
      "[22, 300] loss: 0.451\n",
      "[22, 360] loss: 0.482\n",
      "Epoch: 22 -> Loss: 0.583063423634\n",
      "Epoch: 22 -> Test Accuracy: 80.78\n",
      "[23, 60] loss: 0.460\n",
      "[23, 120] loss: 0.452\n",
      "[23, 180] loss: 0.446\n",
      "[23, 240] loss: 0.453\n",
      "[23, 300] loss: 0.458\n",
      "[23, 360] loss: 0.450\n",
      "Epoch: 23 -> Loss: 0.450862169266\n",
      "Epoch: 23 -> Test Accuracy: 80.95\n",
      "[24, 60] loss: 0.434\n",
      "[24, 120] loss: 0.433\n",
      "[24, 180] loss: 0.458\n",
      "[24, 240] loss: 0.419\n",
      "[24, 300] loss: 0.439\n",
      "[24, 360] loss: 0.428\n",
      "Epoch: 24 -> Loss: 0.648427069187\n",
      "Epoch: 24 -> Test Accuracy: 81.22\n",
      "[25, 60] loss: 0.419\n",
      "[25, 120] loss: 0.446\n",
      "[25, 180] loss: 0.434\n",
      "[25, 240] loss: 0.441\n",
      "[25, 300] loss: 0.437\n",
      "[25, 360] loss: 0.422\n",
      "Epoch: 25 -> Loss: 0.545889735222\n",
      "Epoch: 25 -> Test Accuracy: 81.47\n",
      "[26, 60] loss: 0.418\n",
      "[26, 120] loss: 0.416\n",
      "[26, 180] loss: 0.430\n",
      "[26, 240] loss: 0.431\n",
      "[26, 300] loss: 0.419\n",
      "[26, 360] loss: 0.427\n",
      "Epoch: 26 -> Loss: 0.498003721237\n",
      "Epoch: 26 -> Test Accuracy: 81.69\n",
      "[27, 60] loss: 0.406\n",
      "[27, 120] loss: 0.415\n",
      "[27, 180] loss: 0.409\n",
      "[27, 240] loss: 0.422\n",
      "[27, 300] loss: 0.406\n",
      "[27, 360] loss: 0.416\n",
      "Epoch: 27 -> Loss: 0.471094995737\n",
      "Epoch: 27 -> Test Accuracy: 81.66\n",
      "[28, 60] loss: 0.382\n",
      "[28, 120] loss: 0.429\n",
      "[28, 180] loss: 0.410\n",
      "[28, 240] loss: 0.409\n",
      "[28, 300] loss: 0.421\n",
      "[28, 360] loss: 0.423\n",
      "Epoch: 28 -> Loss: 0.431448370218\n",
      "Epoch: 28 -> Test Accuracy: 81.38\n",
      "[29, 60] loss: 0.394\n",
      "[29, 120] loss: 0.405\n",
      "[29, 180] loss: 0.402\n",
      "[29, 240] loss: 0.401\n",
      "[29, 300] loss: 0.416\n",
      "[29, 360] loss: 0.409\n",
      "Epoch: 29 -> Loss: 0.429306924343\n",
      "Epoch: 29 -> Test Accuracy: 81.26\n",
      "[30, 60] loss: 0.399\n",
      "[30, 120] loss: 0.391\n",
      "[30, 180] loss: 0.403\n",
      "[30, 240] loss: 0.419\n",
      "[30, 300] loss: 0.411\n",
      "[30, 360] loss: 0.407\n",
      "Epoch: 30 -> Loss: 0.501202940941\n",
      "Epoch: 30 -> Test Accuracy: 81.26\n",
      "[31, 60] loss: 0.386\n",
      "[31, 120] loss: 0.390\n",
      "[31, 180] loss: 0.417\n",
      "[31, 240] loss: 0.392\n",
      "[31, 300] loss: 0.419\n",
      "[31, 360] loss: 0.409\n",
      "Epoch: 31 -> Loss: 0.398540556431\n",
      "Epoch: 31 -> Test Accuracy: 81.4\n",
      "[32, 60] loss: 0.388\n",
      "[32, 120] loss: 0.400\n",
      "[32, 180] loss: 0.391\n",
      "[32, 240] loss: 0.409\n",
      "[32, 300] loss: 0.414\n",
      "[32, 360] loss: 0.406\n",
      "Epoch: 32 -> Loss: 0.476649522781\n",
      "Epoch: 32 -> Test Accuracy: 81.64\n",
      "[33, 60] loss: 0.384\n",
      "[33, 120] loss: 0.400\n",
      "[33, 180] loss: 0.399\n",
      "[33, 240] loss: 0.395\n",
      "[33, 300] loss: 0.399\n",
      "[33, 360] loss: 0.404\n",
      "Epoch: 33 -> Loss: 0.363890230656\n",
      "Epoch: 33 -> Test Accuracy: 81.31\n",
      "[34, 60] loss: 0.383\n",
      "[34, 120] loss: 0.381\n",
      "[34, 180] loss: 0.370\n",
      "[34, 240] loss: 0.393\n",
      "[34, 300] loss: 0.419\n",
      "[34, 360] loss: 0.424\n",
      "Epoch: 34 -> Loss: 0.536001622677\n",
      "Epoch: 34 -> Test Accuracy: 81.54\n",
      "[35, 60] loss: 0.381\n",
      "[35, 120] loss: 0.381\n",
      "[35, 180] loss: 0.393\n",
      "[35, 240] loss: 0.405\n",
      "[35, 300] loss: 0.418\n",
      "[35, 360] loss: 0.411\n",
      "Epoch: 35 -> Loss: 0.492414653301\n",
      "Epoch: 35 -> Test Accuracy: 81.39\n",
      "[36, 60] loss: 0.384\n",
      "[36, 120] loss: 0.386\n",
      "[36, 180] loss: 0.395\n",
      "[36, 240] loss: 0.389\n",
      "[36, 300] loss: 0.391\n",
      "[36, 360] loss: 0.399\n",
      "Epoch: 36 -> Loss: 0.306403487921\n",
      "Epoch: 36 -> Test Accuracy: 81.57\n",
      "[37, 60] loss: 0.385\n",
      "[37, 120] loss: 0.383\n",
      "[37, 180] loss: 0.413\n",
      "[37, 240] loss: 0.394\n",
      "[37, 300] loss: 0.409\n",
      "[37, 360] loss: 0.404\n",
      "Epoch: 37 -> Loss: 0.580520272255\n",
      "Epoch: 37 -> Test Accuracy: 81.12\n",
      "[38, 60] loss: 0.386\n",
      "[38, 120] loss: 0.396\n",
      "[38, 180] loss: 0.394\n",
      "[38, 240] loss: 0.374\n",
      "[38, 300] loss: 0.405\n",
      "[38, 360] loss: 0.400\n",
      "Epoch: 38 -> Loss: 0.546226918697\n",
      "Epoch: 38 -> Test Accuracy: 81.31\n",
      "[39, 60] loss: 0.378\n",
      "[39, 120] loss: 0.384\n",
      "[39, 180] loss: 0.388\n",
      "[39, 240] loss: 0.378\n",
      "[39, 300] loss: 0.378\n",
      "[39, 360] loss: 0.406\n",
      "Epoch: 39 -> Loss: 0.546420395374\n",
      "Epoch: 39 -> Test Accuracy: 81.4\n",
      "[40, 60] loss: 0.391\n",
      "[40, 120] loss: 0.396\n",
      "[40, 180] loss: 0.393\n",
      "[40, 240] loss: 0.397\n",
      "[40, 300] loss: 0.391\n",
      "[40, 360] loss: 0.395\n",
      "Epoch: 40 -> Loss: 0.572333931923\n",
      "Epoch: 40 -> Test Accuracy: 81.55\n",
      "[41, 60] loss: 0.351\n",
      "[41, 120] loss: 0.351\n",
      "[41, 180] loss: 0.338\n",
      "[41, 240] loss: 0.356\n",
      "[41, 300] loss: 0.352\n",
      "[41, 360] loss: 0.337\n",
      "Epoch: 41 -> Loss: 0.272331386805\n",
      "Epoch: 41 -> Test Accuracy: 82.52\n",
      "[42, 60] loss: 0.339\n",
      "[42, 120] loss: 0.326\n",
      "[42, 180] loss: 0.313\n",
      "[42, 240] loss: 0.316\n",
      "[42, 300] loss: 0.323\n",
      "[42, 360] loss: 0.321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.201099067926\n",
      "Epoch: 42 -> Test Accuracy: 82.4\n",
      "[43, 60] loss: 0.331\n",
      "[43, 120] loss: 0.310\n",
      "[43, 180] loss: 0.319\n",
      "[43, 240] loss: 0.315\n",
      "[43, 300] loss: 0.312\n",
      "[43, 360] loss: 0.317\n",
      "Epoch: 43 -> Loss: 0.307905286551\n",
      "Epoch: 43 -> Test Accuracy: 82.69\n",
      "[44, 60] loss: 0.312\n",
      "[44, 120] loss: 0.300\n",
      "[44, 180] loss: 0.306\n",
      "[44, 240] loss: 0.309\n",
      "[44, 300] loss: 0.298\n",
      "[44, 360] loss: 0.309\n",
      "Epoch: 44 -> Loss: 0.371604979038\n",
      "Epoch: 44 -> Test Accuracy: 82.74\n",
      "[45, 60] loss: 0.303\n",
      "[45, 120] loss: 0.297\n",
      "[45, 180] loss: 0.297\n",
      "[45, 240] loss: 0.295\n",
      "[45, 300] loss: 0.310\n",
      "[45, 360] loss: 0.315\n",
      "Epoch: 45 -> Loss: 0.396926254034\n",
      "Epoch: 45 -> Test Accuracy: 82.61\n",
      "[46, 60] loss: 0.288\n",
      "[46, 120] loss: 0.295\n",
      "[46, 180] loss: 0.273\n",
      "[46, 240] loss: 0.288\n",
      "[46, 300] loss: 0.293\n",
      "[46, 360] loss: 0.291\n",
      "Epoch: 46 -> Loss: 0.280866056681\n",
      "Epoch: 46 -> Test Accuracy: 82.7\n",
      "[47, 60] loss: 0.283\n",
      "[47, 120] loss: 0.296\n",
      "[47, 180] loss: 0.297\n",
      "[47, 240] loss: 0.280\n",
      "[47, 300] loss: 0.288\n",
      "[47, 360] loss: 0.273\n",
      "Epoch: 47 -> Loss: 0.254033207893\n",
      "Epoch: 47 -> Test Accuracy: 82.89\n",
      "[48, 60] loss: 0.282\n",
      "[48, 120] loss: 0.286\n",
      "[48, 180] loss: 0.289\n",
      "[48, 240] loss: 0.293\n",
      "[48, 300] loss: 0.286\n",
      "[48, 360] loss: 0.284\n",
      "Epoch: 48 -> Loss: 0.292679101229\n",
      "Epoch: 48 -> Test Accuracy: 82.79\n",
      "[49, 60] loss: 0.284\n",
      "[49, 120] loss: 0.277\n",
      "[49, 180] loss: 0.295\n",
      "[49, 240] loss: 0.271\n",
      "[49, 300] loss: 0.280\n",
      "[49, 360] loss: 0.287\n",
      "Epoch: 49 -> Loss: 0.294432789087\n",
      "Epoch: 49 -> Test Accuracy: 82.83\n",
      "[50, 60] loss: 0.279\n",
      "[50, 120] loss: 0.274\n",
      "[50, 180] loss: 0.285\n",
      "[50, 240] loss: 0.280\n",
      "[50, 300] loss: 0.275\n",
      "[50, 360] loss: 0.286\n",
      "Epoch: 50 -> Loss: 0.268331855536\n",
      "Epoch: 50 -> Test Accuracy: 82.83\n",
      "[51, 60] loss: 0.275\n",
      "[51, 120] loss: 0.277\n",
      "[51, 180] loss: 0.281\n",
      "[51, 240] loss: 0.269\n",
      "[51, 300] loss: 0.280\n",
      "[51, 360] loss: 0.277\n",
      "Epoch: 51 -> Loss: 0.292641580105\n",
      "Epoch: 51 -> Test Accuracy: 82.84\n",
      "[52, 60] loss: 0.282\n",
      "[52, 120] loss: 0.273\n",
      "[52, 180] loss: 0.270\n",
      "[52, 240] loss: 0.272\n",
      "[52, 300] loss: 0.270\n",
      "[52, 360] loss: 0.283\n",
      "Epoch: 52 -> Loss: 0.298257708549\n",
      "Epoch: 52 -> Test Accuracy: 82.83\n",
      "[53, 60] loss: 0.281\n",
      "[53, 120] loss: 0.266\n",
      "[53, 180] loss: 0.274\n",
      "[53, 240] loss: 0.284\n",
      "[53, 300] loss: 0.276\n",
      "[53, 360] loss: 0.292\n",
      "Epoch: 53 -> Loss: 0.23089209199\n",
      "Epoch: 53 -> Test Accuracy: 82.69\n",
      "[54, 60] loss: 0.283\n",
      "[54, 120] loss: 0.277\n",
      "[54, 180] loss: 0.273\n",
      "[54, 240] loss: 0.281\n",
      "[54, 300] loss: 0.274\n",
      "[54, 360] loss: 0.267\n",
      "Epoch: 54 -> Loss: 0.422213315964\n",
      "Epoch: 54 -> Test Accuracy: 82.78\n",
      "[55, 60] loss: 0.258\n",
      "[55, 120] loss: 0.282\n",
      "[55, 180] loss: 0.269\n",
      "[55, 240] loss: 0.283\n",
      "[55, 300] loss: 0.273\n",
      "[55, 360] loss: 0.271\n",
      "Epoch: 55 -> Loss: 0.345101833344\n",
      "Epoch: 55 -> Test Accuracy: 82.89\n",
      "[56, 60] loss: 0.274\n",
      "[56, 120] loss: 0.275\n",
      "[56, 180] loss: 0.276\n",
      "[56, 240] loss: 0.271\n",
      "[56, 300] loss: 0.262\n",
      "[56, 360] loss: 0.256\n",
      "Epoch: 56 -> Loss: 0.268840789795\n",
      "Epoch: 56 -> Test Accuracy: 82.89\n",
      "[57, 60] loss: 0.278\n",
      "[57, 120] loss: 0.261\n",
      "[57, 180] loss: 0.262\n",
      "[57, 240] loss: 0.270\n",
      "[57, 300] loss: 0.276\n",
      "[57, 360] loss: 0.272\n",
      "Epoch: 57 -> Loss: 0.286349713802\n",
      "Epoch: 57 -> Test Accuracy: 82.86\n",
      "[58, 60] loss: 0.259\n",
      "[58, 120] loss: 0.276\n",
      "[58, 180] loss: 0.268\n",
      "[58, 240] loss: 0.275\n",
      "[58, 300] loss: 0.267\n",
      "[58, 360] loss: 0.266\n",
      "Epoch: 58 -> Loss: 0.266431182623\n",
      "Epoch: 58 -> Test Accuracy: 82.98\n",
      "[59, 60] loss: 0.277\n",
      "[59, 120] loss: 0.265\n",
      "[59, 180] loss: 0.270\n",
      "[59, 240] loss: 0.275\n",
      "[59, 300] loss: 0.286\n",
      "[59, 360] loss: 0.268\n",
      "Epoch: 59 -> Loss: 0.226109191775\n",
      "Epoch: 59 -> Test Accuracy: 82.81\n",
      "[60, 60] loss: 0.255\n",
      "[60, 120] loss: 0.272\n",
      "[60, 180] loss: 0.260\n",
      "[60, 240] loss: 0.276\n",
      "[60, 300] loss: 0.259\n",
      "[60, 360] loss: 0.257\n",
      "Epoch: 60 -> Loss: 0.2322178334\n",
      "Epoch: 60 -> Test Accuracy: 82.91\n",
      "[61, 60] loss: 0.266\n",
      "[61, 120] loss: 0.266\n",
      "[61, 180] loss: 0.269\n",
      "[61, 240] loss: 0.277\n",
      "[61, 300] loss: 0.267\n",
      "[61, 360] loss: 0.263\n",
      "Epoch: 61 -> Loss: 0.252795696259\n",
      "Epoch: 61 -> Test Accuracy: 82.82\n",
      "[62, 60] loss: 0.269\n",
      "[62, 120] loss: 0.273\n",
      "[62, 180] loss: 0.257\n",
      "[62, 240] loss: 0.257\n",
      "[62, 300] loss: 0.275\n",
      "[62, 360] loss: 0.262\n",
      "Epoch: 62 -> Loss: 0.236779168248\n",
      "Epoch: 62 -> Test Accuracy: 82.8\n",
      "[63, 60] loss: 0.254\n",
      "[63, 120] loss: 0.265\n",
      "[63, 180] loss: 0.257\n",
      "[63, 240] loss: 0.263\n",
      "[63, 300] loss: 0.273\n",
      "[63, 360] loss: 0.262\n",
      "Epoch: 63 -> Loss: 0.272689342499\n",
      "Epoch: 63 -> Test Accuracy: 82.69\n",
      "[64, 60] loss: 0.255\n",
      "[64, 120] loss: 0.263\n",
      "[64, 180] loss: 0.257\n",
      "[64, 240] loss: 0.272\n",
      "[64, 300] loss: 0.266\n",
      "[64, 360] loss: 0.260\n",
      "Epoch: 64 -> Loss: 0.170917749405\n",
      "Epoch: 64 -> Test Accuracy: 82.7\n",
      "[65, 60] loss: 0.275\n",
      "[65, 120] loss: 0.259\n",
      "[65, 180] loss: 0.258\n",
      "[65, 240] loss: 0.251\n",
      "[65, 300] loss: 0.255\n",
      "[65, 360] loss: 0.272\n",
      "Epoch: 65 -> Loss: 0.304179757833\n",
      "Epoch: 65 -> Test Accuracy: 82.74\n",
      "[66, 60] loss: 0.272\n",
      "[66, 120] loss: 0.252\n",
      "[66, 180] loss: 0.264\n",
      "[66, 240] loss: 0.257\n",
      "[66, 300] loss: 0.265\n",
      "[66, 360] loss: 0.266\n",
      "Epoch: 66 -> Loss: 0.271833568811\n",
      "Epoch: 66 -> Test Accuracy: 82.84\n",
      "[67, 60] loss: 0.264\n",
      "[67, 120] loss: 0.253\n",
      "[67, 180] loss: 0.248\n",
      "[67, 240] loss: 0.263\n",
      "[67, 300] loss: 0.257\n",
      "[67, 360] loss: 0.257\n",
      "Epoch: 67 -> Loss: 0.432079225779\n",
      "Epoch: 67 -> Test Accuracy: 82.74\n",
      "[68, 60] loss: 0.256\n",
      "[68, 120] loss: 0.255\n",
      "[68, 180] loss: 0.265\n",
      "[68, 240] loss: 0.259\n",
      "[68, 300] loss: 0.273\n",
      "[68, 360] loss: 0.257\n",
      "Epoch: 68 -> Loss: 0.220080420375\n",
      "Epoch: 68 -> Test Accuracy: 82.78\n",
      "[69, 60] loss: 0.252\n",
      "[69, 120] loss: 0.257\n",
      "[69, 180] loss: 0.258\n",
      "[69, 240] loss: 0.266\n",
      "[69, 300] loss: 0.265\n",
      "[69, 360] loss: 0.253\n",
      "Epoch: 69 -> Loss: 0.345343649387\n",
      "Epoch: 69 -> Test Accuracy: 82.66\n",
      "[70, 60] loss: 0.255\n",
      "[70, 120] loss: 0.255\n",
      "[70, 180] loss: 0.265\n",
      "[70, 240] loss: 0.261\n",
      "[70, 300] loss: 0.266\n",
      "[70, 360] loss: 0.258\n",
      "Epoch: 70 -> Loss: 0.211267799139\n",
      "Epoch: 70 -> Test Accuracy: 82.67\n",
      "[71, 60] loss: 0.246\n",
      "[71, 120] loss: 0.258\n",
      "[71, 180] loss: 0.260\n",
      "[71, 240] loss: 0.247\n",
      "[71, 300] loss: 0.265\n",
      "[71, 360] loss: 0.253\n",
      "Epoch: 71 -> Loss: 0.331225395203\n",
      "Epoch: 71 -> Test Accuracy: 82.78\n",
      "[72, 60] loss: 0.241\n",
      "[72, 120] loss: 0.258\n",
      "[72, 180] loss: 0.255\n",
      "[72, 240] loss: 0.258\n",
      "[72, 300] loss: 0.249\n",
      "[72, 360] loss: 0.262\n",
      "Epoch: 72 -> Loss: 0.244918107986\n",
      "Epoch: 72 -> Test Accuracy: 82.62\n",
      "[73, 60] loss: 0.258\n",
      "[73, 120] loss: 0.271\n",
      "[73, 180] loss: 0.239\n",
      "[73, 240] loss: 0.256\n",
      "[73, 300] loss: 0.246\n",
      "[73, 360] loss: 0.253\n",
      "Epoch: 73 -> Loss: 0.141571238637\n",
      "Epoch: 73 -> Test Accuracy: 82.73\n",
      "[74, 60] loss: 0.250\n",
      "[74, 120] loss: 0.255\n",
      "[74, 180] loss: 0.253\n",
      "[74, 240] loss: 0.252\n",
      "[74, 300] loss: 0.259\n",
      "[74, 360] loss: 0.252\n",
      "Epoch: 74 -> Loss: 0.122856304049\n",
      "Epoch: 74 -> Test Accuracy: 82.66\n",
      "[75, 60] loss: 0.236\n",
      "[75, 120] loss: 0.243\n",
      "[75, 180] loss: 0.260\n",
      "[75, 240] loss: 0.247\n",
      "[75, 300] loss: 0.253\n",
      "[75, 360] loss: 0.242\n",
      "Epoch: 75 -> Loss: 0.209202095866\n",
      "Epoch: 75 -> Test Accuracy: 82.7\n",
      "[76, 60] loss: 0.260\n",
      "[76, 120] loss: 0.236\n",
      "[76, 180] loss: 0.247\n",
      "[76, 240] loss: 0.245\n",
      "[76, 300] loss: 0.248\n",
      "[76, 360] loss: 0.256\n",
      "Epoch: 76 -> Loss: 0.235131695867\n",
      "Epoch: 76 -> Test Accuracy: 82.78\n",
      "[77, 60] loss: 0.251\n",
      "[77, 120] loss: 0.244\n",
      "[77, 180] loss: 0.245\n",
      "[77, 240] loss: 0.253\n",
      "[77, 300] loss: 0.251\n",
      "[77, 360] loss: 0.246\n",
      "Epoch: 77 -> Loss: 0.287729203701\n",
      "Epoch: 77 -> Test Accuracy: 82.68\n",
      "[78, 60] loss: 0.251\n",
      "[78, 120] loss: 0.259\n",
      "[78, 180] loss: 0.253\n",
      "[78, 240] loss: 0.253\n",
      "[78, 300] loss: 0.242\n",
      "[78, 360] loss: 0.237\n",
      "Epoch: 78 -> Loss: 0.297220855951\n",
      "Epoch: 78 -> Test Accuracy: 82.78\n",
      "[79, 60] loss: 0.233\n",
      "[79, 120] loss: 0.243\n",
      "[79, 180] loss: 0.238\n",
      "[79, 240] loss: 0.253\n",
      "[79, 300] loss: 0.240\n",
      "[79, 360] loss: 0.253\n",
      "Epoch: 79 -> Loss: 0.310676425695\n",
      "Epoch: 79 -> Test Accuracy: 82.78\n",
      "[80, 60] loss: 0.260\n",
      "[80, 120] loss: 0.235\n",
      "[80, 180] loss: 0.233\n",
      "[80, 240] loss: 0.248\n",
      "[80, 300] loss: 0.247\n",
      "[80, 360] loss: 0.246\n",
      "Epoch: 80 -> Loss: 0.324612855911\n",
      "Epoch: 80 -> Test Accuracy: 82.9\n",
      "[81, 60] loss: 0.244\n",
      "[81, 120] loss: 0.249\n",
      "[81, 180] loss: 0.246\n",
      "[81, 240] loss: 0.246\n",
      "[81, 300] loss: 0.236\n",
      "[81, 360] loss: 0.242\n",
      "Epoch: 81 -> Loss: 0.243226081133\n",
      "Epoch: 81 -> Test Accuracy: 82.68\n",
      "[82, 60] loss: 0.246\n",
      "[82, 120] loss: 0.245\n",
      "[82, 180] loss: 0.243\n",
      "[82, 240] loss: 0.238\n",
      "[82, 300] loss: 0.233\n",
      "[82, 360] loss: 0.265\n",
      "Epoch: 82 -> Loss: 0.251213312149\n",
      "Epoch: 82 -> Test Accuracy: 82.58\n",
      "[83, 60] loss: 0.243\n",
      "[83, 120] loss: 0.233\n",
      "[83, 180] loss: 0.246\n",
      "[83, 240] loss: 0.243\n",
      "[83, 300] loss: 0.245\n",
      "[83, 360] loss: 0.249\n",
      "Epoch: 83 -> Loss: 0.268557965755\n",
      "Epoch: 83 -> Test Accuracy: 82.69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.245\n",
      "[84, 120] loss: 0.240\n",
      "[84, 180] loss: 0.246\n",
      "[84, 240] loss: 0.237\n",
      "[84, 300] loss: 0.240\n",
      "[84, 360] loss: 0.245\n",
      "Epoch: 84 -> Loss: 0.322443187237\n",
      "Epoch: 84 -> Test Accuracy: 82.71\n",
      "[85, 60] loss: 0.242\n",
      "[85, 120] loss: 0.249\n",
      "[85, 180] loss: 0.241\n",
      "[85, 240] loss: 0.252\n",
      "[85, 300] loss: 0.243\n",
      "[85, 360] loss: 0.227\n",
      "Epoch: 85 -> Loss: 0.196157410741\n",
      "Epoch: 85 -> Test Accuracy: 82.66\n",
      "[86, 60] loss: 0.239\n",
      "[86, 120] loss: 0.238\n",
      "[86, 180] loss: 0.239\n",
      "[86, 240] loss: 0.248\n",
      "[86, 300] loss: 0.239\n",
      "[86, 360] loss: 0.235\n",
      "Epoch: 86 -> Loss: 0.204234689474\n",
      "Epoch: 86 -> Test Accuracy: 82.67\n",
      "[87, 60] loss: 0.231\n",
      "[87, 120] loss: 0.247\n",
      "[87, 180] loss: 0.239\n",
      "[87, 240] loss: 0.235\n",
      "[87, 300] loss: 0.240\n",
      "[87, 360] loss: 0.242\n",
      "Epoch: 87 -> Loss: 0.325607389212\n",
      "Epoch: 87 -> Test Accuracy: 82.73\n",
      "[88, 60] loss: 0.239\n",
      "[88, 120] loss: 0.241\n",
      "[88, 180] loss: 0.244\n",
      "[88, 240] loss: 0.244\n",
      "[88, 300] loss: 0.235\n",
      "[88, 360] loss: 0.242\n",
      "Epoch: 88 -> Loss: 0.138225629926\n",
      "Epoch: 88 -> Test Accuracy: 82.77\n",
      "[89, 60] loss: 0.240\n",
      "[89, 120] loss: 0.238\n",
      "[89, 180] loss: 0.237\n",
      "[89, 240] loss: 0.245\n",
      "[89, 300] loss: 0.243\n",
      "[89, 360] loss: 0.234\n",
      "Epoch: 89 -> Loss: 0.354060471058\n",
      "Epoch: 89 -> Test Accuracy: 82.64\n",
      "[90, 60] loss: 0.241\n",
      "[90, 120] loss: 0.232\n",
      "[90, 180] loss: 0.238\n",
      "[90, 240] loss: 0.233\n",
      "[90, 300] loss: 0.245\n",
      "[90, 360] loss: 0.235\n",
      "Epoch: 90 -> Loss: 0.201234579086\n",
      "Epoch: 90 -> Test Accuracy: 82.64\n",
      "[91, 60] loss: 0.237\n",
      "[91, 120] loss: 0.242\n",
      "[91, 180] loss: 0.250\n",
      "[91, 240] loss: 0.241\n",
      "[91, 300] loss: 0.234\n",
      "[91, 360] loss: 0.226\n",
      "Epoch: 91 -> Loss: 0.236147880554\n",
      "Epoch: 91 -> Test Accuracy: 82.75\n",
      "[92, 60] loss: 0.241\n",
      "[92, 120] loss: 0.242\n",
      "[92, 180] loss: 0.228\n",
      "[92, 240] loss: 0.232\n",
      "[92, 300] loss: 0.241\n",
      "[92, 360] loss: 0.231\n",
      "Epoch: 92 -> Loss: 0.169587552547\n",
      "Epoch: 92 -> Test Accuracy: 82.73\n",
      "[93, 60] loss: 0.237\n",
      "[93, 120] loss: 0.246\n",
      "[93, 180] loss: 0.232\n",
      "[93, 240] loss: 0.250\n",
      "[93, 300] loss: 0.244\n",
      "[93, 360] loss: 0.230\n",
      "Epoch: 93 -> Loss: 0.280930936337\n",
      "Epoch: 93 -> Test Accuracy: 82.64\n",
      "[94, 60] loss: 0.231\n",
      "[94, 120] loss: 0.239\n",
      "[94, 180] loss: 0.250\n",
      "[94, 240] loss: 0.243\n",
      "[94, 300] loss: 0.244\n",
      "[94, 360] loss: 0.236\n",
      "Epoch: 94 -> Loss: 0.227614834905\n",
      "Epoch: 94 -> Test Accuracy: 82.7\n",
      "[95, 60] loss: 0.226\n",
      "[95, 120] loss: 0.233\n",
      "[95, 180] loss: 0.229\n",
      "[95, 240] loss: 0.223\n",
      "[95, 300] loss: 0.242\n",
      "[95, 360] loss: 0.234\n",
      "Epoch: 95 -> Loss: 0.165435105562\n",
      "Epoch: 95 -> Test Accuracy: 82.82\n",
      "[96, 60] loss: 0.231\n",
      "[96, 120] loss: 0.232\n",
      "[96, 180] loss: 0.236\n",
      "[96, 240] loss: 0.223\n",
      "[96, 300] loss: 0.227\n",
      "[96, 360] loss: 0.239\n",
      "Epoch: 96 -> Loss: 0.123778305948\n",
      "Epoch: 96 -> Test Accuracy: 82.8\n",
      "[97, 60] loss: 0.241\n",
      "[97, 120] loss: 0.234\n",
      "[97, 180] loss: 0.227\n",
      "[97, 240] loss: 0.229\n",
      "[97, 300] loss: 0.233\n",
      "[97, 360] loss: 0.229\n",
      "Epoch: 97 -> Loss: 0.231192201376\n",
      "Epoch: 97 -> Test Accuracy: 82.67\n",
      "[98, 60] loss: 0.233\n",
      "[98, 120] loss: 0.239\n",
      "[98, 180] loss: 0.226\n",
      "[98, 240] loss: 0.234\n",
      "[98, 300] loss: 0.223\n",
      "[98, 360] loss: 0.223\n",
      "Epoch: 98 -> Loss: 0.188668206334\n",
      "Epoch: 98 -> Test Accuracy: 82.76\n",
      "[99, 60] loss: 0.229\n",
      "[99, 120] loss: 0.224\n",
      "[99, 180] loss: 0.240\n",
      "[99, 240] loss: 0.238\n",
      "[99, 300] loss: 0.233\n",
      "[99, 360] loss: 0.235\n",
      "Epoch: 99 -> Loss: 0.364156723022\n",
      "Epoch: 99 -> Test Accuracy: 82.71\n",
      "[100, 60] loss: 0.221\n",
      "[100, 120] loss: 0.232\n",
      "[100, 180] loss: 0.232\n",
      "[100, 240] loss: 0.229\n",
      "[100, 300] loss: 0.224\n",
      "[100, 360] loss: 0.243\n",
      "Epoch: 100 -> Loss: 0.249769300222\n",
      "Epoch: 100 -> Test Accuracy: 82.73\n",
      "Finished Training\n",
      "[1, 60] loss: 1.666\n",
      "[1, 120] loss: 0.814\n",
      "[1, 180] loss: 0.757\n",
      "[1, 240] loss: 0.706\n",
      "[1, 300] loss: 0.674\n",
      "[1, 360] loss: 0.666\n",
      "Epoch: 1 -> Loss: 0.5623524189\n",
      "Epoch: 1 -> Test Accuracy: 77.37\n",
      "[2, 60] loss: 0.599\n",
      "[2, 120] loss: 0.575\n",
      "[2, 180] loss: 0.580\n",
      "[2, 240] loss: 0.584\n",
      "[2, 300] loss: 0.558\n",
      "[2, 360] loss: 0.525\n",
      "Epoch: 2 -> Loss: 0.481543838978\n",
      "Epoch: 2 -> Test Accuracy: 79.75\n",
      "[3, 60] loss: 0.512\n",
      "[3, 120] loss: 0.508\n",
      "[3, 180] loss: 0.510\n",
      "[3, 240] loss: 0.528\n",
      "[3, 300] loss: 0.514\n",
      "[3, 360] loss: 0.525\n",
      "Epoch: 3 -> Loss: 0.798101842403\n",
      "Epoch: 3 -> Test Accuracy: 80.55\n",
      "[4, 60] loss: 0.473\n",
      "[4, 120] loss: 0.475\n",
      "[4, 180] loss: 0.482\n",
      "[4, 240] loss: 0.488\n",
      "[4, 300] loss: 0.469\n",
      "[4, 360] loss: 0.496\n",
      "Epoch: 4 -> Loss: 0.605744719505\n",
      "Epoch: 4 -> Test Accuracy: 81.0\n",
      "[5, 60] loss: 0.445\n",
      "[5, 120] loss: 0.447\n",
      "[5, 180] loss: 0.450\n",
      "[5, 240] loss: 0.457\n",
      "[5, 300] loss: 0.455\n",
      "[5, 360] loss: 0.443\n",
      "Epoch: 5 -> Loss: 0.588669300079\n",
      "Epoch: 5 -> Test Accuracy: 82.38\n",
      "[6, 60] loss: 0.443\n",
      "[6, 120] loss: 0.418\n",
      "[6, 180] loss: 0.439\n",
      "[6, 240] loss: 0.438\n",
      "[6, 300] loss: 0.446\n",
      "[6, 360] loss: 0.455\n",
      "Epoch: 6 -> Loss: 0.509273529053\n",
      "Epoch: 6 -> Test Accuracy: 82.12\n",
      "[7, 60] loss: 0.408\n",
      "[7, 120] loss: 0.418\n",
      "[7, 180] loss: 0.436\n",
      "[7, 240] loss: 0.443\n",
      "[7, 300] loss: 0.437\n",
      "[7, 360] loss: 0.434\n",
      "Epoch: 7 -> Loss: 0.532185018063\n",
      "Epoch: 7 -> Test Accuracy: 81.98\n",
      "[8, 60] loss: 0.387\n",
      "[8, 120] loss: 0.417\n",
      "[8, 180] loss: 0.419\n",
      "[8, 240] loss: 0.421\n",
      "[8, 300] loss: 0.429\n",
      "[8, 360] loss: 0.439\n",
      "Epoch: 8 -> Loss: 0.50748950243\n",
      "Epoch: 8 -> Test Accuracy: 82.32\n",
      "[9, 60] loss: 0.390\n",
      "[9, 120] loss: 0.402\n",
      "[9, 180] loss: 0.416\n",
      "[9, 240] loss: 0.416\n",
      "[9, 300] loss: 0.411\n",
      "[9, 360] loss: 0.412\n",
      "Epoch: 9 -> Loss: 0.510656356812\n",
      "Epoch: 9 -> Test Accuracy: 82.62\n",
      "[10, 60] loss: 0.382\n",
      "[10, 120] loss: 0.400\n",
      "[10, 180] loss: 0.400\n",
      "[10, 240] loss: 0.402\n",
      "[10, 300] loss: 0.413\n",
      "[10, 360] loss: 0.427\n",
      "Epoch: 10 -> Loss: 0.272848308086\n",
      "Epoch: 10 -> Test Accuracy: 82.47\n",
      "[11, 60] loss: 0.372\n",
      "[11, 120] loss: 0.378\n",
      "[11, 180] loss: 0.398\n",
      "[11, 240] loss: 0.395\n",
      "[11, 300] loss: 0.409\n",
      "[11, 360] loss: 0.411\n",
      "Epoch: 11 -> Loss: 0.416561424732\n",
      "Epoch: 11 -> Test Accuracy: 82.77\n",
      "[12, 60] loss: 0.382\n",
      "[12, 120] loss: 0.384\n",
      "[12, 180] loss: 0.407\n",
      "[12, 240] loss: 0.386\n",
      "[12, 300] loss: 0.424\n",
      "[12, 360] loss: 0.395\n",
      "Epoch: 12 -> Loss: 0.384766727686\n",
      "Epoch: 12 -> Test Accuracy: 82.93\n",
      "[13, 60] loss: 0.365\n",
      "[13, 120] loss: 0.384\n",
      "[13, 180] loss: 0.388\n",
      "[13, 240] loss: 0.389\n",
      "[13, 300] loss: 0.399\n",
      "[13, 360] loss: 0.401\n",
      "Epoch: 13 -> Loss: 0.306156396866\n",
      "Epoch: 13 -> Test Accuracy: 83.1\n",
      "[14, 60] loss: 0.368\n",
      "[14, 120] loss: 0.375\n",
      "[14, 180] loss: 0.393\n",
      "[14, 240] loss: 0.402\n",
      "[14, 300] loss: 0.390\n",
      "[14, 360] loss: 0.401\n",
      "Epoch: 14 -> Loss: 0.420506805182\n",
      "Epoch: 14 -> Test Accuracy: 82.83\n",
      "[15, 60] loss: 0.357\n",
      "[15, 120] loss: 0.371\n",
      "[15, 180] loss: 0.372\n",
      "[15, 240] loss: 0.374\n",
      "[15, 300] loss: 0.406\n",
      "[15, 360] loss: 0.397\n",
      "Epoch: 15 -> Loss: 0.446647167206\n",
      "Epoch: 15 -> Test Accuracy: 82.9\n",
      "[16, 60] loss: 0.372\n",
      "[16, 120] loss: 0.384\n",
      "[16, 180] loss: 0.388\n",
      "[16, 240] loss: 0.388\n",
      "[16, 300] loss: 0.379\n",
      "[16, 360] loss: 0.373\n",
      "Epoch: 16 -> Loss: 0.423888772726\n",
      "Epoch: 16 -> Test Accuracy: 82.9\n",
      "[17, 60] loss: 0.358\n",
      "[17, 120] loss: 0.378\n",
      "[17, 180] loss: 0.379\n",
      "[17, 240] loss: 0.364\n",
      "[17, 300] loss: 0.380\n",
      "[17, 360] loss: 0.399\n",
      "Epoch: 17 -> Loss: 0.635263800621\n",
      "Epoch: 17 -> Test Accuracy: 82.9\n",
      "[18, 60] loss: 0.355\n",
      "[18, 120] loss: 0.351\n",
      "[18, 180] loss: 0.363\n",
      "[18, 240] loss: 0.384\n",
      "[18, 300] loss: 0.386\n",
      "[18, 360] loss: 0.380\n",
      "Epoch: 18 -> Loss: 0.524244725704\n",
      "Epoch: 18 -> Test Accuracy: 82.31\n",
      "[19, 60] loss: 0.348\n",
      "[19, 120] loss: 0.365\n",
      "[19, 180] loss: 0.375\n",
      "[19, 240] loss: 0.386\n",
      "[19, 300] loss: 0.366\n",
      "[19, 360] loss: 0.384\n",
      "Epoch: 19 -> Loss: 0.282057583332\n",
      "Epoch: 19 -> Test Accuracy: 82.95\n",
      "[20, 60] loss: 0.357\n",
      "[20, 120] loss: 0.353\n",
      "[20, 180] loss: 0.375\n",
      "[20, 240] loss: 0.388\n",
      "[20, 300] loss: 0.376\n",
      "[20, 360] loss: 0.393\n",
      "Epoch: 20 -> Loss: 0.304179668427\n",
      "Epoch: 20 -> Test Accuracy: 83.3\n",
      "[21, 60] loss: 0.329\n",
      "[21, 120] loss: 0.299\n",
      "[21, 180] loss: 0.314\n",
      "[21, 240] loss: 0.285\n",
      "[21, 300] loss: 0.276\n",
      "[21, 360] loss: 0.291\n",
      "Epoch: 21 -> Loss: 0.233612373471\n",
      "Epoch: 21 -> Test Accuracy: 85.0\n",
      "[22, 60] loss: 0.260\n",
      "[22, 120] loss: 0.268\n",
      "[22, 180] loss: 0.263\n",
      "[22, 240] loss: 0.257\n",
      "[22, 300] loss: 0.257\n",
      "[22, 360] loss: 0.270\n",
      "Epoch: 22 -> Loss: 0.312090963125\n",
      "Epoch: 22 -> Test Accuracy: 84.94\n",
      "[23, 60] loss: 0.241\n",
      "[23, 120] loss: 0.250\n",
      "[23, 180] loss: 0.241\n",
      "[23, 240] loss: 0.250\n",
      "[23, 300] loss: 0.255\n",
      "[23, 360] loss: 0.246\n",
      "Epoch: 23 -> Loss: 0.217968255281\n",
      "Epoch: 23 -> Test Accuracy: 85.24\n",
      "[24, 60] loss: 0.231\n",
      "[24, 120] loss: 0.229\n",
      "[24, 180] loss: 0.229\n",
      "[24, 240] loss: 0.234\n",
      "[24, 300] loss: 0.228\n",
      "[24, 360] loss: 0.243\n",
      "Epoch: 24 -> Loss: 0.238859698176\n",
      "Epoch: 24 -> Test Accuracy: 85.08\n",
      "[25, 60] loss: 0.219\n",
      "[25, 120] loss: 0.219\n",
      "[25, 180] loss: 0.221\n",
      "[25, 240] loss: 0.226\n",
      "[25, 300] loss: 0.232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 360] loss: 0.222\n",
      "Epoch: 25 -> Loss: 0.26879543066\n",
      "Epoch: 25 -> Test Accuracy: 85.06\n",
      "[26, 60] loss: 0.209\n",
      "[26, 120] loss: 0.226\n",
      "[26, 180] loss: 0.206\n",
      "[26, 240] loss: 0.213\n",
      "[26, 300] loss: 0.221\n",
      "[26, 360] loss: 0.232\n",
      "Epoch: 26 -> Loss: 0.196099326015\n",
      "Epoch: 26 -> Test Accuracy: 85.03\n",
      "[27, 60] loss: 0.198\n",
      "[27, 120] loss: 0.213\n",
      "[27, 180] loss: 0.212\n",
      "[27, 240] loss: 0.207\n",
      "[27, 300] loss: 0.211\n",
      "[27, 360] loss: 0.213\n",
      "Epoch: 27 -> Loss: 0.232765719295\n",
      "Epoch: 27 -> Test Accuracy: 85.08\n",
      "[28, 60] loss: 0.197\n",
      "[28, 120] loss: 0.196\n",
      "[28, 180] loss: 0.206\n",
      "[28, 240] loss: 0.219\n",
      "[28, 300] loss: 0.209\n",
      "[28, 360] loss: 0.215\n",
      "Epoch: 28 -> Loss: 0.136992484331\n",
      "Epoch: 28 -> Test Accuracy: 85.07\n",
      "[29, 60] loss: 0.208\n",
      "[29, 120] loss: 0.212\n",
      "[29, 180] loss: 0.207\n",
      "[29, 240] loss: 0.214\n",
      "[29, 300] loss: 0.207\n",
      "[29, 360] loss: 0.208\n",
      "Epoch: 29 -> Loss: 0.233009338379\n",
      "Epoch: 29 -> Test Accuracy: 85.23\n",
      "[30, 60] loss: 0.196\n",
      "[30, 120] loss: 0.187\n",
      "[30, 180] loss: 0.211\n",
      "[30, 240] loss: 0.216\n",
      "[30, 300] loss: 0.202\n",
      "[30, 360] loss: 0.215\n",
      "Epoch: 30 -> Loss: 0.287630558014\n",
      "Epoch: 30 -> Test Accuracy: 84.68\n",
      "[31, 60] loss: 0.192\n",
      "[31, 120] loss: 0.186\n",
      "[31, 180] loss: 0.206\n",
      "[31, 240] loss: 0.212\n",
      "[31, 300] loss: 0.203\n",
      "[31, 360] loss: 0.216\n",
      "Epoch: 31 -> Loss: 0.371188461781\n",
      "Epoch: 31 -> Test Accuracy: 85.15\n",
      "[32, 60] loss: 0.199\n",
      "[32, 120] loss: 0.195\n",
      "[32, 180] loss: 0.197\n",
      "[32, 240] loss: 0.210\n",
      "[32, 300] loss: 0.209\n",
      "[32, 360] loss: 0.220\n",
      "Epoch: 32 -> Loss: 0.158961459994\n",
      "Epoch: 32 -> Test Accuracy: 84.94\n",
      "[33, 60] loss: 0.181\n",
      "[33, 120] loss: 0.204\n",
      "[33, 180] loss: 0.191\n",
      "[33, 240] loss: 0.196\n",
      "[33, 300] loss: 0.213\n",
      "[33, 360] loss: 0.201\n",
      "Epoch: 33 -> Loss: 0.199587866664\n",
      "Epoch: 33 -> Test Accuracy: 84.81\n",
      "[34, 60] loss: 0.194\n",
      "[34, 120] loss: 0.194\n",
      "[34, 180] loss: 0.201\n",
      "[34, 240] loss: 0.198\n",
      "[34, 300] loss: 0.213\n",
      "[34, 360] loss: 0.216\n",
      "Epoch: 34 -> Loss: 0.257516592741\n",
      "Epoch: 34 -> Test Accuracy: 84.86\n",
      "[35, 60] loss: 0.202\n",
      "[35, 120] loss: 0.192\n",
      "[35, 180] loss: 0.202\n",
      "[35, 240] loss: 0.201\n",
      "[35, 300] loss: 0.209\n",
      "[35, 360] loss: 0.201\n",
      "Epoch: 35 -> Loss: 0.0968106463552\n",
      "Epoch: 35 -> Test Accuracy: 84.69\n",
      "[36, 60] loss: 0.184\n",
      "[36, 120] loss: 0.190\n",
      "[36, 180] loss: 0.196\n",
      "[36, 240] loss: 0.193\n",
      "[36, 300] loss: 0.207\n",
      "[36, 360] loss: 0.204\n",
      "Epoch: 36 -> Loss: 0.192451283336\n",
      "Epoch: 36 -> Test Accuracy: 84.66\n",
      "[37, 60] loss: 0.182\n",
      "[37, 120] loss: 0.179\n",
      "[37, 180] loss: 0.203\n",
      "[37, 240] loss: 0.189\n",
      "[37, 300] loss: 0.213\n",
      "[37, 360] loss: 0.201\n",
      "Epoch: 37 -> Loss: 0.326590329409\n",
      "Epoch: 37 -> Test Accuracy: 84.12\n",
      "[38, 60] loss: 0.185\n",
      "[38, 120] loss: 0.188\n",
      "[38, 180] loss: 0.201\n",
      "[38, 240] loss: 0.194\n",
      "[38, 300] loss: 0.191\n",
      "[38, 360] loss: 0.208\n",
      "Epoch: 38 -> Loss: 0.354185014963\n",
      "Epoch: 38 -> Test Accuracy: 84.52\n",
      "[39, 60] loss: 0.187\n",
      "[39, 120] loss: 0.192\n",
      "[39, 180] loss: 0.192\n",
      "[39, 240] loss: 0.192\n",
      "[39, 300] loss: 0.202\n",
      "[39, 360] loss: 0.207\n",
      "Epoch: 39 -> Loss: 0.214156314731\n",
      "Epoch: 39 -> Test Accuracy: 84.41\n",
      "[40, 60] loss: 0.185\n",
      "[40, 120] loss: 0.183\n",
      "[40, 180] loss: 0.200\n",
      "[40, 240] loss: 0.205\n",
      "[40, 300] loss: 0.197\n",
      "[40, 360] loss: 0.201\n",
      "Epoch: 40 -> Loss: 0.146930173039\n",
      "Epoch: 40 -> Test Accuracy: 84.33\n",
      "[41, 60] loss: 0.185\n",
      "[41, 120] loss: 0.176\n",
      "[41, 180] loss: 0.154\n",
      "[41, 240] loss: 0.164\n",
      "[41, 300] loss: 0.157\n",
      "[41, 360] loss: 0.155\n",
      "Epoch: 41 -> Loss: 0.181046515703\n",
      "Epoch: 41 -> Test Accuracy: 85.24\n",
      "[42, 60] loss: 0.145\n",
      "[42, 120] loss: 0.149\n",
      "[42, 180] loss: 0.139\n",
      "[42, 240] loss: 0.148\n",
      "[42, 300] loss: 0.147\n",
      "[42, 360] loss: 0.142\n",
      "Epoch: 42 -> Loss: 0.147478714585\n",
      "Epoch: 42 -> Test Accuracy: 85.39\n",
      "[43, 60] loss: 0.145\n",
      "[43, 120] loss: 0.128\n",
      "[43, 180] loss: 0.128\n",
      "[43, 240] loss: 0.137\n",
      "[43, 300] loss: 0.138\n",
      "[43, 360] loss: 0.132\n",
      "Epoch: 43 -> Loss: 0.0616746544838\n",
      "Epoch: 43 -> Test Accuracy: 85.53\n",
      "[44, 60] loss: 0.127\n",
      "[44, 120] loss: 0.133\n",
      "[44, 180] loss: 0.135\n",
      "[44, 240] loss: 0.123\n",
      "[44, 300] loss: 0.138\n",
      "[44, 360] loss: 0.123\n",
      "Epoch: 44 -> Loss: 0.17763236165\n",
      "Epoch: 44 -> Test Accuracy: 85.55\n",
      "[45, 60] loss: 0.126\n",
      "[45, 120] loss: 0.130\n",
      "[45, 180] loss: 0.117\n",
      "[45, 240] loss: 0.130\n",
      "[45, 300] loss: 0.128\n",
      "[45, 360] loss: 0.125\n",
      "Epoch: 45 -> Loss: 0.252658903599\n",
      "Epoch: 45 -> Test Accuracy: 85.42\n",
      "[46, 60] loss: 0.113\n",
      "[46, 120] loss: 0.117\n",
      "[46, 180] loss: 0.125\n",
      "[46, 240] loss: 0.113\n",
      "[46, 300] loss: 0.117\n",
      "[46, 360] loss: 0.115\n",
      "Epoch: 46 -> Loss: 0.0646785870194\n",
      "Epoch: 46 -> Test Accuracy: 85.65\n",
      "[47, 60] loss: 0.116\n",
      "[47, 120] loss: 0.104\n",
      "[47, 180] loss: 0.108\n",
      "[47, 240] loss: 0.120\n",
      "[47, 300] loss: 0.117\n",
      "[47, 360] loss: 0.117\n",
      "Epoch: 47 -> Loss: 0.118232771754\n",
      "Epoch: 47 -> Test Accuracy: 85.71\n",
      "[48, 60] loss: 0.118\n",
      "[48, 120] loss: 0.118\n",
      "[48, 180] loss: 0.107\n",
      "[48, 240] loss: 0.114\n",
      "[48, 300] loss: 0.120\n",
      "[48, 360] loss: 0.115\n",
      "Epoch: 48 -> Loss: 0.0540181398392\n",
      "Epoch: 48 -> Test Accuracy: 85.68\n",
      "[49, 60] loss: 0.103\n",
      "[49, 120] loss: 0.115\n",
      "[49, 180] loss: 0.110\n",
      "[49, 240] loss: 0.122\n",
      "[49, 300] loss: 0.108\n",
      "[49, 360] loss: 0.121\n",
      "Epoch: 49 -> Loss: 0.0805462747812\n",
      "Epoch: 49 -> Test Accuracy: 85.7\n",
      "[50, 60] loss: 0.117\n",
      "[50, 120] loss: 0.107\n",
      "[50, 180] loss: 0.111\n",
      "[50, 240] loss: 0.107\n",
      "[50, 300] loss: 0.108\n",
      "[50, 360] loss: 0.108\n",
      "Epoch: 50 -> Loss: 0.0452306456864\n",
      "Epoch: 50 -> Test Accuracy: 85.68\n",
      "[51, 60] loss: 0.119\n",
      "[51, 120] loss: 0.107\n",
      "[51, 180] loss: 0.109\n",
      "[51, 240] loss: 0.108\n",
      "[51, 300] loss: 0.111\n",
      "[51, 360] loss: 0.115\n",
      "Epoch: 51 -> Loss: 0.0287436544895\n",
      "Epoch: 51 -> Test Accuracy: 85.59\n",
      "[52, 60] loss: 0.111\n",
      "[52, 120] loss: 0.107\n",
      "[52, 180] loss: 0.108\n",
      "[52, 240] loss: 0.114\n",
      "[52, 300] loss: 0.111\n",
      "[52, 360] loss: 0.111\n",
      "Epoch: 52 -> Loss: 0.220405578613\n",
      "Epoch: 52 -> Test Accuracy: 85.86\n",
      "[53, 60] loss: 0.109\n",
      "[53, 120] loss: 0.116\n",
      "[53, 180] loss: 0.105\n",
      "[53, 240] loss: 0.112\n",
      "[53, 300] loss: 0.106\n",
      "[53, 360] loss: 0.107\n",
      "Epoch: 53 -> Loss: 0.0808168500662\n",
      "Epoch: 53 -> Test Accuracy: 85.63\n",
      "[54, 60] loss: 0.103\n",
      "[54, 120] loss: 0.104\n",
      "[54, 180] loss: 0.108\n",
      "[54, 240] loss: 0.099\n",
      "[54, 300] loss: 0.106\n",
      "[54, 360] loss: 0.106\n",
      "Epoch: 54 -> Loss: 0.111137509346\n",
      "Epoch: 54 -> Test Accuracy: 85.69\n",
      "[55, 60] loss: 0.109\n",
      "[55, 120] loss: 0.105\n",
      "[55, 180] loss: 0.111\n",
      "[55, 240] loss: 0.102\n",
      "[55, 300] loss: 0.110\n",
      "[55, 360] loss: 0.112\n",
      "Epoch: 55 -> Loss: 0.152040928602\n",
      "Epoch: 55 -> Test Accuracy: 85.6\n",
      "[56, 60] loss: 0.101\n",
      "[56, 120] loss: 0.101\n",
      "[56, 180] loss: 0.107\n",
      "[56, 240] loss: 0.103\n",
      "[56, 300] loss: 0.103\n",
      "[56, 360] loss: 0.100\n",
      "Epoch: 56 -> Loss: 0.0484032928944\n",
      "Epoch: 56 -> Test Accuracy: 85.65\n",
      "[57, 60] loss: 0.105\n",
      "[57, 120] loss: 0.104\n",
      "[57, 180] loss: 0.098\n",
      "[57, 240] loss: 0.106\n",
      "[57, 300] loss: 0.101\n",
      "[57, 360] loss: 0.108\n",
      "Epoch: 57 -> Loss: 0.061686091125\n",
      "Epoch: 57 -> Test Accuracy: 85.71\n",
      "[58, 60] loss: 0.098\n",
      "[58, 120] loss: 0.106\n",
      "[58, 180] loss: 0.110\n",
      "[58, 240] loss: 0.101\n",
      "[58, 300] loss: 0.098\n",
      "[58, 360] loss: 0.100\n",
      "Epoch: 58 -> Loss: 0.193128123879\n",
      "Epoch: 58 -> Test Accuracy: 85.79\n",
      "[59, 60] loss: 0.108\n",
      "[59, 120] loss: 0.108\n",
      "[59, 180] loss: 0.104\n",
      "[59, 240] loss: 0.103\n",
      "[59, 300] loss: 0.103\n",
      "[59, 360] loss: 0.102\n",
      "Epoch: 59 -> Loss: 0.195188015699\n",
      "Epoch: 59 -> Test Accuracy: 85.74\n",
      "[60, 60] loss: 0.103\n",
      "[60, 120] loss: 0.106\n",
      "[60, 180] loss: 0.097\n",
      "[60, 240] loss: 0.098\n",
      "[60, 300] loss: 0.096\n",
      "[60, 360] loss: 0.097\n",
      "Epoch: 60 -> Loss: 0.0566382594407\n",
      "Epoch: 60 -> Test Accuracy: 85.63\n",
      "[61, 60] loss: 0.095\n",
      "[61, 120] loss: 0.098\n",
      "[61, 180] loss: 0.098\n",
      "[61, 240] loss: 0.106\n",
      "[61, 300] loss: 0.100\n",
      "[61, 360] loss: 0.104\n",
      "Epoch: 61 -> Loss: 0.0798636451364\n",
      "Epoch: 61 -> Test Accuracy: 85.68\n",
      "[62, 60] loss: 0.099\n",
      "[62, 120] loss: 0.093\n",
      "[62, 180] loss: 0.099\n",
      "[62, 240] loss: 0.109\n",
      "[62, 300] loss: 0.094\n",
      "[62, 360] loss: 0.101\n",
      "Epoch: 62 -> Loss: 0.126481920481\n",
      "Epoch: 62 -> Test Accuracy: 85.65\n",
      "[63, 60] loss: 0.103\n",
      "[63, 120] loss: 0.104\n",
      "[63, 180] loss: 0.091\n",
      "[63, 240] loss: 0.100\n",
      "[63, 300] loss: 0.090\n",
      "[63, 360] loss: 0.099\n",
      "Epoch: 63 -> Loss: 0.188348561525\n",
      "Epoch: 63 -> Test Accuracy: 85.8\n",
      "[64, 60] loss: 0.097\n",
      "[64, 120] loss: 0.092\n",
      "[64, 180] loss: 0.092\n",
      "[64, 240] loss: 0.093\n",
      "[64, 300] loss: 0.099\n",
      "[64, 360] loss: 0.099\n",
      "Epoch: 64 -> Loss: 0.113866649568\n",
      "Epoch: 64 -> Test Accuracy: 85.66\n",
      "[65, 60] loss: 0.094\n",
      "[65, 120] loss: 0.091\n",
      "[65, 180] loss: 0.089\n",
      "[65, 240] loss: 0.095\n",
      "[65, 300] loss: 0.097\n",
      "[65, 360] loss: 0.100\n",
      "Epoch: 65 -> Loss: 0.0510505624115\n",
      "Epoch: 65 -> Test Accuracy: 85.79\n",
      "[66, 60] loss: 0.093\n",
      "[66, 120] loss: 0.091\n",
      "[66, 180] loss: 0.102\n",
      "[66, 240] loss: 0.091\n",
      "[66, 300] loss: 0.099\n",
      "[66, 360] loss: 0.093\n",
      "Epoch: 66 -> Loss: 0.0911420658231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Test Accuracy: 85.66\n",
      "[67, 60] loss: 0.098\n",
      "[67, 120] loss: 0.091\n",
      "[67, 180] loss: 0.090\n",
      "[67, 240] loss: 0.094\n",
      "[67, 300] loss: 0.099\n",
      "[67, 360] loss: 0.096\n",
      "Epoch: 67 -> Loss: 0.0928951725364\n",
      "Epoch: 67 -> Test Accuracy: 85.77\n",
      "[68, 60] loss: 0.089\n",
      "[68, 120] loss: 0.099\n",
      "[68, 180] loss: 0.093\n",
      "[68, 240] loss: 0.095\n",
      "[68, 300] loss: 0.096\n",
      "[68, 360] loss: 0.097\n",
      "Epoch: 68 -> Loss: 0.0397040434182\n",
      "Epoch: 68 -> Test Accuracy: 85.72\n",
      "[69, 60] loss: 0.097\n",
      "[69, 120] loss: 0.094\n",
      "[69, 180] loss: 0.091\n",
      "[69, 240] loss: 0.091\n",
      "[69, 300] loss: 0.097\n",
      "[69, 360] loss: 0.093\n",
      "Epoch: 69 -> Loss: 0.196019023657\n",
      "Epoch: 69 -> Test Accuracy: 85.72\n",
      "[70, 60] loss: 0.094\n",
      "[70, 120] loss: 0.093\n",
      "[70, 180] loss: 0.098\n",
      "[70, 240] loss: 0.096\n",
      "[70, 300] loss: 0.087\n",
      "[70, 360] loss: 0.097\n",
      "Epoch: 70 -> Loss: 0.0682639628649\n",
      "Epoch: 70 -> Test Accuracy: 85.58\n",
      "[71, 60] loss: 0.088\n",
      "[71, 120] loss: 0.089\n",
      "[71, 180] loss: 0.093\n",
      "[71, 240] loss: 0.090\n",
      "[71, 300] loss: 0.099\n",
      "[71, 360] loss: 0.093\n",
      "Epoch: 71 -> Loss: 0.0670818313956\n",
      "Epoch: 71 -> Test Accuracy: 85.58\n",
      "[72, 60] loss: 0.083\n",
      "[72, 120] loss: 0.087\n",
      "[72, 180] loss: 0.091\n",
      "[72, 240] loss: 0.094\n",
      "[72, 300] loss: 0.101\n",
      "[72, 360] loss: 0.089\n",
      "Epoch: 72 -> Loss: 0.107989273965\n",
      "Epoch: 72 -> Test Accuracy: 85.54\n",
      "[73, 60] loss: 0.086\n",
      "[73, 120] loss: 0.088\n",
      "[73, 180] loss: 0.089\n",
      "[73, 240] loss: 0.098\n",
      "[73, 300] loss: 0.093\n",
      "[73, 360] loss: 0.092\n",
      "Epoch: 73 -> Loss: 0.0512452833354\n",
      "Epoch: 73 -> Test Accuracy: 85.75\n",
      "[74, 60] loss: 0.084\n",
      "[74, 120] loss: 0.083\n",
      "[74, 180] loss: 0.093\n",
      "[74, 240] loss: 0.093\n",
      "[74, 300] loss: 0.097\n",
      "[74, 360] loss: 0.087\n",
      "Epoch: 74 -> Loss: 0.0651468858123\n",
      "Epoch: 74 -> Test Accuracy: 85.69\n",
      "[75, 60] loss: 0.089\n",
      "[75, 120] loss: 0.086\n",
      "[75, 180] loss: 0.086\n",
      "[75, 240] loss: 0.084\n",
      "[75, 300] loss: 0.087\n",
      "[75, 360] loss: 0.094\n",
      "Epoch: 75 -> Loss: 0.0574106685817\n",
      "Epoch: 75 -> Test Accuracy: 85.67\n",
      "[76, 60] loss: 0.088\n",
      "[76, 120] loss: 0.085\n",
      "[76, 180] loss: 0.085\n",
      "[76, 240] loss: 0.088\n",
      "[76, 300] loss: 0.089\n",
      "[76, 360] loss: 0.094\n",
      "Epoch: 76 -> Loss: 0.321150958538\n",
      "Epoch: 76 -> Test Accuracy: 85.57\n",
      "[77, 60] loss: 0.088\n",
      "[77, 120] loss: 0.086\n",
      "[77, 180] loss: 0.095\n",
      "[77, 240] loss: 0.083\n",
      "[77, 300] loss: 0.090\n",
      "[77, 360] loss: 0.085\n",
      "Epoch: 77 -> Loss: 0.150041341782\n",
      "Epoch: 77 -> Test Accuracy: 85.65\n",
      "[78, 60] loss: 0.085\n",
      "[78, 120] loss: 0.085\n",
      "[78, 180] loss: 0.091\n",
      "[78, 240] loss: 0.089\n",
      "[78, 300] loss: 0.087\n",
      "[78, 360] loss: 0.084\n",
      "Epoch: 78 -> Loss: 0.211216330528\n",
      "Epoch: 78 -> Test Accuracy: 85.75\n",
      "[79, 60] loss: 0.093\n",
      "[79, 120] loss: 0.084\n",
      "[79, 180] loss: 0.092\n",
      "[79, 240] loss: 0.085\n",
      "[79, 300] loss: 0.084\n",
      "[79, 360] loss: 0.087\n",
      "Epoch: 79 -> Loss: 0.0855204388499\n",
      "Epoch: 79 -> Test Accuracy: 85.54\n",
      "[80, 60] loss: 0.090\n",
      "[80, 120] loss: 0.083\n",
      "[80, 180] loss: 0.088\n",
      "[80, 240] loss: 0.085\n",
      "[80, 300] loss: 0.084\n",
      "[80, 360] loss: 0.082\n",
      "Epoch: 80 -> Loss: 0.0219745580107\n",
      "Epoch: 80 -> Test Accuracy: 85.65\n",
      "[81, 60] loss: 0.087\n",
      "[81, 120] loss: 0.089\n",
      "[81, 180] loss: 0.080\n",
      "[81, 240] loss: 0.083\n",
      "[81, 300] loss: 0.090\n",
      "[81, 360] loss: 0.089\n",
      "Epoch: 81 -> Loss: 0.092256680131\n",
      "Epoch: 81 -> Test Accuracy: 85.67\n",
      "[82, 60] loss: 0.079\n",
      "[82, 120] loss: 0.084\n",
      "[82, 180] loss: 0.088\n",
      "[82, 240] loss: 0.084\n",
      "[82, 300] loss: 0.081\n",
      "[82, 360] loss: 0.089\n",
      "Epoch: 82 -> Loss: 0.0495363473892\n",
      "Epoch: 82 -> Test Accuracy: 85.7\n",
      "[83, 60] loss: 0.088\n",
      "[83, 120] loss: 0.086\n",
      "[83, 180] loss: 0.085\n",
      "[83, 240] loss: 0.086\n",
      "[83, 300] loss: 0.087\n",
      "[83, 360] loss: 0.088\n",
      "Epoch: 83 -> Loss: 0.127678662539\n",
      "Epoch: 83 -> Test Accuracy: 85.66\n",
      "[84, 60] loss: 0.079\n",
      "[84, 120] loss: 0.083\n",
      "[84, 180] loss: 0.082\n",
      "[84, 240] loss: 0.088\n",
      "[84, 300] loss: 0.085\n",
      "[84, 360] loss: 0.084\n",
      "Epoch: 84 -> Loss: 0.129593536258\n",
      "Epoch: 84 -> Test Accuracy: 85.71\n",
      "[85, 60] loss: 0.082\n",
      "[85, 120] loss: 0.082\n",
      "[85, 180] loss: 0.080\n",
      "[85, 240] loss: 0.082\n",
      "[85, 300] loss: 0.081\n",
      "[85, 360] loss: 0.090\n",
      "Epoch: 85 -> Loss: 0.108107529581\n",
      "Epoch: 85 -> Test Accuracy: 85.71\n",
      "[86, 60] loss: 0.079\n",
      "[86, 120] loss: 0.081\n",
      "[86, 180] loss: 0.084\n",
      "[86, 240] loss: 0.077\n",
      "[86, 300] loss: 0.080\n",
      "[86, 360] loss: 0.085\n",
      "Epoch: 86 -> Loss: 0.0764025822282\n",
      "Epoch: 86 -> Test Accuracy: 85.7\n",
      "[87, 60] loss: 0.078\n",
      "[87, 120] loss: 0.082\n",
      "[87, 180] loss: 0.086\n",
      "[87, 240] loss: 0.081\n",
      "[87, 300] loss: 0.083\n",
      "[87, 360] loss: 0.084\n",
      "Epoch: 87 -> Loss: 0.157854765654\n",
      "Epoch: 87 -> Test Accuracy: 85.79\n",
      "[88, 60] loss: 0.084\n",
      "[88, 120] loss: 0.079\n",
      "[88, 180] loss: 0.082\n",
      "[88, 240] loss: 0.085\n",
      "[88, 300] loss: 0.079\n",
      "[88, 360] loss: 0.079\n",
      "Epoch: 88 -> Loss: 0.089814260602\n",
      "Epoch: 88 -> Test Accuracy: 85.68\n",
      "[89, 60] loss: 0.086\n",
      "[89, 120] loss: 0.082\n",
      "[89, 180] loss: 0.084\n",
      "[89, 240] loss: 0.081\n",
      "[89, 300] loss: 0.086\n",
      "[89, 360] loss: 0.079\n",
      "Epoch: 89 -> Loss: 0.0830352157354\n",
      "Epoch: 89 -> Test Accuracy: 85.49\n",
      "[90, 60] loss: 0.081\n",
      "[90, 120] loss: 0.079\n",
      "[90, 180] loss: 0.077\n",
      "[90, 240] loss: 0.080\n",
      "[90, 300] loss: 0.082\n",
      "[90, 360] loss: 0.076\n",
      "Epoch: 90 -> Loss: 0.0575953312218\n",
      "Epoch: 90 -> Test Accuracy: 85.65\n",
      "[91, 60] loss: 0.077\n",
      "[91, 120] loss: 0.079\n",
      "[91, 180] loss: 0.077\n",
      "[91, 240] loss: 0.078\n",
      "[91, 300] loss: 0.082\n",
      "[91, 360] loss: 0.081\n",
      "Epoch: 91 -> Loss: 0.047510355711\n",
      "Epoch: 91 -> Test Accuracy: 85.54\n",
      "[92, 60] loss: 0.084\n",
      "[92, 120] loss: 0.081\n",
      "[92, 180] loss: 0.077\n",
      "[92, 240] loss: 0.084\n",
      "[92, 300] loss: 0.075\n",
      "[92, 360] loss: 0.081\n",
      "Epoch: 92 -> Loss: 0.100686267018\n",
      "Epoch: 92 -> Test Accuracy: 85.57\n",
      "[93, 60] loss: 0.079\n",
      "[93, 120] loss: 0.075\n",
      "[93, 180] loss: 0.076\n",
      "[93, 240] loss: 0.078\n",
      "[93, 300] loss: 0.079\n",
      "[93, 360] loss: 0.085\n",
      "Epoch: 93 -> Loss: 0.0804078131914\n",
      "Epoch: 93 -> Test Accuracy: 85.5\n",
      "[94, 60] loss: 0.081\n",
      "[94, 120] loss: 0.080\n",
      "[94, 180] loss: 0.086\n",
      "[94, 240] loss: 0.080\n",
      "[94, 300] loss: 0.079\n",
      "[94, 360] loss: 0.083\n",
      "Epoch: 94 -> Loss: 0.0742163658142\n",
      "Epoch: 94 -> Test Accuracy: 85.59\n",
      "[95, 60] loss: 0.085\n",
      "[95, 120] loss: 0.075\n",
      "[95, 180] loss: 0.077\n",
      "[95, 240] loss: 0.076\n",
      "[95, 300] loss: 0.076\n",
      "[95, 360] loss: 0.078\n",
      "Epoch: 95 -> Loss: 0.0795137733221\n",
      "Epoch: 95 -> Test Accuracy: 85.6\n",
      "[96, 60] loss: 0.071\n",
      "[96, 120] loss: 0.077\n",
      "[96, 180] loss: 0.077\n",
      "[96, 240] loss: 0.079\n",
      "[96, 300] loss: 0.078\n",
      "[96, 360] loss: 0.079\n",
      "Epoch: 96 -> Loss: 0.103549860418\n",
      "Epoch: 96 -> Test Accuracy: 85.67\n",
      "[97, 60] loss: 0.076\n",
      "[97, 120] loss: 0.077\n",
      "[97, 180] loss: 0.076\n",
      "[97, 240] loss: 0.071\n",
      "[97, 300] loss: 0.076\n",
      "[97, 360] loss: 0.084\n",
      "Epoch: 97 -> Loss: 0.137420386076\n",
      "Epoch: 97 -> Test Accuracy: 85.67\n",
      "[98, 60] loss: 0.077\n",
      "[98, 120] loss: 0.075\n",
      "[98, 180] loss: 0.082\n",
      "[98, 240] loss: 0.080\n",
      "[98, 300] loss: 0.077\n",
      "[98, 360] loss: 0.075\n",
      "Epoch: 98 -> Loss: 0.103451728821\n",
      "Epoch: 98 -> Test Accuracy: 85.56\n",
      "[99, 60] loss: 0.077\n",
      "[99, 120] loss: 0.080\n",
      "[99, 180] loss: 0.072\n",
      "[99, 240] loss: 0.074\n",
      "[99, 300] loss: 0.076\n",
      "[99, 360] loss: 0.075\n",
      "Epoch: 99 -> Loss: 0.139910504222\n",
      "Epoch: 99 -> Test Accuracy: 85.69\n",
      "[100, 60] loss: 0.077\n",
      "[100, 120] loss: 0.071\n",
      "[100, 180] loss: 0.075\n",
      "[100, 240] loss: 0.077\n",
      "[100, 300] loss: 0.077\n",
      "[100, 360] loss: 0.072\n",
      "Epoch: 100 -> Loss: 0.0792201608419\n",
      "Epoch: 100 -> Test Accuracy: 85.53\n",
      "Finished Training\n",
      "[1, 60] loss: 1.713\n",
      "[1, 120] loss: 0.928\n",
      "[1, 180] loss: 0.840\n",
      "[1, 240] loss: 0.811\n",
      "[1, 300] loss: 0.777\n",
      "[1, 360] loss: 0.740\n",
      "Epoch: 1 -> Loss: 0.673369646072\n",
      "Epoch: 1 -> Test Accuracy: 71.73\n",
      "[2, 60] loss: 0.725\n",
      "[2, 120] loss: 0.708\n",
      "[2, 180] loss: 0.679\n",
      "[2, 240] loss: 0.698\n",
      "[2, 300] loss: 0.665\n",
      "[2, 360] loss: 0.639\n",
      "Epoch: 2 -> Loss: 0.563983440399\n",
      "Epoch: 2 -> Test Accuracy: 74.33\n",
      "[3, 60] loss: 0.626\n",
      "[3, 120] loss: 0.631\n",
      "[3, 180] loss: 0.628\n",
      "[3, 240] loss: 0.637\n",
      "[3, 300] loss: 0.626\n",
      "[3, 360] loss: 0.625\n",
      "Epoch: 3 -> Loss: 0.70359057188\n",
      "Epoch: 3 -> Test Accuracy: 75.01\n",
      "[4, 60] loss: 0.602\n",
      "[4, 120] loss: 0.577\n",
      "[4, 180] loss: 0.604\n",
      "[4, 240] loss: 0.612\n",
      "[4, 300] loss: 0.602\n",
      "[4, 360] loss: 0.621\n",
      "Epoch: 4 -> Loss: 0.656735777855\n",
      "Epoch: 4 -> Test Accuracy: 75.78\n",
      "[5, 60] loss: 0.573\n",
      "[5, 120] loss: 0.568\n",
      "[5, 180] loss: 0.572\n",
      "[5, 240] loss: 0.574\n",
      "[5, 300] loss: 0.590\n",
      "[5, 360] loss: 0.585\n",
      "Epoch: 5 -> Loss: 0.511868834496\n",
      "Epoch: 5 -> Test Accuracy: 76.61\n",
      "[6, 60] loss: 0.570\n",
      "[6, 120] loss: 0.566\n",
      "[6, 180] loss: 0.564\n",
      "[6, 240] loss: 0.579\n",
      "[6, 300] loss: 0.571\n",
      "[6, 360] loss: 0.572\n",
      "Epoch: 6 -> Loss: 0.64146900177\n",
      "Epoch: 6 -> Test Accuracy: 76.93\n",
      "[7, 60] loss: 0.552\n",
      "[7, 120] loss: 0.576\n",
      "[7, 180] loss: 0.535\n",
      "[7, 240] loss: 0.558\n",
      "[7, 300] loss: 0.552\n",
      "[7, 360] loss: 0.565\n",
      "Epoch: 7 -> Loss: 0.59641379118\n",
      "Epoch: 7 -> Test Accuracy: 77.19\n",
      "[8, 60] loss: 0.543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 120] loss: 0.529\n",
      "[8, 180] loss: 0.568\n",
      "[8, 240] loss: 0.548\n",
      "[8, 300] loss: 0.548\n",
      "[8, 360] loss: 0.551\n",
      "Epoch: 8 -> Loss: 0.607245922089\n",
      "Epoch: 8 -> Test Accuracy: 76.85\n",
      "[9, 60] loss: 0.528\n",
      "[9, 120] loss: 0.545\n",
      "[9, 180] loss: 0.552\n",
      "[9, 240] loss: 0.532\n",
      "[9, 300] loss: 0.539\n",
      "[9, 360] loss: 0.550\n",
      "Epoch: 9 -> Loss: 0.558493852615\n",
      "Epoch: 9 -> Test Accuracy: 77.59\n",
      "[10, 60] loss: 0.525\n",
      "[10, 120] loss: 0.534\n",
      "[10, 180] loss: 0.551\n",
      "[10, 240] loss: 0.533\n",
      "[10, 300] loss: 0.543\n",
      "[10, 360] loss: 0.534\n",
      "Epoch: 10 -> Loss: 0.50290876627\n",
      "Epoch: 10 -> Test Accuracy: 77.13\n",
      "[11, 60] loss: 0.522\n",
      "[11, 120] loss: 0.535\n",
      "[11, 180] loss: 0.535\n",
      "[11, 240] loss: 0.537\n",
      "[11, 300] loss: 0.524\n",
      "[11, 360] loss: 0.535\n",
      "Epoch: 11 -> Loss: 0.506026685238\n",
      "Epoch: 11 -> Test Accuracy: 78.0\n",
      "[12, 60] loss: 0.519\n",
      "[12, 120] loss: 0.538\n",
      "[12, 180] loss: 0.516\n",
      "[12, 240] loss: 0.544\n",
      "[12, 300] loss: 0.534\n",
      "[12, 360] loss: 0.530\n",
      "Epoch: 12 -> Loss: 0.4039940238\n",
      "Epoch: 12 -> Test Accuracy: 77.09\n",
      "[13, 60] loss: 0.490\n",
      "[13, 120] loss: 0.531\n",
      "[13, 180] loss: 0.542\n",
      "[13, 240] loss: 0.535\n",
      "[13, 300] loss: 0.527\n",
      "[13, 360] loss: 0.510\n",
      "Epoch: 13 -> Loss: 0.505799710751\n",
      "Epoch: 13 -> Test Accuracy: 77.36\n",
      "[14, 60] loss: 0.486\n",
      "[14, 120] loss: 0.498\n",
      "[14, 180] loss: 0.528\n",
      "[14, 240] loss: 0.518\n",
      "[14, 300] loss: 0.547\n",
      "[14, 360] loss: 0.542\n",
      "Epoch: 14 -> Loss: 0.525452136993\n",
      "Epoch: 14 -> Test Accuracy: 77.21\n",
      "[15, 60] loss: 0.509\n",
      "[15, 120] loss: 0.493\n",
      "[15, 180] loss: 0.531\n",
      "[15, 240] loss: 0.537\n",
      "[15, 300] loss: 0.506\n",
      "[15, 360] loss: 0.532\n",
      "Epoch: 15 -> Loss: 0.470185697079\n",
      "Epoch: 15 -> Test Accuracy: 77.64\n",
      "[16, 60] loss: 0.501\n",
      "[16, 120] loss: 0.516\n",
      "[16, 180] loss: 0.529\n",
      "[16, 240] loss: 0.517\n",
      "[16, 300] loss: 0.498\n",
      "[16, 360] loss: 0.546\n",
      "Epoch: 16 -> Loss: 0.587037026882\n",
      "Epoch: 16 -> Test Accuracy: 77.38\n",
      "[17, 60] loss: 0.504\n",
      "[17, 120] loss: 0.515\n",
      "[17, 180] loss: 0.508\n",
      "[17, 240] loss: 0.511\n",
      "[17, 300] loss: 0.533\n",
      "[17, 360] loss: 0.520\n",
      "Epoch: 17 -> Loss: 0.516676545143\n",
      "Epoch: 17 -> Test Accuracy: 77.6\n",
      "[18, 60] loss: 0.503\n",
      "[18, 120] loss: 0.517\n",
      "[18, 180] loss: 0.509\n",
      "[18, 240] loss: 0.523\n",
      "[18, 300] loss: 0.532\n",
      "[18, 360] loss: 0.520\n",
      "Epoch: 18 -> Loss: 0.481388419867\n",
      "Epoch: 18 -> Test Accuracy: 77.81\n",
      "[19, 60] loss: 0.496\n",
      "[19, 120] loss: 0.519\n",
      "[19, 180] loss: 0.518\n",
      "[19, 240] loss: 0.515\n",
      "[19, 300] loss: 0.513\n",
      "[19, 360] loss: 0.531\n",
      "Epoch: 19 -> Loss: 0.532352507114\n",
      "Epoch: 19 -> Test Accuracy: 77.8\n",
      "[20, 60] loss: 0.504\n",
      "[20, 120] loss: 0.505\n",
      "[20, 180] loss: 0.515\n",
      "[20, 240] loss: 0.511\n",
      "[20, 300] loss: 0.510\n",
      "[20, 360] loss: 0.527\n",
      "Epoch: 20 -> Loss: 0.409993350506\n",
      "Epoch: 20 -> Test Accuracy: 77.45\n",
      "[21, 60] loss: 0.473\n",
      "[21, 120] loss: 0.460\n",
      "[21, 180] loss: 0.429\n",
      "[21, 240] loss: 0.423\n",
      "[21, 300] loss: 0.438\n",
      "[21, 360] loss: 0.441\n",
      "Epoch: 21 -> Loss: 0.54022026062\n",
      "Epoch: 21 -> Test Accuracy: 79.71\n",
      "[22, 60] loss: 0.417\n",
      "[22, 120] loss: 0.424\n",
      "[22, 180] loss: 0.421\n",
      "[22, 240] loss: 0.406\n",
      "[22, 300] loss: 0.425\n",
      "[22, 360] loss: 0.408\n",
      "Epoch: 22 -> Loss: 0.495474874973\n",
      "Epoch: 22 -> Test Accuracy: 80.34\n",
      "[23, 60] loss: 0.397\n",
      "[23, 120] loss: 0.417\n",
      "[23, 180] loss: 0.395\n",
      "[23, 240] loss: 0.398\n",
      "[23, 300] loss: 0.396\n",
      "[23, 360] loss: 0.393\n",
      "Epoch: 23 -> Loss: 0.392257928848\n",
      "Epoch: 23 -> Test Accuracy: 80.26\n",
      "[24, 60] loss: 0.391\n",
      "[24, 120] loss: 0.388\n",
      "[24, 180] loss: 0.407\n",
      "[24, 240] loss: 0.397\n",
      "[24, 300] loss: 0.375\n",
      "[24, 360] loss: 0.407\n",
      "Epoch: 24 -> Loss: 0.334862232208\n",
      "Epoch: 24 -> Test Accuracy: 80.56\n",
      "[25, 60] loss: 0.368\n",
      "[25, 120] loss: 0.383\n",
      "[25, 180] loss: 0.373\n",
      "[25, 240] loss: 0.371\n",
      "[25, 300] loss: 0.411\n",
      "[25, 360] loss: 0.384\n",
      "Epoch: 25 -> Loss: 0.362238436937\n",
      "Epoch: 25 -> Test Accuracy: 80.09\n",
      "[26, 60] loss: 0.381\n",
      "[26, 120] loss: 0.373\n",
      "[26, 180] loss: 0.368\n",
      "[26, 240] loss: 0.386\n",
      "[26, 300] loss: 0.379\n",
      "[26, 360] loss: 0.371\n",
      "Epoch: 26 -> Loss: 0.490863859653\n",
      "Epoch: 26 -> Test Accuracy: 80.55\n",
      "[27, 60] loss: 0.358\n",
      "[27, 120] loss: 0.363\n",
      "[27, 180] loss: 0.381\n",
      "[27, 240] loss: 0.383\n",
      "[27, 300] loss: 0.391\n",
      "[27, 360] loss: 0.376\n",
      "Epoch: 27 -> Loss: 0.44223690033\n",
      "Epoch: 27 -> Test Accuracy: 80.15\n",
      "[28, 60] loss: 0.363\n",
      "[28, 120] loss: 0.381\n",
      "[28, 180] loss: 0.372\n",
      "[28, 240] loss: 0.364\n",
      "[28, 300] loss: 0.383\n",
      "[28, 360] loss: 0.373\n",
      "Epoch: 28 -> Loss: 0.418700218201\n",
      "Epoch: 28 -> Test Accuracy: 80.23\n",
      "[29, 60] loss: 0.350\n",
      "[29, 120] loss: 0.365\n",
      "[29, 180] loss: 0.376\n",
      "[29, 240] loss: 0.362\n",
      "[29, 300] loss: 0.366\n",
      "[29, 360] loss: 0.367\n",
      "Epoch: 29 -> Loss: 0.384102880955\n",
      "Epoch: 29 -> Test Accuracy: 80.22\n",
      "[30, 60] loss: 0.354\n",
      "[30, 120] loss: 0.359\n",
      "[30, 180] loss: 0.373\n",
      "[30, 240] loss: 0.354\n",
      "[30, 300] loss: 0.368\n",
      "[30, 360] loss: 0.383\n",
      "Epoch: 30 -> Loss: 0.324624925852\n",
      "Epoch: 30 -> Test Accuracy: 80.23\n",
      "[31, 60] loss: 0.362\n",
      "[31, 120] loss: 0.357\n",
      "[31, 180] loss: 0.367\n",
      "[31, 240] loss: 0.361\n",
      "[31, 300] loss: 0.386\n",
      "[31, 360] loss: 0.366\n",
      "Epoch: 31 -> Loss: 0.549670338631\n",
      "Epoch: 31 -> Test Accuracy: 80.41\n",
      "[32, 60] loss: 0.348\n",
      "[32, 120] loss: 0.366\n",
      "[32, 180] loss: 0.363\n",
      "[32, 240] loss: 0.368\n",
      "[32, 300] loss: 0.350\n",
      "[32, 360] loss: 0.370\n",
      "Epoch: 32 -> Loss: 0.218478992581\n",
      "Epoch: 32 -> Test Accuracy: 79.92\n",
      "[33, 60] loss: 0.363\n",
      "[33, 120] loss: 0.344\n",
      "[33, 180] loss: 0.360\n",
      "[33, 240] loss: 0.361\n",
      "[33, 300] loss: 0.350\n",
      "[33, 360] loss: 0.374\n",
      "Epoch: 33 -> Loss: 0.466153144836\n",
      "Epoch: 33 -> Test Accuracy: 79.87\n",
      "[34, 60] loss: 0.364\n",
      "[34, 120] loss: 0.358\n",
      "[34, 180] loss: 0.362\n",
      "[34, 240] loss: 0.361\n",
      "[34, 300] loss: 0.367\n",
      "[34, 360] loss: 0.372\n",
      "Epoch: 34 -> Loss: 0.447794616222\n",
      "Epoch: 34 -> Test Accuracy: 79.24\n",
      "[35, 60] loss: 0.360\n",
      "[35, 120] loss: 0.340\n",
      "[35, 180] loss: 0.367\n",
      "[35, 240] loss: 0.363\n",
      "[35, 300] loss: 0.369\n",
      "[35, 360] loss: 0.365\n",
      "Epoch: 35 -> Loss: 0.449089616537\n",
      "Epoch: 35 -> Test Accuracy: 79.8\n",
      "[36, 60] loss: 0.342\n",
      "[36, 120] loss: 0.365\n",
      "[36, 180] loss: 0.363\n",
      "[36, 240] loss: 0.354\n",
      "[36, 300] loss: 0.364\n",
      "[36, 360] loss: 0.365\n",
      "Epoch: 36 -> Loss: 0.251872003078\n",
      "Epoch: 36 -> Test Accuracy: 79.45\n",
      "[37, 60] loss: 0.358\n",
      "[37, 120] loss: 0.365\n",
      "[37, 180] loss: 0.349\n",
      "[37, 240] loss: 0.338\n",
      "[37, 300] loss: 0.371\n",
      "[37, 360] loss: 0.359\n",
      "Epoch: 37 -> Loss: 0.36882942915\n",
      "Epoch: 37 -> Test Accuracy: 79.7\n",
      "[38, 60] loss: 0.345\n",
      "[38, 120] loss: 0.355\n",
      "[38, 180] loss: 0.359\n",
      "[38, 240] loss: 0.367\n",
      "[38, 300] loss: 0.344\n",
      "[38, 360] loss: 0.360\n",
      "Epoch: 38 -> Loss: 0.68273794651\n",
      "Epoch: 38 -> Test Accuracy: 79.79\n",
      "[39, 60] loss: 0.347\n",
      "[39, 120] loss: 0.346\n",
      "[39, 180] loss: 0.344\n",
      "[39, 240] loss: 0.361\n",
      "[39, 300] loss: 0.362\n",
      "[39, 360] loss: 0.357\n",
      "Epoch: 39 -> Loss: 0.382508456707\n",
      "Epoch: 39 -> Test Accuracy: 79.79\n",
      "[40, 60] loss: 0.339\n",
      "[40, 120] loss: 0.338\n",
      "[40, 180] loss: 0.357\n",
      "[40, 240] loss: 0.365\n",
      "[40, 300] loss: 0.357\n",
      "[40, 360] loss: 0.361\n",
      "Epoch: 40 -> Loss: 0.514642417431\n",
      "Epoch: 40 -> Test Accuracy: 79.52\n",
      "[41, 60] loss: 0.332\n",
      "[41, 120] loss: 0.314\n",
      "[41, 180] loss: 0.327\n",
      "[41, 240] loss: 0.333\n",
      "[41, 300] loss: 0.310\n",
      "[41, 360] loss: 0.295\n",
      "Epoch: 41 -> Loss: 0.289322197437\n",
      "Epoch: 41 -> Test Accuracy: 80.54\n",
      "[42, 60] loss: 0.301\n",
      "[42, 120] loss: 0.293\n",
      "[42, 180] loss: 0.301\n",
      "[42, 240] loss: 0.308\n",
      "[42, 300] loss: 0.294\n",
      "[42, 360] loss: 0.310\n",
      "Epoch: 42 -> Loss: 0.338247537613\n",
      "Epoch: 42 -> Test Accuracy: 80.69\n",
      "[43, 60] loss: 0.304\n",
      "[43, 120] loss: 0.298\n",
      "[43, 180] loss: 0.284\n",
      "[43, 240] loss: 0.285\n",
      "[43, 300] loss: 0.293\n",
      "[43, 360] loss: 0.294\n",
      "Epoch: 43 -> Loss: 0.351669967175\n",
      "Epoch: 43 -> Test Accuracy: 80.81\n",
      "[44, 60] loss: 0.287\n",
      "[44, 120] loss: 0.282\n",
      "[44, 180] loss: 0.281\n",
      "[44, 240] loss: 0.284\n",
      "[44, 300] loss: 0.274\n",
      "[44, 360] loss: 0.285\n",
      "Epoch: 44 -> Loss: 0.155356809497\n",
      "Epoch: 44 -> Test Accuracy: 80.7\n",
      "[45, 60] loss: 0.279\n",
      "[45, 120] loss: 0.284\n",
      "[45, 180] loss: 0.290\n",
      "[45, 240] loss: 0.259\n",
      "[45, 300] loss: 0.282\n",
      "[45, 360] loss: 0.278\n",
      "Epoch: 45 -> Loss: 0.25882101059\n",
      "Epoch: 45 -> Test Accuracy: 80.68\n",
      "[46, 60] loss: 0.278\n",
      "[46, 120] loss: 0.266\n",
      "[46, 180] loss: 0.261\n",
      "[46, 240] loss: 0.265\n",
      "[46, 300] loss: 0.271\n",
      "[46, 360] loss: 0.274\n",
      "Epoch: 46 -> Loss: 0.258960604668\n",
      "Epoch: 46 -> Test Accuracy: 80.7\n",
      "[47, 60] loss: 0.272\n",
      "[47, 120] loss: 0.289\n",
      "[47, 180] loss: 0.270\n",
      "[47, 240] loss: 0.261\n",
      "[47, 300] loss: 0.269\n",
      "[47, 360] loss: 0.261\n",
      "Epoch: 47 -> Loss: 0.282062470913\n",
      "Epoch: 47 -> Test Accuracy: 80.81\n",
      "[48, 60] loss: 0.267\n",
      "[48, 120] loss: 0.261\n",
      "[48, 180] loss: 0.272\n",
      "[48, 240] loss: 0.254\n",
      "[48, 300] loss: 0.266\n",
      "[48, 360] loss: 0.276\n",
      "Epoch: 48 -> Loss: 0.342990249395\n",
      "Epoch: 48 -> Test Accuracy: 81.01\n",
      "[49, 60] loss: 0.264\n",
      "[49, 120] loss: 0.265\n",
      "[49, 180] loss: 0.264\n",
      "[49, 240] loss: 0.265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 300] loss: 0.265\n",
      "[49, 360] loss: 0.262\n",
      "Epoch: 49 -> Loss: 0.285901218653\n",
      "Epoch: 49 -> Test Accuracy: 80.86\n",
      "[50, 60] loss: 0.265\n",
      "[50, 120] loss: 0.264\n",
      "[50, 180] loss: 0.255\n",
      "[50, 240] loss: 0.261\n",
      "[50, 300] loss: 0.269\n",
      "[50, 360] loss: 0.262\n",
      "Epoch: 50 -> Loss: 0.282857120037\n",
      "Epoch: 50 -> Test Accuracy: 81.02\n",
      "[51, 60] loss: 0.267\n",
      "[51, 120] loss: 0.261\n",
      "[51, 180] loss: 0.257\n",
      "[51, 240] loss: 0.256\n",
      "[51, 300] loss: 0.258\n",
      "[51, 360] loss: 0.262\n",
      "Epoch: 51 -> Loss: 0.238241270185\n",
      "Epoch: 51 -> Test Accuracy: 81.13\n",
      "[52, 60] loss: 0.256\n",
      "[52, 120] loss: 0.254\n",
      "[52, 180] loss: 0.269\n",
      "[52, 240] loss: 0.262\n",
      "[52, 300] loss: 0.265\n",
      "[52, 360] loss: 0.269\n",
      "Epoch: 52 -> Loss: 0.323007881641\n",
      "Epoch: 52 -> Test Accuracy: 81.08\n",
      "[53, 60] loss: 0.259\n",
      "[53, 120] loss: 0.252\n",
      "[53, 180] loss: 0.270\n",
      "[53, 240] loss: 0.263\n",
      "[53, 300] loss: 0.265\n",
      "[53, 360] loss: 0.254\n",
      "Epoch: 53 -> Loss: 0.248357981443\n",
      "Epoch: 53 -> Test Accuracy: 81.08\n",
      "[54, 60] loss: 0.255\n",
      "[54, 120] loss: 0.250\n",
      "[54, 180] loss: 0.259\n",
      "[54, 240] loss: 0.265\n",
      "[54, 300] loss: 0.256\n",
      "[54, 360] loss: 0.270\n",
      "Epoch: 54 -> Loss: 0.356463879347\n",
      "Epoch: 54 -> Test Accuracy: 81.21\n",
      "[55, 60] loss: 0.260\n",
      "[55, 120] loss: 0.256\n",
      "[55, 180] loss: 0.240\n",
      "[55, 240] loss: 0.249\n",
      "[55, 300] loss: 0.249\n",
      "[55, 360] loss: 0.257\n",
      "Epoch: 55 -> Loss: 0.161311388016\n",
      "Epoch: 55 -> Test Accuracy: 81.14\n",
      "[56, 60] loss: 0.249\n",
      "[56, 120] loss: 0.262\n",
      "[56, 180] loss: 0.249\n",
      "[56, 240] loss: 0.252\n",
      "[56, 300] loss: 0.239\n",
      "[56, 360] loss: 0.257\n",
      "Epoch: 56 -> Loss: 0.261423945427\n",
      "Epoch: 56 -> Test Accuracy: 81.08\n",
      "[57, 60] loss: 0.245\n",
      "[57, 120] loss: 0.258\n",
      "[57, 180] loss: 0.257\n",
      "[57, 240] loss: 0.255\n",
      "[57, 300] loss: 0.256\n",
      "[57, 360] loss: 0.251\n",
      "Epoch: 57 -> Loss: 0.363118559122\n",
      "Epoch: 57 -> Test Accuracy: 81.26\n",
      "[58, 60] loss: 0.246\n",
      "[58, 120] loss: 0.256\n",
      "[58, 180] loss: 0.245\n",
      "[58, 240] loss: 0.254\n",
      "[58, 300] loss: 0.250\n",
      "[58, 360] loss: 0.235\n",
      "Epoch: 58 -> Loss: 0.204741090536\n",
      "Epoch: 58 -> Test Accuracy: 81.15\n",
      "[59, 60] loss: 0.249\n",
      "[59, 120] loss: 0.241\n",
      "[59, 180] loss: 0.250\n",
      "[59, 240] loss: 0.228\n",
      "[59, 300] loss: 0.253\n",
      "[59, 360] loss: 0.253\n",
      "Epoch: 59 -> Loss: 0.235423177481\n",
      "Epoch: 59 -> Test Accuracy: 81.14\n",
      "[60, 60] loss: 0.254\n",
      "[60, 120] loss: 0.251\n",
      "[60, 180] loss: 0.238\n",
      "[60, 240] loss: 0.242\n",
      "[60, 300] loss: 0.262\n",
      "[60, 360] loss: 0.251\n",
      "Epoch: 60 -> Loss: 0.222998052835\n",
      "Epoch: 60 -> Test Accuracy: 81.05\n",
      "[61, 60] loss: 0.239\n",
      "[61, 120] loss: 0.242\n",
      "[61, 180] loss: 0.244\n",
      "[61, 240] loss: 0.247\n",
      "[61, 300] loss: 0.253\n",
      "[61, 360] loss: 0.249\n",
      "Epoch: 61 -> Loss: 0.194087535143\n",
      "Epoch: 61 -> Test Accuracy: 80.99\n",
      "[62, 60] loss: 0.249\n",
      "[62, 120] loss: 0.249\n",
      "[62, 180] loss: 0.252\n",
      "[62, 240] loss: 0.240\n",
      "[62, 300] loss: 0.254\n",
      "[62, 360] loss: 0.254\n",
      "Epoch: 62 -> Loss: 0.188809171319\n",
      "Epoch: 62 -> Test Accuracy: 80.99\n",
      "[63, 60] loss: 0.259\n",
      "[63, 120] loss: 0.249\n",
      "[63, 180] loss: 0.231\n",
      "[63, 240] loss: 0.250\n",
      "[63, 300] loss: 0.242\n",
      "[63, 360] loss: 0.251\n",
      "Epoch: 63 -> Loss: 0.255340903997\n",
      "Epoch: 63 -> Test Accuracy: 81.01\n",
      "[64, 60] loss: 0.247\n",
      "[64, 120] loss: 0.237\n",
      "[64, 180] loss: 0.247\n",
      "[64, 240] loss: 0.250\n",
      "[64, 300] loss: 0.231\n",
      "[64, 360] loss: 0.257\n",
      "Epoch: 64 -> Loss: 0.241680860519\n",
      "Epoch: 64 -> Test Accuracy: 81.01\n",
      "[65, 60] loss: 0.244\n",
      "[65, 120] loss: 0.246\n",
      "[65, 180] loss: 0.244\n",
      "[65, 240] loss: 0.240\n",
      "[65, 300] loss: 0.250\n",
      "[65, 360] loss: 0.247\n",
      "Epoch: 65 -> Loss: 0.245952695608\n",
      "Epoch: 65 -> Test Accuracy: 81.14\n",
      "[66, 60] loss: 0.239\n",
      "[66, 120] loss: 0.239\n",
      "[66, 180] loss: 0.244\n",
      "[66, 240] loss: 0.245\n",
      "[66, 300] loss: 0.244\n",
      "[66, 360] loss: 0.238\n",
      "Epoch: 66 -> Loss: 0.452591478825\n",
      "Epoch: 66 -> Test Accuracy: 81.12\n",
      "[67, 60] loss: 0.240\n",
      "[67, 120] loss: 0.242\n",
      "[67, 180] loss: 0.244\n",
      "[67, 240] loss: 0.248\n",
      "[67, 300] loss: 0.249\n",
      "[67, 360] loss: 0.233\n",
      "Epoch: 67 -> Loss: 0.246375709772\n",
      "Epoch: 67 -> Test Accuracy: 81.14\n",
      "[68, 60] loss: 0.242\n",
      "[68, 120] loss: 0.236\n",
      "[68, 180] loss: 0.232\n",
      "[68, 240] loss: 0.256\n",
      "[68, 300] loss: 0.236\n",
      "[68, 360] loss: 0.236\n",
      "Epoch: 68 -> Loss: 0.194432482123\n",
      "Epoch: 68 -> Test Accuracy: 81.09\n",
      "[69, 60] loss: 0.255\n",
      "[69, 120] loss: 0.240\n",
      "[69, 180] loss: 0.237\n",
      "[69, 240] loss: 0.237\n",
      "[69, 300] loss: 0.244\n",
      "[69, 360] loss: 0.236\n",
      "Epoch: 69 -> Loss: 0.335268259048\n",
      "Epoch: 69 -> Test Accuracy: 81.08\n",
      "[70, 60] loss: 0.241\n",
      "[70, 120] loss: 0.247\n",
      "[70, 180] loss: 0.244\n",
      "[70, 240] loss: 0.229\n",
      "[70, 300] loss: 0.231\n",
      "[70, 360] loss: 0.246\n",
      "Epoch: 70 -> Loss: 0.201131850481\n",
      "Epoch: 70 -> Test Accuracy: 81.27\n",
      "[71, 60] loss: 0.241\n",
      "[71, 120] loss: 0.233\n",
      "[71, 180] loss: 0.233\n",
      "[71, 240] loss: 0.243\n",
      "[71, 300] loss: 0.236\n",
      "[71, 360] loss: 0.254\n",
      "Epoch: 71 -> Loss: 0.17291021347\n",
      "Epoch: 71 -> Test Accuracy: 81.16\n",
      "[72, 60] loss: 0.232\n",
      "[72, 120] loss: 0.232\n",
      "[72, 180] loss: 0.248\n",
      "[72, 240] loss: 0.242\n",
      "[72, 300] loss: 0.236\n",
      "[72, 360] loss: 0.229\n",
      "Epoch: 72 -> Loss: 0.216406792402\n",
      "Epoch: 72 -> Test Accuracy: 81.26\n",
      "[73, 60] loss: 0.235\n",
      "[73, 120] loss: 0.251\n",
      "[73, 180] loss: 0.230\n",
      "[73, 240] loss: 0.245\n",
      "[73, 300] loss: 0.242\n",
      "[73, 360] loss: 0.228\n",
      "Epoch: 73 -> Loss: 0.46904104948\n",
      "Epoch: 73 -> Test Accuracy: 81.15\n",
      "[74, 60] loss: 0.230\n",
      "[74, 120] loss: 0.233\n",
      "[74, 180] loss: 0.230\n",
      "[74, 240] loss: 0.230\n",
      "[74, 300] loss: 0.235\n",
      "[74, 360] loss: 0.247\n",
      "Epoch: 74 -> Loss: 0.411506593227\n",
      "Epoch: 74 -> Test Accuracy: 81.04\n",
      "[75, 60] loss: 0.231\n",
      "[75, 120] loss: 0.234\n",
      "[75, 180] loss: 0.226\n",
      "[75, 240] loss: 0.238\n",
      "[75, 300] loss: 0.219\n",
      "[75, 360] loss: 0.233\n",
      "Epoch: 75 -> Loss: 0.155154377222\n",
      "Epoch: 75 -> Test Accuracy: 81.0\n",
      "[76, 60] loss: 0.229\n",
      "[76, 120] loss: 0.244\n",
      "[76, 180] loss: 0.224\n",
      "[76, 240] loss: 0.221\n",
      "[76, 300] loss: 0.231\n",
      "[76, 360] loss: 0.245\n",
      "Epoch: 76 -> Loss: 0.202551692724\n",
      "Epoch: 76 -> Test Accuracy: 80.85\n",
      "[77, 60] loss: 0.237\n",
      "[77, 120] loss: 0.228\n",
      "[77, 180] loss: 0.223\n",
      "[77, 240] loss: 0.242\n",
      "[77, 300] loss: 0.232\n",
      "[77, 360] loss: 0.232\n",
      "Epoch: 77 -> Loss: 0.165542334318\n",
      "Epoch: 77 -> Test Accuracy: 81.0\n",
      "[78, 60] loss: 0.236\n",
      "[78, 120] loss: 0.231\n",
      "[78, 180] loss: 0.226\n",
      "[78, 240] loss: 0.245\n",
      "[78, 300] loss: 0.222\n",
      "[78, 360] loss: 0.227\n",
      "Epoch: 78 -> Loss: 0.253785759211\n",
      "Epoch: 78 -> Test Accuracy: 80.91\n",
      "[79, 60] loss: 0.226\n",
      "[79, 120] loss: 0.227\n",
      "[79, 180] loss: 0.236\n",
      "[79, 240] loss: 0.247\n",
      "[79, 300] loss: 0.237\n",
      "[79, 360] loss: 0.253\n",
      "Epoch: 79 -> Loss: 0.268841505051\n",
      "Epoch: 79 -> Test Accuracy: 81.13\n",
      "[80, 60] loss: 0.236\n",
      "[80, 120] loss: 0.229\n",
      "[80, 180] loss: 0.228\n",
      "[80, 240] loss: 0.230\n",
      "[80, 300] loss: 0.239\n",
      "[80, 360] loss: 0.220\n",
      "Epoch: 80 -> Loss: 0.223507240415\n",
      "Epoch: 80 -> Test Accuracy: 81.1\n",
      "[81, 60] loss: 0.223\n",
      "[81, 120] loss: 0.231\n",
      "[81, 180] loss: 0.219\n",
      "[81, 240] loss: 0.231\n",
      "[81, 300] loss: 0.221\n",
      "[81, 360] loss: 0.231\n",
      "Epoch: 81 -> Loss: 0.218839645386\n",
      "Epoch: 81 -> Test Accuracy: 81.06\n",
      "[82, 60] loss: 0.232\n",
      "[82, 120] loss: 0.228\n",
      "[82, 180] loss: 0.235\n",
      "[82, 240] loss: 0.232\n",
      "[82, 300] loss: 0.231\n",
      "[82, 360] loss: 0.219\n",
      "Epoch: 82 -> Loss: 0.171839207411\n",
      "Epoch: 82 -> Test Accuracy: 81.14\n",
      "[83, 60] loss: 0.224\n",
      "[83, 120] loss: 0.226\n",
      "[83, 180] loss: 0.228\n",
      "[83, 240] loss: 0.218\n",
      "[83, 300] loss: 0.225\n",
      "[83, 360] loss: 0.233\n",
      "Epoch: 83 -> Loss: 0.196771472692\n",
      "Epoch: 83 -> Test Accuracy: 80.91\n",
      "[84, 60] loss: 0.229\n",
      "[84, 120] loss: 0.221\n",
      "[84, 180] loss: 0.232\n",
      "[84, 240] loss: 0.222\n",
      "[84, 300] loss: 0.227\n",
      "[84, 360] loss: 0.220\n",
      "Epoch: 84 -> Loss: 0.252200067043\n",
      "Epoch: 84 -> Test Accuracy: 81.08\n",
      "[85, 60] loss: 0.224\n",
      "[85, 120] loss: 0.221\n",
      "[85, 180] loss: 0.234\n",
      "[85, 240] loss: 0.232\n",
      "[85, 300] loss: 0.232\n",
      "[85, 360] loss: 0.229\n",
      "Epoch: 85 -> Loss: 0.37342685461\n",
      "Epoch: 85 -> Test Accuracy: 81.3\n",
      "[86, 60] loss: 0.226\n",
      "[86, 120] loss: 0.228\n",
      "[86, 180] loss: 0.226\n",
      "[86, 240] loss: 0.221\n",
      "[86, 300] loss: 0.232\n",
      "[86, 360] loss: 0.225\n",
      "Epoch: 86 -> Loss: 0.213160425425\n",
      "Epoch: 86 -> Test Accuracy: 81.06\n",
      "[87, 60] loss: 0.227\n",
      "[87, 120] loss: 0.225\n",
      "[87, 180] loss: 0.218\n",
      "[87, 240] loss: 0.224\n",
      "[87, 300] loss: 0.226\n",
      "[87, 360] loss: 0.211\n",
      "Epoch: 87 -> Loss: 0.312127888203\n",
      "Epoch: 87 -> Test Accuracy: 80.99\n",
      "[88, 60] loss: 0.222\n",
      "[88, 120] loss: 0.215\n",
      "[88, 180] loss: 0.231\n",
      "[88, 240] loss: 0.213\n",
      "[88, 300] loss: 0.222\n",
      "[88, 360] loss: 0.226\n",
      "Epoch: 88 -> Loss: 0.155345708132\n",
      "Epoch: 88 -> Test Accuracy: 81.02\n",
      "[89, 60] loss: 0.216\n",
      "[89, 120] loss: 0.212\n",
      "[89, 180] loss: 0.231\n",
      "[89, 240] loss: 0.214\n",
      "[89, 300] loss: 0.215\n",
      "[89, 360] loss: 0.220\n",
      "Epoch: 89 -> Loss: 0.158442497253\n",
      "Epoch: 89 -> Test Accuracy: 81.19\n",
      "[90, 60] loss: 0.233\n",
      "[90, 120] loss: 0.227\n",
      "[90, 180] loss: 0.237\n",
      "[90, 240] loss: 0.221\n",
      "[90, 300] loss: 0.227\n",
      "[90, 360] loss: 0.210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 -> Loss: 0.103151679039\n",
      "Epoch: 90 -> Test Accuracy: 81.03\n",
      "[91, 60] loss: 0.232\n",
      "[91, 120] loss: 0.218\n",
      "[91, 180] loss: 0.219\n",
      "[91, 240] loss: 0.217\n",
      "[91, 300] loss: 0.227\n",
      "[91, 360] loss: 0.224\n",
      "Epoch: 91 -> Loss: 0.181434720755\n",
      "Epoch: 91 -> Test Accuracy: 81.03\n",
      "[92, 60] loss: 0.219\n",
      "[92, 120] loss: 0.219\n",
      "[92, 180] loss: 0.215\n",
      "[92, 240] loss: 0.214\n",
      "[92, 300] loss: 0.224\n",
      "[92, 360] loss: 0.229\n",
      "Epoch: 92 -> Loss: 0.398776292801\n",
      "Epoch: 92 -> Test Accuracy: 81.03\n",
      "[93, 60] loss: 0.211\n",
      "[93, 120] loss: 0.225\n",
      "[93, 180] loss: 0.221\n",
      "[93, 240] loss: 0.226\n",
      "[93, 300] loss: 0.210\n",
      "[93, 360] loss: 0.223\n",
      "Epoch: 93 -> Loss: 0.206774383783\n",
      "Epoch: 93 -> Test Accuracy: 81.14\n",
      "[94, 60] loss: 0.222\n",
      "[94, 120] loss: 0.220\n",
      "[94, 180] loss: 0.220\n",
      "[94, 240] loss: 0.213\n",
      "[94, 300] loss: 0.215\n",
      "[94, 360] loss: 0.225\n",
      "Epoch: 94 -> Loss: 0.2201487571\n",
      "Epoch: 94 -> Test Accuracy: 81.08\n",
      "[95, 60] loss: 0.208\n",
      "[95, 120] loss: 0.214\n",
      "[95, 180] loss: 0.226\n",
      "[95, 240] loss: 0.224\n",
      "[95, 300] loss: 0.224\n",
      "[95, 360] loss: 0.219\n",
      "Epoch: 95 -> Loss: 0.233086153865\n",
      "Epoch: 95 -> Test Accuracy: 80.79\n",
      "[96, 60] loss: 0.208\n",
      "[96, 120] loss: 0.217\n",
      "[96, 180] loss: 0.216\n",
      "[96, 240] loss: 0.231\n",
      "[96, 300] loss: 0.226\n",
      "[96, 360] loss: 0.217\n",
      "Epoch: 96 -> Loss: 0.228109329939\n",
      "Epoch: 96 -> Test Accuracy: 81.0\n",
      "[97, 60] loss: 0.213\n",
      "[97, 120] loss: 0.209\n",
      "[97, 180] loss: 0.215\n",
      "[97, 240] loss: 0.213\n",
      "[97, 300] loss: 0.217\n",
      "[97, 360] loss: 0.219\n",
      "Epoch: 97 -> Loss: 0.274395525455\n",
      "Epoch: 97 -> Test Accuracy: 80.99\n",
      "[98, 60] loss: 0.223\n",
      "[98, 120] loss: 0.209\n",
      "[98, 180] loss: 0.225\n",
      "[98, 240] loss: 0.213\n",
      "[98, 300] loss: 0.219\n",
      "[98, 360] loss: 0.221\n",
      "Epoch: 98 -> Loss: 0.255613148212\n",
      "Epoch: 98 -> Test Accuracy: 80.87\n",
      "[99, 60] loss: 0.214\n",
      "[99, 120] loss: 0.206\n",
      "[99, 180] loss: 0.211\n",
      "[99, 240] loss: 0.219\n",
      "[99, 300] loss: 0.219\n",
      "[99, 360] loss: 0.217\n",
      "Epoch: 99 -> Loss: 0.352199852467\n",
      "Epoch: 99 -> Test Accuracy: 80.94\n",
      "[100, 60] loss: 0.214\n",
      "[100, 120] loss: 0.207\n",
      "[100, 180] loss: 0.220\n",
      "[100, 240] loss: 0.210\n",
      "[100, 300] loss: 0.196\n",
      "[100, 360] loss: 0.208\n",
      "Epoch: 100 -> Loss: 0.229190021753\n",
      "Epoch: 100 -> Test Accuracy: 80.99\n",
      "Finished Training\n",
      "[1, 60] loss: 2.806\n",
      "[1, 120] loss: 2.019\n",
      "[1, 180] loss: 1.976\n",
      "[1, 240] loss: 1.940\n",
      "[1, 300] loss: 1.899\n",
      "[1, 360] loss: 1.875\n",
      "Epoch: 1 -> Loss: 1.76505434513\n",
      "Epoch: 1 -> Test Accuracy: 30.36\n",
      "[2, 60] loss: 1.839\n",
      "[2, 120] loss: 1.841\n",
      "[2, 180] loss: 1.832\n",
      "[2, 240] loss: 1.808\n",
      "[2, 300] loss: 1.814\n",
      "[2, 360] loss: 1.802\n",
      "Epoch: 2 -> Loss: 1.74067950249\n",
      "Epoch: 2 -> Test Accuracy: 32.02\n",
      "[3, 60] loss: 1.789\n",
      "[3, 120] loss: 1.797\n",
      "[3, 180] loss: 1.772\n",
      "[3, 240] loss: 1.751\n",
      "[3, 300] loss: 1.769\n",
      "[3, 360] loss: 1.775\n",
      "Epoch: 3 -> Loss: 1.68059158325\n",
      "Epoch: 3 -> Test Accuracy: 33.39\n",
      "[4, 60] loss: 1.753\n",
      "[4, 120] loss: 1.752\n",
      "[4, 180] loss: 1.760\n",
      "[4, 240] loss: 1.750\n",
      "[4, 300] loss: 1.736\n",
      "[4, 360] loss: 1.745\n",
      "Epoch: 4 -> Loss: 1.65094923973\n",
      "Epoch: 4 -> Test Accuracy: 33.07\n",
      "[5, 60] loss: 1.730\n",
      "[5, 120] loss: 1.746\n",
      "[5, 180] loss: 1.733\n",
      "[5, 240] loss: 1.738\n",
      "[5, 300] loss: 1.715\n",
      "[5, 360] loss: 1.737\n",
      "Epoch: 5 -> Loss: 2.04843187332\n",
      "Epoch: 5 -> Test Accuracy: 34.86\n",
      "[6, 60] loss: 1.731\n",
      "[6, 120] loss: 1.722\n",
      "[6, 180] loss: 1.715\n",
      "[6, 240] loss: 1.723\n",
      "[6, 300] loss: 1.714\n",
      "[6, 360] loss: 1.705\n",
      "Epoch: 6 -> Loss: 1.80668032169\n",
      "Epoch: 6 -> Test Accuracy: 34.42\n",
      "[7, 60] loss: 1.708\n",
      "[7, 120] loss: 1.709\n",
      "[7, 180] loss: 1.710\n",
      "[7, 240] loss: 1.714\n",
      "[7, 300] loss: 1.705\n",
      "[7, 360] loss: 1.703\n",
      "Epoch: 7 -> Loss: 1.6861846447\n",
      "Epoch: 7 -> Test Accuracy: 35.43\n",
      "[8, 60] loss: 1.700\n",
      "[8, 120] loss: 1.696\n",
      "[8, 180] loss: 1.694\n",
      "[8, 240] loss: 1.691\n",
      "[8, 300] loss: 1.687\n",
      "[8, 360] loss: 1.692\n",
      "Epoch: 8 -> Loss: 1.62721788883\n",
      "Epoch: 8 -> Test Accuracy: 35.33\n",
      "[9, 60] loss: 1.691\n",
      "[9, 120] loss: 1.704\n",
      "[9, 180] loss: 1.693\n",
      "[9, 240] loss: 1.683\n",
      "[9, 300] loss: 1.681\n",
      "[9, 360] loss: 1.703\n",
      "Epoch: 9 -> Loss: 1.89050638676\n",
      "Epoch: 9 -> Test Accuracy: 34.32\n",
      "[10, 60] loss: 1.694\n",
      "[10, 120] loss: 1.686\n",
      "[10, 180] loss: 1.687\n",
      "[10, 240] loss: 1.714\n",
      "[10, 300] loss: 1.701\n",
      "[10, 360] loss: 1.685\n",
      "Epoch: 10 -> Loss: 1.65653538704\n",
      "Epoch: 10 -> Test Accuracy: 34.54\n",
      "[11, 60] loss: 1.693\n",
      "[11, 120] loss: 1.678\n",
      "[11, 180] loss: 1.684\n",
      "[11, 240] loss: 1.697\n",
      "[11, 300] loss: 1.683\n",
      "[11, 360] loss: 1.669\n",
      "Epoch: 11 -> Loss: 1.8213313818\n",
      "Epoch: 11 -> Test Accuracy: 35.76\n",
      "[12, 60] loss: 1.674\n",
      "[12, 120] loss: 1.692\n",
      "[12, 180] loss: 1.685\n",
      "[12, 240] loss: 1.687\n",
      "[12, 300] loss: 1.682\n",
      "[12, 360] loss: 1.687\n",
      "Epoch: 12 -> Loss: 1.48024129868\n",
      "Epoch: 12 -> Test Accuracy: 35.11\n",
      "[13, 60] loss: 1.672\n",
      "[13, 120] loss: 1.677\n",
      "[13, 180] loss: 1.670\n",
      "[13, 240] loss: 1.702\n",
      "[13, 300] loss: 1.675\n",
      "[13, 360] loss: 1.680\n",
      "Epoch: 13 -> Loss: 1.70736503601\n",
      "Epoch: 13 -> Test Accuracy: 35.19\n",
      "[14, 60] loss: 1.666\n",
      "[14, 120] loss: 1.700\n",
      "[14, 180] loss: 1.679\n",
      "[14, 240] loss: 1.670\n",
      "[14, 300] loss: 1.675\n",
      "[14, 360] loss: 1.666\n",
      "Epoch: 14 -> Loss: 1.62002182007\n",
      "Epoch: 14 -> Test Accuracy: 36.02\n",
      "[15, 60] loss: 1.666\n",
      "[15, 120] loss: 1.676\n",
      "[15, 180] loss: 1.669\n",
      "[15, 240] loss: 1.661\n",
      "[15, 300] loss: 1.697\n",
      "[15, 360] loss: 1.677\n",
      "Epoch: 15 -> Loss: 1.79775691032\n",
      "Epoch: 15 -> Test Accuracy: 35.25\n",
      "[16, 60] loss: 1.671\n",
      "[16, 120] loss: 1.647\n",
      "[16, 180] loss: 1.677\n",
      "[16, 240] loss: 1.670\n",
      "[16, 300] loss: 1.677\n",
      "[16, 360] loss: 1.676\n",
      "Epoch: 16 -> Loss: 1.59944736958\n",
      "Epoch: 16 -> Test Accuracy: 35.06\n",
      "[17, 60] loss: 1.676\n",
      "[17, 120] loss: 1.670\n",
      "[17, 180] loss: 1.670\n",
      "[17, 240] loss: 1.669\n",
      "[17, 300] loss: 1.698\n",
      "[17, 360] loss: 1.666\n",
      "Epoch: 17 -> Loss: 1.6018550396\n",
      "Epoch: 17 -> Test Accuracy: 36.26\n",
      "[18, 60] loss: 1.646\n",
      "[18, 120] loss: 1.667\n",
      "[18, 180] loss: 1.665\n",
      "[18, 240] loss: 1.666\n",
      "[18, 300] loss: 1.658\n",
      "[18, 360] loss: 1.703\n",
      "Epoch: 18 -> Loss: 1.73076653481\n",
      "Epoch: 18 -> Test Accuracy: 35.56\n",
      "[19, 60] loss: 1.668\n",
      "[19, 120] loss: 1.647\n",
      "[19, 180] loss: 1.671\n",
      "[19, 240] loss: 1.662\n",
      "[19, 300] loss: 1.662\n",
      "[19, 360] loss: 1.669\n",
      "Epoch: 19 -> Loss: 1.71348440647\n",
      "Epoch: 19 -> Test Accuracy: 35.5\n",
      "[20, 60] loss: 1.670\n",
      "[20, 120] loss: 1.663\n",
      "[20, 180] loss: 1.671\n",
      "[20, 240] loss: 1.655\n",
      "[20, 300] loss: 1.663\n",
      "[20, 360] loss: 1.684\n",
      "Epoch: 20 -> Loss: 1.7868270874\n",
      "Epoch: 20 -> Test Accuracy: 35.74\n",
      "[21, 60] loss: 1.625\n",
      "[21, 120] loss: 1.598\n",
      "[21, 180] loss: 1.588\n",
      "[21, 240] loss: 1.576\n",
      "[21, 300] loss: 1.589\n",
      "[21, 360] loss: 1.580\n",
      "Epoch: 21 -> Loss: 1.73661637306\n",
      "Epoch: 21 -> Test Accuracy: 38.18\n",
      "[22, 60] loss: 1.555\n",
      "[22, 120] loss: 1.567\n",
      "[22, 180] loss: 1.553\n",
      "[22, 240] loss: 1.577\n",
      "[22, 300] loss: 1.557\n",
      "[22, 360] loss: 1.568\n",
      "Epoch: 22 -> Loss: 1.62838578224\n",
      "Epoch: 22 -> Test Accuracy: 37.97\n",
      "[23, 60] loss: 1.541\n",
      "[23, 120] loss: 1.557\n",
      "[23, 180] loss: 1.559\n",
      "[23, 240] loss: 1.571\n",
      "[23, 300] loss: 1.540\n",
      "[23, 360] loss: 1.550\n",
      "Epoch: 23 -> Loss: 1.51806807518\n",
      "Epoch: 23 -> Test Accuracy: 39.35\n",
      "[24, 60] loss: 1.553\n",
      "[24, 120] loss: 1.544\n",
      "[24, 180] loss: 1.527\n",
      "[24, 240] loss: 1.527\n",
      "[24, 300] loss: 1.561\n",
      "[24, 360] loss: 1.548\n",
      "Epoch: 24 -> Loss: 1.64017295837\n",
      "Epoch: 24 -> Test Accuracy: 39.16\n",
      "[25, 60] loss: 1.535\n",
      "[25, 120] loss: 1.540\n",
      "[25, 180] loss: 1.536\n",
      "[25, 240] loss: 1.524\n",
      "[25, 300] loss: 1.541\n",
      "[25, 360] loss: 1.528\n",
      "Epoch: 25 -> Loss: 1.50725245476\n",
      "Epoch: 25 -> Test Accuracy: 38.38\n",
      "[26, 60] loss: 1.531\n",
      "[26, 120] loss: 1.540\n",
      "[26, 180] loss: 1.542\n",
      "[26, 240] loss: 1.523\n",
      "[26, 300] loss: 1.552\n",
      "[26, 360] loss: 1.550\n",
      "Epoch: 26 -> Loss: 1.38375413418\n",
      "Epoch: 26 -> Test Accuracy: 39.1\n",
      "[27, 60] loss: 1.529\n",
      "[27, 120] loss: 1.556\n",
      "[27, 180] loss: 1.540\n",
      "[27, 240] loss: 1.531\n",
      "[27, 300] loss: 1.532\n",
      "[27, 360] loss: 1.546\n",
      "Epoch: 27 -> Loss: 1.442912817\n",
      "Epoch: 27 -> Test Accuracy: 39.41\n",
      "[28, 60] loss: 1.530\n",
      "[28, 120] loss: 1.543\n",
      "[28, 180] loss: 1.537\n",
      "[28, 240] loss: 1.529\n",
      "[28, 300] loss: 1.537\n",
      "[28, 360] loss: 1.550\n",
      "Epoch: 28 -> Loss: 1.54566931725\n",
      "Epoch: 28 -> Test Accuracy: 39.16\n",
      "[29, 60] loss: 1.527\n",
      "[29, 120] loss: 1.532\n",
      "[29, 180] loss: 1.531\n",
      "[29, 240] loss: 1.541\n",
      "[29, 300] loss: 1.526\n",
      "[29, 360] loss: 1.535\n",
      "Epoch: 29 -> Loss: 1.62857055664\n",
      "Epoch: 29 -> Test Accuracy: 39.26\n",
      "[30, 60] loss: 1.524\n",
      "[30, 120] loss: 1.528\n",
      "[30, 180] loss: 1.526\n",
      "[30, 240] loss: 1.528\n",
      "[30, 300] loss: 1.539\n",
      "[30, 360] loss: 1.535\n",
      "Epoch: 30 -> Loss: 1.58898615837\n",
      "Epoch: 30 -> Test Accuracy: 39.82\n",
      "[31, 60] loss: 1.539\n",
      "[31, 120] loss: 1.528\n",
      "[31, 180] loss: 1.522\n",
      "[31, 240] loss: 1.530\n",
      "[31, 300] loss: 1.532\n",
      "[31, 360] loss: 1.533\n",
      "Epoch: 31 -> Loss: 1.76898217201\n",
      "Epoch: 31 -> Test Accuracy: 39.76\n",
      "[32, 60] loss: 1.521\n",
      "[32, 120] loss: 1.524\n",
      "[32, 180] loss: 1.524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 240] loss: 1.547\n",
      "[32, 300] loss: 1.545\n",
      "[32, 360] loss: 1.528\n",
      "Epoch: 32 -> Loss: 1.68761444092\n",
      "Epoch: 32 -> Test Accuracy: 39.89\n",
      "[33, 60] loss: 1.525\n",
      "[33, 120] loss: 1.537\n",
      "[33, 180] loss: 1.544\n",
      "[33, 240] loss: 1.517\n",
      "[33, 300] loss: 1.535\n",
      "[33, 360] loss: 1.534\n",
      "Epoch: 33 -> Loss: 1.62631833553\n",
      "Epoch: 33 -> Test Accuracy: 39.46\n",
      "[34, 60] loss: 1.530\n",
      "[34, 120] loss: 1.532\n",
      "[34, 180] loss: 1.514\n",
      "[34, 240] loss: 1.529\n",
      "[34, 300] loss: 1.510\n",
      "[34, 360] loss: 1.533\n",
      "Epoch: 34 -> Loss: 1.60305440426\n",
      "Epoch: 34 -> Test Accuracy: 38.84\n",
      "[35, 60] loss: 1.527\n",
      "[35, 120] loss: 1.520\n",
      "[35, 180] loss: 1.524\n",
      "[35, 240] loss: 1.515\n",
      "[35, 300] loss: 1.540\n",
      "[35, 360] loss: 1.532\n",
      "Epoch: 35 -> Loss: 1.37478029728\n",
      "Epoch: 35 -> Test Accuracy: 40.13\n",
      "[36, 60] loss: 1.527\n",
      "[36, 120] loss: 1.514\n",
      "[36, 180] loss: 1.526\n",
      "[36, 240] loss: 1.534\n",
      "[36, 300] loss: 1.519\n",
      "[36, 360] loss: 1.529\n",
      "Epoch: 36 -> Loss: 1.59059739113\n",
      "Epoch: 36 -> Test Accuracy: 39.49\n",
      "[37, 60] loss: 1.505\n",
      "[37, 120] loss: 1.533\n",
      "[37, 180] loss: 1.555\n",
      "[37, 240] loss: 1.533\n",
      "[37, 300] loss: 1.508\n",
      "[37, 360] loss: 1.523\n",
      "Epoch: 37 -> Loss: 1.47796046734\n",
      "Epoch: 37 -> Test Accuracy: 39.08\n",
      "[38, 60] loss: 1.531\n",
      "[38, 120] loss: 1.519\n",
      "[38, 180] loss: 1.514\n",
      "[38, 240] loss: 1.525\n",
      "[38, 300] loss: 1.514\n",
      "[38, 360] loss: 1.535\n",
      "Epoch: 38 -> Loss: 1.63189911842\n",
      "Epoch: 38 -> Test Accuracy: 39.81\n",
      "[39, 60] loss: 1.533\n",
      "[39, 120] loss: 1.515\n",
      "[39, 180] loss: 1.527\n",
      "[39, 240] loss: 1.522\n",
      "[39, 300] loss: 1.516\n",
      "[39, 360] loss: 1.513\n",
      "Epoch: 39 -> Loss: 1.5201728344\n",
      "Epoch: 39 -> Test Accuracy: 39.38\n",
      "[40, 60] loss: 1.501\n",
      "[40, 120] loss: 1.518\n",
      "[40, 180] loss: 1.519\n",
      "[40, 240] loss: 1.520\n",
      "[40, 300] loss: 1.536\n",
      "[40, 360] loss: 1.544\n",
      "Epoch: 40 -> Loss: 1.47331678867\n",
      "Epoch: 40 -> Test Accuracy: 39.47\n",
      "[41, 60] loss: 1.494\n",
      "[41, 120] loss: 1.483\n",
      "[41, 180] loss: 1.485\n",
      "[41, 240] loss: 1.467\n",
      "[41, 300] loss: 1.466\n",
      "[41, 360] loss: 1.469\n",
      "Epoch: 41 -> Loss: 1.44375741482\n",
      "Epoch: 41 -> Test Accuracy: 41.29\n",
      "[42, 60] loss: 1.460\n",
      "[42, 120] loss: 1.469\n",
      "[42, 180] loss: 1.457\n",
      "[42, 240] loss: 1.436\n",
      "[42, 300] loss: 1.435\n",
      "[42, 360] loss: 1.468\n",
      "Epoch: 42 -> Loss: 1.46078777313\n",
      "Epoch: 42 -> Test Accuracy: 41.45\n",
      "[43, 60] loss: 1.450\n",
      "[43, 120] loss: 1.442\n",
      "[43, 180] loss: 1.455\n",
      "[43, 240] loss: 1.457\n",
      "[43, 300] loss: 1.442\n",
      "[43, 360] loss: 1.465\n",
      "Epoch: 43 -> Loss: 1.43283438683\n",
      "Epoch: 43 -> Test Accuracy: 41.53\n",
      "[44, 60] loss: 1.463\n",
      "[44, 120] loss: 1.440\n",
      "[44, 180] loss: 1.431\n",
      "[44, 240] loss: 1.438\n",
      "[44, 300] loss: 1.460\n",
      "[44, 360] loss: 1.437\n",
      "Epoch: 44 -> Loss: 1.37233448029\n",
      "Epoch: 44 -> Test Accuracy: 41.34\n",
      "[45, 60] loss: 1.449\n",
      "[45, 120] loss: 1.438\n",
      "[45, 180] loss: 1.460\n",
      "[45, 240] loss: 1.448\n",
      "[45, 300] loss: 1.446\n",
      "[45, 360] loss: 1.451\n",
      "Epoch: 45 -> Loss: 1.70065975189\n",
      "Epoch: 45 -> Test Accuracy: 41.54\n",
      "[46, 60] loss: 1.458\n",
      "[46, 120] loss: 1.420\n",
      "[46, 180] loss: 1.430\n",
      "[46, 240] loss: 1.422\n",
      "[46, 300] loss: 1.458\n",
      "[46, 360] loss: 1.427\n",
      "Epoch: 46 -> Loss: 1.39692127705\n",
      "Epoch: 46 -> Test Accuracy: 41.95\n",
      "[47, 60] loss: 1.441\n",
      "[47, 120] loss: 1.427\n",
      "[47, 180] loss: 1.394\n",
      "[47, 240] loss: 1.415\n",
      "[47, 300] loss: 1.441\n",
      "[47, 360] loss: 1.435\n",
      "Epoch: 47 -> Loss: 1.72615838051\n",
      "Epoch: 47 -> Test Accuracy: 41.92\n",
      "[48, 60] loss: 1.446\n",
      "[48, 120] loss: 1.405\n",
      "[48, 180] loss: 1.409\n",
      "[48, 240] loss: 1.408\n",
      "[48, 300] loss: 1.433\n",
      "[48, 360] loss: 1.432\n",
      "Epoch: 48 -> Loss: 1.46553349495\n",
      "Epoch: 48 -> Test Accuracy: 42.03\n",
      "[49, 60] loss: 1.404\n",
      "[49, 120] loss: 1.418\n",
      "[49, 180] loss: 1.428\n",
      "[49, 240] loss: 1.433\n",
      "[49, 300] loss: 1.435\n",
      "[49, 360] loss: 1.428\n",
      "Epoch: 49 -> Loss: 1.25260436535\n",
      "Epoch: 49 -> Test Accuracy: 42.25\n",
      "[50, 60] loss: 1.413\n",
      "[50, 120] loss: 1.411\n",
      "[50, 180] loss: 1.420\n",
      "[50, 240] loss: 1.423\n",
      "[50, 300] loss: 1.397\n",
      "[50, 360] loss: 1.406\n",
      "Epoch: 50 -> Loss: 1.35241687298\n",
      "Epoch: 50 -> Test Accuracy: 42.15\n",
      "[51, 60] loss: 1.417\n",
      "[51, 120] loss: 1.415\n",
      "[51, 180] loss: 1.434\n",
      "[51, 240] loss: 1.410\n",
      "[51, 300] loss: 1.423\n",
      "[51, 360] loss: 1.411\n",
      "Epoch: 51 -> Loss: 1.20157754421\n",
      "Epoch: 51 -> Test Accuracy: 42.13\n",
      "[52, 60] loss: 1.430\n",
      "[52, 120] loss: 1.436\n",
      "[52, 180] loss: 1.400\n",
      "[52, 240] loss: 1.422\n",
      "[52, 300] loss: 1.425\n",
      "[52, 360] loss: 1.407\n",
      "Epoch: 52 -> Loss: 1.30994558334\n",
      "Epoch: 52 -> Test Accuracy: 42.43\n",
      "[53, 60] loss: 1.423\n",
      "[53, 120] loss: 1.417\n",
      "[53, 180] loss: 1.422\n",
      "[53, 240] loss: 1.426\n",
      "[53, 300] loss: 1.412\n",
      "[53, 360] loss: 1.414\n",
      "Epoch: 53 -> Loss: 1.66063094139\n",
      "Epoch: 53 -> Test Accuracy: 42.53\n",
      "[54, 60] loss: 1.424\n",
      "[54, 120] loss: 1.409\n",
      "[54, 180] loss: 1.434\n",
      "[54, 240] loss: 1.423\n",
      "[54, 300] loss: 1.418\n",
      "[54, 360] loss: 1.418\n",
      "Epoch: 54 -> Loss: 1.31610047817\n",
      "Epoch: 54 -> Test Accuracy: 42.38\n",
      "[55, 60] loss: 1.409\n",
      "[55, 120] loss: 1.427\n",
      "[55, 180] loss: 1.419\n",
      "[55, 240] loss: 1.416\n",
      "[55, 300] loss: 1.417\n",
      "[55, 360] loss: 1.401\n",
      "Epoch: 55 -> Loss: 1.46491396427\n",
      "Epoch: 55 -> Test Accuracy: 42.29\n",
      "[56, 60] loss: 1.415\n",
      "[56, 120] loss: 1.411\n",
      "[56, 180] loss: 1.417\n",
      "[56, 240] loss: 1.413\n",
      "[56, 300] loss: 1.407\n",
      "[56, 360] loss: 1.408\n",
      "Epoch: 56 -> Loss: 1.38909506798\n",
      "Epoch: 56 -> Test Accuracy: 42.32\n",
      "[57, 60] loss: 1.413\n",
      "[57, 120] loss: 1.422\n",
      "[57, 180] loss: 1.407\n",
      "[57, 240] loss: 1.425\n",
      "[57, 300] loss: 1.411\n",
      "[57, 360] loss: 1.408\n",
      "Epoch: 57 -> Loss: 1.40994155407\n",
      "Epoch: 57 -> Test Accuracy: 42.69\n",
      "[58, 60] loss: 1.391\n",
      "[58, 120] loss: 1.400\n",
      "[58, 180] loss: 1.419\n",
      "[58, 240] loss: 1.407\n",
      "[58, 300] loss: 1.403\n",
      "[58, 360] loss: 1.437\n",
      "Epoch: 58 -> Loss: 1.50525999069\n",
      "Epoch: 58 -> Test Accuracy: 42.34\n",
      "[59, 60] loss: 1.407\n",
      "[59, 120] loss: 1.421\n",
      "[59, 180] loss: 1.416\n",
      "[59, 240] loss: 1.405\n",
      "[59, 300] loss: 1.405\n",
      "[59, 360] loss: 1.414\n",
      "Epoch: 59 -> Loss: 1.53800940514\n",
      "Epoch: 59 -> Test Accuracy: 42.27\n",
      "[60, 60] loss: 1.408\n",
      "[60, 120] loss: 1.425\n",
      "[60, 180] loss: 1.401\n",
      "[60, 240] loss: 1.422\n",
      "[60, 300] loss: 1.404\n",
      "[60, 360] loss: 1.413\n",
      "Epoch: 60 -> Loss: 1.28074514866\n",
      "Epoch: 60 -> Test Accuracy: 42.46\n",
      "[61, 60] loss: 1.421\n",
      "[61, 120] loss: 1.420\n",
      "[61, 180] loss: 1.391\n",
      "[61, 240] loss: 1.410\n",
      "[61, 300] loss: 1.424\n",
      "[61, 360] loss: 1.418\n",
      "Epoch: 61 -> Loss: 1.35327446461\n",
      "Epoch: 61 -> Test Accuracy: 42.39\n",
      "[62, 60] loss: 1.416\n",
      "[62, 120] loss: 1.398\n",
      "[62, 180] loss: 1.413\n",
      "[62, 240] loss: 1.403\n",
      "[62, 300] loss: 1.388\n",
      "[62, 360] loss: 1.407\n",
      "Epoch: 62 -> Loss: 1.43690466881\n",
      "Epoch: 62 -> Test Accuracy: 42.55\n",
      "[63, 60] loss: 1.411\n",
      "[63, 120] loss: 1.397\n",
      "[63, 180] loss: 1.394\n",
      "[63, 240] loss: 1.417\n",
      "[63, 300] loss: 1.405\n",
      "[63, 360] loss: 1.397\n",
      "Epoch: 63 -> Loss: 1.42931520939\n",
      "Epoch: 63 -> Test Accuracy: 42.39\n",
      "[64, 60] loss: 1.387\n",
      "[64, 120] loss: 1.406\n",
      "[64, 180] loss: 1.418\n",
      "[64, 240] loss: 1.398\n",
      "[64, 300] loss: 1.410\n",
      "[64, 360] loss: 1.389\n",
      "Epoch: 64 -> Loss: 1.18174874783\n",
      "Epoch: 64 -> Test Accuracy: 42.46\n",
      "[65, 60] loss: 1.410\n",
      "[65, 120] loss: 1.421\n",
      "[65, 180] loss: 1.397\n",
      "[65, 240] loss: 1.416\n",
      "[65, 300] loss: 1.403\n",
      "[65, 360] loss: 1.393\n",
      "Epoch: 65 -> Loss: 1.42912828922\n",
      "Epoch: 65 -> Test Accuracy: 42.65\n",
      "[66, 60] loss: 1.408\n",
      "[66, 120] loss: 1.415\n",
      "[66, 180] loss: 1.384\n",
      "[66, 240] loss: 1.412\n",
      "[66, 300] loss: 1.398\n",
      "[66, 360] loss: 1.405\n",
      "Epoch: 66 -> Loss: 1.48204827309\n",
      "Epoch: 66 -> Test Accuracy: 42.77\n",
      "[67, 60] loss: 1.395\n",
      "[67, 120] loss: 1.400\n",
      "[67, 180] loss: 1.389\n",
      "[67, 240] loss: 1.401\n",
      "[67, 300] loss: 1.409\n",
      "[67, 360] loss: 1.405\n",
      "Epoch: 67 -> Loss: 1.41127169132\n",
      "Epoch: 67 -> Test Accuracy: 42.73\n",
      "[68, 60] loss: 1.383\n",
      "[68, 120] loss: 1.430\n",
      "[68, 180] loss: 1.388\n",
      "[68, 240] loss: 1.409\n",
      "[68, 300] loss: 1.417\n",
      "[68, 360] loss: 1.405\n",
      "Epoch: 68 -> Loss: 1.15867686272\n",
      "Epoch: 68 -> Test Accuracy: 42.61\n",
      "[69, 60] loss: 1.419\n",
      "[69, 120] loss: 1.383\n",
      "[69, 180] loss: 1.400\n",
      "[69, 240] loss: 1.420\n",
      "[69, 300] loss: 1.388\n",
      "[69, 360] loss: 1.399\n",
      "Epoch: 69 -> Loss: 1.28681159019\n",
      "Epoch: 69 -> Test Accuracy: 42.79\n",
      "[70, 60] loss: 1.392\n",
      "[70, 120] loss: 1.399\n",
      "[70, 180] loss: 1.408\n",
      "[70, 240] loss: 1.403\n",
      "[70, 300] loss: 1.396\n",
      "[70, 360] loss: 1.405\n",
      "Epoch: 70 -> Loss: 1.43295454979\n",
      "Epoch: 70 -> Test Accuracy: 42.76\n",
      "[71, 60] loss: 1.396\n",
      "[71, 120] loss: 1.425\n",
      "[71, 180] loss: 1.400\n",
      "[71, 240] loss: 1.395\n",
      "[71, 300] loss: 1.401\n",
      "[71, 360] loss: 1.396\n",
      "Epoch: 71 -> Loss: 1.50003004074\n",
      "Epoch: 71 -> Test Accuracy: 42.73\n",
      "[72, 60] loss: 1.417\n",
      "[72, 120] loss: 1.402\n",
      "[72, 180] loss: 1.392\n",
      "[72, 240] loss: 1.413\n",
      "[72, 300] loss: 1.385\n",
      "[72, 360] loss: 1.394\n",
      "Epoch: 72 -> Loss: 1.24273324013\n",
      "Epoch: 72 -> Test Accuracy: 42.39\n",
      "[73, 60] loss: 1.389\n",
      "[73, 120] loss: 1.410\n",
      "[73, 180] loss: 1.406\n",
      "[73, 240] loss: 1.417\n",
      "[73, 300] loss: 1.396\n",
      "[73, 360] loss: 1.377\n",
      "Epoch: 73 -> Loss: 1.3600884676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 -> Test Accuracy: 42.86\n",
      "[74, 60] loss: 1.398\n",
      "[74, 120] loss: 1.410\n",
      "[74, 180] loss: 1.408\n",
      "[74, 240] loss: 1.403\n",
      "[74, 300] loss: 1.386\n",
      "[74, 360] loss: 1.395\n",
      "Epoch: 74 -> Loss: 1.50504624844\n",
      "Epoch: 74 -> Test Accuracy: 42.6\n",
      "[75, 60] loss: 1.406\n",
      "[75, 120] loss: 1.394\n",
      "[75, 180] loss: 1.406\n",
      "[75, 240] loss: 1.406\n",
      "[75, 300] loss: 1.394\n",
      "[75, 360] loss: 1.401\n",
      "Epoch: 75 -> Loss: 1.38171458244\n",
      "Epoch: 75 -> Test Accuracy: 42.78\n",
      "[76, 60] loss: 1.386\n",
      "[76, 120] loss: 1.394\n",
      "[76, 180] loss: 1.402\n",
      "[76, 240] loss: 1.416\n",
      "[76, 300] loss: 1.393\n",
      "[76, 360] loss: 1.393\n",
      "Epoch: 76 -> Loss: 1.5106703043\n",
      "Epoch: 76 -> Test Accuracy: 42.8\n",
      "[77, 60] loss: 1.398\n",
      "[77, 120] loss: 1.383\n",
      "[77, 180] loss: 1.393\n",
      "[77, 240] loss: 1.400\n",
      "[77, 300] loss: 1.401\n",
      "[77, 360] loss: 1.405\n",
      "Epoch: 77 -> Loss: 1.49361693859\n",
      "Epoch: 77 -> Test Accuracy: 42.83\n",
      "[78, 60] loss: 1.399\n",
      "[78, 120] loss: 1.377\n",
      "[78, 180] loss: 1.412\n",
      "[78, 240] loss: 1.395\n",
      "[78, 300] loss: 1.408\n",
      "[78, 360] loss: 1.405\n",
      "Epoch: 78 -> Loss: 1.49322938919\n",
      "Epoch: 78 -> Test Accuracy: 42.89\n",
      "[79, 60] loss: 1.403\n",
      "[79, 120] loss: 1.392\n",
      "[79, 180] loss: 1.385\n",
      "[79, 240] loss: 1.411\n",
      "[79, 300] loss: 1.392\n",
      "[79, 360] loss: 1.390\n",
      "Epoch: 79 -> Loss: 1.4295309782\n",
      "Epoch: 79 -> Test Accuracy: 42.79\n",
      "[80, 60] loss: 1.376\n",
      "[80, 120] loss: 1.390\n",
      "[80, 180] loss: 1.385\n",
      "[80, 240] loss: 1.404\n",
      "[80, 300] loss: 1.389\n",
      "[80, 360] loss: 1.402\n",
      "Epoch: 80 -> Loss: 1.51492500305\n",
      "Epoch: 80 -> Test Accuracy: 42.83\n",
      "[81, 60] loss: 1.395\n",
      "[81, 120] loss: 1.405\n",
      "[81, 180] loss: 1.381\n",
      "[81, 240] loss: 1.398\n",
      "[81, 300] loss: 1.386\n",
      "[81, 360] loss: 1.393\n",
      "Epoch: 81 -> Loss: 1.23707914352\n",
      "Epoch: 81 -> Test Accuracy: 43.02\n",
      "[82, 60] loss: 1.383\n",
      "[82, 120] loss: 1.413\n",
      "[82, 180] loss: 1.391\n",
      "[82, 240] loss: 1.402\n",
      "[82, 300] loss: 1.404\n",
      "[82, 360] loss: 1.384\n",
      "Epoch: 82 -> Loss: 1.37646770477\n",
      "Epoch: 82 -> Test Accuracy: 43.13\n",
      "[83, 60] loss: 1.387\n",
      "[83, 120] loss: 1.382\n",
      "[83, 180] loss: 1.394\n",
      "[83, 240] loss: 1.410\n",
      "[83, 300] loss: 1.413\n",
      "[83, 360] loss: 1.391\n",
      "Epoch: 83 -> Loss: 1.51926970482\n",
      "Epoch: 83 -> Test Accuracy: 43.11\n",
      "[84, 60] loss: 1.388\n",
      "[84, 120] loss: 1.391\n",
      "[84, 180] loss: 1.377\n",
      "[84, 240] loss: 1.398\n",
      "[84, 300] loss: 1.377\n",
      "[84, 360] loss: 1.392\n",
      "Epoch: 84 -> Loss: 1.45605123043\n",
      "Epoch: 84 -> Test Accuracy: 43.0\n",
      "[85, 60] loss: 1.390\n",
      "[85, 120] loss: 1.390\n",
      "[85, 180] loss: 1.382\n",
      "[85, 240] loss: 1.398\n",
      "[85, 300] loss: 1.371\n",
      "[85, 360] loss: 1.386\n",
      "Epoch: 85 -> Loss: 1.3946788311\n",
      "Epoch: 85 -> Test Accuracy: 42.84\n",
      "[86, 60] loss: 1.391\n",
      "[86, 120] loss: 1.375\n",
      "[86, 180] loss: 1.392\n",
      "[86, 240] loss: 1.404\n",
      "[86, 300] loss: 1.394\n",
      "[86, 360] loss: 1.405\n",
      "Epoch: 86 -> Loss: 1.42660856247\n",
      "Epoch: 86 -> Test Accuracy: 43.05\n",
      "[87, 60] loss: 1.380\n",
      "[87, 120] loss: 1.386\n",
      "[87, 180] loss: 1.378\n",
      "[87, 240] loss: 1.390\n",
      "[87, 300] loss: 1.397\n",
      "[87, 360] loss: 1.400\n",
      "Epoch: 87 -> Loss: 1.46219146252\n",
      "Epoch: 87 -> Test Accuracy: 42.86\n",
      "[88, 60] loss: 1.402\n",
      "[88, 120] loss: 1.403\n",
      "[88, 180] loss: 1.379\n",
      "[88, 240] loss: 1.384\n",
      "[88, 300] loss: 1.367\n",
      "[88, 360] loss: 1.401\n",
      "Epoch: 88 -> Loss: 1.37085366249\n",
      "Epoch: 88 -> Test Accuracy: 42.78\n",
      "[89, 60] loss: 1.382\n",
      "[89, 120] loss: 1.383\n",
      "[89, 180] loss: 1.396\n",
      "[89, 240] loss: 1.398\n",
      "[89, 300] loss: 1.396\n",
      "[89, 360] loss: 1.395\n",
      "Epoch: 89 -> Loss: 1.45259916782\n",
      "Epoch: 89 -> Test Accuracy: 43.2\n",
      "[90, 60] loss: 1.388\n",
      "[90, 120] loss: 1.391\n",
      "[90, 180] loss: 1.382\n",
      "[90, 240] loss: 1.391\n",
      "[90, 300] loss: 1.382\n",
      "[90, 360] loss: 1.390\n",
      "Epoch: 90 -> Loss: 1.32273614407\n",
      "Epoch: 90 -> Test Accuracy: 43.19\n",
      "[91, 60] loss: 1.396\n",
      "[91, 120] loss: 1.383\n",
      "[91, 180] loss: 1.393\n",
      "[91, 240] loss: 1.391\n",
      "[91, 300] loss: 1.387\n",
      "[91, 360] loss: 1.372\n",
      "Epoch: 91 -> Loss: 1.35736739635\n",
      "Epoch: 91 -> Test Accuracy: 43.08\n",
      "[92, 60] loss: 1.391\n",
      "[92, 120] loss: 1.369\n",
      "[92, 180] loss: 1.376\n",
      "[92, 240] loss: 1.412\n",
      "[92, 300] loss: 1.392\n",
      "[92, 360] loss: 1.382\n",
      "Epoch: 92 -> Loss: 1.25884985924\n",
      "Epoch: 92 -> Test Accuracy: 42.94\n",
      "[93, 60] loss: 1.379\n",
      "[93, 120] loss: 1.384\n",
      "[93, 180] loss: 1.419\n",
      "[93, 240] loss: 1.395\n",
      "[93, 300] loss: 1.390\n",
      "[93, 360] loss: 1.387\n",
      "Epoch: 93 -> Loss: 1.2289096117\n",
      "Epoch: 93 -> Test Accuracy: 43.06\n",
      "[94, 60] loss: 1.395\n",
      "[94, 120] loss: 1.378\n",
      "[94, 180] loss: 1.379\n",
      "[94, 240] loss: 1.390\n",
      "[94, 300] loss: 1.378\n",
      "[94, 360] loss: 1.371\n",
      "Epoch: 94 -> Loss: 1.30550777912\n",
      "Epoch: 94 -> Test Accuracy: 43.35\n",
      "[95, 60] loss: 1.391\n",
      "[95, 120] loss: 1.376\n",
      "[95, 180] loss: 1.389\n",
      "[95, 240] loss: 1.396\n",
      "[95, 300] loss: 1.379\n",
      "[95, 360] loss: 1.392\n",
      "Epoch: 95 -> Loss: 1.44906532764\n",
      "Epoch: 95 -> Test Accuracy: 42.99\n",
      "[96, 60] loss: 1.398\n",
      "[96, 120] loss: 1.385\n",
      "[96, 180] loss: 1.376\n",
      "[96, 240] loss: 1.388\n",
      "[96, 300] loss: 1.381\n",
      "[96, 360] loss: 1.393\n",
      "Epoch: 96 -> Loss: 1.36627852917\n",
      "Epoch: 96 -> Test Accuracy: 43.14\n",
      "[97, 60] loss: 1.384\n",
      "[97, 120] loss: 1.375\n",
      "[97, 180] loss: 1.377\n",
      "[97, 240] loss: 1.396\n",
      "[97, 300] loss: 1.378\n",
      "[97, 360] loss: 1.374\n",
      "Epoch: 97 -> Loss: 1.34797549248\n",
      "Epoch: 97 -> Test Accuracy: 43.19\n",
      "[98, 60] loss: 1.380\n",
      "[98, 120] loss: 1.419\n",
      "[98, 180] loss: 1.374\n",
      "[98, 240] loss: 1.372\n",
      "[98, 300] loss: 1.380\n",
      "[98, 360] loss: 1.388\n",
      "Epoch: 98 -> Loss: 1.37408971786\n",
      "Epoch: 98 -> Test Accuracy: 43.14\n",
      "[99, 60] loss: 1.381\n",
      "[99, 120] loss: 1.371\n",
      "[99, 180] loss: 1.395\n",
      "[99, 240] loss: 1.381\n",
      "[99, 300] loss: 1.379\n",
      "[99, 360] loss: 1.384\n",
      "Epoch: 99 -> Loss: 1.52033221722\n",
      "Epoch: 99 -> Test Accuracy: 43.19\n",
      "[100, 60] loss: 1.372\n",
      "[100, 120] loss: 1.376\n",
      "[100, 180] loss: 1.401\n",
      "[100, 240] loss: 1.365\n",
      "[100, 300] loss: 1.379\n",
      "[100, 360] loss: 1.383\n",
      "Epoch: 100 -> Loss: 1.36226952076\n",
      "Epoch: 100 -> Test Accuracy: 43.2\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train NonLinearClassifiers on feature map of net_3block\n",
    "block4_loss_log, _, block4_test_accuracy_log, _, _ = tr.train_all_blocks(4, 10, [0.1, 0.02, 0.004, 0.0008], \n",
    "    [20, 40, 45, 100], 0.9, 5e-4, net_block4, criterion, trainloader, None, testloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.376\n",
      "[1, 120] loss: 1.042\n",
      "[1, 180] loss: 0.913\n",
      "[1, 240] loss: 0.894\n",
      "[1, 300] loss: 0.837\n",
      "[1, 360] loss: 0.808\n",
      "Epoch: 1 -> Loss: 0.741010427475\n",
      "Epoch: 1 -> Test Accuracy: 69.36\n",
      "[2, 60] loss: 0.738\n",
      "[2, 120] loss: 0.732\n",
      "[2, 180] loss: 0.716\n",
      "[2, 240] loss: 0.703\n",
      "[2, 300] loss: 0.695\n",
      "[2, 360] loss: 0.686\n",
      "Epoch: 2 -> Loss: 0.697795510292\n",
      "Epoch: 2 -> Test Accuracy: 73.42\n",
      "[3, 60] loss: 0.626\n",
      "[3, 120] loss: 0.638\n",
      "[3, 180] loss: 0.637\n",
      "[3, 240] loss: 0.619\n",
      "[3, 300] loss: 0.629\n",
      "[3, 360] loss: 0.607\n",
      "Epoch: 3 -> Loss: 0.611978173256\n",
      "Epoch: 3 -> Test Accuracy: 74.3\n",
      "[4, 60] loss: 0.567\n",
      "[4, 120] loss: 0.581\n",
      "[4, 180] loss: 0.598\n",
      "[4, 240] loss: 0.586\n",
      "[4, 300] loss: 0.587\n",
      "[4, 360] loss: 0.582\n",
      "Epoch: 4 -> Loss: 0.599568843842\n",
      "Epoch: 4 -> Test Accuracy: 76.22\n",
      "[5, 60] loss: 0.537\n",
      "[5, 120] loss: 0.552\n",
      "[5, 180] loss: 0.546\n",
      "[5, 240] loss: 0.551\n",
      "[5, 300] loss: 0.560\n",
      "[5, 360] loss: 0.567\n",
      "Epoch: 5 -> Loss: 0.653165221214\n",
      "Epoch: 5 -> Test Accuracy: 76.33\n",
      "[6, 60] loss: 0.529\n",
      "[6, 120] loss: 0.512\n",
      "[6, 180] loss: 0.548\n",
      "[6, 240] loss: 0.531\n",
      "[6, 300] loss: 0.533\n",
      "[6, 360] loss: 0.538\n",
      "Epoch: 6 -> Loss: 0.57898658514\n",
      "Epoch: 6 -> Test Accuracy: 77.28\n",
      "[7, 60] loss: 0.512\n",
      "[7, 120] loss: 0.495\n",
      "[7, 180] loss: 0.530\n",
      "[7, 240] loss: 0.499\n",
      "[7, 300] loss: 0.520\n",
      "[7, 360] loss: 0.506\n",
      "Epoch: 7 -> Loss: 0.423888027668\n",
      "Epoch: 7 -> Test Accuracy: 76.63\n",
      "[8, 60] loss: 0.483\n",
      "[8, 120] loss: 0.503\n",
      "[8, 180] loss: 0.507\n",
      "[8, 240] loss: 0.498\n",
      "[8, 300] loss: 0.485\n",
      "[8, 360] loss: 0.506\n",
      "Epoch: 8 -> Loss: 0.650188982487\n",
      "Epoch: 8 -> Test Accuracy: 77.28\n",
      "[9, 60] loss: 0.478\n",
      "[9, 120] loss: 0.472\n",
      "[9, 180] loss: 0.497\n",
      "[9, 240] loss: 0.502\n",
      "[9, 300] loss: 0.509\n",
      "[9, 360] loss: 0.479\n",
      "Epoch: 9 -> Loss: 0.420323371887\n",
      "Epoch: 9 -> Test Accuracy: 78.66\n",
      "[10, 60] loss: 0.467\n",
      "[10, 120] loss: 0.467\n",
      "[10, 180] loss: 0.478\n",
      "[10, 240] loss: 0.466\n",
      "[10, 300] loss: 0.486\n",
      "[10, 360] loss: 0.498\n",
      "Epoch: 10 -> Loss: 0.381906092167\n",
      "Epoch: 10 -> Test Accuracy: 79.19\n",
      "[11, 60] loss: 0.448\n",
      "[11, 120] loss: 0.464\n",
      "[11, 180] loss: 0.464\n",
      "[11, 240] loss: 0.457\n",
      "[11, 300] loss: 0.473\n",
      "[11, 360] loss: 0.485\n",
      "Epoch: 11 -> Loss: 0.472647756338\n",
      "Epoch: 11 -> Test Accuracy: 77.22\n",
      "[12, 60] loss: 0.452\n",
      "[12, 120] loss: 0.451\n",
      "[12, 180] loss: 0.468\n",
      "[12, 240] loss: 0.465\n",
      "[12, 300] loss: 0.479\n",
      "[12, 360] loss: 0.475\n",
      "Epoch: 12 -> Loss: 0.511209130287\n",
      "Epoch: 12 -> Test Accuracy: 79.18\n",
      "[13, 60] loss: 0.427\n",
      "[13, 120] loss: 0.464\n",
      "[13, 180] loss: 0.456\n",
      "[13, 240] loss: 0.461\n",
      "[13, 300] loss: 0.461\n",
      "[13, 360] loss: 0.466\n",
      "Epoch: 13 -> Loss: 0.669395089149\n",
      "Epoch: 13 -> Test Accuracy: 80.09\n",
      "[14, 60] loss: 0.446\n",
      "[14, 120] loss: 0.436\n",
      "[14, 180] loss: 0.452\n",
      "[14, 240] loss: 0.454\n",
      "[14, 300] loss: 0.453\n",
      "[14, 360] loss: 0.477\n",
      "Epoch: 14 -> Loss: 0.3424012959\n",
      "Epoch: 14 -> Test Accuracy: 79.09\n",
      "[15, 60] loss: 0.441\n",
      "[15, 120] loss: 0.445\n",
      "[15, 180] loss: 0.452\n",
      "[15, 240] loss: 0.443\n",
      "[15, 300] loss: 0.457\n",
      "[15, 360] loss: 0.450\n",
      "Epoch: 15 -> Loss: 0.590542376041\n",
      "Epoch: 15 -> Test Accuracy: 79.24\n",
      "[16, 60] loss: 0.444\n",
      "[16, 120] loss: 0.458\n",
      "[16, 180] loss: 0.442\n",
      "[16, 240] loss: 0.445\n",
      "[16, 300] loss: 0.435\n",
      "[16, 360] loss: 0.444\n",
      "Epoch: 16 -> Loss: 0.474045842886\n",
      "Epoch: 16 -> Test Accuracy: 78.59\n",
      "[17, 60] loss: 0.406\n",
      "[17, 120] loss: 0.427\n",
      "[17, 180] loss: 0.432\n",
      "[17, 240] loss: 0.462\n",
      "[17, 300] loss: 0.456\n",
      "[17, 360] loss: 0.471\n",
      "Epoch: 17 -> Loss: 0.615619361401\n",
      "Epoch: 17 -> Test Accuracy: 80.44\n",
      "[18, 60] loss: 0.439\n",
      "[18, 120] loss: 0.442\n",
      "[18, 180] loss: 0.446\n",
      "[18, 240] loss: 0.416\n",
      "[18, 300] loss: 0.434\n",
      "[18, 360] loss: 0.454\n",
      "Epoch: 18 -> Loss: 0.628542304039\n",
      "Epoch: 18 -> Test Accuracy: 80.4\n",
      "[19, 60] loss: 0.421\n",
      "[19, 120] loss: 0.431\n",
      "[19, 180] loss: 0.442\n",
      "[19, 240] loss: 0.431\n",
      "[19, 300] loss: 0.427\n",
      "[19, 360] loss: 0.450\n",
      "Epoch: 19 -> Loss: 0.437790215015\n",
      "Epoch: 19 -> Test Accuracy: 80.15\n",
      "[20, 60] loss: 0.413\n",
      "[20, 120] loss: 0.418\n",
      "[20, 180] loss: 0.440\n",
      "[20, 240] loss: 0.435\n",
      "[20, 300] loss: 0.445\n",
      "[20, 360] loss: 0.454\n",
      "Epoch: 20 -> Loss: 0.475887209177\n",
      "Epoch: 20 -> Test Accuracy: 80.53\n",
      "[21, 60] loss: 0.419\n",
      "[21, 120] loss: 0.421\n",
      "[21, 180] loss: 0.425\n",
      "[21, 240] loss: 0.450\n",
      "[21, 300] loss: 0.436\n",
      "[21, 360] loss: 0.443\n",
      "Epoch: 21 -> Loss: 0.354378551245\n",
      "Epoch: 21 -> Test Accuracy: 79.91\n",
      "[22, 60] loss: 0.415\n",
      "[22, 120] loss: 0.416\n",
      "[22, 180] loss: 0.427\n",
      "[22, 240] loss: 0.433\n",
      "[22, 300] loss: 0.433\n",
      "[22, 360] loss: 0.430\n",
      "Epoch: 22 -> Loss: 0.693014025688\n",
      "Epoch: 22 -> Test Accuracy: 79.68\n",
      "[23, 60] loss: 0.402\n",
      "[23, 120] loss: 0.428\n",
      "[23, 180] loss: 0.413\n",
      "[23, 240] loss: 0.438\n",
      "[23, 300] loss: 0.440\n",
      "[23, 360] loss: 0.442\n",
      "Epoch: 23 -> Loss: 0.539694011211\n",
      "Epoch: 23 -> Test Accuracy: 79.87\n",
      "[24, 60] loss: 0.413\n",
      "[24, 120] loss: 0.415\n",
      "[24, 180] loss: 0.426\n",
      "[24, 240] loss: 0.429\n",
      "[24, 300] loss: 0.425\n",
      "[24, 360] loss: 0.435\n",
      "Epoch: 24 -> Loss: 0.40697479248\n",
      "Epoch: 24 -> Test Accuracy: 80.8\n",
      "[25, 60] loss: 0.412\n",
      "[25, 120] loss: 0.422\n",
      "[25, 180] loss: 0.410\n",
      "[25, 240] loss: 0.441\n",
      "[25, 300] loss: 0.445\n",
      "[25, 360] loss: 0.423\n",
      "Epoch: 25 -> Loss: 0.555473566055\n",
      "Epoch: 25 -> Test Accuracy: 80.69\n",
      "[26, 60] loss: 0.422\n",
      "[26, 120] loss: 0.424\n",
      "[26, 180] loss: 0.432\n",
      "[26, 240] loss: 0.420\n",
      "[26, 300] loss: 0.425\n",
      "[26, 360] loss: 0.429\n",
      "Epoch: 26 -> Loss: 0.392091691494\n",
      "Epoch: 26 -> Test Accuracy: 80.8\n",
      "[27, 60] loss: 0.400\n",
      "[27, 120] loss: 0.413\n",
      "[27, 180] loss: 0.422\n",
      "[27, 240] loss: 0.417\n",
      "[27, 300] loss: 0.440\n",
      "[27, 360] loss: 0.436\n",
      "Epoch: 27 -> Loss: 0.431131988764\n",
      "Epoch: 27 -> Test Accuracy: 80.65\n",
      "[28, 60] loss: 0.415\n",
      "[28, 120] loss: 0.411\n",
      "[28, 180] loss: 0.428\n",
      "[28, 240] loss: 0.429\n",
      "[28, 300] loss: 0.428\n",
      "[28, 360] loss: 0.449\n",
      "Epoch: 28 -> Loss: 0.441088140011\n",
      "Epoch: 28 -> Test Accuracy: 79.31\n",
      "[29, 60] loss: 0.395\n",
      "[29, 120] loss: 0.393\n",
      "[29, 180] loss: 0.431\n",
      "[29, 240] loss: 0.440\n",
      "[29, 300] loss: 0.408\n",
      "[29, 360] loss: 0.436\n",
      "Epoch: 29 -> Loss: 0.524160683155\n",
      "Epoch: 29 -> Test Accuracy: 80.07\n",
      "[30, 60] loss: 0.400\n",
      "[30, 120] loss: 0.414\n",
      "[30, 180] loss: 0.437\n",
      "[30, 240] loss: 0.411\n",
      "[30, 300] loss: 0.422\n",
      "[30, 360] loss: 0.422\n",
      "Epoch: 30 -> Loss: 0.369471877813\n",
      "Epoch: 30 -> Test Accuracy: 80.4\n",
      "[31, 60] loss: 0.389\n",
      "[31, 120] loss: 0.398\n",
      "[31, 180] loss: 0.430\n",
      "[31, 240] loss: 0.423\n",
      "[31, 300] loss: 0.424\n",
      "[31, 360] loss: 0.443\n",
      "Epoch: 31 -> Loss: 0.510131955147\n",
      "Epoch: 31 -> Test Accuracy: 80.1\n",
      "[32, 60] loss: 0.385\n",
      "[32, 120] loss: 0.399\n",
      "[32, 180] loss: 0.411\n",
      "[32, 240] loss: 0.414\n",
      "[32, 300] loss: 0.442\n",
      "[32, 360] loss: 0.414\n",
      "Epoch: 32 -> Loss: 0.346379250288\n",
      "Epoch: 32 -> Test Accuracy: 80.39\n",
      "[33, 60] loss: 0.414\n",
      "[33, 120] loss: 0.401\n",
      "[33, 180] loss: 0.412\n",
      "[33, 240] loss: 0.403\n",
      "[33, 300] loss: 0.426\n",
      "[33, 360] loss: 0.418\n",
      "Epoch: 33 -> Loss: 0.363732308149\n",
      "Epoch: 33 -> Test Accuracy: 80.61\n",
      "[34, 60] loss: 0.404\n",
      "[34, 120] loss: 0.379\n",
      "[34, 180] loss: 0.412\n",
      "[34, 240] loss: 0.425\n",
      "[34, 300] loss: 0.413\n",
      "[34, 360] loss: 0.432\n",
      "Epoch: 34 -> Loss: 0.504508852959\n",
      "Epoch: 34 -> Test Accuracy: 80.27\n",
      "[35, 60] loss: 0.371\n",
      "[35, 120] loss: 0.407\n",
      "[35, 180] loss: 0.431\n",
      "[35, 240] loss: 0.406\n",
      "[35, 300] loss: 0.426\n",
      "[35, 360] loss: 0.412\n",
      "Epoch: 35 -> Loss: 0.362032860518\n",
      "Epoch: 35 -> Test Accuracy: 79.57\n",
      "[36, 60] loss: 0.324\n",
      "[36, 120] loss: 0.290\n",
      "[36, 180] loss: 0.290\n",
      "[36, 240] loss: 0.283\n",
      "[36, 300] loss: 0.284\n",
      "[36, 360] loss: 0.291\n",
      "Epoch: 36 -> Loss: 0.452011108398\n",
      "Epoch: 36 -> Test Accuracy: 84.36\n",
      "[37, 60] loss: 0.266\n",
      "[37, 120] loss: 0.254\n",
      "[37, 180] loss: 0.268\n",
      "[37, 240] loss: 0.268\n",
      "[37, 300] loss: 0.257\n",
      "[37, 360] loss: 0.259\n",
      "Epoch: 37 -> Loss: 0.281140327454\n",
      "Epoch: 37 -> Test Accuracy: 84.34\n",
      "[38, 60] loss: 0.233\n",
      "[38, 120] loss: 0.244\n",
      "[38, 180] loss: 0.248\n",
      "[38, 240] loss: 0.247\n",
      "[38, 300] loss: 0.246\n",
      "[38, 360] loss: 0.255\n",
      "Epoch: 38 -> Loss: 0.0895489901304\n",
      "Epoch: 38 -> Test Accuracy: 85.24\n",
      "[39, 60] loss: 0.216\n",
      "[39, 120] loss: 0.226\n",
      "[39, 180] loss: 0.241\n",
      "[39, 240] loss: 0.245\n",
      "[39, 300] loss: 0.241\n",
      "[39, 360] loss: 0.250\n",
      "Epoch: 39 -> Loss: 0.20507594943\n",
      "Epoch: 39 -> Test Accuracy: 85.04\n",
      "[40, 60] loss: 0.213\n",
      "[40, 120] loss: 0.226\n",
      "[40, 180] loss: 0.215\n",
      "[40, 240] loss: 0.232\n",
      "[40, 300] loss: 0.237\n",
      "[40, 360] loss: 0.233\n",
      "Epoch: 40 -> Loss: 0.264329850674\n",
      "Epoch: 40 -> Test Accuracy: 85.07\n",
      "[41, 60] loss: 0.221\n",
      "[41, 120] loss: 0.222\n",
      "[41, 180] loss: 0.221\n",
      "[41, 240] loss: 0.224\n",
      "[41, 300] loss: 0.256\n",
      "[41, 360] loss: 0.238\n",
      "Epoch: 41 -> Loss: 0.130392864347\n",
      "Epoch: 41 -> Test Accuracy: 84.27\n",
      "[42, 60] loss: 0.219\n",
      "[42, 120] loss: 0.218\n",
      "[42, 180] loss: 0.225\n",
      "[42, 240] loss: 0.235\n",
      "[42, 300] loss: 0.237\n",
      "[42, 360] loss: 0.237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.302528142929\n",
      "Epoch: 42 -> Test Accuracy: 84.53\n",
      "[43, 60] loss: 0.204\n",
      "[43, 120] loss: 0.211\n",
      "[43, 180] loss: 0.214\n",
      "[43, 240] loss: 0.225\n",
      "[43, 300] loss: 0.231\n",
      "[43, 360] loss: 0.235\n",
      "Epoch: 43 -> Loss: 0.222333043814\n",
      "Epoch: 43 -> Test Accuracy: 83.7\n",
      "[44, 60] loss: 0.221\n",
      "[44, 120] loss: 0.218\n",
      "[44, 180] loss: 0.217\n",
      "[44, 240] loss: 0.221\n",
      "[44, 300] loss: 0.238\n",
      "[44, 360] loss: 0.237\n",
      "Epoch: 44 -> Loss: 0.238920122385\n",
      "Epoch: 44 -> Test Accuracy: 84.63\n",
      "[45, 60] loss: 0.209\n",
      "[45, 120] loss: 0.220\n",
      "[45, 180] loss: 0.226\n",
      "[45, 240] loss: 0.224\n",
      "[45, 300] loss: 0.235\n",
      "[45, 360] loss: 0.244\n",
      "Epoch: 45 -> Loss: 0.263933122158\n",
      "Epoch: 45 -> Test Accuracy: 84.81\n",
      "[46, 60] loss: 0.206\n",
      "[46, 120] loss: 0.223\n",
      "[46, 180] loss: 0.224\n",
      "[46, 240] loss: 0.234\n",
      "[46, 300] loss: 0.219\n",
      "[46, 360] loss: 0.245\n",
      "Epoch: 46 -> Loss: 0.203419446945\n",
      "Epoch: 46 -> Test Accuracy: 84.36\n",
      "[47, 60] loss: 0.207\n",
      "[47, 120] loss: 0.218\n",
      "[47, 180] loss: 0.230\n",
      "[47, 240] loss: 0.231\n",
      "[47, 300] loss: 0.233\n",
      "[47, 360] loss: 0.225\n",
      "Epoch: 47 -> Loss: 0.198939710855\n",
      "Epoch: 47 -> Test Accuracy: 83.67\n",
      "[48, 60] loss: 0.213\n",
      "[48, 120] loss: 0.209\n",
      "[48, 180] loss: 0.231\n",
      "[48, 240] loss: 0.223\n",
      "[48, 300] loss: 0.229\n",
      "[48, 360] loss: 0.231\n",
      "Epoch: 48 -> Loss: 0.234617397189\n",
      "Epoch: 48 -> Test Accuracy: 83.85\n",
      "[49, 60] loss: 0.208\n",
      "[49, 120] loss: 0.208\n",
      "[49, 180] loss: 0.221\n",
      "[49, 240] loss: 0.229\n",
      "[49, 300] loss: 0.238\n",
      "[49, 360] loss: 0.231\n",
      "Epoch: 49 -> Loss: 0.210381984711\n",
      "Epoch: 49 -> Test Accuracy: 83.63\n",
      "[50, 60] loss: 0.214\n",
      "[50, 120] loss: 0.206\n",
      "[50, 180] loss: 0.221\n",
      "[50, 240] loss: 0.233\n",
      "[50, 300] loss: 0.225\n",
      "[50, 360] loss: 0.228\n",
      "Epoch: 50 -> Loss: 0.216195017099\n",
      "Epoch: 50 -> Test Accuracy: 83.58\n",
      "[51, 60] loss: 0.215\n",
      "[51, 120] loss: 0.219\n",
      "[51, 180] loss: 0.215\n",
      "[51, 240] loss: 0.237\n",
      "[51, 300] loss: 0.221\n",
      "[51, 360] loss: 0.232\n",
      "Epoch: 51 -> Loss: 0.173260658979\n",
      "Epoch: 51 -> Test Accuracy: 83.81\n",
      "[52, 60] loss: 0.209\n",
      "[52, 120] loss: 0.215\n",
      "[52, 180] loss: 0.218\n",
      "[52, 240] loss: 0.225\n",
      "[52, 300] loss: 0.228\n",
      "[52, 360] loss: 0.232\n",
      "Epoch: 52 -> Loss: 0.216831997037\n",
      "Epoch: 52 -> Test Accuracy: 83.32\n",
      "[53, 60] loss: 0.205\n",
      "[53, 120] loss: 0.218\n",
      "[53, 180] loss: 0.224\n",
      "[53, 240] loss: 0.214\n",
      "[53, 300] loss: 0.227\n",
      "[53, 360] loss: 0.243\n",
      "Epoch: 53 -> Loss: 0.19231300056\n",
      "Epoch: 53 -> Test Accuracy: 83.04\n",
      "[54, 60] loss: 0.216\n",
      "[54, 120] loss: 0.213\n",
      "[54, 180] loss: 0.210\n",
      "[54, 240] loss: 0.232\n",
      "[54, 300] loss: 0.226\n",
      "[54, 360] loss: 0.234\n",
      "Epoch: 54 -> Loss: 0.154579699039\n",
      "Epoch: 54 -> Test Accuracy: 82.27\n",
      "[55, 60] loss: 0.216\n",
      "[55, 120] loss: 0.217\n",
      "[55, 180] loss: 0.221\n",
      "[55, 240] loss: 0.236\n",
      "[55, 300] loss: 0.237\n",
      "[55, 360] loss: 0.229\n",
      "Epoch: 55 -> Loss: 0.21344730258\n",
      "Epoch: 55 -> Test Accuracy: 84.02\n",
      "[56, 60] loss: 0.205\n",
      "[56, 120] loss: 0.216\n",
      "[56, 180] loss: 0.211\n",
      "[56, 240] loss: 0.234\n",
      "[56, 300] loss: 0.228\n",
      "[56, 360] loss: 0.224\n",
      "Epoch: 56 -> Loss: 0.124242082238\n",
      "Epoch: 56 -> Test Accuracy: 83.46\n",
      "[57, 60] loss: 0.210\n",
      "[57, 120] loss: 0.219\n",
      "[57, 180] loss: 0.219\n",
      "[57, 240] loss: 0.228\n",
      "[57, 300] loss: 0.231\n",
      "[57, 360] loss: 0.236\n",
      "Epoch: 57 -> Loss: 0.403712272644\n",
      "Epoch: 57 -> Test Accuracy: 83.49\n",
      "[58, 60] loss: 0.207\n",
      "[58, 120] loss: 0.212\n",
      "[58, 180] loss: 0.221\n",
      "[58, 240] loss: 0.225\n",
      "[58, 300] loss: 0.225\n",
      "[58, 360] loss: 0.236\n",
      "Epoch: 58 -> Loss: 0.270137965679\n",
      "Epoch: 58 -> Test Accuracy: 83.76\n",
      "[59, 60] loss: 0.199\n",
      "[59, 120] loss: 0.216\n",
      "[59, 180] loss: 0.224\n",
      "[59, 240] loss: 0.223\n",
      "[59, 300] loss: 0.226\n",
      "[59, 360] loss: 0.245\n",
      "Epoch: 59 -> Loss: 0.246567681432\n",
      "Epoch: 59 -> Test Accuracy: 83.02\n",
      "[60, 60] loss: 0.203\n",
      "[60, 120] loss: 0.206\n",
      "[60, 180] loss: 0.226\n",
      "[60, 240] loss: 0.221\n",
      "[60, 300] loss: 0.218\n",
      "[60, 360] loss: 0.230\n",
      "Epoch: 60 -> Loss: 0.174086645246\n",
      "Epoch: 60 -> Test Accuracy: 82.93\n",
      "[61, 60] loss: 0.218\n",
      "[61, 120] loss: 0.208\n",
      "[61, 180] loss: 0.214\n",
      "[61, 240] loss: 0.220\n",
      "[61, 300] loss: 0.215\n",
      "[61, 360] loss: 0.223\n",
      "Epoch: 61 -> Loss: 0.220513552427\n",
      "Epoch: 61 -> Test Accuracy: 83.65\n",
      "[62, 60] loss: 0.207\n",
      "[62, 120] loss: 0.210\n",
      "[62, 180] loss: 0.216\n",
      "[62, 240] loss: 0.213\n",
      "[62, 300] loss: 0.223\n",
      "[62, 360] loss: 0.217\n",
      "Epoch: 62 -> Loss: 0.23776447773\n",
      "Epoch: 62 -> Test Accuracy: 84.13\n",
      "[63, 60] loss: 0.199\n",
      "[63, 120] loss: 0.211\n",
      "[63, 180] loss: 0.214\n",
      "[63, 240] loss: 0.222\n",
      "[63, 300] loss: 0.214\n",
      "[63, 360] loss: 0.221\n",
      "Epoch: 63 -> Loss: 0.351051747799\n",
      "Epoch: 63 -> Test Accuracy: 83.34\n",
      "[64, 60] loss: 0.213\n",
      "[64, 120] loss: 0.220\n",
      "[64, 180] loss: 0.213\n",
      "[64, 240] loss: 0.214\n",
      "[64, 300] loss: 0.225\n",
      "[64, 360] loss: 0.239\n",
      "Epoch: 64 -> Loss: 0.19595913589\n",
      "Epoch: 64 -> Test Accuracy: 83.31\n",
      "[65, 60] loss: 0.203\n",
      "[65, 120] loss: 0.196\n",
      "[65, 180] loss: 0.213\n",
      "[65, 240] loss: 0.222\n",
      "[65, 300] loss: 0.217\n",
      "[65, 360] loss: 0.247\n",
      "Epoch: 65 -> Loss: 0.236455589533\n",
      "Epoch: 65 -> Test Accuracy: 83.51\n",
      "[66, 60] loss: 0.203\n",
      "[66, 120] loss: 0.208\n",
      "[66, 180] loss: 0.212\n",
      "[66, 240] loss: 0.218\n",
      "[66, 300] loss: 0.225\n",
      "[66, 360] loss: 0.218\n",
      "Epoch: 66 -> Loss: 0.312620788813\n",
      "Epoch: 66 -> Test Accuracy: 83.45\n",
      "[67, 60] loss: 0.209\n",
      "[67, 120] loss: 0.201\n",
      "[67, 180] loss: 0.219\n",
      "[67, 240] loss: 0.214\n",
      "[67, 300] loss: 0.223\n",
      "[67, 360] loss: 0.226\n",
      "Epoch: 67 -> Loss: 0.345077812672\n",
      "Epoch: 67 -> Test Accuracy: 83.8\n",
      "[68, 60] loss: 0.214\n",
      "[68, 120] loss: 0.204\n",
      "[68, 180] loss: 0.212\n",
      "[68, 240] loss: 0.218\n",
      "[68, 300] loss: 0.208\n",
      "[68, 360] loss: 0.219\n",
      "Epoch: 68 -> Loss: 0.278367221355\n",
      "Epoch: 68 -> Test Accuracy: 83.83\n",
      "[69, 60] loss: 0.192\n",
      "[69, 120] loss: 0.197\n",
      "[69, 180] loss: 0.204\n",
      "[69, 240] loss: 0.218\n",
      "[69, 300] loss: 0.224\n",
      "[69, 360] loss: 0.218\n",
      "Epoch: 69 -> Loss: 0.157950371504\n",
      "Epoch: 69 -> Test Accuracy: 83.89\n",
      "[70, 60] loss: 0.194\n",
      "[70, 120] loss: 0.196\n",
      "[70, 180] loss: 0.213\n",
      "[70, 240] loss: 0.218\n",
      "[70, 300] loss: 0.216\n",
      "[70, 360] loss: 0.219\n",
      "Epoch: 70 -> Loss: 0.289320290089\n",
      "Epoch: 70 -> Test Accuracy: 83.3\n",
      "[71, 60] loss: 0.163\n",
      "[71, 120] loss: 0.153\n",
      "[71, 180] loss: 0.148\n",
      "[71, 240] loss: 0.142\n",
      "[71, 300] loss: 0.142\n",
      "[71, 360] loss: 0.146\n",
      "Epoch: 71 -> Loss: 0.152266561985\n",
      "Epoch: 71 -> Test Accuracy: 85.54\n",
      "[72, 60] loss: 0.131\n",
      "[72, 120] loss: 0.124\n",
      "[72, 180] loss: 0.139\n",
      "[72, 240] loss: 0.131\n",
      "[72, 300] loss: 0.130\n",
      "[72, 360] loss: 0.126\n",
      "Epoch: 72 -> Loss: 0.0920889228582\n",
      "Epoch: 72 -> Test Accuracy: 85.31\n",
      "[73, 60] loss: 0.119\n",
      "[73, 120] loss: 0.122\n",
      "[73, 180] loss: 0.125\n",
      "[73, 240] loss: 0.125\n",
      "[73, 300] loss: 0.128\n",
      "[73, 360] loss: 0.127\n",
      "Epoch: 73 -> Loss: 0.165922135115\n",
      "Epoch: 73 -> Test Accuracy: 85.56\n",
      "[74, 60] loss: 0.121\n",
      "[74, 120] loss: 0.118\n",
      "[74, 180] loss: 0.112\n",
      "[74, 240] loss: 0.115\n",
      "[74, 300] loss: 0.121\n",
      "[74, 360] loss: 0.119\n",
      "Epoch: 74 -> Loss: 0.147976875305\n",
      "Epoch: 74 -> Test Accuracy: 85.61\n",
      "[75, 60] loss: 0.113\n",
      "[75, 120] loss: 0.120\n",
      "[75, 180] loss: 0.114\n",
      "[75, 240] loss: 0.112\n",
      "[75, 300] loss: 0.119\n",
      "[75, 360] loss: 0.123\n",
      "Epoch: 75 -> Loss: 0.0907336324453\n",
      "Epoch: 75 -> Test Accuracy: 85.54\n",
      "[76, 60] loss: 0.108\n",
      "[76, 120] loss: 0.117\n",
      "[76, 180] loss: 0.110\n",
      "[76, 240] loss: 0.116\n",
      "[76, 300] loss: 0.112\n",
      "[76, 360] loss: 0.112\n",
      "Epoch: 76 -> Loss: 0.137025922537\n",
      "Epoch: 76 -> Test Accuracy: 85.58\n",
      "[77, 60] loss: 0.105\n",
      "[77, 120] loss: 0.112\n",
      "[77, 180] loss: 0.110\n",
      "[77, 240] loss: 0.109\n",
      "[77, 300] loss: 0.109\n",
      "[77, 360] loss: 0.110\n",
      "Epoch: 77 -> Loss: 0.11887498945\n",
      "Epoch: 77 -> Test Accuracy: 85.36\n",
      "[78, 60] loss: 0.111\n",
      "[78, 120] loss: 0.105\n",
      "[78, 180] loss: 0.109\n",
      "[78, 240] loss: 0.109\n",
      "[78, 300] loss: 0.110\n",
      "[78, 360] loss: 0.110\n",
      "Epoch: 78 -> Loss: 0.116873122752\n",
      "Epoch: 78 -> Test Accuracy: 85.14\n",
      "[79, 60] loss: 0.100\n",
      "[79, 120] loss: 0.105\n",
      "[79, 180] loss: 0.106\n",
      "[79, 240] loss: 0.108\n",
      "[79, 300] loss: 0.108\n",
      "[79, 360] loss: 0.113\n",
      "Epoch: 79 -> Loss: 0.144470959902\n",
      "Epoch: 79 -> Test Accuracy: 85.1\n",
      "[80, 60] loss: 0.100\n",
      "[80, 120] loss: 0.098\n",
      "[80, 180] loss: 0.107\n",
      "[80, 240] loss: 0.103\n",
      "[80, 300] loss: 0.095\n",
      "[80, 360] loss: 0.105\n",
      "Epoch: 80 -> Loss: 0.140769764781\n",
      "Epoch: 80 -> Test Accuracy: 85.14\n",
      "[81, 60] loss: 0.099\n",
      "[81, 120] loss: 0.099\n",
      "[81, 180] loss: 0.099\n",
      "[81, 240] loss: 0.104\n",
      "[81, 300] loss: 0.106\n",
      "[81, 360] loss: 0.098\n",
      "Epoch: 81 -> Loss: 0.172728762031\n",
      "Epoch: 81 -> Test Accuracy: 85.06\n",
      "[82, 60] loss: 0.094\n",
      "[82, 120] loss: 0.096\n",
      "[82, 180] loss: 0.100\n",
      "[82, 240] loss: 0.099\n",
      "[82, 300] loss: 0.105\n",
      "[82, 360] loss: 0.109\n",
      "Epoch: 82 -> Loss: 0.0757977217436\n",
      "Epoch: 82 -> Test Accuracy: 85.44\n",
      "[83, 60] loss: 0.097\n",
      "[83, 120] loss: 0.098\n",
      "[83, 180] loss: 0.100\n",
      "[83, 240] loss: 0.101\n",
      "[83, 300] loss: 0.096\n",
      "[83, 360] loss: 0.098\n",
      "Epoch: 83 -> Loss: 0.14152738452\n",
      "Epoch: 83 -> Test Accuracy: 85.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.093\n",
      "[84, 120] loss: 0.092\n",
      "[84, 180] loss: 0.099\n",
      "[84, 240] loss: 0.102\n",
      "[84, 300] loss: 0.099\n",
      "[84, 360] loss: 0.100\n",
      "Epoch: 84 -> Loss: 0.0869622081518\n",
      "Epoch: 84 -> Test Accuracy: 85.49\n",
      "[85, 60] loss: 0.097\n",
      "[85, 120] loss: 0.097\n",
      "[85, 180] loss: 0.093\n",
      "[85, 240] loss: 0.098\n",
      "[85, 300] loss: 0.099\n",
      "[85, 360] loss: 0.099\n",
      "Epoch: 85 -> Loss: 0.100130841136\n",
      "Epoch: 85 -> Test Accuracy: 85.39\n",
      "[86, 60] loss: 0.088\n",
      "[86, 120] loss: 0.091\n",
      "[86, 180] loss: 0.084\n",
      "[86, 240] loss: 0.089\n",
      "[86, 300] loss: 0.083\n",
      "[86, 360] loss: 0.086\n",
      "Epoch: 86 -> Loss: 0.0797803252935\n",
      "Epoch: 86 -> Test Accuracy: 85.53\n",
      "[87, 60] loss: 0.087\n",
      "[87, 120] loss: 0.087\n",
      "[87, 180] loss: 0.082\n",
      "[87, 240] loss: 0.083\n",
      "[87, 300] loss: 0.086\n",
      "[87, 360] loss: 0.082\n",
      "Epoch: 87 -> Loss: 0.0665135756135\n",
      "Epoch: 87 -> Test Accuracy: 85.44\n",
      "[88, 60] loss: 0.079\n",
      "[88, 120] loss: 0.082\n",
      "[88, 180] loss: 0.083\n",
      "[88, 240] loss: 0.084\n",
      "[88, 300] loss: 0.082\n",
      "[88, 360] loss: 0.082\n",
      "Epoch: 88 -> Loss: 0.11388900131\n",
      "Epoch: 88 -> Test Accuracy: 85.26\n",
      "[89, 60] loss: 0.083\n",
      "[89, 120] loss: 0.082\n",
      "[89, 180] loss: 0.084\n",
      "[89, 240] loss: 0.085\n",
      "[89, 300] loss: 0.082\n",
      "[89, 360] loss: 0.085\n",
      "Epoch: 89 -> Loss: 0.0934200957417\n",
      "Epoch: 89 -> Test Accuracy: 85.47\n",
      "[90, 60] loss: 0.082\n",
      "[90, 120] loss: 0.084\n",
      "[90, 180] loss: 0.087\n",
      "[90, 240] loss: 0.079\n",
      "[90, 300] loss: 0.091\n",
      "[90, 360] loss: 0.078\n",
      "Epoch: 90 -> Loss: 0.13071924448\n",
      "Epoch: 90 -> Test Accuracy: 85.29\n",
      "[91, 60] loss: 0.080\n",
      "[91, 120] loss: 0.074\n",
      "[91, 180] loss: 0.084\n",
      "[91, 240] loss: 0.081\n",
      "[91, 300] loss: 0.083\n",
      "[91, 360] loss: 0.083\n",
      "Epoch: 91 -> Loss: 0.148835211992\n",
      "Epoch: 91 -> Test Accuracy: 85.35\n",
      "[92, 60] loss: 0.083\n",
      "[92, 120] loss: 0.075\n",
      "[92, 180] loss: 0.078\n",
      "[92, 240] loss: 0.080\n",
      "[92, 300] loss: 0.084\n",
      "[92, 360] loss: 0.080\n",
      "Epoch: 92 -> Loss: 0.118026301265\n",
      "Epoch: 92 -> Test Accuracy: 85.3\n",
      "[93, 60] loss: 0.081\n",
      "[93, 120] loss: 0.076\n",
      "[93, 180] loss: 0.080\n",
      "[93, 240] loss: 0.081\n",
      "[93, 300] loss: 0.082\n",
      "[93, 360] loss: 0.080\n",
      "Epoch: 93 -> Loss: 0.121410176158\n",
      "Epoch: 93 -> Test Accuracy: 85.41\n",
      "[94, 60] loss: 0.078\n",
      "[94, 120] loss: 0.076\n",
      "[94, 180] loss: 0.080\n",
      "[94, 240] loss: 0.081\n",
      "[94, 300] loss: 0.079\n",
      "[94, 360] loss: 0.080\n",
      "Epoch: 94 -> Loss: 0.0665175542235\n",
      "Epoch: 94 -> Test Accuracy: 85.29\n",
      "[95, 60] loss: 0.082\n",
      "[95, 120] loss: 0.077\n",
      "[95, 180] loss: 0.082\n",
      "[95, 240] loss: 0.076\n",
      "[95, 300] loss: 0.080\n",
      "[95, 360] loss: 0.077\n",
      "Epoch: 95 -> Loss: 0.126655966043\n",
      "Epoch: 95 -> Test Accuracy: 85.3\n",
      "[96, 60] loss: 0.078\n",
      "[96, 120] loss: 0.079\n",
      "[96, 180] loss: 0.076\n",
      "[96, 240] loss: 0.081\n",
      "[96, 300] loss: 0.083\n",
      "[96, 360] loss: 0.080\n",
      "Epoch: 96 -> Loss: 0.0726384371519\n",
      "Epoch: 96 -> Test Accuracy: 85.31\n",
      "[97, 60] loss: 0.081\n",
      "[97, 120] loss: 0.084\n",
      "[97, 180] loss: 0.077\n",
      "[97, 240] loss: 0.080\n",
      "[97, 300] loss: 0.076\n",
      "[97, 360] loss: 0.080\n",
      "Epoch: 97 -> Loss: 0.066988453269\n",
      "Epoch: 97 -> Test Accuracy: 85.23\n",
      "[98, 60] loss: 0.076\n",
      "[98, 120] loss: 0.080\n",
      "[98, 180] loss: 0.074\n",
      "[98, 240] loss: 0.080\n",
      "[98, 300] loss: 0.079\n",
      "[98, 360] loss: 0.084\n",
      "Epoch: 98 -> Loss: 0.0478844456375\n",
      "Epoch: 98 -> Test Accuracy: 85.34\n",
      "[99, 60] loss: 0.076\n",
      "[99, 120] loss: 0.079\n",
      "[99, 180] loss: 0.076\n",
      "[99, 240] loss: 0.080\n",
      "[99, 300] loss: 0.078\n",
      "[99, 360] loss: 0.081\n",
      "Epoch: 99 -> Loss: 0.0790641009808\n",
      "Epoch: 99 -> Test Accuracy: 85.27\n",
      "[100, 60] loss: 0.077\n",
      "[100, 120] loss: 0.080\n",
      "[100, 180] loss: 0.078\n",
      "[100, 240] loss: 0.078\n",
      "[100, 300] loss: 0.077\n",
      "[100, 360] loss: 0.080\n",
      "Epoch: 100 -> Loss: 0.0964441373944\n",
      "Epoch: 100 -> Test Accuracy: 85.19\n",
      "Finished Training\n",
      "[1, 60] loss: 0.907\n",
      "[1, 120] loss: 0.636\n",
      "[1, 180] loss: 0.583\n",
      "[1, 240] loss: 0.552\n",
      "[1, 300] loss: 0.529\n",
      "[1, 360] loss: 0.511\n",
      "Epoch: 1 -> Loss: 0.554467797279\n",
      "Epoch: 1 -> Test Accuracy: 79.72\n",
      "[2, 60] loss: 0.453\n",
      "[2, 120] loss: 0.444\n",
      "[2, 180] loss: 0.442\n",
      "[2, 240] loss: 0.445\n",
      "[2, 300] loss: 0.424\n",
      "[2, 360] loss: 0.414\n",
      "Epoch: 2 -> Loss: 0.337723314762\n",
      "Epoch: 2 -> Test Accuracy: 81.47\n",
      "[3, 60] loss: 0.391\n",
      "[3, 120] loss: 0.388\n",
      "[3, 180] loss: 0.393\n",
      "[3, 240] loss: 0.401\n",
      "[3, 300] loss: 0.400\n",
      "[3, 360] loss: 0.388\n",
      "Epoch: 3 -> Loss: 0.34307512641\n",
      "Epoch: 3 -> Test Accuracy: 81.58\n",
      "[4, 60] loss: 0.355\n",
      "[4, 120] loss: 0.337\n",
      "[4, 180] loss: 0.368\n",
      "[4, 240] loss: 0.378\n",
      "[4, 300] loss: 0.365\n",
      "[4, 360] loss: 0.373\n",
      "Epoch: 4 -> Loss: 0.501252651215\n",
      "Epoch: 4 -> Test Accuracy: 82.39\n",
      "[5, 60] loss: 0.351\n",
      "[5, 120] loss: 0.339\n",
      "[5, 180] loss: 0.348\n",
      "[5, 240] loss: 0.347\n",
      "[5, 300] loss: 0.348\n",
      "[5, 360] loss: 0.352\n",
      "Epoch: 5 -> Loss: 0.403210639954\n",
      "Epoch: 5 -> Test Accuracy: 82.79\n",
      "[6, 60] loss: 0.319\n",
      "[6, 120] loss: 0.325\n",
      "[6, 180] loss: 0.324\n",
      "[6, 240] loss: 0.341\n",
      "[6, 300] loss: 0.356\n",
      "[6, 360] loss: 0.341\n",
      "Epoch: 6 -> Loss: 0.431040853262\n",
      "Epoch: 6 -> Test Accuracy: 83.17\n",
      "[7, 60] loss: 0.299\n",
      "[7, 120] loss: 0.317\n",
      "[7, 180] loss: 0.309\n",
      "[7, 240] loss: 0.310\n",
      "[7, 300] loss: 0.350\n",
      "[7, 360] loss: 0.327\n",
      "Epoch: 7 -> Loss: 0.44353467226\n",
      "Epoch: 7 -> Test Accuracy: 84.05\n",
      "[8, 60] loss: 0.286\n",
      "[8, 120] loss: 0.304\n",
      "[8, 180] loss: 0.318\n",
      "[8, 240] loss: 0.311\n",
      "[8, 300] loss: 0.326\n",
      "[8, 360] loss: 0.333\n",
      "Epoch: 8 -> Loss: 0.558756232262\n",
      "Epoch: 8 -> Test Accuracy: 82.8\n",
      "[9, 60] loss: 0.287\n",
      "[9, 120] loss: 0.293\n",
      "[9, 180] loss: 0.307\n",
      "[9, 240] loss: 0.313\n",
      "[9, 300] loss: 0.326\n",
      "[9, 360] loss: 0.322\n",
      "Epoch: 9 -> Loss: 0.4932526052\n",
      "Epoch: 9 -> Test Accuracy: 83.51\n",
      "[10, 60] loss: 0.289\n",
      "[10, 120] loss: 0.299\n",
      "[10, 180] loss: 0.286\n",
      "[10, 240] loss: 0.305\n",
      "[10, 300] loss: 0.320\n",
      "[10, 360] loss: 0.312\n",
      "Epoch: 10 -> Loss: 0.300950527191\n",
      "Epoch: 10 -> Test Accuracy: 83.48\n",
      "[11, 60] loss: 0.280\n",
      "[11, 120] loss: 0.293\n",
      "[11, 180] loss: 0.294\n",
      "[11, 240] loss: 0.300\n",
      "[11, 300] loss: 0.287\n",
      "[11, 360] loss: 0.320\n",
      "Epoch: 11 -> Loss: 0.330504268408\n",
      "Epoch: 11 -> Test Accuracy: 83.62\n",
      "[12, 60] loss: 0.279\n",
      "[12, 120] loss: 0.290\n",
      "[12, 180] loss: 0.296\n",
      "[12, 240] loss: 0.292\n",
      "[12, 300] loss: 0.302\n",
      "[12, 360] loss: 0.301\n",
      "Epoch: 12 -> Loss: 0.227276712656\n",
      "Epoch: 12 -> Test Accuracy: 83.43\n",
      "[13, 60] loss: 0.270\n",
      "[13, 120] loss: 0.295\n",
      "[13, 180] loss: 0.291\n",
      "[13, 240] loss: 0.297\n",
      "[13, 300] loss: 0.285\n",
      "[13, 360] loss: 0.302\n",
      "Epoch: 13 -> Loss: 0.240523070097\n",
      "Epoch: 13 -> Test Accuracy: 84.4\n",
      "[14, 60] loss: 0.279\n",
      "[14, 120] loss: 0.270\n",
      "[14, 180] loss: 0.283\n",
      "[14, 240] loss: 0.282\n",
      "[14, 300] loss: 0.292\n",
      "[14, 360] loss: 0.298\n",
      "Epoch: 14 -> Loss: 0.219689562917\n",
      "Epoch: 14 -> Test Accuracy: 83.44\n",
      "[15, 60] loss: 0.258\n",
      "[15, 120] loss: 0.273\n",
      "[15, 180] loss: 0.281\n",
      "[15, 240] loss: 0.293\n",
      "[15, 300] loss: 0.301\n",
      "[15, 360] loss: 0.291\n",
      "Epoch: 15 -> Loss: 0.2872826159\n",
      "Epoch: 15 -> Test Accuracy: 83.28\n",
      "[16, 60] loss: 0.272\n",
      "[16, 120] loss: 0.268\n",
      "[16, 180] loss: 0.287\n",
      "[16, 240] loss: 0.276\n",
      "[16, 300] loss: 0.300\n",
      "[16, 360] loss: 0.280\n",
      "Epoch: 16 -> Loss: 0.389301270247\n",
      "Epoch: 16 -> Test Accuracy: 84.36\n",
      "[17, 60] loss: 0.246\n",
      "[17, 120] loss: 0.280\n",
      "[17, 180] loss: 0.285\n",
      "[17, 240] loss: 0.274\n",
      "[17, 300] loss: 0.284\n",
      "[17, 360] loss: 0.298\n",
      "Epoch: 17 -> Loss: 0.151867464185\n",
      "Epoch: 17 -> Test Accuracy: 84.53\n",
      "[18, 60] loss: 0.257\n",
      "[18, 120] loss: 0.265\n",
      "[18, 180] loss: 0.290\n",
      "[18, 240] loss: 0.272\n",
      "[18, 300] loss: 0.288\n",
      "[18, 360] loss: 0.285\n",
      "Epoch: 18 -> Loss: 0.26074847579\n",
      "Epoch: 18 -> Test Accuracy: 84.07\n",
      "[19, 60] loss: 0.254\n",
      "[19, 120] loss: 0.265\n",
      "[19, 180] loss: 0.267\n",
      "[19, 240] loss: 0.287\n",
      "[19, 300] loss: 0.287\n",
      "[19, 360] loss: 0.289\n",
      "Epoch: 19 -> Loss: 0.277999997139\n",
      "Epoch: 19 -> Test Accuracy: 83.6\n",
      "[20, 60] loss: 0.253\n",
      "[20, 120] loss: 0.264\n",
      "[20, 180] loss: 0.270\n",
      "[20, 240] loss: 0.290\n",
      "[20, 300] loss: 0.285\n",
      "[20, 360] loss: 0.283\n",
      "Epoch: 20 -> Loss: 0.294038921595\n",
      "Epoch: 20 -> Test Accuracy: 84.31\n",
      "[21, 60] loss: 0.245\n",
      "[21, 120] loss: 0.265\n",
      "[21, 180] loss: 0.269\n",
      "[21, 240] loss: 0.290\n",
      "[21, 300] loss: 0.277\n",
      "[21, 360] loss: 0.297\n",
      "Epoch: 21 -> Loss: 0.283550292253\n",
      "Epoch: 21 -> Test Accuracy: 84.19\n",
      "[22, 60] loss: 0.241\n",
      "[22, 120] loss: 0.249\n",
      "[22, 180] loss: 0.259\n",
      "[22, 240] loss: 0.279\n",
      "[22, 300] loss: 0.281\n",
      "[22, 360] loss: 0.280\n",
      "Epoch: 22 -> Loss: 0.315671950579\n",
      "Epoch: 22 -> Test Accuracy: 84.1\n",
      "[23, 60] loss: 0.245\n",
      "[23, 120] loss: 0.268\n",
      "[23, 180] loss: 0.260\n",
      "[23, 240] loss: 0.280\n",
      "[23, 300] loss: 0.274\n",
      "[23, 360] loss: 0.289\n",
      "Epoch: 23 -> Loss: 0.329927355051\n",
      "Epoch: 23 -> Test Accuracy: 83.83\n",
      "[24, 60] loss: 0.251\n",
      "[24, 120] loss: 0.240\n",
      "[24, 180] loss: 0.259\n",
      "[24, 240] loss: 0.279\n",
      "[24, 300] loss: 0.284\n",
      "[24, 360] loss: 0.275\n",
      "Epoch: 24 -> Loss: 0.247120946646\n",
      "Epoch: 24 -> Test Accuracy: 83.89\n",
      "[25, 60] loss: 0.226\n",
      "[25, 120] loss: 0.261\n",
      "[25, 180] loss: 0.272\n",
      "[25, 240] loss: 0.271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 300] loss: 0.284\n",
      "[25, 360] loss: 0.279\n",
      "Epoch: 25 -> Loss: 0.21403875947\n",
      "Epoch: 25 -> Test Accuracy: 83.87\n",
      "[26, 60] loss: 0.242\n",
      "[26, 120] loss: 0.251\n",
      "[26, 180] loss: 0.269\n",
      "[26, 240] loss: 0.272\n",
      "[26, 300] loss: 0.294\n",
      "[26, 360] loss: 0.267\n",
      "Epoch: 26 -> Loss: 0.328526705503\n",
      "Epoch: 26 -> Test Accuracy: 83.57\n",
      "[27, 60] loss: 0.248\n",
      "[27, 120] loss: 0.248\n",
      "[27, 180] loss: 0.258\n",
      "[27, 240] loss: 0.275\n",
      "[27, 300] loss: 0.270\n",
      "[27, 360] loss: 0.276\n",
      "Epoch: 27 -> Loss: 0.344846099615\n",
      "Epoch: 27 -> Test Accuracy: 84.84\n",
      "[28, 60] loss: 0.243\n",
      "[28, 120] loss: 0.252\n",
      "[28, 180] loss: 0.263\n",
      "[28, 240] loss: 0.265\n",
      "[28, 300] loss: 0.282\n",
      "[28, 360] loss: 0.274\n",
      "Epoch: 28 -> Loss: 0.290785968304\n",
      "Epoch: 28 -> Test Accuracy: 84.18\n",
      "[29, 60] loss: 0.248\n",
      "[29, 120] loss: 0.246\n",
      "[29, 180] loss: 0.254\n",
      "[29, 240] loss: 0.267\n",
      "[29, 300] loss: 0.285\n",
      "[29, 360] loss: 0.268\n",
      "Epoch: 29 -> Loss: 0.268285512924\n",
      "Epoch: 29 -> Test Accuracy: 84.79\n",
      "[30, 60] loss: 0.231\n",
      "[30, 120] loss: 0.249\n",
      "[30, 180] loss: 0.268\n",
      "[30, 240] loss: 0.269\n",
      "[30, 300] loss: 0.283\n",
      "[30, 360] loss: 0.265\n",
      "Epoch: 30 -> Loss: 0.31484246254\n",
      "Epoch: 30 -> Test Accuracy: 83.78\n",
      "[31, 60] loss: 0.247\n",
      "[31, 120] loss: 0.250\n",
      "[31, 180] loss: 0.250\n",
      "[31, 240] loss: 0.274\n",
      "[31, 300] loss: 0.264\n",
      "[31, 360] loss: 0.273\n",
      "Epoch: 31 -> Loss: 0.390973359346\n",
      "Epoch: 31 -> Test Accuracy: 84.7\n",
      "[32, 60] loss: 0.233\n",
      "[32, 120] loss: 0.254\n",
      "[32, 180] loss: 0.272\n",
      "[32, 240] loss: 0.262\n",
      "[32, 300] loss: 0.261\n",
      "[32, 360] loss: 0.266\n",
      "Epoch: 32 -> Loss: 0.212218612432\n",
      "Epoch: 32 -> Test Accuracy: 83.79\n",
      "[33, 60] loss: 0.240\n",
      "[33, 120] loss: 0.246\n",
      "[33, 180] loss: 0.246\n",
      "[33, 240] loss: 0.261\n",
      "[33, 300] loss: 0.272\n",
      "[33, 360] loss: 0.280\n",
      "Epoch: 33 -> Loss: 0.242671534419\n",
      "Epoch: 33 -> Test Accuracy: 84.75\n",
      "[34, 60] loss: 0.246\n",
      "[34, 120] loss: 0.244\n",
      "[34, 180] loss: 0.253\n",
      "[34, 240] loss: 0.265\n",
      "[34, 300] loss: 0.285\n",
      "[34, 360] loss: 0.269\n",
      "Epoch: 34 -> Loss: 0.269895106554\n",
      "Epoch: 34 -> Test Accuracy: 85.32\n",
      "[35, 60] loss: 0.233\n",
      "[35, 120] loss: 0.266\n",
      "[35, 180] loss: 0.259\n",
      "[35, 240] loss: 0.262\n",
      "[35, 300] loss: 0.265\n",
      "[35, 360] loss: 0.283\n",
      "Epoch: 35 -> Loss: 0.342716395855\n",
      "Epoch: 35 -> Test Accuracy: 84.51\n",
      "[36, 60] loss: 0.207\n",
      "[36, 120] loss: 0.184\n",
      "[36, 180] loss: 0.174\n",
      "[36, 240] loss: 0.163\n",
      "[36, 300] loss: 0.170\n",
      "[36, 360] loss: 0.170\n",
      "Epoch: 36 -> Loss: 0.159483775496\n",
      "Epoch: 36 -> Test Accuracy: 87.1\n",
      "[37, 60] loss: 0.144\n",
      "[37, 120] loss: 0.152\n",
      "[37, 180] loss: 0.141\n",
      "[37, 240] loss: 0.140\n",
      "[37, 300] loss: 0.146\n",
      "[37, 360] loss: 0.141\n",
      "Epoch: 37 -> Loss: 0.0825532376766\n",
      "Epoch: 37 -> Test Accuracy: 87.34\n",
      "[38, 60] loss: 0.126\n",
      "[38, 120] loss: 0.123\n",
      "[38, 180] loss: 0.129\n",
      "[38, 240] loss: 0.127\n",
      "[38, 300] loss: 0.140\n",
      "[38, 360] loss: 0.141\n",
      "Epoch: 38 -> Loss: 0.116008117795\n",
      "Epoch: 38 -> Test Accuracy: 86.98\n",
      "[39, 60] loss: 0.118\n",
      "[39, 120] loss: 0.125\n",
      "[39, 180] loss: 0.127\n",
      "[39, 240] loss: 0.131\n",
      "[39, 300] loss: 0.116\n",
      "[39, 360] loss: 0.127\n",
      "Epoch: 39 -> Loss: 0.14033152163\n",
      "Epoch: 39 -> Test Accuracy: 87.28\n",
      "[40, 60] loss: 0.113\n",
      "[40, 120] loss: 0.110\n",
      "[40, 180] loss: 0.113\n",
      "[40, 240] loss: 0.112\n",
      "[40, 300] loss: 0.115\n",
      "[40, 360] loss: 0.125\n",
      "Epoch: 40 -> Loss: 0.105070851743\n",
      "Epoch: 40 -> Test Accuracy: 86.88\n",
      "[41, 60] loss: 0.101\n",
      "[41, 120] loss: 0.102\n",
      "[41, 180] loss: 0.108\n",
      "[41, 240] loss: 0.115\n",
      "[41, 300] loss: 0.121\n",
      "[41, 360] loss: 0.122\n",
      "Epoch: 41 -> Loss: 0.0851335972548\n",
      "Epoch: 41 -> Test Accuracy: 87.1\n",
      "[42, 60] loss: 0.100\n",
      "[42, 120] loss: 0.111\n",
      "[42, 180] loss: 0.107\n",
      "[42, 240] loss: 0.105\n",
      "[42, 300] loss: 0.118\n",
      "[42, 360] loss: 0.113\n",
      "Epoch: 42 -> Loss: 0.0793545991182\n",
      "Epoch: 42 -> Test Accuracy: 86.88\n",
      "[43, 60] loss: 0.104\n",
      "[43, 120] loss: 0.109\n",
      "[43, 180] loss: 0.110\n",
      "[43, 240] loss: 0.102\n",
      "[43, 300] loss: 0.111\n",
      "[43, 360] loss: 0.111\n",
      "Epoch: 43 -> Loss: 0.103165328503\n",
      "Epoch: 43 -> Test Accuracy: 86.78\n",
      "[44, 60] loss: 0.103\n",
      "[44, 120] loss: 0.098\n",
      "[44, 180] loss: 0.106\n",
      "[44, 240] loss: 0.112\n",
      "[44, 300] loss: 0.101\n",
      "[44, 360] loss: 0.116\n",
      "Epoch: 44 -> Loss: 0.171624928713\n",
      "Epoch: 44 -> Test Accuracy: 86.28\n",
      "[45, 60] loss: 0.103\n",
      "[45, 120] loss: 0.090\n",
      "[45, 180] loss: 0.103\n",
      "[45, 240] loss: 0.112\n",
      "[45, 300] loss: 0.115\n",
      "[45, 360] loss: 0.117\n",
      "Epoch: 45 -> Loss: 0.120378874242\n",
      "Epoch: 45 -> Test Accuracy: 86.98\n",
      "[46, 60] loss: 0.102\n",
      "[46, 120] loss: 0.093\n",
      "[46, 180] loss: 0.108\n",
      "[46, 240] loss: 0.099\n",
      "[46, 300] loss: 0.107\n",
      "[46, 360] loss: 0.109\n",
      "Epoch: 46 -> Loss: 0.101112321019\n",
      "Epoch: 46 -> Test Accuracy: 86.53\n",
      "[47, 60] loss: 0.098\n",
      "[47, 120] loss: 0.110\n",
      "[47, 180] loss: 0.104\n",
      "[47, 240] loss: 0.105\n",
      "[47, 300] loss: 0.108\n",
      "[47, 360] loss: 0.118\n",
      "Epoch: 47 -> Loss: 0.20741315186\n",
      "Epoch: 47 -> Test Accuracy: 86.27\n",
      "[48, 60] loss: 0.101\n",
      "[48, 120] loss: 0.097\n",
      "[48, 180] loss: 0.101\n",
      "[48, 240] loss: 0.109\n",
      "[48, 300] loss: 0.107\n",
      "[48, 360] loss: 0.111\n",
      "Epoch: 48 -> Loss: 0.0870244428515\n",
      "Epoch: 48 -> Test Accuracy: 86.42\n",
      "[49, 60] loss: 0.100\n",
      "[49, 120] loss: 0.095\n",
      "[49, 180] loss: 0.102\n",
      "[49, 240] loss: 0.117\n",
      "[49, 300] loss: 0.115\n",
      "[49, 360] loss: 0.121\n",
      "Epoch: 49 -> Loss: 0.130111530423\n",
      "Epoch: 49 -> Test Accuracy: 86.19\n",
      "[50, 60] loss: 0.103\n",
      "[50, 120] loss: 0.099\n",
      "[50, 180] loss: 0.109\n",
      "[50, 240] loss: 0.116\n",
      "[50, 300] loss: 0.114\n",
      "[50, 360] loss: 0.117\n",
      "Epoch: 50 -> Loss: 0.141013562679\n",
      "Epoch: 50 -> Test Accuracy: 85.9\n",
      "[51, 60] loss: 0.101\n",
      "[51, 120] loss: 0.099\n",
      "[51, 180] loss: 0.099\n",
      "[51, 240] loss: 0.112\n",
      "[51, 300] loss: 0.113\n",
      "[51, 360] loss: 0.115\n",
      "Epoch: 51 -> Loss: 0.118292823434\n",
      "Epoch: 51 -> Test Accuracy: 86.27\n",
      "[52, 60] loss: 0.099\n",
      "[52, 120] loss: 0.104\n",
      "[52, 180] loss: 0.107\n",
      "[52, 240] loss: 0.107\n",
      "[52, 300] loss: 0.108\n",
      "[52, 360] loss: 0.120\n",
      "Epoch: 52 -> Loss: 0.142367511988\n",
      "Epoch: 52 -> Test Accuracy: 86.1\n",
      "[53, 60] loss: 0.100\n",
      "[53, 120] loss: 0.099\n",
      "[53, 180] loss: 0.101\n",
      "[53, 240] loss: 0.109\n",
      "[53, 300] loss: 0.113\n",
      "[53, 360] loss: 0.116\n",
      "Epoch: 53 -> Loss: 0.105673715472\n",
      "Epoch: 53 -> Test Accuracy: 85.95\n",
      "[54, 60] loss: 0.095\n",
      "[54, 120] loss: 0.102\n",
      "[54, 180] loss: 0.109\n",
      "[54, 240] loss: 0.115\n",
      "[54, 300] loss: 0.116\n",
      "[54, 360] loss: 0.116\n",
      "Epoch: 54 -> Loss: 0.17556771636\n",
      "Epoch: 54 -> Test Accuracy: 86.05\n",
      "[55, 60] loss: 0.101\n",
      "[55, 120] loss: 0.105\n",
      "[55, 180] loss: 0.106\n",
      "[55, 240] loss: 0.112\n",
      "[55, 300] loss: 0.120\n",
      "[55, 360] loss: 0.119\n",
      "Epoch: 55 -> Loss: 0.155950471759\n",
      "Epoch: 55 -> Test Accuracy: 86.12\n",
      "[56, 60] loss: 0.093\n",
      "[56, 120] loss: 0.098\n",
      "[56, 180] loss: 0.105\n",
      "[56, 240] loss: 0.103\n",
      "[56, 300] loss: 0.116\n",
      "[56, 360] loss: 0.113\n",
      "Epoch: 56 -> Loss: 0.040999867022\n",
      "Epoch: 56 -> Test Accuracy: 86.27\n",
      "[57, 60] loss: 0.098\n",
      "[57, 120] loss: 0.096\n",
      "[57, 180] loss: 0.097\n",
      "[57, 240] loss: 0.107\n",
      "[57, 300] loss: 0.106\n",
      "[57, 360] loss: 0.115\n",
      "Epoch: 57 -> Loss: 0.108648732305\n",
      "Epoch: 57 -> Test Accuracy: 85.97\n",
      "[58, 60] loss: 0.093\n",
      "[58, 120] loss: 0.102\n",
      "[58, 180] loss: 0.103\n",
      "[58, 240] loss: 0.112\n",
      "[58, 300] loss: 0.116\n",
      "[58, 360] loss: 0.111\n",
      "Epoch: 58 -> Loss: 0.0810605660081\n",
      "Epoch: 58 -> Test Accuracy: 85.92\n",
      "[59, 60] loss: 0.101\n",
      "[59, 120] loss: 0.100\n",
      "[59, 180] loss: 0.101\n",
      "[59, 240] loss: 0.105\n",
      "[59, 300] loss: 0.105\n",
      "[59, 360] loss: 0.111\n",
      "Epoch: 59 -> Loss: 0.11481551826\n",
      "Epoch: 59 -> Test Accuracy: 85.85\n",
      "[60, 60] loss: 0.095\n",
      "[60, 120] loss: 0.096\n",
      "[60, 180] loss: 0.108\n",
      "[60, 240] loss: 0.112\n",
      "[60, 300] loss: 0.109\n",
      "[60, 360] loss: 0.107\n",
      "Epoch: 60 -> Loss: 0.121362172067\n",
      "Epoch: 60 -> Test Accuracy: 85.34\n",
      "[61, 60] loss: 0.097\n",
      "[61, 120] loss: 0.108\n",
      "[61, 180] loss: 0.099\n",
      "[61, 240] loss: 0.108\n",
      "[61, 300] loss: 0.102\n",
      "[61, 360] loss: 0.119\n",
      "Epoch: 61 -> Loss: 0.0667873844504\n",
      "Epoch: 61 -> Test Accuracy: 85.73\n",
      "[62, 60] loss: 0.103\n",
      "[62, 120] loss: 0.095\n",
      "[62, 180] loss: 0.102\n",
      "[62, 240] loss: 0.107\n",
      "[62, 300] loss: 0.108\n",
      "[62, 360] loss: 0.111\n",
      "Epoch: 62 -> Loss: 0.0922214537859\n",
      "Epoch: 62 -> Test Accuracy: 85.42\n",
      "[63, 60] loss: 0.092\n",
      "[63, 120] loss: 0.099\n",
      "[63, 180] loss: 0.098\n",
      "[63, 240] loss: 0.100\n",
      "[63, 300] loss: 0.110\n",
      "[63, 360] loss: 0.115\n",
      "Epoch: 63 -> Loss: 0.111963905394\n",
      "Epoch: 63 -> Test Accuracy: 85.85\n",
      "[64, 60] loss: 0.087\n",
      "[64, 120] loss: 0.094\n",
      "[64, 180] loss: 0.095\n",
      "[64, 240] loss: 0.103\n",
      "[64, 300] loss: 0.101\n",
      "[64, 360] loss: 0.108\n",
      "Epoch: 64 -> Loss: 0.191099062562\n",
      "Epoch: 64 -> Test Accuracy: 85.94\n",
      "[65, 60] loss: 0.097\n",
      "[65, 120] loss: 0.087\n",
      "[65, 180] loss: 0.098\n",
      "[65, 240] loss: 0.104\n",
      "[65, 300] loss: 0.109\n",
      "[65, 360] loss: 0.108\n",
      "Epoch: 65 -> Loss: 0.112742498517\n",
      "Epoch: 65 -> Test Accuracy: 86.01\n",
      "[66, 60] loss: 0.104\n",
      "[66, 120] loss: 0.101\n",
      "[66, 180] loss: 0.098\n",
      "[66, 240] loss: 0.110\n",
      "[66, 300] loss: 0.107\n",
      "[66, 360] loss: 0.110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Loss: 0.0615716688335\n",
      "Epoch: 66 -> Test Accuracy: 85.6\n",
      "[67, 60] loss: 0.100\n",
      "[67, 120] loss: 0.101\n",
      "[67, 180] loss: 0.096\n",
      "[67, 240] loss: 0.098\n",
      "[67, 300] loss: 0.102\n",
      "[67, 360] loss: 0.116\n",
      "Epoch: 67 -> Loss: 0.120392024517\n",
      "Epoch: 67 -> Test Accuracy: 85.41\n",
      "[68, 60] loss: 0.098\n",
      "[68, 120] loss: 0.095\n",
      "[68, 180] loss: 0.104\n",
      "[68, 240] loss: 0.098\n",
      "[68, 300] loss: 0.106\n",
      "[68, 360] loss: 0.121\n",
      "Epoch: 68 -> Loss: 0.142064541578\n",
      "Epoch: 68 -> Test Accuracy: 85.72\n",
      "[69, 60] loss: 0.088\n",
      "[69, 120] loss: 0.089\n",
      "[69, 180] loss: 0.102\n",
      "[69, 240] loss: 0.102\n",
      "[69, 300] loss: 0.104\n",
      "[69, 360] loss: 0.104\n",
      "Epoch: 69 -> Loss: 0.106493912637\n",
      "Epoch: 69 -> Test Accuracy: 86.29\n",
      "[70, 60] loss: 0.108\n",
      "[70, 120] loss: 0.101\n",
      "[70, 180] loss: 0.102\n",
      "[70, 240] loss: 0.109\n",
      "[70, 300] loss: 0.111\n",
      "[70, 360] loss: 0.104\n",
      "Epoch: 70 -> Loss: 0.0716516599059\n",
      "Epoch: 70 -> Test Accuracy: 85.79\n",
      "[71, 60] loss: 0.072\n",
      "[71, 120] loss: 0.070\n",
      "[71, 180] loss: 0.065\n",
      "[71, 240] loss: 0.065\n",
      "[71, 300] loss: 0.064\n",
      "[71, 360] loss: 0.063\n",
      "Epoch: 71 -> Loss: 0.0283118542284\n",
      "Epoch: 71 -> Test Accuracy: 86.98\n",
      "[72, 60] loss: 0.055\n",
      "[72, 120] loss: 0.050\n",
      "[72, 180] loss: 0.055\n",
      "[72, 240] loss: 0.051\n",
      "[72, 300] loss: 0.054\n",
      "[72, 360] loss: 0.052\n",
      "Epoch: 72 -> Loss: 0.0638207644224\n",
      "Epoch: 72 -> Test Accuracy: 87.32\n",
      "[73, 60] loss: 0.051\n",
      "[73, 120] loss: 0.046\n",
      "[73, 180] loss: 0.049\n",
      "[73, 240] loss: 0.050\n",
      "[73, 300] loss: 0.049\n",
      "[73, 360] loss: 0.047\n",
      "Epoch: 73 -> Loss: 0.0525310151279\n",
      "Epoch: 73 -> Test Accuracy: 87.31\n",
      "[74, 60] loss: 0.044\n",
      "[74, 120] loss: 0.044\n",
      "[74, 180] loss: 0.044\n",
      "[74, 240] loss: 0.046\n",
      "[74, 300] loss: 0.043\n",
      "[74, 360] loss: 0.047\n",
      "Epoch: 74 -> Loss: 0.0487731695175\n",
      "Epoch: 74 -> Test Accuracy: 87.41\n",
      "[75, 60] loss: 0.041\n",
      "[75, 120] loss: 0.041\n",
      "[75, 180] loss: 0.040\n",
      "[75, 240] loss: 0.044\n",
      "[75, 300] loss: 0.038\n",
      "[75, 360] loss: 0.042\n",
      "Epoch: 75 -> Loss: 0.0646852627397\n",
      "Epoch: 75 -> Test Accuracy: 87.38\n",
      "[76, 60] loss: 0.038\n",
      "[76, 120] loss: 0.040\n",
      "[76, 180] loss: 0.041\n",
      "[76, 240] loss: 0.040\n",
      "[76, 300] loss: 0.041\n",
      "[76, 360] loss: 0.040\n",
      "Epoch: 76 -> Loss: 0.0567289665341\n",
      "Epoch: 76 -> Test Accuracy: 87.35\n",
      "[77, 60] loss: 0.036\n",
      "[77, 120] loss: 0.037\n",
      "[77, 180] loss: 0.040\n",
      "[77, 240] loss: 0.039\n",
      "[77, 300] loss: 0.039\n",
      "[77, 360] loss: 0.040\n",
      "Epoch: 77 -> Loss: 0.0298965964466\n",
      "Epoch: 77 -> Test Accuracy: 87.43\n",
      "[78, 60] loss: 0.037\n",
      "[78, 120] loss: 0.035\n",
      "[78, 180] loss: 0.036\n",
      "[78, 240] loss: 0.038\n",
      "[78, 300] loss: 0.037\n",
      "[78, 360] loss: 0.038\n",
      "Epoch: 78 -> Loss: 0.0560201629996\n",
      "Epoch: 78 -> Test Accuracy: 87.34\n",
      "[79, 60] loss: 0.035\n",
      "[79, 120] loss: 0.035\n",
      "[79, 180] loss: 0.035\n",
      "[79, 240] loss: 0.034\n",
      "[79, 300] loss: 0.037\n",
      "[79, 360] loss: 0.039\n",
      "Epoch: 79 -> Loss: 0.0272085014731\n",
      "Epoch: 79 -> Test Accuracy: 87.27\n",
      "[80, 60] loss: 0.033\n",
      "[80, 120] loss: 0.035\n",
      "[80, 180] loss: 0.035\n",
      "[80, 240] loss: 0.037\n",
      "[80, 300] loss: 0.037\n",
      "[80, 360] loss: 0.035\n",
      "Epoch: 80 -> Loss: 0.0840249359608\n",
      "Epoch: 80 -> Test Accuracy: 87.42\n",
      "[81, 60] loss: 0.032\n",
      "[81, 120] loss: 0.032\n",
      "[81, 180] loss: 0.036\n",
      "[81, 240] loss: 0.033\n",
      "[81, 300] loss: 0.036\n",
      "[81, 360] loss: 0.033\n",
      "Epoch: 81 -> Loss: 0.0457958467305\n",
      "Epoch: 81 -> Test Accuracy: 87.48\n",
      "[82, 60] loss: 0.032\n",
      "[82, 120] loss: 0.033\n",
      "[82, 180] loss: 0.035\n",
      "[82, 240] loss: 0.034\n",
      "[82, 300] loss: 0.033\n",
      "[82, 360] loss: 0.033\n",
      "Epoch: 82 -> Loss: 0.0705414712429\n",
      "Epoch: 82 -> Test Accuracy: 87.55\n",
      "[83, 60] loss: 0.032\n",
      "[83, 120] loss: 0.030\n",
      "[83, 180] loss: 0.035\n",
      "[83, 240] loss: 0.033\n",
      "[83, 300] loss: 0.031\n",
      "[83, 360] loss: 0.034\n",
      "Epoch: 83 -> Loss: 0.0714917704463\n",
      "Epoch: 83 -> Test Accuracy: 87.45\n",
      "[84, 60] loss: 0.032\n",
      "[84, 120] loss: 0.030\n",
      "[84, 180] loss: 0.032\n",
      "[84, 240] loss: 0.032\n",
      "[84, 300] loss: 0.031\n",
      "[84, 360] loss: 0.033\n",
      "Epoch: 84 -> Loss: 0.0440199822187\n",
      "Epoch: 84 -> Test Accuracy: 87.18\n",
      "[85, 60] loss: 0.029\n",
      "[85, 120] loss: 0.031\n",
      "[85, 180] loss: 0.033\n",
      "[85, 240] loss: 0.032\n",
      "[85, 300] loss: 0.031\n",
      "[85, 360] loss: 0.034\n",
      "Epoch: 85 -> Loss: 0.0358209684491\n",
      "Epoch: 85 -> Test Accuracy: 87.46\n",
      "[86, 60] loss: 0.030\n",
      "[86, 120] loss: 0.029\n",
      "[86, 180] loss: 0.028\n",
      "[86, 240] loss: 0.029\n",
      "[86, 300] loss: 0.029\n",
      "[86, 360] loss: 0.030\n",
      "Epoch: 86 -> Loss: 0.0255404952914\n",
      "Epoch: 86 -> Test Accuracy: 87.5\n",
      "[87, 60] loss: 0.029\n",
      "[87, 120] loss: 0.030\n",
      "[87, 180] loss: 0.028\n",
      "[87, 240] loss: 0.025\n",
      "[87, 300] loss: 0.028\n",
      "[87, 360] loss: 0.027\n",
      "Epoch: 87 -> Loss: 0.0373086929321\n",
      "Epoch: 87 -> Test Accuracy: 87.62\n",
      "[88, 60] loss: 0.028\n",
      "[88, 120] loss: 0.026\n",
      "[88, 180] loss: 0.025\n",
      "[88, 240] loss: 0.025\n",
      "[88, 300] loss: 0.027\n",
      "[88, 360] loss: 0.028\n",
      "Epoch: 88 -> Loss: 0.0332235470414\n",
      "Epoch: 88 -> Test Accuracy: 87.44\n",
      "[89, 60] loss: 0.027\n",
      "[89, 120] loss: 0.027\n",
      "[89, 180] loss: 0.028\n",
      "[89, 240] loss: 0.029\n",
      "[89, 300] loss: 0.028\n",
      "[89, 360] loss: 0.027\n",
      "Epoch: 89 -> Loss: 0.0757935941219\n",
      "Epoch: 89 -> Test Accuracy: 87.51\n",
      "[90, 60] loss: 0.027\n",
      "[90, 120] loss: 0.028\n",
      "[90, 180] loss: 0.026\n",
      "[90, 240] loss: 0.029\n",
      "[90, 300] loss: 0.027\n",
      "[90, 360] loss: 0.028\n",
      "Epoch: 90 -> Loss: 0.0413166806102\n",
      "Epoch: 90 -> Test Accuracy: 87.61\n",
      "[91, 60] loss: 0.027\n",
      "[91, 120] loss: 0.028\n",
      "[91, 180] loss: 0.026\n",
      "[91, 240] loss: 0.028\n",
      "[91, 300] loss: 0.027\n",
      "[91, 360] loss: 0.027\n",
      "Epoch: 91 -> Loss: 0.0229833628982\n",
      "Epoch: 91 -> Test Accuracy: 87.57\n",
      "[92, 60] loss: 0.025\n",
      "[92, 120] loss: 0.027\n",
      "[92, 180] loss: 0.026\n",
      "[92, 240] loss: 0.025\n",
      "[92, 300] loss: 0.027\n",
      "[92, 360] loss: 0.025\n",
      "Epoch: 92 -> Loss: 0.0167468488216\n",
      "Epoch: 92 -> Test Accuracy: 87.58\n",
      "[93, 60] loss: 0.027\n",
      "[93, 120] loss: 0.029\n",
      "[93, 180] loss: 0.027\n",
      "[93, 240] loss: 0.029\n",
      "[93, 300] loss: 0.026\n",
      "[93, 360] loss: 0.029\n",
      "Epoch: 93 -> Loss: 0.0906433686614\n",
      "Epoch: 93 -> Test Accuracy: 87.46\n",
      "[94, 60] loss: 0.025\n",
      "[94, 120] loss: 0.028\n",
      "[94, 180] loss: 0.024\n",
      "[94, 240] loss: 0.026\n",
      "[94, 300] loss: 0.028\n",
      "[94, 360] loss: 0.026\n",
      "Epoch: 94 -> Loss: 0.0270922221243\n",
      "Epoch: 94 -> Test Accuracy: 87.51\n",
      "[95, 60] loss: 0.024\n",
      "[95, 120] loss: 0.028\n",
      "[95, 180] loss: 0.026\n",
      "[95, 240] loss: 0.025\n",
      "[95, 300] loss: 0.026\n",
      "[95, 360] loss: 0.027\n",
      "Epoch: 95 -> Loss: 0.0367638990283\n",
      "Epoch: 95 -> Test Accuracy: 87.58\n",
      "[96, 60] loss: 0.023\n",
      "[96, 120] loss: 0.027\n",
      "[96, 180] loss: 0.026\n",
      "[96, 240] loss: 0.026\n",
      "[96, 300] loss: 0.027\n",
      "[96, 360] loss: 0.027\n",
      "Epoch: 96 -> Loss: 0.0215857513249\n",
      "Epoch: 96 -> Test Accuracy: 87.54\n",
      "[97, 60] loss: 0.025\n",
      "[97, 120] loss: 0.027\n",
      "[97, 180] loss: 0.025\n",
      "[97, 240] loss: 0.026\n",
      "[97, 300] loss: 0.026\n",
      "[97, 360] loss: 0.025\n",
      "Epoch: 97 -> Loss: 0.0136824902147\n",
      "Epoch: 97 -> Test Accuracy: 87.46\n",
      "[98, 60] loss: 0.025\n",
      "[98, 120] loss: 0.025\n",
      "[98, 180] loss: 0.026\n",
      "[98, 240] loss: 0.027\n",
      "[98, 300] loss: 0.026\n",
      "[98, 360] loss: 0.023\n",
      "Epoch: 98 -> Loss: 0.035959918052\n",
      "Epoch: 98 -> Test Accuracy: 87.47\n",
      "[99, 60] loss: 0.025\n",
      "[99, 120] loss: 0.025\n",
      "[99, 180] loss: 0.024\n",
      "[99, 240] loss: 0.025\n",
      "[99, 300] loss: 0.023\n",
      "[99, 360] loss: 0.027\n",
      "Epoch: 99 -> Loss: 0.0260456651449\n",
      "Epoch: 99 -> Test Accuracy: 87.53\n",
      "[100, 60] loss: 0.027\n",
      "[100, 120] loss: 0.027\n",
      "[100, 180] loss: 0.026\n",
      "[100, 240] loss: 0.024\n",
      "[100, 300] loss: 0.024\n",
      "[100, 360] loss: 0.025\n",
      "Epoch: 100 -> Loss: 0.0394380167127\n",
      "Epoch: 100 -> Test Accuracy: 87.51\n",
      "Finished Training\n",
      "[1, 60] loss: 0.927\n",
      "[1, 120] loss: 0.706\n",
      "[1, 180] loss: 0.694\n",
      "[1, 240] loss: 0.611\n",
      "[1, 300] loss: 0.613\n",
      "[1, 360] loss: 0.594\n",
      "Epoch: 1 -> Loss: 0.811976909637\n",
      "Epoch: 1 -> Test Accuracy: 73.16\n",
      "[2, 60] loss: 0.582\n",
      "[2, 120] loss: 0.556\n",
      "[2, 180] loss: 0.554\n",
      "[2, 240] loss: 0.549\n",
      "[2, 300] loss: 0.544\n",
      "[2, 360] loss: 0.555\n",
      "Epoch: 2 -> Loss: 0.433220922947\n",
      "Epoch: 2 -> Test Accuracy: 77.11\n",
      "[3, 60] loss: 0.515\n",
      "[3, 120] loss: 0.517\n",
      "[3, 180] loss: 0.534\n",
      "[3, 240] loss: 0.510\n",
      "[3, 300] loss: 0.508\n",
      "[3, 360] loss: 0.517\n",
      "Epoch: 3 -> Loss: 0.713454246521\n",
      "Epoch: 3 -> Test Accuracy: 77.81\n",
      "[4, 60] loss: 0.507\n",
      "[4, 120] loss: 0.487\n",
      "[4, 180] loss: 0.497\n",
      "[4, 240] loss: 0.506\n",
      "[4, 300] loss: 0.498\n",
      "[4, 360] loss: 0.510\n",
      "Epoch: 4 -> Loss: 0.487881273031\n",
      "Epoch: 4 -> Test Accuracy: 77.82\n",
      "[5, 60] loss: 0.484\n",
      "[5, 120] loss: 0.488\n",
      "[5, 180] loss: 0.477\n",
      "[5, 240] loss: 0.479\n",
      "[5, 300] loss: 0.498\n",
      "[5, 360] loss: 0.497\n",
      "Epoch: 5 -> Loss: 0.403085798025\n",
      "Epoch: 5 -> Test Accuracy: 78.08\n",
      "[6, 60] loss: 0.467\n",
      "[6, 120] loss: 0.478\n",
      "[6, 180] loss: 0.473\n",
      "[6, 240] loss: 0.485\n",
      "[6, 300] loss: 0.486\n",
      "[6, 360] loss: 0.485\n",
      "Epoch: 6 -> Loss: 0.432117313147\n",
      "Epoch: 6 -> Test Accuracy: 78.4\n",
      "[7, 60] loss: 0.449\n",
      "[7, 120] loss: 0.463\n",
      "[7, 180] loss: 0.458\n",
      "[7, 240] loss: 0.488\n",
      "[7, 300] loss: 0.485\n",
      "[7, 360] loss: 0.482\n",
      "Epoch: 7 -> Loss: 0.425429910421\n",
      "Epoch: 7 -> Test Accuracy: 78.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 60] loss: 0.447\n",
      "[8, 120] loss: 0.469\n",
      "[8, 180] loss: 0.457\n",
      "[8, 240] loss: 0.476\n",
      "[8, 300] loss: 0.465\n",
      "[8, 360] loss: 0.468\n",
      "Epoch: 8 -> Loss: 0.547881960869\n",
      "Epoch: 8 -> Test Accuracy: 78.58\n",
      "[9, 60] loss: 0.459\n",
      "[9, 120] loss: 0.462\n",
      "[9, 180] loss: 0.468\n",
      "[9, 240] loss: 0.454\n",
      "[9, 300] loss: 0.463\n",
      "[9, 360] loss: 0.456\n",
      "Epoch: 9 -> Loss: 0.346526294947\n",
      "Epoch: 9 -> Test Accuracy: 78.99\n",
      "[10, 60] loss: 0.461\n",
      "[10, 120] loss: 0.458\n",
      "[10, 180] loss: 0.457\n",
      "[10, 240] loss: 0.460\n",
      "[10, 300] loss: 0.452\n",
      "[10, 360] loss: 0.464\n",
      "Epoch: 10 -> Loss: 0.371485412121\n",
      "Epoch: 10 -> Test Accuracy: 79.56\n",
      "[11, 60] loss: 0.456\n",
      "[11, 120] loss: 0.455\n",
      "[11, 180] loss: 0.445\n",
      "[11, 240] loss: 0.463\n",
      "[11, 300] loss: 0.462\n",
      "[11, 360] loss: 0.458\n",
      "Epoch: 11 -> Loss: 0.404909223318\n",
      "Epoch: 11 -> Test Accuracy: 78.25\n",
      "[12, 60] loss: 0.445\n",
      "[12, 120] loss: 0.431\n",
      "[12, 180] loss: 0.461\n",
      "[12, 240] loss: 0.469\n",
      "[12, 300] loss: 0.449\n",
      "[12, 360] loss: 0.459\n",
      "Epoch: 12 -> Loss: 0.296258121729\n",
      "Epoch: 12 -> Test Accuracy: 78.54\n",
      "[13, 60] loss: 0.456\n",
      "[13, 120] loss: 0.438\n",
      "[13, 180] loss: 0.436\n",
      "[13, 240] loss: 0.450\n",
      "[13, 300] loss: 0.445\n",
      "[13, 360] loss: 0.449\n",
      "Epoch: 13 -> Loss: 0.433744490147\n",
      "Epoch: 13 -> Test Accuracy: 78.46\n",
      "[14, 60] loss: 0.429\n",
      "[14, 120] loss: 0.437\n",
      "[14, 180] loss: 0.448\n",
      "[14, 240] loss: 0.458\n",
      "[14, 300] loss: 0.448\n",
      "[14, 360] loss: 0.448\n",
      "Epoch: 14 -> Loss: 0.408450603485\n",
      "Epoch: 14 -> Test Accuracy: 78.51\n",
      "[15, 60] loss: 0.427\n",
      "[15, 120] loss: 0.436\n",
      "[15, 180] loss: 0.428\n",
      "[15, 240] loss: 0.445\n",
      "[15, 300] loss: 0.439\n",
      "[15, 360] loss: 0.465\n",
      "Epoch: 15 -> Loss: 0.506433069706\n",
      "Epoch: 15 -> Test Accuracy: 78.85\n",
      "[16, 60] loss: 0.391\n",
      "[16, 120] loss: 0.459\n",
      "[16, 180] loss: 0.444\n",
      "[16, 240] loss: 0.439\n",
      "[16, 300] loss: 0.446\n",
      "[16, 360] loss: 0.444\n",
      "Epoch: 16 -> Loss: 0.394210159779\n",
      "Epoch: 16 -> Test Accuracy: 79.46\n",
      "[17, 60] loss: 0.424\n",
      "[17, 120] loss: 0.442\n",
      "[17, 180] loss: 0.436\n",
      "[17, 240] loss: 0.446\n",
      "[17, 300] loss: 0.453\n",
      "[17, 360] loss: 0.431\n",
      "Epoch: 17 -> Loss: 0.391075283289\n",
      "Epoch: 17 -> Test Accuracy: 79.72\n",
      "[18, 60] loss: 0.426\n",
      "[18, 120] loss: 0.423\n",
      "[18, 180] loss: 0.428\n",
      "[18, 240] loss: 0.450\n",
      "[18, 300] loss: 0.444\n",
      "[18, 360] loss: 0.437\n",
      "Epoch: 18 -> Loss: 0.596585512161\n",
      "Epoch: 18 -> Test Accuracy: 79.04\n",
      "[19, 60] loss: 0.422\n",
      "[19, 120] loss: 0.435\n",
      "[19, 180] loss: 0.441\n",
      "[19, 240] loss: 0.442\n",
      "[19, 300] loss: 0.441\n",
      "[19, 360] loss: 0.440\n",
      "Epoch: 19 -> Loss: 0.308455973864\n",
      "Epoch: 19 -> Test Accuracy: 78.88\n",
      "[20, 60] loss: 0.415\n",
      "[20, 120] loss: 0.426\n",
      "[20, 180] loss: 0.440\n",
      "[20, 240] loss: 0.441\n",
      "[20, 300] loss: 0.449\n",
      "[20, 360] loss: 0.450\n",
      "Epoch: 20 -> Loss: 0.481938660145\n",
      "Epoch: 20 -> Test Accuracy: 79.73\n",
      "[21, 60] loss: 0.428\n",
      "[21, 120] loss: 0.419\n",
      "[21, 180] loss: 0.435\n",
      "[21, 240] loss: 0.430\n",
      "[21, 300] loss: 0.447\n",
      "[21, 360] loss: 0.438\n",
      "Epoch: 21 -> Loss: 0.314565896988\n",
      "Epoch: 21 -> Test Accuracy: 79.29\n",
      "[22, 60] loss: 0.435\n",
      "[22, 120] loss: 0.435\n",
      "[22, 180] loss: 0.416\n",
      "[22, 240] loss: 0.433\n",
      "[22, 300] loss: 0.445\n",
      "[22, 360] loss: 0.424\n",
      "Epoch: 22 -> Loss: 0.653281331062\n",
      "Epoch: 22 -> Test Accuracy: 79.16\n",
      "[23, 60] loss: 0.430\n",
      "[23, 120] loss: 0.414\n",
      "[23, 180] loss: 0.426\n",
      "[23, 240] loss: 0.452\n",
      "[23, 300] loss: 0.441\n",
      "[23, 360] loss: 0.433\n",
      "Epoch: 23 -> Loss: 0.382326424122\n",
      "Epoch: 23 -> Test Accuracy: 78.85\n",
      "[24, 60] loss: 0.423\n",
      "[24, 120] loss: 0.420\n",
      "[24, 180] loss: 0.427\n",
      "[24, 240] loss: 0.436\n",
      "[24, 300] loss: 0.434\n",
      "[24, 360] loss: 0.435\n",
      "Epoch: 24 -> Loss: 0.360422283411\n",
      "Epoch: 24 -> Test Accuracy: 79.82\n",
      "[25, 60] loss: 0.403\n",
      "[25, 120] loss: 0.421\n",
      "[25, 180] loss: 0.421\n",
      "[25, 240] loss: 0.443\n",
      "[25, 300] loss: 0.438\n",
      "[25, 360] loss: 0.455\n",
      "Epoch: 25 -> Loss: 0.485194593668\n",
      "Epoch: 25 -> Test Accuracy: 79.33\n",
      "[26, 60] loss: 0.418\n",
      "[26, 120] loss: 0.436\n",
      "[26, 180] loss: 0.426\n",
      "[26, 240] loss: 0.433\n",
      "[26, 300] loss: 0.429\n",
      "[26, 360] loss: 0.452\n",
      "Epoch: 26 -> Loss: 0.433655440807\n",
      "Epoch: 26 -> Test Accuracy: 79.91\n",
      "[27, 60] loss: 0.411\n",
      "[27, 120] loss: 0.432\n",
      "[27, 180] loss: 0.429\n",
      "[27, 240] loss: 0.414\n",
      "[27, 300] loss: 0.418\n",
      "[27, 360] loss: 0.455\n",
      "Epoch: 27 -> Loss: 0.462397426367\n",
      "Epoch: 27 -> Test Accuracy: 79.15\n",
      "[28, 60] loss: 0.410\n",
      "[28, 120] loss: 0.425\n",
      "[28, 180] loss: 0.403\n",
      "[28, 240] loss: 0.450\n",
      "[28, 300] loss: 0.427\n",
      "[28, 360] loss: 0.446\n",
      "Epoch: 28 -> Loss: 0.421744346619\n",
      "Epoch: 28 -> Test Accuracy: 78.94\n",
      "[29, 60] loss: 0.408\n",
      "[29, 120] loss: 0.415\n",
      "[29, 180] loss: 0.442\n",
      "[29, 240] loss: 0.434\n",
      "[29, 300] loss: 0.428\n",
      "[29, 360] loss: 0.424\n",
      "Epoch: 29 -> Loss: 0.635691225529\n",
      "Epoch: 29 -> Test Accuracy: 79.91\n",
      "[30, 60] loss: 0.396\n",
      "[30, 120] loss: 0.420\n",
      "[30, 180] loss: 0.438\n",
      "[30, 240] loss: 0.441\n",
      "[30, 300] loss: 0.430\n",
      "[30, 360] loss: 0.438\n",
      "Epoch: 30 -> Loss: 0.44491443038\n",
      "Epoch: 30 -> Test Accuracy: 78.85\n",
      "[31, 60] loss: 0.430\n",
      "[31, 120] loss: 0.419\n",
      "[31, 180] loss: 0.425\n",
      "[31, 240] loss: 0.424\n",
      "[31, 300] loss: 0.431\n",
      "[31, 360] loss: 0.442\n",
      "Epoch: 31 -> Loss: 0.419756472111\n",
      "Epoch: 31 -> Test Accuracy: 79.34\n",
      "[32, 60] loss: 0.411\n",
      "[32, 120] loss: 0.416\n",
      "[32, 180] loss: 0.413\n",
      "[32, 240] loss: 0.439\n",
      "[32, 300] loss: 0.429\n",
      "[32, 360] loss: 0.448\n",
      "Epoch: 32 -> Loss: 0.450654566288\n",
      "Epoch: 32 -> Test Accuracy: 79.81\n",
      "[33, 60] loss: 0.404\n",
      "[33, 120] loss: 0.424\n",
      "[33, 180] loss: 0.423\n",
      "[33, 240] loss: 0.430\n",
      "[33, 300] loss: 0.445\n",
      "[33, 360] loss: 0.438\n",
      "Epoch: 33 -> Loss: 0.564715325832\n",
      "Epoch: 33 -> Test Accuracy: 80.12\n",
      "[34, 60] loss: 0.416\n",
      "[34, 120] loss: 0.435\n",
      "[34, 180] loss: 0.427\n",
      "[34, 240] loss: 0.423\n",
      "[34, 300] loss: 0.427\n",
      "[34, 360] loss: 0.442\n",
      "Epoch: 34 -> Loss: 0.406145274639\n",
      "Epoch: 34 -> Test Accuracy: 79.83\n",
      "[35, 60] loss: 0.414\n",
      "[35, 120] loss: 0.423\n",
      "[35, 180] loss: 0.432\n",
      "[35, 240] loss: 0.434\n",
      "[35, 300] loss: 0.411\n",
      "[35, 360] loss: 0.429\n",
      "Epoch: 35 -> Loss: 0.470032036304\n",
      "Epoch: 35 -> Test Accuracy: 78.69\n",
      "[36, 60] loss: 0.370\n",
      "[36, 120] loss: 0.352\n",
      "[36, 180] loss: 0.337\n",
      "[36, 240] loss: 0.356\n",
      "[36, 300] loss: 0.349\n",
      "[36, 360] loss: 0.328\n",
      "Epoch: 36 -> Loss: 0.239828780293\n",
      "Epoch: 36 -> Test Accuracy: 81.94\n",
      "[37, 60] loss: 0.327\n",
      "[37, 120] loss: 0.310\n",
      "[37, 180] loss: 0.328\n",
      "[37, 240] loss: 0.317\n",
      "[37, 300] loss: 0.339\n",
      "[37, 360] loss: 0.326\n",
      "Epoch: 37 -> Loss: 0.335123121738\n",
      "Epoch: 37 -> Test Accuracy: 82.21\n",
      "[38, 60] loss: 0.309\n",
      "[38, 120] loss: 0.311\n",
      "[38, 180] loss: 0.312\n",
      "[38, 240] loss: 0.310\n",
      "[38, 300] loss: 0.323\n",
      "[38, 360] loss: 0.314\n",
      "Epoch: 38 -> Loss: 0.407171189785\n",
      "Epoch: 38 -> Test Accuracy: 82.26\n",
      "[39, 60] loss: 0.298\n",
      "[39, 120] loss: 0.312\n",
      "[39, 180] loss: 0.306\n",
      "[39, 240] loss: 0.286\n",
      "[39, 300] loss: 0.318\n",
      "[39, 360] loss: 0.309\n",
      "Epoch: 39 -> Loss: 0.31560999155\n",
      "Epoch: 39 -> Test Accuracy: 82.17\n",
      "[40, 60] loss: 0.283\n",
      "[40, 120] loss: 0.298\n",
      "[40, 180] loss: 0.293\n",
      "[40, 240] loss: 0.313\n",
      "[40, 300] loss: 0.309\n",
      "[40, 360] loss: 0.314\n",
      "Epoch: 40 -> Loss: 0.327544867992\n",
      "Epoch: 40 -> Test Accuracy: 82.04\n",
      "[41, 60] loss: 0.279\n",
      "[41, 120] loss: 0.287\n",
      "[41, 180] loss: 0.305\n",
      "[41, 240] loss: 0.305\n",
      "[41, 300] loss: 0.297\n",
      "[41, 360] loss: 0.300\n",
      "Epoch: 41 -> Loss: 0.418065220118\n",
      "Epoch: 41 -> Test Accuracy: 81.83\n",
      "[42, 60] loss: 0.294\n",
      "[42, 120] loss: 0.283\n",
      "[42, 180] loss: 0.306\n",
      "[42, 240] loss: 0.311\n",
      "[42, 300] loss: 0.312\n",
      "[42, 360] loss: 0.304\n",
      "Epoch: 42 -> Loss: 0.415787875652\n",
      "Epoch: 42 -> Test Accuracy: 82.21\n",
      "[43, 60] loss: 0.273\n",
      "[43, 120] loss: 0.289\n",
      "[43, 180] loss: 0.295\n",
      "[43, 240] loss: 0.309\n",
      "[43, 300] loss: 0.315\n",
      "[43, 360] loss: 0.293\n",
      "Epoch: 43 -> Loss: 0.199077174067\n",
      "Epoch: 43 -> Test Accuracy: 81.73\n",
      "[44, 60] loss: 0.271\n",
      "[44, 120] loss: 0.292\n",
      "[44, 180] loss: 0.282\n",
      "[44, 240] loss: 0.286\n",
      "[44, 300] loss: 0.300\n",
      "[44, 360] loss: 0.308\n",
      "Epoch: 44 -> Loss: 0.395281791687\n",
      "Epoch: 44 -> Test Accuracy: 81.65\n",
      "[45, 60] loss: 0.293\n",
      "[45, 120] loss: 0.289\n",
      "[45, 180] loss: 0.294\n",
      "[45, 240] loss: 0.291\n",
      "[45, 300] loss: 0.296\n",
      "[45, 360] loss: 0.296\n",
      "Epoch: 45 -> Loss: 0.357759684324\n",
      "Epoch: 45 -> Test Accuracy: 81.49\n",
      "[46, 60] loss: 0.294\n",
      "[46, 120] loss: 0.284\n",
      "[46, 180] loss: 0.269\n",
      "[46, 240] loss: 0.301\n",
      "[46, 300] loss: 0.297\n",
      "[46, 360] loss: 0.296\n",
      "Epoch: 46 -> Loss: 0.243716195226\n",
      "Epoch: 46 -> Test Accuracy: 81.48\n",
      "[47, 60] loss: 0.293\n",
      "[47, 120] loss: 0.291\n",
      "[47, 180] loss: 0.292\n",
      "[47, 240] loss: 0.292\n",
      "[47, 300] loss: 0.292\n",
      "[47, 360] loss: 0.299\n",
      "Epoch: 47 -> Loss: 0.361132323742\n",
      "Epoch: 47 -> Test Accuracy: 81.38\n",
      "[48, 60] loss: 0.287\n",
      "[48, 120] loss: 0.291\n",
      "[48, 180] loss: 0.274\n",
      "[48, 240] loss: 0.282\n",
      "[48, 300] loss: 0.293\n",
      "[48, 360] loss: 0.293\n",
      "Epoch: 48 -> Loss: 0.331814050674\n",
      "Epoch: 48 -> Test Accuracy: 81.92\n",
      "[49, 60] loss: 0.281\n",
      "[49, 120] loss: 0.292\n",
      "[49, 180] loss: 0.282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 240] loss: 0.292\n",
      "[49, 300] loss: 0.300\n",
      "[49, 360] loss: 0.298\n",
      "Epoch: 49 -> Loss: 0.386801183224\n",
      "Epoch: 49 -> Test Accuracy: 81.21\n",
      "[50, 60] loss: 0.272\n",
      "[50, 120] loss: 0.293\n",
      "[50, 180] loss: 0.292\n",
      "[50, 240] loss: 0.283\n",
      "[50, 300] loss: 0.301\n",
      "[50, 360] loss: 0.291\n",
      "Epoch: 50 -> Loss: 0.23200365901\n",
      "Epoch: 50 -> Test Accuracy: 81.19\n",
      "[51, 60] loss: 0.274\n",
      "[51, 120] loss: 0.291\n",
      "[51, 180] loss: 0.286\n",
      "[51, 240] loss: 0.296\n",
      "[51, 300] loss: 0.292\n",
      "[51, 360] loss: 0.287\n",
      "Epoch: 51 -> Loss: 0.242871567607\n",
      "Epoch: 51 -> Test Accuracy: 80.92\n",
      "[52, 60] loss: 0.273\n",
      "[52, 120] loss: 0.280\n",
      "[52, 180] loss: 0.297\n",
      "[52, 240] loss: 0.278\n",
      "[52, 300] loss: 0.287\n",
      "[52, 360] loss: 0.302\n",
      "Epoch: 52 -> Loss: 0.286178827286\n",
      "Epoch: 52 -> Test Accuracy: 80.63\n",
      "[53, 60] loss: 0.278\n",
      "[53, 120] loss: 0.274\n",
      "[53, 180] loss: 0.295\n",
      "[53, 240] loss: 0.283\n",
      "[53, 300] loss: 0.305\n",
      "[53, 360] loss: 0.307\n",
      "Epoch: 53 -> Loss: 0.316494882107\n",
      "Epoch: 53 -> Test Accuracy: 81.29\n",
      "[54, 60] loss: 0.265\n",
      "[54, 120] loss: 0.271\n",
      "[54, 180] loss: 0.286\n",
      "[54, 240] loss: 0.294\n",
      "[54, 300] loss: 0.281\n",
      "[54, 360] loss: 0.294\n",
      "Epoch: 54 -> Loss: 0.257633566856\n",
      "Epoch: 54 -> Test Accuracy: 81.32\n",
      "[55, 60] loss: 0.272\n",
      "[55, 120] loss: 0.269\n",
      "[55, 180] loss: 0.277\n",
      "[55, 240] loss: 0.291\n",
      "[55, 300] loss: 0.296\n",
      "[55, 360] loss: 0.286\n",
      "Epoch: 55 -> Loss: 0.210259392858\n",
      "Epoch: 55 -> Test Accuracy: 81.15\n",
      "[56, 60] loss: 0.262\n",
      "[56, 120] loss: 0.278\n",
      "[56, 180] loss: 0.285\n",
      "[56, 240] loss: 0.276\n",
      "[56, 300] loss: 0.285\n",
      "[56, 360] loss: 0.292\n",
      "Epoch: 56 -> Loss: 0.20684723556\n",
      "Epoch: 56 -> Test Accuracy: 80.95\n",
      "[57, 60] loss: 0.277\n",
      "[57, 120] loss: 0.274\n",
      "[57, 180] loss: 0.279\n",
      "[57, 240] loss: 0.276\n",
      "[57, 300] loss: 0.284\n",
      "[57, 360] loss: 0.305\n",
      "Epoch: 57 -> Loss: 0.476442813873\n",
      "Epoch: 57 -> Test Accuracy: 81.72\n",
      "[58, 60] loss: 0.287\n",
      "[58, 120] loss: 0.277\n",
      "[58, 180] loss: 0.269\n",
      "[58, 240] loss: 0.273\n",
      "[58, 300] loss: 0.287\n",
      "[58, 360] loss: 0.291\n",
      "Epoch: 58 -> Loss: 0.35708412528\n",
      "Epoch: 58 -> Test Accuracy: 81.53\n",
      "[59, 60] loss: 0.263\n",
      "[59, 120] loss: 0.281\n",
      "[59, 180] loss: 0.275\n",
      "[59, 240] loss: 0.280\n",
      "[59, 300] loss: 0.287\n",
      "[59, 360] loss: 0.303\n",
      "Epoch: 59 -> Loss: 0.203604191542\n",
      "Epoch: 59 -> Test Accuracy: 81.76\n",
      "[60, 60] loss: 0.283\n",
      "[60, 120] loss: 0.277\n",
      "[60, 180] loss: 0.269\n",
      "[60, 240] loss: 0.282\n",
      "[60, 300] loss: 0.275\n",
      "[60, 360] loss: 0.288\n",
      "Epoch: 60 -> Loss: 0.323610693216\n",
      "Epoch: 60 -> Test Accuracy: 81.23\n",
      "[61, 60] loss: 0.270\n",
      "[61, 120] loss: 0.278\n",
      "[61, 180] loss: 0.280\n",
      "[61, 240] loss: 0.299\n",
      "[61, 300] loss: 0.283\n",
      "[61, 360] loss: 0.272\n",
      "Epoch: 61 -> Loss: 0.362679421902\n",
      "Epoch: 61 -> Test Accuracy: 81.07\n",
      "[62, 60] loss: 0.278\n",
      "[62, 120] loss: 0.270\n",
      "[62, 180] loss: 0.282\n",
      "[62, 240] loss: 0.281\n",
      "[62, 300] loss: 0.279\n",
      "[62, 360] loss: 0.277\n",
      "Epoch: 62 -> Loss: 0.281638562679\n",
      "Epoch: 62 -> Test Accuracy: 81.47\n",
      "[63, 60] loss: 0.260\n",
      "[63, 120] loss: 0.266\n",
      "[63, 180] loss: 0.298\n",
      "[63, 240] loss: 0.265\n",
      "[63, 300] loss: 0.275\n",
      "[63, 360] loss: 0.295\n",
      "Epoch: 63 -> Loss: 0.306471168995\n",
      "Epoch: 63 -> Test Accuracy: 81.1\n",
      "[64, 60] loss: 0.260\n",
      "[64, 120] loss: 0.265\n",
      "[64, 180] loss: 0.272\n",
      "[64, 240] loss: 0.280\n",
      "[64, 300] loss: 0.280\n",
      "[64, 360] loss: 0.284\n",
      "Epoch: 64 -> Loss: 0.202255055308\n",
      "Epoch: 64 -> Test Accuracy: 81.75\n",
      "[65, 60] loss: 0.261\n",
      "[65, 120] loss: 0.260\n",
      "[65, 180] loss: 0.261\n",
      "[65, 240] loss: 0.272\n",
      "[65, 300] loss: 0.285\n",
      "[65, 360] loss: 0.285\n",
      "Epoch: 65 -> Loss: 0.345646888018\n",
      "Epoch: 65 -> Test Accuracy: 80.95\n",
      "[66, 60] loss: 0.267\n",
      "[66, 120] loss: 0.269\n",
      "[66, 180] loss: 0.267\n",
      "[66, 240] loss: 0.270\n",
      "[66, 300] loss: 0.277\n",
      "[66, 360] loss: 0.286\n",
      "Epoch: 66 -> Loss: 0.385968446732\n",
      "Epoch: 66 -> Test Accuracy: 80.76\n",
      "[67, 60] loss: 0.255\n",
      "[67, 120] loss: 0.263\n",
      "[67, 180] loss: 0.270\n",
      "[67, 240] loss: 0.279\n",
      "[67, 300] loss: 0.284\n",
      "[67, 360] loss: 0.270\n",
      "Epoch: 67 -> Loss: 0.227666288614\n",
      "Epoch: 67 -> Test Accuracy: 81.22\n",
      "[68, 60] loss: 0.256\n",
      "[68, 120] loss: 0.281\n",
      "[68, 180] loss: 0.274\n",
      "[68, 240] loss: 0.273\n",
      "[68, 300] loss: 0.284\n",
      "[68, 360] loss: 0.280\n",
      "Epoch: 68 -> Loss: 0.238471776247\n",
      "Epoch: 68 -> Test Accuracy: 80.59\n",
      "[69, 60] loss: 0.259\n",
      "[69, 120] loss: 0.252\n",
      "[69, 180] loss: 0.279\n",
      "[69, 240] loss: 0.274\n",
      "[69, 300] loss: 0.278\n",
      "[69, 360] loss: 0.273\n",
      "Epoch: 69 -> Loss: 0.189903706312\n",
      "Epoch: 69 -> Test Accuracy: 81.48\n",
      "[70, 60] loss: 0.251\n",
      "[70, 120] loss: 0.261\n",
      "[70, 180] loss: 0.259\n",
      "[70, 240] loss: 0.281\n",
      "[70, 300] loss: 0.278\n",
      "[70, 360] loss: 0.275\n",
      "Epoch: 70 -> Loss: 0.223925873637\n",
      "Epoch: 70 -> Test Accuracy: 80.98\n",
      "[71, 60] loss: 0.233\n",
      "[71, 120] loss: 0.217\n",
      "[71, 180] loss: 0.218\n",
      "[71, 240] loss: 0.218\n",
      "[71, 300] loss: 0.222\n",
      "[71, 360] loss: 0.224\n",
      "Epoch: 71 -> Loss: 0.260722696781\n",
      "Epoch: 71 -> Test Accuracy: 82.68\n",
      "[72, 60] loss: 0.205\n",
      "[72, 120] loss: 0.204\n",
      "[72, 180] loss: 0.199\n",
      "[72, 240] loss: 0.199\n",
      "[72, 300] loss: 0.201\n",
      "[72, 360] loss: 0.213\n",
      "Epoch: 72 -> Loss: 0.214494615793\n",
      "Epoch: 72 -> Test Accuracy: 82.19\n",
      "[73, 60] loss: 0.194\n",
      "[73, 120] loss: 0.183\n",
      "[73, 180] loss: 0.209\n",
      "[73, 240] loss: 0.203\n",
      "[73, 300] loss: 0.208\n",
      "[73, 360] loss: 0.185\n",
      "Epoch: 73 -> Loss: 0.156655460596\n",
      "Epoch: 73 -> Test Accuracy: 82.83\n",
      "[74, 60] loss: 0.186\n",
      "[74, 120] loss: 0.195\n",
      "[74, 180] loss: 0.188\n",
      "[74, 240] loss: 0.192\n",
      "[74, 300] loss: 0.183\n",
      "[74, 360] loss: 0.195\n",
      "Epoch: 74 -> Loss: 0.207262486219\n",
      "Epoch: 74 -> Test Accuracy: 82.72\n",
      "[75, 60] loss: 0.186\n",
      "[75, 120] loss: 0.180\n",
      "[75, 180] loss: 0.186\n",
      "[75, 240] loss: 0.189\n",
      "[75, 300] loss: 0.194\n",
      "[75, 360] loss: 0.186\n",
      "Epoch: 75 -> Loss: 0.316560894251\n",
      "Epoch: 75 -> Test Accuracy: 82.58\n",
      "[76, 60] loss: 0.181\n",
      "[76, 120] loss: 0.177\n",
      "[76, 180] loss: 0.188\n",
      "[76, 240] loss: 0.183\n",
      "[76, 300] loss: 0.181\n",
      "[76, 360] loss: 0.183\n",
      "Epoch: 76 -> Loss: 0.214853838086\n",
      "Epoch: 76 -> Test Accuracy: 82.18\n",
      "[77, 60] loss: 0.178\n",
      "[77, 120] loss: 0.177\n",
      "[77, 180] loss: 0.165\n",
      "[77, 240] loss: 0.184\n",
      "[77, 300] loss: 0.187\n",
      "[77, 360] loss: 0.196\n",
      "Epoch: 77 -> Loss: 0.300101459026\n",
      "Epoch: 77 -> Test Accuracy: 82.48\n",
      "[78, 60] loss: 0.172\n",
      "[78, 120] loss: 0.176\n",
      "[78, 180] loss: 0.176\n",
      "[78, 240] loss: 0.179\n",
      "[78, 300] loss: 0.169\n",
      "[78, 360] loss: 0.185\n",
      "Epoch: 78 -> Loss: 0.218461677432\n",
      "Epoch: 78 -> Test Accuracy: 82.4\n",
      "[79, 60] loss: 0.188\n",
      "[79, 120] loss: 0.183\n",
      "[79, 180] loss: 0.175\n",
      "[79, 240] loss: 0.179\n",
      "[79, 300] loss: 0.184\n",
      "[79, 360] loss: 0.178\n",
      "Epoch: 79 -> Loss: 0.223710864782\n",
      "Epoch: 79 -> Test Accuracy: 82.95\n",
      "[80, 60] loss: 0.172\n",
      "[80, 120] loss: 0.183\n",
      "[80, 180] loss: 0.170\n",
      "[80, 240] loss: 0.175\n",
      "[80, 300] loss: 0.167\n",
      "[80, 360] loss: 0.169\n",
      "Epoch: 80 -> Loss: 0.266410052776\n",
      "Epoch: 80 -> Test Accuracy: 82.41\n",
      "[81, 60] loss: 0.174\n",
      "[81, 120] loss: 0.168\n",
      "[81, 180] loss: 0.155\n",
      "[81, 240] loss: 0.173\n",
      "[81, 300] loss: 0.177\n",
      "[81, 360] loss: 0.179\n",
      "Epoch: 81 -> Loss: 0.122830294073\n",
      "Epoch: 81 -> Test Accuracy: 82.57\n",
      "[82, 60] loss: 0.165\n",
      "[82, 120] loss: 0.162\n",
      "[82, 180] loss: 0.167\n",
      "[82, 240] loss: 0.166\n",
      "[82, 300] loss: 0.180\n",
      "[82, 360] loss: 0.180\n",
      "Epoch: 82 -> Loss: 0.207649797201\n",
      "Epoch: 82 -> Test Accuracy: 82.28\n",
      "[83, 60] loss: 0.169\n",
      "[83, 120] loss: 0.166\n",
      "[83, 180] loss: 0.170\n",
      "[83, 240] loss: 0.153\n",
      "[83, 300] loss: 0.173\n",
      "[83, 360] loss: 0.165\n",
      "Epoch: 83 -> Loss: 0.154333978891\n",
      "Epoch: 83 -> Test Accuracy: 82.63\n",
      "[84, 60] loss: 0.163\n",
      "[84, 120] loss: 0.163\n",
      "[84, 180] loss: 0.167\n",
      "[84, 240] loss: 0.165\n",
      "[84, 300] loss: 0.175\n",
      "[84, 360] loss: 0.173\n",
      "Epoch: 84 -> Loss: 0.135525375605\n",
      "Epoch: 84 -> Test Accuracy: 82.21\n",
      "[85, 60] loss: 0.157\n",
      "[85, 120] loss: 0.169\n",
      "[85, 180] loss: 0.162\n",
      "[85, 240] loss: 0.167\n",
      "[85, 300] loss: 0.169\n",
      "[85, 360] loss: 0.165\n",
      "Epoch: 85 -> Loss: 0.139781787992\n",
      "Epoch: 85 -> Test Accuracy: 82.38\n",
      "[86, 60] loss: 0.162\n",
      "[86, 120] loss: 0.147\n",
      "[86, 180] loss: 0.154\n",
      "[86, 240] loss: 0.150\n",
      "[86, 300] loss: 0.152\n",
      "[86, 360] loss: 0.152\n",
      "Epoch: 86 -> Loss: 0.162830859423\n",
      "Epoch: 86 -> Test Accuracy: 82.98\n",
      "[87, 60] loss: 0.149\n",
      "[87, 120] loss: 0.145\n",
      "[87, 180] loss: 0.141\n",
      "[87, 240] loss: 0.146\n",
      "[87, 300] loss: 0.145\n",
      "[87, 360] loss: 0.148\n",
      "Epoch: 87 -> Loss: 0.153992176056\n",
      "Epoch: 87 -> Test Accuracy: 83.13\n",
      "[88, 60] loss: 0.149\n",
      "[88, 120] loss: 0.145\n",
      "[88, 180] loss: 0.147\n",
      "[88, 240] loss: 0.146\n",
      "[88, 300] loss: 0.148\n",
      "[88, 360] loss: 0.143\n",
      "Epoch: 88 -> Loss: 0.178847685456\n",
      "Epoch: 88 -> Test Accuracy: 82.6\n",
      "[89, 60] loss: 0.147\n",
      "[89, 120] loss: 0.147\n",
      "[89, 180] loss: 0.144\n",
      "[89, 240] loss: 0.132\n",
      "[89, 300] loss: 0.146\n",
      "[89, 360] loss: 0.137\n",
      "Epoch: 89 -> Loss: 0.145955607295\n",
      "Epoch: 89 -> Test Accuracy: 82.8\n",
      "[90, 60] loss: 0.141\n",
      "[90, 120] loss: 0.143\n",
      "[90, 180] loss: 0.136\n",
      "[90, 240] loss: 0.146\n",
      "[90, 300] loss: 0.156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90, 360] loss: 0.146\n",
      "Epoch: 90 -> Loss: 0.12051513046\n",
      "Epoch: 90 -> Test Accuracy: 82.93\n",
      "[91, 60] loss: 0.137\n",
      "[91, 120] loss: 0.147\n",
      "[91, 180] loss: 0.136\n",
      "[91, 240] loss: 0.146\n",
      "[91, 300] loss: 0.142\n",
      "[91, 360] loss: 0.139\n",
      "Epoch: 91 -> Loss: 0.120810866356\n",
      "Epoch: 91 -> Test Accuracy: 82.75\n",
      "[92, 60] loss: 0.136\n",
      "[92, 120] loss: 0.145\n",
      "[92, 180] loss: 0.139\n",
      "[92, 240] loss: 0.148\n",
      "[92, 300] loss: 0.137\n",
      "[92, 360] loss: 0.142\n",
      "Epoch: 92 -> Loss: 0.225755020976\n",
      "Epoch: 92 -> Test Accuracy: 82.93\n",
      "[93, 60] loss: 0.138\n",
      "[93, 120] loss: 0.133\n",
      "[93, 180] loss: 0.140\n",
      "[93, 240] loss: 0.149\n",
      "[93, 300] loss: 0.138\n",
      "[93, 360] loss: 0.141\n",
      "Epoch: 93 -> Loss: 0.134782940149\n",
      "Epoch: 93 -> Test Accuracy: 82.84\n",
      "[94, 60] loss: 0.135\n",
      "[94, 120] loss: 0.136\n",
      "[94, 180] loss: 0.134\n",
      "[94, 240] loss: 0.146\n",
      "[94, 300] loss: 0.136\n",
      "[94, 360] loss: 0.143\n",
      "Epoch: 94 -> Loss: 0.169268041849\n",
      "Epoch: 94 -> Test Accuracy: 82.68\n",
      "[95, 60] loss: 0.131\n",
      "[95, 120] loss: 0.143\n",
      "[95, 180] loss: 0.138\n",
      "[95, 240] loss: 0.142\n",
      "[95, 300] loss: 0.140\n",
      "[95, 360] loss: 0.144\n",
      "Epoch: 95 -> Loss: 0.135362163186\n",
      "Epoch: 95 -> Test Accuracy: 82.81\n",
      "[96, 60] loss: 0.137\n",
      "[96, 120] loss: 0.140\n",
      "[96, 180] loss: 0.134\n",
      "[96, 240] loss: 0.143\n",
      "[96, 300] loss: 0.143\n",
      "[96, 360] loss: 0.149\n",
      "Epoch: 96 -> Loss: 0.138682290912\n",
      "Epoch: 96 -> Test Accuracy: 82.65\n",
      "[97, 60] loss: 0.136\n",
      "[97, 120] loss: 0.134\n",
      "[97, 180] loss: 0.128\n",
      "[97, 240] loss: 0.143\n",
      "[97, 300] loss: 0.134\n",
      "[97, 360] loss: 0.137\n",
      "Epoch: 97 -> Loss: 0.0915599763393\n",
      "Epoch: 97 -> Test Accuracy: 82.56\n",
      "[98, 60] loss: 0.135\n",
      "[98, 120] loss: 0.133\n",
      "[98, 180] loss: 0.129\n",
      "[98, 240] loss: 0.142\n",
      "[98, 300] loss: 0.136\n",
      "[98, 360] loss: 0.136\n",
      "Epoch: 98 -> Loss: 0.102231681347\n",
      "Epoch: 98 -> Test Accuracy: 82.82\n",
      "[99, 60] loss: 0.139\n",
      "[99, 120] loss: 0.134\n",
      "[99, 180] loss: 0.141\n",
      "[99, 240] loss: 0.142\n",
      "[99, 300] loss: 0.139\n",
      "[99, 360] loss: 0.133\n",
      "Epoch: 99 -> Loss: 0.148599386215\n",
      "Epoch: 99 -> Test Accuracy: 82.68\n",
      "[100, 60] loss: 0.143\n",
      "[100, 120] loss: 0.134\n",
      "[100, 180] loss: 0.142\n",
      "[100, 240] loss: 0.130\n",
      "[100, 300] loss: 0.141\n",
      "[100, 360] loss: 0.130\n",
      "Epoch: 100 -> Loss: 0.162463098764\n",
      "Epoch: 100 -> Test Accuracy: 82.66\n",
      "Finished Training\n",
      "[1, 60] loss: 2.073\n",
      "[1, 120] loss: 1.916\n",
      "[1, 180] loss: 1.866\n",
      "[1, 240] loss: 1.819\n",
      "[1, 300] loss: 1.798\n",
      "[1, 360] loss: 1.791\n",
      "Epoch: 1 -> Loss: 1.71760714054\n",
      "Epoch: 1 -> Test Accuracy: 31.74\n",
      "[2, 60] loss: 1.760\n",
      "[2, 120] loss: 1.746\n",
      "[2, 180] loss: 1.716\n",
      "[2, 240] loss: 1.722\n",
      "[2, 300] loss: 1.708\n",
      "[2, 360] loss: 1.679\n",
      "Epoch: 2 -> Loss: 1.79519402981\n",
      "Epoch: 2 -> Test Accuracy: 34.69\n",
      "[3, 60] loss: 1.680\n",
      "[3, 120] loss: 1.679\n",
      "[3, 180] loss: 1.676\n",
      "[3, 240] loss: 1.637\n",
      "[3, 300] loss: 1.659\n",
      "[3, 360] loss: 1.642\n",
      "Epoch: 3 -> Loss: 1.53267753124\n",
      "Epoch: 3 -> Test Accuracy: 35.49\n",
      "[4, 60] loss: 1.663\n",
      "[4, 120] loss: 1.635\n",
      "[4, 180] loss: 1.618\n",
      "[4, 240] loss: 1.619\n",
      "[4, 300] loss: 1.613\n",
      "[4, 360] loss: 1.615\n",
      "Epoch: 4 -> Loss: 1.64429593086\n",
      "Epoch: 4 -> Test Accuracy: 36.25\n",
      "[5, 60] loss: 1.621\n",
      "[5, 120] loss: 1.617\n",
      "[5, 180] loss: 1.599\n",
      "[5, 240] loss: 1.614\n",
      "[5, 300] loss: 1.579\n",
      "[5, 360] loss: 1.594\n",
      "Epoch: 5 -> Loss: 1.53579962254\n",
      "Epoch: 5 -> Test Accuracy: 37.23\n",
      "[6, 60] loss: 1.589\n",
      "[6, 120] loss: 1.570\n",
      "[6, 180] loss: 1.612\n",
      "[6, 240] loss: 1.578\n",
      "[6, 300] loss: 1.587\n",
      "[6, 360] loss: 1.580\n",
      "Epoch: 6 -> Loss: 1.61392271519\n",
      "Epoch: 6 -> Test Accuracy: 38.37\n",
      "[7, 60] loss: 1.596\n",
      "[7, 120] loss: 1.575\n",
      "[7, 180] loss: 1.565\n",
      "[7, 240] loss: 1.586\n",
      "[7, 300] loss: 1.577\n",
      "[7, 360] loss: 1.570\n",
      "Epoch: 7 -> Loss: 1.53140175343\n",
      "Epoch: 7 -> Test Accuracy: 38.57\n",
      "[8, 60] loss: 1.565\n",
      "[8, 120] loss: 1.566\n",
      "[8, 180] loss: 1.567\n",
      "[8, 240] loss: 1.564\n",
      "[8, 300] loss: 1.571\n",
      "[8, 360] loss: 1.574\n",
      "Epoch: 8 -> Loss: 1.5217911005\n",
      "Epoch: 8 -> Test Accuracy: 39.32\n",
      "[9, 60] loss: 1.573\n",
      "[9, 120] loss: 1.550\n",
      "[9, 180] loss: 1.550\n",
      "[9, 240] loss: 1.563\n",
      "[9, 300] loss: 1.570\n",
      "[9, 360] loss: 1.551\n",
      "Epoch: 9 -> Loss: 1.55963587761\n",
      "Epoch: 9 -> Test Accuracy: 37.82\n",
      "[10, 60] loss: 1.553\n",
      "[10, 120] loss: 1.575\n",
      "[10, 180] loss: 1.542\n",
      "[10, 240] loss: 1.533\n",
      "[10, 300] loss: 1.544\n",
      "[10, 360] loss: 1.535\n",
      "Epoch: 10 -> Loss: 1.75096929073\n",
      "Epoch: 10 -> Test Accuracy: 38.5\n",
      "[11, 60] loss: 1.558\n",
      "[11, 120] loss: 1.534\n",
      "[11, 180] loss: 1.556\n",
      "[11, 240] loss: 1.546\n",
      "[11, 300] loss: 1.515\n",
      "[11, 360] loss: 1.531\n",
      "Epoch: 11 -> Loss: 1.49889528751\n",
      "Epoch: 11 -> Test Accuracy: 39.78\n",
      "[12, 60] loss: 1.533\n",
      "[12, 120] loss: 1.543\n",
      "[12, 180] loss: 1.545\n",
      "[12, 240] loss: 1.563\n",
      "[12, 300] loss: 1.540\n",
      "[12, 360] loss: 1.536\n",
      "Epoch: 12 -> Loss: 1.66640436649\n",
      "Epoch: 12 -> Test Accuracy: 40.34\n",
      "[13, 60] loss: 1.529\n",
      "[13, 120] loss: 1.536\n",
      "[13, 180] loss: 1.545\n",
      "[13, 240] loss: 1.514\n",
      "[13, 300] loss: 1.544\n",
      "[13, 360] loss: 1.535\n",
      "Epoch: 13 -> Loss: 1.37521529198\n",
      "Epoch: 13 -> Test Accuracy: 40.61\n",
      "[14, 60] loss: 1.543\n",
      "[14, 120] loss: 1.522\n",
      "[14, 180] loss: 1.542\n",
      "[14, 240] loss: 1.537\n",
      "[14, 300] loss: 1.532\n",
      "[14, 360] loss: 1.518\n",
      "Epoch: 14 -> Loss: 1.72813093662\n",
      "Epoch: 14 -> Test Accuracy: 40.45\n",
      "[15, 60] loss: 1.530\n",
      "[15, 120] loss: 1.529\n",
      "[15, 180] loss: 1.510\n",
      "[15, 240] loss: 1.530\n",
      "[15, 300] loss: 1.517\n",
      "[15, 360] loss: 1.534\n",
      "Epoch: 15 -> Loss: 1.61027216911\n",
      "Epoch: 15 -> Test Accuracy: 39.71\n",
      "[16, 60] loss: 1.523\n",
      "[16, 120] loss: 1.509\n",
      "[16, 180] loss: 1.532\n",
      "[16, 240] loss: 1.528\n",
      "[16, 300] loss: 1.512\n",
      "[16, 360] loss: 1.531\n",
      "Epoch: 16 -> Loss: 1.5634367466\n",
      "Epoch: 16 -> Test Accuracy: 38.22\n",
      "[17, 60] loss: 1.508\n",
      "[17, 120] loss: 1.527\n",
      "[17, 180] loss: 1.526\n",
      "[17, 240] loss: 1.523\n",
      "[17, 300] loss: 1.519\n",
      "[17, 360] loss: 1.522\n",
      "Epoch: 17 -> Loss: 1.5672492981\n",
      "Epoch: 17 -> Test Accuracy: 39.15\n",
      "[18, 60] loss: 1.514\n",
      "[18, 120] loss: 1.529\n",
      "[18, 180] loss: 1.507\n",
      "[18, 240] loss: 1.509\n",
      "[18, 300] loss: 1.518\n",
      "[18, 360] loss: 1.524\n",
      "Epoch: 18 -> Loss: 1.54853355885\n",
      "Epoch: 18 -> Test Accuracy: 40.01\n",
      "[19, 60] loss: 1.537\n",
      "[19, 120] loss: 1.500\n",
      "[19, 180] loss: 1.541\n",
      "[19, 240] loss: 1.506\n",
      "[19, 300] loss: 1.518\n",
      "[19, 360] loss: 1.510\n",
      "Epoch: 19 -> Loss: 1.50794243813\n",
      "Epoch: 19 -> Test Accuracy: 40.97\n",
      "[20, 60] loss: 1.531\n",
      "[20, 120] loss: 1.518\n",
      "[20, 180] loss: 1.516\n",
      "[20, 240] loss: 1.504\n",
      "[20, 300] loss: 1.513\n",
      "[20, 360] loss: 1.517\n",
      "Epoch: 20 -> Loss: 1.70556509495\n",
      "Epoch: 20 -> Test Accuracy: 40.82\n",
      "[21, 60] loss: 1.492\n",
      "[21, 120] loss: 1.514\n",
      "[21, 180] loss: 1.498\n",
      "[21, 240] loss: 1.520\n",
      "[21, 300] loss: 1.508\n",
      "[21, 360] loss: 1.525\n",
      "Epoch: 21 -> Loss: 1.56300830841\n",
      "Epoch: 21 -> Test Accuracy: 40.26\n",
      "[22, 60] loss: 1.491\n",
      "[22, 120] loss: 1.520\n",
      "[22, 180] loss: 1.503\n",
      "[22, 240] loss: 1.510\n",
      "[22, 300] loss: 1.504\n",
      "[22, 360] loss: 1.525\n",
      "Epoch: 22 -> Loss: 1.55678665638\n",
      "Epoch: 22 -> Test Accuracy: 41.01\n",
      "[23, 60] loss: 1.495\n",
      "[23, 120] loss: 1.520\n",
      "[23, 180] loss: 1.516\n",
      "[23, 240] loss: 1.517\n",
      "[23, 300] loss: 1.487\n",
      "[23, 360] loss: 1.492\n",
      "Epoch: 23 -> Loss: 1.42354571819\n",
      "Epoch: 23 -> Test Accuracy: 40.3\n",
      "[24, 60] loss: 1.499\n",
      "[24, 120] loss: 1.498\n",
      "[24, 180] loss: 1.504\n",
      "[24, 240] loss: 1.527\n",
      "[24, 300] loss: 1.515\n",
      "[24, 360] loss: 1.516\n",
      "Epoch: 24 -> Loss: 1.47712361813\n",
      "Epoch: 24 -> Test Accuracy: 39.98\n",
      "[25, 60] loss: 1.489\n",
      "[25, 120] loss: 1.516\n",
      "[25, 180] loss: 1.493\n",
      "[25, 240] loss: 1.509\n",
      "[25, 300] loss: 1.528\n",
      "[25, 360] loss: 1.506\n",
      "Epoch: 25 -> Loss: 1.45872306824\n",
      "Epoch: 25 -> Test Accuracy: 40.12\n",
      "[26, 60] loss: 1.505\n",
      "[26, 120] loss: 1.503\n",
      "[26, 180] loss: 1.505\n",
      "[26, 240] loss: 1.492\n",
      "[26, 300] loss: 1.511\n",
      "[26, 360] loss: 1.499\n",
      "Epoch: 26 -> Loss: 1.6533216238\n",
      "Epoch: 26 -> Test Accuracy: 40.57\n",
      "[27, 60] loss: 1.478\n",
      "[27, 120] loss: 1.510\n",
      "[27, 180] loss: 1.522\n",
      "[27, 240] loss: 1.498\n",
      "[27, 300] loss: 1.501\n",
      "[27, 360] loss: 1.502\n",
      "Epoch: 27 -> Loss: 1.47486019135\n",
      "Epoch: 27 -> Test Accuracy: 39.36\n",
      "[28, 60] loss: 1.496\n",
      "[28, 120] loss: 1.496\n",
      "[28, 180] loss: 1.498\n",
      "[28, 240] loss: 1.515\n",
      "[28, 300] loss: 1.483\n",
      "[28, 360] loss: 1.514\n",
      "Epoch: 28 -> Loss: 1.60209465027\n",
      "Epoch: 28 -> Test Accuracy: 38.95\n",
      "[29, 60] loss: 1.490\n",
      "[29, 120] loss: 1.506\n",
      "[29, 180] loss: 1.508\n",
      "[29, 240] loss: 1.502\n",
      "[29, 300] loss: 1.520\n",
      "[29, 360] loss: 1.510\n",
      "Epoch: 29 -> Loss: 1.69791162014\n",
      "Epoch: 29 -> Test Accuracy: 40.8\n",
      "[30, 60] loss: 1.491\n",
      "[30, 120] loss: 1.517\n",
      "[30, 180] loss: 1.509\n",
      "[30, 240] loss: 1.502\n",
      "[30, 300] loss: 1.493\n",
      "[30, 360] loss: 1.477\n",
      "Epoch: 30 -> Loss: 1.55574226379\n",
      "Epoch: 30 -> Test Accuracy: 40.09\n",
      "[31, 60] loss: 1.507\n",
      "[31, 120] loss: 1.498\n",
      "[31, 180] loss: 1.496\n",
      "[31, 240] loss: 1.496\n",
      "[31, 300] loss: 1.492\n",
      "[31, 360] loss: 1.507\n",
      "Epoch: 31 -> Loss: 1.2946574688\n",
      "Epoch: 31 -> Test Accuracy: 40.67\n",
      "[32, 60] loss: 1.488\n",
      "[32, 120] loss: 1.494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 180] loss: 1.521\n",
      "[32, 240] loss: 1.473\n",
      "[32, 300] loss: 1.516\n",
      "[32, 360] loss: 1.488\n",
      "Epoch: 32 -> Loss: 1.553809762\n",
      "Epoch: 32 -> Test Accuracy: 40.61\n",
      "[33, 60] loss: 1.472\n",
      "[33, 120] loss: 1.511\n",
      "[33, 180] loss: 1.495\n",
      "[33, 240] loss: 1.501\n",
      "[33, 300] loss: 1.509\n",
      "[33, 360] loss: 1.480\n",
      "Epoch: 33 -> Loss: 1.49745738506\n",
      "Epoch: 33 -> Test Accuracy: 41.26\n",
      "[34, 60] loss: 1.484\n",
      "[34, 120] loss: 1.496\n",
      "[34, 180] loss: 1.499\n",
      "[34, 240] loss: 1.488\n",
      "[34, 300] loss: 1.487\n",
      "[34, 360] loss: 1.514\n",
      "Epoch: 34 -> Loss: 1.6510477066\n",
      "Epoch: 34 -> Test Accuracy: 40.5\n",
      "[35, 60] loss: 1.478\n",
      "[35, 120] loss: 1.504\n",
      "[35, 180] loss: 1.488\n",
      "[35, 240] loss: 1.498\n",
      "[35, 300] loss: 1.503\n",
      "[35, 360] loss: 1.496\n",
      "Epoch: 35 -> Loss: 1.45281708241\n",
      "Epoch: 35 -> Test Accuracy: 41.19\n",
      "[36, 60] loss: 1.448\n",
      "[36, 120] loss: 1.396\n",
      "[36, 180] loss: 1.382\n",
      "[36, 240] loss: 1.385\n",
      "[36, 300] loss: 1.392\n",
      "[36, 360] loss: 1.380\n",
      "Epoch: 36 -> Loss: 1.28960323334\n",
      "Epoch: 36 -> Test Accuracy: 45.18\n",
      "[37, 60] loss: 1.371\n",
      "[37, 120] loss: 1.356\n",
      "[37, 180] loss: 1.346\n",
      "[37, 240] loss: 1.359\n",
      "[37, 300] loss: 1.362\n",
      "[37, 360] loss: 1.364\n",
      "Epoch: 37 -> Loss: 1.45676577091\n",
      "Epoch: 37 -> Test Accuracy: 44.81\n",
      "[38, 60] loss: 1.354\n",
      "[38, 120] loss: 1.349\n",
      "[38, 180] loss: 1.383\n",
      "[38, 240] loss: 1.364\n",
      "[38, 300] loss: 1.357\n",
      "[38, 360] loss: 1.347\n",
      "Epoch: 38 -> Loss: 1.5001295805\n",
      "Epoch: 38 -> Test Accuracy: 45.28\n",
      "[39, 60] loss: 1.363\n",
      "[39, 120] loss: 1.342\n",
      "[39, 180] loss: 1.359\n",
      "[39, 240] loss: 1.355\n",
      "[39, 300] loss: 1.365\n",
      "[39, 360] loss: 1.354\n",
      "Epoch: 39 -> Loss: 1.31775963306\n",
      "Epoch: 39 -> Test Accuracy: 45.98\n",
      "[40, 60] loss: 1.339\n",
      "[40, 120] loss: 1.358\n",
      "[40, 180] loss: 1.353\n",
      "[40, 240] loss: 1.358\n",
      "[40, 300] loss: 1.363\n",
      "[40, 360] loss: 1.346\n",
      "Epoch: 40 -> Loss: 1.35470378399\n",
      "Epoch: 40 -> Test Accuracy: 45.3\n",
      "[41, 60] loss: 1.372\n",
      "[41, 120] loss: 1.358\n",
      "[41, 180] loss: 1.340\n",
      "[41, 240] loss: 1.357\n",
      "[41, 300] loss: 1.351\n",
      "[41, 360] loss: 1.361\n",
      "Epoch: 41 -> Loss: 1.32758748531\n",
      "Epoch: 41 -> Test Accuracy: 45.23\n",
      "[42, 60] loss: 1.373\n",
      "[42, 120] loss: 1.352\n",
      "[42, 180] loss: 1.332\n",
      "[42, 240] loss: 1.364\n",
      "[42, 300] loss: 1.355\n",
      "[42, 360] loss: 1.365\n",
      "Epoch: 42 -> Loss: 1.3448292017\n",
      "Epoch: 42 -> Test Accuracy: 45.85\n",
      "[43, 60] loss: 1.347\n",
      "[43, 120] loss: 1.356\n",
      "[43, 180] loss: 1.348\n",
      "[43, 240] loss: 1.363\n",
      "[43, 300] loss: 1.359\n",
      "[43, 360] loss: 1.359\n",
      "Epoch: 43 -> Loss: 1.22689974308\n",
      "Epoch: 43 -> Test Accuracy: 45.84\n",
      "[44, 60] loss: 1.349\n",
      "[44, 120] loss: 1.364\n",
      "[44, 180] loss: 1.355\n",
      "[44, 240] loss: 1.333\n",
      "[44, 300] loss: 1.341\n",
      "[44, 360] loss: 1.355\n",
      "Epoch: 44 -> Loss: 1.34917318821\n",
      "Epoch: 44 -> Test Accuracy: 45.15\n",
      "[45, 60] loss: 1.365\n",
      "[45, 120] loss: 1.341\n",
      "[45, 180] loss: 1.371\n",
      "[45, 240] loss: 1.347\n",
      "[45, 300] loss: 1.342\n",
      "[45, 360] loss: 1.345\n",
      "Epoch: 45 -> Loss: 1.45276069641\n",
      "Epoch: 45 -> Test Accuracy: 45.87\n",
      "[46, 60] loss: 1.332\n",
      "[46, 120] loss: 1.342\n",
      "[46, 180] loss: 1.368\n",
      "[46, 240] loss: 1.361\n",
      "[46, 300] loss: 1.342\n",
      "[46, 360] loss: 1.357\n",
      "Epoch: 46 -> Loss: 1.34223783016\n",
      "Epoch: 46 -> Test Accuracy: 45.22\n",
      "[47, 60] loss: 1.343\n",
      "[47, 120] loss: 1.355\n",
      "[47, 180] loss: 1.371\n",
      "[47, 240] loss: 1.358\n",
      "[47, 300] loss: 1.346\n",
      "[47, 360] loss: 1.358\n",
      "Epoch: 47 -> Loss: 1.30796718597\n",
      "Epoch: 47 -> Test Accuracy: 45.83\n",
      "[48, 60] loss: 1.358\n",
      "[48, 120] loss: 1.343\n",
      "[48, 180] loss: 1.326\n",
      "[48, 240] loss: 1.341\n",
      "[48, 300] loss: 1.344\n",
      "[48, 360] loss: 1.367\n",
      "Epoch: 48 -> Loss: 1.33875989914\n",
      "Epoch: 48 -> Test Accuracy: 45.38\n",
      "[49, 60] loss: 1.360\n",
      "[49, 120] loss: 1.337\n",
      "[49, 180] loss: 1.345\n",
      "[49, 240] loss: 1.349\n",
      "[49, 300] loss: 1.352\n",
      "[49, 360] loss: 1.344\n",
      "Epoch: 49 -> Loss: 1.59174060822\n",
      "Epoch: 49 -> Test Accuracy: 45.6\n",
      "[50, 60] loss: 1.321\n",
      "[50, 120] loss: 1.339\n",
      "[50, 180] loss: 1.364\n",
      "[50, 240] loss: 1.330\n",
      "[50, 300] loss: 1.350\n",
      "[50, 360] loss: 1.358\n",
      "Epoch: 50 -> Loss: 1.32994580269\n",
      "Epoch: 50 -> Test Accuracy: 45.02\n",
      "[51, 60] loss: 1.345\n",
      "[51, 120] loss: 1.343\n",
      "[51, 180] loss: 1.353\n",
      "[51, 240] loss: 1.333\n",
      "[51, 300] loss: 1.345\n",
      "[51, 360] loss: 1.371\n",
      "Epoch: 51 -> Loss: 1.39850378036\n",
      "Epoch: 51 -> Test Accuracy: 45.37\n",
      "[52, 60] loss: 1.341\n",
      "[52, 120] loss: 1.346\n",
      "[52, 180] loss: 1.343\n",
      "[52, 240] loss: 1.329\n",
      "[52, 300] loss: 1.357\n",
      "[52, 360] loss: 1.363\n",
      "Epoch: 52 -> Loss: 1.21067214012\n",
      "Epoch: 52 -> Test Accuracy: 45.17\n",
      "[53, 60] loss: 1.352\n",
      "[53, 120] loss: 1.351\n",
      "[53, 180] loss: 1.351\n",
      "[53, 240] loss: 1.345\n",
      "[53, 300] loss: 1.337\n",
      "[53, 360] loss: 1.333\n",
      "Epoch: 53 -> Loss: 1.32541787624\n",
      "Epoch: 53 -> Test Accuracy: 45.5\n",
      "[54, 60] loss: 1.350\n",
      "[54, 120] loss: 1.355\n",
      "[54, 180] loss: 1.343\n",
      "[54, 240] loss: 1.345\n",
      "[54, 300] loss: 1.358\n",
      "[54, 360] loss: 1.337\n",
      "Epoch: 54 -> Loss: 1.30200409889\n",
      "Epoch: 54 -> Test Accuracy: 44.7\n",
      "[55, 60] loss: 1.335\n",
      "[55, 120] loss: 1.327\n",
      "[55, 180] loss: 1.355\n",
      "[55, 240] loss: 1.340\n",
      "[55, 300] loss: 1.334\n",
      "[55, 360] loss: 1.334\n",
      "Epoch: 55 -> Loss: 1.31791043282\n",
      "Epoch: 55 -> Test Accuracy: 44.62\n",
      "[56, 60] loss: 1.346\n",
      "[56, 120] loss: 1.361\n",
      "[56, 180] loss: 1.351\n",
      "[56, 240] loss: 1.348\n",
      "[56, 300] loss: 1.348\n",
      "[56, 360] loss: 1.357\n",
      "Epoch: 56 -> Loss: 1.35783421993\n",
      "Epoch: 56 -> Test Accuracy: 45.26\n",
      "[57, 60] loss: 1.331\n",
      "[57, 120] loss: 1.342\n",
      "[57, 180] loss: 1.333\n",
      "[57, 240] loss: 1.361\n",
      "[57, 300] loss: 1.352\n",
      "[57, 360] loss: 1.352\n",
      "Epoch: 57 -> Loss: 1.36792206764\n",
      "Epoch: 57 -> Test Accuracy: 44.68\n",
      "[58, 60] loss: 1.330\n",
      "[58, 120] loss: 1.342\n",
      "[58, 180] loss: 1.341\n",
      "[58, 240] loss: 1.363\n",
      "[58, 300] loss: 1.340\n",
      "[58, 360] loss: 1.334\n",
      "Epoch: 58 -> Loss: 1.15069460869\n",
      "Epoch: 58 -> Test Accuracy: 45.31\n",
      "[59, 60] loss: 1.337\n",
      "[59, 120] loss: 1.333\n",
      "[59, 180] loss: 1.367\n",
      "[59, 240] loss: 1.342\n",
      "[59, 300] loss: 1.328\n",
      "[59, 360] loss: 1.370\n",
      "Epoch: 59 -> Loss: 1.29760813713\n",
      "Epoch: 59 -> Test Accuracy: 46.39\n",
      "[60, 60] loss: 1.335\n",
      "[60, 120] loss: 1.350\n",
      "[60, 180] loss: 1.351\n",
      "[60, 240] loss: 1.346\n",
      "[60, 300] loss: 1.350\n",
      "[60, 360] loss: 1.329\n",
      "Epoch: 60 -> Loss: 1.25584697723\n",
      "Epoch: 60 -> Test Accuracy: 44.65\n",
      "[61, 60] loss: 1.324\n",
      "[61, 120] loss: 1.330\n",
      "[61, 180] loss: 1.349\n",
      "[61, 240] loss: 1.358\n",
      "[61, 300] loss: 1.337\n",
      "[61, 360] loss: 1.366\n",
      "Epoch: 61 -> Loss: 1.40248990059\n",
      "Epoch: 61 -> Test Accuracy: 45.78\n",
      "[62, 60] loss: 1.346\n",
      "[62, 120] loss: 1.345\n",
      "[62, 180] loss: 1.347\n",
      "[62, 240] loss: 1.342\n",
      "[62, 300] loss: 1.326\n",
      "[62, 360] loss: 1.336\n",
      "Epoch: 62 -> Loss: 1.31433546543\n",
      "Epoch: 62 -> Test Accuracy: 45.51\n",
      "[63, 60] loss: 1.342\n",
      "[63, 120] loss: 1.325\n",
      "[63, 180] loss: 1.343\n",
      "[63, 240] loss: 1.341\n",
      "[63, 300] loss: 1.311\n",
      "[63, 360] loss: 1.340\n",
      "Epoch: 63 -> Loss: 1.43909955025\n",
      "Epoch: 63 -> Test Accuracy: 45.62\n",
      "[64, 60] loss: 1.333\n",
      "[64, 120] loss: 1.334\n",
      "[64, 180] loss: 1.343\n",
      "[64, 240] loss: 1.342\n",
      "[64, 300] loss: 1.335\n",
      "[64, 360] loss: 1.337\n",
      "Epoch: 64 -> Loss: 1.34157276154\n",
      "Epoch: 64 -> Test Accuracy: 45.53\n",
      "[65, 60] loss: 1.321\n",
      "[65, 120] loss: 1.358\n",
      "[65, 180] loss: 1.346\n",
      "[65, 240] loss: 1.354\n",
      "[65, 300] loss: 1.339\n",
      "[65, 360] loss: 1.339\n",
      "Epoch: 65 -> Loss: 1.29442334175\n",
      "Epoch: 65 -> Test Accuracy: 45.59\n",
      "[66, 60] loss: 1.336\n",
      "[66, 120] loss: 1.317\n",
      "[66, 180] loss: 1.351\n",
      "[66, 240] loss: 1.340\n",
      "[66, 300] loss: 1.343\n",
      "[66, 360] loss: 1.350\n",
      "Epoch: 66 -> Loss: 1.16732418537\n",
      "Epoch: 66 -> Test Accuracy: 44.74\n",
      "[67, 60] loss: 1.309\n",
      "[67, 120] loss: 1.349\n",
      "[67, 180] loss: 1.365\n",
      "[67, 240] loss: 1.331\n",
      "[67, 300] loss: 1.336\n",
      "[67, 360] loss: 1.343\n",
      "Epoch: 67 -> Loss: 1.38639450073\n",
      "Epoch: 67 -> Test Accuracy: 45.6\n",
      "[68, 60] loss: 1.308\n",
      "[68, 120] loss: 1.349\n",
      "[68, 180] loss: 1.337\n",
      "[68, 240] loss: 1.337\n",
      "[68, 300] loss: 1.335\n",
      "[68, 360] loss: 1.346\n",
      "Epoch: 68 -> Loss: 1.0570499897\n",
      "Epoch: 68 -> Test Accuracy: 46.34\n",
      "[69, 60] loss: 1.315\n",
      "[69, 120] loss: 1.336\n",
      "[69, 180] loss: 1.338\n",
      "[69, 240] loss: 1.340\n",
      "[69, 300] loss: 1.341\n",
      "[69, 360] loss: 1.339\n",
      "Epoch: 69 -> Loss: 1.30697309971\n",
      "Epoch: 69 -> Test Accuracy: 45.35\n",
      "[70, 60] loss: 1.326\n",
      "[70, 120] loss: 1.332\n",
      "[70, 180] loss: 1.348\n",
      "[70, 240] loss: 1.317\n",
      "[70, 300] loss: 1.349\n",
      "[70, 360] loss: 1.337\n",
      "Epoch: 70 -> Loss: 1.32937085629\n",
      "Epoch: 70 -> Test Accuracy: 45.54\n",
      "[71, 60] loss: 1.312\n",
      "[71, 120] loss: 1.275\n",
      "[71, 180] loss: 1.261\n",
      "[71, 240] loss: 1.252\n",
      "[71, 300] loss: 1.274\n",
      "[71, 360] loss: 1.248\n",
      "Epoch: 71 -> Loss: 1.33318948746\n",
      "Epoch: 71 -> Test Accuracy: 48.16\n",
      "[72, 60] loss: 1.255\n",
      "[72, 120] loss: 1.258\n",
      "[72, 180] loss: 1.252\n",
      "[72, 240] loss: 1.249\n",
      "[72, 300] loss: 1.247\n",
      "[72, 360] loss: 1.232\n",
      "Epoch: 72 -> Loss: 1.24111390114\n",
      "Epoch: 72 -> Test Accuracy: 48.57\n",
      "[73, 60] loss: 1.259\n",
      "[73, 120] loss: 1.247\n",
      "[73, 180] loss: 1.238\n",
      "[73, 240] loss: 1.241\n",
      "[73, 300] loss: 1.235\n",
      "[73, 360] loss: 1.247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 -> Loss: 1.23151230812\n",
      "Epoch: 73 -> Test Accuracy: 48.6\n",
      "[74, 60] loss: 1.241\n",
      "[74, 120] loss: 1.216\n",
      "[74, 180] loss: 1.226\n",
      "[74, 240] loss: 1.246\n",
      "[74, 300] loss: 1.242\n",
      "[74, 360] loss: 1.242\n",
      "Epoch: 74 -> Loss: 1.14615464211\n",
      "Epoch: 74 -> Test Accuracy: 49.37\n",
      "[75, 60] loss: 1.224\n",
      "[75, 120] loss: 1.231\n",
      "[75, 180] loss: 1.231\n",
      "[75, 240] loss: 1.216\n",
      "[75, 300] loss: 1.242\n",
      "[75, 360] loss: 1.251\n",
      "Epoch: 75 -> Loss: 1.25943422318\n",
      "Epoch: 75 -> Test Accuracy: 49.04\n",
      "[76, 60] loss: 1.234\n",
      "[76, 120] loss: 1.241\n",
      "[76, 180] loss: 1.230\n",
      "[76, 240] loss: 1.214\n",
      "[76, 300] loss: 1.224\n",
      "[76, 360] loss: 1.226\n",
      "Epoch: 76 -> Loss: 1.12891149521\n",
      "Epoch: 76 -> Test Accuracy: 49.07\n",
      "[77, 60] loss: 1.246\n",
      "[77, 120] loss: 1.237\n",
      "[77, 180] loss: 1.204\n",
      "[77, 240] loss: 1.227\n",
      "[77, 300] loss: 1.248\n",
      "[77, 360] loss: 1.223\n",
      "Epoch: 77 -> Loss: 1.43607461452\n",
      "Epoch: 77 -> Test Accuracy: 48.54\n",
      "[78, 60] loss: 1.234\n",
      "[78, 120] loss: 1.213\n",
      "[78, 180] loss: 1.234\n",
      "[78, 240] loss: 1.227\n",
      "[78, 300] loss: 1.229\n",
      "[78, 360] loss: 1.221\n",
      "Epoch: 78 -> Loss: 1.23097133636\n",
      "Epoch: 78 -> Test Accuracy: 48.96\n",
      "[79, 60] loss: 1.214\n",
      "[79, 120] loss: 1.215\n",
      "[79, 180] loss: 1.244\n",
      "[79, 240] loss: 1.212\n",
      "[79, 300] loss: 1.223\n",
      "[79, 360] loss: 1.234\n",
      "Epoch: 79 -> Loss: 1.27827203274\n",
      "Epoch: 79 -> Test Accuracy: 49.26\n",
      "[80, 60] loss: 1.242\n",
      "[80, 120] loss: 1.251\n",
      "[80, 180] loss: 1.208\n",
      "[80, 240] loss: 1.225\n",
      "[80, 300] loss: 1.241\n",
      "[80, 360] loss: 1.207\n",
      "Epoch: 80 -> Loss: 1.22577726841\n",
      "Epoch: 80 -> Test Accuracy: 49.82\n",
      "[81, 60] loss: 1.234\n",
      "[81, 120] loss: 1.220\n",
      "[81, 180] loss: 1.204\n",
      "[81, 240] loss: 1.212\n",
      "[81, 300] loss: 1.230\n",
      "[81, 360] loss: 1.203\n",
      "Epoch: 81 -> Loss: 1.2160680294\n",
      "Epoch: 81 -> Test Accuracy: 49.31\n",
      "[82, 60] loss: 1.209\n",
      "[82, 120] loss: 1.218\n",
      "[82, 180] loss: 1.228\n",
      "[82, 240] loss: 1.227\n",
      "[82, 300] loss: 1.219\n",
      "[82, 360] loss: 1.243\n",
      "Epoch: 82 -> Loss: 1.40606153011\n",
      "Epoch: 82 -> Test Accuracy: 48.72\n",
      "[83, 60] loss: 1.231\n",
      "[83, 120] loss: 1.217\n",
      "[83, 180] loss: 1.220\n",
      "[83, 240] loss: 1.240\n",
      "[83, 300] loss: 1.241\n",
      "[83, 360] loss: 1.209\n",
      "Epoch: 83 -> Loss: 1.31402921677\n",
      "Epoch: 83 -> Test Accuracy: 49.4\n",
      "[84, 60] loss: 1.233\n",
      "[84, 120] loss: 1.235\n",
      "[84, 180] loss: 1.225\n",
      "[84, 240] loss: 1.228\n",
      "[84, 300] loss: 1.220\n",
      "[84, 360] loss: 1.216\n",
      "Epoch: 84 -> Loss: 1.25196063519\n",
      "Epoch: 84 -> Test Accuracy: 49.46\n",
      "[85, 60] loss: 1.218\n",
      "[85, 120] loss: 1.228\n",
      "[85, 180] loss: 1.227\n",
      "[85, 240] loss: 1.225\n",
      "[85, 300] loss: 1.214\n",
      "[85, 360] loss: 1.217\n",
      "Epoch: 85 -> Loss: 1.21463739872\n",
      "Epoch: 85 -> Test Accuracy: 49.58\n",
      "[86, 60] loss: 1.206\n",
      "[86, 120] loss: 1.181\n",
      "[86, 180] loss: 1.189\n",
      "[86, 240] loss: 1.195\n",
      "[86, 300] loss: 1.189\n",
      "[86, 360] loss: 1.194\n",
      "Epoch: 86 -> Loss: 1.29379343987\n",
      "Epoch: 86 -> Test Accuracy: 50.53\n",
      "[87, 60] loss: 1.196\n",
      "[87, 120] loss: 1.195\n",
      "[87, 180] loss: 1.204\n",
      "[87, 240] loss: 1.167\n",
      "[87, 300] loss: 1.183\n",
      "[87, 360] loss: 1.171\n",
      "Epoch: 87 -> Loss: 1.30982613564\n",
      "Epoch: 87 -> Test Accuracy: 50.36\n",
      "[88, 60] loss: 1.192\n",
      "[88, 120] loss: 1.194\n",
      "[88, 180] loss: 1.177\n",
      "[88, 240] loss: 1.180\n",
      "[88, 300] loss: 1.167\n",
      "[88, 360] loss: 1.209\n",
      "Epoch: 88 -> Loss: 1.22941255569\n",
      "Epoch: 88 -> Test Accuracy: 50.64\n",
      "[89, 60] loss: 1.162\n",
      "[89, 120] loss: 1.182\n",
      "[89, 180] loss: 1.180\n",
      "[89, 240] loss: 1.187\n",
      "[89, 300] loss: 1.183\n",
      "[89, 360] loss: 1.177\n",
      "Epoch: 89 -> Loss: 1.38024711609\n",
      "Epoch: 89 -> Test Accuracy: 50.59\n",
      "[90, 60] loss: 1.190\n",
      "[90, 120] loss: 1.175\n",
      "[90, 180] loss: 1.193\n",
      "[90, 240] loss: 1.170\n",
      "[90, 300] loss: 1.176\n",
      "[90, 360] loss: 1.177\n",
      "Epoch: 90 -> Loss: 1.45272397995\n",
      "Epoch: 90 -> Test Accuracy: 50.22\n",
      "[91, 60] loss: 1.179\n",
      "[91, 120] loss: 1.171\n",
      "[91, 180] loss: 1.193\n",
      "[91, 240] loss: 1.172\n",
      "[91, 300] loss: 1.175\n",
      "[91, 360] loss: 1.181\n",
      "Epoch: 91 -> Loss: 1.13063764572\n",
      "Epoch: 91 -> Test Accuracy: 50.88\n",
      "[92, 60] loss: 1.181\n",
      "[92, 120] loss: 1.160\n",
      "[92, 180] loss: 1.188\n",
      "[92, 240] loss: 1.164\n",
      "[92, 300] loss: 1.171\n",
      "[92, 360] loss: 1.188\n",
      "Epoch: 92 -> Loss: 1.25010788441\n",
      "Epoch: 92 -> Test Accuracy: 50.91\n",
      "[93, 60] loss: 1.168\n",
      "[93, 120] loss: 1.171\n",
      "[93, 180] loss: 1.178\n",
      "[93, 240] loss: 1.182\n",
      "[93, 300] loss: 1.187\n",
      "[93, 360] loss: 1.162\n",
      "Epoch: 93 -> Loss: 1.40806150436\n",
      "Epoch: 93 -> Test Accuracy: 51.1\n",
      "[94, 60] loss: 1.175\n",
      "[94, 120] loss: 1.169\n",
      "[94, 180] loss: 1.187\n",
      "[94, 240] loss: 1.159\n",
      "[94, 300] loss: 1.168\n",
      "[94, 360] loss: 1.172\n",
      "Epoch: 94 -> Loss: 1.04961645603\n",
      "Epoch: 94 -> Test Accuracy: 50.53\n",
      "[95, 60] loss: 1.181\n",
      "[95, 120] loss: 1.168\n",
      "[95, 180] loss: 1.169\n",
      "[95, 240] loss: 1.164\n",
      "[95, 300] loss: 1.171\n",
      "[95, 360] loss: 1.172\n",
      "Epoch: 95 -> Loss: 1.17322087288\n",
      "Epoch: 95 -> Test Accuracy: 50.44\n",
      "[96, 60] loss: 1.174\n",
      "[96, 120] loss: 1.179\n",
      "[96, 180] loss: 1.177\n",
      "[96, 240] loss: 1.169\n",
      "[96, 300] loss: 1.164\n",
      "[96, 360] loss: 1.181\n",
      "Epoch: 96 -> Loss: 1.09100556374\n",
      "Epoch: 96 -> Test Accuracy: 50.65\n",
      "[97, 60] loss: 1.167\n",
      "[97, 120] loss: 1.172\n",
      "[97, 180] loss: 1.189\n",
      "[97, 240] loss: 1.158\n",
      "[97, 300] loss: 1.171\n",
      "[97, 360] loss: 1.155\n",
      "Epoch: 97 -> Loss: 1.2168841362\n",
      "Epoch: 97 -> Test Accuracy: 50.67\n",
      "[98, 60] loss: 1.168\n",
      "[98, 120] loss: 1.173\n",
      "[98, 180] loss: 1.173\n",
      "[98, 240] loss: 1.163\n",
      "[98, 300] loss: 1.171\n",
      "[98, 360] loss: 1.179\n",
      "Epoch: 98 -> Loss: 1.0208234787\n",
      "Epoch: 98 -> Test Accuracy: 51.08\n",
      "[99, 60] loss: 1.165\n",
      "[99, 120] loss: 1.171\n",
      "[99, 180] loss: 1.176\n",
      "[99, 240] loss: 1.189\n",
      "[99, 300] loss: 1.185\n",
      "[99, 360] loss: 1.152\n",
      "Epoch: 99 -> Loss: 1.1514788866\n",
      "Epoch: 99 -> Test Accuracy: 50.67\n",
      "[100, 60] loss: 1.152\n",
      "[100, 120] loss: 1.176\n",
      "[100, 180] loss: 1.185\n",
      "[100, 240] loss: 1.164\n",
      "[100, 300] loss: 1.169\n",
      "[100, 360] loss: 1.178\n",
      "Epoch: 100 -> Loss: 1.42129659653\n",
      "Epoch: 100 -> Test Accuracy: 50.91\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train ConvClassifiers on feature map of net_3block\n",
    "conv_block4_loss_log, _, conv_block4_test_accuracy_log, _, _ = tr.train_all_blocks(4, 10, [0.1, 0.02, 0.004, 0.0008], \n",
    "    [35, 70, 85, 100], 0.9, 5e-4, net_block4, criterion, trainloader, None, testloader, use_ConvClassifier=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save variables\n",
    "fm.save_variable([rot_block4_loss_log, rot_block4_test_accuracy_log, \n",
    "                  block4_loss_log, block4_test_accuracy_log, \n",
    "                  conv_block4_loss_log, conv_block4_test_accuracy_log], \"4_block_net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename files\n",
    "fm.add_block_to_name(4, [100, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Block RotNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "net_block5 = RN.RotNet(num_classes=4, num_conv_block=5, add_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.149\n",
      "[1, 120] loss: 1.019\n",
      "[1, 180] loss: 0.948\n",
      "[1, 240] loss: 0.885\n",
      "[1, 300] loss: 0.867\n",
      "[1, 360] loss: 0.832\n",
      "Epoch: 1 -> Loss: 0.881160914898\n",
      "Epoch: 1 -> Test Accuracy: 67.94\n",
      "[2, 60] loss: 0.787\n",
      "[2, 120] loss: 0.742\n",
      "[2, 180] loss: 0.718\n",
      "[2, 240] loss: 0.717\n",
      "[2, 300] loss: 0.681\n",
      "[2, 360] loss: 0.668\n",
      "Epoch: 2 -> Loss: 0.548422813416\n",
      "Epoch: 2 -> Test Accuracy: 74.82\n",
      "[3, 60] loss: 0.640\n",
      "[3, 120] loss: 0.622\n",
      "[3, 180] loss: 0.628\n",
      "[3, 240] loss: 0.603\n",
      "[3, 300] loss: 0.602\n",
      "[3, 360] loss: 0.575\n",
      "Epoch: 3 -> Loss: 0.407884776592\n",
      "Epoch: 3 -> Test Accuracy: 77.97\n",
      "[4, 60] loss: 0.547\n",
      "[4, 120] loss: 0.557\n",
      "[4, 180] loss: 0.546\n",
      "[4, 240] loss: 0.570\n",
      "[4, 300] loss: 0.545\n",
      "[4, 360] loss: 0.537\n",
      "Epoch: 4 -> Loss: 0.592630028725\n",
      "Epoch: 4 -> Test Accuracy: 79.935\n",
      "[5, 60] loss: 0.518\n",
      "[5, 120] loss: 0.503\n",
      "[5, 180] loss: 0.511\n",
      "[5, 240] loss: 0.495\n",
      "[5, 300] loss: 0.518\n",
      "[5, 360] loss: 0.493\n",
      "Epoch: 5 -> Loss: 0.569274783134\n",
      "Epoch: 5 -> Test Accuracy: 80.275\n",
      "[6, 60] loss: 0.470\n",
      "[6, 120] loss: 0.492\n",
      "[6, 180] loss: 0.472\n",
      "[6, 240] loss: 0.492\n",
      "[6, 300] loss: 0.479\n",
      "[6, 360] loss: 0.472\n",
      "Epoch: 6 -> Loss: 0.50712120533\n",
      "Epoch: 6 -> Test Accuracy: 81.9275\n",
      "[7, 60] loss: 0.449\n",
      "[7, 120] loss: 0.468\n",
      "[7, 180] loss: 0.469\n",
      "[7, 240] loss: 0.456\n",
      "[7, 300] loss: 0.445\n",
      "[7, 360] loss: 0.458\n",
      "Epoch: 7 -> Loss: 0.380683481693\n",
      "Epoch: 7 -> Test Accuracy: 82.285\n",
      "[8, 60] loss: 0.447\n",
      "[8, 120] loss: 0.447\n",
      "[8, 180] loss: 0.440\n",
      "[8, 240] loss: 0.439\n",
      "[8, 300] loss: 0.428\n",
      "[8, 360] loss: 0.443\n",
      "Epoch: 8 -> Loss: 0.469857543707\n",
      "Epoch: 8 -> Test Accuracy: 82.23\n",
      "[9, 60] loss: 0.422\n",
      "[9, 120] loss: 0.433\n",
      "[9, 180] loss: 0.427\n",
      "[9, 240] loss: 0.427\n",
      "[9, 300] loss: 0.431\n",
      "[9, 360] loss: 0.419\n",
      "Epoch: 9 -> Loss: 0.395461976528\n",
      "Epoch: 9 -> Test Accuracy: 83.065\n",
      "[10, 60] loss: 0.403\n",
      "[10, 120] loss: 0.416\n",
      "[10, 180] loss: 0.417\n",
      "[10, 240] loss: 0.418\n",
      "[10, 300] loss: 0.408\n",
      "[10, 360] loss: 0.406\n",
      "Epoch: 10 -> Loss: 0.371103852987\n",
      "Epoch: 10 -> Test Accuracy: 84.165\n",
      "[11, 60] loss: 0.392\n",
      "[11, 120] loss: 0.395\n",
      "[11, 180] loss: 0.421\n",
      "[11, 240] loss: 0.398\n",
      "[11, 300] loss: 0.414\n",
      "[11, 360] loss: 0.389\n",
      "Epoch: 11 -> Loss: 0.467694759369\n",
      "Epoch: 11 -> Test Accuracy: 84.2325\n",
      "[12, 60] loss: 0.384\n",
      "[12, 120] loss: 0.384\n",
      "[12, 180] loss: 0.397\n",
      "[12, 240] loss: 0.398\n",
      "[12, 300] loss: 0.400\n",
      "[12, 360] loss: 0.401\n",
      "Epoch: 12 -> Loss: 0.402349323034\n",
      "Epoch: 12 -> Test Accuracy: 84.7\n",
      "[13, 60] loss: 0.368\n",
      "[13, 120] loss: 0.390\n",
      "[13, 180] loss: 0.383\n",
      "[13, 240] loss: 0.375\n",
      "[13, 300] loss: 0.384\n",
      "[13, 360] loss: 0.395\n",
      "Epoch: 13 -> Loss: 0.461198717356\n",
      "Epoch: 13 -> Test Accuracy: 84.3525\n",
      "[14, 60] loss: 0.372\n",
      "[14, 120] loss: 0.374\n",
      "[14, 180] loss: 0.372\n",
      "[14, 240] loss: 0.374\n",
      "[14, 300] loss: 0.386\n",
      "[14, 360] loss: 0.382\n",
      "Epoch: 14 -> Loss: 0.431313097477\n",
      "Epoch: 14 -> Test Accuracy: 84.135\n",
      "[15, 60] loss: 0.363\n",
      "[15, 120] loss: 0.366\n",
      "[15, 180] loss: 0.381\n",
      "[15, 240] loss: 0.373\n",
      "[15, 300] loss: 0.367\n",
      "[15, 360] loss: 0.378\n",
      "Epoch: 15 -> Loss: 0.303707897663\n",
      "Epoch: 15 -> Test Accuracy: 84.5825\n",
      "[16, 60] loss: 0.354\n",
      "[16, 120] loss: 0.360\n",
      "[16, 180] loss: 0.369\n",
      "[16, 240] loss: 0.379\n",
      "[16, 300] loss: 0.372\n",
      "[16, 360] loss: 0.370\n",
      "Epoch: 16 -> Loss: 0.480542600155\n",
      "Epoch: 16 -> Test Accuracy: 84.4475\n",
      "[17, 60] loss: 0.359\n",
      "[17, 120] loss: 0.363\n",
      "[17, 180] loss: 0.355\n",
      "[17, 240] loss: 0.366\n",
      "[17, 300] loss: 0.366\n",
      "[17, 360] loss: 0.363\n",
      "Epoch: 17 -> Loss: 0.289995372295\n",
      "Epoch: 17 -> Test Accuracy: 84.7775\n",
      "[18, 60] loss: 0.346\n",
      "[18, 120] loss: 0.350\n",
      "[18, 180] loss: 0.342\n",
      "[18, 240] loss: 0.355\n",
      "[18, 300] loss: 0.364\n",
      "[18, 360] loss: 0.368\n",
      "Epoch: 18 -> Loss: 0.442254602909\n",
      "Epoch: 18 -> Test Accuracy: 84.89\n",
      "[19, 60] loss: 0.342\n",
      "[19, 120] loss: 0.352\n",
      "[19, 180] loss: 0.348\n",
      "[19, 240] loss: 0.361\n",
      "[19, 300] loss: 0.356\n",
      "[19, 360] loss: 0.353\n",
      "Epoch: 19 -> Loss: 0.419402420521\n",
      "Epoch: 19 -> Test Accuracy: 85.1425\n",
      "[20, 60] loss: 0.341\n",
      "[20, 120] loss: 0.346\n",
      "[20, 180] loss: 0.357\n",
      "[20, 240] loss: 0.343\n",
      "[20, 300] loss: 0.353\n",
      "[20, 360] loss: 0.360\n",
      "Epoch: 20 -> Loss: 0.34176838398\n",
      "Epoch: 20 -> Test Accuracy: 85.865\n",
      "[21, 60] loss: 0.331\n",
      "[21, 120] loss: 0.355\n",
      "[21, 180] loss: 0.350\n",
      "[21, 240] loss: 0.352\n",
      "[21, 300] loss: 0.352\n",
      "[21, 360] loss: 0.335\n",
      "Epoch: 21 -> Loss: 0.26520717144\n",
      "Epoch: 21 -> Test Accuracy: 85.23\n",
      "[22, 60] loss: 0.330\n",
      "[22, 120] loss: 0.341\n",
      "[22, 180] loss: 0.350\n",
      "[22, 240] loss: 0.345\n",
      "[22, 300] loss: 0.342\n",
      "[22, 360] loss: 0.339\n",
      "Epoch: 22 -> Loss: 0.337615072727\n",
      "Epoch: 22 -> Test Accuracy: 86.1375\n",
      "[23, 60] loss: 0.335\n",
      "[23, 120] loss: 0.322\n",
      "[23, 180] loss: 0.341\n",
      "[23, 240] loss: 0.352\n",
      "[23, 300] loss: 0.357\n",
      "[23, 360] loss: 0.335\n",
      "Epoch: 23 -> Loss: 0.445211559534\n",
      "Epoch: 23 -> Test Accuracy: 86.1125\n",
      "[24, 60] loss: 0.323\n",
      "[24, 120] loss: 0.343\n",
      "[24, 180] loss: 0.329\n",
      "[24, 240] loss: 0.342\n",
      "[24, 300] loss: 0.341\n",
      "[24, 360] loss: 0.351\n",
      "Epoch: 24 -> Loss: 0.316045701504\n",
      "Epoch: 24 -> Test Accuracy: 86.2175\n",
      "[25, 60] loss: 0.327\n",
      "[25, 120] loss: 0.330\n",
      "[25, 180] loss: 0.342\n",
      "[25, 240] loss: 0.321\n",
      "[25, 300] loss: 0.358\n",
      "[25, 360] loss: 0.334\n",
      "Epoch: 25 -> Loss: 0.389112174511\n",
      "Epoch: 25 -> Test Accuracy: 86.21\n",
      "[26, 60] loss: 0.320\n",
      "[26, 120] loss: 0.342\n",
      "[26, 180] loss: 0.325\n",
      "[26, 240] loss: 0.317\n",
      "[26, 300] loss: 0.338\n",
      "[26, 360] loss: 0.352\n",
      "Epoch: 26 -> Loss: 0.355546295643\n",
      "Epoch: 26 -> Test Accuracy: 85.6375\n",
      "[27, 60] loss: 0.315\n",
      "[27, 120] loss: 0.326\n",
      "[27, 180] loss: 0.340\n",
      "[27, 240] loss: 0.322\n",
      "[27, 300] loss: 0.321\n",
      "[27, 360] loss: 0.346\n",
      "Epoch: 27 -> Loss: 0.486218065023\n",
      "Epoch: 27 -> Test Accuracy: 84.82\n",
      "[28, 60] loss: 0.323\n",
      "[28, 120] loss: 0.336\n",
      "[28, 180] loss: 0.326\n",
      "[28, 240] loss: 0.333\n",
      "[28, 300] loss: 0.331\n",
      "[28, 360] loss: 0.338\n",
      "Epoch: 28 -> Loss: 0.260115712881\n",
      "Epoch: 28 -> Test Accuracy: 85.62\n",
      "[29, 60] loss: 0.317\n",
      "[29, 120] loss: 0.323\n",
      "[29, 180] loss: 0.320\n",
      "[29, 240] loss: 0.339\n",
      "[29, 300] loss: 0.333\n",
      "[29, 360] loss: 0.331\n",
      "Epoch: 29 -> Loss: 0.338069558144\n",
      "Epoch: 29 -> Test Accuracy: 85.7075\n",
      "[30, 60] loss: 0.313\n",
      "[30, 120] loss: 0.330\n",
      "[30, 180] loss: 0.312\n",
      "[30, 240] loss: 0.338\n",
      "[30, 300] loss: 0.331\n",
      "[30, 360] loss: 0.333\n",
      "Epoch: 30 -> Loss: 0.30751401186\n",
      "Epoch: 30 -> Test Accuracy: 85.71\n",
      "[31, 60] loss: 0.305\n",
      "[31, 120] loss: 0.334\n",
      "[31, 180] loss: 0.328\n",
      "[31, 240] loss: 0.321\n",
      "[31, 300] loss: 0.311\n",
      "[31, 360] loss: 0.328\n",
      "Epoch: 31 -> Loss: 0.293336123228\n",
      "Epoch: 31 -> Test Accuracy: 85.66\n",
      "[32, 60] loss: 0.309\n",
      "[32, 120] loss: 0.323\n",
      "[32, 180] loss: 0.324\n",
      "[32, 240] loss: 0.329\n",
      "[32, 300] loss: 0.338\n",
      "[32, 360] loss: 0.318\n",
      "Epoch: 32 -> Loss: 0.342967808247\n",
      "Epoch: 32 -> Test Accuracy: 86.07\n",
      "[33, 60] loss: 0.309\n",
      "[33, 120] loss: 0.322\n",
      "[33, 180] loss: 0.327\n",
      "[33, 240] loss: 0.325\n",
      "[33, 300] loss: 0.317\n",
      "[33, 360] loss: 0.334\n",
      "Epoch: 33 -> Loss: 0.357565075159\n",
      "Epoch: 33 -> Test Accuracy: 84.4025\n",
      "[34, 60] loss: 0.316\n",
      "[34, 120] loss: 0.316\n",
      "[34, 180] loss: 0.328\n",
      "[34, 240] loss: 0.322\n",
      "[34, 300] loss: 0.333\n",
      "[34, 360] loss: 0.322\n",
      "Epoch: 34 -> Loss: 0.353720933199\n",
      "Epoch: 34 -> Test Accuracy: 86.13\n",
      "[35, 60] loss: 0.323\n",
      "[35, 120] loss: 0.333\n",
      "[35, 180] loss: 0.306\n",
      "[35, 240] loss: 0.321\n",
      "[35, 300] loss: 0.312\n",
      "[35, 360] loss: 0.317\n",
      "Epoch: 35 -> Loss: 0.350825726986\n",
      "Epoch: 35 -> Test Accuracy: 86.73\n",
      "[36, 60] loss: 0.307\n",
      "[36, 120] loss: 0.312\n",
      "[36, 180] loss: 0.323\n",
      "[36, 240] loss: 0.325\n",
      "[36, 300] loss: 0.314\n",
      "[36, 360] loss: 0.320\n",
      "Epoch: 36 -> Loss: 0.357005387545\n",
      "Epoch: 36 -> Test Accuracy: 85.745\n",
      "[37, 60] loss: 0.307\n",
      "[37, 120] loss: 0.313\n",
      "[37, 180] loss: 0.309\n",
      "[37, 240] loss: 0.320\n",
      "[37, 300] loss: 0.330\n",
      "[37, 360] loss: 0.322\n",
      "Epoch: 37 -> Loss: 0.334428459406\n",
      "Epoch: 37 -> Test Accuracy: 86.405\n",
      "[38, 60] loss: 0.298\n",
      "[38, 120] loss: 0.318\n",
      "[38, 180] loss: 0.317\n",
      "[38, 240] loss: 0.320\n",
      "[38, 300] loss: 0.321\n",
      "[38, 360] loss: 0.321\n",
      "Epoch: 38 -> Loss: 0.326941072941\n",
      "Epoch: 38 -> Test Accuracy: 86.615\n",
      "[39, 60] loss: 0.309\n",
      "[39, 120] loss: 0.319\n",
      "[39, 180] loss: 0.313\n",
      "[39, 240] loss: 0.319\n",
      "[39, 300] loss: 0.327\n",
      "[39, 360] loss: 0.321\n",
      "Epoch: 39 -> Loss: 0.237495973706\n",
      "Epoch: 39 -> Test Accuracy: 86.7025\n",
      "[40, 60] loss: 0.304\n",
      "[40, 120] loss: 0.303\n",
      "[40, 180] loss: 0.321\n",
      "[40, 240] loss: 0.324\n",
      "[40, 300] loss: 0.318\n",
      "[40, 360] loss: 0.325\n",
      "Epoch: 40 -> Loss: 0.353388190269\n",
      "Epoch: 40 -> Test Accuracy: 85.35\n",
      "[41, 60] loss: 0.303\n",
      "[41, 120] loss: 0.311\n",
      "[41, 180] loss: 0.311\n",
      "[41, 240] loss: 0.316\n",
      "[41, 300] loss: 0.327\n",
      "[41, 360] loss: 0.316\n",
      "Epoch: 41 -> Loss: 0.323357433081\n",
      "Epoch: 41 -> Test Accuracy: 85.46\n",
      "[42, 60] loss: 0.314\n",
      "[42, 120] loss: 0.313\n",
      "[42, 180] loss: 0.333\n",
      "[42, 240] loss: 0.320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 300] loss: 0.314\n",
      "[42, 360] loss: 0.312\n",
      "Epoch: 42 -> Loss: 0.253769606352\n",
      "Epoch: 42 -> Test Accuracy: 87.0525\n",
      "[43, 60] loss: 0.312\n",
      "[43, 120] loss: 0.304\n",
      "[43, 180] loss: 0.323\n",
      "[43, 240] loss: 0.311\n",
      "[43, 300] loss: 0.316\n",
      "[43, 360] loss: 0.307\n",
      "Epoch: 43 -> Loss: 0.563426613808\n",
      "Epoch: 43 -> Test Accuracy: 85.84\n",
      "[44, 60] loss: 0.308\n",
      "[44, 120] loss: 0.311\n",
      "[44, 180] loss: 0.314\n",
      "[44, 240] loss: 0.314\n",
      "[44, 300] loss: 0.314\n",
      "[44, 360] loss: 0.316\n",
      "Epoch: 44 -> Loss: 0.197260409594\n",
      "Epoch: 44 -> Test Accuracy: 85.445\n",
      "[45, 60] loss: 0.301\n",
      "[45, 120] loss: 0.307\n",
      "[45, 180] loss: 0.311\n",
      "[45, 240] loss: 0.306\n",
      "[45, 300] loss: 0.329\n",
      "[45, 360] loss: 0.307\n",
      "Epoch: 45 -> Loss: 0.355705320835\n",
      "Epoch: 45 -> Test Accuracy: 86.38\n",
      "[46, 60] loss: 0.307\n",
      "[46, 120] loss: 0.321\n",
      "[46, 180] loss: 0.298\n",
      "[46, 240] loss: 0.311\n",
      "[46, 300] loss: 0.313\n",
      "[46, 360] loss: 0.318\n",
      "Epoch: 46 -> Loss: 0.340223789215\n",
      "Epoch: 46 -> Test Accuracy: 86.5175\n",
      "[47, 60] loss: 0.292\n",
      "[47, 120] loss: 0.294\n",
      "[47, 180] loss: 0.313\n",
      "[47, 240] loss: 0.324\n",
      "[47, 300] loss: 0.310\n",
      "[47, 360] loss: 0.312\n",
      "Epoch: 47 -> Loss: 0.346970498562\n",
      "Epoch: 47 -> Test Accuracy: 86.3675\n",
      "[48, 60] loss: 0.304\n",
      "[48, 120] loss: 0.310\n",
      "[48, 180] loss: 0.305\n",
      "[48, 240] loss: 0.315\n",
      "[48, 300] loss: 0.305\n",
      "[48, 360] loss: 0.325\n",
      "Epoch: 48 -> Loss: 0.295426338911\n",
      "Epoch: 48 -> Test Accuracy: 86.075\n",
      "[49, 60] loss: 0.303\n",
      "[49, 120] loss: 0.299\n",
      "[49, 180] loss: 0.306\n",
      "[49, 240] loss: 0.298\n",
      "[49, 300] loss: 0.311\n",
      "[49, 360] loss: 0.314\n",
      "Epoch: 49 -> Loss: 0.327210903168\n",
      "Epoch: 49 -> Test Accuracy: 86.2275\n",
      "[50, 60] loss: 0.300\n",
      "[50, 120] loss: 0.314\n",
      "[50, 180] loss: 0.316\n",
      "[50, 240] loss: 0.310\n",
      "[50, 300] loss: 0.299\n",
      "[50, 360] loss: 0.307\n",
      "Epoch: 50 -> Loss: 0.262164920568\n",
      "Epoch: 50 -> Test Accuracy: 86.45\n",
      "[51, 60] loss: 0.304\n",
      "[51, 120] loss: 0.297\n",
      "[51, 180] loss: 0.316\n",
      "[51, 240] loss: 0.304\n",
      "[51, 300] loss: 0.303\n",
      "[51, 360] loss: 0.314\n",
      "Epoch: 51 -> Loss: 0.558704257011\n",
      "Epoch: 51 -> Test Accuracy: 86.43\n",
      "[52, 60] loss: 0.297\n",
      "[52, 120] loss: 0.300\n",
      "[52, 180] loss: 0.303\n",
      "[52, 240] loss: 0.310\n",
      "[52, 300] loss: 0.312\n",
      "[52, 360] loss: 0.316\n",
      "Epoch: 52 -> Loss: 0.211936801672\n",
      "Epoch: 52 -> Test Accuracy: 86.44\n",
      "[53, 60] loss: 0.295\n",
      "[53, 120] loss: 0.304\n",
      "[53, 180] loss: 0.299\n",
      "[53, 240] loss: 0.321\n",
      "[53, 300] loss: 0.309\n",
      "[53, 360] loss: 0.316\n",
      "Epoch: 53 -> Loss: 0.397771954536\n",
      "Epoch: 53 -> Test Accuracy: 86.7725\n",
      "[54, 60] loss: 0.287\n",
      "[54, 120] loss: 0.305\n",
      "[54, 180] loss: 0.298\n",
      "[54, 240] loss: 0.308\n",
      "[54, 300] loss: 0.323\n",
      "[54, 360] loss: 0.316\n",
      "Epoch: 54 -> Loss: 0.216649442911\n",
      "Epoch: 54 -> Test Accuracy: 86.64\n",
      "[55, 60] loss: 0.297\n",
      "[55, 120] loss: 0.292\n",
      "[55, 180] loss: 0.304\n",
      "[55, 240] loss: 0.307\n",
      "[55, 300] loss: 0.320\n",
      "[55, 360] loss: 0.304\n",
      "Epoch: 55 -> Loss: 0.238026827574\n",
      "Epoch: 55 -> Test Accuracy: 87.0825\n",
      "[56, 60] loss: 0.302\n",
      "[56, 120] loss: 0.303\n",
      "[56, 180] loss: 0.303\n",
      "[56, 240] loss: 0.302\n",
      "[56, 300] loss: 0.308\n",
      "[56, 360] loss: 0.312\n",
      "Epoch: 56 -> Loss: 0.297676801682\n",
      "Epoch: 56 -> Test Accuracy: 87.385\n",
      "[57, 60] loss: 0.315\n",
      "[57, 120] loss: 0.298\n",
      "[57, 180] loss: 0.292\n",
      "[57, 240] loss: 0.311\n",
      "[57, 300] loss: 0.305\n",
      "[57, 360] loss: 0.315\n",
      "Epoch: 57 -> Loss: 0.223637789488\n",
      "Epoch: 57 -> Test Accuracy: 86.9925\n",
      "[58, 60] loss: 0.289\n",
      "[58, 120] loss: 0.310\n",
      "[58, 180] loss: 0.292\n",
      "[58, 240] loss: 0.318\n",
      "[58, 300] loss: 0.299\n",
      "[58, 360] loss: 0.305\n",
      "Epoch: 58 -> Loss: 0.29629650712\n",
      "Epoch: 58 -> Test Accuracy: 86.595\n",
      "[59, 60] loss: 0.283\n",
      "[59, 120] loss: 0.293\n",
      "[59, 180] loss: 0.303\n",
      "[59, 240] loss: 0.306\n",
      "[59, 300] loss: 0.313\n",
      "[59, 360] loss: 0.318\n",
      "Epoch: 59 -> Loss: 0.416480720043\n",
      "Epoch: 59 -> Test Accuracy: 86.865\n",
      "[60, 60] loss: 0.308\n",
      "[60, 120] loss: 0.301\n",
      "[60, 180] loss: 0.309\n",
      "[60, 240] loss: 0.295\n",
      "[60, 300] loss: 0.309\n",
      "[60, 360] loss: 0.308\n",
      "Epoch: 60 -> Loss: 0.315067499876\n",
      "Epoch: 60 -> Test Accuracy: 85.9925\n",
      "[61, 60] loss: 0.234\n",
      "[61, 120] loss: 0.203\n",
      "[61, 180] loss: 0.193\n",
      "[61, 240] loss: 0.194\n",
      "[61, 300] loss: 0.184\n",
      "[61, 360] loss: 0.182\n",
      "Epoch: 61 -> Loss: 0.257493793964\n",
      "Epoch: 61 -> Test Accuracy: 90.8375\n",
      "[62, 60] loss: 0.165\n",
      "[62, 120] loss: 0.175\n",
      "[62, 180] loss: 0.162\n",
      "[62, 240] loss: 0.175\n",
      "[62, 300] loss: 0.164\n",
      "[62, 360] loss: 0.178\n",
      "Epoch: 62 -> Loss: 0.0865824595094\n",
      "Epoch: 62 -> Test Accuracy: 91.0775\n",
      "[63, 60] loss: 0.154\n",
      "[63, 120] loss: 0.149\n",
      "[63, 180] loss: 0.161\n",
      "[63, 240] loss: 0.160\n",
      "[63, 300] loss: 0.159\n",
      "[63, 360] loss: 0.165\n",
      "Epoch: 63 -> Loss: 0.153549820185\n",
      "Epoch: 63 -> Test Accuracy: 90.75\n",
      "[64, 60] loss: 0.139\n",
      "[64, 120] loss: 0.157\n",
      "[64, 180] loss: 0.152\n",
      "[64, 240] loss: 0.159\n",
      "[64, 300] loss: 0.160\n",
      "[64, 360] loss: 0.148\n",
      "Epoch: 64 -> Loss: 0.187169626355\n",
      "Epoch: 64 -> Test Accuracy: 90.67\n",
      "[65, 60] loss: 0.139\n",
      "[65, 120] loss: 0.151\n",
      "[65, 180] loss: 0.156\n",
      "[65, 240] loss: 0.147\n",
      "[65, 300] loss: 0.155\n",
      "[65, 360] loss: 0.160\n",
      "Epoch: 65 -> Loss: 0.233649969101\n",
      "Epoch: 65 -> Test Accuracy: 91.2475\n",
      "[66, 60] loss: 0.133\n",
      "[66, 120] loss: 0.140\n",
      "[66, 180] loss: 0.146\n",
      "[66, 240] loss: 0.154\n",
      "[66, 300] loss: 0.149\n",
      "[66, 360] loss: 0.170\n",
      "Epoch: 66 -> Loss: 0.180664598942\n",
      "Epoch: 66 -> Test Accuracy: 90.92\n",
      "[67, 60] loss: 0.141\n",
      "[67, 120] loss: 0.130\n",
      "[67, 180] loss: 0.144\n",
      "[67, 240] loss: 0.150\n",
      "[67, 300] loss: 0.159\n",
      "[67, 360] loss: 0.150\n",
      "Epoch: 67 -> Loss: 0.240997821093\n",
      "Epoch: 67 -> Test Accuracy: 90.7375\n",
      "[68, 60] loss: 0.135\n",
      "[68, 120] loss: 0.137\n",
      "[68, 180] loss: 0.140\n",
      "[68, 240] loss: 0.145\n",
      "[68, 300] loss: 0.153\n",
      "[68, 360] loss: 0.156\n",
      "Epoch: 68 -> Loss: 0.0974007621408\n",
      "Epoch: 68 -> Test Accuracy: 90.805\n",
      "[69, 60] loss: 0.136\n",
      "[69, 120] loss: 0.137\n",
      "[69, 180] loss: 0.143\n",
      "[69, 240] loss: 0.151\n",
      "[69, 300] loss: 0.156\n",
      "[69, 360] loss: 0.152\n",
      "Epoch: 69 -> Loss: 0.107269763947\n",
      "Epoch: 69 -> Test Accuracy: 90.62\n",
      "[70, 60] loss: 0.133\n",
      "[70, 120] loss: 0.143\n",
      "[70, 180] loss: 0.156\n",
      "[70, 240] loss: 0.155\n",
      "[70, 300] loss: 0.150\n",
      "[70, 360] loss: 0.151\n",
      "Epoch: 70 -> Loss: 0.152205005288\n",
      "Epoch: 70 -> Test Accuracy: 90.6575\n",
      "[71, 60] loss: 0.136\n",
      "[71, 120] loss: 0.143\n",
      "[71, 180] loss: 0.149\n",
      "[71, 240] loss: 0.156\n",
      "[71, 300] loss: 0.140\n",
      "[71, 360] loss: 0.155\n",
      "Epoch: 71 -> Loss: 0.0578576922417\n",
      "Epoch: 71 -> Test Accuracy: 90.595\n",
      "[72, 60] loss: 0.142\n",
      "[72, 120] loss: 0.143\n",
      "[72, 180] loss: 0.143\n",
      "[72, 240] loss: 0.148\n",
      "[72, 300] loss: 0.148\n",
      "[72, 360] loss: 0.162\n",
      "Epoch: 72 -> Loss: 0.229731589556\n",
      "Epoch: 72 -> Test Accuracy: 90.5675\n",
      "[73, 60] loss: 0.138\n",
      "[73, 120] loss: 0.137\n",
      "[73, 180] loss: 0.144\n",
      "[73, 240] loss: 0.157\n",
      "[73, 300] loss: 0.155\n",
      "[73, 360] loss: 0.149\n",
      "Epoch: 73 -> Loss: 0.139179721475\n",
      "Epoch: 73 -> Test Accuracy: 90.2975\n",
      "[74, 60] loss: 0.131\n",
      "[74, 120] loss: 0.142\n",
      "[74, 180] loss: 0.152\n",
      "[74, 240] loss: 0.149\n",
      "[74, 300] loss: 0.149\n",
      "[74, 360] loss: 0.166\n",
      "Epoch: 74 -> Loss: 0.123803041875\n",
      "Epoch: 74 -> Test Accuracy: 90.335\n",
      "[75, 60] loss: 0.133\n",
      "[75, 120] loss: 0.144\n",
      "[75, 180] loss: 0.147\n",
      "[75, 240] loss: 0.151\n",
      "[75, 300] loss: 0.154\n",
      "[75, 360] loss: 0.162\n",
      "Epoch: 75 -> Loss: 0.0926921665668\n",
      "Epoch: 75 -> Test Accuracy: 90.645\n",
      "[76, 60] loss: 0.127\n",
      "[76, 120] loss: 0.143\n",
      "[76, 180] loss: 0.154\n",
      "[76, 240] loss: 0.152\n",
      "[76, 300] loss: 0.158\n",
      "[76, 360] loss: 0.157\n",
      "Epoch: 76 -> Loss: 0.233729764819\n",
      "Epoch: 76 -> Test Accuracy: 89.8525\n",
      "[77, 60] loss: 0.137\n",
      "[77, 120] loss: 0.148\n",
      "[77, 180] loss: 0.152\n",
      "[77, 240] loss: 0.153\n",
      "[77, 300] loss: 0.148\n",
      "[77, 360] loss: 0.155\n",
      "Epoch: 77 -> Loss: 0.134552687407\n",
      "Epoch: 77 -> Test Accuracy: 89.805\n",
      "[78, 60] loss: 0.141\n",
      "[78, 120] loss: 0.139\n",
      "[78, 180] loss: 0.149\n",
      "[78, 240] loss: 0.152\n",
      "[78, 300] loss: 0.145\n",
      "[78, 360] loss: 0.152\n",
      "Epoch: 78 -> Loss: 0.12340823561\n",
      "Epoch: 78 -> Test Accuracy: 90.435\n",
      "[79, 60] loss: 0.138\n",
      "[79, 120] loss: 0.142\n",
      "[79, 180] loss: 0.147\n",
      "[79, 240] loss: 0.150\n",
      "[79, 300] loss: 0.152\n",
      "[79, 360] loss: 0.156\n",
      "Epoch: 79 -> Loss: 0.119437493384\n",
      "Epoch: 79 -> Test Accuracy: 90.48\n",
      "[80, 60] loss: 0.133\n",
      "[80, 120] loss: 0.143\n",
      "[80, 180] loss: 0.156\n",
      "[80, 240] loss: 0.150\n",
      "[80, 300] loss: 0.151\n",
      "[80, 360] loss: 0.161\n",
      "Epoch: 80 -> Loss: 0.197319746017\n",
      "Epoch: 80 -> Test Accuracy: 90.72\n",
      "[81, 60] loss: 0.137\n",
      "[81, 120] loss: 0.135\n",
      "[81, 180] loss: 0.140\n",
      "[81, 240] loss: 0.164\n",
      "[81, 300] loss: 0.153\n",
      "[81, 360] loss: 0.153\n",
      "Epoch: 81 -> Loss: 0.147236421704\n",
      "Epoch: 81 -> Test Accuracy: 90.2075\n",
      "[82, 60] loss: 0.133\n",
      "[82, 120] loss: 0.142\n",
      "[82, 180] loss: 0.148\n",
      "[82, 240] loss: 0.152\n",
      "[82, 300] loss: 0.159\n",
      "[82, 360] loss: 0.146\n",
      "Epoch: 82 -> Loss: 0.162711307406\n",
      "Epoch: 82 -> Test Accuracy: 90.5125\n",
      "[83, 60] loss: 0.137\n",
      "[83, 120] loss: 0.141\n",
      "[83, 180] loss: 0.154\n",
      "[83, 240] loss: 0.163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83, 300] loss: 0.144\n",
      "[83, 360] loss: 0.142\n",
      "Epoch: 83 -> Loss: 0.18048402667\n",
      "Epoch: 83 -> Test Accuracy: 90.06\n",
      "[84, 60] loss: 0.140\n",
      "[84, 120] loss: 0.142\n",
      "[84, 180] loss: 0.147\n",
      "[84, 240] loss: 0.153\n",
      "[84, 300] loss: 0.153\n",
      "[84, 360] loss: 0.148\n",
      "Epoch: 84 -> Loss: 0.216561958194\n",
      "Epoch: 84 -> Test Accuracy: 90.1975\n",
      "[85, 60] loss: 0.144\n",
      "[85, 120] loss: 0.150\n",
      "[85, 180] loss: 0.148\n",
      "[85, 240] loss: 0.147\n",
      "[85, 300] loss: 0.151\n",
      "[85, 360] loss: 0.148\n",
      "Epoch: 85 -> Loss: 0.126949474216\n",
      "Epoch: 85 -> Test Accuracy: 90.1625\n",
      "[86, 60] loss: 0.131\n",
      "[86, 120] loss: 0.144\n",
      "[86, 180] loss: 0.150\n",
      "[86, 240] loss: 0.149\n",
      "[86, 300] loss: 0.146\n",
      "[86, 360] loss: 0.153\n",
      "Epoch: 86 -> Loss: 0.150083363056\n",
      "Epoch: 86 -> Test Accuracy: 90.045\n",
      "[87, 60] loss: 0.142\n",
      "[87, 120] loss: 0.133\n",
      "[87, 180] loss: 0.146\n",
      "[87, 240] loss: 0.146\n",
      "[87, 300] loss: 0.148\n",
      "[87, 360] loss: 0.153\n",
      "Epoch: 87 -> Loss: 0.199031338096\n",
      "Epoch: 87 -> Test Accuracy: 90.345\n",
      "[88, 60] loss: 0.133\n",
      "[88, 120] loss: 0.137\n",
      "[88, 180] loss: 0.141\n",
      "[88, 240] loss: 0.153\n",
      "[88, 300] loss: 0.155\n",
      "[88, 360] loss: 0.152\n",
      "Epoch: 88 -> Loss: 0.0984996110201\n",
      "Epoch: 88 -> Test Accuracy: 90.0775\n",
      "[89, 60] loss: 0.134\n",
      "[89, 120] loss: 0.141\n",
      "[89, 180] loss: 0.150\n",
      "[89, 240] loss: 0.141\n",
      "[89, 300] loss: 0.150\n",
      "[89, 360] loss: 0.153\n",
      "Epoch: 89 -> Loss: 0.19020023942\n",
      "Epoch: 89 -> Test Accuracy: 89.4325\n",
      "[90, 60] loss: 0.130\n",
      "[90, 120] loss: 0.138\n",
      "[90, 180] loss: 0.146\n",
      "[90, 240] loss: 0.152\n",
      "[90, 300] loss: 0.152\n",
      "[90, 360] loss: 0.150\n",
      "Epoch: 90 -> Loss: 0.133213981986\n",
      "Epoch: 90 -> Test Accuracy: 89.86\n",
      "[91, 60] loss: 0.129\n",
      "[91, 120] loss: 0.138\n",
      "[91, 180] loss: 0.138\n",
      "[91, 240] loss: 0.137\n",
      "[91, 300] loss: 0.149\n",
      "[91, 360] loss: 0.156\n",
      "Epoch: 91 -> Loss: 0.106935165823\n",
      "Epoch: 91 -> Test Accuracy: 90.335\n",
      "[92, 60] loss: 0.133\n",
      "[92, 120] loss: 0.138\n",
      "[92, 180] loss: 0.134\n",
      "[92, 240] loss: 0.142\n",
      "[92, 300] loss: 0.146\n",
      "[92, 360] loss: 0.149\n",
      "Epoch: 92 -> Loss: 0.0827312022448\n",
      "Epoch: 92 -> Test Accuracy: 89.91\n",
      "[93, 60] loss: 0.142\n",
      "[93, 120] loss: 0.141\n",
      "[93, 180] loss: 0.146\n",
      "[93, 240] loss: 0.139\n",
      "[93, 300] loss: 0.147\n",
      "[93, 360] loss: 0.144\n",
      "Epoch: 93 -> Loss: 0.128798484802\n",
      "Epoch: 93 -> Test Accuracy: 89.765\n",
      "[94, 60] loss: 0.128\n",
      "[94, 120] loss: 0.140\n",
      "[94, 180] loss: 0.149\n",
      "[94, 240] loss: 0.144\n",
      "[94, 300] loss: 0.151\n",
      "[94, 360] loss: 0.143\n",
      "Epoch: 94 -> Loss: 0.179246529937\n",
      "Epoch: 94 -> Test Accuracy: 89.98\n",
      "[95, 60] loss: 0.130\n",
      "[95, 120] loss: 0.142\n",
      "[95, 180] loss: 0.142\n",
      "[95, 240] loss: 0.144\n",
      "[95, 300] loss: 0.149\n",
      "[95, 360] loss: 0.145\n",
      "Epoch: 95 -> Loss: 0.0688802152872\n",
      "Epoch: 95 -> Test Accuracy: 90.195\n",
      "[96, 60] loss: 0.129\n",
      "[96, 120] loss: 0.141\n",
      "[96, 180] loss: 0.135\n",
      "[96, 240] loss: 0.142\n",
      "[96, 300] loss: 0.145\n",
      "[96, 360] loss: 0.141\n",
      "Epoch: 96 -> Loss: 0.143388211727\n",
      "Epoch: 96 -> Test Accuracy: 89.8\n",
      "[97, 60] loss: 0.126\n",
      "[97, 120] loss: 0.149\n",
      "[97, 180] loss: 0.136\n",
      "[97, 240] loss: 0.144\n",
      "[97, 300] loss: 0.143\n",
      "[97, 360] loss: 0.144\n",
      "Epoch: 97 -> Loss: 0.0866463035345\n",
      "Epoch: 97 -> Test Accuracy: 90.2775\n",
      "[98, 60] loss: 0.126\n",
      "[98, 120] loss: 0.139\n",
      "[98, 180] loss: 0.141\n",
      "[98, 240] loss: 0.150\n",
      "[98, 300] loss: 0.144\n",
      "[98, 360] loss: 0.147\n",
      "Epoch: 98 -> Loss: 0.124624237418\n",
      "Epoch: 98 -> Test Accuracy: 89.89\n",
      "[99, 60] loss: 0.138\n",
      "[99, 120] loss: 0.133\n",
      "[99, 180] loss: 0.137\n",
      "[99, 240] loss: 0.140\n",
      "[99, 300] loss: 0.145\n",
      "[99, 360] loss: 0.141\n",
      "Epoch: 99 -> Loss: 0.14703579247\n",
      "Epoch: 99 -> Test Accuracy: 89.775\n",
      "[100, 60] loss: 0.127\n",
      "[100, 120] loss: 0.143\n",
      "[100, 180] loss: 0.148\n",
      "[100, 240] loss: 0.143\n",
      "[100, 300] loss: 0.140\n",
      "[100, 360] loss: 0.145\n",
      "Epoch: 100 -> Loss: 0.129637151957\n",
      "Epoch: 100 -> Test Accuracy: 89.885\n",
      "[101, 60] loss: 0.125\n",
      "[101, 120] loss: 0.138\n",
      "[101, 180] loss: 0.140\n",
      "[101, 240] loss: 0.136\n",
      "[101, 300] loss: 0.153\n",
      "[101, 360] loss: 0.138\n",
      "Epoch: 101 -> Loss: 0.0857701897621\n",
      "Epoch: 101 -> Test Accuracy: 90.29\n",
      "[102, 60] loss: 0.124\n",
      "[102, 120] loss: 0.135\n",
      "[102, 180] loss: 0.136\n",
      "[102, 240] loss: 0.146\n",
      "[102, 300] loss: 0.136\n",
      "[102, 360] loss: 0.147\n",
      "Epoch: 102 -> Loss: 0.159628331661\n",
      "Epoch: 102 -> Test Accuracy: 89.525\n",
      "[103, 60] loss: 0.129\n",
      "[103, 120] loss: 0.133\n",
      "[103, 180] loss: 0.138\n",
      "[103, 240] loss: 0.138\n",
      "[103, 300] loss: 0.158\n",
      "[103, 360] loss: 0.151\n",
      "Epoch: 103 -> Loss: 0.0769262760878\n",
      "Epoch: 103 -> Test Accuracy: 90.025\n",
      "[104, 60] loss: 0.127\n",
      "[104, 120] loss: 0.134\n",
      "[104, 180] loss: 0.133\n",
      "[104, 240] loss: 0.141\n",
      "[104, 300] loss: 0.141\n",
      "[104, 360] loss: 0.135\n",
      "Epoch: 104 -> Loss: 0.197350844741\n",
      "Epoch: 104 -> Test Accuracy: 90.4075\n",
      "[105, 60] loss: 0.133\n",
      "[105, 120] loss: 0.130\n",
      "[105, 180] loss: 0.144\n",
      "[105, 240] loss: 0.136\n",
      "[105, 300] loss: 0.136\n",
      "[105, 360] loss: 0.142\n",
      "Epoch: 105 -> Loss: 0.121463991702\n",
      "Epoch: 105 -> Test Accuracy: 90.1875\n",
      "[106, 60] loss: 0.128\n",
      "[106, 120] loss: 0.126\n",
      "[106, 180] loss: 0.129\n",
      "[106, 240] loss: 0.130\n",
      "[106, 300] loss: 0.151\n",
      "[106, 360] loss: 0.149\n",
      "Epoch: 106 -> Loss: 0.20069296658\n",
      "Epoch: 106 -> Test Accuracy: 89.93\n",
      "[107, 60] loss: 0.130\n",
      "[107, 120] loss: 0.128\n",
      "[107, 180] loss: 0.140\n",
      "[107, 240] loss: 0.145\n",
      "[107, 300] loss: 0.142\n",
      "[107, 360] loss: 0.138\n",
      "Epoch: 107 -> Loss: 0.103429235518\n",
      "Epoch: 107 -> Test Accuracy: 90.385\n",
      "[108, 60] loss: 0.131\n",
      "[108, 120] loss: 0.130\n",
      "[108, 180] loss: 0.134\n",
      "[108, 240] loss: 0.142\n",
      "[108, 300] loss: 0.137\n",
      "[108, 360] loss: 0.137\n",
      "Epoch: 108 -> Loss: 0.0865264981985\n",
      "Epoch: 108 -> Test Accuracy: 90.2075\n",
      "[109, 60] loss: 0.126\n",
      "[109, 120] loss: 0.132\n",
      "[109, 180] loss: 0.134\n",
      "[109, 240] loss: 0.137\n",
      "[109, 300] loss: 0.130\n",
      "[109, 360] loss: 0.137\n",
      "Epoch: 109 -> Loss: 0.246076077223\n",
      "Epoch: 109 -> Test Accuracy: 89.7825\n",
      "[110, 60] loss: 0.128\n",
      "[110, 120] loss: 0.131\n",
      "[110, 180] loss: 0.136\n",
      "[110, 240] loss: 0.137\n",
      "[110, 300] loss: 0.135\n",
      "[110, 360] loss: 0.148\n",
      "Epoch: 110 -> Loss: 0.138960167766\n",
      "Epoch: 110 -> Test Accuracy: 90.205\n",
      "[111, 60] loss: 0.123\n",
      "[111, 120] loss: 0.134\n",
      "[111, 180] loss: 0.132\n",
      "[111, 240] loss: 0.139\n",
      "[111, 300] loss: 0.131\n",
      "[111, 360] loss: 0.142\n",
      "Epoch: 111 -> Loss: 0.11817779392\n",
      "Epoch: 111 -> Test Accuracy: 90.2075\n",
      "[112, 60] loss: 0.128\n",
      "[112, 120] loss: 0.144\n",
      "[112, 180] loss: 0.135\n",
      "[112, 240] loss: 0.129\n",
      "[112, 300] loss: 0.137\n",
      "[112, 360] loss: 0.140\n",
      "Epoch: 112 -> Loss: 0.158275038004\n",
      "Epoch: 112 -> Test Accuracy: 90.22\n",
      "[113, 60] loss: 0.124\n",
      "[113, 120] loss: 0.134\n",
      "[113, 180] loss: 0.135\n",
      "[113, 240] loss: 0.136\n",
      "[113, 300] loss: 0.141\n",
      "[113, 360] loss: 0.138\n",
      "Epoch: 113 -> Loss: 0.128312349319\n",
      "Epoch: 113 -> Test Accuracy: 89.9325\n",
      "[114, 60] loss: 0.125\n",
      "[114, 120] loss: 0.131\n",
      "[114, 180] loss: 0.133\n",
      "[114, 240] loss: 0.125\n",
      "[114, 300] loss: 0.147\n",
      "[114, 360] loss: 0.134\n",
      "Epoch: 114 -> Loss: 0.137061059475\n",
      "Epoch: 114 -> Test Accuracy: 90.3575\n",
      "[115, 60] loss: 0.128\n",
      "[115, 120] loss: 0.125\n",
      "[115, 180] loss: 0.136\n",
      "[115, 240] loss: 0.131\n",
      "[115, 300] loss: 0.140\n",
      "[115, 360] loss: 0.139\n",
      "Epoch: 115 -> Loss: 0.0742851570249\n",
      "Epoch: 115 -> Test Accuracy: 89.935\n",
      "[116, 60] loss: 0.120\n",
      "[116, 120] loss: 0.131\n",
      "[116, 180] loss: 0.136\n",
      "[116, 240] loss: 0.141\n",
      "[116, 300] loss: 0.133\n",
      "[116, 360] loss: 0.137\n",
      "Epoch: 116 -> Loss: 0.0660155415535\n",
      "Epoch: 116 -> Test Accuracy: 90.13\n",
      "[117, 60] loss: 0.125\n",
      "[117, 120] loss: 0.125\n",
      "[117, 180] loss: 0.131\n",
      "[117, 240] loss: 0.130\n",
      "[117, 300] loss: 0.136\n",
      "[117, 360] loss: 0.144\n",
      "Epoch: 117 -> Loss: 0.138345554471\n",
      "Epoch: 117 -> Test Accuracy: 89.8425\n",
      "[118, 60] loss: 0.127\n",
      "[118, 120] loss: 0.129\n",
      "[118, 180] loss: 0.130\n",
      "[118, 240] loss: 0.134\n",
      "[118, 300] loss: 0.145\n",
      "[118, 360] loss: 0.132\n",
      "Epoch: 118 -> Loss: 0.231734111905\n",
      "Epoch: 118 -> Test Accuracy: 90.3125\n",
      "[119, 60] loss: 0.116\n",
      "[119, 120] loss: 0.125\n",
      "[119, 180] loss: 0.127\n",
      "[119, 240] loss: 0.139\n",
      "[119, 300] loss: 0.137\n",
      "[119, 360] loss: 0.143\n",
      "Epoch: 119 -> Loss: 0.155663475394\n",
      "Epoch: 119 -> Test Accuracy: 89.49\n",
      "[120, 60] loss: 0.131\n",
      "[120, 120] loss: 0.126\n",
      "[120, 180] loss: 0.135\n",
      "[120, 240] loss: 0.137\n",
      "[120, 300] loss: 0.140\n",
      "[120, 360] loss: 0.133\n",
      "Epoch: 120 -> Loss: 0.137778788805\n",
      "Epoch: 120 -> Test Accuracy: 89.735\n",
      "[121, 60] loss: 0.094\n",
      "[121, 120] loss: 0.074\n",
      "[121, 180] loss: 0.073\n",
      "[121, 240] loss: 0.069\n",
      "[121, 300] loss: 0.067\n",
      "[121, 360] loss: 0.061\n",
      "Epoch: 121 -> Loss: 0.135361716151\n",
      "Epoch: 121 -> Test Accuracy: 92.08\n",
      "[122, 60] loss: 0.055\n",
      "[122, 120] loss: 0.059\n",
      "[122, 180] loss: 0.053\n",
      "[122, 240] loss: 0.057\n",
      "[122, 300] loss: 0.057\n",
      "[122, 360] loss: 0.055\n",
      "Epoch: 122 -> Loss: 0.0408348068595\n",
      "Epoch: 122 -> Test Accuracy: 91.9175\n",
      "[123, 60] loss: 0.048\n",
      "[123, 120] loss: 0.044\n",
      "[123, 180] loss: 0.048\n",
      "[123, 240] loss: 0.045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123, 300] loss: 0.049\n",
      "[123, 360] loss: 0.047\n",
      "Epoch: 123 -> Loss: 0.0200503431261\n",
      "Epoch: 123 -> Test Accuracy: 91.94\n",
      "[124, 60] loss: 0.041\n",
      "[124, 120] loss: 0.042\n",
      "[124, 180] loss: 0.042\n",
      "[124, 240] loss: 0.044\n",
      "[124, 300] loss: 0.044\n",
      "[124, 360] loss: 0.044\n",
      "Epoch: 124 -> Loss: 0.0708405822515\n",
      "Epoch: 124 -> Test Accuracy: 91.84\n",
      "[125, 60] loss: 0.040\n",
      "[125, 120] loss: 0.040\n",
      "[125, 180] loss: 0.039\n",
      "[125, 240] loss: 0.042\n",
      "[125, 300] loss: 0.041\n",
      "[125, 360] loss: 0.042\n",
      "Epoch: 125 -> Loss: 0.0240495614707\n",
      "Epoch: 125 -> Test Accuracy: 92.16\n",
      "[126, 60] loss: 0.039\n",
      "[126, 120] loss: 0.036\n",
      "[126, 180] loss: 0.038\n",
      "[126, 240] loss: 0.041\n",
      "[126, 300] loss: 0.036\n",
      "[126, 360] loss: 0.037\n",
      "Epoch: 126 -> Loss: 0.0288580060005\n",
      "Epoch: 126 -> Test Accuracy: 91.96\n",
      "[127, 60] loss: 0.036\n",
      "[127, 120] loss: 0.039\n",
      "[127, 180] loss: 0.035\n",
      "[127, 240] loss: 0.040\n",
      "[127, 300] loss: 0.038\n",
      "[127, 360] loss: 0.038\n",
      "Epoch: 127 -> Loss: 0.0375020503998\n",
      "Epoch: 127 -> Test Accuracy: 91.9625\n",
      "[128, 60] loss: 0.032\n",
      "[128, 120] loss: 0.036\n",
      "[128, 180] loss: 0.032\n",
      "[128, 240] loss: 0.035\n",
      "[128, 300] loss: 0.038\n",
      "[128, 360] loss: 0.036\n",
      "Epoch: 128 -> Loss: 0.0523435696959\n",
      "Epoch: 128 -> Test Accuracy: 91.8575\n",
      "[129, 60] loss: 0.035\n",
      "[129, 120] loss: 0.034\n",
      "[129, 180] loss: 0.032\n",
      "[129, 240] loss: 0.031\n",
      "[129, 300] loss: 0.036\n",
      "[129, 360] loss: 0.034\n",
      "Epoch: 129 -> Loss: 0.0339855179191\n",
      "Epoch: 129 -> Test Accuracy: 91.935\n",
      "[130, 60] loss: 0.031\n",
      "[130, 120] loss: 0.031\n",
      "[130, 180] loss: 0.034\n",
      "[130, 240] loss: 0.027\n",
      "[130, 300] loss: 0.033\n",
      "[130, 360] loss: 0.031\n",
      "Epoch: 130 -> Loss: 0.0164341032505\n",
      "Epoch: 130 -> Test Accuracy: 92.0\n",
      "[131, 60] loss: 0.030\n",
      "[131, 120] loss: 0.030\n",
      "[131, 180] loss: 0.028\n",
      "[131, 240] loss: 0.032\n",
      "[131, 300] loss: 0.034\n",
      "[131, 360] loss: 0.034\n",
      "Epoch: 131 -> Loss: 0.037492223084\n",
      "Epoch: 131 -> Test Accuracy: 92.0425\n",
      "[132, 60] loss: 0.028\n",
      "[132, 120] loss: 0.030\n",
      "[132, 180] loss: 0.030\n",
      "[132, 240] loss: 0.030\n",
      "[132, 300] loss: 0.032\n",
      "[132, 360] loss: 0.033\n",
      "Epoch: 132 -> Loss: 0.0191562417895\n",
      "Epoch: 132 -> Test Accuracy: 91.815\n",
      "[133, 60] loss: 0.032\n",
      "[133, 120] loss: 0.028\n",
      "[133, 180] loss: 0.027\n",
      "[133, 240] loss: 0.029\n",
      "[133, 300] loss: 0.032\n",
      "[133, 360] loss: 0.030\n",
      "Epoch: 133 -> Loss: 0.0479798987508\n",
      "Epoch: 133 -> Test Accuracy: 91.645\n",
      "[134, 60] loss: 0.028\n",
      "[134, 120] loss: 0.027\n",
      "[134, 180] loss: 0.030\n",
      "[134, 240] loss: 0.029\n",
      "[134, 300] loss: 0.032\n",
      "[134, 360] loss: 0.031\n",
      "Epoch: 134 -> Loss: 0.0395761393011\n",
      "Epoch: 134 -> Test Accuracy: 91.765\n",
      "[135, 60] loss: 0.027\n",
      "[135, 120] loss: 0.027\n",
      "[135, 180] loss: 0.029\n",
      "[135, 240] loss: 0.031\n",
      "[135, 300] loss: 0.030\n",
      "[135, 360] loss: 0.032\n",
      "Epoch: 135 -> Loss: 0.0443197861314\n",
      "Epoch: 135 -> Test Accuracy: 91.66\n",
      "[136, 60] loss: 0.025\n",
      "[136, 120] loss: 0.027\n",
      "[136, 180] loss: 0.028\n",
      "[136, 240] loss: 0.031\n",
      "[136, 300] loss: 0.029\n",
      "[136, 360] loss: 0.028\n",
      "Epoch: 136 -> Loss: 0.043962970376\n",
      "Epoch: 136 -> Test Accuracy: 91.655\n",
      "[137, 60] loss: 0.029\n",
      "[137, 120] loss: 0.031\n",
      "[137, 180] loss: 0.025\n",
      "[137, 240] loss: 0.028\n",
      "[137, 300] loss: 0.029\n",
      "[137, 360] loss: 0.030\n",
      "Epoch: 137 -> Loss: 0.0119212325662\n",
      "Epoch: 137 -> Test Accuracy: 91.7175\n",
      "[138, 60] loss: 0.028\n",
      "[138, 120] loss: 0.026\n",
      "[138, 180] loss: 0.026\n",
      "[138, 240] loss: 0.031\n",
      "[138, 300] loss: 0.033\n",
      "[138, 360] loss: 0.030\n",
      "Epoch: 138 -> Loss: 0.00929636694491\n",
      "Epoch: 138 -> Test Accuracy: 91.8375\n",
      "[139, 60] loss: 0.026\n",
      "[139, 120] loss: 0.026\n",
      "[139, 180] loss: 0.030\n",
      "[139, 240] loss: 0.030\n",
      "[139, 300] loss: 0.030\n",
      "[139, 360] loss: 0.027\n",
      "Epoch: 139 -> Loss: 0.0289001911879\n",
      "Epoch: 139 -> Test Accuracy: 91.8125\n",
      "[140, 60] loss: 0.027\n",
      "[140, 120] loss: 0.027\n",
      "[140, 180] loss: 0.025\n",
      "[140, 240] loss: 0.027\n",
      "[140, 300] loss: 0.025\n",
      "[140, 360] loss: 0.026\n",
      "Epoch: 140 -> Loss: 0.0296438075602\n",
      "Epoch: 140 -> Test Accuracy: 91.6925\n",
      "[141, 60] loss: 0.023\n",
      "[141, 120] loss: 0.030\n",
      "[141, 180] loss: 0.025\n",
      "[141, 240] loss: 0.026\n",
      "[141, 300] loss: 0.025\n",
      "[141, 360] loss: 0.029\n",
      "Epoch: 141 -> Loss: 0.0180297922343\n",
      "Epoch: 141 -> Test Accuracy: 91.84\n",
      "[142, 60] loss: 0.027\n",
      "[142, 120] loss: 0.027\n",
      "[142, 180] loss: 0.026\n",
      "[142, 240] loss: 0.030\n",
      "[142, 300] loss: 0.029\n",
      "[142, 360] loss: 0.031\n",
      "Epoch: 142 -> Loss: 0.028716975823\n",
      "Epoch: 142 -> Test Accuracy: 91.5875\n",
      "[143, 60] loss: 0.027\n",
      "[143, 120] loss: 0.025\n",
      "[143, 180] loss: 0.028\n",
      "[143, 240] loss: 0.031\n",
      "[143, 300] loss: 0.029\n",
      "[143, 360] loss: 0.032\n",
      "Epoch: 143 -> Loss: 0.0296049751341\n",
      "Epoch: 143 -> Test Accuracy: 91.7\n",
      "[144, 60] loss: 0.026\n",
      "[144, 120] loss: 0.026\n",
      "[144, 180] loss: 0.030\n",
      "[144, 240] loss: 0.025\n",
      "[144, 300] loss: 0.029\n",
      "[144, 360] loss: 0.028\n",
      "Epoch: 144 -> Loss: 0.0317931398749\n",
      "Epoch: 144 -> Test Accuracy: 91.46\n",
      "[145, 60] loss: 0.025\n",
      "[145, 120] loss: 0.027\n",
      "[145, 180] loss: 0.029\n",
      "[145, 240] loss: 0.027\n",
      "[145, 300] loss: 0.032\n",
      "[145, 360] loss: 0.029\n",
      "Epoch: 145 -> Loss: 0.0411706194282\n",
      "Epoch: 145 -> Test Accuracy: 91.34\n",
      "[146, 60] loss: 0.024\n",
      "[146, 120] loss: 0.028\n",
      "[146, 180] loss: 0.027\n",
      "[146, 240] loss: 0.027\n",
      "[146, 300] loss: 0.030\n",
      "[146, 360] loss: 0.029\n",
      "Epoch: 146 -> Loss: 0.0376299843192\n",
      "Epoch: 146 -> Test Accuracy: 91.7125\n",
      "[147, 60] loss: 0.027\n",
      "[147, 120] loss: 0.025\n",
      "[147, 180] loss: 0.026\n",
      "[147, 240] loss: 0.028\n",
      "[147, 300] loss: 0.027\n",
      "[147, 360] loss: 0.030\n",
      "Epoch: 147 -> Loss: 0.0418602786958\n",
      "Epoch: 147 -> Test Accuracy: 91.495\n",
      "[148, 60] loss: 0.024\n",
      "[148, 120] loss: 0.024\n",
      "[148, 180] loss: 0.028\n",
      "[148, 240] loss: 0.031\n",
      "[148, 300] loss: 0.029\n",
      "[148, 360] loss: 0.030\n",
      "Epoch: 148 -> Loss: 0.0266954693943\n",
      "Epoch: 148 -> Test Accuracy: 91.4575\n",
      "[149, 60] loss: 0.024\n",
      "[149, 120] loss: 0.026\n",
      "[149, 180] loss: 0.026\n",
      "[149, 240] loss: 0.026\n",
      "[149, 300] loss: 0.029\n",
      "[149, 360] loss: 0.030\n",
      "Epoch: 149 -> Loss: 0.0661013275385\n",
      "Epoch: 149 -> Test Accuracy: 91.6575\n",
      "[150, 60] loss: 0.023\n",
      "[150, 120] loss: 0.027\n",
      "[150, 180] loss: 0.027\n",
      "[150, 240] loss: 0.028\n",
      "[150, 300] loss: 0.028\n",
      "[150, 360] loss: 0.029\n",
      "Epoch: 150 -> Loss: 0.0413826182485\n",
      "Epoch: 150 -> Test Accuracy: 91.4325\n",
      "[151, 60] loss: 0.026\n",
      "[151, 120] loss: 0.024\n",
      "[151, 180] loss: 0.024\n",
      "[151, 240] loss: 0.029\n",
      "[151, 300] loss: 0.029\n",
      "[151, 360] loss: 0.028\n",
      "Epoch: 151 -> Loss: 0.0223772898316\n",
      "Epoch: 151 -> Test Accuracy: 91.7475\n",
      "[152, 60] loss: 0.025\n",
      "[152, 120] loss: 0.026\n",
      "[152, 180] loss: 0.027\n",
      "[152, 240] loss: 0.028\n",
      "[152, 300] loss: 0.030\n",
      "[152, 360] loss: 0.032\n",
      "Epoch: 152 -> Loss: 0.0361060909927\n",
      "Epoch: 152 -> Test Accuracy: 91.555\n",
      "[153, 60] loss: 0.026\n",
      "[153, 120] loss: 0.027\n",
      "[153, 180] loss: 0.030\n",
      "[153, 240] loss: 0.029\n",
      "[153, 300] loss: 0.029\n",
      "[153, 360] loss: 0.033\n",
      "Epoch: 153 -> Loss: 0.0324813909829\n",
      "Epoch: 153 -> Test Accuracy: 91.375\n",
      "[154, 60] loss: 0.027\n",
      "[154, 120] loss: 0.027\n",
      "[154, 180] loss: 0.026\n",
      "[154, 240] loss: 0.030\n",
      "[154, 300] loss: 0.029\n",
      "[154, 360] loss: 0.030\n",
      "Epoch: 154 -> Loss: 0.0305881146342\n",
      "Epoch: 154 -> Test Accuracy: 91.6375\n",
      "[155, 60] loss: 0.027\n",
      "[155, 120] loss: 0.025\n",
      "[155, 180] loss: 0.027\n",
      "[155, 240] loss: 0.028\n",
      "[155, 300] loss: 0.028\n",
      "[155, 360] loss: 0.030\n",
      "Epoch: 155 -> Loss: 0.00882679410279\n",
      "Epoch: 155 -> Test Accuracy: 91.7675\n",
      "[156, 60] loss: 0.027\n",
      "[156, 120] loss: 0.027\n",
      "[156, 180] loss: 0.029\n",
      "[156, 240] loss: 0.025\n",
      "[156, 300] loss: 0.032\n",
      "[156, 360] loss: 0.033\n",
      "Epoch: 156 -> Loss: 0.0525775365531\n",
      "Epoch: 156 -> Test Accuracy: 91.21\n",
      "[157, 60] loss: 0.027\n",
      "[157, 120] loss: 0.026\n",
      "[157, 180] loss: 0.030\n",
      "[157, 240] loss: 0.030\n",
      "[157, 300] loss: 0.027\n",
      "[157, 360] loss: 0.029\n",
      "Epoch: 157 -> Loss: 0.0153251262382\n",
      "Epoch: 157 -> Test Accuracy: 91.3425\n",
      "[158, 60] loss: 0.024\n",
      "[158, 120] loss: 0.027\n",
      "[158, 180] loss: 0.027\n",
      "[158, 240] loss: 0.029\n",
      "[158, 300] loss: 0.032\n",
      "[158, 360] loss: 0.030\n",
      "Epoch: 158 -> Loss: 0.0151279149577\n",
      "Epoch: 158 -> Test Accuracy: 91.69\n",
      "[159, 60] loss: 0.024\n",
      "[159, 120] loss: 0.024\n",
      "[159, 180] loss: 0.028\n",
      "[159, 240] loss: 0.029\n",
      "[159, 300] loss: 0.026\n",
      "[159, 360] loss: 0.031\n",
      "Epoch: 159 -> Loss: 0.0288920942694\n",
      "Epoch: 159 -> Test Accuracy: 91.57\n",
      "[160, 60] loss: 0.024\n",
      "[160, 120] loss: 0.027\n",
      "[160, 180] loss: 0.030\n",
      "[160, 240] loss: 0.034\n",
      "[160, 300] loss: 0.030\n",
      "[160, 360] loss: 0.031\n",
      "Epoch: 160 -> Loss: 0.0279274322093\n",
      "Epoch: 160 -> Test Accuracy: 91.2125\n",
      "[161, 60] loss: 0.021\n",
      "[161, 120] loss: 0.019\n",
      "[161, 180] loss: 0.017\n",
      "[161, 240] loss: 0.015\n",
      "[161, 300] loss: 0.015\n",
      "[161, 360] loss: 0.015\n",
      "Epoch: 161 -> Loss: 0.0142570389435\n",
      "Epoch: 161 -> Test Accuracy: 91.925\n",
      "[162, 60] loss: 0.012\n",
      "[162, 120] loss: 0.012\n",
      "[162, 180] loss: 0.013\n",
      "[162, 240] loss: 0.013\n",
      "[162, 300] loss: 0.011\n",
      "[162, 360] loss: 0.013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 162 -> Loss: 0.0203562006354\n",
      "Epoch: 162 -> Test Accuracy: 92.095\n",
      "[163, 60] loss: 0.012\n",
      "[163, 120] loss: 0.010\n",
      "[163, 180] loss: 0.010\n",
      "[163, 240] loss: 0.011\n",
      "[163, 300] loss: 0.010\n",
      "[163, 360] loss: 0.012\n",
      "Epoch: 163 -> Loss: 0.0027140781749\n",
      "Epoch: 163 -> Test Accuracy: 92.1275\n",
      "[164, 60] loss: 0.009\n",
      "[164, 120] loss: 0.009\n",
      "[164, 180] loss: 0.012\n",
      "[164, 240] loss: 0.009\n",
      "[164, 300] loss: 0.009\n",
      "[164, 360] loss: 0.010\n",
      "Epoch: 164 -> Loss: 0.00260318745859\n",
      "Epoch: 164 -> Test Accuracy: 92.12\n",
      "[165, 60] loss: 0.009\n",
      "[165, 120] loss: 0.009\n",
      "[165, 180] loss: 0.009\n",
      "[165, 240] loss: 0.009\n",
      "[165, 300] loss: 0.008\n",
      "[165, 360] loss: 0.010\n",
      "Epoch: 165 -> Loss: 0.00682274857536\n",
      "Epoch: 165 -> Test Accuracy: 92.11\n",
      "[166, 60] loss: 0.009\n",
      "[166, 120] loss: 0.008\n",
      "[166, 180] loss: 0.009\n",
      "[166, 240] loss: 0.009\n",
      "[166, 300] loss: 0.007\n",
      "[166, 360] loss: 0.010\n",
      "Epoch: 166 -> Loss: 0.00325839081779\n",
      "Epoch: 166 -> Test Accuracy: 92.1675\n",
      "[167, 60] loss: 0.009\n",
      "[167, 120] loss: 0.007\n",
      "[167, 180] loss: 0.007\n",
      "[167, 240] loss: 0.007\n",
      "[167, 300] loss: 0.008\n",
      "[167, 360] loss: 0.008\n",
      "Epoch: 167 -> Loss: 0.00573956593871\n",
      "Epoch: 167 -> Test Accuracy: 92.19\n",
      "[168, 60] loss: 0.007\n",
      "[168, 120] loss: 0.008\n",
      "[168, 180] loss: 0.007\n",
      "[168, 240] loss: 0.009\n",
      "[168, 300] loss: 0.008\n",
      "[168, 360] loss: 0.007\n",
      "Epoch: 168 -> Loss: 0.00942800659686\n",
      "Epoch: 168 -> Test Accuracy: 92.15\n",
      "[169, 60] loss: 0.007\n",
      "[169, 120] loss: 0.008\n",
      "[169, 180] loss: 0.008\n",
      "[169, 240] loss: 0.007\n",
      "[169, 300] loss: 0.007\n",
      "[169, 360] loss: 0.006\n",
      "Epoch: 169 -> Loss: 0.0164706707001\n",
      "Epoch: 169 -> Test Accuracy: 92.11\n",
      "[170, 60] loss: 0.007\n",
      "[170, 120] loss: 0.008\n",
      "[170, 180] loss: 0.007\n",
      "[170, 240] loss: 0.006\n",
      "[170, 300] loss: 0.007\n",
      "[170, 360] loss: 0.007\n",
      "Epoch: 170 -> Loss: 0.00253883446567\n",
      "Epoch: 170 -> Test Accuracy: 92.1125\n",
      "[171, 60] loss: 0.006\n",
      "[171, 120] loss: 0.005\n",
      "[171, 180] loss: 0.007\n",
      "[171, 240] loss: 0.007\n",
      "[171, 300] loss: 0.007\n",
      "[171, 360] loss: 0.007\n",
      "Epoch: 171 -> Loss: 0.0145443994552\n",
      "Epoch: 171 -> Test Accuracy: 92.25\n",
      "[172, 60] loss: 0.007\n",
      "[172, 120] loss: 0.007\n",
      "[172, 180] loss: 0.006\n",
      "[172, 240] loss: 0.006\n",
      "[172, 300] loss: 0.007\n",
      "[172, 360] loss: 0.006\n",
      "Epoch: 172 -> Loss: 0.00540729239583\n",
      "Epoch: 172 -> Test Accuracy: 92.075\n",
      "[173, 60] loss: 0.007\n",
      "[173, 120] loss: 0.006\n",
      "[173, 180] loss: 0.006\n",
      "[173, 240] loss: 0.006\n",
      "[173, 300] loss: 0.006\n",
      "[173, 360] loss: 0.007\n",
      "Epoch: 173 -> Loss: 0.00267573446035\n",
      "Epoch: 173 -> Test Accuracy: 92.125\n",
      "[174, 60] loss: 0.007\n",
      "[174, 120] loss: 0.006\n",
      "[174, 180] loss: 0.006\n",
      "[174, 240] loss: 0.006\n",
      "[174, 300] loss: 0.006\n",
      "[174, 360] loss: 0.007\n",
      "Epoch: 174 -> Loss: 0.0180952567607\n",
      "Epoch: 174 -> Test Accuracy: 92.0625\n",
      "[175, 60] loss: 0.006\n",
      "[175, 120] loss: 0.006\n",
      "[175, 180] loss: 0.006\n",
      "[175, 240] loss: 0.006\n",
      "[175, 300] loss: 0.006\n",
      "[175, 360] loss: 0.006\n",
      "Epoch: 175 -> Loss: 0.0025624029804\n",
      "Epoch: 175 -> Test Accuracy: 92.1725\n",
      "[176, 60] loss: 0.006\n",
      "[176, 120] loss: 0.005\n",
      "[176, 180] loss: 0.006\n",
      "[176, 240] loss: 0.005\n",
      "[176, 300] loss: 0.006\n",
      "[176, 360] loss: 0.006\n",
      "Epoch: 176 -> Loss: 0.00418569892645\n",
      "Epoch: 176 -> Test Accuracy: 92.105\n",
      "[177, 60] loss: 0.005\n",
      "[177, 120] loss: 0.006\n",
      "[177, 180] loss: 0.005\n",
      "[177, 240] loss: 0.006\n",
      "[177, 300] loss: 0.006\n",
      "[177, 360] loss: 0.006\n",
      "Epoch: 177 -> Loss: 0.00610925536603\n",
      "Epoch: 177 -> Test Accuracy: 92.1875\n",
      "[178, 60] loss: 0.005\n",
      "[178, 120] loss: 0.006\n",
      "[178, 180] loss: 0.006\n",
      "[178, 240] loss: 0.006\n",
      "[178, 300] loss: 0.006\n",
      "[178, 360] loss: 0.006\n",
      "Epoch: 178 -> Loss: 0.00253976648673\n",
      "Epoch: 178 -> Test Accuracy: 92.12\n",
      "[179, 60] loss: 0.005\n",
      "[179, 120] loss: 0.005\n",
      "[179, 180] loss: 0.005\n",
      "[179, 240] loss: 0.005\n",
      "[179, 300] loss: 0.004\n",
      "[179, 360] loss: 0.006\n",
      "Epoch: 179 -> Loss: 0.00596762588248\n",
      "Epoch: 179 -> Test Accuracy: 92.1775\n",
      "[180, 60] loss: 0.006\n",
      "[180, 120] loss: 0.006\n",
      "[180, 180] loss: 0.006\n",
      "[180, 240] loss: 0.005\n",
      "[180, 300] loss: 0.006\n",
      "[180, 360] loss: 0.005\n",
      "Epoch: 180 -> Loss: 0.00357889314182\n",
      "Epoch: 180 -> Test Accuracy: 92.07\n",
      "[181, 60] loss: 0.005\n",
      "[181, 120] loss: 0.006\n",
      "[181, 180] loss: 0.006\n",
      "[181, 240] loss: 0.006\n",
      "[181, 300] loss: 0.005\n",
      "[181, 360] loss: 0.005\n",
      "Epoch: 181 -> Loss: 0.00358352810144\n",
      "Epoch: 181 -> Test Accuracy: 92.04\n",
      "[182, 60] loss: 0.005\n",
      "[182, 120] loss: 0.005\n",
      "[182, 180] loss: 0.006\n",
      "[182, 240] loss: 0.006\n",
      "[182, 300] loss: 0.006\n",
      "[182, 360] loss: 0.005\n",
      "Epoch: 182 -> Loss: 0.00769708212465\n",
      "Epoch: 182 -> Test Accuracy: 92.12\n",
      "[183, 60] loss: 0.005\n",
      "[183, 120] loss: 0.005\n",
      "[183, 180] loss: 0.005\n",
      "[183, 240] loss: 0.005\n",
      "[183, 300] loss: 0.005\n",
      "[183, 360] loss: 0.006\n",
      "Epoch: 183 -> Loss: 0.00608270475641\n",
      "Epoch: 183 -> Test Accuracy: 92.0275\n",
      "[184, 60] loss: 0.005\n",
      "[184, 120] loss: 0.005\n",
      "[184, 180] loss: 0.005\n",
      "[184, 240] loss: 0.005\n",
      "[184, 300] loss: 0.005\n",
      "[184, 360] loss: 0.004\n",
      "Epoch: 184 -> Loss: 0.00909864716232\n",
      "Epoch: 184 -> Test Accuracy: 92.04\n",
      "[185, 60] loss: 0.005\n",
      "[185, 120] loss: 0.005\n",
      "[185, 180] loss: 0.004\n",
      "[185, 240] loss: 0.005\n",
      "[185, 300] loss: 0.005\n",
      "[185, 360] loss: 0.006\n",
      "Epoch: 185 -> Loss: 0.0100166443735\n",
      "Epoch: 185 -> Test Accuracy: 92.14\n",
      "[186, 60] loss: 0.005\n",
      "[186, 120] loss: 0.004\n",
      "[186, 180] loss: 0.004\n",
      "[186, 240] loss: 0.004\n",
      "[186, 300] loss: 0.005\n",
      "[186, 360] loss: 0.004\n",
      "Epoch: 186 -> Loss: 0.00254052202217\n",
      "Epoch: 186 -> Test Accuracy: 92.055\n",
      "[187, 60] loss: 0.005\n",
      "[187, 120] loss: 0.005\n",
      "[187, 180] loss: 0.004\n",
      "[187, 240] loss: 0.005\n",
      "[187, 300] loss: 0.005\n",
      "[187, 360] loss: 0.005\n",
      "Epoch: 187 -> Loss: 0.0117574324831\n",
      "Epoch: 187 -> Test Accuracy: 92.21\n",
      "[188, 60] loss: 0.004\n",
      "[188, 120] loss: 0.004\n",
      "[188, 180] loss: 0.004\n",
      "[188, 240] loss: 0.005\n",
      "[188, 300] loss: 0.004\n",
      "[188, 360] loss: 0.005\n",
      "Epoch: 188 -> Loss: 0.0145831378177\n",
      "Epoch: 188 -> Test Accuracy: 92.165\n",
      "[189, 60] loss: 0.004\n",
      "[189, 120] loss: 0.004\n",
      "[189, 180] loss: 0.005\n",
      "[189, 240] loss: 0.004\n",
      "[189, 300] loss: 0.005\n",
      "[189, 360] loss: 0.005\n",
      "Epoch: 189 -> Loss: 0.0075488910079\n",
      "Epoch: 189 -> Test Accuracy: 92.175\n",
      "[190, 60] loss: 0.004\n",
      "[190, 120] loss: 0.004\n",
      "[190, 180] loss: 0.005\n",
      "[190, 240] loss: 0.005\n",
      "[190, 300] loss: 0.005\n",
      "[190, 360] loss: 0.005\n",
      "Epoch: 190 -> Loss: 0.00440950226039\n",
      "Epoch: 190 -> Test Accuracy: 92.145\n",
      "[191, 60] loss: 0.004\n",
      "[191, 120] loss: 0.005\n",
      "[191, 180] loss: 0.004\n",
      "[191, 240] loss: 0.004\n",
      "[191, 300] loss: 0.004\n",
      "[191, 360] loss: 0.004\n",
      "Epoch: 191 -> Loss: 0.00400735344738\n",
      "Epoch: 191 -> Test Accuracy: 92.1425\n",
      "[192, 60] loss: 0.004\n",
      "[192, 120] loss: 0.004\n",
      "[192, 180] loss: 0.004\n",
      "[192, 240] loss: 0.004\n",
      "[192, 300] loss: 0.004\n",
      "[192, 360] loss: 0.004\n",
      "Epoch: 192 -> Loss: 0.00373878027312\n",
      "Epoch: 192 -> Test Accuracy: 92.1375\n",
      "[193, 60] loss: 0.005\n",
      "[193, 120] loss: 0.005\n",
      "[193, 180] loss: 0.003\n",
      "[193, 240] loss: 0.005\n",
      "[193, 300] loss: 0.005\n",
      "[193, 360] loss: 0.004\n",
      "Epoch: 193 -> Loss: 0.00563342729583\n",
      "Epoch: 193 -> Test Accuracy: 92.0925\n",
      "[194, 60] loss: 0.003\n",
      "[194, 120] loss: 0.004\n",
      "[194, 180] loss: 0.004\n",
      "[194, 240] loss: 0.004\n",
      "[194, 300] loss: 0.005\n",
      "[194, 360] loss: 0.005\n",
      "Epoch: 194 -> Loss: 0.00618495140225\n",
      "Epoch: 194 -> Test Accuracy: 92.15\n",
      "[195, 60] loss: 0.003\n",
      "[195, 120] loss: 0.004\n",
      "[195, 180] loss: 0.004\n",
      "[195, 240] loss: 0.004\n",
      "[195, 300] loss: 0.004\n",
      "[195, 360] loss: 0.005\n",
      "Epoch: 195 -> Loss: 0.010261176154\n",
      "Epoch: 195 -> Test Accuracy: 92.13\n",
      "[196, 60] loss: 0.004\n",
      "[196, 120] loss: 0.004\n",
      "[196, 180] loss: 0.004\n",
      "[196, 240] loss: 0.004\n",
      "[196, 300] loss: 0.004\n",
      "[196, 360] loss: 0.004\n",
      "Epoch: 196 -> Loss: 0.00834834761918\n",
      "Epoch: 196 -> Test Accuracy: 92.075\n",
      "[197, 60] loss: 0.004\n",
      "[197, 120] loss: 0.004\n",
      "[197, 180] loss: 0.004\n",
      "[197, 240] loss: 0.004\n",
      "[197, 300] loss: 0.004\n",
      "[197, 360] loss: 0.004\n",
      "Epoch: 197 -> Loss: 0.00131736847106\n",
      "Epoch: 197 -> Test Accuracy: 92.0975\n",
      "[198, 60] loss: 0.004\n",
      "[198, 120] loss: 0.004\n",
      "[198, 180] loss: 0.004\n",
      "[198, 240] loss: 0.003\n",
      "[198, 300] loss: 0.004\n",
      "[198, 360] loss: 0.004\n",
      "Epoch: 198 -> Loss: 0.00291008199565\n",
      "Epoch: 198 -> Test Accuracy: 92.0725\n",
      "[199, 60] loss: 0.004\n",
      "[199, 120] loss: 0.004\n",
      "[199, 180] loss: 0.004\n",
      "[199, 240] loss: 0.004\n",
      "[199, 300] loss: 0.004\n",
      "[199, 360] loss: 0.004\n",
      "Epoch: 199 -> Loss: 0.00275315786712\n",
      "Epoch: 199 -> Test Accuracy: 92.0275\n",
      "[200, 60] loss: 0.004\n",
      "[200, 120] loss: 0.004\n",
      "[200, 180] loss: 0.004\n",
      "[200, 240] loss: 0.004\n",
      "[200, 300] loss: 0.004\n",
      "[200, 360] loss: 0.005\n",
      "Epoch: 200 -> Loss: 0.00229547172785\n",
      "Epoch: 200 -> Test Accuracy: 92.0875\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "rot_block5_loss_log, _, rot_block5_test_accuracy_log, _, _ = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], \n",
    "    [60, 120, 160, 200], 0.9, 5e-4, net_block5, criterion, trainloader, None, testloader, rot=['90', '180', '270'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 2.203\n",
      "[1, 120] loss: 1.267\n",
      "[1, 180] loss: 1.140\n",
      "[1, 240] loss: 1.080\n",
      "[1, 300] loss: 1.048\n",
      "[1, 360] loss: 0.999\n",
      "Epoch: 1 -> Loss: 0.934138476849\n",
      "Epoch: 1 -> Test Accuracy: 67.18\n",
      "[2, 60] loss: 0.946\n",
      "[2, 120] loss: 0.918\n",
      "[2, 180] loss: 0.906\n",
      "[2, 240] loss: 0.909\n",
      "[2, 300] loss: 0.889\n",
      "[2, 360] loss: 0.874\n",
      "Epoch: 2 -> Loss: 0.738484025002\n",
      "Epoch: 2 -> Test Accuracy: 70.94\n",
      "[3, 60] loss: 0.828\n",
      "[3, 120] loss: 0.838\n",
      "[3, 180] loss: 0.823\n",
      "[3, 240] loss: 0.814\n",
      "[3, 300] loss: 0.801\n",
      "[3, 360] loss: 0.804\n",
      "Epoch: 3 -> Loss: 0.982511878014\n",
      "Epoch: 3 -> Test Accuracy: 72.24\n",
      "[4, 60] loss: 0.790\n",
      "[4, 120] loss: 0.764\n",
      "[4, 180] loss: 0.790\n",
      "[4, 240] loss: 0.771\n",
      "[4, 300] loss: 0.746\n",
      "[4, 360] loss: 0.756\n",
      "Epoch: 4 -> Loss: 0.804670989513\n",
      "Epoch: 4 -> Test Accuracy: 73.25\n",
      "[5, 60] loss: 0.745\n",
      "[5, 120] loss: 0.733\n",
      "[5, 180] loss: 0.741\n",
      "[5, 240] loss: 0.734\n",
      "[5, 300] loss: 0.732\n",
      "[5, 360] loss: 0.716\n",
      "Epoch: 5 -> Loss: 0.571606516838\n",
      "Epoch: 5 -> Test Accuracy: 75.17\n",
      "[6, 60] loss: 0.707\n",
      "[6, 120] loss: 0.707\n",
      "[6, 180] loss: 0.718\n",
      "[6, 240] loss: 0.722\n",
      "[6, 300] loss: 0.704\n",
      "[6, 360] loss: 0.714\n",
      "Epoch: 6 -> Loss: 0.661566793919\n",
      "Epoch: 6 -> Test Accuracy: 76.47\n",
      "[7, 60] loss: 0.680\n",
      "[7, 120] loss: 0.700\n",
      "[7, 180] loss: 0.692\n",
      "[7, 240] loss: 0.686\n",
      "[7, 300] loss: 0.689\n",
      "[7, 360] loss: 0.687\n",
      "Epoch: 7 -> Loss: 0.807422816753\n",
      "Epoch: 7 -> Test Accuracy: 75.79\n",
      "[8, 60] loss: 0.666\n",
      "[8, 120] loss: 0.670\n",
      "[8, 180] loss: 0.672\n",
      "[8, 240] loss: 0.673\n",
      "[8, 300] loss: 0.670\n",
      "[8, 360] loss: 0.674\n",
      "Epoch: 8 -> Loss: 0.754280626774\n",
      "Epoch: 8 -> Test Accuracy: 76.09\n",
      "[9, 60] loss: 0.663\n",
      "[9, 120] loss: 0.654\n",
      "[9, 180] loss: 0.677\n",
      "[9, 240] loss: 0.659\n",
      "[9, 300] loss: 0.669\n",
      "[9, 360] loss: 0.657\n",
      "Epoch: 9 -> Loss: 1.07830035686\n",
      "Epoch: 9 -> Test Accuracy: 76.77\n",
      "[10, 60] loss: 0.642\n",
      "[10, 120] loss: 0.663\n",
      "[10, 180] loss: 0.645\n",
      "[10, 240] loss: 0.667\n",
      "[10, 300] loss: 0.655\n",
      "[10, 360] loss: 0.647\n",
      "Epoch: 10 -> Loss: 0.630775332451\n",
      "Epoch: 10 -> Test Accuracy: 77.33\n",
      "[11, 60] loss: 0.660\n",
      "[11, 120] loss: 0.626\n",
      "[11, 180] loss: 0.652\n",
      "[11, 240] loss: 0.643\n",
      "[11, 300] loss: 0.674\n",
      "[11, 360] loss: 0.633\n",
      "Epoch: 11 -> Loss: 0.747834086418\n",
      "Epoch: 11 -> Test Accuracy: 77.84\n",
      "[12, 60] loss: 0.612\n",
      "[12, 120] loss: 0.621\n",
      "[12, 180] loss: 0.632\n",
      "[12, 240] loss: 0.647\n",
      "[12, 300] loss: 0.639\n",
      "[12, 360] loss: 0.644\n",
      "Epoch: 12 -> Loss: 0.624695539474\n",
      "Epoch: 12 -> Test Accuracy: 77.48\n",
      "[13, 60] loss: 0.608\n",
      "[13, 120] loss: 0.607\n",
      "[13, 180] loss: 0.634\n",
      "[13, 240] loss: 0.640\n",
      "[13, 300] loss: 0.640\n",
      "[13, 360] loss: 0.660\n",
      "Epoch: 13 -> Loss: 0.632779598236\n",
      "Epoch: 13 -> Test Accuracy: 77.51\n",
      "[14, 60] loss: 0.603\n",
      "[14, 120] loss: 0.594\n",
      "[14, 180] loss: 0.624\n",
      "[14, 240] loss: 0.664\n",
      "[14, 300] loss: 0.644\n",
      "[14, 360] loss: 0.635\n",
      "Epoch: 14 -> Loss: 0.696481585503\n",
      "Epoch: 14 -> Test Accuracy: 77.63\n",
      "[15, 60] loss: 0.616\n",
      "[15, 120] loss: 0.632\n",
      "[15, 180] loss: 0.626\n",
      "[15, 240] loss: 0.644\n",
      "[15, 300] loss: 0.610\n",
      "[15, 360] loss: 0.628\n",
      "Epoch: 15 -> Loss: 0.574533641338\n",
      "Epoch: 15 -> Test Accuracy: 77.39\n",
      "[16, 60] loss: 0.613\n",
      "[16, 120] loss: 0.609\n",
      "[16, 180] loss: 0.611\n",
      "[16, 240] loss: 0.633\n",
      "[16, 300] loss: 0.651\n",
      "[16, 360] loss: 0.611\n",
      "Epoch: 16 -> Loss: 0.762658774853\n",
      "Epoch: 16 -> Test Accuracy: 77.3\n",
      "[17, 60] loss: 0.616\n",
      "[17, 120] loss: 0.615\n",
      "[17, 180] loss: 0.618\n",
      "[17, 240] loss: 0.623\n",
      "[17, 300] loss: 0.618\n",
      "[17, 360] loss: 0.617\n",
      "Epoch: 17 -> Loss: 0.805720448494\n",
      "Epoch: 17 -> Test Accuracy: 77.95\n",
      "[18, 60] loss: 0.601\n",
      "[18, 120] loss: 0.609\n",
      "[18, 180] loss: 0.613\n",
      "[18, 240] loss: 0.626\n",
      "[18, 300] loss: 0.628\n",
      "[18, 360] loss: 0.628\n",
      "Epoch: 18 -> Loss: 0.525689005852\n",
      "Epoch: 18 -> Test Accuracy: 78.34\n",
      "[19, 60] loss: 0.596\n",
      "[19, 120] loss: 0.617\n",
      "[19, 180] loss: 0.585\n",
      "[19, 240] loss: 0.614\n",
      "[19, 300] loss: 0.620\n",
      "[19, 360] loss: 0.625\n",
      "Epoch: 19 -> Loss: 0.638005912304\n",
      "Epoch: 19 -> Test Accuracy: 78.37\n",
      "[20, 60] loss: 0.589\n",
      "[20, 120] loss: 0.598\n",
      "[20, 180] loss: 0.595\n",
      "[20, 240] loss: 0.619\n",
      "[20, 300] loss: 0.631\n",
      "[20, 360] loss: 0.619\n",
      "Epoch: 20 -> Loss: 0.580710947514\n",
      "Epoch: 20 -> Test Accuracy: 78.96\n",
      "[21, 60] loss: 0.549\n",
      "[21, 120] loss: 0.515\n",
      "[21, 180] loss: 0.511\n",
      "[21, 240] loss: 0.503\n",
      "[21, 300] loss: 0.513\n",
      "[21, 360] loss: 0.497\n",
      "Epoch: 21 -> Loss: 0.361059010029\n",
      "Epoch: 21 -> Test Accuracy: 80.57\n",
      "[22, 60] loss: 0.476\n",
      "[22, 120] loss: 0.499\n",
      "[22, 180] loss: 0.489\n",
      "[22, 240] loss: 0.456\n",
      "[22, 300] loss: 0.472\n",
      "[22, 360] loss: 0.468\n",
      "Epoch: 22 -> Loss: 0.598335027695\n",
      "Epoch: 22 -> Test Accuracy: 81.21\n",
      "[23, 60] loss: 0.453\n",
      "[23, 120] loss: 0.474\n",
      "[23, 180] loss: 0.455\n",
      "[23, 240] loss: 0.471\n",
      "[23, 300] loss: 0.456\n",
      "[23, 360] loss: 0.460\n",
      "Epoch: 23 -> Loss: 0.249007463455\n",
      "Epoch: 23 -> Test Accuracy: 81.43\n",
      "[24, 60] loss: 0.426\n",
      "[24, 120] loss: 0.467\n",
      "[24, 180] loss: 0.454\n",
      "[24, 240] loss: 0.437\n",
      "[24, 300] loss: 0.448\n",
      "[24, 360] loss: 0.440\n",
      "Epoch: 24 -> Loss: 0.579602837563\n",
      "Epoch: 24 -> Test Accuracy: 81.6\n",
      "[25, 60] loss: 0.429\n",
      "[25, 120] loss: 0.437\n",
      "[25, 180] loss: 0.440\n",
      "[25, 240] loss: 0.456\n",
      "[25, 300] loss: 0.421\n",
      "[25, 360] loss: 0.451\n",
      "Epoch: 25 -> Loss: 0.49041634798\n",
      "Epoch: 25 -> Test Accuracy: 81.39\n",
      "[26, 60] loss: 0.427\n",
      "[26, 120] loss: 0.435\n",
      "[26, 180] loss: 0.421\n",
      "[26, 240] loss: 0.437\n",
      "[26, 300] loss: 0.437\n",
      "[26, 360] loss: 0.448\n",
      "Epoch: 26 -> Loss: 0.428549855947\n",
      "Epoch: 26 -> Test Accuracy: 81.52\n",
      "[27, 60] loss: 0.429\n",
      "[27, 120] loss: 0.409\n",
      "[27, 180] loss: 0.422\n",
      "[27, 240] loss: 0.436\n",
      "[27, 300] loss: 0.424\n",
      "[27, 360] loss: 0.429\n",
      "Epoch: 27 -> Loss: 0.469826638699\n",
      "Epoch: 27 -> Test Accuracy: 80.98\n",
      "[28, 60] loss: 0.401\n",
      "[28, 120] loss: 0.419\n",
      "[28, 180] loss: 0.414\n",
      "[28, 240] loss: 0.406\n",
      "[28, 300] loss: 0.434\n",
      "[28, 360] loss: 0.403\n",
      "Epoch: 28 -> Loss: 0.39718401432\n",
      "Epoch: 28 -> Test Accuracy: 81.12\n",
      "[29, 60] loss: 0.401\n",
      "[29, 120] loss: 0.396\n",
      "[29, 180] loss: 0.404\n",
      "[29, 240] loss: 0.411\n",
      "[29, 300] loss: 0.421\n",
      "[29, 360] loss: 0.433\n",
      "Epoch: 29 -> Loss: 0.419315159321\n",
      "Epoch: 29 -> Test Accuracy: 81.61\n",
      "[30, 60] loss: 0.396\n",
      "[30, 120] loss: 0.409\n",
      "[30, 180] loss: 0.407\n",
      "[30, 240] loss: 0.428\n",
      "[30, 300] loss: 0.399\n",
      "[30, 360] loss: 0.422\n",
      "Epoch: 30 -> Loss: 0.338633000851\n",
      "Epoch: 30 -> Test Accuracy: 81.27\n",
      "[31, 60] loss: 0.413\n",
      "[31, 120] loss: 0.400\n",
      "[31, 180] loss: 0.427\n",
      "[31, 240] loss: 0.416\n",
      "[31, 300] loss: 0.405\n",
      "[31, 360] loss: 0.416\n",
      "Epoch: 31 -> Loss: 0.442918926477\n",
      "Epoch: 31 -> Test Accuracy: 81.89\n",
      "[32, 60] loss: 0.394\n",
      "[32, 120] loss: 0.415\n",
      "[32, 180] loss: 0.395\n",
      "[32, 240] loss: 0.414\n",
      "[32, 300] loss: 0.425\n",
      "[32, 360] loss: 0.415\n",
      "Epoch: 32 -> Loss: 0.669987976551\n",
      "Epoch: 32 -> Test Accuracy: 81.33\n",
      "[33, 60] loss: 0.407\n",
      "[33, 120] loss: 0.398\n",
      "[33, 180] loss: 0.391\n",
      "[33, 240] loss: 0.391\n",
      "[33, 300] loss: 0.393\n",
      "[33, 360] loss: 0.421\n",
      "Epoch: 33 -> Loss: 0.419778496027\n",
      "Epoch: 33 -> Test Accuracy: 81.09\n",
      "[34, 60] loss: 0.384\n",
      "[34, 120] loss: 0.398\n",
      "[34, 180] loss: 0.404\n",
      "[34, 240] loss: 0.399\n",
      "[34, 300] loss: 0.428\n",
      "[34, 360] loss: 0.414\n",
      "Epoch: 34 -> Loss: 0.335553556681\n",
      "Epoch: 34 -> Test Accuracy: 81.64\n",
      "[35, 60] loss: 0.384\n",
      "[35, 120] loss: 0.380\n",
      "[35, 180] loss: 0.403\n",
      "[35, 240] loss: 0.387\n",
      "[35, 300] loss: 0.422\n",
      "[35, 360] loss: 0.418\n",
      "Epoch: 35 -> Loss: 0.360492408276\n",
      "Epoch: 35 -> Test Accuracy: 81.43\n",
      "[36, 60] loss: 0.392\n",
      "[36, 120] loss: 0.399\n",
      "[36, 180] loss: 0.390\n",
      "[36, 240] loss: 0.412\n",
      "[36, 300] loss: 0.417\n",
      "[36, 360] loss: 0.408\n",
      "Epoch: 36 -> Loss: 0.499121576548\n",
      "Epoch: 36 -> Test Accuracy: 81.2\n",
      "[37, 60] loss: 0.383\n",
      "[37, 120] loss: 0.398\n",
      "[37, 180] loss: 0.394\n",
      "[37, 240] loss: 0.420\n",
      "[37, 300] loss: 0.410\n",
      "[37, 360] loss: 0.415\n",
      "Epoch: 37 -> Loss: 0.384531915188\n",
      "Epoch: 37 -> Test Accuracy: 81.43\n",
      "[38, 60] loss: 0.402\n",
      "[38, 120] loss: 0.382\n",
      "[38, 180] loss: 0.413\n",
      "[38, 240] loss: 0.396\n",
      "[38, 300] loss: 0.406\n",
      "[38, 360] loss: 0.400\n",
      "Epoch: 38 -> Loss: 0.853610992432\n",
      "Epoch: 38 -> Test Accuracy: 81.77\n",
      "[39, 60] loss: 0.386\n",
      "[39, 120] loss: 0.395\n",
      "[39, 180] loss: 0.397\n",
      "[39, 240] loss: 0.412\n",
      "[39, 300] loss: 0.412\n",
      "[39, 360] loss: 0.384\n",
      "Epoch: 39 -> Loss: 0.249185651541\n",
      "Epoch: 39 -> Test Accuracy: 81.42\n",
      "[40, 60] loss: 0.388\n",
      "[40, 120] loss: 0.392\n",
      "[40, 180] loss: 0.388\n",
      "[40, 240] loss: 0.404\n",
      "[40, 300] loss: 0.401\n",
      "[40, 360] loss: 0.392\n",
      "Epoch: 40 -> Loss: 0.468721061945\n",
      "Epoch: 40 -> Test Accuracy: 81.44\n",
      "[41, 60] loss: 0.386\n",
      "[41, 120] loss: 0.361\n",
      "[41, 180] loss: 0.355\n",
      "[41, 240] loss: 0.350\n",
      "[41, 300] loss: 0.349\n",
      "[41, 360] loss: 0.338\n",
      "Epoch: 41 -> Loss: 0.301237910986\n",
      "Epoch: 41 -> Test Accuracy: 82.7\n",
      "[42, 60] loss: 0.342\n",
      "[42, 120] loss: 0.336\n",
      "[42, 180] loss: 0.326\n",
      "[42, 240] loss: 0.328\n",
      "[42, 300] loss: 0.330\n",
      "[42, 360] loss: 0.325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.318571090698\n",
      "Epoch: 42 -> Test Accuracy: 82.16\n",
      "[43, 60] loss: 0.327\n",
      "[43, 120] loss: 0.311\n",
      "[43, 180] loss: 0.309\n",
      "[43, 240] loss: 0.317\n",
      "[43, 300] loss: 0.322\n",
      "[43, 360] loss: 0.330\n",
      "Epoch: 43 -> Loss: 0.446107953787\n",
      "Epoch: 43 -> Test Accuracy: 82.4\n",
      "[44, 60] loss: 0.313\n",
      "[44, 120] loss: 0.319\n",
      "[44, 180] loss: 0.314\n",
      "[44, 240] loss: 0.322\n",
      "[44, 300] loss: 0.300\n",
      "[44, 360] loss: 0.313\n",
      "Epoch: 44 -> Loss: 0.303883850574\n",
      "Epoch: 44 -> Test Accuracy: 82.91\n",
      "[45, 60] loss: 0.307\n",
      "[45, 120] loss: 0.305\n",
      "[45, 180] loss: 0.308\n",
      "[45, 240] loss: 0.300\n",
      "[45, 300] loss: 0.307\n",
      "[45, 360] loss: 0.304\n",
      "Epoch: 45 -> Loss: 0.415184259415\n",
      "Epoch: 45 -> Test Accuracy: 82.23\n",
      "[46, 60] loss: 0.297\n",
      "[46, 120] loss: 0.296\n",
      "[46, 180] loss: 0.298\n",
      "[46, 240] loss: 0.286\n",
      "[46, 300] loss: 0.296\n",
      "[46, 360] loss: 0.293\n",
      "Epoch: 46 -> Loss: 0.295275509357\n",
      "Epoch: 46 -> Test Accuracy: 82.62\n",
      "[47, 60] loss: 0.289\n",
      "[47, 120] loss: 0.298\n",
      "[47, 180] loss: 0.286\n",
      "[47, 240] loss: 0.298\n",
      "[47, 300] loss: 0.309\n",
      "[47, 360] loss: 0.287\n",
      "Epoch: 47 -> Loss: 0.454717576504\n",
      "Epoch: 47 -> Test Accuracy: 82.71\n",
      "[48, 60] loss: 0.284\n",
      "[48, 120] loss: 0.284\n",
      "[48, 180] loss: 0.289\n",
      "[48, 240] loss: 0.284\n",
      "[48, 300] loss: 0.304\n",
      "[48, 360] loss: 0.289\n",
      "Epoch: 48 -> Loss: 0.261302322149\n",
      "Epoch: 48 -> Test Accuracy: 82.85\n",
      "[49, 60] loss: 0.297\n",
      "[49, 120] loss: 0.287\n",
      "[49, 180] loss: 0.298\n",
      "[49, 240] loss: 0.277\n",
      "[49, 300] loss: 0.287\n",
      "[49, 360] loss: 0.278\n",
      "Epoch: 49 -> Loss: 0.330753177404\n",
      "Epoch: 49 -> Test Accuracy: 82.86\n",
      "[50, 60] loss: 0.291\n",
      "[50, 120] loss: 0.295\n",
      "[50, 180] loss: 0.288\n",
      "[50, 240] loss: 0.292\n",
      "[50, 300] loss: 0.284\n",
      "[50, 360] loss: 0.283\n",
      "Epoch: 50 -> Loss: 0.319669187069\n",
      "Epoch: 50 -> Test Accuracy: 82.8\n",
      "[51, 60] loss: 0.271\n",
      "[51, 120] loss: 0.285\n",
      "[51, 180] loss: 0.277\n",
      "[51, 240] loss: 0.278\n",
      "[51, 300] loss: 0.284\n",
      "[51, 360] loss: 0.292\n",
      "Epoch: 51 -> Loss: 0.27058494091\n",
      "Epoch: 51 -> Test Accuracy: 82.77\n",
      "[52, 60] loss: 0.293\n",
      "[52, 120] loss: 0.268\n",
      "[52, 180] loss: 0.284\n",
      "[52, 240] loss: 0.286\n",
      "[52, 300] loss: 0.272\n",
      "[52, 360] loss: 0.282\n",
      "Epoch: 52 -> Loss: 0.438805878162\n",
      "Epoch: 52 -> Test Accuracy: 82.89\n",
      "[53, 60] loss: 0.279\n",
      "[53, 120] loss: 0.278\n",
      "[53, 180] loss: 0.284\n",
      "[53, 240] loss: 0.269\n",
      "[53, 300] loss: 0.278\n",
      "[53, 360] loss: 0.284\n",
      "Epoch: 53 -> Loss: 0.349044322968\n",
      "Epoch: 53 -> Test Accuracy: 82.95\n",
      "[54, 60] loss: 0.295\n",
      "[54, 120] loss: 0.282\n",
      "[54, 180] loss: 0.287\n",
      "[54, 240] loss: 0.268\n",
      "[54, 300] loss: 0.278\n",
      "[54, 360] loss: 0.278\n",
      "Epoch: 54 -> Loss: 0.329121053219\n",
      "Epoch: 54 -> Test Accuracy: 82.76\n",
      "[55, 60] loss: 0.261\n",
      "[55, 120] loss: 0.276\n",
      "[55, 180] loss: 0.272\n",
      "[55, 240] loss: 0.285\n",
      "[55, 300] loss: 0.296\n",
      "[55, 360] loss: 0.280\n",
      "Epoch: 55 -> Loss: 0.249124377966\n",
      "Epoch: 55 -> Test Accuracy: 82.95\n",
      "[56, 60] loss: 0.268\n",
      "[56, 120] loss: 0.271\n",
      "[56, 180] loss: 0.276\n",
      "[56, 240] loss: 0.273\n",
      "[56, 300] loss: 0.275\n",
      "[56, 360] loss: 0.287\n",
      "Epoch: 56 -> Loss: 0.393769562244\n",
      "Epoch: 56 -> Test Accuracy: 82.86\n",
      "[57, 60] loss: 0.268\n",
      "[57, 120] loss: 0.282\n",
      "[57, 180] loss: 0.275\n",
      "[57, 240] loss: 0.270\n",
      "[57, 300] loss: 0.280\n",
      "[57, 360] loss: 0.284\n",
      "Epoch: 57 -> Loss: 0.459519147873\n",
      "Epoch: 57 -> Test Accuracy: 82.9\n",
      "[58, 60] loss: 0.273\n",
      "[58, 120] loss: 0.273\n",
      "[58, 180] loss: 0.267\n",
      "[58, 240] loss: 0.265\n",
      "[58, 300] loss: 0.277\n",
      "[58, 360] loss: 0.282\n",
      "Epoch: 58 -> Loss: 0.293583929539\n",
      "Epoch: 58 -> Test Accuracy: 82.97\n",
      "[59, 60] loss: 0.274\n",
      "[59, 120] loss: 0.276\n",
      "[59, 180] loss: 0.280\n",
      "[59, 240] loss: 0.284\n",
      "[59, 300] loss: 0.277\n",
      "[59, 360] loss: 0.267\n",
      "Epoch: 59 -> Loss: 0.393366843462\n",
      "Epoch: 59 -> Test Accuracy: 82.94\n",
      "[60, 60] loss: 0.281\n",
      "[60, 120] loss: 0.279\n",
      "[60, 180] loss: 0.279\n",
      "[60, 240] loss: 0.271\n",
      "[60, 300] loss: 0.263\n",
      "[60, 360] loss: 0.269\n",
      "Epoch: 60 -> Loss: 0.35941940546\n",
      "Epoch: 60 -> Test Accuracy: 82.82\n",
      "[61, 60] loss: 0.264\n",
      "[61, 120] loss: 0.270\n",
      "[61, 180] loss: 0.266\n",
      "[61, 240] loss: 0.268\n",
      "[61, 300] loss: 0.274\n",
      "[61, 360] loss: 0.269\n",
      "Epoch: 61 -> Loss: 0.338788986206\n",
      "Epoch: 61 -> Test Accuracy: 82.87\n",
      "[62, 60] loss: 0.264\n",
      "[62, 120] loss: 0.269\n",
      "[62, 180] loss: 0.265\n",
      "[62, 240] loss: 0.276\n",
      "[62, 300] loss: 0.264\n",
      "[62, 360] loss: 0.279\n",
      "Epoch: 62 -> Loss: 0.230710893869\n",
      "Epoch: 62 -> Test Accuracy: 82.98\n",
      "[63, 60] loss: 0.271\n",
      "[63, 120] loss: 0.265\n",
      "[63, 180] loss: 0.271\n",
      "[63, 240] loss: 0.270\n",
      "[63, 300] loss: 0.271\n",
      "[63, 360] loss: 0.253\n",
      "Epoch: 63 -> Loss: 0.237260907888\n",
      "Epoch: 63 -> Test Accuracy: 83.11\n",
      "[64, 60] loss: 0.268\n",
      "[64, 120] loss: 0.279\n",
      "[64, 180] loss: 0.275\n",
      "[64, 240] loss: 0.264\n",
      "[64, 300] loss: 0.263\n",
      "[64, 360] loss: 0.265\n",
      "Epoch: 64 -> Loss: 0.292119443417\n",
      "Epoch: 64 -> Test Accuracy: 83.05\n",
      "[65, 60] loss: 0.269\n",
      "[65, 120] loss: 0.263\n",
      "[65, 180] loss: 0.271\n",
      "[65, 240] loss: 0.269\n",
      "[65, 300] loss: 0.277\n",
      "[65, 360] loss: 0.275\n",
      "Epoch: 65 -> Loss: 0.175618767738\n",
      "Epoch: 65 -> Test Accuracy: 82.83\n",
      "[66, 60] loss: 0.267\n",
      "[66, 120] loss: 0.265\n",
      "[66, 180] loss: 0.258\n",
      "[66, 240] loss: 0.270\n",
      "[66, 300] loss: 0.268\n",
      "[66, 360] loss: 0.256\n",
      "Epoch: 66 -> Loss: 0.27006906271\n",
      "Epoch: 66 -> Test Accuracy: 82.91\n",
      "[67, 60] loss: 0.268\n",
      "[67, 120] loss: 0.265\n",
      "[67, 180] loss: 0.265\n",
      "[67, 240] loss: 0.267\n",
      "[67, 300] loss: 0.260\n",
      "[67, 360] loss: 0.254\n",
      "Epoch: 67 -> Loss: 0.383474111557\n",
      "Epoch: 67 -> Test Accuracy: 83.04\n",
      "[68, 60] loss: 0.267\n",
      "[68, 120] loss: 0.263\n",
      "[68, 180] loss: 0.268\n",
      "[68, 240] loss: 0.268\n",
      "[68, 300] loss: 0.272\n",
      "[68, 360] loss: 0.260\n",
      "Epoch: 68 -> Loss: 0.261537641287\n",
      "Epoch: 68 -> Test Accuracy: 83.1\n",
      "[69, 60] loss: 0.261\n",
      "[69, 120] loss: 0.268\n",
      "[69, 180] loss: 0.258\n",
      "[69, 240] loss: 0.257\n",
      "[69, 300] loss: 0.257\n",
      "[69, 360] loss: 0.279\n",
      "Epoch: 69 -> Loss: 0.423229306936\n",
      "Epoch: 69 -> Test Accuracy: 83.21\n",
      "[70, 60] loss: 0.254\n",
      "[70, 120] loss: 0.265\n",
      "[70, 180] loss: 0.262\n",
      "[70, 240] loss: 0.261\n",
      "[70, 300] loss: 0.261\n",
      "[70, 360] loss: 0.259\n",
      "Epoch: 70 -> Loss: 0.269256025553\n",
      "Epoch: 70 -> Test Accuracy: 83.02\n",
      "[71, 60] loss: 0.254\n",
      "[71, 120] loss: 0.243\n",
      "[71, 180] loss: 0.267\n",
      "[71, 240] loss: 0.252\n",
      "[71, 300] loss: 0.253\n",
      "[71, 360] loss: 0.266\n",
      "Epoch: 71 -> Loss: 0.295404344797\n",
      "Epoch: 71 -> Test Accuracy: 83.05\n",
      "[72, 60] loss: 0.255\n",
      "[72, 120] loss: 0.255\n",
      "[72, 180] loss: 0.252\n",
      "[72, 240] loss: 0.258\n",
      "[72, 300] loss: 0.268\n",
      "[72, 360] loss: 0.263\n",
      "Epoch: 72 -> Loss: 0.193092316389\n",
      "Epoch: 72 -> Test Accuracy: 82.91\n",
      "[73, 60] loss: 0.277\n",
      "[73, 120] loss: 0.261\n",
      "[73, 180] loss: 0.248\n",
      "[73, 240] loss: 0.261\n",
      "[73, 300] loss: 0.253\n",
      "[73, 360] loss: 0.259\n",
      "Epoch: 73 -> Loss: 0.272996783257\n",
      "Epoch: 73 -> Test Accuracy: 82.98\n",
      "[74, 60] loss: 0.255\n",
      "[74, 120] loss: 0.252\n",
      "[74, 180] loss: 0.246\n",
      "[74, 240] loss: 0.263\n",
      "[74, 300] loss: 0.258\n",
      "[74, 360] loss: 0.256\n",
      "Epoch: 74 -> Loss: 0.213544756174\n",
      "Epoch: 74 -> Test Accuracy: 83.07\n",
      "[75, 60] loss: 0.250\n",
      "[75, 120] loss: 0.255\n",
      "[75, 180] loss: 0.255\n",
      "[75, 240] loss: 0.257\n",
      "[75, 300] loss: 0.259\n",
      "[75, 360] loss: 0.262\n",
      "Epoch: 75 -> Loss: 0.279076695442\n",
      "Epoch: 75 -> Test Accuracy: 83.15\n",
      "[76, 60] loss: 0.257\n",
      "[76, 120] loss: 0.251\n",
      "[76, 180] loss: 0.250\n",
      "[76, 240] loss: 0.261\n",
      "[76, 300] loss: 0.255\n",
      "[76, 360] loss: 0.252\n",
      "Epoch: 76 -> Loss: 0.431295096874\n",
      "Epoch: 76 -> Test Accuracy: 83.09\n",
      "[77, 60] loss: 0.251\n",
      "[77, 120] loss: 0.253\n",
      "[77, 180] loss: 0.248\n",
      "[77, 240] loss: 0.258\n",
      "[77, 300] loss: 0.259\n",
      "[77, 360] loss: 0.258\n",
      "Epoch: 77 -> Loss: 0.431585609913\n",
      "Epoch: 77 -> Test Accuracy: 82.98\n",
      "[78, 60] loss: 0.255\n",
      "[78, 120] loss: 0.270\n",
      "[78, 180] loss: 0.243\n",
      "[78, 240] loss: 0.243\n",
      "[78, 300] loss: 0.247\n",
      "[78, 360] loss: 0.257\n",
      "Epoch: 78 -> Loss: 0.334683716297\n",
      "Epoch: 78 -> Test Accuracy: 83.11\n",
      "[79, 60] loss: 0.258\n",
      "[79, 120] loss: 0.251\n",
      "[79, 180] loss: 0.255\n",
      "[79, 240] loss: 0.256\n",
      "[79, 300] loss: 0.259\n",
      "[79, 360] loss: 0.255\n",
      "Epoch: 79 -> Loss: 0.368666112423\n",
      "Epoch: 79 -> Test Accuracy: 83.1\n",
      "[80, 60] loss: 0.261\n",
      "[80, 120] loss: 0.259\n",
      "[80, 180] loss: 0.242\n",
      "[80, 240] loss: 0.253\n",
      "[80, 300] loss: 0.243\n",
      "[80, 360] loss: 0.250\n",
      "Epoch: 80 -> Loss: 0.173023015261\n",
      "Epoch: 80 -> Test Accuracy: 82.99\n",
      "[81, 60] loss: 0.251\n",
      "[81, 120] loss: 0.261\n",
      "[81, 180] loss: 0.240\n",
      "[81, 240] loss: 0.247\n",
      "[81, 300] loss: 0.252\n",
      "[81, 360] loss: 0.256\n",
      "Epoch: 81 -> Loss: 0.142772838473\n",
      "Epoch: 81 -> Test Accuracy: 83.01\n",
      "[82, 60] loss: 0.241\n",
      "[82, 120] loss: 0.248\n",
      "[82, 180] loss: 0.249\n",
      "[82, 240] loss: 0.261\n",
      "[82, 300] loss: 0.254\n",
      "[82, 360] loss: 0.248\n",
      "Epoch: 82 -> Loss: 0.224539831281\n",
      "Epoch: 82 -> Test Accuracy: 82.94\n",
      "[83, 60] loss: 0.244\n",
      "[83, 120] loss: 0.236\n",
      "[83, 180] loss: 0.240\n",
      "[83, 240] loss: 0.251\n",
      "[83, 300] loss: 0.256\n",
      "[83, 360] loss: 0.246\n",
      "Epoch: 83 -> Loss: 0.285708129406\n",
      "Epoch: 83 -> Test Accuracy: 83.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.251\n",
      "[84, 120] loss: 0.256\n",
      "[84, 180] loss: 0.244\n",
      "[84, 240] loss: 0.251\n",
      "[84, 300] loss: 0.247\n",
      "[84, 360] loss: 0.248\n",
      "Epoch: 84 -> Loss: 0.289580643177\n",
      "Epoch: 84 -> Test Accuracy: 83.07\n",
      "[85, 60] loss: 0.244\n",
      "[85, 120] loss: 0.251\n",
      "[85, 180] loss: 0.248\n",
      "[85, 240] loss: 0.252\n",
      "[85, 300] loss: 0.249\n",
      "[85, 360] loss: 0.251\n",
      "Epoch: 85 -> Loss: 0.266908824444\n",
      "Epoch: 85 -> Test Accuracy: 82.99\n",
      "[86, 60] loss: 0.240\n",
      "[86, 120] loss: 0.239\n",
      "[86, 180] loss: 0.242\n",
      "[86, 240] loss: 0.258\n",
      "[86, 300] loss: 0.237\n",
      "[86, 360] loss: 0.242\n",
      "Epoch: 86 -> Loss: 0.249841243029\n",
      "Epoch: 86 -> Test Accuracy: 83.05\n",
      "[87, 60] loss: 0.262\n",
      "[87, 120] loss: 0.243\n",
      "[87, 180] loss: 0.245\n",
      "[87, 240] loss: 0.242\n",
      "[87, 300] loss: 0.247\n",
      "[87, 360] loss: 0.250\n",
      "Epoch: 87 -> Loss: 0.377417176962\n",
      "Epoch: 87 -> Test Accuracy: 83.1\n",
      "[88, 60] loss: 0.237\n",
      "[88, 120] loss: 0.249\n",
      "[88, 180] loss: 0.253\n",
      "[88, 240] loss: 0.252\n",
      "[88, 300] loss: 0.236\n",
      "[88, 360] loss: 0.251\n",
      "Epoch: 88 -> Loss: 0.178559452295\n",
      "Epoch: 88 -> Test Accuracy: 82.99\n",
      "[89, 60] loss: 0.248\n",
      "[89, 120] loss: 0.248\n",
      "[89, 180] loss: 0.237\n",
      "[89, 240] loss: 0.244\n",
      "[89, 300] loss: 0.245\n",
      "[89, 360] loss: 0.235\n",
      "Epoch: 89 -> Loss: 0.394643485546\n",
      "Epoch: 89 -> Test Accuracy: 83.06\n",
      "[90, 60] loss: 0.240\n",
      "[90, 120] loss: 0.244\n",
      "[90, 180] loss: 0.240\n",
      "[90, 240] loss: 0.253\n",
      "[90, 300] loss: 0.253\n",
      "[90, 360] loss: 0.231\n",
      "Epoch: 90 -> Loss: 0.217695787549\n",
      "Epoch: 90 -> Test Accuracy: 83.11\n",
      "[91, 60] loss: 0.235\n",
      "[91, 120] loss: 0.242\n",
      "[91, 180] loss: 0.247\n",
      "[91, 240] loss: 0.237\n",
      "[91, 300] loss: 0.249\n",
      "[91, 360] loss: 0.241\n",
      "Epoch: 91 -> Loss: 0.198085188866\n",
      "Epoch: 91 -> Test Accuracy: 82.86\n",
      "[92, 60] loss: 0.229\n",
      "[92, 120] loss: 0.245\n",
      "[92, 180] loss: 0.231\n",
      "[92, 240] loss: 0.253\n",
      "[92, 300] loss: 0.239\n",
      "[92, 360] loss: 0.254\n",
      "Epoch: 92 -> Loss: 0.200795456767\n",
      "Epoch: 92 -> Test Accuracy: 82.94\n",
      "[93, 60] loss: 0.234\n",
      "[93, 120] loss: 0.243\n",
      "[93, 180] loss: 0.233\n",
      "[93, 240] loss: 0.241\n",
      "[93, 300] loss: 0.238\n",
      "[93, 360] loss: 0.242\n",
      "Epoch: 93 -> Loss: 0.275528669357\n",
      "Epoch: 93 -> Test Accuracy: 82.91\n",
      "[94, 60] loss: 0.232\n",
      "[94, 120] loss: 0.233\n",
      "[94, 180] loss: 0.247\n",
      "[94, 240] loss: 0.237\n",
      "[94, 300] loss: 0.246\n",
      "[94, 360] loss: 0.230\n",
      "Epoch: 94 -> Loss: 0.18770340085\n",
      "Epoch: 94 -> Test Accuracy: 82.87\n",
      "[95, 60] loss: 0.240\n",
      "[95, 120] loss: 0.235\n",
      "[95, 180] loss: 0.238\n",
      "[95, 240] loss: 0.245\n",
      "[95, 300] loss: 0.229\n",
      "[95, 360] loss: 0.234\n",
      "Epoch: 95 -> Loss: 0.22963257134\n",
      "Epoch: 95 -> Test Accuracy: 82.8\n",
      "[96, 60] loss: 0.230\n",
      "[96, 120] loss: 0.236\n",
      "[96, 180] loss: 0.235\n",
      "[96, 240] loss: 0.250\n",
      "[96, 300] loss: 0.240\n",
      "[96, 360] loss: 0.238\n",
      "Epoch: 96 -> Loss: 0.301763981581\n",
      "Epoch: 96 -> Test Accuracy: 82.81\n",
      "[97, 60] loss: 0.223\n",
      "[97, 120] loss: 0.242\n",
      "[97, 180] loss: 0.245\n",
      "[97, 240] loss: 0.241\n",
      "[97, 300] loss: 0.219\n",
      "[97, 360] loss: 0.243\n",
      "Epoch: 97 -> Loss: 0.232356950641\n",
      "Epoch: 97 -> Test Accuracy: 83.04\n",
      "[98, 60] loss: 0.234\n",
      "[98, 120] loss: 0.245\n",
      "[98, 180] loss: 0.237\n",
      "[98, 240] loss: 0.231\n",
      "[98, 300] loss: 0.234\n",
      "[98, 360] loss: 0.234\n",
      "Epoch: 98 -> Loss: 0.279518306255\n",
      "Epoch: 98 -> Test Accuracy: 82.84\n",
      "[99, 60] loss: 0.238\n",
      "[99, 120] loss: 0.242\n",
      "[99, 180] loss: 0.244\n",
      "[99, 240] loss: 0.246\n",
      "[99, 300] loss: 0.228\n",
      "[99, 360] loss: 0.227\n",
      "Epoch: 99 -> Loss: 0.185070052743\n",
      "Epoch: 99 -> Test Accuracy: 83.16\n",
      "[100, 60] loss: 0.233\n",
      "[100, 120] loss: 0.232\n",
      "[100, 180] loss: 0.235\n",
      "[100, 240] loss: 0.224\n",
      "[100, 300] loss: 0.247\n",
      "[100, 360] loss: 0.233\n",
      "Epoch: 100 -> Loss: 0.513307988644\n",
      "Epoch: 100 -> Test Accuracy: 82.99\n",
      "Finished Training\n",
      "[1, 60] loss: 1.714\n",
      "[1, 120] loss: 0.846\n",
      "[1, 180] loss: 0.778\n",
      "[1, 240] loss: 0.718\n",
      "[1, 300] loss: 0.683\n",
      "[1, 360] loss: 0.664\n",
      "Epoch: 1 -> Loss: 1.04639101028\n",
      "Epoch: 1 -> Test Accuracy: 77.73\n",
      "[2, 60] loss: 0.595\n",
      "[2, 120] loss: 0.617\n",
      "[2, 180] loss: 0.583\n",
      "[2, 240] loss: 0.561\n",
      "[2, 300] loss: 0.565\n",
      "[2, 360] loss: 0.562\n",
      "Epoch: 2 -> Loss: 0.56279283762\n",
      "Epoch: 2 -> Test Accuracy: 80.38\n",
      "[3, 60] loss: 0.504\n",
      "[3, 120] loss: 0.529\n",
      "[3, 180] loss: 0.526\n",
      "[3, 240] loss: 0.518\n",
      "[3, 300] loss: 0.513\n",
      "[3, 360] loss: 0.511\n",
      "Epoch: 3 -> Loss: 0.43296828866\n",
      "Epoch: 3 -> Test Accuracy: 81.26\n",
      "[4, 60] loss: 0.462\n",
      "[4, 120] loss: 0.496\n",
      "[4, 180] loss: 0.496\n",
      "[4, 240] loss: 0.481\n",
      "[4, 300] loss: 0.484\n",
      "[4, 360] loss: 0.474\n",
      "Epoch: 4 -> Loss: 0.304161906242\n",
      "Epoch: 4 -> Test Accuracy: 81.93\n",
      "[5, 60] loss: 0.456\n",
      "[5, 120] loss: 0.460\n",
      "[5, 180] loss: 0.453\n",
      "[5, 240] loss: 0.454\n",
      "[5, 300] loss: 0.465\n",
      "[5, 360] loss: 0.454\n",
      "Epoch: 5 -> Loss: 0.51943820715\n",
      "Epoch: 5 -> Test Accuracy: 82.57\n",
      "[6, 60] loss: 0.447\n",
      "[6, 120] loss: 0.446\n",
      "[6, 180] loss: 0.437\n",
      "[6, 240] loss: 0.459\n",
      "[6, 300] loss: 0.452\n",
      "[6, 360] loss: 0.449\n",
      "Epoch: 6 -> Loss: 0.583590865135\n",
      "Epoch: 6 -> Test Accuracy: 82.73\n",
      "[7, 60] loss: 0.417\n",
      "[7, 120] loss: 0.443\n",
      "[7, 180] loss: 0.422\n",
      "[7, 240] loss: 0.449\n",
      "[7, 300] loss: 0.424\n",
      "[7, 360] loss: 0.434\n",
      "Epoch: 7 -> Loss: 0.22104716301\n",
      "Epoch: 7 -> Test Accuracy: 82.85\n",
      "[8, 60] loss: 0.416\n",
      "[8, 120] loss: 0.429\n",
      "[8, 180] loss: 0.418\n",
      "[8, 240] loss: 0.429\n",
      "[8, 300] loss: 0.421\n",
      "[8, 360] loss: 0.425\n",
      "Epoch: 8 -> Loss: 0.387065708637\n",
      "Epoch: 8 -> Test Accuracy: 82.75\n",
      "[9, 60] loss: 0.406\n",
      "[9, 120] loss: 0.410\n",
      "[9, 180] loss: 0.417\n",
      "[9, 240] loss: 0.410\n",
      "[9, 300] loss: 0.435\n",
      "[9, 360] loss: 0.417\n",
      "Epoch: 9 -> Loss: 0.392576932907\n",
      "Epoch: 9 -> Test Accuracy: 83.89\n",
      "[10, 60] loss: 0.378\n",
      "[10, 120] loss: 0.408\n",
      "[10, 180] loss: 0.409\n",
      "[10, 240] loss: 0.421\n",
      "[10, 300] loss: 0.410\n",
      "[10, 360] loss: 0.418\n",
      "Epoch: 10 -> Loss: 0.51383292675\n",
      "Epoch: 10 -> Test Accuracy: 83.52\n",
      "[11, 60] loss: 0.390\n",
      "[11, 120] loss: 0.393\n",
      "[11, 180] loss: 0.392\n",
      "[11, 240] loss: 0.406\n",
      "[11, 300] loss: 0.406\n",
      "[11, 360] loss: 0.422\n",
      "Epoch: 11 -> Loss: 0.320388644934\n",
      "Epoch: 11 -> Test Accuracy: 83.01\n",
      "[12, 60] loss: 0.383\n",
      "[12, 120] loss: 0.400\n",
      "[12, 180] loss: 0.403\n",
      "[12, 240] loss: 0.392\n",
      "[12, 300] loss: 0.403\n",
      "[12, 360] loss: 0.416\n",
      "Epoch: 12 -> Loss: 0.452863633633\n",
      "Epoch: 12 -> Test Accuracy: 83.66\n",
      "[13, 60] loss: 0.374\n",
      "[13, 120] loss: 0.376\n",
      "[13, 180] loss: 0.385\n",
      "[13, 240] loss: 0.399\n",
      "[13, 300] loss: 0.400\n",
      "[13, 360] loss: 0.402\n",
      "Epoch: 13 -> Loss: 0.586328148842\n",
      "Epoch: 13 -> Test Accuracy: 84.08\n",
      "[14, 60] loss: 0.380\n",
      "[14, 120] loss: 0.399\n",
      "[14, 180] loss: 0.391\n",
      "[14, 240] loss: 0.382\n",
      "[14, 300] loss: 0.396\n",
      "[14, 360] loss: 0.389\n",
      "Epoch: 14 -> Loss: 0.382238090038\n",
      "Epoch: 14 -> Test Accuracy: 84.06\n",
      "[15, 60] loss: 0.377\n",
      "[15, 120] loss: 0.384\n",
      "[15, 180] loss: 0.377\n",
      "[15, 240] loss: 0.390\n",
      "[15, 300] loss: 0.385\n",
      "[15, 360] loss: 0.407\n",
      "Epoch: 15 -> Loss: 0.21057343483\n",
      "Epoch: 15 -> Test Accuracy: 83.79\n",
      "[16, 60] loss: 0.361\n",
      "[16, 120] loss: 0.363\n",
      "[16, 180] loss: 0.386\n",
      "[16, 240] loss: 0.387\n",
      "[16, 300] loss: 0.378\n",
      "[16, 360] loss: 0.385\n",
      "Epoch: 16 -> Loss: 0.540003716946\n",
      "Epoch: 16 -> Test Accuracy: 84.07\n",
      "[17, 60] loss: 0.360\n",
      "[17, 120] loss: 0.363\n",
      "[17, 180] loss: 0.376\n",
      "[17, 240] loss: 0.386\n",
      "[17, 300] loss: 0.397\n",
      "[17, 360] loss: 0.394\n",
      "Epoch: 17 -> Loss: 0.562584996223\n",
      "Epoch: 17 -> Test Accuracy: 84.17\n",
      "[18, 60] loss: 0.358\n",
      "[18, 120] loss: 0.369\n",
      "[18, 180] loss: 0.366\n",
      "[18, 240] loss: 0.376\n",
      "[18, 300] loss: 0.380\n",
      "[18, 360] loss: 0.396\n",
      "Epoch: 18 -> Loss: 0.363105356693\n",
      "Epoch: 18 -> Test Accuracy: 83.99\n",
      "[19, 60] loss: 0.366\n",
      "[19, 120] loss: 0.369\n",
      "[19, 180] loss: 0.370\n",
      "[19, 240] loss: 0.374\n",
      "[19, 300] loss: 0.391\n",
      "[19, 360] loss: 0.393\n",
      "Epoch: 19 -> Loss: 0.328978687525\n",
      "Epoch: 19 -> Test Accuracy: 83.76\n",
      "[20, 60] loss: 0.355\n",
      "[20, 120] loss: 0.356\n",
      "[20, 180] loss: 0.368\n",
      "[20, 240] loss: 0.372\n",
      "[20, 300] loss: 0.397\n",
      "[20, 360] loss: 0.392\n",
      "Epoch: 20 -> Loss: 0.339789927006\n",
      "Epoch: 20 -> Test Accuracy: 84.01\n",
      "[21, 60] loss: 0.319\n",
      "[21, 120] loss: 0.309\n",
      "[21, 180] loss: 0.298\n",
      "[21, 240] loss: 0.297\n",
      "[21, 300] loss: 0.295\n",
      "[21, 360] loss: 0.282\n",
      "Epoch: 21 -> Loss: 0.364473640919\n",
      "Epoch: 21 -> Test Accuracy: 85.77\n",
      "[22, 60] loss: 0.269\n",
      "[22, 120] loss: 0.262\n",
      "[22, 180] loss: 0.273\n",
      "[22, 240] loss: 0.268\n",
      "[22, 300] loss: 0.266\n",
      "[22, 360] loss: 0.270\n",
      "Epoch: 22 -> Loss: 0.360457837582\n",
      "Epoch: 22 -> Test Accuracy: 85.97\n",
      "[23, 60] loss: 0.243\n",
      "[23, 120] loss: 0.235\n",
      "[23, 180] loss: 0.248\n",
      "[23, 240] loss: 0.244\n",
      "[23, 300] loss: 0.236\n",
      "[23, 360] loss: 0.249\n",
      "Epoch: 23 -> Loss: 0.26738268137\n",
      "Epoch: 23 -> Test Accuracy: 85.7\n",
      "[24, 60] loss: 0.231\n",
      "[24, 120] loss: 0.230\n",
      "[24, 180] loss: 0.239\n",
      "[24, 240] loss: 0.235\n",
      "[24, 300] loss: 0.251\n",
      "[24, 360] loss: 0.252\n",
      "Epoch: 24 -> Loss: 0.265910983086\n",
      "Epoch: 24 -> Test Accuracy: 85.85\n",
      "[25, 60] loss: 0.230\n",
      "[25, 120] loss: 0.214\n",
      "[25, 180] loss: 0.232\n",
      "[25, 240] loss: 0.236\n",
      "[25, 300] loss: 0.226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 360] loss: 0.240\n",
      "Epoch: 25 -> Loss: 0.278952866793\n",
      "Epoch: 25 -> Test Accuracy: 85.61\n",
      "[26, 60] loss: 0.223\n",
      "[26, 120] loss: 0.222\n",
      "[26, 180] loss: 0.216\n",
      "[26, 240] loss: 0.216\n",
      "[26, 300] loss: 0.217\n",
      "[26, 360] loss: 0.222\n",
      "Epoch: 26 -> Loss: 0.139011666179\n",
      "Epoch: 26 -> Test Accuracy: 85.63\n",
      "[27, 60] loss: 0.224\n",
      "[27, 120] loss: 0.208\n",
      "[27, 180] loss: 0.213\n",
      "[27, 240] loss: 0.224\n",
      "[27, 300] loss: 0.228\n",
      "[27, 360] loss: 0.217\n",
      "Epoch: 27 -> Loss: 0.278864204884\n",
      "Epoch: 27 -> Test Accuracy: 85.71\n",
      "[28, 60] loss: 0.206\n",
      "[28, 120] loss: 0.200\n",
      "[28, 180] loss: 0.214\n",
      "[28, 240] loss: 0.214\n",
      "[28, 300] loss: 0.236\n",
      "[28, 360] loss: 0.212\n",
      "Epoch: 28 -> Loss: 0.26783233881\n",
      "Epoch: 28 -> Test Accuracy: 85.67\n",
      "[29, 60] loss: 0.203\n",
      "[29, 120] loss: 0.204\n",
      "[29, 180] loss: 0.202\n",
      "[29, 240] loss: 0.203\n",
      "[29, 300] loss: 0.229\n",
      "[29, 360] loss: 0.218\n",
      "Epoch: 29 -> Loss: 0.166415497661\n",
      "Epoch: 29 -> Test Accuracy: 85.47\n",
      "[30, 60] loss: 0.203\n",
      "[30, 120] loss: 0.201\n",
      "[30, 180] loss: 0.205\n",
      "[30, 240] loss: 0.203\n",
      "[30, 300] loss: 0.209\n",
      "[30, 360] loss: 0.214\n",
      "Epoch: 30 -> Loss: 0.210741370916\n",
      "Epoch: 30 -> Test Accuracy: 85.83\n",
      "[31, 60] loss: 0.197\n",
      "[31, 120] loss: 0.208\n",
      "[31, 180] loss: 0.218\n",
      "[31, 240] loss: 0.203\n",
      "[31, 300] loss: 0.213\n",
      "[31, 360] loss: 0.216\n",
      "Epoch: 31 -> Loss: 0.297113120556\n",
      "Epoch: 31 -> Test Accuracy: 85.57\n",
      "[32, 60] loss: 0.197\n",
      "[32, 120] loss: 0.193\n",
      "[32, 180] loss: 0.199\n",
      "[32, 240] loss: 0.202\n",
      "[32, 300] loss: 0.207\n",
      "[32, 360] loss: 0.215\n",
      "Epoch: 32 -> Loss: 0.125907689333\n",
      "Epoch: 32 -> Test Accuracy: 85.6\n",
      "[33, 60] loss: 0.191\n",
      "[33, 120] loss: 0.195\n",
      "[33, 180] loss: 0.189\n",
      "[33, 240] loss: 0.200\n",
      "[33, 300] loss: 0.212\n",
      "[33, 360] loss: 0.217\n",
      "Epoch: 33 -> Loss: 0.297772824764\n",
      "Epoch: 33 -> Test Accuracy: 85.37\n",
      "[34, 60] loss: 0.187\n",
      "[34, 120] loss: 0.191\n",
      "[34, 180] loss: 0.210\n",
      "[34, 240] loss: 0.208\n",
      "[34, 300] loss: 0.205\n",
      "[34, 360] loss: 0.206\n",
      "Epoch: 34 -> Loss: 0.28152641654\n",
      "Epoch: 34 -> Test Accuracy: 85.84\n",
      "[35, 60] loss: 0.195\n",
      "[35, 120] loss: 0.197\n",
      "[35, 180] loss: 0.203\n",
      "[35, 240] loss: 0.210\n",
      "[35, 300] loss: 0.202\n",
      "[35, 360] loss: 0.203\n",
      "Epoch: 35 -> Loss: 0.152056574821\n",
      "Epoch: 35 -> Test Accuracy: 85.52\n",
      "[36, 60] loss: 0.194\n",
      "[36, 120] loss: 0.190\n",
      "[36, 180] loss: 0.194\n",
      "[36, 240] loss: 0.198\n",
      "[36, 300] loss: 0.198\n",
      "[36, 360] loss: 0.211\n",
      "Epoch: 36 -> Loss: 0.190544500947\n",
      "Epoch: 36 -> Test Accuracy: 85.83\n",
      "[37, 60] loss: 0.192\n",
      "[37, 120] loss: 0.198\n",
      "[37, 180] loss: 0.204\n",
      "[37, 240] loss: 0.198\n",
      "[37, 300] loss: 0.206\n",
      "[37, 360] loss: 0.206\n",
      "Epoch: 37 -> Loss: 0.218623995781\n",
      "Epoch: 37 -> Test Accuracy: 85.07\n",
      "[38, 60] loss: 0.185\n",
      "[38, 120] loss: 0.194\n",
      "[38, 180] loss: 0.208\n",
      "[38, 240] loss: 0.192\n",
      "[38, 300] loss: 0.208\n",
      "[38, 360] loss: 0.203\n",
      "Epoch: 38 -> Loss: 0.194257065654\n",
      "Epoch: 38 -> Test Accuracy: 85.46\n",
      "[39, 60] loss: 0.190\n",
      "[39, 120] loss: 0.189\n",
      "[39, 180] loss: 0.205\n",
      "[39, 240] loss: 0.201\n",
      "[39, 300] loss: 0.203\n",
      "[39, 360] loss: 0.210\n",
      "Epoch: 39 -> Loss: 0.232700198889\n",
      "Epoch: 39 -> Test Accuracy: 85.26\n",
      "[40, 60] loss: 0.188\n",
      "[40, 120] loss: 0.189\n",
      "[40, 180] loss: 0.192\n",
      "[40, 240] loss: 0.199\n",
      "[40, 300] loss: 0.202\n",
      "[40, 360] loss: 0.203\n",
      "Epoch: 40 -> Loss: 0.109252527356\n",
      "Epoch: 40 -> Test Accuracy: 85.39\n",
      "[41, 60] loss: 0.163\n",
      "[41, 120] loss: 0.172\n",
      "[41, 180] loss: 0.172\n",
      "[41, 240] loss: 0.157\n",
      "[41, 300] loss: 0.169\n",
      "[41, 360] loss: 0.164\n",
      "Epoch: 41 -> Loss: 0.205100134015\n",
      "Epoch: 41 -> Test Accuracy: 86.33\n",
      "[42, 60] loss: 0.141\n",
      "[42, 120] loss: 0.146\n",
      "[42, 180] loss: 0.147\n",
      "[42, 240] loss: 0.146\n",
      "[42, 300] loss: 0.151\n",
      "[42, 360] loss: 0.145\n",
      "Epoch: 42 -> Loss: 0.147721216083\n",
      "Epoch: 42 -> Test Accuracy: 86.41\n",
      "[43, 60] loss: 0.143\n",
      "[43, 120] loss: 0.139\n",
      "[43, 180] loss: 0.136\n",
      "[43, 240] loss: 0.141\n",
      "[43, 300] loss: 0.144\n",
      "[43, 360] loss: 0.136\n",
      "Epoch: 43 -> Loss: 0.073365367949\n",
      "Epoch: 43 -> Test Accuracy: 86.33\n",
      "[44, 60] loss: 0.133\n",
      "[44, 120] loss: 0.141\n",
      "[44, 180] loss: 0.124\n",
      "[44, 240] loss: 0.133\n",
      "[44, 300] loss: 0.135\n",
      "[44, 360] loss: 0.138\n",
      "Epoch: 44 -> Loss: 0.0713579654694\n",
      "Epoch: 44 -> Test Accuracy: 86.53\n",
      "[45, 60] loss: 0.121\n",
      "[45, 120] loss: 0.132\n",
      "[45, 180] loss: 0.131\n",
      "[45, 240] loss: 0.120\n",
      "[45, 300] loss: 0.124\n",
      "[45, 360] loss: 0.127\n",
      "Epoch: 45 -> Loss: 0.0891796201468\n",
      "Epoch: 45 -> Test Accuracy: 86.8\n",
      "[46, 60] loss: 0.119\n",
      "[46, 120] loss: 0.130\n",
      "[46, 180] loss: 0.127\n",
      "[46, 240] loss: 0.123\n",
      "[46, 300] loss: 0.119\n",
      "[46, 360] loss: 0.113\n",
      "Epoch: 46 -> Loss: 0.229067713022\n",
      "Epoch: 46 -> Test Accuracy: 86.76\n",
      "[47, 60] loss: 0.115\n",
      "[47, 120] loss: 0.118\n",
      "[47, 180] loss: 0.121\n",
      "[47, 240] loss: 0.112\n",
      "[47, 300] loss: 0.114\n",
      "[47, 360] loss: 0.112\n",
      "Epoch: 47 -> Loss: 0.109820306301\n",
      "Epoch: 47 -> Test Accuracy: 86.77\n",
      "[48, 60] loss: 0.120\n",
      "[48, 120] loss: 0.113\n",
      "[48, 180] loss: 0.115\n",
      "[48, 240] loss: 0.115\n",
      "[48, 300] loss: 0.114\n",
      "[48, 360] loss: 0.115\n",
      "Epoch: 48 -> Loss: 0.159790098667\n",
      "Epoch: 48 -> Test Accuracy: 86.87\n",
      "[49, 60] loss: 0.118\n",
      "[49, 120] loss: 0.114\n",
      "[49, 180] loss: 0.114\n",
      "[49, 240] loss: 0.109\n",
      "[49, 300] loss: 0.121\n",
      "[49, 360] loss: 0.114\n",
      "Epoch: 49 -> Loss: 0.203773930669\n",
      "Epoch: 49 -> Test Accuracy: 86.74\n",
      "[50, 60] loss: 0.112\n",
      "[50, 120] loss: 0.114\n",
      "[50, 180] loss: 0.117\n",
      "[50, 240] loss: 0.117\n",
      "[50, 300] loss: 0.116\n",
      "[50, 360] loss: 0.110\n",
      "Epoch: 50 -> Loss: 0.0489693619311\n",
      "Epoch: 50 -> Test Accuracy: 86.8\n",
      "[51, 60] loss: 0.115\n",
      "[51, 120] loss: 0.105\n",
      "[51, 180] loss: 0.111\n",
      "[51, 240] loss: 0.117\n",
      "[51, 300] loss: 0.121\n",
      "[51, 360] loss: 0.114\n",
      "Epoch: 51 -> Loss: 0.0831125900149\n",
      "Epoch: 51 -> Test Accuracy: 86.88\n",
      "[52, 60] loss: 0.105\n",
      "[52, 120] loss: 0.109\n",
      "[52, 180] loss: 0.108\n",
      "[52, 240] loss: 0.119\n",
      "[52, 300] loss: 0.111\n",
      "[52, 360] loss: 0.114\n",
      "Epoch: 52 -> Loss: 0.0960056334734\n",
      "Epoch: 52 -> Test Accuracy: 86.68\n",
      "[53, 60] loss: 0.114\n",
      "[53, 120] loss: 0.103\n",
      "[53, 180] loss: 0.102\n",
      "[53, 240] loss: 0.113\n",
      "[53, 300] loss: 0.108\n",
      "[53, 360] loss: 0.111\n",
      "Epoch: 53 -> Loss: 0.183796599507\n",
      "Epoch: 53 -> Test Accuracy: 86.66\n",
      "[54, 60] loss: 0.105\n",
      "[54, 120] loss: 0.099\n",
      "[54, 180] loss: 0.118\n",
      "[54, 240] loss: 0.106\n",
      "[54, 300] loss: 0.106\n",
      "[54, 360] loss: 0.116\n",
      "Epoch: 54 -> Loss: 0.137077435851\n",
      "Epoch: 54 -> Test Accuracy: 86.68\n",
      "[55, 60] loss: 0.106\n",
      "[55, 120] loss: 0.101\n",
      "[55, 180] loss: 0.108\n",
      "[55, 240] loss: 0.103\n",
      "[55, 300] loss: 0.111\n",
      "[55, 360] loss: 0.111\n",
      "Epoch: 55 -> Loss: 0.0754505842924\n",
      "Epoch: 55 -> Test Accuracy: 86.81\n",
      "[56, 60] loss: 0.104\n",
      "[56, 120] loss: 0.111\n",
      "[56, 180] loss: 0.105\n",
      "[56, 240] loss: 0.100\n",
      "[56, 300] loss: 0.111\n",
      "[56, 360] loss: 0.105\n",
      "Epoch: 56 -> Loss: 0.0597851760685\n",
      "Epoch: 56 -> Test Accuracy: 86.75\n",
      "[57, 60] loss: 0.102\n",
      "[57, 120] loss: 0.103\n",
      "[57, 180] loss: 0.112\n",
      "[57, 240] loss: 0.106\n",
      "[57, 300] loss: 0.114\n",
      "[57, 360] loss: 0.106\n",
      "Epoch: 57 -> Loss: 0.0392521508038\n",
      "Epoch: 57 -> Test Accuracy: 86.65\n",
      "[58, 60] loss: 0.107\n",
      "[58, 120] loss: 0.101\n",
      "[58, 180] loss: 0.108\n",
      "[58, 240] loss: 0.114\n",
      "[58, 300] loss: 0.104\n",
      "[58, 360] loss: 0.104\n",
      "Epoch: 58 -> Loss: 0.0882904455066\n",
      "Epoch: 58 -> Test Accuracy: 86.59\n",
      "[59, 60] loss: 0.103\n",
      "[59, 120] loss: 0.101\n",
      "[59, 180] loss: 0.112\n",
      "[59, 240] loss: 0.099\n",
      "[59, 300] loss: 0.113\n",
      "[59, 360] loss: 0.095\n",
      "Epoch: 59 -> Loss: 0.11221011728\n",
      "Epoch: 59 -> Test Accuracy: 86.61\n",
      "[60, 60] loss: 0.111\n",
      "[60, 120] loss: 0.097\n",
      "[60, 180] loss: 0.108\n",
      "[60, 240] loss: 0.104\n",
      "[60, 300] loss: 0.107\n",
      "[60, 360] loss: 0.099\n",
      "Epoch: 60 -> Loss: 0.129187971354\n",
      "Epoch: 60 -> Test Accuracy: 86.68\n",
      "[61, 60] loss: 0.100\n",
      "[61, 120] loss: 0.101\n",
      "[61, 180] loss: 0.104\n",
      "[61, 240] loss: 0.104\n",
      "[61, 300] loss: 0.092\n",
      "[61, 360] loss: 0.107\n",
      "Epoch: 61 -> Loss: 0.289845347404\n",
      "Epoch: 61 -> Test Accuracy: 86.59\n",
      "[62, 60] loss: 0.110\n",
      "[62, 120] loss: 0.104\n",
      "[62, 180] loss: 0.096\n",
      "[62, 240] loss: 0.102\n",
      "[62, 300] loss: 0.104\n",
      "[62, 360] loss: 0.097\n",
      "Epoch: 62 -> Loss: 0.0566322728992\n",
      "Epoch: 62 -> Test Accuracy: 86.6\n",
      "[63, 60] loss: 0.095\n",
      "[63, 120] loss: 0.105\n",
      "[63, 180] loss: 0.108\n",
      "[63, 240] loss: 0.103\n",
      "[63, 300] loss: 0.096\n",
      "[63, 360] loss: 0.100\n",
      "Epoch: 63 -> Loss: 0.136897712946\n",
      "Epoch: 63 -> Test Accuracy: 86.79\n",
      "[64, 60] loss: 0.102\n",
      "[64, 120] loss: 0.097\n",
      "[64, 180] loss: 0.092\n",
      "[64, 240] loss: 0.106\n",
      "[64, 300] loss: 0.098\n",
      "[64, 360] loss: 0.097\n",
      "Epoch: 64 -> Loss: 0.0665801391006\n",
      "Epoch: 64 -> Test Accuracy: 86.74\n",
      "[65, 60] loss: 0.098\n",
      "[65, 120] loss: 0.101\n",
      "[65, 180] loss: 0.098\n",
      "[65, 240] loss: 0.093\n",
      "[65, 300] loss: 0.099\n",
      "[65, 360] loss: 0.099\n",
      "Epoch: 65 -> Loss: 0.0706637501717\n",
      "Epoch: 65 -> Test Accuracy: 86.66\n",
      "[66, 60] loss: 0.100\n",
      "[66, 120] loss: 0.099\n",
      "[66, 180] loss: 0.097\n",
      "[66, 240] loss: 0.101\n",
      "[66, 300] loss: 0.097\n",
      "[66, 360] loss: 0.098\n",
      "Epoch: 66 -> Loss: 0.0828182920814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Test Accuracy: 86.68\n",
      "[67, 60] loss: 0.095\n",
      "[67, 120] loss: 0.091\n",
      "[67, 180] loss: 0.098\n",
      "[67, 240] loss: 0.105\n",
      "[67, 300] loss: 0.097\n",
      "[67, 360] loss: 0.102\n",
      "Epoch: 67 -> Loss: 0.224867194891\n",
      "Epoch: 67 -> Test Accuracy: 86.77\n",
      "[68, 60] loss: 0.088\n",
      "[68, 120] loss: 0.095\n",
      "[68, 180] loss: 0.094\n",
      "[68, 240] loss: 0.097\n",
      "[68, 300] loss: 0.099\n",
      "[68, 360] loss: 0.091\n",
      "Epoch: 68 -> Loss: 0.177250146866\n",
      "Epoch: 68 -> Test Accuracy: 86.81\n",
      "[69, 60] loss: 0.092\n",
      "[69, 120] loss: 0.104\n",
      "[69, 180] loss: 0.099\n",
      "[69, 240] loss: 0.097\n",
      "[69, 300] loss: 0.096\n",
      "[69, 360] loss: 0.096\n",
      "Epoch: 69 -> Loss: 0.110779598355\n",
      "Epoch: 69 -> Test Accuracy: 86.73\n",
      "[70, 60] loss: 0.100\n",
      "[70, 120] loss: 0.102\n",
      "[70, 180] loss: 0.094\n",
      "[70, 240] loss: 0.088\n",
      "[70, 300] loss: 0.093\n",
      "[70, 360] loss: 0.099\n",
      "Epoch: 70 -> Loss: 0.0637176558375\n",
      "Epoch: 70 -> Test Accuracy: 86.73\n",
      "[71, 60] loss: 0.092\n",
      "[71, 120] loss: 0.092\n",
      "[71, 180] loss: 0.095\n",
      "[71, 240] loss: 0.089\n",
      "[71, 300] loss: 0.089\n",
      "[71, 360] loss: 0.089\n",
      "Epoch: 71 -> Loss: 0.0852275788784\n",
      "Epoch: 71 -> Test Accuracy: 86.66\n",
      "[72, 60] loss: 0.090\n",
      "[72, 120] loss: 0.099\n",
      "[72, 180] loss: 0.086\n",
      "[72, 240] loss: 0.089\n",
      "[72, 300] loss: 0.097\n",
      "[72, 360] loss: 0.093\n",
      "Epoch: 72 -> Loss: 0.0352444723248\n",
      "Epoch: 72 -> Test Accuracy: 86.72\n",
      "[73, 60] loss: 0.090\n",
      "[73, 120] loss: 0.096\n",
      "[73, 180] loss: 0.088\n",
      "[73, 240] loss: 0.093\n",
      "[73, 300] loss: 0.086\n",
      "[73, 360] loss: 0.097\n",
      "Epoch: 73 -> Loss: 0.112273514271\n",
      "Epoch: 73 -> Test Accuracy: 86.67\n",
      "[74, 60] loss: 0.096\n",
      "[74, 120] loss: 0.094\n",
      "[74, 180] loss: 0.094\n",
      "[74, 240] loss: 0.089\n",
      "[74, 300] loss: 0.089\n",
      "[74, 360] loss: 0.100\n",
      "Epoch: 74 -> Loss: 0.0390239059925\n",
      "Epoch: 74 -> Test Accuracy: 86.78\n",
      "[75, 60] loss: 0.083\n",
      "[75, 120] loss: 0.094\n",
      "[75, 180] loss: 0.093\n",
      "[75, 240] loss: 0.097\n",
      "[75, 300] loss: 0.098\n",
      "[75, 360] loss: 0.091\n",
      "Epoch: 75 -> Loss: 0.112057171762\n",
      "Epoch: 75 -> Test Accuracy: 86.58\n",
      "[76, 60] loss: 0.085\n",
      "[76, 120] loss: 0.091\n",
      "[76, 180] loss: 0.086\n",
      "[76, 240] loss: 0.094\n",
      "[76, 300] loss: 0.084\n",
      "[76, 360] loss: 0.090\n",
      "Epoch: 76 -> Loss: 0.130586057901\n",
      "Epoch: 76 -> Test Accuracy: 86.55\n",
      "[77, 60] loss: 0.088\n",
      "[77, 120] loss: 0.088\n",
      "[77, 180] loss: 0.090\n",
      "[77, 240] loss: 0.095\n",
      "[77, 300] loss: 0.092\n",
      "[77, 360] loss: 0.093\n",
      "Epoch: 77 -> Loss: 0.0890759825706\n",
      "Epoch: 77 -> Test Accuracy: 86.7\n",
      "[78, 60] loss: 0.091\n",
      "[78, 120] loss: 0.086\n",
      "[78, 180] loss: 0.085\n",
      "[78, 240] loss: 0.084\n",
      "[78, 300] loss: 0.091\n",
      "[78, 360] loss: 0.088\n",
      "Epoch: 78 -> Loss: 0.0861165151\n",
      "Epoch: 78 -> Test Accuracy: 86.67\n",
      "[79, 60] loss: 0.091\n",
      "[79, 120] loss: 0.083\n",
      "[79, 180] loss: 0.088\n",
      "[79, 240] loss: 0.081\n",
      "[79, 300] loss: 0.085\n",
      "[79, 360] loss: 0.088\n",
      "Epoch: 79 -> Loss: 0.117215394974\n",
      "Epoch: 79 -> Test Accuracy: 86.6\n",
      "[80, 60] loss: 0.090\n",
      "[80, 120] loss: 0.087\n",
      "[80, 180] loss: 0.086\n",
      "[80, 240] loss: 0.093\n",
      "[80, 300] loss: 0.087\n",
      "[80, 360] loss: 0.089\n",
      "Epoch: 80 -> Loss: 0.0689456537366\n",
      "Epoch: 80 -> Test Accuracy: 86.84\n",
      "[81, 60] loss: 0.090\n",
      "[81, 120] loss: 0.086\n",
      "[81, 180] loss: 0.086\n",
      "[81, 240] loss: 0.084\n",
      "[81, 300] loss: 0.082\n",
      "[81, 360] loss: 0.095\n",
      "Epoch: 81 -> Loss: 0.134788423777\n",
      "Epoch: 81 -> Test Accuracy: 86.6\n",
      "[82, 60] loss: 0.083\n",
      "[82, 120] loss: 0.092\n",
      "[82, 180] loss: 0.085\n",
      "[82, 240] loss: 0.085\n",
      "[82, 300] loss: 0.086\n",
      "[82, 360] loss: 0.087\n",
      "Epoch: 82 -> Loss: 0.0822015404701\n",
      "Epoch: 82 -> Test Accuracy: 86.62\n",
      "[83, 60] loss: 0.087\n",
      "[83, 120] loss: 0.086\n",
      "[83, 180] loss: 0.087\n",
      "[83, 240] loss: 0.089\n",
      "[83, 300] loss: 0.090\n",
      "[83, 360] loss: 0.088\n",
      "Epoch: 83 -> Loss: 0.117660902441\n",
      "Epoch: 83 -> Test Accuracy: 86.51\n",
      "[84, 60] loss: 0.091\n",
      "[84, 120] loss: 0.086\n",
      "[84, 180] loss: 0.086\n",
      "[84, 240] loss: 0.076\n",
      "[84, 300] loss: 0.085\n",
      "[84, 360] loss: 0.093\n",
      "Epoch: 84 -> Loss: 0.0571805723011\n",
      "Epoch: 84 -> Test Accuracy: 86.56\n",
      "[85, 60] loss: 0.080\n",
      "[85, 120] loss: 0.081\n",
      "[85, 180] loss: 0.085\n",
      "[85, 240] loss: 0.093\n",
      "[85, 300] loss: 0.085\n",
      "[85, 360] loss: 0.097\n",
      "Epoch: 85 -> Loss: 0.106787264347\n",
      "Epoch: 85 -> Test Accuracy: 86.54\n",
      "[86, 60] loss: 0.083\n",
      "[86, 120] loss: 0.080\n",
      "[86, 180] loss: 0.084\n",
      "[86, 240] loss: 0.082\n",
      "[86, 300] loss: 0.085\n",
      "[86, 360] loss: 0.088\n",
      "Epoch: 86 -> Loss: 0.064419709146\n",
      "Epoch: 86 -> Test Accuracy: 86.63\n",
      "[87, 60] loss: 0.078\n",
      "[87, 120] loss: 0.082\n",
      "[87, 180] loss: 0.082\n",
      "[87, 240] loss: 0.086\n",
      "[87, 300] loss: 0.080\n",
      "[87, 360] loss: 0.084\n",
      "Epoch: 87 -> Loss: 0.0733853951097\n",
      "Epoch: 87 -> Test Accuracy: 86.73\n",
      "[88, 60] loss: 0.076\n",
      "[88, 120] loss: 0.081\n",
      "[88, 180] loss: 0.083\n",
      "[88, 240] loss: 0.079\n",
      "[88, 300] loss: 0.080\n",
      "[88, 360] loss: 0.085\n",
      "Epoch: 88 -> Loss: 0.109329894185\n",
      "Epoch: 88 -> Test Accuracy: 86.54\n",
      "[89, 60] loss: 0.081\n",
      "[89, 120] loss: 0.080\n",
      "[89, 180] loss: 0.084\n",
      "[89, 240] loss: 0.080\n",
      "[89, 300] loss: 0.083\n",
      "[89, 360] loss: 0.080\n",
      "Epoch: 89 -> Loss: 0.0608838610351\n",
      "Epoch: 89 -> Test Accuracy: 86.65\n",
      "[90, 60] loss: 0.076\n",
      "[90, 120] loss: 0.090\n",
      "[90, 180] loss: 0.087\n",
      "[90, 240] loss: 0.085\n",
      "[90, 300] loss: 0.077\n",
      "[90, 360] loss: 0.082\n",
      "Epoch: 90 -> Loss: 0.086173273623\n",
      "Epoch: 90 -> Test Accuracy: 86.6\n",
      "[91, 60] loss: 0.078\n",
      "[91, 120] loss: 0.082\n",
      "[91, 180] loss: 0.080\n",
      "[91, 240] loss: 0.075\n",
      "[91, 300] loss: 0.078\n",
      "[91, 360] loss: 0.081\n",
      "Epoch: 91 -> Loss: 0.0714503973722\n",
      "Epoch: 91 -> Test Accuracy: 86.53\n",
      "[92, 60] loss: 0.082\n",
      "[92, 120] loss: 0.082\n",
      "[92, 180] loss: 0.076\n",
      "[92, 240] loss: 0.085\n",
      "[92, 300] loss: 0.081\n",
      "[92, 360] loss: 0.075\n",
      "Epoch: 92 -> Loss: 0.105925962329\n",
      "Epoch: 92 -> Test Accuracy: 86.62\n",
      "[93, 60] loss: 0.078\n",
      "[93, 120] loss: 0.075\n",
      "[93, 180] loss: 0.084\n",
      "[93, 240] loss: 0.080\n",
      "[93, 300] loss: 0.082\n",
      "[93, 360] loss: 0.079\n",
      "Epoch: 93 -> Loss: 0.042452685535\n",
      "Epoch: 93 -> Test Accuracy: 86.72\n",
      "[94, 60] loss: 0.075\n",
      "[94, 120] loss: 0.078\n",
      "[94, 180] loss: 0.080\n",
      "[94, 240] loss: 0.083\n",
      "[94, 300] loss: 0.078\n",
      "[94, 360] loss: 0.078\n",
      "Epoch: 94 -> Loss: 0.0499518290162\n",
      "Epoch: 94 -> Test Accuracy: 86.82\n",
      "[95, 60] loss: 0.075\n",
      "[95, 120] loss: 0.085\n",
      "[95, 180] loss: 0.078\n",
      "[95, 240] loss: 0.081\n",
      "[95, 300] loss: 0.083\n",
      "[95, 360] loss: 0.080\n",
      "Epoch: 95 -> Loss: 0.0876734182239\n",
      "Epoch: 95 -> Test Accuracy: 86.77\n",
      "[96, 60] loss: 0.077\n",
      "[96, 120] loss: 0.077\n",
      "[96, 180] loss: 0.076\n",
      "[96, 240] loss: 0.076\n",
      "[96, 300] loss: 0.077\n",
      "[96, 360] loss: 0.078\n",
      "Epoch: 96 -> Loss: 0.0407050177455\n",
      "Epoch: 96 -> Test Accuracy: 86.81\n",
      "[97, 60] loss: 0.078\n",
      "[97, 120] loss: 0.079\n",
      "[97, 180] loss: 0.073\n",
      "[97, 240] loss: 0.081\n",
      "[97, 300] loss: 0.075\n",
      "[97, 360] loss: 0.074\n",
      "Epoch: 97 -> Loss: 0.117532037199\n",
      "Epoch: 97 -> Test Accuracy: 86.81\n",
      "[98, 60] loss: 0.076\n",
      "[98, 120] loss: 0.082\n",
      "[98, 180] loss: 0.073\n",
      "[98, 240] loss: 0.080\n",
      "[98, 300] loss: 0.080\n",
      "[98, 360] loss: 0.078\n",
      "Epoch: 98 -> Loss: 0.0739609375596\n",
      "Epoch: 98 -> Test Accuracy: 86.8\n",
      "[99, 60] loss: 0.076\n",
      "[99, 120] loss: 0.069\n",
      "[99, 180] loss: 0.077\n",
      "[99, 240] loss: 0.079\n",
      "[99, 300] loss: 0.081\n",
      "[99, 360] loss: 0.083\n",
      "Epoch: 99 -> Loss: 0.0920497626066\n",
      "Epoch: 99 -> Test Accuracy: 86.77\n",
      "[100, 60] loss: 0.079\n",
      "[100, 120] loss: 0.067\n",
      "[100, 180] loss: 0.074\n",
      "[100, 240] loss: 0.073\n",
      "[100, 300] loss: 0.074\n",
      "[100, 360] loss: 0.078\n",
      "Epoch: 100 -> Loss: 0.141795456409\n",
      "Epoch: 100 -> Test Accuracy: 86.61\n",
      "Finished Training\n",
      "[1, 60] loss: 1.734\n",
      "[1, 120] loss: 0.877\n",
      "[1, 180] loss: 0.817\n",
      "[1, 240] loss: 0.770\n",
      "[1, 300] loss: 0.745\n",
      "[1, 360] loss: 0.710\n",
      "Epoch: 1 -> Loss: 0.563965916634\n",
      "Epoch: 1 -> Test Accuracy: 73.61\n",
      "[2, 60] loss: 0.700\n",
      "[2, 120] loss: 0.657\n",
      "[2, 180] loss: 0.653\n",
      "[2, 240] loss: 0.659\n",
      "[2, 300] loss: 0.635\n",
      "[2, 360] loss: 0.635\n",
      "Epoch: 2 -> Loss: 0.569432318211\n",
      "Epoch: 2 -> Test Accuracy: 75.22\n",
      "[3, 60] loss: 0.616\n",
      "[3, 120] loss: 0.599\n",
      "[3, 180] loss: 0.585\n",
      "[3, 240] loss: 0.629\n",
      "[3, 300] loss: 0.592\n",
      "[3, 360] loss: 0.588\n",
      "Epoch: 3 -> Loss: 0.71588498354\n",
      "Epoch: 3 -> Test Accuracy: 76.34\n",
      "[4, 60] loss: 0.563\n",
      "[4, 120] loss: 0.575\n",
      "[4, 180] loss: 0.576\n",
      "[4, 240] loss: 0.571\n",
      "[4, 300] loss: 0.572\n",
      "[4, 360] loss: 0.569\n",
      "Epoch: 4 -> Loss: 0.669156551361\n",
      "Epoch: 4 -> Test Accuracy: 77.21\n",
      "[5, 60] loss: 0.555\n",
      "[5, 120] loss: 0.565\n",
      "[5, 180] loss: 0.562\n",
      "[5, 240] loss: 0.512\n",
      "[5, 300] loss: 0.555\n",
      "[5, 360] loss: 0.561\n",
      "Epoch: 5 -> Loss: 0.635642170906\n",
      "Epoch: 5 -> Test Accuracy: 77.95\n",
      "[6, 60] loss: 0.546\n",
      "[6, 120] loss: 0.542\n",
      "[6, 180] loss: 0.531\n",
      "[6, 240] loss: 0.539\n",
      "[6, 300] loss: 0.543\n",
      "[6, 360] loss: 0.541\n",
      "Epoch: 6 -> Loss: 0.847508430481\n",
      "Epoch: 6 -> Test Accuracy: 78.21\n",
      "[7, 60] loss: 0.522\n",
      "[7, 120] loss: 0.508\n",
      "[7, 180] loss: 0.536\n",
      "[7, 240] loss: 0.531\n",
      "[7, 300] loss: 0.528\n",
      "[7, 360] loss: 0.536\n",
      "Epoch: 7 -> Loss: 0.513782083988\n",
      "Epoch: 7 -> Test Accuracy: 78.82\n",
      "[8, 60] loss: 0.527\n",
      "[8, 120] loss: 0.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 180] loss: 0.537\n",
      "[8, 240] loss: 0.514\n",
      "[8, 300] loss: 0.549\n",
      "[8, 360] loss: 0.512\n",
      "Epoch: 8 -> Loss: 0.850462138653\n",
      "Epoch: 8 -> Test Accuracy: 78.5\n",
      "[9, 60] loss: 0.498\n",
      "[9, 120] loss: 0.500\n",
      "[9, 180] loss: 0.498\n",
      "[9, 240] loss: 0.508\n",
      "[9, 300] loss: 0.508\n",
      "[9, 360] loss: 0.519\n",
      "Epoch: 9 -> Loss: 0.48277464509\n",
      "Epoch: 9 -> Test Accuracy: 79.34\n",
      "[10, 60] loss: 0.526\n",
      "[10, 120] loss: 0.500\n",
      "[10, 180] loss: 0.497\n",
      "[10, 240] loss: 0.495\n",
      "[10, 300] loss: 0.504\n",
      "[10, 360] loss: 0.510\n",
      "Epoch: 10 -> Loss: 0.612861573696\n",
      "Epoch: 10 -> Test Accuracy: 79.34\n",
      "[11, 60] loss: 0.486\n",
      "[11, 120] loss: 0.491\n",
      "[11, 180] loss: 0.506\n",
      "[11, 240] loss: 0.518\n",
      "[11, 300] loss: 0.504\n",
      "[11, 360] loss: 0.490\n",
      "Epoch: 11 -> Loss: 0.638846099377\n",
      "Epoch: 11 -> Test Accuracy: 79.17\n",
      "[12, 60] loss: 0.467\n",
      "[12, 120] loss: 0.505\n",
      "[12, 180] loss: 0.499\n",
      "[12, 240] loss: 0.503\n",
      "[12, 300] loss: 0.495\n",
      "[12, 360] loss: 0.489\n",
      "Epoch: 12 -> Loss: 0.344787597656\n",
      "Epoch: 12 -> Test Accuracy: 79.8\n",
      "[13, 60] loss: 0.481\n",
      "[13, 120] loss: 0.492\n",
      "[13, 180] loss: 0.477\n",
      "[13, 240] loss: 0.489\n",
      "[13, 300] loss: 0.518\n",
      "[13, 360] loss: 0.510\n",
      "Epoch: 13 -> Loss: 0.453244686127\n",
      "Epoch: 13 -> Test Accuracy: 79.26\n",
      "[14, 60] loss: 0.456\n",
      "[14, 120] loss: 0.491\n",
      "[14, 180] loss: 0.503\n",
      "[14, 240] loss: 0.479\n",
      "[14, 300] loss: 0.492\n",
      "[14, 360] loss: 0.495\n",
      "Epoch: 14 -> Loss: 0.504789054394\n",
      "Epoch: 14 -> Test Accuracy: 79.48\n",
      "[15, 60] loss: 0.478\n",
      "[15, 120] loss: 0.500\n",
      "[15, 180] loss: 0.477\n",
      "[15, 240] loss: 0.459\n",
      "[15, 300] loss: 0.494\n",
      "[15, 360] loss: 0.496\n",
      "Epoch: 15 -> Loss: 0.422408908606\n",
      "Epoch: 15 -> Test Accuracy: 79.12\n",
      "[16, 60] loss: 0.465\n",
      "[16, 120] loss: 0.476\n",
      "[16, 180] loss: 0.498\n",
      "[16, 240] loss: 0.475\n",
      "[16, 300] loss: 0.489\n",
      "[16, 360] loss: 0.490\n",
      "Epoch: 16 -> Loss: 0.542528808117\n",
      "Epoch: 16 -> Test Accuracy: 79.78\n",
      "[17, 60] loss: 0.482\n",
      "[17, 120] loss: 0.473\n",
      "[17, 180] loss: 0.464\n",
      "[17, 240] loss: 0.477\n",
      "[17, 300] loss: 0.499\n",
      "[17, 360] loss: 0.478\n",
      "Epoch: 17 -> Loss: 0.403333961964\n",
      "Epoch: 17 -> Test Accuracy: 80.11\n",
      "[18, 60] loss: 0.472\n",
      "[18, 120] loss: 0.468\n",
      "[18, 180] loss: 0.490\n",
      "[18, 240] loss: 0.472\n",
      "[18, 300] loss: 0.497\n",
      "[18, 360] loss: 0.473\n",
      "Epoch: 18 -> Loss: 0.592651307583\n",
      "Epoch: 18 -> Test Accuracy: 79.92\n",
      "[19, 60] loss: 0.459\n",
      "[19, 120] loss: 0.480\n",
      "[19, 180] loss: 0.467\n",
      "[19, 240] loss: 0.496\n",
      "[19, 300] loss: 0.482\n",
      "[19, 360] loss: 0.477\n",
      "Epoch: 19 -> Loss: 0.490086078644\n",
      "Epoch: 19 -> Test Accuracy: 79.26\n",
      "[20, 60] loss: 0.469\n",
      "[20, 120] loss: 0.465\n",
      "[20, 180] loss: 0.458\n",
      "[20, 240] loss: 0.482\n",
      "[20, 300] loss: 0.482\n",
      "[20, 360] loss: 0.478\n",
      "Epoch: 20 -> Loss: 0.482139110565\n",
      "Epoch: 20 -> Test Accuracy: 79.85\n",
      "[21, 60] loss: 0.422\n",
      "[21, 120] loss: 0.438\n",
      "[21, 180] loss: 0.409\n",
      "[21, 240] loss: 0.408\n",
      "[21, 300] loss: 0.399\n",
      "[21, 360] loss: 0.405\n",
      "Epoch: 21 -> Loss: 0.454132378101\n",
      "Epoch: 21 -> Test Accuracy: 82.09\n",
      "[22, 60] loss: 0.380\n",
      "[22, 120] loss: 0.372\n",
      "[22, 180] loss: 0.376\n",
      "[22, 240] loss: 0.386\n",
      "[22, 300] loss: 0.371\n",
      "[22, 360] loss: 0.379\n",
      "Epoch: 22 -> Loss: 0.225936338305\n",
      "Epoch: 22 -> Test Accuracy: 81.98\n",
      "[23, 60] loss: 0.359\n",
      "[23, 120] loss: 0.366\n",
      "[23, 180] loss: 0.358\n",
      "[23, 240] loss: 0.365\n",
      "[23, 300] loss: 0.364\n",
      "[23, 360] loss: 0.364\n",
      "Epoch: 23 -> Loss: 0.467597663403\n",
      "Epoch: 23 -> Test Accuracy: 81.9\n",
      "[24, 60] loss: 0.346\n",
      "[24, 120] loss: 0.365\n",
      "[24, 180] loss: 0.347\n",
      "[24, 240] loss: 0.342\n",
      "[24, 300] loss: 0.347\n",
      "[24, 360] loss: 0.351\n",
      "Epoch: 24 -> Loss: 0.498348474503\n",
      "Epoch: 24 -> Test Accuracy: 82.06\n",
      "[25, 60] loss: 0.343\n",
      "[25, 120] loss: 0.327\n",
      "[25, 180] loss: 0.349\n",
      "[25, 240] loss: 0.355\n",
      "[25, 300] loss: 0.341\n",
      "[25, 360] loss: 0.351\n",
      "Epoch: 25 -> Loss: 0.421560049057\n",
      "Epoch: 25 -> Test Accuracy: 82.23\n",
      "[26, 60] loss: 0.343\n",
      "[26, 120] loss: 0.329\n",
      "[26, 180] loss: 0.321\n",
      "[26, 240] loss: 0.349\n",
      "[26, 300] loss: 0.342\n",
      "[26, 360] loss: 0.339\n",
      "Epoch: 26 -> Loss: 0.437863022089\n",
      "Epoch: 26 -> Test Accuracy: 82.44\n",
      "[27, 60] loss: 0.320\n",
      "[27, 120] loss: 0.333\n",
      "[27, 180] loss: 0.336\n",
      "[27, 240] loss: 0.346\n",
      "[27, 300] loss: 0.333\n",
      "[27, 360] loss: 0.348\n",
      "Epoch: 27 -> Loss: 0.39853990078\n",
      "Epoch: 27 -> Test Accuracy: 82.42\n",
      "[28, 60] loss: 0.324\n",
      "[28, 120] loss: 0.349\n",
      "[28, 180] loss: 0.323\n",
      "[28, 240] loss: 0.331\n",
      "[28, 300] loss: 0.336\n",
      "[28, 360] loss: 0.328\n",
      "Epoch: 28 -> Loss: 0.313502848148\n",
      "Epoch: 28 -> Test Accuracy: 82.46\n",
      "[29, 60] loss: 0.309\n",
      "[29, 120] loss: 0.315\n",
      "[29, 180] loss: 0.333\n",
      "[29, 240] loss: 0.330\n",
      "[29, 300] loss: 0.347\n",
      "[29, 360] loss: 0.347\n",
      "Epoch: 29 -> Loss: 0.135889172554\n",
      "Epoch: 29 -> Test Accuracy: 82.2\n",
      "[30, 60] loss: 0.324\n",
      "[30, 120] loss: 0.317\n",
      "[30, 180] loss: 0.333\n",
      "[30, 240] loss: 0.312\n",
      "[30, 300] loss: 0.323\n",
      "[30, 360] loss: 0.337\n",
      "Epoch: 30 -> Loss: 0.263492047787\n",
      "Epoch: 30 -> Test Accuracy: 81.89\n",
      "[31, 60] loss: 0.313\n",
      "[31, 120] loss: 0.315\n",
      "[31, 180] loss: 0.321\n",
      "[31, 240] loss: 0.315\n",
      "[31, 300] loss: 0.334\n",
      "[31, 360] loss: 0.331\n",
      "Epoch: 31 -> Loss: 0.200822591782\n",
      "Epoch: 31 -> Test Accuracy: 81.95\n",
      "[32, 60] loss: 0.314\n",
      "[32, 120] loss: 0.311\n",
      "[32, 180] loss: 0.336\n",
      "[32, 240] loss: 0.326\n",
      "[32, 300] loss: 0.329\n",
      "[32, 360] loss: 0.316\n",
      "Epoch: 32 -> Loss: 0.304923832417\n",
      "Epoch: 32 -> Test Accuracy: 81.99\n",
      "[33, 60] loss: 0.328\n",
      "[33, 120] loss: 0.308\n",
      "[33, 180] loss: 0.338\n",
      "[33, 240] loss: 0.310\n",
      "[33, 300] loss: 0.323\n",
      "[33, 360] loss: 0.328\n",
      "Epoch: 33 -> Loss: 0.360907793045\n",
      "Epoch: 33 -> Test Accuracy: 82.18\n",
      "[34, 60] loss: 0.326\n",
      "[34, 120] loss: 0.312\n",
      "[34, 180] loss: 0.313\n",
      "[34, 240] loss: 0.315\n",
      "[34, 300] loss: 0.309\n",
      "[34, 360] loss: 0.321\n",
      "Epoch: 34 -> Loss: 0.331376373768\n",
      "Epoch: 34 -> Test Accuracy: 81.81\n",
      "[35, 60] loss: 0.310\n",
      "[35, 120] loss: 0.320\n",
      "[35, 180] loss: 0.316\n",
      "[35, 240] loss: 0.303\n",
      "[35, 300] loss: 0.313\n",
      "[35, 360] loss: 0.326\n",
      "Epoch: 35 -> Loss: 0.347342073917\n",
      "Epoch: 35 -> Test Accuracy: 81.39\n",
      "[36, 60] loss: 0.306\n",
      "[36, 120] loss: 0.322\n",
      "[36, 180] loss: 0.316\n",
      "[36, 240] loss: 0.324\n",
      "[36, 300] loss: 0.317\n",
      "[36, 360] loss: 0.323\n",
      "Epoch: 36 -> Loss: 0.376078784466\n",
      "Epoch: 36 -> Test Accuracy: 81.76\n",
      "[37, 60] loss: 0.305\n",
      "[37, 120] loss: 0.323\n",
      "[37, 180] loss: 0.310\n",
      "[37, 240] loss: 0.314\n",
      "[37, 300] loss: 0.306\n",
      "[37, 360] loss: 0.321\n",
      "Epoch: 37 -> Loss: 0.210995957255\n",
      "Epoch: 37 -> Test Accuracy: 81.73\n",
      "[38, 60] loss: 0.291\n",
      "[38, 120] loss: 0.315\n",
      "[38, 180] loss: 0.309\n",
      "[38, 240] loss: 0.325\n",
      "[38, 300] loss: 0.322\n",
      "[38, 360] loss: 0.327\n",
      "Epoch: 38 -> Loss: 0.289833724499\n",
      "Epoch: 38 -> Test Accuracy: 81.37\n",
      "[39, 60] loss: 0.313\n",
      "[39, 120] loss: 0.301\n",
      "[39, 180] loss: 0.317\n",
      "[39, 240] loss: 0.324\n",
      "[39, 300] loss: 0.315\n",
      "[39, 360] loss: 0.318\n",
      "Epoch: 39 -> Loss: 0.184994310141\n",
      "Epoch: 39 -> Test Accuracy: 81.47\n",
      "[40, 60] loss: 0.298\n",
      "[40, 120] loss: 0.311\n",
      "[40, 180] loss: 0.308\n",
      "[40, 240] loss: 0.307\n",
      "[40, 300] loss: 0.318\n",
      "[40, 360] loss: 0.313\n",
      "Epoch: 40 -> Loss: 0.176293224096\n",
      "Epoch: 40 -> Test Accuracy: 81.65\n",
      "[41, 60] loss: 0.292\n",
      "[41, 120] loss: 0.283\n",
      "[41, 180] loss: 0.280\n",
      "[41, 240] loss: 0.269\n",
      "[41, 300] loss: 0.267\n",
      "[41, 360] loss: 0.273\n",
      "Epoch: 41 -> Loss: 0.339751899242\n",
      "Epoch: 41 -> Test Accuracy: 82.47\n",
      "[42, 60] loss: 0.264\n",
      "[42, 120] loss: 0.253\n",
      "[42, 180] loss: 0.270\n",
      "[42, 240] loss: 0.263\n",
      "[42, 300] loss: 0.257\n",
      "[42, 360] loss: 0.258\n",
      "Epoch: 42 -> Loss: 0.254116952419\n",
      "Epoch: 42 -> Test Accuracy: 82.77\n",
      "[43, 60] loss: 0.252\n",
      "[43, 120] loss: 0.230\n",
      "[43, 180] loss: 0.249\n",
      "[43, 240] loss: 0.254\n",
      "[43, 300] loss: 0.257\n",
      "[43, 360] loss: 0.243\n",
      "Epoch: 43 -> Loss: 0.424805700779\n",
      "Epoch: 43 -> Test Accuracy: 83.0\n",
      "[44, 60] loss: 0.253\n",
      "[44, 120] loss: 0.250\n",
      "[44, 180] loss: 0.240\n",
      "[44, 240] loss: 0.242\n",
      "[44, 300] loss: 0.250\n",
      "[44, 360] loss: 0.250\n",
      "Epoch: 44 -> Loss: 0.136565297842\n",
      "Epoch: 44 -> Test Accuracy: 82.76\n",
      "[45, 60] loss: 0.238\n",
      "[45, 120] loss: 0.239\n",
      "[45, 180] loss: 0.252\n",
      "[45, 240] loss: 0.238\n",
      "[45, 300] loss: 0.236\n",
      "[45, 360] loss: 0.241\n",
      "Epoch: 45 -> Loss: 0.18790717423\n",
      "Epoch: 45 -> Test Accuracy: 82.77\n",
      "[46, 60] loss: 0.234\n",
      "[46, 120] loss: 0.224\n",
      "[46, 180] loss: 0.231\n",
      "[46, 240] loss: 0.234\n",
      "[46, 300] loss: 0.226\n",
      "[46, 360] loss: 0.226\n",
      "Epoch: 46 -> Loss: 0.208056241274\n",
      "Epoch: 46 -> Test Accuracy: 83.12\n",
      "[47, 60] loss: 0.229\n",
      "[47, 120] loss: 0.232\n",
      "[47, 180] loss: 0.238\n",
      "[47, 240] loss: 0.223\n",
      "[47, 300] loss: 0.228\n",
      "[47, 360] loss: 0.227\n",
      "Epoch: 47 -> Loss: 0.134548678994\n",
      "Epoch: 47 -> Test Accuracy: 83.14\n",
      "[48, 60] loss: 0.234\n",
      "[48, 120] loss: 0.222\n",
      "[48, 180] loss: 0.229\n",
      "[48, 240] loss: 0.227\n",
      "[48, 300] loss: 0.230\n",
      "[48, 360] loss: 0.218\n",
      "Epoch: 48 -> Loss: 0.196943730116\n",
      "Epoch: 48 -> Test Accuracy: 83.07\n",
      "[49, 60] loss: 0.226\n",
      "[49, 120] loss: 0.216\n",
      "[49, 180] loss: 0.216\n",
      "[49, 240] loss: 0.220\n",
      "[49, 300] loss: 0.224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 360] loss: 0.235\n",
      "Epoch: 49 -> Loss: 0.195076107979\n",
      "Epoch: 49 -> Test Accuracy: 83.13\n",
      "[50, 60] loss: 0.216\n",
      "[50, 120] loss: 0.228\n",
      "[50, 180] loss: 0.230\n",
      "[50, 240] loss: 0.217\n",
      "[50, 300] loss: 0.222\n",
      "[50, 360] loss: 0.217\n",
      "Epoch: 50 -> Loss: 0.208085611463\n",
      "Epoch: 50 -> Test Accuracy: 83.09\n",
      "[51, 60] loss: 0.223\n",
      "[51, 120] loss: 0.213\n",
      "[51, 180] loss: 0.219\n",
      "[51, 240] loss: 0.221\n",
      "[51, 300] loss: 0.219\n",
      "[51, 360] loss: 0.217\n",
      "Epoch: 51 -> Loss: 0.375768214464\n",
      "Epoch: 51 -> Test Accuracy: 83.19\n",
      "[52, 60] loss: 0.229\n",
      "[52, 120] loss: 0.221\n",
      "[52, 180] loss: 0.216\n",
      "[52, 240] loss: 0.223\n",
      "[52, 300] loss: 0.218\n",
      "[52, 360] loss: 0.215\n",
      "Epoch: 52 -> Loss: 0.168355494738\n",
      "Epoch: 52 -> Test Accuracy: 83.2\n",
      "[53, 60] loss: 0.226\n",
      "[53, 120] loss: 0.211\n",
      "[53, 180] loss: 0.217\n",
      "[53, 240] loss: 0.210\n",
      "[53, 300] loss: 0.232\n",
      "[53, 360] loss: 0.225\n",
      "Epoch: 53 -> Loss: 0.234898015857\n",
      "Epoch: 53 -> Test Accuracy: 83.1\n",
      "[54, 60] loss: 0.222\n",
      "[54, 120] loss: 0.211\n",
      "[54, 180] loss: 0.222\n",
      "[54, 240] loss: 0.227\n",
      "[54, 300] loss: 0.218\n",
      "[54, 360] loss: 0.206\n",
      "Epoch: 54 -> Loss: 0.257687360048\n",
      "Epoch: 54 -> Test Accuracy: 83.02\n",
      "[55, 60] loss: 0.220\n",
      "[55, 120] loss: 0.217\n",
      "[55, 180] loss: 0.217\n",
      "[55, 240] loss: 0.214\n",
      "[55, 300] loss: 0.198\n",
      "[55, 360] loss: 0.210\n",
      "Epoch: 55 -> Loss: 0.170941501856\n",
      "Epoch: 55 -> Test Accuracy: 83.06\n",
      "[56, 60] loss: 0.201\n",
      "[56, 120] loss: 0.209\n",
      "[56, 180] loss: 0.210\n",
      "[56, 240] loss: 0.217\n",
      "[56, 300] loss: 0.218\n",
      "[56, 360] loss: 0.215\n",
      "Epoch: 56 -> Loss: 0.175722688437\n",
      "Epoch: 56 -> Test Accuracy: 83.15\n",
      "[57, 60] loss: 0.207\n",
      "[57, 120] loss: 0.223\n",
      "[57, 180] loss: 0.218\n",
      "[57, 240] loss: 0.219\n",
      "[57, 300] loss: 0.206\n",
      "[57, 360] loss: 0.207\n",
      "Epoch: 57 -> Loss: 0.21506524086\n",
      "Epoch: 57 -> Test Accuracy: 83.06\n",
      "[58, 60] loss: 0.205\n",
      "[58, 120] loss: 0.215\n",
      "[58, 180] loss: 0.213\n",
      "[58, 240] loss: 0.216\n",
      "[58, 300] loss: 0.212\n",
      "[58, 360] loss: 0.204\n",
      "Epoch: 58 -> Loss: 0.296482861042\n",
      "Epoch: 58 -> Test Accuracy: 83.0\n",
      "[59, 60] loss: 0.212\n",
      "[59, 120] loss: 0.205\n",
      "[59, 180] loss: 0.211\n",
      "[59, 240] loss: 0.209\n",
      "[59, 300] loss: 0.203\n",
      "[59, 360] loss: 0.200\n",
      "Epoch: 59 -> Loss: 0.165866702795\n",
      "Epoch: 59 -> Test Accuracy: 83.3\n",
      "[60, 60] loss: 0.215\n",
      "[60, 120] loss: 0.208\n",
      "[60, 180] loss: 0.210\n",
      "[60, 240] loss: 0.212\n",
      "[60, 300] loss: 0.216\n",
      "[60, 360] loss: 0.204\n",
      "Epoch: 60 -> Loss: 0.0986204817891\n",
      "Epoch: 60 -> Test Accuracy: 83.12\n",
      "[61, 60] loss: 0.194\n",
      "[61, 120] loss: 0.218\n",
      "[61, 180] loss: 0.208\n",
      "[61, 240] loss: 0.210\n",
      "[61, 300] loss: 0.215\n",
      "[61, 360] loss: 0.199\n",
      "Epoch: 61 -> Loss: 0.326933324337\n",
      "Epoch: 61 -> Test Accuracy: 83.17\n",
      "[62, 60] loss: 0.195\n",
      "[62, 120] loss: 0.202\n",
      "[62, 180] loss: 0.209\n",
      "[62, 240] loss: 0.206\n",
      "[62, 300] loss: 0.200\n",
      "[62, 360] loss: 0.198\n",
      "Epoch: 62 -> Loss: 0.214783504605\n",
      "Epoch: 62 -> Test Accuracy: 83.1\n",
      "[63, 60] loss: 0.195\n",
      "[63, 120] loss: 0.205\n",
      "[63, 180] loss: 0.223\n",
      "[63, 240] loss: 0.197\n",
      "[63, 300] loss: 0.192\n",
      "[63, 360] loss: 0.203\n",
      "Epoch: 63 -> Loss: 0.24207046628\n",
      "Epoch: 63 -> Test Accuracy: 83.17\n",
      "[64, 60] loss: 0.206\n",
      "[64, 120] loss: 0.204\n",
      "[64, 180] loss: 0.214\n",
      "[64, 240] loss: 0.197\n",
      "[64, 300] loss: 0.198\n",
      "[64, 360] loss: 0.209\n",
      "Epoch: 64 -> Loss: 0.224704906344\n",
      "Epoch: 64 -> Test Accuracy: 83.18\n",
      "[65, 60] loss: 0.201\n",
      "[65, 120] loss: 0.209\n",
      "[65, 180] loss: 0.199\n",
      "[65, 240] loss: 0.203\n",
      "[65, 300] loss: 0.201\n",
      "[65, 360] loss: 0.213\n",
      "Epoch: 65 -> Loss: 0.24217478931\n",
      "Epoch: 65 -> Test Accuracy: 83.06\n",
      "[66, 60] loss: 0.202\n",
      "[66, 120] loss: 0.201\n",
      "[66, 180] loss: 0.207\n",
      "[66, 240] loss: 0.204\n",
      "[66, 300] loss: 0.201\n",
      "[66, 360] loss: 0.201\n",
      "Epoch: 66 -> Loss: 0.206585437059\n",
      "Epoch: 66 -> Test Accuracy: 83.16\n",
      "[67, 60] loss: 0.203\n",
      "[67, 120] loss: 0.208\n",
      "[67, 180] loss: 0.211\n",
      "[67, 240] loss: 0.197\n",
      "[67, 300] loss: 0.205\n",
      "[67, 360] loss: 0.192\n",
      "Epoch: 67 -> Loss: 0.208486914635\n",
      "Epoch: 67 -> Test Accuracy: 83.1\n",
      "[68, 60] loss: 0.202\n",
      "[68, 120] loss: 0.199\n",
      "[68, 180] loss: 0.188\n",
      "[68, 240] loss: 0.203\n",
      "[68, 300] loss: 0.192\n",
      "[68, 360] loss: 0.195\n",
      "Epoch: 68 -> Loss: 0.238188698888\n",
      "Epoch: 68 -> Test Accuracy: 83.06\n",
      "[69, 60] loss: 0.197\n",
      "[69, 120] loss: 0.197\n",
      "[69, 180] loss: 0.202\n",
      "[69, 240] loss: 0.199\n",
      "[69, 300] loss: 0.214\n",
      "[69, 360] loss: 0.193\n",
      "Epoch: 69 -> Loss: 0.236370801926\n",
      "Epoch: 69 -> Test Accuracy: 83.17\n",
      "[70, 60] loss: 0.202\n",
      "[70, 120] loss: 0.181\n",
      "[70, 180] loss: 0.192\n",
      "[70, 240] loss: 0.205\n",
      "[70, 300] loss: 0.203\n",
      "[70, 360] loss: 0.209\n",
      "Epoch: 70 -> Loss: 0.189635664225\n",
      "Epoch: 70 -> Test Accuracy: 83.22\n",
      "[71, 60] loss: 0.202\n",
      "[71, 120] loss: 0.206\n",
      "[71, 180] loss: 0.208\n",
      "[71, 240] loss: 0.193\n",
      "[71, 300] loss: 0.193\n",
      "[71, 360] loss: 0.204\n",
      "Epoch: 71 -> Loss: 0.215808585286\n",
      "Epoch: 71 -> Test Accuracy: 83.12\n",
      "[72, 60] loss: 0.201\n",
      "[72, 120] loss: 0.200\n",
      "[72, 180] loss: 0.189\n",
      "[72, 240] loss: 0.199\n",
      "[72, 300] loss: 0.206\n",
      "[72, 360] loss: 0.203\n",
      "Epoch: 72 -> Loss: 0.211605101824\n",
      "Epoch: 72 -> Test Accuracy: 83.21\n",
      "[73, 60] loss: 0.198\n",
      "[73, 120] loss: 0.199\n",
      "[73, 180] loss: 0.209\n",
      "[73, 240] loss: 0.196\n",
      "[73, 300] loss: 0.187\n",
      "[73, 360] loss: 0.195\n",
      "Epoch: 73 -> Loss: 0.152925416827\n",
      "Epoch: 73 -> Test Accuracy: 83.19\n",
      "[74, 60] loss: 0.184\n",
      "[74, 120] loss: 0.194\n",
      "[74, 180] loss: 0.203\n",
      "[74, 240] loss: 0.204\n",
      "[74, 300] loss: 0.194\n",
      "[74, 360] loss: 0.190\n",
      "Epoch: 74 -> Loss: 0.159657418728\n",
      "Epoch: 74 -> Test Accuracy: 82.94\n",
      "[75, 60] loss: 0.200\n",
      "[75, 120] loss: 0.190\n",
      "[75, 180] loss: 0.195\n",
      "[75, 240] loss: 0.190\n",
      "[75, 300] loss: 0.195\n",
      "[75, 360] loss: 0.178\n",
      "Epoch: 75 -> Loss: 0.242218062282\n",
      "Epoch: 75 -> Test Accuracy: 83.26\n",
      "[76, 60] loss: 0.183\n",
      "[76, 120] loss: 0.192\n",
      "[76, 180] loss: 0.189\n",
      "[76, 240] loss: 0.208\n",
      "[76, 300] loss: 0.201\n",
      "[76, 360] loss: 0.182\n",
      "Epoch: 76 -> Loss: 0.209986642003\n",
      "Epoch: 76 -> Test Accuracy: 83.18\n",
      "[77, 60] loss: 0.188\n",
      "[77, 120] loss: 0.192\n",
      "[77, 180] loss: 0.184\n",
      "[77, 240] loss: 0.196\n",
      "[77, 300] loss: 0.191\n",
      "[77, 360] loss: 0.195\n",
      "Epoch: 77 -> Loss: 0.168890431523\n",
      "Epoch: 77 -> Test Accuracy: 83.12\n",
      "[78, 60] loss: 0.194\n",
      "[78, 120] loss: 0.199\n",
      "[78, 180] loss: 0.200\n",
      "[78, 240] loss: 0.186\n",
      "[78, 300] loss: 0.189\n",
      "[78, 360] loss: 0.190\n",
      "Epoch: 78 -> Loss: 0.175486952066\n",
      "Epoch: 78 -> Test Accuracy: 83.32\n",
      "[79, 60] loss: 0.189\n",
      "[79, 120] loss: 0.195\n",
      "[79, 180] loss: 0.177\n",
      "[79, 240] loss: 0.196\n",
      "[79, 300] loss: 0.185\n",
      "[79, 360] loss: 0.185\n",
      "Epoch: 79 -> Loss: 0.143351063132\n",
      "Epoch: 79 -> Test Accuracy: 83.26\n",
      "[80, 60] loss: 0.186\n",
      "[80, 120] loss: 0.189\n",
      "[80, 180] loss: 0.190\n",
      "[80, 240] loss: 0.185\n",
      "[80, 300] loss: 0.192\n",
      "[80, 360] loss: 0.189\n",
      "Epoch: 80 -> Loss: 0.191567525268\n",
      "Epoch: 80 -> Test Accuracy: 83.37\n",
      "[81, 60] loss: 0.184\n",
      "[81, 120] loss: 0.185\n",
      "[81, 180] loss: 0.189\n",
      "[81, 240] loss: 0.192\n",
      "[81, 300] loss: 0.199\n",
      "[81, 360] loss: 0.184\n",
      "Epoch: 81 -> Loss: 0.285828828812\n",
      "Epoch: 81 -> Test Accuracy: 83.3\n",
      "[82, 60] loss: 0.191\n",
      "[82, 120] loss: 0.185\n",
      "[82, 180] loss: 0.188\n",
      "[82, 240] loss: 0.186\n",
      "[82, 300] loss: 0.187\n",
      "[82, 360] loss: 0.188\n",
      "Epoch: 82 -> Loss: 0.205583184958\n",
      "Epoch: 82 -> Test Accuracy: 83.13\n",
      "[83, 60] loss: 0.181\n",
      "[83, 120] loss: 0.193\n",
      "[83, 180] loss: 0.188\n",
      "[83, 240] loss: 0.185\n",
      "[83, 300] loss: 0.189\n",
      "[83, 360] loss: 0.188\n",
      "Epoch: 83 -> Loss: 0.143986821175\n",
      "Epoch: 83 -> Test Accuracy: 83.02\n",
      "[84, 60] loss: 0.182\n",
      "[84, 120] loss: 0.189\n",
      "[84, 180] loss: 0.181\n",
      "[84, 240] loss: 0.189\n",
      "[84, 300] loss: 0.181\n",
      "[84, 360] loss: 0.186\n",
      "Epoch: 84 -> Loss: 0.262384951115\n",
      "Epoch: 84 -> Test Accuracy: 83.07\n",
      "[85, 60] loss: 0.186\n",
      "[85, 120] loss: 0.183\n",
      "[85, 180] loss: 0.191\n",
      "[85, 240] loss: 0.174\n",
      "[85, 300] loss: 0.177\n",
      "[85, 360] loss: 0.185\n",
      "Epoch: 85 -> Loss: 0.131295651197\n",
      "Epoch: 85 -> Test Accuracy: 83.05\n",
      "[86, 60] loss: 0.179\n",
      "[86, 120] loss: 0.180\n",
      "[86, 180] loss: 0.187\n",
      "[86, 240] loss: 0.188\n",
      "[86, 300] loss: 0.176\n",
      "[86, 360] loss: 0.178\n",
      "Epoch: 86 -> Loss: 0.21776342392\n",
      "Epoch: 86 -> Test Accuracy: 83.17\n",
      "[87, 60] loss: 0.185\n",
      "[87, 120] loss: 0.183\n",
      "[87, 180] loss: 0.194\n",
      "[87, 240] loss: 0.188\n",
      "[87, 300] loss: 0.181\n",
      "[87, 360] loss: 0.181\n",
      "Epoch: 87 -> Loss: 0.192548587918\n",
      "Epoch: 87 -> Test Accuracy: 83.02\n",
      "[88, 60] loss: 0.186\n",
      "[88, 120] loss: 0.192\n",
      "[88, 180] loss: 0.172\n",
      "[88, 240] loss: 0.189\n",
      "[88, 300] loss: 0.175\n",
      "[88, 360] loss: 0.188\n",
      "Epoch: 88 -> Loss: 0.210859745741\n",
      "Epoch: 88 -> Test Accuracy: 83.11\n",
      "[89, 60] loss: 0.185\n",
      "[89, 120] loss: 0.175\n",
      "[89, 180] loss: 0.186\n",
      "[89, 240] loss: 0.198\n",
      "[89, 300] loss: 0.183\n",
      "[89, 360] loss: 0.177\n",
      "Epoch: 89 -> Loss: 0.179989367723\n",
      "Epoch: 89 -> Test Accuracy: 83.12\n",
      "[90, 60] loss: 0.169\n",
      "[90, 120] loss: 0.180\n",
      "[90, 180] loss: 0.186\n",
      "[90, 240] loss: 0.177\n",
      "[90, 300] loss: 0.174\n",
      "[90, 360] loss: 0.187\n",
      "Epoch: 90 -> Loss: 0.192623734474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 -> Test Accuracy: 83.08\n",
      "[91, 60] loss: 0.180\n",
      "[91, 120] loss: 0.180\n",
      "[91, 180] loss: 0.175\n",
      "[91, 240] loss: 0.177\n",
      "[91, 300] loss: 0.173\n",
      "[91, 360] loss: 0.176\n",
      "Epoch: 91 -> Loss: 0.14748133719\n",
      "Epoch: 91 -> Test Accuracy: 82.92\n",
      "[92, 60] loss: 0.180\n",
      "[92, 120] loss: 0.181\n",
      "[92, 180] loss: 0.172\n",
      "[92, 240] loss: 0.177\n",
      "[92, 300] loss: 0.182\n",
      "[92, 360] loss: 0.192\n",
      "Epoch: 92 -> Loss: 0.239515498281\n",
      "Epoch: 92 -> Test Accuracy: 83.01\n",
      "[93, 60] loss: 0.183\n",
      "[93, 120] loss: 0.185\n",
      "[93, 180] loss: 0.184\n",
      "[93, 240] loss: 0.180\n",
      "[93, 300] loss: 0.167\n",
      "[93, 360] loss: 0.175\n",
      "Epoch: 93 -> Loss: 0.185495361686\n",
      "Epoch: 93 -> Test Accuracy: 83.09\n",
      "[94, 60] loss: 0.172\n",
      "[94, 120] loss: 0.179\n",
      "[94, 180] loss: 0.180\n",
      "[94, 240] loss: 0.179\n",
      "[94, 300] loss: 0.176\n",
      "[94, 360] loss: 0.175\n",
      "Epoch: 94 -> Loss: 0.238231986761\n",
      "Epoch: 94 -> Test Accuracy: 83.06\n",
      "[95, 60] loss: 0.181\n",
      "[95, 120] loss: 0.171\n",
      "[95, 180] loss: 0.180\n",
      "[95, 240] loss: 0.183\n",
      "[95, 300] loss: 0.183\n",
      "[95, 360] loss: 0.176\n",
      "Epoch: 95 -> Loss: 0.220256850123\n",
      "Epoch: 95 -> Test Accuracy: 83.04\n",
      "[96, 60] loss: 0.169\n",
      "[96, 120] loss: 0.177\n",
      "[96, 180] loss: 0.172\n",
      "[96, 240] loss: 0.173\n",
      "[96, 300] loss: 0.180\n",
      "[96, 360] loss: 0.179\n",
      "Epoch: 96 -> Loss: 0.212572365999\n",
      "Epoch: 96 -> Test Accuracy: 82.93\n",
      "[97, 60] loss: 0.168\n",
      "[97, 120] loss: 0.183\n",
      "[97, 180] loss: 0.176\n",
      "[97, 240] loss: 0.173\n",
      "[97, 300] loss: 0.169\n",
      "[97, 360] loss: 0.177\n",
      "Epoch: 97 -> Loss: 0.182201638818\n",
      "Epoch: 97 -> Test Accuracy: 83.03\n",
      "[98, 60] loss: 0.165\n",
      "[98, 120] loss: 0.180\n",
      "[98, 180] loss: 0.179\n",
      "[98, 240] loss: 0.179\n",
      "[98, 300] loss: 0.166\n",
      "[98, 360] loss: 0.183\n",
      "Epoch: 98 -> Loss: 0.149679690599\n",
      "Epoch: 98 -> Test Accuracy: 83.04\n",
      "[99, 60] loss: 0.168\n",
      "[99, 120] loss: 0.173\n",
      "[99, 180] loss: 0.173\n",
      "[99, 240] loss: 0.172\n",
      "[99, 300] loss: 0.173\n",
      "[99, 360] loss: 0.184\n",
      "Epoch: 99 -> Loss: 0.0804316550493\n",
      "Epoch: 99 -> Test Accuracy: 83.04\n",
      "[100, 60] loss: 0.173\n",
      "[100, 120] loss: 0.180\n",
      "[100, 180] loss: 0.172\n",
      "[100, 240] loss: 0.178\n",
      "[100, 300] loss: 0.169\n",
      "[100, 360] loss: 0.181\n",
      "Epoch: 100 -> Loss: 0.146418690681\n",
      "Epoch: 100 -> Test Accuracy: 82.97\n",
      "Finished Training\n",
      "[1, 60] loss: 2.191\n",
      "[1, 120] loss: 1.411\n",
      "[1, 180] loss: 1.293\n",
      "[1, 240] loss: 1.274\n",
      "[1, 300] loss: 1.200\n",
      "[1, 360] loss: 1.171\n",
      "Epoch: 1 -> Loss: 1.1072422266\n",
      "Epoch: 1 -> Test Accuracy: 54.52\n",
      "[2, 60] loss: 1.121\n",
      "[2, 120] loss: 1.104\n",
      "[2, 180] loss: 1.110\n",
      "[2, 240] loss: 1.076\n",
      "[2, 300] loss: 1.069\n",
      "[2, 360] loss: 1.064\n",
      "Epoch: 2 -> Loss: 1.02581489086\n",
      "Epoch: 2 -> Test Accuracy: 58.09\n",
      "[3, 60] loss: 1.051\n",
      "[3, 120] loss: 1.017\n",
      "[3, 180] loss: 1.026\n",
      "[3, 240] loss: 1.034\n",
      "[3, 300] loss: 1.025\n",
      "[3, 360] loss: 1.030\n",
      "Epoch: 3 -> Loss: 0.966168701649\n",
      "Epoch: 3 -> Test Accuracy: 59.41\n",
      "[4, 60] loss: 1.012\n",
      "[4, 120] loss: 0.994\n",
      "[4, 180] loss: 0.992\n",
      "[4, 240] loss: 0.998\n",
      "[4, 300] loss: 0.998\n",
      "[4, 360] loss: 1.015\n",
      "Epoch: 4 -> Loss: 0.961718380451\n",
      "Epoch: 4 -> Test Accuracy: 58.52\n",
      "[5, 60] loss: 0.991\n",
      "[5, 120] loss: 0.968\n",
      "[5, 180] loss: 0.972\n",
      "[5, 240] loss: 0.983\n",
      "[5, 300] loss: 0.995\n",
      "[5, 360] loss: 0.991\n",
      "Epoch: 5 -> Loss: 1.00417256355\n",
      "Epoch: 5 -> Test Accuracy: 60.82\n",
      "[6, 60] loss: 0.971\n",
      "[6, 120] loss: 0.956\n",
      "[6, 180] loss: 0.967\n",
      "[6, 240] loss: 0.987\n",
      "[6, 300] loss: 0.959\n",
      "[6, 360] loss: 0.962\n",
      "Epoch: 6 -> Loss: 0.975885510445\n",
      "Epoch: 6 -> Test Accuracy: 61.51\n",
      "[7, 60] loss: 0.960\n",
      "[7, 120] loss: 0.972\n",
      "[7, 180] loss: 0.967\n",
      "[7, 240] loss: 0.944\n",
      "[7, 300] loss: 0.948\n",
      "[7, 360] loss: 0.971\n",
      "Epoch: 7 -> Loss: 0.940536499023\n",
      "Epoch: 7 -> Test Accuracy: 61.7\n",
      "[8, 60] loss: 0.931\n",
      "[8, 120] loss: 0.971\n",
      "[8, 180] loss: 0.973\n",
      "[8, 240] loss: 0.940\n",
      "[8, 300] loss: 0.973\n",
      "[8, 360] loss: 0.966\n",
      "Epoch: 8 -> Loss: 0.86392724514\n",
      "Epoch: 8 -> Test Accuracy: 60.51\n",
      "[9, 60] loss: 0.948\n",
      "[9, 120] loss: 0.928\n",
      "[9, 180] loss: 0.951\n",
      "[9, 240] loss: 0.945\n",
      "[9, 300] loss: 0.943\n",
      "[9, 360] loss: 0.946\n",
      "Epoch: 9 -> Loss: 1.06884932518\n",
      "Epoch: 9 -> Test Accuracy: 61.24\n",
      "[10, 60] loss: 0.932\n",
      "[10, 120] loss: 0.942\n",
      "[10, 180] loss: 0.943\n",
      "[10, 240] loss: 0.949\n",
      "[10, 300] loss: 0.945\n",
      "[10, 360] loss: 0.955\n",
      "Epoch: 10 -> Loss: 0.908406853676\n",
      "Epoch: 10 -> Test Accuracy: 61.48\n",
      "[11, 60] loss: 0.934\n",
      "[11, 120] loss: 0.939\n",
      "[11, 180] loss: 0.950\n",
      "[11, 240] loss: 0.936\n",
      "[11, 300] loss: 0.941\n",
      "[11, 360] loss: 0.934\n",
      "Epoch: 11 -> Loss: 1.08785414696\n",
      "Epoch: 11 -> Test Accuracy: 62.19\n",
      "[12, 60] loss: 0.931\n",
      "[12, 120] loss: 0.945\n",
      "[12, 180] loss: 0.934\n",
      "[12, 240] loss: 0.952\n",
      "[12, 300] loss: 0.939\n",
      "[12, 360] loss: 0.940\n",
      "Epoch: 12 -> Loss: 1.28531646729\n",
      "Epoch: 12 -> Test Accuracy: 61.53\n",
      "[13, 60] loss: 0.931\n",
      "[13, 120] loss: 0.920\n",
      "[13, 180] loss: 0.940\n",
      "[13, 240] loss: 0.926\n",
      "[13, 300] loss: 0.959\n",
      "[13, 360] loss: 0.952\n",
      "Epoch: 13 -> Loss: 0.959764003754\n",
      "Epoch: 13 -> Test Accuracy: 60.51\n",
      "[14, 60] loss: 0.905\n",
      "[14, 120] loss: 0.922\n",
      "[14, 180] loss: 0.967\n",
      "[14, 240] loss: 0.941\n",
      "[14, 300] loss: 0.941\n",
      "[14, 360] loss: 0.936\n",
      "Epoch: 14 -> Loss: 1.20246744156\n",
      "Epoch: 14 -> Test Accuracy: 61.52\n",
      "[15, 60] loss: 0.931\n",
      "[15, 120] loss: 0.916\n",
      "[15, 180] loss: 0.928\n",
      "[15, 240] loss: 0.939\n",
      "[15, 300] loss: 0.939\n",
      "[15, 360] loss: 0.931\n",
      "Epoch: 15 -> Loss: 1.19631075859\n",
      "Epoch: 15 -> Test Accuracy: 61.61\n",
      "[16, 60] loss: 0.908\n",
      "[16, 120] loss: 0.943\n",
      "[16, 180] loss: 0.936\n",
      "[16, 240] loss: 0.939\n",
      "[16, 300] loss: 0.912\n",
      "[16, 360] loss: 0.945\n",
      "Epoch: 16 -> Loss: 1.02553844452\n",
      "Epoch: 16 -> Test Accuracy: 62.09\n",
      "[17, 60] loss: 0.914\n",
      "[17, 120] loss: 0.908\n",
      "[17, 180] loss: 0.922\n",
      "[17, 240] loss: 0.934\n",
      "[17, 300] loss: 0.939\n",
      "[17, 360] loss: 0.940\n",
      "Epoch: 17 -> Loss: 1.01609575748\n",
      "Epoch: 17 -> Test Accuracy: 62.29\n",
      "[18, 60] loss: 0.912\n",
      "[18, 120] loss: 0.934\n",
      "[18, 180] loss: 0.923\n",
      "[18, 240] loss: 0.916\n",
      "[18, 300] loss: 0.941\n",
      "[18, 360] loss: 0.952\n",
      "Epoch: 18 -> Loss: 1.16538918018\n",
      "Epoch: 18 -> Test Accuracy: 62.28\n",
      "[19, 60] loss: 0.926\n",
      "[19, 120] loss: 0.938\n",
      "[19, 180] loss: 0.921\n",
      "[19, 240] loss: 0.918\n",
      "[19, 300] loss: 0.941\n",
      "[19, 360] loss: 0.934\n",
      "Epoch: 19 -> Loss: 0.869778990746\n",
      "Epoch: 19 -> Test Accuracy: 61.93\n",
      "[20, 60] loss: 0.911\n",
      "[20, 120] loss: 0.939\n",
      "[20, 180] loss: 0.927\n",
      "[20, 240] loss: 0.928\n",
      "[20, 300] loss: 0.936\n",
      "[20, 360] loss: 0.905\n",
      "Epoch: 20 -> Loss: 1.12866854668\n",
      "Epoch: 20 -> Test Accuracy: 62.0\n",
      "[21, 60] loss: 0.877\n",
      "[21, 120] loss: 0.862\n",
      "[21, 180] loss: 0.832\n",
      "[21, 240] loss: 0.828\n",
      "[21, 300] loss: 0.830\n",
      "[21, 360] loss: 0.825\n",
      "Epoch: 21 -> Loss: 0.546085119247\n",
      "Epoch: 21 -> Test Accuracy: 65.45\n",
      "[22, 60] loss: 0.816\n",
      "[22, 120] loss: 0.801\n",
      "[22, 180] loss: 0.819\n",
      "[22, 240] loss: 0.801\n",
      "[22, 300] loss: 0.816\n",
      "[22, 360] loss: 0.820\n",
      "Epoch: 22 -> Loss: 0.864797472954\n",
      "Epoch: 22 -> Test Accuracy: 65.57\n",
      "[23, 60] loss: 0.806\n",
      "[23, 120] loss: 0.783\n",
      "[23, 180] loss: 0.813\n",
      "[23, 240] loss: 0.791\n",
      "[23, 300] loss: 0.782\n",
      "[23, 360] loss: 0.804\n",
      "Epoch: 23 -> Loss: 0.625189900398\n",
      "Epoch: 23 -> Test Accuracy: 66.0\n",
      "[24, 60] loss: 0.771\n",
      "[24, 120] loss: 0.804\n",
      "[24, 180] loss: 0.788\n",
      "[24, 240] loss: 0.781\n",
      "[24, 300] loss: 0.800\n",
      "[24, 360] loss: 0.787\n",
      "Epoch: 24 -> Loss: 0.84089076519\n",
      "Epoch: 24 -> Test Accuracy: 66.16\n",
      "[25, 60] loss: 0.786\n",
      "[25, 120] loss: 0.788\n",
      "[25, 180] loss: 0.784\n",
      "[25, 240] loss: 0.774\n",
      "[25, 300] loss: 0.773\n",
      "[25, 360] loss: 0.805\n",
      "Epoch: 25 -> Loss: 0.655754864216\n",
      "Epoch: 25 -> Test Accuracy: 66.12\n",
      "[26, 60] loss: 0.766\n",
      "[26, 120] loss: 0.781\n",
      "[26, 180] loss: 0.785\n",
      "[26, 240] loss: 0.781\n",
      "[26, 300] loss: 0.783\n",
      "[26, 360] loss: 0.785\n",
      "Epoch: 26 -> Loss: 0.708276152611\n",
      "Epoch: 26 -> Test Accuracy: 66.19\n",
      "[27, 60] loss: 0.783\n",
      "[27, 120] loss: 0.780\n",
      "[27, 180] loss: 0.792\n",
      "[27, 240] loss: 0.772\n",
      "[27, 300] loss: 0.776\n",
      "[27, 360] loss: 0.775\n",
      "Epoch: 27 -> Loss: 0.649144768715\n",
      "Epoch: 27 -> Test Accuracy: 66.7\n",
      "[28, 60] loss: 0.771\n",
      "[28, 120] loss: 0.762\n",
      "[28, 180] loss: 0.782\n",
      "[28, 240] loss: 0.795\n",
      "[28, 300] loss: 0.772\n",
      "[28, 360] loss: 0.764\n",
      "Epoch: 28 -> Loss: 0.884694218636\n",
      "Epoch: 28 -> Test Accuracy: 66.4\n",
      "[29, 60] loss: 0.771\n",
      "[29, 120] loss: 0.769\n",
      "[29, 180] loss: 0.769\n",
      "[29, 240] loss: 0.778\n",
      "[29, 300] loss: 0.765\n",
      "[29, 360] loss: 0.800\n",
      "Epoch: 29 -> Loss: 0.625299572945\n",
      "Epoch: 29 -> Test Accuracy: 66.38\n",
      "[30, 60] loss: 0.775\n",
      "[30, 120] loss: 0.778\n",
      "[30, 180] loss: 0.765\n",
      "[30, 240] loss: 0.763\n",
      "[30, 300] loss: 0.758\n",
      "[30, 360] loss: 0.784\n",
      "Epoch: 30 -> Loss: 0.741673648357\n",
      "Epoch: 30 -> Test Accuracy: 67.06\n",
      "[31, 60] loss: 0.778\n",
      "[31, 120] loss: 0.775\n",
      "[31, 180] loss: 0.784\n",
      "[31, 240] loss: 0.758\n",
      "[31, 300] loss: 0.775\n",
      "[31, 360] loss: 0.782\n",
      "Epoch: 31 -> Loss: 0.803859353065\n",
      "Epoch: 31 -> Test Accuracy: 67.04\n",
      "[32, 60] loss: 0.778\n",
      "[32, 120] loss: 0.789\n",
      "[32, 180] loss: 0.765\n",
      "[32, 240] loss: 0.780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 300] loss: 0.744\n",
      "[32, 360] loss: 0.786\n",
      "Epoch: 32 -> Loss: 0.690040707588\n",
      "Epoch: 32 -> Test Accuracy: 66.67\n",
      "[33, 60] loss: 0.743\n",
      "[33, 120] loss: 0.766\n",
      "[33, 180] loss: 0.795\n",
      "[33, 240] loss: 0.792\n",
      "[33, 300] loss: 0.764\n",
      "[33, 360] loss: 0.770\n",
      "Epoch: 33 -> Loss: 0.762346923351\n",
      "Epoch: 33 -> Test Accuracy: 65.95\n",
      "[34, 60] loss: 0.767\n",
      "[34, 120] loss: 0.775\n",
      "[34, 180] loss: 0.757\n",
      "[34, 240] loss: 0.787\n",
      "[34, 300] loss: 0.761\n",
      "[34, 360] loss: 0.792\n",
      "Epoch: 34 -> Loss: 0.779279351234\n",
      "Epoch: 34 -> Test Accuracy: 66.19\n",
      "[35, 60] loss: 0.756\n",
      "[35, 120] loss: 0.760\n",
      "[35, 180] loss: 0.769\n",
      "[35, 240] loss: 0.775\n",
      "[35, 300] loss: 0.750\n",
      "[35, 360] loss: 0.779\n",
      "Epoch: 35 -> Loss: 0.849234938622\n",
      "Epoch: 35 -> Test Accuracy: 66.46\n",
      "[36, 60] loss: 0.766\n",
      "[36, 120] loss: 0.775\n",
      "[36, 180] loss: 0.779\n",
      "[36, 240] loss: 0.763\n",
      "[36, 300] loss: 0.766\n",
      "[36, 360] loss: 0.771\n",
      "Epoch: 36 -> Loss: 0.688422560692\n",
      "Epoch: 36 -> Test Accuracy: 66.25\n",
      "[37, 60] loss: 0.763\n",
      "[37, 120] loss: 0.778\n",
      "[37, 180] loss: 0.780\n",
      "[37, 240] loss: 0.772\n",
      "[37, 300] loss: 0.773\n",
      "[37, 360] loss: 0.758\n",
      "Epoch: 37 -> Loss: 0.747616291046\n",
      "Epoch: 37 -> Test Accuracy: 66.73\n",
      "[38, 60] loss: 0.767\n",
      "[38, 120] loss: 0.764\n",
      "[38, 180] loss: 0.769\n",
      "[38, 240] loss: 0.765\n",
      "[38, 300] loss: 0.776\n",
      "[38, 360] loss: 0.772\n",
      "Epoch: 38 -> Loss: 0.751553595066\n",
      "Epoch: 38 -> Test Accuracy: 66.08\n",
      "[39, 60] loss: 0.754\n",
      "[39, 120] loss: 0.766\n",
      "[39, 180] loss: 0.767\n",
      "[39, 240] loss: 0.778\n",
      "[39, 300] loss: 0.768\n",
      "[39, 360] loss: 0.773\n",
      "Epoch: 39 -> Loss: 0.776242017746\n",
      "Epoch: 39 -> Test Accuracy: 66.43\n",
      "[40, 60] loss: 0.760\n",
      "[40, 120] loss: 0.764\n",
      "[40, 180] loss: 0.756\n",
      "[40, 240] loss: 0.775\n",
      "[40, 300] loss: 0.788\n",
      "[40, 360] loss: 0.775\n",
      "Epoch: 40 -> Loss: 0.843619525433\n",
      "Epoch: 40 -> Test Accuracy: 65.76\n",
      "[41, 60] loss: 0.751\n",
      "[41, 120] loss: 0.711\n",
      "[41, 180] loss: 0.742\n",
      "[41, 240] loss: 0.722\n",
      "[41, 300] loss: 0.712\n",
      "[41, 360] loss: 0.721\n",
      "Epoch: 41 -> Loss: 0.713569521904\n",
      "Epoch: 41 -> Test Accuracy: 68.03\n",
      "[42, 60] loss: 0.690\n",
      "[42, 120] loss: 0.705\n",
      "[42, 180] loss: 0.710\n",
      "[42, 240] loss: 0.697\n",
      "[42, 300] loss: 0.706\n",
      "[42, 360] loss: 0.697\n",
      "Epoch: 42 -> Loss: 0.626388788223\n",
      "Epoch: 42 -> Test Accuracy: 68.68\n",
      "[43, 60] loss: 0.712\n",
      "[43, 120] loss: 0.703\n",
      "[43, 180] loss: 0.710\n",
      "[43, 240] loss: 0.691\n",
      "[43, 300] loss: 0.694\n",
      "[43, 360] loss: 0.690\n",
      "Epoch: 43 -> Loss: 0.735307097435\n",
      "Epoch: 43 -> Test Accuracy: 68.41\n",
      "[44, 60] loss: 0.698\n",
      "[44, 120] loss: 0.692\n",
      "[44, 180] loss: 0.681\n",
      "[44, 240] loss: 0.697\n",
      "[44, 300] loss: 0.665\n",
      "[44, 360] loss: 0.680\n",
      "Epoch: 44 -> Loss: 0.678746581078\n",
      "Epoch: 44 -> Test Accuracy: 68.55\n",
      "[45, 60] loss: 0.666\n",
      "[45, 120] loss: 0.685\n",
      "[45, 180] loss: 0.689\n",
      "[45, 240] loss: 0.688\n",
      "[45, 300] loss: 0.679\n",
      "[45, 360] loss: 0.680\n",
      "Epoch: 45 -> Loss: 0.768225312233\n",
      "Epoch: 45 -> Test Accuracy: 69.03\n",
      "[46, 60] loss: 0.688\n",
      "[46, 120] loss: 0.678\n",
      "[46, 180] loss: 0.665\n",
      "[46, 240] loss: 0.676\n",
      "[46, 300] loss: 0.664\n",
      "[46, 360] loss: 0.656\n",
      "Epoch: 46 -> Loss: 0.595205187798\n",
      "Epoch: 46 -> Test Accuracy: 69.19\n",
      "[47, 60] loss: 0.664\n",
      "[47, 120] loss: 0.668\n",
      "[47, 180] loss: 0.688\n",
      "[47, 240] loss: 0.678\n",
      "[47, 300] loss: 0.662\n",
      "[47, 360] loss: 0.654\n",
      "Epoch: 47 -> Loss: 0.698985099792\n",
      "Epoch: 47 -> Test Accuracy: 69.35\n",
      "[48, 60] loss: 0.664\n",
      "[48, 120] loss: 0.673\n",
      "[48, 180] loss: 0.679\n",
      "[48, 240] loss: 0.654\n",
      "[48, 300] loss: 0.669\n",
      "[48, 360] loss: 0.646\n",
      "Epoch: 48 -> Loss: 0.639390289783\n",
      "Epoch: 48 -> Test Accuracy: 69.33\n",
      "[49, 60] loss: 0.669\n",
      "[49, 120] loss: 0.659\n",
      "[49, 180] loss: 0.680\n",
      "[49, 240] loss: 0.662\n",
      "[49, 300] loss: 0.650\n",
      "[49, 360] loss: 0.657\n",
      "Epoch: 49 -> Loss: 0.783468723297\n",
      "Epoch: 49 -> Test Accuracy: 69.36\n",
      "[50, 60] loss: 0.653\n",
      "[50, 120] loss: 0.659\n",
      "[50, 180] loss: 0.673\n",
      "[50, 240] loss: 0.660\n",
      "[50, 300] loss: 0.661\n",
      "[50, 360] loss: 0.647\n",
      "Epoch: 50 -> Loss: 0.562859535217\n",
      "Epoch: 50 -> Test Accuracy: 69.38\n",
      "[51, 60] loss: 0.660\n",
      "[51, 120] loss: 0.678\n",
      "[51, 180] loss: 0.665\n",
      "[51, 240] loss: 0.652\n",
      "[51, 300] loss: 0.646\n",
      "[51, 360] loss: 0.649\n",
      "Epoch: 51 -> Loss: 0.696938157082\n",
      "Epoch: 51 -> Test Accuracy: 69.43\n",
      "[52, 60] loss: 0.662\n",
      "[52, 120] loss: 0.652\n",
      "[52, 180] loss: 0.660\n",
      "[52, 240] loss: 0.655\n",
      "[52, 300] loss: 0.660\n",
      "[52, 360] loss: 0.664\n",
      "Epoch: 52 -> Loss: 0.688036859035\n",
      "Epoch: 52 -> Test Accuracy: 69.33\n",
      "[53, 60] loss: 0.660\n",
      "[53, 120] loss: 0.668\n",
      "[53, 180] loss: 0.645\n",
      "[53, 240] loss: 0.652\n",
      "[53, 300] loss: 0.672\n",
      "[53, 360] loss: 0.642\n",
      "Epoch: 53 -> Loss: 0.538119316101\n",
      "Epoch: 53 -> Test Accuracy: 69.44\n",
      "[54, 60] loss: 0.652\n",
      "[54, 120] loss: 0.659\n",
      "[54, 180] loss: 0.654\n",
      "[54, 240] loss: 0.662\n",
      "[54, 300] loss: 0.657\n",
      "[54, 360] loss: 0.663\n",
      "Epoch: 54 -> Loss: 0.616702497005\n",
      "Epoch: 54 -> Test Accuracy: 69.42\n",
      "[55, 60] loss: 0.660\n",
      "[55, 120] loss: 0.649\n",
      "[55, 180] loss: 0.652\n",
      "[55, 240] loss: 0.642\n",
      "[55, 300] loss: 0.669\n",
      "[55, 360] loss: 0.662\n",
      "Epoch: 55 -> Loss: 0.642870426178\n",
      "Epoch: 55 -> Test Accuracy: 69.42\n",
      "[56, 60] loss: 0.659\n",
      "[56, 120] loss: 0.649\n",
      "[56, 180] loss: 0.648\n",
      "[56, 240] loss: 0.654\n",
      "[56, 300] loss: 0.662\n",
      "[56, 360] loss: 0.644\n",
      "Epoch: 56 -> Loss: 0.751730680466\n",
      "Epoch: 56 -> Test Accuracy: 69.29\n",
      "[57, 60] loss: 0.650\n",
      "[57, 120] loss: 0.660\n",
      "[57, 180] loss: 0.641\n",
      "[57, 240] loss: 0.676\n",
      "[57, 300] loss: 0.644\n",
      "[57, 360] loss: 0.661\n",
      "Epoch: 57 -> Loss: 0.798629641533\n",
      "Epoch: 57 -> Test Accuracy: 69.15\n",
      "[58, 60] loss: 0.650\n",
      "[58, 120] loss: 0.657\n",
      "[58, 180] loss: 0.652\n",
      "[58, 240] loss: 0.645\n",
      "[58, 300] loss: 0.642\n",
      "[58, 360] loss: 0.658\n",
      "Epoch: 58 -> Loss: 0.483989775181\n",
      "Epoch: 58 -> Test Accuracy: 69.59\n",
      "[59, 60] loss: 0.650\n",
      "[59, 120] loss: 0.652\n",
      "[59, 180] loss: 0.668\n",
      "[59, 240] loss: 0.648\n",
      "[59, 300] loss: 0.644\n",
      "[59, 360] loss: 0.673\n",
      "Epoch: 59 -> Loss: 0.638101160526\n",
      "Epoch: 59 -> Test Accuracy: 69.45\n",
      "[60, 60] loss: 0.643\n",
      "[60, 120] loss: 0.650\n",
      "[60, 180] loss: 0.637\n",
      "[60, 240] loss: 0.641\n",
      "[60, 300] loss: 0.644\n",
      "[60, 360] loss: 0.660\n",
      "Epoch: 60 -> Loss: 0.696840405464\n",
      "Epoch: 60 -> Test Accuracy: 69.75\n",
      "[61, 60] loss: 0.662\n",
      "[61, 120] loss: 0.634\n",
      "[61, 180] loss: 0.662\n",
      "[61, 240] loss: 0.667\n",
      "[61, 300] loss: 0.646\n",
      "[61, 360] loss: 0.643\n",
      "Epoch: 61 -> Loss: 0.763362109661\n",
      "Epoch: 61 -> Test Accuracy: 69.69\n",
      "[62, 60] loss: 0.642\n",
      "[62, 120] loss: 0.646\n",
      "[62, 180] loss: 0.656\n",
      "[62, 240] loss: 0.660\n",
      "[62, 300] loss: 0.646\n",
      "[62, 360] loss: 0.644\n",
      "Epoch: 62 -> Loss: 0.699550271034\n",
      "Epoch: 62 -> Test Accuracy: 69.66\n",
      "[63, 60] loss: 0.647\n",
      "[63, 120] loss: 0.667\n",
      "[63, 180] loss: 0.631\n",
      "[63, 240] loss: 0.670\n",
      "[63, 300] loss: 0.651\n",
      "[63, 360] loss: 0.650\n",
      "Epoch: 63 -> Loss: 0.710153996944\n",
      "Epoch: 63 -> Test Accuracy: 69.61\n",
      "[64, 60] loss: 0.646\n",
      "[64, 120] loss: 0.644\n",
      "[64, 180] loss: 0.653\n",
      "[64, 240] loss: 0.645\n",
      "[64, 300] loss: 0.659\n",
      "[64, 360] loss: 0.668\n",
      "Epoch: 64 -> Loss: 0.535039722919\n",
      "Epoch: 64 -> Test Accuracy: 69.48\n",
      "[65, 60] loss: 0.645\n",
      "[65, 120] loss: 0.664\n",
      "[65, 180] loss: 0.646\n",
      "[65, 240] loss: 0.638\n",
      "[65, 300] loss: 0.646\n",
      "[65, 360] loss: 0.649\n",
      "Epoch: 65 -> Loss: 0.621975839138\n",
      "Epoch: 65 -> Test Accuracy: 69.49\n",
      "[66, 60] loss: 0.657\n",
      "[66, 120] loss: 0.644\n",
      "[66, 180] loss: 0.656\n",
      "[66, 240] loss: 0.653\n",
      "[66, 300] loss: 0.628\n",
      "[66, 360] loss: 0.653\n",
      "Epoch: 66 -> Loss: 0.821982860565\n",
      "Epoch: 66 -> Test Accuracy: 69.38\n",
      "[67, 60] loss: 0.641\n",
      "[67, 120] loss: 0.644\n",
      "[67, 180] loss: 0.629\n",
      "[67, 240] loss: 0.655\n",
      "[67, 300] loss: 0.654\n",
      "[67, 360] loss: 0.642\n",
      "Epoch: 67 -> Loss: 0.694625020027\n",
      "Epoch: 67 -> Test Accuracy: 69.5\n",
      "[68, 60] loss: 0.641\n",
      "[68, 120] loss: 0.659\n",
      "[68, 180] loss: 0.656\n",
      "[68, 240] loss: 0.637\n",
      "[68, 300] loss: 0.634\n",
      "[68, 360] loss: 0.644\n",
      "Epoch: 68 -> Loss: 0.623920977116\n",
      "Epoch: 68 -> Test Accuracy: 69.86\n",
      "[69, 60] loss: 0.652\n",
      "[69, 120] loss: 0.649\n",
      "[69, 180] loss: 0.631\n",
      "[69, 240] loss: 0.632\n",
      "[69, 300] loss: 0.656\n",
      "[69, 360] loss: 0.655\n",
      "Epoch: 69 -> Loss: 0.678097784519\n",
      "Epoch: 69 -> Test Accuracy: 69.7\n",
      "[70, 60] loss: 0.644\n",
      "[70, 120] loss: 0.649\n",
      "[70, 180] loss: 0.637\n",
      "[70, 240] loss: 0.638\n",
      "[70, 300] loss: 0.641\n",
      "[70, 360] loss: 0.647\n",
      "Epoch: 70 -> Loss: 0.620460629463\n",
      "Epoch: 70 -> Test Accuracy: 69.66\n",
      "[71, 60] loss: 0.662\n",
      "[71, 120] loss: 0.637\n",
      "[71, 180] loss: 0.648\n",
      "[71, 240] loss: 0.631\n",
      "[71, 300] loss: 0.635\n",
      "[71, 360] loss: 0.641\n",
      "Epoch: 71 -> Loss: 0.656400978565\n",
      "Epoch: 71 -> Test Accuracy: 69.74\n",
      "[72, 60] loss: 0.639\n",
      "[72, 120] loss: 0.649\n",
      "[72, 180] loss: 0.637\n",
      "[72, 240] loss: 0.642\n",
      "[72, 300] loss: 0.637\n",
      "[72, 360] loss: 0.654\n",
      "Epoch: 72 -> Loss: 0.710140585899\n",
      "Epoch: 72 -> Test Accuracy: 69.77\n",
      "[73, 60] loss: 0.614\n",
      "[73, 120] loss: 0.632\n",
      "[73, 180] loss: 0.658\n",
      "[73, 240] loss: 0.634\n",
      "[73, 300] loss: 0.647\n",
      "[73, 360] loss: 0.659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 -> Loss: 0.700736165047\n",
      "Epoch: 73 -> Test Accuracy: 69.54\n",
      "[74, 60] loss: 0.647\n",
      "[74, 120] loss: 0.634\n",
      "[74, 180] loss: 0.667\n",
      "[74, 240] loss: 0.639\n",
      "[74, 300] loss: 0.641\n",
      "[74, 360] loss: 0.618\n",
      "Epoch: 74 -> Loss: 0.669369578362\n",
      "Epoch: 74 -> Test Accuracy: 69.71\n",
      "[75, 60] loss: 0.645\n",
      "[75, 120] loss: 0.641\n",
      "[75, 180] loss: 0.629\n",
      "[75, 240] loss: 0.642\n",
      "[75, 300] loss: 0.644\n",
      "[75, 360] loss: 0.644\n",
      "Epoch: 75 -> Loss: 0.803560137749\n",
      "Epoch: 75 -> Test Accuracy: 69.62\n",
      "[76, 60] loss: 0.642\n",
      "[76, 120] loss: 0.633\n",
      "[76, 180] loss: 0.640\n",
      "[76, 240] loss: 0.647\n",
      "[76, 300] loss: 0.662\n",
      "[76, 360] loss: 0.637\n",
      "Epoch: 76 -> Loss: 0.694324374199\n",
      "Epoch: 76 -> Test Accuracy: 69.74\n",
      "[77, 60] loss: 0.633\n",
      "[77, 120] loss: 0.630\n",
      "[77, 180] loss: 0.655\n",
      "[77, 240] loss: 0.650\n",
      "[77, 300] loss: 0.641\n",
      "[77, 360] loss: 0.630\n",
      "Epoch: 77 -> Loss: 0.598105728626\n",
      "Epoch: 77 -> Test Accuracy: 69.8\n",
      "[78, 60] loss: 0.644\n",
      "[78, 120] loss: 0.619\n",
      "[78, 180] loss: 0.648\n",
      "[78, 240] loss: 0.615\n",
      "[78, 300] loss: 0.636\n",
      "[78, 360] loss: 0.645\n",
      "Epoch: 78 -> Loss: 0.749642312527\n",
      "Epoch: 78 -> Test Accuracy: 70.05\n",
      "[79, 60] loss: 0.628\n",
      "[79, 120] loss: 0.638\n",
      "[79, 180] loss: 0.631\n",
      "[79, 240] loss: 0.632\n",
      "[79, 300] loss: 0.650\n",
      "[79, 360] loss: 0.624\n",
      "Epoch: 79 -> Loss: 0.632800340652\n",
      "Epoch: 79 -> Test Accuracy: 69.88\n",
      "[80, 60] loss: 0.633\n",
      "[80, 120] loss: 0.650\n",
      "[80, 180] loss: 0.639\n",
      "[80, 240] loss: 0.630\n",
      "[80, 300] loss: 0.622\n",
      "[80, 360] loss: 0.618\n",
      "Epoch: 80 -> Loss: 0.958995938301\n",
      "Epoch: 80 -> Test Accuracy: 69.8\n",
      "[81, 60] loss: 0.642\n",
      "[81, 120] loss: 0.638\n",
      "[81, 180] loss: 0.647\n",
      "[81, 240] loss: 0.612\n",
      "[81, 300] loss: 0.652\n",
      "[81, 360] loss: 0.631\n",
      "Epoch: 81 -> Loss: 0.690440773964\n",
      "Epoch: 81 -> Test Accuracy: 69.42\n",
      "[82, 60] loss: 0.637\n",
      "[82, 120] loss: 0.634\n",
      "[82, 180] loss: 0.647\n",
      "[82, 240] loss: 0.619\n",
      "[82, 300] loss: 0.629\n",
      "[82, 360] loss: 0.645\n",
      "Epoch: 82 -> Loss: 0.641621172428\n",
      "Epoch: 82 -> Test Accuracy: 69.59\n",
      "[83, 60] loss: 0.645\n",
      "[83, 120] loss: 0.617\n",
      "[83, 180] loss: 0.642\n",
      "[83, 240] loss: 0.634\n",
      "[83, 300] loss: 0.632\n",
      "[83, 360] loss: 0.624\n",
      "Epoch: 83 -> Loss: 0.697280168533\n",
      "Epoch: 83 -> Test Accuracy: 69.66\n",
      "[84, 60] loss: 0.638\n",
      "[84, 120] loss: 0.619\n",
      "[84, 180] loss: 0.638\n",
      "[84, 240] loss: 0.629\n",
      "[84, 300] loss: 0.631\n",
      "[84, 360] loss: 0.621\n",
      "Epoch: 84 -> Loss: 0.647112727165\n",
      "Epoch: 84 -> Test Accuracy: 69.72\n",
      "[85, 60] loss: 0.630\n",
      "[85, 120] loss: 0.636\n",
      "[85, 180] loss: 0.639\n",
      "[85, 240] loss: 0.626\n",
      "[85, 300] loss: 0.640\n",
      "[85, 360] loss: 0.638\n",
      "Epoch: 85 -> Loss: 0.610825896263\n",
      "Epoch: 85 -> Test Accuracy: 70.06\n",
      "[86, 60] loss: 0.637\n",
      "[86, 120] loss: 0.628\n",
      "[86, 180] loss: 0.619\n",
      "[86, 240] loss: 0.637\n",
      "[86, 300] loss: 0.628\n",
      "[86, 360] loss: 0.649\n",
      "Epoch: 86 -> Loss: 0.554062187672\n",
      "Epoch: 86 -> Test Accuracy: 69.92\n",
      "[87, 60] loss: 0.638\n",
      "[87, 120] loss: 0.630\n",
      "[87, 180] loss: 0.628\n",
      "[87, 240] loss: 0.623\n",
      "[87, 300] loss: 0.653\n",
      "[87, 360] loss: 0.616\n",
      "Epoch: 87 -> Loss: 0.611580133438\n",
      "Epoch: 87 -> Test Accuracy: 69.89\n",
      "[88, 60] loss: 0.637\n",
      "[88, 120] loss: 0.623\n",
      "[88, 180] loss: 0.629\n",
      "[88, 240] loss: 0.640\n",
      "[88, 300] loss: 0.619\n",
      "[88, 360] loss: 0.645\n",
      "Epoch: 88 -> Loss: 0.47976565361\n",
      "Epoch: 88 -> Test Accuracy: 69.83\n",
      "[89, 60] loss: 0.623\n",
      "[89, 120] loss: 0.613\n",
      "[89, 180] loss: 0.635\n",
      "[89, 240] loss: 0.627\n",
      "[89, 300] loss: 0.633\n",
      "[89, 360] loss: 0.609\n",
      "Epoch: 89 -> Loss: 0.70491284132\n",
      "Epoch: 89 -> Test Accuracy: 69.89\n",
      "[90, 60] loss: 0.625\n",
      "[90, 120] loss: 0.621\n",
      "[90, 180] loss: 0.614\n",
      "[90, 240] loss: 0.652\n",
      "[90, 300] loss: 0.623\n",
      "[90, 360] loss: 0.636\n",
      "Epoch: 90 -> Loss: 0.626114428043\n",
      "Epoch: 90 -> Test Accuracy: 70.03\n",
      "[91, 60] loss: 0.635\n",
      "[91, 120] loss: 0.635\n",
      "[91, 180] loss: 0.632\n",
      "[91, 240] loss: 0.636\n",
      "[91, 300] loss: 0.617\n",
      "[91, 360] loss: 0.622\n",
      "Epoch: 91 -> Loss: 0.859375178814\n",
      "Epoch: 91 -> Test Accuracy: 70.14\n",
      "[92, 60] loss: 0.611\n",
      "[92, 120] loss: 0.625\n",
      "[92, 180] loss: 0.640\n",
      "[92, 240] loss: 0.622\n",
      "[92, 300] loss: 0.612\n",
      "[92, 360] loss: 0.641\n",
      "Epoch: 92 -> Loss: 0.588716387749\n",
      "Epoch: 92 -> Test Accuracy: 70.05\n",
      "[93, 60] loss: 0.635\n",
      "[93, 120] loss: 0.616\n",
      "[93, 180] loss: 0.643\n",
      "[93, 240] loss: 0.621\n",
      "[93, 300] loss: 0.616\n",
      "[93, 360] loss: 0.617\n",
      "Epoch: 93 -> Loss: 0.561856329441\n",
      "Epoch: 93 -> Test Accuracy: 70.12\n",
      "[94, 60] loss: 0.629\n",
      "[94, 120] loss: 0.627\n",
      "[94, 180] loss: 0.625\n",
      "[94, 240] loss: 0.627\n",
      "[94, 300] loss: 0.629\n",
      "[94, 360] loss: 0.621\n",
      "Epoch: 94 -> Loss: 0.762690365314\n",
      "Epoch: 94 -> Test Accuracy: 69.94\n",
      "[95, 60] loss: 0.644\n",
      "[95, 120] loss: 0.624\n",
      "[95, 180] loss: 0.620\n",
      "[95, 240] loss: 0.637\n",
      "[95, 300] loss: 0.637\n",
      "[95, 360] loss: 0.603\n",
      "Epoch: 95 -> Loss: 0.640201508999\n",
      "Epoch: 95 -> Test Accuracy: 70.29\n",
      "[96, 60] loss: 0.618\n",
      "[96, 120] loss: 0.631\n",
      "[96, 180] loss: 0.639\n",
      "[96, 240] loss: 0.619\n",
      "[96, 300] loss: 0.612\n",
      "[96, 360] loss: 0.624\n",
      "Epoch: 96 -> Loss: 0.531246304512\n",
      "Epoch: 96 -> Test Accuracy: 70.02\n",
      "[97, 60] loss: 0.631\n",
      "[97, 120] loss: 0.605\n",
      "[97, 180] loss: 0.631\n",
      "[97, 240] loss: 0.626\n",
      "[97, 300] loss: 0.616\n",
      "[97, 360] loss: 0.621\n",
      "Epoch: 97 -> Loss: 0.565261721611\n",
      "Epoch: 97 -> Test Accuracy: 70.1\n",
      "[98, 60] loss: 0.627\n",
      "[98, 120] loss: 0.638\n",
      "[98, 180] loss: 0.625\n",
      "[98, 240] loss: 0.621\n",
      "[98, 300] loss: 0.623\n",
      "[98, 360] loss: 0.624\n",
      "Epoch: 98 -> Loss: 0.565526306629\n",
      "Epoch: 98 -> Test Accuracy: 70.16\n",
      "[99, 60] loss: 0.616\n",
      "[99, 120] loss: 0.612\n",
      "[99, 180] loss: 0.634\n",
      "[99, 240] loss: 0.632\n",
      "[99, 300] loss: 0.610\n",
      "[99, 360] loss: 0.627\n",
      "Epoch: 99 -> Loss: 0.834654927254\n",
      "Epoch: 99 -> Test Accuracy: 69.94\n",
      "[100, 60] loss: 0.627\n",
      "[100, 120] loss: 0.613\n",
      "[100, 180] loss: 0.629\n",
      "[100, 240] loss: 0.619\n",
      "[100, 300] loss: 0.611\n",
      "[100, 360] loss: 0.620\n",
      "Epoch: 100 -> Loss: 0.538132488728\n",
      "Epoch: 100 -> Test Accuracy: 69.83\n",
      "Finished Training\n",
      "[1, 60] loss: 2.794\n",
      "[1, 120] loss: 2.127\n",
      "[1, 180] loss: 2.073\n",
      "[1, 240] loss: 2.061\n",
      "[1, 300] loss: 2.013\n",
      "[1, 360] loss: 1.991\n",
      "Epoch: 1 -> Loss: 2.12518143654\n",
      "Epoch: 1 -> Test Accuracy: 27.64\n",
      "[2, 60] loss: 1.970\n",
      "[2, 120] loss: 1.951\n",
      "[2, 180] loss: 1.961\n",
      "[2, 240] loss: 1.935\n",
      "[2, 300] loss: 1.932\n",
      "[2, 360] loss: 1.922\n",
      "Epoch: 2 -> Loss: 2.13803625107\n",
      "Epoch: 2 -> Test Accuracy: 27.98\n",
      "[3, 60] loss: 1.923\n",
      "[3, 120] loss: 1.902\n",
      "[3, 180] loss: 1.897\n",
      "[3, 240] loss: 1.902\n",
      "[3, 300] loss: 1.894\n",
      "[3, 360] loss: 1.878\n",
      "Epoch: 3 -> Loss: 1.90916764736\n",
      "Epoch: 3 -> Test Accuracy: 29.29\n",
      "[4, 60] loss: 1.902\n",
      "[4, 120] loss: 1.885\n",
      "[4, 180] loss: 1.865\n",
      "[4, 240] loss: 1.872\n",
      "[4, 300] loss: 1.887\n",
      "[4, 360] loss: 1.885\n",
      "Epoch: 4 -> Loss: 1.76940464973\n",
      "Epoch: 4 -> Test Accuracy: 29.57\n",
      "[5, 60] loss: 1.883\n",
      "[5, 120] loss: 1.873\n",
      "[5, 180] loss: 1.860\n",
      "[5, 240] loss: 1.858\n",
      "[5, 300] loss: 1.865\n",
      "[5, 360] loss: 1.845\n",
      "Epoch: 5 -> Loss: 2.01018571854\n",
      "Epoch: 5 -> Test Accuracy: 29.92\n",
      "[6, 60] loss: 1.846\n",
      "[6, 120] loss: 1.863\n",
      "[6, 180] loss: 1.856\n",
      "[6, 240] loss: 1.854\n",
      "[6, 300] loss: 1.863\n",
      "[6, 360] loss: 1.842\n",
      "Epoch: 6 -> Loss: 1.70246505737\n",
      "Epoch: 6 -> Test Accuracy: 30.48\n",
      "[7, 60] loss: 1.836\n",
      "[7, 120] loss: 1.848\n",
      "[7, 180] loss: 1.845\n",
      "[7, 240] loss: 1.843\n",
      "[7, 300] loss: 1.848\n",
      "[7, 360] loss: 1.851\n",
      "Epoch: 7 -> Loss: 2.04760336876\n",
      "Epoch: 7 -> Test Accuracy: 30.91\n",
      "[8, 60] loss: 1.858\n",
      "[8, 120] loss: 1.839\n",
      "[8, 180] loss: 1.838\n",
      "[8, 240] loss: 1.833\n",
      "[8, 300] loss: 1.837\n",
      "[8, 360] loss: 1.841\n",
      "Epoch: 8 -> Loss: 1.81221354008\n",
      "Epoch: 8 -> Test Accuracy: 30.27\n",
      "[9, 60] loss: 1.829\n",
      "[9, 120] loss: 1.843\n",
      "[9, 180] loss: 1.838\n",
      "[9, 240] loss: 1.825\n",
      "[9, 300] loss: 1.833\n",
      "[9, 360] loss: 1.829\n",
      "Epoch: 9 -> Loss: 1.88672542572\n",
      "Epoch: 9 -> Test Accuracy: 30.44\n",
      "[10, 60] loss: 1.819\n",
      "[10, 120] loss: 1.845\n",
      "[10, 180] loss: 1.805\n",
      "[10, 240] loss: 1.841\n",
      "[10, 300] loss: 1.845\n",
      "[10, 360] loss: 1.834\n",
      "Epoch: 10 -> Loss: 1.75250780582\n",
      "Epoch: 10 -> Test Accuracy: 30.13\n",
      "[11, 60] loss: 1.837\n",
      "[11, 120] loss: 1.826\n",
      "[11, 180] loss: 1.824\n",
      "[11, 240] loss: 1.822\n",
      "[11, 300] loss: 1.821\n",
      "[11, 360] loss: 1.812\n",
      "Epoch: 11 -> Loss: 1.95405387878\n",
      "Epoch: 11 -> Test Accuracy: 31.44\n",
      "[12, 60] loss: 1.815\n",
      "[12, 120] loss: 1.826\n",
      "[12, 180] loss: 1.844\n",
      "[12, 240] loss: 1.831\n",
      "[12, 300] loss: 1.810\n",
      "[12, 360] loss: 1.810\n",
      "Epoch: 12 -> Loss: 1.65560984612\n",
      "Epoch: 12 -> Test Accuracy: 31.01\n",
      "[13, 60] loss: 1.812\n",
      "[13, 120] loss: 1.834\n",
      "[13, 180] loss: 1.828\n",
      "[13, 240] loss: 1.823\n",
      "[13, 300] loss: 1.825\n",
      "[13, 360] loss: 1.834\n",
      "Epoch: 13 -> Loss: 1.79082989693\n",
      "Epoch: 13 -> Test Accuracy: 31.45\n",
      "[14, 60] loss: 1.823\n",
      "[14, 120] loss: 1.829\n",
      "[14, 180] loss: 1.824\n",
      "[14, 240] loss: 1.828\n",
      "[14, 300] loss: 1.809\n",
      "[14, 360] loss: 1.814\n",
      "Epoch: 14 -> Loss: 1.81268715858\n",
      "Epoch: 14 -> Test Accuracy: 30.5\n",
      "[15, 60] loss: 1.827\n",
      "[15, 120] loss: 1.819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 180] loss: 1.806\n",
      "[15, 240] loss: 1.802\n",
      "[15, 300] loss: 1.831\n",
      "[15, 360] loss: 1.825\n",
      "Epoch: 15 -> Loss: 1.87135100365\n",
      "Epoch: 15 -> Test Accuracy: 31.19\n",
      "[16, 60] loss: 1.830\n",
      "[16, 120] loss: 1.826\n",
      "[16, 180] loss: 1.823\n",
      "[16, 240] loss: 1.812\n",
      "[16, 300] loss: 1.828\n",
      "[16, 360] loss: 1.823\n",
      "Epoch: 16 -> Loss: 1.66989779472\n",
      "Epoch: 16 -> Test Accuracy: 31.25\n",
      "[17, 60] loss: 1.809\n",
      "[17, 120] loss: 1.794\n",
      "[17, 180] loss: 1.814\n",
      "[17, 240] loss: 1.815\n",
      "[17, 300] loss: 1.826\n",
      "[17, 360] loss: 1.788\n",
      "Epoch: 17 -> Loss: 1.80468523502\n",
      "Epoch: 17 -> Test Accuracy: 30.83\n",
      "[18, 60] loss: 1.824\n",
      "[18, 120] loss: 1.809\n",
      "[18, 180] loss: 1.807\n",
      "[18, 240] loss: 1.823\n",
      "[18, 300] loss: 1.825\n",
      "[18, 360] loss: 1.813\n",
      "Epoch: 18 -> Loss: 1.84267365932\n",
      "Epoch: 18 -> Test Accuracy: 31.14\n",
      "[19, 60] loss: 1.816\n",
      "[19, 120] loss: 1.798\n",
      "[19, 180] loss: 1.813\n",
      "[19, 240] loss: 1.817\n",
      "[19, 300] loss: 1.817\n",
      "[19, 360] loss: 1.828\n",
      "Epoch: 19 -> Loss: 1.64079380035\n",
      "Epoch: 19 -> Test Accuracy: 31.6\n",
      "[20, 60] loss: 1.813\n",
      "[20, 120] loss: 1.827\n",
      "[20, 180] loss: 1.816\n",
      "[20, 240] loss: 1.805\n",
      "[20, 300] loss: 1.812\n",
      "[20, 360] loss: 1.808\n",
      "Epoch: 20 -> Loss: 1.89683890343\n",
      "Epoch: 20 -> Test Accuracy: 31.27\n",
      "[21, 60] loss: 1.787\n",
      "[21, 120] loss: 1.763\n",
      "[21, 180] loss: 1.742\n",
      "[21, 240] loss: 1.730\n",
      "[21, 300] loss: 1.725\n",
      "[21, 360] loss: 1.724\n",
      "Epoch: 21 -> Loss: 1.78155934811\n",
      "Epoch: 21 -> Test Accuracy: 33.46\n",
      "[22, 60] loss: 1.731\n",
      "[22, 120] loss: 1.727\n",
      "[22, 180] loss: 1.739\n",
      "[22, 240] loss: 1.706\n",
      "[22, 300] loss: 1.719\n",
      "[22, 360] loss: 1.734\n",
      "Epoch: 22 -> Loss: 1.5975805521\n",
      "Epoch: 22 -> Test Accuracy: 34.05\n",
      "[23, 60] loss: 1.721\n",
      "[23, 120] loss: 1.715\n",
      "[23, 180] loss: 1.713\n",
      "[23, 240] loss: 1.702\n",
      "[23, 300] loss: 1.709\n",
      "[23, 360] loss: 1.718\n",
      "Epoch: 23 -> Loss: 1.5761783123\n",
      "Epoch: 23 -> Test Accuracy: 33.98\n",
      "[24, 60] loss: 1.723\n",
      "[24, 120] loss: 1.712\n",
      "[24, 180] loss: 1.719\n",
      "[24, 240] loss: 1.718\n",
      "[24, 300] loss: 1.708\n",
      "[24, 360] loss: 1.686\n",
      "Epoch: 24 -> Loss: 1.60008311272\n",
      "Epoch: 24 -> Test Accuracy: 34.2\n",
      "[25, 60] loss: 1.709\n",
      "[25, 120] loss: 1.695\n",
      "[25, 180] loss: 1.713\n",
      "[25, 240] loss: 1.704\n",
      "[25, 300] loss: 1.707\n",
      "[25, 360] loss: 1.719\n",
      "Epoch: 25 -> Loss: 1.67064762115\n",
      "Epoch: 25 -> Test Accuracy: 34.45\n",
      "[26, 60] loss: 1.701\n",
      "[26, 120] loss: 1.720\n",
      "[26, 180] loss: 1.717\n",
      "[26, 240] loss: 1.722\n",
      "[26, 300] loss: 1.688\n",
      "[26, 360] loss: 1.721\n",
      "Epoch: 26 -> Loss: 1.70441031456\n",
      "Epoch: 26 -> Test Accuracy: 34.42\n",
      "[27, 60] loss: 1.705\n",
      "[27, 120] loss: 1.706\n",
      "[27, 180] loss: 1.692\n",
      "[27, 240] loss: 1.702\n",
      "[27, 300] loss: 1.709\n",
      "[27, 360] loss: 1.700\n",
      "Epoch: 27 -> Loss: 1.6701977253\n",
      "Epoch: 27 -> Test Accuracy: 34.38\n",
      "[28, 60] loss: 1.697\n",
      "[28, 120] loss: 1.694\n",
      "[28, 180] loss: 1.711\n",
      "[28, 240] loss: 1.698\n",
      "[28, 300] loss: 1.692\n",
      "[28, 360] loss: 1.717\n",
      "Epoch: 28 -> Loss: 1.64550232887\n",
      "Epoch: 28 -> Test Accuracy: 34.67\n",
      "[29, 60] loss: 1.699\n",
      "[29, 120] loss: 1.693\n",
      "[29, 180] loss: 1.699\n",
      "[29, 240] loss: 1.696\n",
      "[29, 300] loss: 1.703\n",
      "[29, 360] loss: 1.717\n",
      "Epoch: 29 -> Loss: 1.71169245243\n",
      "Epoch: 29 -> Test Accuracy: 34.06\n",
      "[30, 60] loss: 1.702\n",
      "[30, 120] loss: 1.692\n",
      "[30, 180] loss: 1.690\n",
      "[30, 240] loss: 1.719\n",
      "[30, 300] loss: 1.701\n",
      "[30, 360] loss: 1.726\n",
      "Epoch: 30 -> Loss: 1.74969387054\n",
      "Epoch: 30 -> Test Accuracy: 34.61\n",
      "[31, 60] loss: 1.705\n",
      "[31, 120] loss: 1.689\n",
      "[31, 180] loss: 1.706\n",
      "[31, 240] loss: 1.696\n",
      "[31, 300] loss: 1.698\n",
      "[31, 360] loss: 1.695\n",
      "Epoch: 31 -> Loss: 1.82270336151\n",
      "Epoch: 31 -> Test Accuracy: 34.52\n",
      "[32, 60] loss: 1.696\n",
      "[32, 120] loss: 1.705\n",
      "[32, 180] loss: 1.688\n",
      "[32, 240] loss: 1.696\n",
      "[32, 300] loss: 1.713\n",
      "[32, 360] loss: 1.697\n",
      "Epoch: 32 -> Loss: 1.82992291451\n",
      "Epoch: 32 -> Test Accuracy: 34.6\n",
      "[33, 60] loss: 1.718\n",
      "[33, 120] loss: 1.672\n",
      "[33, 180] loss: 1.689\n",
      "[33, 240] loss: 1.700\n",
      "[33, 300] loss: 1.689\n",
      "[33, 360] loss: 1.707\n",
      "Epoch: 33 -> Loss: 1.6656421423\n",
      "Epoch: 33 -> Test Accuracy: 34.22\n",
      "[34, 60] loss: 1.679\n",
      "[34, 120] loss: 1.681\n",
      "[34, 180] loss: 1.704\n",
      "[34, 240] loss: 1.689\n",
      "[34, 300] loss: 1.694\n",
      "[34, 360] loss: 1.705\n",
      "Epoch: 34 -> Loss: 1.61780869961\n",
      "Epoch: 34 -> Test Accuracy: 34.1\n",
      "[35, 60] loss: 1.693\n",
      "[35, 120] loss: 1.693\n",
      "[35, 180] loss: 1.685\n",
      "[35, 240] loss: 1.689\n",
      "[35, 300] loss: 1.686\n",
      "[35, 360] loss: 1.699\n",
      "Epoch: 35 -> Loss: 1.73220694065\n",
      "Epoch: 35 -> Test Accuracy: 34.0\n",
      "[36, 60] loss: 1.697\n",
      "[36, 120] loss: 1.706\n",
      "[36, 180] loss: 1.706\n",
      "[36, 240] loss: 1.691\n",
      "[36, 300] loss: 1.692\n",
      "[36, 360] loss: 1.696\n",
      "Epoch: 36 -> Loss: 1.77762758732\n",
      "Epoch: 36 -> Test Accuracy: 35.05\n",
      "[37, 60] loss: 1.713\n",
      "[37, 120] loss: 1.685\n",
      "[37, 180] loss: 1.708\n",
      "[37, 240] loss: 1.710\n",
      "[37, 300] loss: 1.694\n",
      "[37, 360] loss: 1.692\n",
      "Epoch: 37 -> Loss: 1.68940448761\n",
      "Epoch: 37 -> Test Accuracy: 34.62\n",
      "[38, 60] loss: 1.686\n",
      "[38, 120] loss: 1.685\n",
      "[38, 180] loss: 1.705\n",
      "[38, 240] loss: 1.707\n",
      "[38, 300] loss: 1.703\n",
      "[38, 360] loss: 1.704\n",
      "Epoch: 38 -> Loss: 1.59341371059\n",
      "Epoch: 38 -> Test Accuracy: 34.72\n",
      "[39, 60] loss: 1.694\n",
      "[39, 120] loss: 1.719\n",
      "[39, 180] loss: 1.697\n",
      "[39, 240] loss: 1.686\n",
      "[39, 300] loss: 1.683\n",
      "[39, 360] loss: 1.702\n",
      "Epoch: 39 -> Loss: 1.78464257717\n",
      "Epoch: 39 -> Test Accuracy: 33.98\n",
      "[40, 60] loss: 1.713\n",
      "[40, 120] loss: 1.687\n",
      "[40, 180] loss: 1.701\n",
      "[40, 240] loss: 1.683\n",
      "[40, 300] loss: 1.684\n",
      "[40, 360] loss: 1.683\n",
      "Epoch: 40 -> Loss: 1.65682029724\n",
      "Epoch: 40 -> Test Accuracy: 34.14\n",
      "[41, 60] loss: 1.669\n",
      "[41, 120] loss: 1.660\n",
      "[41, 180] loss: 1.662\n",
      "[41, 240] loss: 1.655\n",
      "[41, 300] loss: 1.637\n",
      "[41, 360] loss: 1.648\n",
      "Epoch: 41 -> Loss: 1.69890785217\n",
      "Epoch: 41 -> Test Accuracy: 35.64\n",
      "[42, 60] loss: 1.639\n",
      "[42, 120] loss: 1.645\n",
      "[42, 180] loss: 1.636\n",
      "[42, 240] loss: 1.644\n",
      "[42, 300] loss: 1.656\n",
      "[42, 360] loss: 1.653\n",
      "Epoch: 42 -> Loss: 1.66673505306\n",
      "Epoch: 42 -> Test Accuracy: 35.76\n",
      "[43, 60] loss: 1.639\n",
      "[43, 120] loss: 1.648\n",
      "[43, 180] loss: 1.642\n",
      "[43, 240] loss: 1.633\n",
      "[43, 300] loss: 1.634\n",
      "[43, 360] loss: 1.636\n",
      "Epoch: 43 -> Loss: 1.67028069496\n",
      "Epoch: 43 -> Test Accuracy: 35.93\n",
      "[44, 60] loss: 1.615\n",
      "[44, 120] loss: 1.631\n",
      "[44, 180] loss: 1.624\n",
      "[44, 240] loss: 1.635\n",
      "[44, 300] loss: 1.615\n",
      "[44, 360] loss: 1.615\n",
      "Epoch: 44 -> Loss: 1.85347270966\n",
      "Epoch: 44 -> Test Accuracy: 36.25\n",
      "[45, 60] loss: 1.628\n",
      "[45, 120] loss: 1.640\n",
      "[45, 180] loss: 1.635\n",
      "[45, 240] loss: 1.649\n",
      "[45, 300] loss: 1.623\n",
      "[45, 360] loss: 1.625\n",
      "Epoch: 45 -> Loss: 1.5884077549\n",
      "Epoch: 45 -> Test Accuracy: 36.58\n",
      "[46, 60] loss: 1.615\n",
      "[46, 120] loss: 1.628\n",
      "[46, 180] loss: 1.621\n",
      "[46, 240] loss: 1.619\n",
      "[46, 300] loss: 1.612\n",
      "[46, 360] loss: 1.613\n",
      "Epoch: 46 -> Loss: 1.68181300163\n",
      "Epoch: 46 -> Test Accuracy: 36.53\n",
      "[47, 60] loss: 1.614\n",
      "[47, 120] loss: 1.612\n",
      "[47, 180] loss: 1.615\n",
      "[47, 240] loss: 1.628\n",
      "[47, 300] loss: 1.619\n",
      "[47, 360] loss: 1.619\n",
      "Epoch: 47 -> Loss: 1.65128874779\n",
      "Epoch: 47 -> Test Accuracy: 36.45\n",
      "[48, 60] loss: 1.623\n",
      "[48, 120] loss: 1.613\n",
      "[48, 180] loss: 1.620\n",
      "[48, 240] loss: 1.631\n",
      "[48, 300] loss: 1.603\n",
      "[48, 360] loss: 1.628\n",
      "Epoch: 48 -> Loss: 1.74921667576\n",
      "Epoch: 48 -> Test Accuracy: 36.74\n",
      "[49, 60] loss: 1.629\n",
      "[49, 120] loss: 1.602\n",
      "[49, 180] loss: 1.613\n",
      "[49, 240] loss: 1.623\n",
      "[49, 300] loss: 1.622\n",
      "[49, 360] loss: 1.579\n",
      "Epoch: 49 -> Loss: 1.60309791565\n",
      "Epoch: 49 -> Test Accuracy: 36.82\n",
      "[50, 60] loss: 1.609\n",
      "[50, 120] loss: 1.624\n",
      "[50, 180] loss: 1.616\n",
      "[50, 240] loss: 1.602\n",
      "[50, 300] loss: 1.625\n",
      "[50, 360] loss: 1.620\n",
      "Epoch: 50 -> Loss: 1.57591342926\n",
      "Epoch: 50 -> Test Accuracy: 36.6\n",
      "[51, 60] loss: 1.596\n",
      "[51, 120] loss: 1.605\n",
      "[51, 180] loss: 1.607\n",
      "[51, 240] loss: 1.621\n",
      "[51, 300] loss: 1.628\n",
      "[51, 360] loss: 1.605\n",
      "Epoch: 51 -> Loss: 1.60931754112\n",
      "Epoch: 51 -> Test Accuracy: 36.64\n",
      "[52, 60] loss: 1.599\n",
      "[52, 120] loss: 1.618\n",
      "[52, 180] loss: 1.603\n",
      "[52, 240] loss: 1.628\n",
      "[52, 300] loss: 1.619\n",
      "[52, 360] loss: 1.602\n",
      "Epoch: 52 -> Loss: 1.67688429356\n",
      "Epoch: 52 -> Test Accuracy: 36.5\n",
      "[53, 60] loss: 1.607\n",
      "[53, 120] loss: 1.617\n",
      "[53, 180] loss: 1.615\n",
      "[53, 240] loss: 1.604\n",
      "[53, 300] loss: 1.622\n",
      "[53, 360] loss: 1.590\n",
      "Epoch: 53 -> Loss: 1.3912923336\n",
      "Epoch: 53 -> Test Accuracy: 36.52\n",
      "[54, 60] loss: 1.611\n",
      "[54, 120] loss: 1.605\n",
      "[54, 180] loss: 1.601\n",
      "[54, 240] loss: 1.602\n",
      "[54, 300] loss: 1.600\n",
      "[54, 360] loss: 1.610\n",
      "Epoch: 54 -> Loss: 1.63470113277\n",
      "Epoch: 54 -> Test Accuracy: 36.8\n",
      "[55, 60] loss: 1.609\n",
      "[55, 120] loss: 1.602\n",
      "[55, 180] loss: 1.598\n",
      "[55, 240] loss: 1.609\n",
      "[55, 300] loss: 1.592\n",
      "[55, 360] loss: 1.622\n",
      "Epoch: 55 -> Loss: 1.85528635979\n",
      "Epoch: 55 -> Test Accuracy: 36.58\n",
      "[56, 60] loss: 1.616\n",
      "[56, 120] loss: 1.602\n",
      "[56, 180] loss: 1.616\n",
      "[56, 240] loss: 1.599\n",
      "[56, 300] loss: 1.607\n",
      "[56, 360] loss: 1.603\n",
      "Epoch: 56 -> Loss: 1.61834740639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56 -> Test Accuracy: 36.89\n",
      "[57, 60] loss: 1.607\n",
      "[57, 120] loss: 1.616\n",
      "[57, 180] loss: 1.618\n",
      "[57, 240] loss: 1.590\n",
      "[57, 300] loss: 1.621\n",
      "[57, 360] loss: 1.615\n",
      "Epoch: 57 -> Loss: 1.46420919895\n",
      "Epoch: 57 -> Test Accuracy: 36.88\n",
      "[58, 60] loss: 1.608\n",
      "[58, 120] loss: 1.610\n",
      "[58, 180] loss: 1.607\n",
      "[58, 240] loss: 1.610\n",
      "[58, 300] loss: 1.616\n",
      "[58, 360] loss: 1.608\n",
      "Epoch: 58 -> Loss: 1.75742685795\n",
      "Epoch: 58 -> Test Accuracy: 36.81\n",
      "[59, 60] loss: 1.598\n",
      "[59, 120] loss: 1.585\n",
      "[59, 180] loss: 1.594\n",
      "[59, 240] loss: 1.612\n",
      "[59, 300] loss: 1.597\n",
      "[59, 360] loss: 1.605\n",
      "Epoch: 59 -> Loss: 1.52518963814\n",
      "Epoch: 59 -> Test Accuracy: 37.04\n",
      "[60, 60] loss: 1.610\n",
      "[60, 120] loss: 1.599\n",
      "[60, 180] loss: 1.614\n",
      "[60, 240] loss: 1.600\n",
      "[60, 300] loss: 1.598\n",
      "[60, 360] loss: 1.599\n",
      "Epoch: 60 -> Loss: 1.6344563961\n",
      "Epoch: 60 -> Test Accuracy: 36.89\n",
      "[61, 60] loss: 1.605\n",
      "[61, 120] loss: 1.591\n",
      "[61, 180] loss: 1.587\n",
      "[61, 240] loss: 1.618\n",
      "[61, 300] loss: 1.603\n",
      "[61, 360] loss: 1.604\n",
      "Epoch: 61 -> Loss: 1.56204903126\n",
      "Epoch: 61 -> Test Accuracy: 36.79\n",
      "[62, 60] loss: 1.606\n",
      "[62, 120] loss: 1.593\n",
      "[62, 180] loss: 1.595\n",
      "[62, 240] loss: 1.610\n",
      "[62, 300] loss: 1.606\n",
      "[62, 360] loss: 1.602\n",
      "Epoch: 62 -> Loss: 1.32753717899\n",
      "Epoch: 62 -> Test Accuracy: 36.83\n",
      "[63, 60] loss: 1.603\n",
      "[63, 120] loss: 1.618\n",
      "[63, 180] loss: 1.598\n",
      "[63, 240] loss: 1.598\n",
      "[63, 300] loss: 1.602\n",
      "[63, 360] loss: 1.590\n",
      "Epoch: 63 -> Loss: 1.75866985321\n",
      "Epoch: 63 -> Test Accuracy: 36.68\n",
      "[64, 60] loss: 1.606\n",
      "[64, 120] loss: 1.595\n",
      "[64, 180] loss: 1.587\n",
      "[64, 240] loss: 1.599\n",
      "[64, 300] loss: 1.596\n",
      "[64, 360] loss: 1.624\n",
      "Epoch: 64 -> Loss: 1.53834414482\n",
      "Epoch: 64 -> Test Accuracy: 36.83\n",
      "[65, 60] loss: 1.612\n",
      "[65, 120] loss: 1.592\n",
      "[65, 180] loss: 1.603\n",
      "[65, 240] loss: 1.577\n",
      "[65, 300] loss: 1.589\n",
      "[65, 360] loss: 1.583\n",
      "Epoch: 65 -> Loss: 1.61043930054\n",
      "Epoch: 65 -> Test Accuracy: 36.89\n",
      "[66, 60] loss: 1.615\n",
      "[66, 120] loss: 1.595\n",
      "[66, 180] loss: 1.590\n",
      "[66, 240] loss: 1.597\n",
      "[66, 300] loss: 1.596\n",
      "[66, 360] loss: 1.594\n",
      "Epoch: 66 -> Loss: 1.61056113243\n",
      "Epoch: 66 -> Test Accuracy: 36.76\n",
      "[67, 60] loss: 1.605\n",
      "[67, 120] loss: 1.584\n",
      "[67, 180] loss: 1.592\n",
      "[67, 240] loss: 1.599\n",
      "[67, 300] loss: 1.615\n",
      "[67, 360] loss: 1.588\n",
      "Epoch: 67 -> Loss: 1.63146901131\n",
      "Epoch: 67 -> Test Accuracy: 36.78\n",
      "[68, 60] loss: 1.605\n",
      "[68, 120] loss: 1.608\n",
      "[68, 180] loss: 1.616\n",
      "[68, 240] loss: 1.583\n",
      "[68, 300] loss: 1.595\n",
      "[68, 360] loss: 1.587\n",
      "Epoch: 68 -> Loss: 1.7512203455\n",
      "Epoch: 68 -> Test Accuracy: 37.04\n",
      "[69, 60] loss: 1.594\n",
      "[69, 120] loss: 1.585\n",
      "[69, 180] loss: 1.580\n",
      "[69, 240] loss: 1.594\n",
      "[69, 300] loss: 1.586\n",
      "[69, 360] loss: 1.599\n",
      "Epoch: 69 -> Loss: 1.48832798004\n",
      "Epoch: 69 -> Test Accuracy: 36.95\n",
      "[70, 60] loss: 1.602\n",
      "[70, 120] loss: 1.591\n",
      "[70, 180] loss: 1.612\n",
      "[70, 240] loss: 1.590\n",
      "[70, 300] loss: 1.589\n",
      "[70, 360] loss: 1.611\n",
      "Epoch: 70 -> Loss: 1.55993568897\n",
      "Epoch: 70 -> Test Accuracy: 36.92\n",
      "[71, 60] loss: 1.607\n",
      "[71, 120] loss: 1.590\n",
      "[71, 180] loss: 1.580\n",
      "[71, 240] loss: 1.615\n",
      "[71, 300] loss: 1.592\n",
      "[71, 360] loss: 1.589\n",
      "Epoch: 71 -> Loss: 1.61201345921\n",
      "Epoch: 71 -> Test Accuracy: 36.8\n",
      "[72, 60] loss: 1.600\n",
      "[72, 120] loss: 1.589\n",
      "[72, 180] loss: 1.593\n",
      "[72, 240] loss: 1.575\n",
      "[72, 300] loss: 1.600\n",
      "[72, 360] loss: 1.581\n",
      "Epoch: 72 -> Loss: 1.54764342308\n",
      "Epoch: 72 -> Test Accuracy: 36.94\n",
      "[73, 60] loss: 1.603\n",
      "[73, 120] loss: 1.618\n",
      "[73, 180] loss: 1.577\n",
      "[73, 240] loss: 1.587\n",
      "[73, 300] loss: 1.611\n",
      "[73, 360] loss: 1.598\n",
      "Epoch: 73 -> Loss: 1.65829825401\n",
      "Epoch: 73 -> Test Accuracy: 36.88\n",
      "[74, 60] loss: 1.613\n",
      "[74, 120] loss: 1.611\n",
      "[74, 180] loss: 1.593\n",
      "[74, 240] loss: 1.604\n",
      "[74, 300] loss: 1.585\n",
      "[74, 360] loss: 1.593\n",
      "Epoch: 74 -> Loss: 1.70490705967\n",
      "Epoch: 74 -> Test Accuracy: 36.95\n",
      "[75, 60] loss: 1.608\n",
      "[75, 120] loss: 1.596\n",
      "[75, 180] loss: 1.594\n",
      "[75, 240] loss: 1.588\n",
      "[75, 300] loss: 1.597\n",
      "[75, 360] loss: 1.595\n",
      "Epoch: 75 -> Loss: 1.7018238306\n",
      "Epoch: 75 -> Test Accuracy: 36.9\n",
      "[76, 60] loss: 1.583\n",
      "[76, 120] loss: 1.598\n",
      "[76, 180] loss: 1.598\n",
      "[76, 240] loss: 1.608\n",
      "[76, 300] loss: 1.605\n",
      "[76, 360] loss: 1.593\n",
      "Epoch: 76 -> Loss: 1.72341918945\n",
      "Epoch: 76 -> Test Accuracy: 36.95\n",
      "[77, 60] loss: 1.588\n",
      "[77, 120] loss: 1.591\n",
      "[77, 180] loss: 1.597\n",
      "[77, 240] loss: 1.589\n",
      "[77, 300] loss: 1.575\n",
      "[77, 360] loss: 1.598\n",
      "Epoch: 77 -> Loss: 1.64409959316\n",
      "Epoch: 77 -> Test Accuracy: 36.77\n",
      "[78, 60] loss: 1.594\n",
      "[78, 120] loss: 1.595\n",
      "[78, 180] loss: 1.580\n",
      "[78, 240] loss: 1.589\n",
      "[78, 300] loss: 1.598\n",
      "[78, 360] loss: 1.594\n",
      "Epoch: 78 -> Loss: 1.47731614113\n",
      "Epoch: 78 -> Test Accuracy: 36.79\n",
      "[79, 60] loss: 1.595\n",
      "[79, 120] loss: 1.598\n",
      "[79, 180] loss: 1.588\n",
      "[79, 240] loss: 1.614\n",
      "[79, 300] loss: 1.596\n",
      "[79, 360] loss: 1.592\n",
      "Epoch: 79 -> Loss: 1.66056096554\n",
      "Epoch: 79 -> Test Accuracy: 36.91\n",
      "[80, 60] loss: 1.568\n",
      "[80, 120] loss: 1.587\n",
      "[80, 180] loss: 1.601\n",
      "[80, 240] loss: 1.592\n",
      "[80, 300] loss: 1.596\n",
      "[80, 360] loss: 1.604\n",
      "Epoch: 80 -> Loss: 1.37372291088\n",
      "Epoch: 80 -> Test Accuracy: 36.66\n",
      "[81, 60] loss: 1.576\n",
      "[81, 120] loss: 1.580\n",
      "[81, 180] loss: 1.598\n",
      "[81, 240] loss: 1.603\n",
      "[81, 300] loss: 1.579\n",
      "[81, 360] loss: 1.600\n",
      "Epoch: 81 -> Loss: 1.68288075924\n",
      "Epoch: 81 -> Test Accuracy: 36.65\n",
      "[82, 60] loss: 1.605\n",
      "[82, 120] loss: 1.591\n",
      "[82, 180] loss: 1.578\n",
      "[82, 240] loss: 1.584\n",
      "[82, 300] loss: 1.597\n",
      "[82, 360] loss: 1.595\n",
      "Epoch: 82 -> Loss: 1.684679389\n",
      "Epoch: 82 -> Test Accuracy: 36.86\n",
      "[83, 60] loss: 1.581\n",
      "[83, 120] loss: 1.588\n",
      "[83, 180] loss: 1.582\n",
      "[83, 240] loss: 1.589\n",
      "[83, 300] loss: 1.587\n",
      "[83, 360] loss: 1.601\n",
      "Epoch: 83 -> Loss: 1.63597083092\n",
      "Epoch: 83 -> Test Accuracy: 36.71\n",
      "[84, 60] loss: 1.604\n",
      "[84, 120] loss: 1.577\n",
      "[84, 180] loss: 1.571\n",
      "[84, 240] loss: 1.604\n",
      "[84, 300] loss: 1.607\n",
      "[84, 360] loss: 1.583\n",
      "Epoch: 84 -> Loss: 1.66544377804\n",
      "Epoch: 84 -> Test Accuracy: 36.98\n",
      "[85, 60] loss: 1.572\n",
      "[85, 120] loss: 1.615\n",
      "[85, 180] loss: 1.605\n",
      "[85, 240] loss: 1.605\n",
      "[85, 300] loss: 1.566\n",
      "[85, 360] loss: 1.589\n",
      "Epoch: 85 -> Loss: 1.42604160309\n",
      "Epoch: 85 -> Test Accuracy: 36.77\n",
      "[86, 60] loss: 1.579\n",
      "[86, 120] loss: 1.593\n",
      "[86, 180] loss: 1.596\n",
      "[86, 240] loss: 1.582\n",
      "[86, 300] loss: 1.606\n",
      "[86, 360] loss: 1.591\n",
      "Epoch: 86 -> Loss: 1.54443860054\n",
      "Epoch: 86 -> Test Accuracy: 36.79\n",
      "[87, 60] loss: 1.557\n",
      "[87, 120] loss: 1.604\n",
      "[87, 180] loss: 1.593\n",
      "[87, 240] loss: 1.585\n",
      "[87, 300] loss: 1.586\n",
      "[87, 360] loss: 1.574\n",
      "Epoch: 87 -> Loss: 1.71023631096\n",
      "Epoch: 87 -> Test Accuracy: 36.64\n",
      "[88, 60] loss: 1.584\n",
      "[88, 120] loss: 1.584\n",
      "[88, 180] loss: 1.594\n",
      "[88, 240] loss: 1.586\n",
      "[88, 300] loss: 1.602\n",
      "[88, 360] loss: 1.593\n",
      "Epoch: 88 -> Loss: 1.59364581108\n",
      "Epoch: 88 -> Test Accuracy: 37.01\n",
      "[89, 60] loss: 1.572\n",
      "[89, 120] loss: 1.601\n",
      "[89, 180] loss: 1.603\n",
      "[89, 240] loss: 1.576\n",
      "[89, 300] loss: 1.619\n",
      "[89, 360] loss: 1.590\n",
      "Epoch: 89 -> Loss: 1.64988100529\n",
      "Epoch: 89 -> Test Accuracy: 36.71\n",
      "[90, 60] loss: 1.584\n",
      "[90, 120] loss: 1.591\n",
      "[90, 180] loss: 1.574\n",
      "[90, 240] loss: 1.575\n",
      "[90, 300] loss: 1.582\n",
      "[90, 360] loss: 1.593\n",
      "Epoch: 90 -> Loss: 1.73972094059\n",
      "Epoch: 90 -> Test Accuracy: 36.77\n",
      "[91, 60] loss: 1.572\n",
      "[91, 120] loss: 1.589\n",
      "[91, 180] loss: 1.605\n",
      "[91, 240] loss: 1.576\n",
      "[91, 300] loss: 1.564\n",
      "[91, 360] loss: 1.594\n",
      "Epoch: 91 -> Loss: 1.57792210579\n",
      "Epoch: 91 -> Test Accuracy: 36.38\n",
      "[92, 60] loss: 1.574\n",
      "[92, 120] loss: 1.589\n",
      "[92, 180] loss: 1.604\n",
      "[92, 240] loss: 1.608\n",
      "[92, 300] loss: 1.582\n",
      "[92, 360] loss: 1.594\n",
      "Epoch: 92 -> Loss: 1.71652662754\n",
      "Epoch: 92 -> Test Accuracy: 36.89\n",
      "[93, 60] loss: 1.596\n",
      "[93, 120] loss: 1.590\n",
      "[93, 180] loss: 1.579\n",
      "[93, 240] loss: 1.601\n",
      "[93, 300] loss: 1.599\n",
      "[93, 360] loss: 1.604\n",
      "Epoch: 93 -> Loss: 1.66917073727\n",
      "Epoch: 93 -> Test Accuracy: 36.61\n",
      "[94, 60] loss: 1.599\n",
      "[94, 120] loss: 1.574\n",
      "[94, 180] loss: 1.599\n",
      "[94, 240] loss: 1.588\n",
      "[94, 300] loss: 1.566\n",
      "[94, 360] loss: 1.576\n",
      "Epoch: 94 -> Loss: 1.50129497051\n",
      "Epoch: 94 -> Test Accuracy: 36.51\n",
      "[95, 60] loss: 1.572\n",
      "[95, 120] loss: 1.592\n",
      "[95, 180] loss: 1.584\n",
      "[95, 240] loss: 1.585\n",
      "[95, 300] loss: 1.586\n",
      "[95, 360] loss: 1.592\n",
      "Epoch: 95 -> Loss: 1.65045166016\n",
      "Epoch: 95 -> Test Accuracy: 36.64\n",
      "[96, 60] loss: 1.600\n",
      "[96, 120] loss: 1.579\n",
      "[96, 180] loss: 1.594\n",
      "[96, 240] loss: 1.590\n",
      "[96, 300] loss: 1.594\n",
      "[96, 360] loss: 1.596\n",
      "Epoch: 96 -> Loss: 1.63389182091\n",
      "Epoch: 96 -> Test Accuracy: 36.67\n",
      "[97, 60] loss: 1.581\n",
      "[97, 120] loss: 1.588\n",
      "[97, 180] loss: 1.574\n",
      "[97, 240] loss: 1.597\n",
      "[97, 300] loss: 1.585\n",
      "[97, 360] loss: 1.576\n",
      "Epoch: 97 -> Loss: 1.51688170433\n",
      "Epoch: 97 -> Test Accuracy: 36.73\n",
      "[98, 60] loss: 1.579\n",
      "[98, 120] loss: 1.578\n",
      "[98, 180] loss: 1.590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98, 240] loss: 1.592\n",
      "[98, 300] loss: 1.579\n",
      "[98, 360] loss: 1.588\n",
      "Epoch: 98 -> Loss: 1.7388446331\n",
      "Epoch: 98 -> Test Accuracy: 37.05\n",
      "[99, 60] loss: 1.581\n",
      "[99, 120] loss: 1.591\n",
      "[99, 180] loss: 1.606\n",
      "[99, 240] loss: 1.593\n",
      "[99, 300] loss: 1.597\n",
      "[99, 360] loss: 1.579\n",
      "Epoch: 99 -> Loss: 1.52238571644\n",
      "Epoch: 99 -> Test Accuracy: 36.73\n",
      "[100, 60] loss: 1.608\n",
      "[100, 120] loss: 1.571\n",
      "[100, 180] loss: 1.580\n",
      "[100, 240] loss: 1.594\n",
      "[100, 300] loss: 1.588\n",
      "[100, 360] loss: 1.569\n",
      "Epoch: 100 -> Loss: 1.73447918892\n",
      "Epoch: 100 -> Test Accuracy: 36.9\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train NonLinearClassifiers on feature map of net_3block\n",
    "block5_loss_log, _, block5_test_accuracy_log, _, _ = tr.train_all_blocks(5, 10, [0.1, 0.02, 0.004, 0.0008], \n",
    "    [20, 40, 45, 100], 0.9, 5e-4, net_block5, criterion, trainloader, None, testloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.415\n",
      "[1, 120] loss: 1.049\n",
      "[1, 180] loss: 0.962\n",
      "[1, 240] loss: 0.913\n",
      "[1, 300] loss: 0.846\n",
      "[1, 360] loss: 0.820\n",
      "Epoch: 1 -> Loss: 0.900788605213\n",
      "Epoch: 1 -> Test Accuracy: 69.86\n",
      "[2, 60] loss: 0.756\n",
      "[2, 120] loss: 0.748\n",
      "[2, 180] loss: 0.732\n",
      "[2, 240] loss: 0.701\n",
      "[2, 300] loss: 0.706\n",
      "[2, 360] loss: 0.709\n",
      "Epoch: 2 -> Loss: 0.587452173233\n",
      "Epoch: 2 -> Test Accuracy: 74.13\n",
      "[3, 60] loss: 0.655\n",
      "[3, 120] loss: 0.656\n",
      "[3, 180] loss: 0.636\n",
      "[3, 240] loss: 0.640\n",
      "[3, 300] loss: 0.628\n",
      "[3, 360] loss: 0.605\n",
      "Epoch: 3 -> Loss: 0.866232037544\n",
      "Epoch: 3 -> Test Accuracy: 74.97\n",
      "[4, 60] loss: 0.619\n",
      "[4, 120] loss: 0.593\n",
      "[4, 180] loss: 0.610\n",
      "[4, 240] loss: 0.574\n",
      "[4, 300] loss: 0.585\n",
      "[4, 360] loss: 0.591\n",
      "Epoch: 4 -> Loss: 0.621171534061\n",
      "Epoch: 4 -> Test Accuracy: 76.79\n",
      "[5, 60] loss: 0.560\n",
      "[5, 120] loss: 0.555\n",
      "[5, 180] loss: 0.566\n",
      "[5, 240] loss: 0.574\n",
      "[5, 300] loss: 0.555\n",
      "[5, 360] loss: 0.582\n",
      "Epoch: 5 -> Loss: 0.68909573555\n",
      "Epoch: 5 -> Test Accuracy: 76.13\n",
      "[6, 60] loss: 0.532\n",
      "[6, 120] loss: 0.536\n",
      "[6, 180] loss: 0.544\n",
      "[6, 240] loss: 0.541\n",
      "[6, 300] loss: 0.535\n",
      "[6, 360] loss: 0.531\n",
      "Epoch: 6 -> Loss: 0.53924959898\n",
      "Epoch: 6 -> Test Accuracy: 78.31\n",
      "[7, 60] loss: 0.509\n",
      "[7, 120] loss: 0.515\n",
      "[7, 180] loss: 0.532\n",
      "[7, 240] loss: 0.533\n",
      "[7, 300] loss: 0.527\n",
      "[7, 360] loss: 0.531\n",
      "Epoch: 7 -> Loss: 0.412747919559\n",
      "Epoch: 7 -> Test Accuracy: 78.01\n",
      "[8, 60] loss: 0.487\n",
      "[8, 120] loss: 0.529\n",
      "[8, 180] loss: 0.515\n",
      "[8, 240] loss: 0.502\n",
      "[8, 300] loss: 0.515\n",
      "[8, 360] loss: 0.511\n",
      "Epoch: 8 -> Loss: 0.428011983633\n",
      "Epoch: 8 -> Test Accuracy: 79.57\n",
      "[9, 60] loss: 0.495\n",
      "[9, 120] loss: 0.491\n",
      "[9, 180] loss: 0.496\n",
      "[9, 240] loss: 0.500\n",
      "[9, 300] loss: 0.522\n",
      "[9, 360] loss: 0.500\n",
      "Epoch: 9 -> Loss: 0.470202505589\n",
      "Epoch: 9 -> Test Accuracy: 78.66\n",
      "[10, 60] loss: 0.492\n",
      "[10, 120] loss: 0.481\n",
      "[10, 180] loss: 0.488\n",
      "[10, 240] loss: 0.475\n",
      "[10, 300] loss: 0.507\n",
      "[10, 360] loss: 0.500\n",
      "Epoch: 10 -> Loss: 0.407345682383\n",
      "Epoch: 10 -> Test Accuracy: 78.88\n",
      "[11, 60] loss: 0.465\n",
      "[11, 120] loss: 0.476\n",
      "[11, 180] loss: 0.465\n",
      "[11, 240] loss: 0.489\n",
      "[11, 300] loss: 0.484\n",
      "[11, 360] loss: 0.496\n",
      "Epoch: 11 -> Loss: 0.516036629677\n",
      "Epoch: 11 -> Test Accuracy: 79.51\n",
      "[12, 60] loss: 0.464\n",
      "[12, 120] loss: 0.474\n",
      "[12, 180] loss: 0.487\n",
      "[12, 240] loss: 0.477\n",
      "[12, 300] loss: 0.474\n",
      "[12, 360] loss: 0.484\n",
      "Epoch: 12 -> Loss: 0.487961471081\n",
      "Epoch: 12 -> Test Accuracy: 80.58\n",
      "[13, 60] loss: 0.453\n",
      "[13, 120] loss: 0.457\n",
      "[13, 180] loss: 0.484\n",
      "[13, 240] loss: 0.485\n",
      "[13, 300] loss: 0.487\n",
      "[13, 360] loss: 0.452\n",
      "Epoch: 13 -> Loss: 0.598883748055\n",
      "Epoch: 13 -> Test Accuracy: 79.56\n",
      "[14, 60] loss: 0.439\n",
      "[14, 120] loss: 0.458\n",
      "[14, 180] loss: 0.461\n",
      "[14, 240] loss: 0.479\n",
      "[14, 300] loss: 0.466\n",
      "[14, 360] loss: 0.481\n",
      "Epoch: 14 -> Loss: 0.590564310551\n",
      "Epoch: 14 -> Test Accuracy: 78.51\n",
      "[15, 60] loss: 0.453\n",
      "[15, 120] loss: 0.445\n",
      "[15, 180] loss: 0.471\n",
      "[15, 240] loss: 0.477\n",
      "[15, 300] loss: 0.468\n",
      "[15, 360] loss: 0.463\n",
      "Epoch: 15 -> Loss: 0.562554359436\n",
      "Epoch: 15 -> Test Accuracy: 79.56\n",
      "[16, 60] loss: 0.429\n",
      "[16, 120] loss: 0.440\n",
      "[16, 180] loss: 0.456\n",
      "[16, 240] loss: 0.462\n",
      "[16, 300] loss: 0.480\n",
      "[16, 360] loss: 0.468\n",
      "Epoch: 16 -> Loss: 0.492955118418\n",
      "Epoch: 16 -> Test Accuracy: 79.61\n",
      "[17, 60] loss: 0.432\n",
      "[17, 120] loss: 0.422\n",
      "[17, 180] loss: 0.449\n",
      "[17, 240] loss: 0.467\n",
      "[17, 300] loss: 0.457\n",
      "[17, 360] loss: 0.447\n",
      "Epoch: 17 -> Loss: 0.583244264126\n",
      "Epoch: 17 -> Test Accuracy: 80.03\n",
      "[18, 60] loss: 0.437\n",
      "[18, 120] loss: 0.432\n",
      "[18, 180] loss: 0.435\n",
      "[18, 240] loss: 0.449\n",
      "[18, 300] loss: 0.460\n",
      "[18, 360] loss: 0.458\n",
      "Epoch: 18 -> Loss: 0.424815237522\n",
      "Epoch: 18 -> Test Accuracy: 80.79\n",
      "[19, 60] loss: 0.428\n",
      "[19, 120] loss: 0.430\n",
      "[19, 180] loss: 0.434\n",
      "[19, 240] loss: 0.456\n",
      "[19, 300] loss: 0.466\n",
      "[19, 360] loss: 0.451\n",
      "Epoch: 19 -> Loss: 0.483695358038\n",
      "Epoch: 19 -> Test Accuracy: 80.6\n",
      "[20, 60] loss: 0.431\n",
      "[20, 120] loss: 0.419\n",
      "[20, 180] loss: 0.444\n",
      "[20, 240] loss: 0.441\n",
      "[20, 300] loss: 0.462\n",
      "[20, 360] loss: 0.448\n",
      "Epoch: 20 -> Loss: 0.460440695286\n",
      "Epoch: 20 -> Test Accuracy: 81.51\n",
      "[21, 60] loss: 0.400\n",
      "[21, 120] loss: 0.431\n",
      "[21, 180] loss: 0.443\n",
      "[21, 240] loss: 0.443\n",
      "[21, 300] loss: 0.455\n",
      "[21, 360] loss: 0.469\n",
      "Epoch: 21 -> Loss: 0.32574364543\n",
      "Epoch: 21 -> Test Accuracy: 79.81\n",
      "[22, 60] loss: 0.431\n",
      "[22, 120] loss: 0.431\n",
      "[22, 180] loss: 0.435\n",
      "[22, 240] loss: 0.441\n",
      "[22, 300] loss: 0.434\n",
      "[22, 360] loss: 0.435\n",
      "Epoch: 22 -> Loss: 0.633691191673\n",
      "Epoch: 22 -> Test Accuracy: 81.46\n",
      "[23, 60] loss: 0.411\n",
      "[23, 120] loss: 0.420\n",
      "[23, 180] loss: 0.438\n",
      "[23, 240] loss: 0.456\n",
      "[23, 300] loss: 0.438\n",
      "[23, 360] loss: 0.439\n",
      "Epoch: 23 -> Loss: 0.336621940136\n",
      "Epoch: 23 -> Test Accuracy: 80.94\n",
      "[24, 60] loss: 0.415\n",
      "[24, 120] loss: 0.439\n",
      "[24, 180] loss: 0.423\n",
      "[24, 240] loss: 0.436\n",
      "[24, 300] loss: 0.442\n",
      "[24, 360] loss: 0.450\n",
      "Epoch: 24 -> Loss: 0.379792630672\n",
      "Epoch: 24 -> Test Accuracy: 80.08\n",
      "[25, 60] loss: 0.412\n",
      "[25, 120] loss: 0.415\n",
      "[25, 180] loss: 0.421\n",
      "[25, 240] loss: 0.456\n",
      "[25, 300] loss: 0.444\n",
      "[25, 360] loss: 0.442\n",
      "Epoch: 25 -> Loss: 0.412296384573\n",
      "Epoch: 25 -> Test Accuracy: 80.37\n",
      "[26, 60] loss: 0.411\n",
      "[26, 120] loss: 0.423\n",
      "[26, 180] loss: 0.427\n",
      "[26, 240] loss: 0.433\n",
      "[26, 300] loss: 0.443\n",
      "[26, 360] loss: 0.435\n",
      "Epoch: 26 -> Loss: 0.45783701539\n",
      "Epoch: 26 -> Test Accuracy: 80.67\n",
      "[27, 60] loss: 0.424\n",
      "[27, 120] loss: 0.426\n",
      "[27, 180] loss: 0.437\n",
      "[27, 240] loss: 0.428\n",
      "[27, 300] loss: 0.434\n",
      "[27, 360] loss: 0.449\n",
      "Epoch: 27 -> Loss: 0.416194140911\n",
      "Epoch: 27 -> Test Accuracy: 80.36\n",
      "[28, 60] loss: 0.404\n",
      "[28, 120] loss: 0.424\n",
      "[28, 180] loss: 0.425\n",
      "[28, 240] loss: 0.427\n",
      "[28, 300] loss: 0.456\n",
      "[28, 360] loss: 0.425\n",
      "Epoch: 28 -> Loss: 0.475871801376\n",
      "Epoch: 28 -> Test Accuracy: 81.02\n",
      "[29, 60] loss: 0.418\n",
      "[29, 120] loss: 0.428\n",
      "[29, 180] loss: 0.408\n",
      "[29, 240] loss: 0.429\n",
      "[29, 300] loss: 0.441\n",
      "[29, 360] loss: 0.430\n",
      "Epoch: 29 -> Loss: 0.228295847774\n",
      "Epoch: 29 -> Test Accuracy: 80.63\n",
      "[30, 60] loss: 0.407\n",
      "[30, 120] loss: 0.392\n",
      "[30, 180] loss: 0.439\n",
      "[30, 240] loss: 0.434\n",
      "[30, 300] loss: 0.445\n",
      "[30, 360] loss: 0.444\n",
      "Epoch: 30 -> Loss: 0.398962438107\n",
      "Epoch: 30 -> Test Accuracy: 80.46\n",
      "[31, 60] loss: 0.387\n",
      "[31, 120] loss: 0.404\n",
      "[31, 180] loss: 0.424\n",
      "[31, 240] loss: 0.436\n",
      "[31, 300] loss: 0.424\n",
      "[31, 360] loss: 0.445\n",
      "Epoch: 31 -> Loss: 0.49449262023\n",
      "Epoch: 31 -> Test Accuracy: 81.57\n",
      "[32, 60] loss: 0.415\n",
      "[32, 120] loss: 0.423\n",
      "[32, 180] loss: 0.430\n",
      "[32, 240] loss: 0.429\n",
      "[32, 300] loss: 0.432\n",
      "[32, 360] loss: 0.420\n",
      "Epoch: 32 -> Loss: 0.52691078186\n",
      "Epoch: 32 -> Test Accuracy: 81.28\n",
      "[33, 60] loss: 0.404\n",
      "[33, 120] loss: 0.397\n",
      "[33, 180] loss: 0.417\n",
      "[33, 240] loss: 0.453\n",
      "[33, 300] loss: 0.437\n",
      "[33, 360] loss: 0.430\n",
      "Epoch: 33 -> Loss: 0.33303463459\n",
      "Epoch: 33 -> Test Accuracy: 80.68\n",
      "[34, 60] loss: 0.412\n",
      "[34, 120] loss: 0.431\n",
      "[34, 180] loss: 0.427\n",
      "[34, 240] loss: 0.437\n",
      "[34, 300] loss: 0.416\n",
      "[34, 360] loss: 0.434\n",
      "Epoch: 34 -> Loss: 0.31060180068\n",
      "Epoch: 34 -> Test Accuracy: 80.99\n",
      "[35, 60] loss: 0.395\n",
      "[35, 120] loss: 0.408\n",
      "[35, 180] loss: 0.421\n",
      "[35, 240] loss: 0.439\n",
      "[35, 300] loss: 0.427\n",
      "[35, 360] loss: 0.427\n",
      "Epoch: 35 -> Loss: 0.422322809696\n",
      "Epoch: 35 -> Test Accuracy: 80.94\n",
      "[36, 60] loss: 0.339\n",
      "[36, 120] loss: 0.298\n",
      "[36, 180] loss: 0.296\n",
      "[36, 240] loss: 0.295\n",
      "[36, 300] loss: 0.283\n",
      "[36, 360] loss: 0.288\n",
      "Epoch: 36 -> Loss: 0.202215984464\n",
      "Epoch: 36 -> Test Accuracy: 85.1\n",
      "[37, 60] loss: 0.266\n",
      "[37, 120] loss: 0.256\n",
      "[37, 180] loss: 0.256\n",
      "[37, 240] loss: 0.265\n",
      "[37, 300] loss: 0.278\n",
      "[37, 360] loss: 0.268\n",
      "Epoch: 37 -> Loss: 0.27025565505\n",
      "Epoch: 37 -> Test Accuracy: 85.27\n",
      "[38, 60] loss: 0.244\n",
      "[38, 120] loss: 0.249\n",
      "[38, 180] loss: 0.258\n",
      "[38, 240] loss: 0.251\n",
      "[38, 300] loss: 0.259\n",
      "[38, 360] loss: 0.262\n",
      "Epoch: 38 -> Loss: 0.291774064302\n",
      "Epoch: 38 -> Test Accuracy: 85.63\n",
      "[39, 60] loss: 0.231\n",
      "[39, 120] loss: 0.236\n",
      "[39, 180] loss: 0.240\n",
      "[39, 240] loss: 0.245\n",
      "[39, 300] loss: 0.251\n",
      "[39, 360] loss: 0.252\n",
      "Epoch: 39 -> Loss: 0.22743883729\n",
      "Epoch: 39 -> Test Accuracy: 84.99\n",
      "[40, 60] loss: 0.235\n",
      "[40, 120] loss: 0.242\n",
      "[40, 180] loss: 0.226\n",
      "[40, 240] loss: 0.246\n",
      "[40, 300] loss: 0.242\n",
      "[40, 360] loss: 0.246\n",
      "Epoch: 40 -> Loss: 0.219916626811\n",
      "Epoch: 40 -> Test Accuracy: 84.85\n",
      "[41, 60] loss: 0.223\n",
      "[41, 120] loss: 0.232\n",
      "[41, 180] loss: 0.234\n",
      "[41, 240] loss: 0.233\n",
      "[41, 300] loss: 0.241\n",
      "[41, 360] loss: 0.247\n",
      "Epoch: 41 -> Loss: 0.246628478169\n",
      "Epoch: 41 -> Test Accuracy: 85.26\n",
      "[42, 60] loss: 0.227\n",
      "[42, 120] loss: 0.229\n",
      "[42, 180] loss: 0.226\n",
      "[42, 240] loss: 0.234\n",
      "[42, 300] loss: 0.253\n",
      "[42, 360] loss: 0.243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.315601766109\n",
      "Epoch: 42 -> Test Accuracy: 83.94\n",
      "[43, 60] loss: 0.222\n",
      "[43, 120] loss: 0.227\n",
      "[43, 180] loss: 0.230\n",
      "[43, 240] loss: 0.232\n",
      "[43, 300] loss: 0.238\n",
      "[43, 360] loss: 0.238\n",
      "Epoch: 43 -> Loss: 0.196926355362\n",
      "Epoch: 43 -> Test Accuracy: 84.69\n",
      "[44, 60] loss: 0.210\n",
      "[44, 120] loss: 0.224\n",
      "[44, 180] loss: 0.236\n",
      "[44, 240] loss: 0.240\n",
      "[44, 300] loss: 0.233\n",
      "[44, 360] loss: 0.247\n",
      "Epoch: 44 -> Loss: 0.221259504557\n",
      "Epoch: 44 -> Test Accuracy: 85.13\n",
      "[45, 60] loss: 0.219\n",
      "[45, 120] loss: 0.227\n",
      "[45, 180] loss: 0.232\n",
      "[45, 240] loss: 0.227\n",
      "[45, 300] loss: 0.247\n",
      "[45, 360] loss: 0.240\n",
      "Epoch: 45 -> Loss: 0.303429782391\n",
      "Epoch: 45 -> Test Accuracy: 83.88\n",
      "[46, 60] loss: 0.221\n",
      "[46, 120] loss: 0.230\n",
      "[46, 180] loss: 0.218\n",
      "[46, 240] loss: 0.235\n",
      "[46, 300] loss: 0.236\n",
      "[46, 360] loss: 0.237\n",
      "Epoch: 46 -> Loss: 0.325609445572\n",
      "Epoch: 46 -> Test Accuracy: 84.49\n",
      "[47, 60] loss: 0.219\n",
      "[47, 120] loss: 0.227\n",
      "[47, 180] loss: 0.225\n",
      "[47, 240] loss: 0.227\n",
      "[47, 300] loss: 0.235\n",
      "[47, 360] loss: 0.243\n",
      "Epoch: 47 -> Loss: 0.274577945471\n",
      "Epoch: 47 -> Test Accuracy: 84.63\n",
      "[48, 60] loss: 0.208\n",
      "[48, 120] loss: 0.222\n",
      "[48, 180] loss: 0.230\n",
      "[48, 240] loss: 0.243\n",
      "[48, 300] loss: 0.247\n",
      "[48, 360] loss: 0.238\n",
      "Epoch: 48 -> Loss: 0.232420533895\n",
      "Epoch: 48 -> Test Accuracy: 84.28\n",
      "[49, 60] loss: 0.212\n",
      "[49, 120] loss: 0.222\n",
      "[49, 180] loss: 0.228\n",
      "[49, 240] loss: 0.240\n",
      "[49, 300] loss: 0.233\n",
      "[49, 360] loss: 0.241\n",
      "Epoch: 49 -> Loss: 0.435170352459\n",
      "Epoch: 49 -> Test Accuracy: 84.34\n",
      "[50, 60] loss: 0.218\n",
      "[50, 120] loss: 0.215\n",
      "[50, 180] loss: 0.223\n",
      "[50, 240] loss: 0.238\n",
      "[50, 300] loss: 0.237\n",
      "[50, 360] loss: 0.250\n",
      "Epoch: 50 -> Loss: 0.186760351062\n",
      "Epoch: 50 -> Test Accuracy: 84.34\n",
      "[51, 60] loss: 0.222\n",
      "[51, 120] loss: 0.233\n",
      "[51, 180] loss: 0.230\n",
      "[51, 240] loss: 0.235\n",
      "[51, 300] loss: 0.224\n",
      "[51, 360] loss: 0.242\n",
      "Epoch: 51 -> Loss: 0.279261350632\n",
      "Epoch: 51 -> Test Accuracy: 84.73\n",
      "[52, 60] loss: 0.224\n",
      "[52, 120] loss: 0.210\n",
      "[52, 180] loss: 0.239\n",
      "[52, 240] loss: 0.241\n",
      "[52, 300] loss: 0.232\n",
      "[52, 360] loss: 0.257\n",
      "Epoch: 52 -> Loss: 0.306978404522\n",
      "Epoch: 52 -> Test Accuracy: 84.24\n",
      "[53, 60] loss: 0.207\n",
      "[53, 120] loss: 0.222\n",
      "[53, 180] loss: 0.222\n",
      "[53, 240] loss: 0.228\n",
      "[53, 300] loss: 0.239\n",
      "[53, 360] loss: 0.247\n",
      "Epoch: 53 -> Loss: 0.267037242651\n",
      "Epoch: 53 -> Test Accuracy: 84.3\n",
      "[54, 60] loss: 0.218\n",
      "[54, 120] loss: 0.217\n",
      "[54, 180] loss: 0.233\n",
      "[54, 240] loss: 0.237\n",
      "[54, 300] loss: 0.240\n",
      "[54, 360] loss: 0.238\n",
      "Epoch: 54 -> Loss: 0.249963924289\n",
      "Epoch: 54 -> Test Accuracy: 83.81\n",
      "[55, 60] loss: 0.225\n",
      "[55, 120] loss: 0.223\n",
      "[55, 180] loss: 0.230\n",
      "[55, 240] loss: 0.229\n",
      "[55, 300] loss: 0.232\n",
      "[55, 360] loss: 0.229\n",
      "Epoch: 55 -> Loss: 0.154286265373\n",
      "Epoch: 55 -> Test Accuracy: 84.11\n",
      "[56, 60] loss: 0.218\n",
      "[56, 120] loss: 0.227\n",
      "[56, 180] loss: 0.232\n",
      "[56, 240] loss: 0.237\n",
      "[56, 300] loss: 0.226\n",
      "[56, 360] loss: 0.231\n",
      "Epoch: 56 -> Loss: 0.197830051184\n",
      "Epoch: 56 -> Test Accuracy: 83.68\n",
      "[57, 60] loss: 0.228\n",
      "[57, 120] loss: 0.209\n",
      "[57, 180] loss: 0.224\n",
      "[57, 240] loss: 0.212\n",
      "[57, 300] loss: 0.247\n",
      "[57, 360] loss: 0.235\n",
      "Epoch: 57 -> Loss: 0.337525904179\n",
      "Epoch: 57 -> Test Accuracy: 84.18\n",
      "[58, 60] loss: 0.210\n",
      "[58, 120] loss: 0.221\n",
      "[58, 180] loss: 0.226\n",
      "[58, 240] loss: 0.231\n",
      "[58, 300] loss: 0.234\n",
      "[58, 360] loss: 0.239\n",
      "Epoch: 58 -> Loss: 0.164969041944\n",
      "Epoch: 58 -> Test Accuracy: 84.68\n",
      "[59, 60] loss: 0.213\n",
      "[59, 120] loss: 0.217\n",
      "[59, 180] loss: 0.216\n",
      "[59, 240] loss: 0.240\n",
      "[59, 300] loss: 0.237\n",
      "[59, 360] loss: 0.238\n",
      "Epoch: 59 -> Loss: 0.123755656183\n",
      "Epoch: 59 -> Test Accuracy: 84.39\n",
      "[60, 60] loss: 0.207\n",
      "[60, 120] loss: 0.226\n",
      "[60, 180] loss: 0.222\n",
      "[60, 240] loss: 0.225\n",
      "[60, 300] loss: 0.229\n",
      "[60, 360] loss: 0.243\n",
      "Epoch: 60 -> Loss: 0.176886588335\n",
      "Epoch: 60 -> Test Accuracy: 84.17\n",
      "[61, 60] loss: 0.208\n",
      "[61, 120] loss: 0.212\n",
      "[61, 180] loss: 0.219\n",
      "[61, 240] loss: 0.222\n",
      "[61, 300] loss: 0.235\n",
      "[61, 360] loss: 0.234\n",
      "Epoch: 61 -> Loss: 0.198918029666\n",
      "Epoch: 61 -> Test Accuracy: 84.29\n",
      "[62, 60] loss: 0.197\n",
      "[62, 120] loss: 0.214\n",
      "[62, 180] loss: 0.221\n",
      "[62, 240] loss: 0.226\n",
      "[62, 300] loss: 0.231\n",
      "[62, 360] loss: 0.237\n",
      "Epoch: 62 -> Loss: 0.392230451107\n",
      "Epoch: 62 -> Test Accuracy: 83.92\n",
      "[63, 60] loss: 0.218\n",
      "[63, 120] loss: 0.221\n",
      "[63, 180] loss: 0.216\n",
      "[63, 240] loss: 0.232\n",
      "[63, 300] loss: 0.228\n",
      "[63, 360] loss: 0.229\n",
      "Epoch: 63 -> Loss: 0.185526266694\n",
      "Epoch: 63 -> Test Accuracy: 84.18\n",
      "[64, 60] loss: 0.196\n",
      "[64, 120] loss: 0.205\n",
      "[64, 180] loss: 0.212\n",
      "[64, 240] loss: 0.218\n",
      "[64, 300] loss: 0.232\n",
      "[64, 360] loss: 0.233\n",
      "Epoch: 64 -> Loss: 0.178130716085\n",
      "Epoch: 64 -> Test Accuracy: 83.72\n",
      "[65, 60] loss: 0.200\n",
      "[65, 120] loss: 0.233\n",
      "[65, 180] loss: 0.223\n",
      "[65, 240] loss: 0.224\n",
      "[65, 300] loss: 0.228\n",
      "[65, 360] loss: 0.235\n",
      "Epoch: 65 -> Loss: 0.219020754099\n",
      "Epoch: 65 -> Test Accuracy: 84.39\n",
      "[66, 60] loss: 0.208\n",
      "[66, 120] loss: 0.209\n",
      "[66, 180] loss: 0.217\n",
      "[66, 240] loss: 0.222\n",
      "[66, 300] loss: 0.235\n",
      "[66, 360] loss: 0.245\n",
      "Epoch: 66 -> Loss: 0.143887713552\n",
      "Epoch: 66 -> Test Accuracy: 84.06\n",
      "[67, 60] loss: 0.198\n",
      "[67, 120] loss: 0.207\n",
      "[67, 180] loss: 0.223\n",
      "[67, 240] loss: 0.222\n",
      "[67, 300] loss: 0.227\n",
      "[67, 360] loss: 0.241\n",
      "Epoch: 67 -> Loss: 0.307341635227\n",
      "Epoch: 67 -> Test Accuracy: 83.57\n",
      "[68, 60] loss: 0.210\n",
      "[68, 120] loss: 0.206\n",
      "[68, 180] loss: 0.214\n",
      "[68, 240] loss: 0.222\n",
      "[68, 300] loss: 0.226\n",
      "[68, 360] loss: 0.228\n",
      "Epoch: 68 -> Loss: 0.355814576149\n",
      "Epoch: 68 -> Test Accuracy: 83.65\n",
      "[69, 60] loss: 0.211\n",
      "[69, 120] loss: 0.214\n",
      "[69, 180] loss: 0.218\n",
      "[69, 240] loss: 0.212\n",
      "[69, 300] loss: 0.221\n",
      "[69, 360] loss: 0.226\n",
      "Epoch: 69 -> Loss: 0.331316262484\n",
      "Epoch: 69 -> Test Accuracy: 83.92\n",
      "[70, 60] loss: 0.202\n",
      "[70, 120] loss: 0.205\n",
      "[70, 180] loss: 0.211\n",
      "[70, 240] loss: 0.216\n",
      "[70, 300] loss: 0.233\n",
      "[70, 360] loss: 0.232\n",
      "Epoch: 70 -> Loss: 0.311778217554\n",
      "Epoch: 70 -> Test Accuracy: 83.89\n",
      "[71, 60] loss: 0.177\n",
      "[71, 120] loss: 0.159\n",
      "[71, 180] loss: 0.153\n",
      "[71, 240] loss: 0.144\n",
      "[71, 300] loss: 0.135\n",
      "[71, 360] loss: 0.145\n",
      "Epoch: 71 -> Loss: 0.111974135041\n",
      "Epoch: 71 -> Test Accuracy: 85.93\n",
      "[72, 60] loss: 0.134\n",
      "[72, 120] loss: 0.137\n",
      "[72, 180] loss: 0.134\n",
      "[72, 240] loss: 0.138\n",
      "[72, 300] loss: 0.135\n",
      "[72, 360] loss: 0.134\n",
      "Epoch: 72 -> Loss: 0.114581860602\n",
      "Epoch: 72 -> Test Accuracy: 86.18\n",
      "[73, 60] loss: 0.117\n",
      "[73, 120] loss: 0.126\n",
      "[73, 180] loss: 0.127\n",
      "[73, 240] loss: 0.126\n",
      "[73, 300] loss: 0.128\n",
      "[73, 360] loss: 0.131\n",
      "Epoch: 73 -> Loss: 0.146867126226\n",
      "Epoch: 73 -> Test Accuracy: 86.21\n",
      "[74, 60] loss: 0.112\n",
      "[74, 120] loss: 0.122\n",
      "[74, 180] loss: 0.121\n",
      "[74, 240] loss: 0.133\n",
      "[74, 300] loss: 0.122\n",
      "[74, 360] loss: 0.129\n",
      "Epoch: 74 -> Loss: 0.17271065712\n",
      "Epoch: 74 -> Test Accuracy: 86.39\n",
      "[75, 60] loss: 0.114\n",
      "[75, 120] loss: 0.111\n",
      "[75, 180] loss: 0.116\n",
      "[75, 240] loss: 0.122\n",
      "[75, 300] loss: 0.122\n",
      "[75, 360] loss: 0.119\n",
      "Epoch: 75 -> Loss: 0.120461568236\n",
      "Epoch: 75 -> Test Accuracy: 86.25\n",
      "[76, 60] loss: 0.109\n",
      "[76, 120] loss: 0.112\n",
      "[76, 180] loss: 0.115\n",
      "[76, 240] loss: 0.121\n",
      "[76, 300] loss: 0.119\n",
      "[76, 360] loss: 0.115\n",
      "Epoch: 76 -> Loss: 0.161824047565\n",
      "Epoch: 76 -> Test Accuracy: 86.44\n",
      "[77, 60] loss: 0.110\n",
      "[77, 120] loss: 0.114\n",
      "[77, 180] loss: 0.117\n",
      "[77, 240] loss: 0.118\n",
      "[77, 300] loss: 0.119\n",
      "[77, 360] loss: 0.116\n",
      "Epoch: 77 -> Loss: 0.119151569903\n",
      "Epoch: 77 -> Test Accuracy: 86.36\n",
      "[78, 60] loss: 0.109\n",
      "[78, 120] loss: 0.110\n",
      "[78, 180] loss: 0.116\n",
      "[78, 240] loss: 0.118\n",
      "[78, 300] loss: 0.115\n",
      "[78, 360] loss: 0.115\n",
      "Epoch: 78 -> Loss: 0.137861475348\n",
      "Epoch: 78 -> Test Accuracy: 86.19\n",
      "[79, 60] loss: 0.105\n",
      "[79, 120] loss: 0.108\n",
      "[79, 180] loss: 0.114\n",
      "[79, 240] loss: 0.112\n",
      "[79, 300] loss: 0.108\n",
      "[79, 360] loss: 0.121\n",
      "Epoch: 79 -> Loss: 0.0691243633628\n",
      "Epoch: 79 -> Test Accuracy: 85.82\n",
      "[80, 60] loss: 0.107\n",
      "[80, 120] loss: 0.105\n",
      "[80, 180] loss: 0.109\n",
      "[80, 240] loss: 0.110\n",
      "[80, 300] loss: 0.111\n",
      "[80, 360] loss: 0.113\n",
      "Epoch: 80 -> Loss: 0.141553446651\n",
      "Epoch: 80 -> Test Accuracy: 86.09\n",
      "[81, 60] loss: 0.092\n",
      "[81, 120] loss: 0.103\n",
      "[81, 180] loss: 0.101\n",
      "[81, 240] loss: 0.110\n",
      "[81, 300] loss: 0.115\n",
      "[81, 360] loss: 0.110\n",
      "Epoch: 81 -> Loss: 0.12724712491\n",
      "Epoch: 81 -> Test Accuracy: 85.86\n",
      "[82, 60] loss: 0.097\n",
      "[82, 120] loss: 0.095\n",
      "[82, 180] loss: 0.104\n",
      "[82, 240] loss: 0.108\n",
      "[82, 300] loss: 0.108\n",
      "[82, 360] loss: 0.107\n",
      "Epoch: 82 -> Loss: 0.0958694666624\n",
      "Epoch: 82 -> Test Accuracy: 86.06\n",
      "[83, 60] loss: 0.103\n",
      "[83, 120] loss: 0.100\n",
      "[83, 180] loss: 0.105\n",
      "[83, 240] loss: 0.111\n",
      "[83, 300] loss: 0.101\n",
      "[83, 360] loss: 0.113\n",
      "Epoch: 83 -> Loss: 0.115622676909\n",
      "Epoch: 83 -> Test Accuracy: 85.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.096\n",
      "[84, 120] loss: 0.096\n",
      "[84, 180] loss: 0.105\n",
      "[84, 240] loss: 0.107\n",
      "[84, 300] loss: 0.109\n",
      "[84, 360] loss: 0.108\n",
      "Epoch: 84 -> Loss: 0.117718979716\n",
      "Epoch: 84 -> Test Accuracy: 85.77\n",
      "[85, 60] loss: 0.101\n",
      "[85, 120] loss: 0.096\n",
      "[85, 180] loss: 0.104\n",
      "[85, 240] loss: 0.102\n",
      "[85, 300] loss: 0.110\n",
      "[85, 360] loss: 0.104\n",
      "Epoch: 85 -> Loss: 0.123285248876\n",
      "Epoch: 85 -> Test Accuracy: 85.89\n",
      "[86, 60] loss: 0.093\n",
      "[86, 120] loss: 0.095\n",
      "[86, 180] loss: 0.091\n",
      "[86, 240] loss: 0.094\n",
      "[86, 300] loss: 0.089\n",
      "[86, 360] loss: 0.094\n",
      "Epoch: 86 -> Loss: 0.120373107493\n",
      "Epoch: 86 -> Test Accuracy: 85.96\n",
      "[87, 60] loss: 0.085\n",
      "[87, 120] loss: 0.087\n",
      "[87, 180] loss: 0.086\n",
      "[87, 240] loss: 0.092\n",
      "[87, 300] loss: 0.088\n",
      "[87, 360] loss: 0.088\n",
      "Epoch: 87 -> Loss: 0.0820851475\n",
      "Epoch: 87 -> Test Accuracy: 86.16\n",
      "[88, 60] loss: 0.088\n",
      "[88, 120] loss: 0.088\n",
      "[88, 180] loss: 0.087\n",
      "[88, 240] loss: 0.087\n",
      "[88, 300] loss: 0.089\n",
      "[88, 360] loss: 0.085\n",
      "Epoch: 88 -> Loss: 0.104723110795\n",
      "Epoch: 88 -> Test Accuracy: 86.13\n",
      "[89, 60] loss: 0.086\n",
      "[89, 120] loss: 0.086\n",
      "[89, 180] loss: 0.087\n",
      "[89, 240] loss: 0.085\n",
      "[89, 300] loss: 0.084\n",
      "[89, 360] loss: 0.088\n",
      "Epoch: 89 -> Loss: 0.0945586189628\n",
      "Epoch: 89 -> Test Accuracy: 86.15\n",
      "[90, 60] loss: 0.082\n",
      "[90, 120] loss: 0.083\n",
      "[90, 180] loss: 0.086\n",
      "[90, 240] loss: 0.088\n",
      "[90, 300] loss: 0.085\n",
      "[90, 360] loss: 0.087\n",
      "Epoch: 90 -> Loss: 0.139472141862\n",
      "Epoch: 90 -> Test Accuracy: 85.97\n",
      "[91, 60] loss: 0.079\n",
      "[91, 120] loss: 0.084\n",
      "[91, 180] loss: 0.085\n",
      "[91, 240] loss: 0.087\n",
      "[91, 300] loss: 0.085\n",
      "[91, 360] loss: 0.083\n",
      "Epoch: 91 -> Loss: 0.131771340966\n",
      "Epoch: 91 -> Test Accuracy: 86.08\n",
      "[92, 60] loss: 0.083\n",
      "[92, 120] loss: 0.084\n",
      "[92, 180] loss: 0.084\n",
      "[92, 240] loss: 0.084\n",
      "[92, 300] loss: 0.090\n",
      "[92, 360] loss: 0.081\n",
      "Epoch: 92 -> Loss: 0.103041410446\n",
      "Epoch: 92 -> Test Accuracy: 86.18\n",
      "[93, 60] loss: 0.084\n",
      "[93, 120] loss: 0.082\n",
      "[93, 180] loss: 0.078\n",
      "[93, 240] loss: 0.083\n",
      "[93, 300] loss: 0.085\n",
      "[93, 360] loss: 0.084\n",
      "Epoch: 93 -> Loss: 0.0800497382879\n",
      "Epoch: 93 -> Test Accuracy: 86.19\n",
      "[94, 60] loss: 0.080\n",
      "[94, 120] loss: 0.086\n",
      "[94, 180] loss: 0.084\n",
      "[94, 240] loss: 0.085\n",
      "[94, 300] loss: 0.083\n",
      "[94, 360] loss: 0.084\n",
      "Epoch: 94 -> Loss: 0.0738931819797\n",
      "Epoch: 94 -> Test Accuracy: 86.18\n",
      "[95, 60] loss: 0.080\n",
      "[95, 120] loss: 0.086\n",
      "[95, 180] loss: 0.080\n",
      "[95, 240] loss: 0.087\n",
      "[95, 300] loss: 0.085\n",
      "[95, 360] loss: 0.082\n",
      "Epoch: 95 -> Loss: 0.166881412268\n",
      "Epoch: 95 -> Test Accuracy: 86.06\n",
      "[96, 60] loss: 0.081\n",
      "[96, 120] loss: 0.081\n",
      "[96, 180] loss: 0.086\n",
      "[96, 240] loss: 0.080\n",
      "[96, 300] loss: 0.080\n",
      "[96, 360] loss: 0.082\n",
      "Epoch: 96 -> Loss: 0.0975266620517\n",
      "Epoch: 96 -> Test Accuracy: 85.93\n",
      "[97, 60] loss: 0.082\n",
      "[97, 120] loss: 0.081\n",
      "[97, 180] loss: 0.079\n",
      "[97, 240] loss: 0.084\n",
      "[97, 300] loss: 0.086\n",
      "[97, 360] loss: 0.082\n",
      "Epoch: 97 -> Loss: 0.0995287969708\n",
      "Epoch: 97 -> Test Accuracy: 85.96\n",
      "[98, 60] loss: 0.079\n",
      "[98, 120] loss: 0.082\n",
      "[98, 180] loss: 0.078\n",
      "[98, 240] loss: 0.081\n",
      "[98, 300] loss: 0.083\n",
      "[98, 360] loss: 0.085\n",
      "Epoch: 98 -> Loss: 0.0681326836348\n",
      "Epoch: 98 -> Test Accuracy: 86.22\n",
      "[99, 60] loss: 0.081\n",
      "[99, 120] loss: 0.082\n",
      "[99, 180] loss: 0.081\n",
      "[99, 240] loss: 0.084\n",
      "[99, 300] loss: 0.082\n",
      "[99, 360] loss: 0.084\n",
      "Epoch: 99 -> Loss: 0.0908462777734\n",
      "Epoch: 99 -> Test Accuracy: 86.04\n",
      "[100, 60] loss: 0.080\n",
      "[100, 120] loss: 0.079\n",
      "[100, 180] loss: 0.082\n",
      "[100, 240] loss: 0.084\n",
      "[100, 300] loss: 0.084\n",
      "[100, 360] loss: 0.079\n",
      "Epoch: 100 -> Loss: 0.0940409004688\n",
      "Epoch: 100 -> Test Accuracy: 86.15\n",
      "Finished Training\n",
      "[1, 60] loss: 0.906\n",
      "[1, 120] loss: 0.643\n",
      "[1, 180] loss: 0.577\n",
      "[1, 240] loss: 0.572\n",
      "[1, 300] loss: 0.532\n",
      "[1, 360] loss: 0.505\n",
      "Epoch: 1 -> Loss: 0.620981812477\n",
      "Epoch: 1 -> Test Accuracy: 80.37\n",
      "[2, 60] loss: 0.455\n",
      "[2, 120] loss: 0.452\n",
      "[2, 180] loss: 0.457\n",
      "[2, 240] loss: 0.426\n",
      "[2, 300] loss: 0.441\n",
      "[2, 360] loss: 0.437\n",
      "Epoch: 2 -> Loss: 0.435760974884\n",
      "Epoch: 2 -> Test Accuracy: 82.1\n",
      "[3, 60] loss: 0.394\n",
      "[3, 120] loss: 0.397\n",
      "[3, 180] loss: 0.405\n",
      "[3, 240] loss: 0.393\n",
      "[3, 300] loss: 0.398\n",
      "[3, 360] loss: 0.394\n",
      "Epoch: 3 -> Loss: 0.44801941514\n",
      "Epoch: 3 -> Test Accuracy: 82.22\n",
      "[4, 60] loss: 0.347\n",
      "[4, 120] loss: 0.369\n",
      "[4, 180] loss: 0.368\n",
      "[4, 240] loss: 0.381\n",
      "[4, 300] loss: 0.383\n",
      "[4, 360] loss: 0.371\n",
      "Epoch: 4 -> Loss: 0.377430617809\n",
      "Epoch: 4 -> Test Accuracy: 84.44\n",
      "[5, 60] loss: 0.330\n",
      "[5, 120] loss: 0.355\n",
      "[5, 180] loss: 0.341\n",
      "[5, 240] loss: 0.377\n",
      "[5, 300] loss: 0.355\n",
      "[5, 360] loss: 0.359\n",
      "Epoch: 5 -> Loss: 0.314605176449\n",
      "Epoch: 5 -> Test Accuracy: 83.93\n",
      "[6, 60] loss: 0.316\n",
      "[6, 120] loss: 0.325\n",
      "[6, 180] loss: 0.356\n",
      "[6, 240] loss: 0.330\n",
      "[6, 300] loss: 0.343\n",
      "[6, 360] loss: 0.358\n",
      "Epoch: 6 -> Loss: 0.280491441488\n",
      "Epoch: 6 -> Test Accuracy: 84.45\n",
      "[7, 60] loss: 0.296\n",
      "[7, 120] loss: 0.333\n",
      "[7, 180] loss: 0.326\n",
      "[7, 240] loss: 0.339\n",
      "[7, 300] loss: 0.337\n",
      "[7, 360] loss: 0.339\n",
      "Epoch: 7 -> Loss: 0.278632521629\n",
      "Epoch: 7 -> Test Accuracy: 85.14\n",
      "[8, 60] loss: 0.303\n",
      "[8, 120] loss: 0.321\n",
      "[8, 180] loss: 0.307\n",
      "[8, 240] loss: 0.315\n",
      "[8, 300] loss: 0.327\n",
      "[8, 360] loss: 0.324\n",
      "Epoch: 8 -> Loss: 0.399484157562\n",
      "Epoch: 8 -> Test Accuracy: 84.98\n",
      "[9, 60] loss: 0.288\n",
      "[9, 120] loss: 0.297\n",
      "[9, 180] loss: 0.314\n",
      "[9, 240] loss: 0.331\n",
      "[9, 300] loss: 0.319\n",
      "[9, 360] loss: 0.337\n",
      "Epoch: 9 -> Loss: 0.380634129047\n",
      "Epoch: 9 -> Test Accuracy: 83.99\n",
      "[10, 60] loss: 0.285\n",
      "[10, 120] loss: 0.303\n",
      "[10, 180] loss: 0.301\n",
      "[10, 240] loss: 0.309\n",
      "[10, 300] loss: 0.301\n",
      "[10, 360] loss: 0.319\n",
      "Epoch: 10 -> Loss: 0.289529263973\n",
      "Epoch: 10 -> Test Accuracy: 85.09\n",
      "[11, 60] loss: 0.284\n",
      "[11, 120] loss: 0.287\n",
      "[11, 180] loss: 0.308\n",
      "[11, 240] loss: 0.310\n",
      "[11, 300] loss: 0.307\n",
      "[11, 360] loss: 0.317\n",
      "Epoch: 11 -> Loss: 0.372826457024\n",
      "Epoch: 11 -> Test Accuracy: 84.12\n",
      "[12, 60] loss: 0.275\n",
      "[12, 120] loss: 0.301\n",
      "[12, 180] loss: 0.289\n",
      "[12, 240] loss: 0.294\n",
      "[12, 300] loss: 0.301\n",
      "[12, 360] loss: 0.316\n",
      "Epoch: 12 -> Loss: 0.261351168156\n",
      "Epoch: 12 -> Test Accuracy: 84.19\n",
      "[13, 60] loss: 0.289\n",
      "[13, 120] loss: 0.284\n",
      "[13, 180] loss: 0.293\n",
      "[13, 240] loss: 0.281\n",
      "[13, 300] loss: 0.320\n",
      "[13, 360] loss: 0.300\n",
      "Epoch: 13 -> Loss: 0.29214400053\n",
      "Epoch: 13 -> Test Accuracy: 84.59\n",
      "[14, 60] loss: 0.265\n",
      "[14, 120] loss: 0.274\n",
      "[14, 180] loss: 0.276\n",
      "[14, 240] loss: 0.286\n",
      "[14, 300] loss: 0.305\n",
      "[14, 360] loss: 0.294\n",
      "Epoch: 14 -> Loss: 0.244513511658\n",
      "Epoch: 14 -> Test Accuracy: 84.0\n",
      "[15, 60] loss: 0.260\n",
      "[15, 120] loss: 0.272\n",
      "[15, 180] loss: 0.280\n",
      "[15, 240] loss: 0.302\n",
      "[15, 300] loss: 0.280\n",
      "[15, 360] loss: 0.292\n",
      "Epoch: 15 -> Loss: 0.317390650511\n",
      "Epoch: 15 -> Test Accuracy: 85.05\n",
      "[16, 60] loss: 0.273\n",
      "[16, 120] loss: 0.259\n",
      "[16, 180] loss: 0.279\n",
      "[16, 240] loss: 0.294\n",
      "[16, 300] loss: 0.290\n",
      "[16, 360] loss: 0.303\n",
      "Epoch: 16 -> Loss: 0.355598598719\n",
      "Epoch: 16 -> Test Accuracy: 85.21\n",
      "[17, 60] loss: 0.265\n",
      "[17, 120] loss: 0.272\n",
      "[17, 180] loss: 0.286\n",
      "[17, 240] loss: 0.282\n",
      "[17, 300] loss: 0.286\n",
      "[17, 360] loss: 0.278\n",
      "Epoch: 17 -> Loss: 0.292506963015\n",
      "Epoch: 17 -> Test Accuracy: 84.17\n",
      "[18, 60] loss: 0.259\n",
      "[18, 120] loss: 0.279\n",
      "[18, 180] loss: 0.287\n",
      "[18, 240] loss: 0.304\n",
      "[18, 300] loss: 0.287\n",
      "[18, 360] loss: 0.283\n",
      "Epoch: 18 -> Loss: 0.305723279715\n",
      "Epoch: 18 -> Test Accuracy: 84.85\n",
      "[19, 60] loss: 0.258\n",
      "[19, 120] loss: 0.265\n",
      "[19, 180] loss: 0.273\n",
      "[19, 240] loss: 0.288\n",
      "[19, 300] loss: 0.298\n",
      "[19, 360] loss: 0.286\n",
      "Epoch: 19 -> Loss: 0.280637323856\n",
      "Epoch: 19 -> Test Accuracy: 84.73\n",
      "[20, 60] loss: 0.263\n",
      "[20, 120] loss: 0.249\n",
      "[20, 180] loss: 0.277\n",
      "[20, 240] loss: 0.295\n",
      "[20, 300] loss: 0.292\n",
      "[20, 360] loss: 0.295\n",
      "Epoch: 20 -> Loss: 0.252203434706\n",
      "Epoch: 20 -> Test Accuracy: 84.67\n",
      "[21, 60] loss: 0.252\n",
      "[21, 120] loss: 0.261\n",
      "[21, 180] loss: 0.279\n",
      "[21, 240] loss: 0.273\n",
      "[21, 300] loss: 0.297\n",
      "[21, 360] loss: 0.298\n",
      "Epoch: 21 -> Loss: 0.204109877348\n",
      "Epoch: 21 -> Test Accuracy: 85.44\n",
      "[22, 60] loss: 0.238\n",
      "[22, 120] loss: 0.254\n",
      "[22, 180] loss: 0.278\n",
      "[22, 240] loss: 0.276\n",
      "[22, 300] loss: 0.274\n",
      "[22, 360] loss: 0.282\n",
      "Epoch: 22 -> Loss: 0.30065792799\n",
      "Epoch: 22 -> Test Accuracy: 85.37\n",
      "[23, 60] loss: 0.272\n",
      "[23, 120] loss: 0.254\n",
      "[23, 180] loss: 0.259\n",
      "[23, 240] loss: 0.301\n",
      "[23, 300] loss: 0.281\n",
      "[23, 360] loss: 0.279\n",
      "Epoch: 23 -> Loss: 0.217699617147\n",
      "Epoch: 23 -> Test Accuracy: 85.25\n",
      "[24, 60] loss: 0.252\n",
      "[24, 120] loss: 0.260\n",
      "[24, 180] loss: 0.273\n",
      "[24, 240] loss: 0.265\n",
      "[24, 300] loss: 0.275\n",
      "[24, 360] loss: 0.283\n",
      "Epoch: 24 -> Loss: 0.245756104589\n",
      "Epoch: 24 -> Test Accuracy: 84.97\n",
      "[25, 60] loss: 0.246\n",
      "[25, 120] loss: 0.261\n",
      "[25, 180] loss: 0.261\n",
      "[25, 240] loss: 0.270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 300] loss: 0.276\n",
      "[25, 360] loss: 0.279\n",
      "Epoch: 25 -> Loss: 0.307028323412\n",
      "Epoch: 25 -> Test Accuracy: 84.01\n",
      "[26, 60] loss: 0.250\n",
      "[26, 120] loss: 0.260\n",
      "[26, 180] loss: 0.285\n",
      "[26, 240] loss: 0.265\n",
      "[26, 300] loss: 0.286\n",
      "[26, 360] loss: 0.282\n",
      "Epoch: 26 -> Loss: 0.22989718616\n",
      "Epoch: 26 -> Test Accuracy: 85.62\n",
      "[27, 60] loss: 0.259\n",
      "[27, 120] loss: 0.252\n",
      "[27, 180] loss: 0.266\n",
      "[27, 240] loss: 0.285\n",
      "[27, 300] loss: 0.280\n",
      "[27, 360] loss: 0.288\n",
      "Epoch: 27 -> Loss: 0.347602188587\n",
      "Epoch: 27 -> Test Accuracy: 84.25\n",
      "[28, 60] loss: 0.260\n",
      "[28, 120] loss: 0.257\n",
      "[28, 180] loss: 0.268\n",
      "[28, 240] loss: 0.275\n",
      "[28, 300] loss: 0.276\n",
      "[28, 360] loss: 0.277\n",
      "Epoch: 28 -> Loss: 0.302180826664\n",
      "Epoch: 28 -> Test Accuracy: 85.22\n",
      "[29, 60] loss: 0.242\n",
      "[29, 120] loss: 0.256\n",
      "[29, 180] loss: 0.266\n",
      "[29, 240] loss: 0.283\n",
      "[29, 300] loss: 0.271\n",
      "[29, 360] loss: 0.256\n",
      "Epoch: 29 -> Loss: 0.359811782837\n",
      "Epoch: 29 -> Test Accuracy: 84.81\n",
      "[30, 60] loss: 0.252\n",
      "[30, 120] loss: 0.238\n",
      "[30, 180] loss: 0.268\n",
      "[30, 240] loss: 0.257\n",
      "[30, 300] loss: 0.269\n",
      "[30, 360] loss: 0.276\n",
      "Epoch: 30 -> Loss: 0.174617677927\n",
      "Epoch: 30 -> Test Accuracy: 84.72\n",
      "[31, 60] loss: 0.248\n",
      "[31, 120] loss: 0.244\n",
      "[31, 180] loss: 0.274\n",
      "[31, 240] loss: 0.275\n",
      "[31, 300] loss: 0.279\n",
      "[31, 360] loss: 0.272\n",
      "Epoch: 31 -> Loss: 0.342692524195\n",
      "Epoch: 31 -> Test Accuracy: 85.18\n",
      "[32, 60] loss: 0.243\n",
      "[32, 120] loss: 0.261\n",
      "[32, 180] loss: 0.259\n",
      "[32, 240] loss: 0.279\n",
      "[32, 300] loss: 0.267\n",
      "[32, 360] loss: 0.284\n",
      "Epoch: 32 -> Loss: 0.276132822037\n",
      "Epoch: 32 -> Test Accuracy: 85.63\n",
      "[33, 60] loss: 0.246\n",
      "[33, 120] loss: 0.254\n",
      "[33, 180] loss: 0.257\n",
      "[33, 240] loss: 0.262\n",
      "[33, 300] loss: 0.284\n",
      "[33, 360] loss: 0.281\n",
      "Epoch: 33 -> Loss: 0.231749504805\n",
      "Epoch: 33 -> Test Accuracy: 85.89\n",
      "[34, 60] loss: 0.236\n",
      "[34, 120] loss: 0.252\n",
      "[34, 180] loss: 0.269\n",
      "[34, 240] loss: 0.269\n",
      "[34, 300] loss: 0.269\n",
      "[34, 360] loss: 0.265\n",
      "Epoch: 34 -> Loss: 0.236305803061\n",
      "Epoch: 34 -> Test Accuracy: 84.94\n",
      "[35, 60] loss: 0.251\n",
      "[35, 120] loss: 0.258\n",
      "[35, 180] loss: 0.252\n",
      "[35, 240] loss: 0.269\n",
      "[35, 300] loss: 0.266\n",
      "[35, 360] loss: 0.285\n",
      "Epoch: 35 -> Loss: 0.281209051609\n",
      "Epoch: 35 -> Test Accuracy: 86.0\n",
      "[36, 60] loss: 0.203\n",
      "[36, 120] loss: 0.187\n",
      "[36, 180] loss: 0.176\n",
      "[36, 240] loss: 0.165\n",
      "[36, 300] loss: 0.168\n",
      "[36, 360] loss: 0.164\n",
      "Epoch: 36 -> Loss: 0.0974139124155\n",
      "Epoch: 36 -> Test Accuracy: 87.89\n",
      "[37, 60] loss: 0.138\n",
      "[37, 120] loss: 0.145\n",
      "[37, 180] loss: 0.147\n",
      "[37, 240] loss: 0.151\n",
      "[37, 300] loss: 0.145\n",
      "[37, 360] loss: 0.155\n",
      "Epoch: 37 -> Loss: 0.24301366508\n",
      "Epoch: 37 -> Test Accuracy: 87.82\n",
      "[38, 60] loss: 0.134\n",
      "[38, 120] loss: 0.133\n",
      "[38, 180] loss: 0.136\n",
      "[38, 240] loss: 0.134\n",
      "[38, 300] loss: 0.140\n",
      "[38, 360] loss: 0.131\n",
      "Epoch: 38 -> Loss: 0.113305784762\n",
      "Epoch: 38 -> Test Accuracy: 87.97\n",
      "[39, 60] loss: 0.116\n",
      "[39, 120] loss: 0.125\n",
      "[39, 180] loss: 0.114\n",
      "[39, 240] loss: 0.131\n",
      "[39, 300] loss: 0.131\n",
      "[39, 360] loss: 0.132\n",
      "Epoch: 39 -> Loss: 0.197534650564\n",
      "Epoch: 39 -> Test Accuracy: 87.87\n",
      "[40, 60] loss: 0.113\n",
      "[40, 120] loss: 0.116\n",
      "[40, 180] loss: 0.117\n",
      "[40, 240] loss: 0.117\n",
      "[40, 300] loss: 0.124\n",
      "[40, 360] loss: 0.117\n",
      "Epoch: 40 -> Loss: 0.182494670153\n",
      "Epoch: 40 -> Test Accuracy: 87.9\n",
      "[41, 60] loss: 0.103\n",
      "[41, 120] loss: 0.104\n",
      "[41, 180] loss: 0.114\n",
      "[41, 240] loss: 0.113\n",
      "[41, 300] loss: 0.127\n",
      "[41, 360] loss: 0.117\n",
      "Epoch: 41 -> Loss: 0.173839256167\n",
      "Epoch: 41 -> Test Accuracy: 87.56\n",
      "[42, 60] loss: 0.101\n",
      "[42, 120] loss: 0.106\n",
      "[42, 180] loss: 0.109\n",
      "[42, 240] loss: 0.110\n",
      "[42, 300] loss: 0.112\n",
      "[42, 360] loss: 0.116\n",
      "Epoch: 42 -> Loss: 0.13174316287\n",
      "Epoch: 42 -> Test Accuracy: 87.74\n",
      "[43, 60] loss: 0.103\n",
      "[43, 120] loss: 0.096\n",
      "[43, 180] loss: 0.103\n",
      "[43, 240] loss: 0.104\n",
      "[43, 300] loss: 0.115\n",
      "[43, 360] loss: 0.114\n",
      "Epoch: 43 -> Loss: 0.107854351401\n",
      "Epoch: 43 -> Test Accuracy: 87.82\n",
      "[44, 60] loss: 0.094\n",
      "[44, 120] loss: 0.102\n",
      "[44, 180] loss: 0.109\n",
      "[44, 240] loss: 0.108\n",
      "[44, 300] loss: 0.122\n",
      "[44, 360] loss: 0.112\n",
      "Epoch: 44 -> Loss: 0.0988167077303\n",
      "Epoch: 44 -> Test Accuracy: 87.56\n",
      "[45, 60] loss: 0.102\n",
      "[45, 120] loss: 0.100\n",
      "[45, 180] loss: 0.103\n",
      "[45, 240] loss: 0.106\n",
      "[45, 300] loss: 0.116\n",
      "[45, 360] loss: 0.111\n",
      "Epoch: 45 -> Loss: 0.183416828513\n",
      "Epoch: 45 -> Test Accuracy: 87.0\n",
      "[46, 60] loss: 0.103\n",
      "[46, 120] loss: 0.099\n",
      "[46, 180] loss: 0.099\n",
      "[46, 240] loss: 0.105\n",
      "[46, 300] loss: 0.108\n",
      "[46, 360] loss: 0.113\n",
      "Epoch: 46 -> Loss: 0.0834857001901\n",
      "Epoch: 46 -> Test Accuracy: 87.39\n",
      "[47, 60] loss: 0.101\n",
      "[47, 120] loss: 0.099\n",
      "[47, 180] loss: 0.104\n",
      "[47, 240] loss: 0.105\n",
      "[47, 300] loss: 0.109\n",
      "[47, 360] loss: 0.111\n",
      "Epoch: 47 -> Loss: 0.186075478792\n",
      "Epoch: 47 -> Test Accuracy: 87.57\n",
      "[48, 60] loss: 0.100\n",
      "[48, 120] loss: 0.102\n",
      "[48, 180] loss: 0.098\n",
      "[48, 240] loss: 0.098\n",
      "[48, 300] loss: 0.112\n",
      "[48, 360] loss: 0.111\n",
      "Epoch: 48 -> Loss: 0.116233274341\n",
      "Epoch: 48 -> Test Accuracy: 86.86\n",
      "[49, 60] loss: 0.092\n",
      "[49, 120] loss: 0.092\n",
      "[49, 180] loss: 0.107\n",
      "[49, 240] loss: 0.112\n",
      "[49, 300] loss: 0.112\n",
      "[49, 360] loss: 0.109\n",
      "Epoch: 49 -> Loss: 0.100978054106\n",
      "Epoch: 49 -> Test Accuracy: 87.25\n",
      "[50, 60] loss: 0.100\n",
      "[50, 120] loss: 0.103\n",
      "[50, 180] loss: 0.105\n",
      "[50, 240] loss: 0.103\n",
      "[50, 300] loss: 0.106\n",
      "[50, 360] loss: 0.131\n",
      "Epoch: 50 -> Loss: 0.135252192616\n",
      "Epoch: 50 -> Test Accuracy: 86.77\n",
      "[51, 60] loss: 0.102\n",
      "[51, 120] loss: 0.105\n",
      "[51, 180] loss: 0.110\n",
      "[51, 240] loss: 0.111\n",
      "[51, 300] loss: 0.113\n",
      "[51, 360] loss: 0.122\n",
      "Epoch: 51 -> Loss: 0.115717865527\n",
      "Epoch: 51 -> Test Accuracy: 86.73\n",
      "[52, 60] loss: 0.099\n",
      "[52, 120] loss: 0.100\n",
      "[52, 180] loss: 0.107\n",
      "[52, 240] loss: 0.117\n",
      "[52, 300] loss: 0.105\n",
      "[52, 360] loss: 0.107\n",
      "Epoch: 52 -> Loss: 0.171980425715\n",
      "Epoch: 52 -> Test Accuracy: 87.48\n",
      "[53, 60] loss: 0.105\n",
      "[53, 120] loss: 0.104\n",
      "[53, 180] loss: 0.108\n",
      "[53, 240] loss: 0.110\n",
      "[53, 300] loss: 0.111\n",
      "[53, 360] loss: 0.115\n",
      "Epoch: 53 -> Loss: 0.0536459609866\n",
      "Epoch: 53 -> Test Accuracy: 86.84\n",
      "[54, 60] loss: 0.094\n",
      "[54, 120] loss: 0.099\n",
      "[54, 180] loss: 0.108\n",
      "[54, 240] loss: 0.109\n",
      "[54, 300] loss: 0.112\n",
      "[54, 360] loss: 0.115\n",
      "Epoch: 54 -> Loss: 0.0517288446426\n",
      "Epoch: 54 -> Test Accuracy: 86.63\n",
      "[55, 60] loss: 0.101\n",
      "[55, 120] loss: 0.106\n",
      "[55, 180] loss: 0.103\n",
      "[55, 240] loss: 0.117\n",
      "[55, 300] loss: 0.114\n",
      "[55, 360] loss: 0.114\n",
      "Epoch: 55 -> Loss: 0.075156852603\n",
      "Epoch: 55 -> Test Accuracy: 87.28\n",
      "[56, 60] loss: 0.100\n",
      "[56, 120] loss: 0.097\n",
      "[56, 180] loss: 0.106\n",
      "[56, 240] loss: 0.111\n",
      "[56, 300] loss: 0.122\n",
      "[56, 360] loss: 0.113\n",
      "Epoch: 56 -> Loss: 0.141502022743\n",
      "Epoch: 56 -> Test Accuracy: 87.59\n",
      "[57, 60] loss: 0.106\n",
      "[57, 120] loss: 0.096\n",
      "[57, 180] loss: 0.100\n",
      "[57, 240] loss: 0.106\n",
      "[57, 300] loss: 0.115\n",
      "[57, 360] loss: 0.117\n",
      "Epoch: 57 -> Loss: 0.104330800474\n",
      "Epoch: 57 -> Test Accuracy: 86.24\n",
      "[58, 60] loss: 0.100\n",
      "[58, 120] loss: 0.100\n",
      "[58, 180] loss: 0.103\n",
      "[58, 240] loss: 0.112\n",
      "[58, 300] loss: 0.104\n",
      "[58, 360] loss: 0.118\n",
      "Epoch: 58 -> Loss: 0.197342216969\n",
      "Epoch: 58 -> Test Accuracy: 86.95\n",
      "[59, 60] loss: 0.102\n",
      "[59, 120] loss: 0.098\n",
      "[59, 180] loss: 0.107\n",
      "[59, 240] loss: 0.103\n",
      "[59, 300] loss: 0.099\n",
      "[59, 360] loss: 0.120\n",
      "Epoch: 59 -> Loss: 0.0807591155171\n",
      "Epoch: 59 -> Test Accuracy: 86.85\n",
      "[60, 60] loss: 0.110\n",
      "[60, 120] loss: 0.097\n",
      "[60, 180] loss: 0.103\n",
      "[60, 240] loss: 0.104\n",
      "[60, 300] loss: 0.113\n",
      "[60, 360] loss: 0.114\n",
      "Epoch: 60 -> Loss: 0.148805141449\n",
      "Epoch: 60 -> Test Accuracy: 87.0\n",
      "[61, 60] loss: 0.100\n",
      "[61, 120] loss: 0.107\n",
      "[61, 180] loss: 0.104\n",
      "[61, 240] loss: 0.102\n",
      "[61, 300] loss: 0.107\n",
      "[61, 360] loss: 0.113\n",
      "Epoch: 61 -> Loss: 0.153521344066\n",
      "Epoch: 61 -> Test Accuracy: 86.64\n",
      "[62, 60] loss: 0.093\n",
      "[62, 120] loss: 0.094\n",
      "[62, 180] loss: 0.103\n",
      "[62, 240] loss: 0.114\n",
      "[62, 300] loss: 0.106\n",
      "[62, 360] loss: 0.119\n",
      "Epoch: 62 -> Loss: 0.0503429360688\n",
      "Epoch: 62 -> Test Accuracy: 87.5\n",
      "[63, 60] loss: 0.094\n",
      "[63, 120] loss: 0.091\n",
      "[63, 180] loss: 0.107\n",
      "[63, 240] loss: 0.108\n",
      "[63, 300] loss: 0.112\n",
      "[63, 360] loss: 0.114\n",
      "Epoch: 63 -> Loss: 0.114434838295\n",
      "Epoch: 63 -> Test Accuracy: 86.74\n",
      "[64, 60] loss: 0.098\n",
      "[64, 120] loss: 0.099\n",
      "[64, 180] loss: 0.092\n",
      "[64, 240] loss: 0.104\n",
      "[64, 300] loss: 0.114\n",
      "[64, 360] loss: 0.120\n",
      "Epoch: 64 -> Loss: 0.138472825289\n",
      "Epoch: 64 -> Test Accuracy: 86.45\n",
      "[65, 60] loss: 0.103\n",
      "[65, 120] loss: 0.097\n",
      "[65, 180] loss: 0.104\n",
      "[65, 240] loss: 0.101\n",
      "[65, 300] loss: 0.121\n",
      "[65, 360] loss: 0.118\n",
      "Epoch: 65 -> Loss: 0.127903312445\n",
      "Epoch: 65 -> Test Accuracy: 86.9\n",
      "[66, 60] loss: 0.099\n",
      "[66, 120] loss: 0.094\n",
      "[66, 180] loss: 0.102\n",
      "[66, 240] loss: 0.096\n",
      "[66, 300] loss: 0.101\n",
      "[66, 360] loss: 0.105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Loss: 0.0944371372461\n",
      "Epoch: 66 -> Test Accuracy: 86.86\n",
      "[67, 60] loss: 0.097\n",
      "[67, 120] loss: 0.095\n",
      "[67, 180] loss: 0.098\n",
      "[67, 240] loss: 0.099\n",
      "[67, 300] loss: 0.112\n",
      "[67, 360] loss: 0.116\n",
      "Epoch: 67 -> Loss: 0.0530914664268\n",
      "Epoch: 67 -> Test Accuracy: 86.55\n",
      "[68, 60] loss: 0.094\n",
      "[68, 120] loss: 0.094\n",
      "[68, 180] loss: 0.099\n",
      "[68, 240] loss: 0.104\n",
      "[68, 300] loss: 0.107\n",
      "[68, 360] loss: 0.116\n",
      "Epoch: 68 -> Loss: 0.143045663834\n",
      "Epoch: 68 -> Test Accuracy: 86.5\n",
      "[69, 60] loss: 0.096\n",
      "[69, 120] loss: 0.098\n",
      "[69, 180] loss: 0.103\n",
      "[69, 240] loss: 0.097\n",
      "[69, 300] loss: 0.107\n",
      "[69, 360] loss: 0.114\n",
      "Epoch: 69 -> Loss: 0.0928893759847\n",
      "Epoch: 69 -> Test Accuracy: 86.9\n",
      "[70, 60] loss: 0.093\n",
      "[70, 120] loss: 0.087\n",
      "[70, 180] loss: 0.096\n",
      "[70, 240] loss: 0.104\n",
      "[70, 300] loss: 0.100\n",
      "[70, 360] loss: 0.115\n",
      "Epoch: 70 -> Loss: 0.172365143895\n",
      "Epoch: 70 -> Test Accuracy: 86.85\n",
      "[71, 60] loss: 0.082\n",
      "[71, 120] loss: 0.070\n",
      "[71, 180] loss: 0.063\n",
      "[71, 240] loss: 0.060\n",
      "[71, 300] loss: 0.058\n",
      "[71, 360] loss: 0.059\n",
      "Epoch: 71 -> Loss: 0.0896271914244\n",
      "Epoch: 71 -> Test Accuracy: 88.15\n",
      "[72, 60] loss: 0.053\n",
      "[72, 120] loss: 0.050\n",
      "[72, 180] loss: 0.054\n",
      "[72, 240] loss: 0.052\n",
      "[72, 300] loss: 0.052\n",
      "[72, 360] loss: 0.047\n",
      "Epoch: 72 -> Loss: 0.0616508424282\n",
      "Epoch: 72 -> Test Accuracy: 88.42\n",
      "[73, 60] loss: 0.046\n",
      "[73, 120] loss: 0.045\n",
      "[73, 180] loss: 0.049\n",
      "[73, 240] loss: 0.047\n",
      "[73, 300] loss: 0.046\n",
      "[73, 360] loss: 0.050\n",
      "Epoch: 73 -> Loss: 0.0324875824153\n",
      "Epoch: 73 -> Test Accuracy: 88.36\n",
      "[74, 60] loss: 0.040\n",
      "[74, 120] loss: 0.046\n",
      "[74, 180] loss: 0.046\n",
      "[74, 240] loss: 0.044\n",
      "[74, 300] loss: 0.045\n",
      "[74, 360] loss: 0.045\n",
      "Epoch: 74 -> Loss: 0.0635283067822\n",
      "Epoch: 74 -> Test Accuracy: 88.39\n",
      "[75, 60] loss: 0.041\n",
      "[75, 120] loss: 0.039\n",
      "[75, 180] loss: 0.041\n",
      "[75, 240] loss: 0.045\n",
      "[75, 300] loss: 0.045\n",
      "[75, 360] loss: 0.036\n",
      "Epoch: 75 -> Loss: 0.0272960718721\n",
      "Epoch: 75 -> Test Accuracy: 88.57\n",
      "[76, 60] loss: 0.038\n",
      "[76, 120] loss: 0.037\n",
      "[76, 180] loss: 0.040\n",
      "[76, 240] loss: 0.037\n",
      "[76, 300] loss: 0.044\n",
      "[76, 360] loss: 0.042\n",
      "Epoch: 76 -> Loss: 0.0266915857792\n",
      "Epoch: 76 -> Test Accuracy: 88.4\n",
      "[77, 60] loss: 0.036\n",
      "[77, 120] loss: 0.039\n",
      "[77, 180] loss: 0.038\n",
      "[77, 240] loss: 0.040\n",
      "[77, 300] loss: 0.036\n",
      "[77, 360] loss: 0.039\n",
      "Epoch: 77 -> Loss: 0.0539554059505\n",
      "Epoch: 77 -> Test Accuracy: 88.31\n",
      "[78, 60] loss: 0.039\n",
      "[78, 120] loss: 0.034\n",
      "[78, 180] loss: 0.038\n",
      "[78, 240] loss: 0.037\n",
      "[78, 300] loss: 0.036\n",
      "[78, 360] loss: 0.034\n",
      "Epoch: 78 -> Loss: 0.0256349090487\n",
      "Epoch: 78 -> Test Accuracy: 88.46\n",
      "[79, 60] loss: 0.034\n",
      "[79, 120] loss: 0.037\n",
      "[79, 180] loss: 0.039\n",
      "[79, 240] loss: 0.032\n",
      "[79, 300] loss: 0.037\n",
      "[79, 360] loss: 0.035\n",
      "Epoch: 79 -> Loss: 0.0353242829442\n",
      "Epoch: 79 -> Test Accuracy: 88.34\n",
      "[80, 60] loss: 0.032\n",
      "[80, 120] loss: 0.035\n",
      "[80, 180] loss: 0.034\n",
      "[80, 240] loss: 0.034\n",
      "[80, 300] loss: 0.035\n",
      "[80, 360] loss: 0.032\n",
      "Epoch: 80 -> Loss: 0.0467406436801\n",
      "Epoch: 80 -> Test Accuracy: 88.53\n",
      "[81, 60] loss: 0.032\n",
      "[81, 120] loss: 0.036\n",
      "[81, 180] loss: 0.033\n",
      "[81, 240] loss: 0.033\n",
      "[81, 300] loss: 0.034\n",
      "[81, 360] loss: 0.034\n",
      "Epoch: 81 -> Loss: 0.0352541320026\n",
      "Epoch: 81 -> Test Accuracy: 88.4\n",
      "[82, 60] loss: 0.031\n",
      "[82, 120] loss: 0.034\n",
      "[82, 180] loss: 0.033\n",
      "[82, 240] loss: 0.034\n",
      "[82, 300] loss: 0.032\n",
      "[82, 360] loss: 0.034\n",
      "Epoch: 82 -> Loss: 0.0729989632964\n",
      "Epoch: 82 -> Test Accuracy: 88.19\n",
      "[83, 60] loss: 0.030\n",
      "[83, 120] loss: 0.031\n",
      "[83, 180] loss: 0.033\n",
      "[83, 240] loss: 0.032\n",
      "[83, 300] loss: 0.035\n",
      "[83, 360] loss: 0.034\n",
      "Epoch: 83 -> Loss: 0.0354339145124\n",
      "Epoch: 83 -> Test Accuracy: 88.24\n",
      "[84, 60] loss: 0.030\n",
      "[84, 120] loss: 0.031\n",
      "[84, 180] loss: 0.032\n",
      "[84, 240] loss: 0.033\n",
      "[84, 300] loss: 0.032\n",
      "[84, 360] loss: 0.031\n",
      "Epoch: 84 -> Loss: 0.0121742431074\n",
      "Epoch: 84 -> Test Accuracy: 88.36\n",
      "[85, 60] loss: 0.031\n",
      "[85, 120] loss: 0.030\n",
      "[85, 180] loss: 0.033\n",
      "[85, 240] loss: 0.030\n",
      "[85, 300] loss: 0.031\n",
      "[85, 360] loss: 0.033\n",
      "Epoch: 85 -> Loss: 0.0452589169145\n",
      "Epoch: 85 -> Test Accuracy: 88.36\n",
      "[86, 60] loss: 0.031\n",
      "[86, 120] loss: 0.026\n",
      "[86, 180] loss: 0.028\n",
      "[86, 240] loss: 0.026\n",
      "[86, 300] loss: 0.028\n",
      "[86, 360] loss: 0.026\n",
      "Epoch: 86 -> Loss: 0.0490776225924\n",
      "Epoch: 86 -> Test Accuracy: 88.45\n",
      "[87, 60] loss: 0.028\n",
      "[87, 120] loss: 0.030\n",
      "[87, 180] loss: 0.026\n",
      "[87, 240] loss: 0.027\n",
      "[87, 300] loss: 0.026\n",
      "[87, 360] loss: 0.026\n",
      "Epoch: 87 -> Loss: 0.0277912858874\n",
      "Epoch: 87 -> Test Accuracy: 88.55\n",
      "[88, 60] loss: 0.027\n",
      "[88, 120] loss: 0.028\n",
      "[88, 180] loss: 0.027\n",
      "[88, 240] loss: 0.027\n",
      "[88, 300] loss: 0.026\n",
      "[88, 360] loss: 0.026\n",
      "Epoch: 88 -> Loss: 0.0122788846493\n",
      "Epoch: 88 -> Test Accuracy: 88.56\n",
      "[89, 60] loss: 0.026\n",
      "[89, 120] loss: 0.025\n",
      "[89, 180] loss: 0.028\n",
      "[89, 240] loss: 0.024\n",
      "[89, 300] loss: 0.026\n",
      "[89, 360] loss: 0.027\n",
      "Epoch: 89 -> Loss: 0.0354909040034\n",
      "Epoch: 89 -> Test Accuracy: 88.53\n",
      "[90, 60] loss: 0.026\n",
      "[90, 120] loss: 0.025\n",
      "[90, 180] loss: 0.027\n",
      "[90, 240] loss: 0.025\n",
      "[90, 300] loss: 0.026\n",
      "[90, 360] loss: 0.026\n",
      "Epoch: 90 -> Loss: 0.0264928080142\n",
      "Epoch: 90 -> Test Accuracy: 88.46\n",
      "[91, 60] loss: 0.026\n",
      "[91, 120] loss: 0.024\n",
      "[91, 180] loss: 0.024\n",
      "[91, 240] loss: 0.028\n",
      "[91, 300] loss: 0.028\n",
      "[91, 360] loss: 0.025\n",
      "Epoch: 91 -> Loss: 0.0590617768466\n",
      "Epoch: 91 -> Test Accuracy: 88.48\n",
      "[92, 60] loss: 0.025\n",
      "[92, 120] loss: 0.027\n",
      "[92, 180] loss: 0.025\n",
      "[92, 240] loss: 0.028\n",
      "[92, 300] loss: 0.026\n",
      "[92, 360] loss: 0.026\n",
      "Epoch: 92 -> Loss: 0.015181648545\n",
      "Epoch: 92 -> Test Accuracy: 88.49\n",
      "[93, 60] loss: 0.026\n",
      "[93, 120] loss: 0.026\n",
      "[93, 180] loss: 0.025\n",
      "[93, 240] loss: 0.024\n",
      "[93, 300] loss: 0.024\n",
      "[93, 360] loss: 0.027\n",
      "Epoch: 93 -> Loss: 0.0412289127707\n",
      "Epoch: 93 -> Test Accuracy: 88.46\n",
      "[94, 60] loss: 0.025\n",
      "[94, 120] loss: 0.028\n",
      "[94, 180] loss: 0.026\n",
      "[94, 240] loss: 0.024\n",
      "[94, 300] loss: 0.026\n",
      "[94, 360] loss: 0.024\n",
      "Epoch: 94 -> Loss: 0.0177456680685\n",
      "Epoch: 94 -> Test Accuracy: 88.62\n",
      "[95, 60] loss: 0.027\n",
      "[95, 120] loss: 0.026\n",
      "[95, 180] loss: 0.024\n",
      "[95, 240] loss: 0.025\n",
      "[95, 300] loss: 0.028\n",
      "[95, 360] loss: 0.026\n",
      "Epoch: 95 -> Loss: 0.0105563756078\n",
      "Epoch: 95 -> Test Accuracy: 88.54\n",
      "[96, 60] loss: 0.025\n",
      "[96, 120] loss: 0.027\n",
      "[96, 180] loss: 0.025\n",
      "[96, 240] loss: 0.025\n",
      "[96, 300] loss: 0.027\n",
      "[96, 360] loss: 0.027\n",
      "Epoch: 96 -> Loss: 0.0214056726545\n",
      "Epoch: 96 -> Test Accuracy: 88.47\n",
      "[97, 60] loss: 0.025\n",
      "[97, 120] loss: 0.024\n",
      "[97, 180] loss: 0.027\n",
      "[97, 240] loss: 0.026\n",
      "[97, 300] loss: 0.027\n",
      "[97, 360] loss: 0.024\n",
      "Epoch: 97 -> Loss: 0.015567690134\n",
      "Epoch: 97 -> Test Accuracy: 88.53\n",
      "[98, 60] loss: 0.026\n",
      "[98, 120] loss: 0.024\n",
      "[98, 180] loss: 0.027\n",
      "[98, 240] loss: 0.024\n",
      "[98, 300] loss: 0.026\n",
      "[98, 360] loss: 0.024\n",
      "Epoch: 98 -> Loss: 0.0595293268561\n",
      "Epoch: 98 -> Test Accuracy: 88.56\n",
      "[99, 60] loss: 0.024\n",
      "[99, 120] loss: 0.024\n",
      "[99, 180] loss: 0.024\n",
      "[99, 240] loss: 0.024\n",
      "[99, 300] loss: 0.025\n",
      "[99, 360] loss: 0.025\n",
      "Epoch: 99 -> Loss: 0.0156923178583\n",
      "Epoch: 99 -> Test Accuracy: 88.6\n",
      "[100, 60] loss: 0.023\n",
      "[100, 120] loss: 0.024\n",
      "[100, 180] loss: 0.023\n",
      "[100, 240] loss: 0.024\n",
      "[100, 300] loss: 0.026\n",
      "[100, 360] loss: 0.025\n",
      "Epoch: 100 -> Loss: 0.0167124755681\n",
      "Epoch: 100 -> Test Accuracy: 88.37\n",
      "Finished Training\n",
      "[1, 60] loss: 0.919\n",
      "[1, 120] loss: 0.668\n",
      "[1, 180] loss: 0.623\n",
      "[1, 240] loss: 0.589\n",
      "[1, 300] loss: 0.597\n",
      "[1, 360] loss: 0.560\n",
      "Epoch: 1 -> Loss: 0.57883554697\n",
      "Epoch: 1 -> Test Accuracy: 77.47\n",
      "[2, 60] loss: 0.541\n",
      "[2, 120] loss: 0.523\n",
      "[2, 180] loss: 0.523\n",
      "[2, 240] loss: 0.511\n",
      "[2, 300] loss: 0.525\n",
      "[2, 360] loss: 0.510\n",
      "Epoch: 2 -> Loss: 0.6604424119\n",
      "Epoch: 2 -> Test Accuracy: 77.93\n",
      "[3, 60] loss: 0.492\n",
      "[3, 120] loss: 0.491\n",
      "[3, 180] loss: 0.475\n",
      "[3, 240] loss: 0.484\n",
      "[3, 300] loss: 0.488\n",
      "[3, 360] loss: 0.473\n",
      "Epoch: 3 -> Loss: 0.256731241941\n",
      "Epoch: 3 -> Test Accuracy: 78.23\n",
      "[4, 60] loss: 0.461\n",
      "[4, 120] loss: 0.460\n",
      "[4, 180] loss: 0.469\n",
      "[4, 240] loss: 0.464\n",
      "[4, 300] loss: 0.473\n",
      "[4, 360] loss: 0.486\n",
      "Epoch: 4 -> Loss: 0.635275483131\n",
      "Epoch: 4 -> Test Accuracy: 79.56\n",
      "[5, 60] loss: 0.449\n",
      "[5, 120] loss: 0.457\n",
      "[5, 180] loss: 0.444\n",
      "[5, 240] loss: 0.455\n",
      "[5, 300] loss: 0.457\n",
      "[5, 360] loss: 0.458\n",
      "Epoch: 5 -> Loss: 0.440662533045\n",
      "Epoch: 5 -> Test Accuracy: 80.34\n",
      "[6, 60] loss: 0.419\n",
      "[6, 120] loss: 0.452\n",
      "[6, 180] loss: 0.442\n",
      "[6, 240] loss: 0.451\n",
      "[6, 300] loss: 0.442\n",
      "[6, 360] loss: 0.444\n",
      "Epoch: 6 -> Loss: 0.336867451668\n",
      "Epoch: 6 -> Test Accuracy: 79.76\n",
      "[7, 60] loss: 0.418\n",
      "[7, 120] loss: 0.421\n",
      "[7, 180] loss: 0.454\n",
      "[7, 240] loss: 0.439\n",
      "[7, 300] loss: 0.447\n",
      "[7, 360] loss: 0.442\n",
      "Epoch: 7 -> Loss: 0.505534350872\n",
      "Epoch: 7 -> Test Accuracy: 81.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 60] loss: 0.410\n",
      "[8, 120] loss: 0.424\n",
      "[8, 180] loss: 0.424\n",
      "[8, 240] loss: 0.414\n",
      "[8, 300] loss: 0.445\n",
      "[8, 360] loss: 0.430\n",
      "Epoch: 8 -> Loss: 0.504957199097\n",
      "Epoch: 8 -> Test Accuracy: 79.94\n",
      "[9, 60] loss: 0.410\n",
      "[9, 120] loss: 0.422\n",
      "[9, 180] loss: 0.447\n",
      "[9, 240] loss: 0.416\n",
      "[9, 300] loss: 0.433\n",
      "[9, 360] loss: 0.412\n",
      "Epoch: 9 -> Loss: 0.469581663609\n",
      "Epoch: 9 -> Test Accuracy: 81.25\n",
      "[10, 60] loss: 0.414\n",
      "[10, 120] loss: 0.415\n",
      "[10, 180] loss: 0.436\n",
      "[10, 240] loss: 0.407\n",
      "[10, 300] loss: 0.415\n",
      "[10, 360] loss: 0.432\n",
      "Epoch: 10 -> Loss: 0.48280531168\n",
      "Epoch: 10 -> Test Accuracy: 80.97\n",
      "[11, 60] loss: 0.396\n",
      "[11, 120] loss: 0.417\n",
      "[11, 180] loss: 0.417\n",
      "[11, 240] loss: 0.423\n",
      "[11, 300] loss: 0.414\n",
      "[11, 360] loss: 0.422\n",
      "Epoch: 11 -> Loss: 0.483160585165\n",
      "Epoch: 11 -> Test Accuracy: 81.14\n",
      "[12, 60] loss: 0.409\n",
      "[12, 120] loss: 0.411\n",
      "[12, 180] loss: 0.396\n",
      "[12, 240] loss: 0.418\n",
      "[12, 300] loss: 0.418\n",
      "[12, 360] loss: 0.425\n",
      "Epoch: 12 -> Loss: 0.455816835165\n",
      "Epoch: 12 -> Test Accuracy: 80.53\n",
      "[13, 60] loss: 0.398\n",
      "[13, 120] loss: 0.394\n",
      "[13, 180] loss: 0.411\n",
      "[13, 240] loss: 0.408\n",
      "[13, 300] loss: 0.411\n",
      "[13, 360] loss: 0.418\n",
      "Epoch: 13 -> Loss: 0.451216071844\n",
      "Epoch: 13 -> Test Accuracy: 81.64\n",
      "[14, 60] loss: 0.403\n",
      "[14, 120] loss: 0.402\n",
      "[14, 180] loss: 0.397\n",
      "[14, 240] loss: 0.412\n",
      "[14, 300] loss: 0.411\n",
      "[14, 360] loss: 0.416\n",
      "Epoch: 14 -> Loss: 0.478238344193\n",
      "Epoch: 14 -> Test Accuracy: 81.12\n",
      "[15, 60] loss: 0.385\n",
      "[15, 120] loss: 0.388\n",
      "[15, 180] loss: 0.410\n",
      "[15, 240] loss: 0.408\n",
      "[15, 300] loss: 0.409\n",
      "[15, 360] loss: 0.406\n",
      "Epoch: 15 -> Loss: 0.475679695606\n",
      "Epoch: 15 -> Test Accuracy: 81.03\n",
      "[16, 60] loss: 0.391\n",
      "[16, 120] loss: 0.395\n",
      "[16, 180] loss: 0.414\n",
      "[16, 240] loss: 0.392\n",
      "[16, 300] loss: 0.399\n",
      "[16, 360] loss: 0.405\n",
      "Epoch: 16 -> Loss: 0.642308235168\n",
      "Epoch: 16 -> Test Accuracy: 81.48\n",
      "[17, 60] loss: 0.382\n",
      "[17, 120] loss: 0.394\n",
      "[17, 180] loss: 0.419\n",
      "[17, 240] loss: 0.398\n",
      "[17, 300] loss: 0.410\n",
      "[17, 360] loss: 0.395\n",
      "Epoch: 17 -> Loss: 0.46499595046\n",
      "Epoch: 17 -> Test Accuracy: 80.99\n",
      "[18, 60] loss: 0.388\n",
      "[18, 120] loss: 0.389\n",
      "[18, 180] loss: 0.395\n",
      "[18, 240] loss: 0.391\n",
      "[18, 300] loss: 0.402\n",
      "[18, 360] loss: 0.419\n",
      "Epoch: 18 -> Loss: 0.378707587719\n",
      "Epoch: 18 -> Test Accuracy: 81.45\n",
      "[19, 60] loss: 0.365\n",
      "[19, 120] loss: 0.402\n",
      "[19, 180] loss: 0.408\n",
      "[19, 240] loss: 0.404\n",
      "[19, 300] loss: 0.388\n",
      "[19, 360] loss: 0.391\n",
      "Epoch: 19 -> Loss: 0.464482694864\n",
      "Epoch: 19 -> Test Accuracy: 82.36\n",
      "[20, 60] loss: 0.400\n",
      "[20, 120] loss: 0.387\n",
      "[20, 180] loss: 0.400\n",
      "[20, 240] loss: 0.393\n",
      "[20, 300] loss: 0.414\n",
      "[20, 360] loss: 0.383\n",
      "Epoch: 20 -> Loss: 0.367227613926\n",
      "Epoch: 20 -> Test Accuracy: 82.01\n",
      "[21, 60] loss: 0.388\n",
      "[21, 120] loss: 0.397\n",
      "[21, 180] loss: 0.385\n",
      "[21, 240] loss: 0.410\n",
      "[21, 300] loss: 0.406\n",
      "[21, 360] loss: 0.397\n",
      "Epoch: 21 -> Loss: 0.586154282093\n",
      "Epoch: 21 -> Test Accuracy: 81.88\n",
      "[22, 60] loss: 0.390\n",
      "[22, 120] loss: 0.379\n",
      "[22, 180] loss: 0.390\n",
      "[22, 240] loss: 0.400\n",
      "[22, 300] loss: 0.380\n",
      "[22, 360] loss: 0.408\n",
      "Epoch: 22 -> Loss: 0.409020721912\n",
      "Epoch: 22 -> Test Accuracy: 81.71\n",
      "[23, 60] loss: 0.366\n",
      "[23, 120] loss: 0.378\n",
      "[23, 180] loss: 0.392\n",
      "[23, 240] loss: 0.389\n",
      "[23, 300] loss: 0.397\n",
      "[23, 360] loss: 0.410\n",
      "Epoch: 23 -> Loss: 0.408734709024\n",
      "Epoch: 23 -> Test Accuracy: 82.06\n",
      "[24, 60] loss: 0.361\n",
      "[24, 120] loss: 0.388\n",
      "[24, 180] loss: 0.400\n",
      "[24, 240] loss: 0.384\n",
      "[24, 300] loss: 0.402\n",
      "[24, 360] loss: 0.400\n",
      "Epoch: 24 -> Loss: 0.458495616913\n",
      "Epoch: 24 -> Test Accuracy: 81.89\n",
      "[25, 60] loss: 0.364\n",
      "[25, 120] loss: 0.387\n",
      "[25, 180] loss: 0.399\n",
      "[25, 240] loss: 0.398\n",
      "[25, 300] loss: 0.387\n",
      "[25, 360] loss: 0.385\n",
      "Epoch: 25 -> Loss: 0.539923846722\n",
      "Epoch: 25 -> Test Accuracy: 81.53\n",
      "[26, 60] loss: 0.382\n",
      "[26, 120] loss: 0.389\n",
      "[26, 180] loss: 0.391\n",
      "[26, 240] loss: 0.393\n",
      "[26, 300] loss: 0.391\n",
      "[26, 360] loss: 0.394\n",
      "Epoch: 26 -> Loss: 0.416108548641\n",
      "Epoch: 26 -> Test Accuracy: 81.95\n",
      "[27, 60] loss: 0.373\n",
      "[27, 120] loss: 0.372\n",
      "[27, 180] loss: 0.386\n",
      "[27, 240] loss: 0.406\n",
      "[27, 300] loss: 0.395\n",
      "[27, 360] loss: 0.393\n",
      "Epoch: 27 -> Loss: 0.390419334173\n",
      "Epoch: 27 -> Test Accuracy: 81.03\n",
      "[28, 60] loss: 0.373\n",
      "[28, 120] loss: 0.368\n",
      "[28, 180] loss: 0.378\n",
      "[28, 240] loss: 0.389\n",
      "[28, 300] loss: 0.398\n",
      "[28, 360] loss: 0.405\n",
      "Epoch: 28 -> Loss: 0.418180137873\n",
      "Epoch: 28 -> Test Accuracy: 81.29\n",
      "[29, 60] loss: 0.362\n",
      "[29, 120] loss: 0.387\n",
      "[29, 180] loss: 0.399\n",
      "[29, 240] loss: 0.385\n",
      "[29, 300] loss: 0.393\n",
      "[29, 360] loss: 0.406\n",
      "Epoch: 29 -> Loss: 0.397904962301\n",
      "Epoch: 29 -> Test Accuracy: 81.25\n",
      "[30, 60] loss: 0.364\n",
      "[30, 120] loss: 0.392\n",
      "[30, 180] loss: 0.388\n",
      "[30, 240] loss: 0.402\n",
      "[30, 300] loss: 0.402\n",
      "[30, 360] loss: 0.393\n",
      "Epoch: 30 -> Loss: 0.421426296234\n",
      "Epoch: 30 -> Test Accuracy: 81.99\n",
      "[31, 60] loss: 0.361\n",
      "[31, 120] loss: 0.397\n",
      "[31, 180] loss: 0.389\n",
      "[31, 240] loss: 0.392\n",
      "[31, 300] loss: 0.382\n",
      "[31, 360] loss: 0.387\n",
      "Epoch: 31 -> Loss: 0.42198485136\n",
      "Epoch: 31 -> Test Accuracy: 81.17\n",
      "[32, 60] loss: 0.367\n",
      "[32, 120] loss: 0.376\n",
      "[32, 180] loss: 0.393\n",
      "[32, 240] loss: 0.401\n",
      "[32, 300] loss: 0.384\n",
      "[32, 360] loss: 0.397\n",
      "Epoch: 32 -> Loss: 0.355418473482\n",
      "Epoch: 32 -> Test Accuracy: 81.99\n",
      "[33, 60] loss: 0.371\n",
      "[33, 120] loss: 0.375\n",
      "[33, 180] loss: 0.390\n",
      "[33, 240] loss: 0.386\n",
      "[33, 300] loss: 0.399\n",
      "[33, 360] loss: 0.396\n",
      "Epoch: 33 -> Loss: 0.303262770176\n",
      "Epoch: 33 -> Test Accuracy: 81.56\n",
      "[34, 60] loss: 0.370\n",
      "[34, 120] loss: 0.376\n",
      "[34, 180] loss: 0.391\n",
      "[34, 240] loss: 0.388\n",
      "[34, 300] loss: 0.393\n",
      "[34, 360] loss: 0.375\n",
      "Epoch: 34 -> Loss: 0.586661815643\n",
      "Epoch: 34 -> Test Accuracy: 81.13\n",
      "[35, 60] loss: 0.372\n",
      "[35, 120] loss: 0.372\n",
      "[35, 180] loss: 0.380\n",
      "[35, 240] loss: 0.384\n",
      "[35, 300] loss: 0.400\n",
      "[35, 360] loss: 0.395\n",
      "Epoch: 35 -> Loss: 0.41078415513\n",
      "Epoch: 35 -> Test Accuracy: 81.7\n",
      "[36, 60] loss: 0.333\n",
      "[36, 120] loss: 0.320\n",
      "[36, 180] loss: 0.299\n",
      "[36, 240] loss: 0.292\n",
      "[36, 300] loss: 0.307\n",
      "[36, 360] loss: 0.291\n",
      "Epoch: 36 -> Loss: 0.441001325846\n",
      "Epoch: 36 -> Test Accuracy: 84.21\n",
      "[37, 60] loss: 0.280\n",
      "[37, 120] loss: 0.289\n",
      "[37, 180] loss: 0.263\n",
      "[37, 240] loss: 0.270\n",
      "[37, 300] loss: 0.278\n",
      "[37, 360] loss: 0.278\n",
      "Epoch: 37 -> Loss: 0.38457351923\n",
      "Epoch: 37 -> Test Accuracy: 84.23\n",
      "[38, 60] loss: 0.263\n",
      "[38, 120] loss: 0.259\n",
      "[38, 180] loss: 0.271\n",
      "[38, 240] loss: 0.270\n",
      "[38, 300] loss: 0.278\n",
      "[38, 360] loss: 0.283\n",
      "Epoch: 38 -> Loss: 0.279603779316\n",
      "Epoch: 38 -> Test Accuracy: 84.29\n",
      "[39, 60] loss: 0.254\n",
      "[39, 120] loss: 0.257\n",
      "[39, 180] loss: 0.262\n",
      "[39, 240] loss: 0.279\n",
      "[39, 300] loss: 0.265\n",
      "[39, 360] loss: 0.271\n",
      "Epoch: 39 -> Loss: 0.299817711115\n",
      "Epoch: 39 -> Test Accuracy: 84.4\n",
      "[40, 60] loss: 0.257\n",
      "[40, 120] loss: 0.250\n",
      "[40, 180] loss: 0.249\n",
      "[40, 240] loss: 0.270\n",
      "[40, 300] loss: 0.254\n",
      "[40, 360] loss: 0.265\n",
      "Epoch: 40 -> Loss: 0.286311089993\n",
      "Epoch: 40 -> Test Accuracy: 84.34\n",
      "[41, 60] loss: 0.248\n",
      "[41, 120] loss: 0.243\n",
      "[41, 180] loss: 0.255\n",
      "[41, 240] loss: 0.259\n",
      "[41, 300] loss: 0.260\n",
      "[41, 360] loss: 0.270\n",
      "Epoch: 41 -> Loss: 0.236666411161\n",
      "Epoch: 41 -> Test Accuracy: 84.07\n",
      "[42, 60] loss: 0.251\n",
      "[42, 120] loss: 0.246\n",
      "[42, 180] loss: 0.249\n",
      "[42, 240] loss: 0.245\n",
      "[42, 300] loss: 0.265\n",
      "[42, 360] loss: 0.253\n",
      "Epoch: 42 -> Loss: 0.378370434046\n",
      "Epoch: 42 -> Test Accuracy: 83.87\n",
      "[43, 60] loss: 0.231\n",
      "[43, 120] loss: 0.245\n",
      "[43, 180] loss: 0.257\n",
      "[43, 240] loss: 0.268\n",
      "[43, 300] loss: 0.248\n",
      "[43, 360] loss: 0.279\n",
      "Epoch: 43 -> Loss: 0.376384198666\n",
      "Epoch: 43 -> Test Accuracy: 83.76\n",
      "[44, 60] loss: 0.241\n",
      "[44, 120] loss: 0.252\n",
      "[44, 180] loss: 0.239\n",
      "[44, 240] loss: 0.246\n",
      "[44, 300] loss: 0.262\n",
      "[44, 360] loss: 0.247\n",
      "Epoch: 44 -> Loss: 0.189631775022\n",
      "Epoch: 44 -> Test Accuracy: 83.41\n",
      "[45, 60] loss: 0.231\n",
      "[45, 120] loss: 0.240\n",
      "[45, 180] loss: 0.245\n",
      "[45, 240] loss: 0.240\n",
      "[45, 300] loss: 0.259\n",
      "[45, 360] loss: 0.262\n",
      "Epoch: 45 -> Loss: 0.286123812199\n",
      "Epoch: 45 -> Test Accuracy: 83.79\n",
      "[46, 60] loss: 0.236\n",
      "[46, 120] loss: 0.230\n",
      "[46, 180] loss: 0.234\n",
      "[46, 240] loss: 0.244\n",
      "[46, 300] loss: 0.244\n",
      "[46, 360] loss: 0.250\n",
      "Epoch: 46 -> Loss: 0.262541204691\n",
      "Epoch: 46 -> Test Accuracy: 83.56\n",
      "[47, 60] loss: 0.233\n",
      "[47, 120] loss: 0.235\n",
      "[47, 180] loss: 0.239\n",
      "[47, 240] loss: 0.248\n",
      "[47, 300] loss: 0.256\n",
      "[47, 360] loss: 0.250\n",
      "Epoch: 47 -> Loss: 0.18812802434\n",
      "Epoch: 47 -> Test Accuracy: 83.88\n",
      "[48, 60] loss: 0.234\n",
      "[48, 120] loss: 0.234\n",
      "[48, 180] loss: 0.241\n",
      "[48, 240] loss: 0.260\n",
      "[48, 300] loss: 0.253\n",
      "[48, 360] loss: 0.256\n",
      "Epoch: 48 -> Loss: 0.220440149307\n",
      "Epoch: 48 -> Test Accuracy: 83.59\n",
      "[49, 60] loss: 0.234\n",
      "[49, 120] loss: 0.231\n",
      "[49, 180] loss: 0.240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 240] loss: 0.253\n",
      "[49, 300] loss: 0.248\n",
      "[49, 360] loss: 0.255\n",
      "Epoch: 49 -> Loss: 0.135067388415\n",
      "Epoch: 49 -> Test Accuracy: 83.58\n",
      "[50, 60] loss: 0.228\n",
      "[50, 120] loss: 0.234\n",
      "[50, 180] loss: 0.248\n",
      "[50, 240] loss: 0.246\n",
      "[50, 300] loss: 0.262\n",
      "[50, 360] loss: 0.259\n",
      "Epoch: 50 -> Loss: 0.252639204264\n",
      "Epoch: 50 -> Test Accuracy: 84.06\n",
      "[51, 60] loss: 0.237\n",
      "[51, 120] loss: 0.235\n",
      "[51, 180] loss: 0.253\n",
      "[51, 240] loss: 0.246\n",
      "[51, 300] loss: 0.244\n",
      "[51, 360] loss: 0.248\n",
      "Epoch: 51 -> Loss: 0.27722042799\n",
      "Epoch: 51 -> Test Accuracy: 83.78\n",
      "[52, 60] loss: 0.226\n",
      "[52, 120] loss: 0.237\n",
      "[52, 180] loss: 0.240\n",
      "[52, 240] loss: 0.242\n",
      "[52, 300] loss: 0.246\n",
      "[52, 360] loss: 0.249\n",
      "Epoch: 52 -> Loss: 0.384587109089\n",
      "Epoch: 52 -> Test Accuracy: 83.49\n",
      "[53, 60] loss: 0.222\n",
      "[53, 120] loss: 0.237\n",
      "[53, 180] loss: 0.236\n",
      "[53, 240] loss: 0.244\n",
      "[53, 300] loss: 0.274\n",
      "[53, 360] loss: 0.240\n",
      "Epoch: 53 -> Loss: 0.341534942389\n",
      "Epoch: 53 -> Test Accuracy: 83.32\n",
      "[54, 60] loss: 0.235\n",
      "[54, 120] loss: 0.245\n",
      "[54, 180] loss: 0.240\n",
      "[54, 240] loss: 0.250\n",
      "[54, 300] loss: 0.253\n",
      "[54, 360] loss: 0.252\n",
      "Epoch: 54 -> Loss: 0.196792647243\n",
      "Epoch: 54 -> Test Accuracy: 82.98\n",
      "[55, 60] loss: 0.226\n",
      "[55, 120] loss: 0.240\n",
      "[55, 180] loss: 0.251\n",
      "[55, 240] loss: 0.249\n",
      "[55, 300] loss: 0.234\n",
      "[55, 360] loss: 0.238\n",
      "Epoch: 55 -> Loss: 0.221841454506\n",
      "Epoch: 55 -> Test Accuracy: 83.73\n",
      "[56, 60] loss: 0.218\n",
      "[56, 120] loss: 0.215\n",
      "[56, 180] loss: 0.230\n",
      "[56, 240] loss: 0.242\n",
      "[56, 300] loss: 0.248\n",
      "[56, 360] loss: 0.238\n",
      "Epoch: 56 -> Loss: 0.399901300669\n",
      "Epoch: 56 -> Test Accuracy: 83.22\n",
      "[57, 60] loss: 0.227\n",
      "[57, 120] loss: 0.245\n",
      "[57, 180] loss: 0.237\n",
      "[57, 240] loss: 0.238\n",
      "[57, 300] loss: 0.245\n",
      "[57, 360] loss: 0.233\n",
      "Epoch: 57 -> Loss: 0.204351454973\n",
      "Epoch: 57 -> Test Accuracy: 83.6\n",
      "[58, 60] loss: 0.235\n",
      "[58, 120] loss: 0.224\n",
      "[58, 180] loss: 0.233\n",
      "[58, 240] loss: 0.233\n",
      "[58, 300] loss: 0.252\n",
      "[58, 360] loss: 0.249\n",
      "Epoch: 58 -> Loss: 0.282838642597\n",
      "Epoch: 58 -> Test Accuracy: 83.29\n",
      "[59, 60] loss: 0.210\n",
      "[59, 120] loss: 0.227\n",
      "[59, 180] loss: 0.238\n",
      "[59, 240] loss: 0.242\n",
      "[59, 300] loss: 0.245\n",
      "[59, 360] loss: 0.251\n",
      "Epoch: 59 -> Loss: 0.300481498241\n",
      "Epoch: 59 -> Test Accuracy: 83.2\n",
      "[60, 60] loss: 0.222\n",
      "[60, 120] loss: 0.237\n",
      "[60, 180] loss: 0.236\n",
      "[60, 240] loss: 0.235\n",
      "[60, 300] loss: 0.253\n",
      "[60, 360] loss: 0.237\n",
      "Epoch: 60 -> Loss: 0.160578802228\n",
      "Epoch: 60 -> Test Accuracy: 83.07\n",
      "[61, 60] loss: 0.213\n",
      "[61, 120] loss: 0.233\n",
      "[61, 180] loss: 0.232\n",
      "[61, 240] loss: 0.234\n",
      "[61, 300] loss: 0.244\n",
      "[61, 360] loss: 0.245\n",
      "Epoch: 61 -> Loss: 0.291521638632\n",
      "Epoch: 61 -> Test Accuracy: 83.3\n",
      "[62, 60] loss: 0.221\n",
      "[62, 120] loss: 0.249\n",
      "[62, 180] loss: 0.223\n",
      "[62, 240] loss: 0.230\n",
      "[62, 300] loss: 0.231\n",
      "[62, 360] loss: 0.247\n",
      "Epoch: 62 -> Loss: 0.21839466691\n",
      "Epoch: 62 -> Test Accuracy: 83.67\n",
      "[63, 60] loss: 0.221\n",
      "[63, 120] loss: 0.222\n",
      "[63, 180] loss: 0.238\n",
      "[63, 240] loss: 0.226\n",
      "[63, 300] loss: 0.238\n",
      "[63, 360] loss: 0.249\n",
      "Epoch: 63 -> Loss: 0.349877864122\n",
      "Epoch: 63 -> Test Accuracy: 83.16\n",
      "[64, 60] loss: 0.205\n",
      "[64, 120] loss: 0.227\n",
      "[64, 180] loss: 0.228\n",
      "[64, 240] loss: 0.232\n",
      "[64, 300] loss: 0.243\n",
      "[64, 360] loss: 0.240\n",
      "Epoch: 64 -> Loss: 0.2253254354\n",
      "Epoch: 64 -> Test Accuracy: 83.97\n",
      "[65, 60] loss: 0.220\n",
      "[65, 120] loss: 0.223\n",
      "[65, 180] loss: 0.230\n",
      "[65, 240] loss: 0.234\n",
      "[65, 300] loss: 0.224\n",
      "[65, 360] loss: 0.234\n",
      "Epoch: 65 -> Loss: 0.13227160275\n",
      "Epoch: 65 -> Test Accuracy: 83.59\n",
      "[66, 60] loss: 0.202\n",
      "[66, 120] loss: 0.221\n",
      "[66, 180] loss: 0.238\n",
      "[66, 240] loss: 0.235\n",
      "[66, 300] loss: 0.238\n",
      "[66, 360] loss: 0.244\n",
      "Epoch: 66 -> Loss: 0.237127736211\n",
      "Epoch: 66 -> Test Accuracy: 83.45\n",
      "[67, 60] loss: 0.221\n",
      "[67, 120] loss: 0.223\n",
      "[67, 180] loss: 0.227\n",
      "[67, 240] loss: 0.228\n",
      "[67, 300] loss: 0.237\n",
      "[67, 360] loss: 0.239\n",
      "Epoch: 67 -> Loss: 0.166134983301\n",
      "Epoch: 67 -> Test Accuracy: 83.41\n",
      "[68, 60] loss: 0.209\n",
      "[68, 120] loss: 0.225\n",
      "[68, 180] loss: 0.226\n",
      "[68, 240] loss: 0.232\n",
      "[68, 300] loss: 0.240\n",
      "[68, 360] loss: 0.254\n",
      "Epoch: 68 -> Loss: 0.178356960416\n",
      "Epoch: 68 -> Test Accuracy: 83.26\n",
      "[69, 60] loss: 0.223\n",
      "[69, 120] loss: 0.223\n",
      "[69, 180] loss: 0.221\n",
      "[69, 240] loss: 0.223\n",
      "[69, 300] loss: 0.254\n",
      "[69, 360] loss: 0.242\n",
      "Epoch: 69 -> Loss: 0.254440128803\n",
      "Epoch: 69 -> Test Accuracy: 83.57\n",
      "[70, 60] loss: 0.212\n",
      "[70, 120] loss: 0.219\n",
      "[70, 180] loss: 0.229\n",
      "[70, 240] loss: 0.230\n",
      "[70, 300] loss: 0.233\n",
      "[70, 360] loss: 0.246\n",
      "Epoch: 70 -> Loss: 0.190396592021\n",
      "Epoch: 70 -> Test Accuracy: 83.44\n",
      "[71, 60] loss: 0.193\n",
      "[71, 120] loss: 0.176\n",
      "[71, 180] loss: 0.176\n",
      "[71, 240] loss: 0.186\n",
      "[71, 300] loss: 0.169\n",
      "[71, 360] loss: 0.170\n",
      "Epoch: 71 -> Loss: 0.177175864577\n",
      "Epoch: 71 -> Test Accuracy: 84.86\n",
      "[72, 60] loss: 0.175\n",
      "[72, 120] loss: 0.159\n",
      "[72, 180] loss: 0.165\n",
      "[72, 240] loss: 0.165\n",
      "[72, 300] loss: 0.156\n",
      "[72, 360] loss: 0.164\n",
      "Epoch: 72 -> Loss: 0.171286255121\n",
      "Epoch: 72 -> Test Accuracy: 84.62\n",
      "[73, 60] loss: 0.159\n",
      "[73, 120] loss: 0.154\n",
      "[73, 180] loss: 0.159\n",
      "[73, 240] loss: 0.153\n",
      "[73, 300] loss: 0.152\n",
      "[73, 360] loss: 0.156\n",
      "Epoch: 73 -> Loss: 0.0984207391739\n",
      "Epoch: 73 -> Test Accuracy: 84.7\n",
      "[74, 60] loss: 0.143\n",
      "[74, 120] loss: 0.154\n",
      "[74, 180] loss: 0.153\n",
      "[74, 240] loss: 0.152\n",
      "[74, 300] loss: 0.146\n",
      "[74, 360] loss: 0.155\n",
      "Epoch: 74 -> Loss: 0.175467908382\n",
      "Epoch: 74 -> Test Accuracy: 84.7\n",
      "[75, 60] loss: 0.142\n",
      "[75, 120] loss: 0.147\n",
      "[75, 180] loss: 0.154\n",
      "[75, 240] loss: 0.143\n",
      "[75, 300] loss: 0.146\n",
      "[75, 360] loss: 0.148\n",
      "Epoch: 75 -> Loss: 0.231389716268\n",
      "Epoch: 75 -> Test Accuracy: 84.89\n",
      "[76, 60] loss: 0.138\n",
      "[76, 120] loss: 0.147\n",
      "[76, 180] loss: 0.140\n",
      "[76, 240] loss: 0.143\n",
      "[76, 300] loss: 0.145\n",
      "[76, 360] loss: 0.150\n",
      "Epoch: 76 -> Loss: 0.124104842544\n",
      "Epoch: 76 -> Test Accuracy: 84.47\n",
      "[77, 60] loss: 0.132\n",
      "[77, 120] loss: 0.143\n",
      "[77, 180] loss: 0.135\n",
      "[77, 240] loss: 0.144\n",
      "[77, 300] loss: 0.146\n",
      "[77, 360] loss: 0.142\n",
      "Epoch: 77 -> Loss: 0.202249482274\n",
      "Epoch: 77 -> Test Accuracy: 84.77\n",
      "[78, 60] loss: 0.135\n",
      "[78, 120] loss: 0.142\n",
      "[78, 180] loss: 0.145\n",
      "[78, 240] loss: 0.133\n",
      "[78, 300] loss: 0.140\n",
      "[78, 360] loss: 0.140\n",
      "Epoch: 78 -> Loss: 0.114086247981\n",
      "Epoch: 78 -> Test Accuracy: 84.88\n",
      "[79, 60] loss: 0.130\n",
      "[79, 120] loss: 0.131\n",
      "[79, 180] loss: 0.130\n",
      "[79, 240] loss: 0.144\n",
      "[79, 300] loss: 0.134\n",
      "[79, 360] loss: 0.136\n",
      "Epoch: 79 -> Loss: 0.108104944229\n",
      "Epoch: 79 -> Test Accuracy: 84.82\n",
      "[80, 60] loss: 0.127\n",
      "[80, 120] loss: 0.133\n",
      "[80, 180] loss: 0.139\n",
      "[80, 240] loss: 0.134\n",
      "[80, 300] loss: 0.130\n",
      "[80, 360] loss: 0.139\n",
      "Epoch: 80 -> Loss: 0.146549865603\n",
      "Epoch: 80 -> Test Accuracy: 84.59\n",
      "[81, 60] loss: 0.128\n",
      "[81, 120] loss: 0.129\n",
      "[81, 180] loss: 0.127\n",
      "[81, 240] loss: 0.131\n",
      "[81, 300] loss: 0.125\n",
      "[81, 360] loss: 0.136\n",
      "Epoch: 81 -> Loss: 0.124700501561\n",
      "Epoch: 81 -> Test Accuracy: 84.63\n",
      "[82, 60] loss: 0.123\n",
      "[82, 120] loss: 0.121\n",
      "[82, 180] loss: 0.123\n",
      "[82, 240] loss: 0.138\n",
      "[82, 300] loss: 0.130\n",
      "[82, 360] loss: 0.134\n",
      "Epoch: 82 -> Loss: 0.141051828861\n",
      "Epoch: 82 -> Test Accuracy: 84.69\n",
      "[83, 60] loss: 0.120\n",
      "[83, 120] loss: 0.122\n",
      "[83, 180] loss: 0.127\n",
      "[83, 240] loss: 0.126\n",
      "[83, 300] loss: 0.133\n",
      "[83, 360] loss: 0.125\n",
      "Epoch: 83 -> Loss: 0.139468163252\n",
      "Epoch: 83 -> Test Accuracy: 84.72\n",
      "[84, 60] loss: 0.126\n",
      "[84, 120] loss: 0.128\n",
      "[84, 180] loss: 0.123\n",
      "[84, 240] loss: 0.134\n",
      "[84, 300] loss: 0.131\n",
      "[84, 360] loss: 0.129\n",
      "Epoch: 84 -> Loss: 0.110215187073\n",
      "Epoch: 84 -> Test Accuracy: 84.77\n",
      "[85, 60] loss: 0.123\n",
      "[85, 120] loss: 0.126\n",
      "[85, 180] loss: 0.127\n",
      "[85, 240] loss: 0.125\n",
      "[85, 300] loss: 0.125\n",
      "[85, 360] loss: 0.126\n",
      "Epoch: 85 -> Loss: 0.0831171497703\n",
      "Epoch: 85 -> Test Accuracy: 84.86\n",
      "[86, 60] loss: 0.120\n",
      "[86, 120] loss: 0.118\n",
      "[86, 180] loss: 0.119\n",
      "[86, 240] loss: 0.114\n",
      "[86, 300] loss: 0.114\n",
      "[86, 360] loss: 0.114\n",
      "Epoch: 86 -> Loss: 0.0824557989836\n",
      "Epoch: 86 -> Test Accuracy: 85.3\n",
      "[87, 60] loss: 0.115\n",
      "[87, 120] loss: 0.108\n",
      "[87, 180] loss: 0.111\n",
      "[87, 240] loss: 0.112\n",
      "[87, 300] loss: 0.113\n",
      "[87, 360] loss: 0.104\n",
      "Epoch: 87 -> Loss: 0.11882455647\n",
      "Epoch: 87 -> Test Accuracy: 85.1\n",
      "[88, 60] loss: 0.107\n",
      "[88, 120] loss: 0.108\n",
      "[88, 180] loss: 0.109\n",
      "[88, 240] loss: 0.111\n",
      "[88, 300] loss: 0.107\n",
      "[88, 360] loss: 0.116\n",
      "Epoch: 88 -> Loss: 0.169601291418\n",
      "Epoch: 88 -> Test Accuracy: 85.18\n",
      "[89, 60] loss: 0.109\n",
      "[89, 120] loss: 0.108\n",
      "[89, 180] loss: 0.104\n",
      "[89, 240] loss: 0.113\n",
      "[89, 300] loss: 0.114\n",
      "[89, 360] loss: 0.106\n",
      "Epoch: 89 -> Loss: 0.0594609007239\n",
      "Epoch: 89 -> Test Accuracy: 85.22\n",
      "[90, 60] loss: 0.105\n",
      "[90, 120] loss: 0.111\n",
      "[90, 180] loss: 0.108\n",
      "[90, 240] loss: 0.110\n",
      "[90, 300] loss: 0.101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90, 360] loss: 0.111\n",
      "Epoch: 90 -> Loss: 0.0566617138684\n",
      "Epoch: 90 -> Test Accuracy: 85.08\n",
      "[91, 60] loss: 0.105\n",
      "[91, 120] loss: 0.103\n",
      "[91, 180] loss: 0.109\n",
      "[91, 240] loss: 0.110\n",
      "[91, 300] loss: 0.108\n",
      "[91, 360] loss: 0.105\n",
      "Epoch: 91 -> Loss: 0.0784490630031\n",
      "Epoch: 91 -> Test Accuracy: 85.13\n",
      "[92, 60] loss: 0.105\n",
      "[92, 120] loss: 0.104\n",
      "[92, 180] loss: 0.106\n",
      "[92, 240] loss: 0.106\n",
      "[92, 300] loss: 0.104\n",
      "[92, 360] loss: 0.106\n",
      "Epoch: 92 -> Loss: 0.179231435061\n",
      "Epoch: 92 -> Test Accuracy: 85.1\n",
      "[93, 60] loss: 0.106\n",
      "[93, 120] loss: 0.111\n",
      "[93, 180] loss: 0.104\n",
      "[93, 240] loss: 0.102\n",
      "[93, 300] loss: 0.107\n",
      "[93, 360] loss: 0.103\n",
      "Epoch: 93 -> Loss: 0.0651546195149\n",
      "Epoch: 93 -> Test Accuracy: 84.99\n",
      "[94, 60] loss: 0.102\n",
      "[94, 120] loss: 0.098\n",
      "[94, 180] loss: 0.105\n",
      "[94, 240] loss: 0.106\n",
      "[94, 300] loss: 0.106\n",
      "[94, 360] loss: 0.105\n",
      "Epoch: 94 -> Loss: 0.101241387427\n",
      "Epoch: 94 -> Test Accuracy: 84.99\n",
      "[95, 60] loss: 0.109\n",
      "[95, 120] loss: 0.106\n",
      "[95, 180] loss: 0.104\n",
      "[95, 240] loss: 0.110\n",
      "[95, 300] loss: 0.101\n",
      "[95, 360] loss: 0.110\n",
      "Epoch: 95 -> Loss: 0.0894213318825\n",
      "Epoch: 95 -> Test Accuracy: 85.13\n",
      "[96, 60] loss: 0.101\n",
      "[96, 120] loss: 0.105\n",
      "[96, 180] loss: 0.103\n",
      "[96, 240] loss: 0.104\n",
      "[96, 300] loss: 0.107\n",
      "[96, 360] loss: 0.107\n",
      "Epoch: 96 -> Loss: 0.0813144221902\n",
      "Epoch: 96 -> Test Accuracy: 85.17\n",
      "[97, 60] loss: 0.094\n",
      "[97, 120] loss: 0.102\n",
      "[97, 180] loss: 0.108\n",
      "[97, 240] loss: 0.102\n",
      "[97, 300] loss: 0.102\n",
      "[97, 360] loss: 0.097\n",
      "Epoch: 97 -> Loss: 0.166965335608\n",
      "Epoch: 97 -> Test Accuracy: 85.01\n",
      "[98, 60] loss: 0.096\n",
      "[98, 120] loss: 0.104\n",
      "[98, 180] loss: 0.105\n",
      "[98, 240] loss: 0.098\n",
      "[98, 300] loss: 0.103\n",
      "[98, 360] loss: 0.101\n",
      "Epoch: 98 -> Loss: 0.0970427766442\n",
      "Epoch: 98 -> Test Accuracy: 85.2\n",
      "[99, 60] loss: 0.106\n",
      "[99, 120] loss: 0.098\n",
      "[99, 180] loss: 0.102\n",
      "[99, 240] loss: 0.098\n",
      "[99, 300] loss: 0.102\n",
      "[99, 360] loss: 0.100\n",
      "Epoch: 99 -> Loss: 0.0899411588907\n",
      "Epoch: 99 -> Test Accuracy: 85.14\n",
      "[100, 60] loss: 0.099\n",
      "[100, 120] loss: 0.102\n",
      "[100, 180] loss: 0.101\n",
      "[100, 240] loss: 0.103\n",
      "[100, 300] loss: 0.102\n",
      "[100, 360] loss: 0.094\n",
      "Epoch: 100 -> Loss: 0.0914579704404\n",
      "Epoch: 100 -> Test Accuracy: 85.15\n",
      "Finished Training\n",
      "[1, 60] loss: 1.477\n",
      "[1, 120] loss: 1.170\n",
      "[1, 180] loss: 1.105\n",
      "[1, 240] loss: 1.036\n",
      "[1, 300] loss: 1.027\n",
      "[1, 360] loss: 1.011\n",
      "Epoch: 1 -> Loss: 1.29146075249\n",
      "Epoch: 1 -> Test Accuracy: 59.01\n",
      "[2, 60] loss: 0.996\n",
      "[2, 120] loss: 0.970\n",
      "[2, 180] loss: 0.973\n",
      "[2, 240] loss: 0.955\n",
      "[2, 300] loss: 0.935\n",
      "[2, 360] loss: 0.920\n",
      "Epoch: 2 -> Loss: 0.989014327526\n",
      "Epoch: 2 -> Test Accuracy: 61.38\n",
      "[3, 60] loss: 0.903\n",
      "[3, 120] loss: 0.923\n",
      "[3, 180] loss: 0.922\n",
      "[3, 240] loss: 0.889\n",
      "[3, 300] loss: 0.918\n",
      "[3, 360] loss: 0.911\n",
      "Epoch: 3 -> Loss: 1.02579319477\n",
      "Epoch: 3 -> Test Accuracy: 62.38\n",
      "[4, 60] loss: 0.901\n",
      "[4, 120] loss: 0.880\n",
      "[4, 180] loss: 0.895\n",
      "[4, 240] loss: 0.868\n",
      "[4, 300] loss: 0.886\n",
      "[4, 360] loss: 0.872\n",
      "Epoch: 4 -> Loss: 0.795169174671\n",
      "Epoch: 4 -> Test Accuracy: 63.09\n",
      "[5, 60] loss: 0.871\n",
      "[5, 120] loss: 0.874\n",
      "[5, 180] loss: 0.877\n",
      "[5, 240] loss: 0.871\n",
      "[5, 300] loss: 0.867\n",
      "[5, 360] loss: 0.884\n",
      "Epoch: 5 -> Loss: 1.03900039196\n",
      "Epoch: 5 -> Test Accuracy: 62.6\n",
      "[6, 60] loss: 0.884\n",
      "[6, 120] loss: 0.881\n",
      "[6, 180] loss: 0.864\n",
      "[6, 240] loss: 0.846\n",
      "[6, 300] loss: 0.874\n",
      "[6, 360] loss: 0.859\n",
      "Epoch: 6 -> Loss: 0.776762843132\n",
      "Epoch: 6 -> Test Accuracy: 62.36\n",
      "[7, 60] loss: 0.859\n",
      "[7, 120] loss: 0.863\n",
      "[7, 180] loss: 0.845\n",
      "[7, 240] loss: 0.852\n",
      "[7, 300] loss: 0.857\n",
      "[7, 360] loss: 0.856\n",
      "Epoch: 7 -> Loss: 0.890381336212\n",
      "Epoch: 7 -> Test Accuracy: 65.08\n",
      "[8, 60] loss: 0.864\n",
      "[8, 120] loss: 0.824\n",
      "[8, 180] loss: 0.845\n",
      "[8, 240] loss: 0.836\n",
      "[8, 300] loss: 0.861\n",
      "[8, 360] loss: 0.865\n",
      "Epoch: 8 -> Loss: 1.0472625494\n",
      "Epoch: 8 -> Test Accuracy: 64.23\n",
      "[9, 60] loss: 0.846\n",
      "[9, 120] loss: 0.849\n",
      "[9, 180] loss: 0.844\n",
      "[9, 240] loss: 0.838\n",
      "[9, 300] loss: 0.825\n",
      "[9, 360] loss: 0.864\n",
      "Epoch: 9 -> Loss: 0.957485675812\n",
      "Epoch: 9 -> Test Accuracy: 64.83\n",
      "[10, 60] loss: 0.825\n",
      "[10, 120] loss: 0.856\n",
      "[10, 180] loss: 0.827\n",
      "[10, 240] loss: 0.843\n",
      "[10, 300] loss: 0.827\n",
      "[10, 360] loss: 0.835\n",
      "Epoch: 10 -> Loss: 0.722516238689\n",
      "Epoch: 10 -> Test Accuracy: 64.25\n",
      "[11, 60] loss: 0.825\n",
      "[11, 120] loss: 0.848\n",
      "[11, 180] loss: 0.828\n",
      "[11, 240] loss: 0.839\n",
      "[11, 300] loss: 0.821\n",
      "[11, 360] loss: 0.843\n",
      "Epoch: 11 -> Loss: 0.954572498798\n",
      "Epoch: 11 -> Test Accuracy: 64.82\n",
      "[12, 60] loss: 0.828\n",
      "[12, 120] loss: 0.841\n",
      "[12, 180] loss: 0.827\n",
      "[12, 240] loss: 0.821\n",
      "[12, 300] loss: 0.831\n",
      "[12, 360] loss: 0.839\n",
      "Epoch: 12 -> Loss: 0.679040074348\n",
      "Epoch: 12 -> Test Accuracy: 65.0\n",
      "[13, 60] loss: 0.837\n",
      "[13, 120] loss: 0.836\n",
      "[13, 180] loss: 0.804\n",
      "[13, 240] loss: 0.804\n",
      "[13, 300] loss: 0.822\n",
      "[13, 360] loss: 0.841\n",
      "Epoch: 13 -> Loss: 1.16653943062\n",
      "Epoch: 13 -> Test Accuracy: 64.15\n",
      "[14, 60] loss: 0.821\n",
      "[14, 120] loss: 0.847\n",
      "[14, 180] loss: 0.812\n",
      "[14, 240] loss: 0.798\n",
      "[14, 300] loss: 0.825\n",
      "[14, 360] loss: 0.822\n",
      "Epoch: 14 -> Loss: 0.889801502228\n",
      "Epoch: 14 -> Test Accuracy: 65.46\n",
      "[15, 60] loss: 0.795\n",
      "[15, 120] loss: 0.835\n",
      "[15, 180] loss: 0.825\n",
      "[15, 240] loss: 0.821\n",
      "[15, 300] loss: 0.818\n",
      "[15, 360] loss: 0.829\n",
      "Epoch: 15 -> Loss: 0.806725382805\n",
      "Epoch: 15 -> Test Accuracy: 64.08\n",
      "[16, 60] loss: 0.807\n",
      "[16, 120] loss: 0.826\n",
      "[16, 180] loss: 0.820\n",
      "[16, 240] loss: 0.818\n",
      "[16, 300] loss: 0.830\n",
      "[16, 360] loss: 0.814\n",
      "Epoch: 16 -> Loss: 0.742408156395\n",
      "Epoch: 16 -> Test Accuracy: 65.05\n",
      "[17, 60] loss: 0.801\n",
      "[17, 120] loss: 0.791\n",
      "[17, 180] loss: 0.818\n",
      "[17, 240] loss: 0.845\n",
      "[17, 300] loss: 0.807\n",
      "[17, 360] loss: 0.826\n",
      "Epoch: 17 -> Loss: 0.893497347832\n",
      "Epoch: 17 -> Test Accuracy: 65.36\n",
      "[18, 60] loss: 0.820\n",
      "[18, 120] loss: 0.783\n",
      "[18, 180] loss: 0.818\n",
      "[18, 240] loss: 0.826\n",
      "[18, 300] loss: 0.818\n",
      "[18, 360] loss: 0.837\n",
      "Epoch: 18 -> Loss: 0.890633940697\n",
      "Epoch: 18 -> Test Accuracy: 64.78\n",
      "[19, 60] loss: 0.817\n",
      "[19, 120] loss: 0.807\n",
      "[19, 180] loss: 0.825\n",
      "[19, 240] loss: 0.812\n",
      "[19, 300] loss: 0.815\n",
      "[19, 360] loss: 0.807\n",
      "Epoch: 19 -> Loss: 0.78113758564\n",
      "Epoch: 19 -> Test Accuracy: 65.32\n",
      "[20, 60] loss: 0.810\n",
      "[20, 120] loss: 0.815\n",
      "[20, 180] loss: 0.811\n",
      "[20, 240] loss: 0.805\n",
      "[20, 300] loss: 0.833\n",
      "[20, 360] loss: 0.796\n",
      "Epoch: 20 -> Loss: 0.707835078239\n",
      "Epoch: 20 -> Test Accuracy: 65.32\n",
      "[21, 60] loss: 0.823\n",
      "[21, 120] loss: 0.810\n",
      "[21, 180] loss: 0.806\n",
      "[21, 240] loss: 0.814\n",
      "[21, 300] loss: 0.787\n",
      "[21, 360] loss: 0.821\n",
      "Epoch: 21 -> Loss: 0.833182632923\n",
      "Epoch: 21 -> Test Accuracy: 65.89\n",
      "[22, 60] loss: 0.821\n",
      "[22, 120] loss: 0.799\n",
      "[22, 180] loss: 0.814\n",
      "[22, 240] loss: 0.788\n",
      "[22, 300] loss: 0.823\n",
      "[22, 360] loss: 0.821\n",
      "Epoch: 22 -> Loss: 0.926984965801\n",
      "Epoch: 22 -> Test Accuracy: 64.12\n",
      "[23, 60] loss: 0.814\n",
      "[23, 120] loss: 0.807\n",
      "[23, 180] loss: 0.802\n",
      "[23, 240] loss: 0.803\n",
      "[23, 300] loss: 0.815\n",
      "[23, 360] loss: 0.817\n",
      "Epoch: 23 -> Loss: 0.717298686504\n",
      "Epoch: 23 -> Test Accuracy: 65.72\n",
      "[24, 60] loss: 0.805\n",
      "[24, 120] loss: 0.803\n",
      "[24, 180] loss: 0.820\n",
      "[24, 240] loss: 0.810\n",
      "[24, 300] loss: 0.805\n",
      "[24, 360] loss: 0.806\n",
      "Epoch: 24 -> Loss: 0.771484076977\n",
      "Epoch: 24 -> Test Accuracy: 65.71\n",
      "[25, 60] loss: 0.800\n",
      "[25, 120] loss: 0.794\n",
      "[25, 180] loss: 0.796\n",
      "[25, 240] loss: 0.808\n",
      "[25, 300] loss: 0.809\n",
      "[25, 360] loss: 0.823\n",
      "Epoch: 25 -> Loss: 0.87439841032\n",
      "Epoch: 25 -> Test Accuracy: 64.47\n",
      "[26, 60] loss: 0.806\n",
      "[26, 120] loss: 0.807\n",
      "[26, 180] loss: 0.791\n",
      "[26, 240] loss: 0.828\n",
      "[26, 300] loss: 0.802\n",
      "[26, 360] loss: 0.801\n",
      "Epoch: 26 -> Loss: 0.713323712349\n",
      "Epoch: 26 -> Test Accuracy: 65.18\n",
      "[27, 60] loss: 0.805\n",
      "[27, 120] loss: 0.803\n",
      "[27, 180] loss: 0.815\n",
      "[27, 240] loss: 0.810\n",
      "[27, 300] loss: 0.785\n",
      "[27, 360] loss: 0.814\n",
      "Epoch: 27 -> Loss: 0.924541294575\n",
      "Epoch: 27 -> Test Accuracy: 65.77\n",
      "[28, 60] loss: 0.823\n",
      "[28, 120] loss: 0.808\n",
      "[28, 180] loss: 0.801\n",
      "[28, 240] loss: 0.784\n",
      "[28, 300] loss: 0.802\n",
      "[28, 360] loss: 0.797\n",
      "Epoch: 28 -> Loss: 0.937145233154\n",
      "Epoch: 28 -> Test Accuracy: 65.28\n",
      "[29, 60] loss: 0.782\n",
      "[29, 120] loss: 0.780\n",
      "[29, 180] loss: 0.831\n",
      "[29, 240] loss: 0.813\n",
      "[29, 300] loss: 0.808\n",
      "[29, 360] loss: 0.808\n",
      "Epoch: 29 -> Loss: 0.988396346569\n",
      "Epoch: 29 -> Test Accuracy: 66.12\n",
      "[30, 60] loss: 0.798\n",
      "[30, 120] loss: 0.822\n",
      "[30, 180] loss: 0.803\n",
      "[30, 240] loss: 0.804\n",
      "[30, 300] loss: 0.827\n",
      "[30, 360] loss: 0.826\n",
      "Epoch: 30 -> Loss: 0.726292133331\n",
      "Epoch: 30 -> Test Accuracy: 64.75\n",
      "[31, 60] loss: 0.792\n",
      "[31, 120] loss: 0.803\n",
      "[31, 180] loss: 0.817\n",
      "[31, 240] loss: 0.812\n",
      "[31, 300] loss: 0.817\n",
      "[31, 360] loss: 0.796\n",
      "Epoch: 31 -> Loss: 0.660496354103\n",
      "Epoch: 31 -> Test Accuracy: 65.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 60] loss: 0.789\n",
      "[32, 120] loss: 0.825\n",
      "[32, 180] loss: 0.800\n",
      "[32, 240] loss: 0.795\n",
      "[32, 300] loss: 0.799\n",
      "[32, 360] loss: 0.816\n",
      "Epoch: 32 -> Loss: 0.536200046539\n",
      "Epoch: 32 -> Test Accuracy: 65.8\n",
      "[33, 60] loss: 0.782\n",
      "[33, 120] loss: 0.787\n",
      "[33, 180] loss: 0.818\n",
      "[33, 240] loss: 0.796\n",
      "[33, 300] loss: 0.798\n",
      "[33, 360] loss: 0.813\n",
      "Epoch: 33 -> Loss: 0.817380428314\n",
      "Epoch: 33 -> Test Accuracy: 65.58\n",
      "[34, 60] loss: 0.781\n",
      "[34, 120] loss: 0.808\n",
      "[34, 180] loss: 0.817\n",
      "[34, 240] loss: 0.818\n",
      "[34, 300] loss: 0.819\n",
      "[34, 360] loss: 0.795\n",
      "Epoch: 34 -> Loss: 0.626615107059\n",
      "Epoch: 34 -> Test Accuracy: 64.77\n",
      "[35, 60] loss: 0.798\n",
      "[35, 120] loss: 0.808\n",
      "[35, 180] loss: 0.811\n",
      "[35, 240] loss: 0.790\n",
      "[35, 300] loss: 0.791\n",
      "[35, 360] loss: 0.796\n",
      "Epoch: 35 -> Loss: 0.773610949516\n",
      "Epoch: 35 -> Test Accuracy: 66.33\n",
      "[36, 60] loss: 0.754\n",
      "[36, 120] loss: 0.707\n",
      "[36, 180] loss: 0.700\n",
      "[36, 240] loss: 0.701\n",
      "[36, 300] loss: 0.703\n",
      "[36, 360] loss: 0.703\n",
      "Epoch: 36 -> Loss: 0.5983902812\n",
      "Epoch: 36 -> Test Accuracy: 69.6\n",
      "[37, 60] loss: 0.693\n",
      "[37, 120] loss: 0.696\n",
      "[37, 180] loss: 0.699\n",
      "[37, 240] loss: 0.669\n",
      "[37, 300] loss: 0.687\n",
      "[37, 360] loss: 0.717\n",
      "Epoch: 37 -> Loss: 0.708930373192\n",
      "Epoch: 37 -> Test Accuracy: 69.22\n",
      "[38, 60] loss: 0.667\n",
      "[38, 120] loss: 0.683\n",
      "[38, 180] loss: 0.686\n",
      "[38, 240] loss: 0.698\n",
      "[38, 300] loss: 0.689\n",
      "[38, 360] loss: 0.664\n",
      "Epoch: 38 -> Loss: 0.615850806236\n",
      "Epoch: 38 -> Test Accuracy: 68.88\n",
      "[39, 60] loss: 0.650\n",
      "[39, 120] loss: 0.664\n",
      "[39, 180] loss: 0.672\n",
      "[39, 240] loss: 0.682\n",
      "[39, 300] loss: 0.677\n",
      "[39, 360] loss: 0.686\n",
      "Epoch: 39 -> Loss: 0.652957081795\n",
      "Epoch: 39 -> Test Accuracy: 70.22\n",
      "[40, 60] loss: 0.667\n",
      "[40, 120] loss: 0.683\n",
      "[40, 180] loss: 0.658\n",
      "[40, 240] loss: 0.665\n",
      "[40, 300] loss: 0.682\n",
      "[40, 360] loss: 0.695\n",
      "Epoch: 40 -> Loss: 0.837391197681\n",
      "Epoch: 40 -> Test Accuracy: 69.61\n",
      "[41, 60] loss: 0.669\n",
      "[41, 120] loss: 0.673\n",
      "[41, 180] loss: 0.682\n",
      "[41, 240] loss: 0.688\n",
      "[41, 300] loss: 0.669\n",
      "[41, 360] loss: 0.677\n",
      "Epoch: 41 -> Loss: 0.754501998425\n",
      "Epoch: 41 -> Test Accuracy: 69.72\n",
      "[42, 60] loss: 0.673\n",
      "[42, 120] loss: 0.672\n",
      "[42, 180] loss: 0.666\n",
      "[42, 240] loss: 0.664\n",
      "[42, 300] loss: 0.662\n",
      "[42, 360] loss: 0.677\n",
      "Epoch: 42 -> Loss: 0.697021365166\n",
      "Epoch: 42 -> Test Accuracy: 69.74\n",
      "[43, 60] loss: 0.659\n",
      "[43, 120] loss: 0.665\n",
      "[43, 180] loss: 0.672\n",
      "[43, 240] loss: 0.669\n",
      "[43, 300] loss: 0.668\n",
      "[43, 360] loss: 0.692\n",
      "Epoch: 43 -> Loss: 0.628744482994\n",
      "Epoch: 43 -> Test Accuracy: 69.68\n",
      "[44, 60] loss: 0.674\n",
      "[44, 120] loss: 0.674\n",
      "[44, 180] loss: 0.688\n",
      "[44, 240] loss: 0.661\n",
      "[44, 300] loss: 0.674\n",
      "[44, 360] loss: 0.671\n",
      "Epoch: 44 -> Loss: 0.559017598629\n",
      "Epoch: 44 -> Test Accuracy: 69.89\n",
      "[45, 60] loss: 0.661\n",
      "[45, 120] loss: 0.685\n",
      "[45, 180] loss: 0.677\n",
      "[45, 240] loss: 0.658\n",
      "[45, 300] loss: 0.663\n",
      "[45, 360] loss: 0.664\n",
      "Epoch: 45 -> Loss: 0.684351444244\n",
      "Epoch: 45 -> Test Accuracy: 70.11\n",
      "[46, 60] loss: 0.656\n",
      "[46, 120] loss: 0.679\n",
      "[46, 180] loss: 0.685\n",
      "[46, 240] loss: 0.652\n",
      "[46, 300] loss: 0.667\n",
      "[46, 360] loss: 0.672\n",
      "Epoch: 46 -> Loss: 0.800442695618\n",
      "Epoch: 46 -> Test Accuracy: 70.24\n",
      "[47, 60] loss: 0.649\n",
      "[47, 120] loss: 0.679\n",
      "[47, 180] loss: 0.662\n",
      "[47, 240] loss: 0.685\n",
      "[47, 300] loss: 0.675\n",
      "[47, 360] loss: 0.666\n",
      "Epoch: 47 -> Loss: 0.643348157406\n",
      "Epoch: 47 -> Test Accuracy: 69.72\n",
      "[48, 60] loss: 0.665\n",
      "[48, 120] loss: 0.674\n",
      "[48, 180] loss: 0.659\n",
      "[48, 240] loss: 0.691\n",
      "[48, 300] loss: 0.665\n",
      "[48, 360] loss: 0.672\n",
      "Epoch: 48 -> Loss: 0.619407951832\n",
      "Epoch: 48 -> Test Accuracy: 69.47\n",
      "[49, 60] loss: 0.663\n",
      "[49, 120] loss: 0.685\n",
      "[49, 180] loss: 0.663\n",
      "[49, 240] loss: 0.665\n",
      "[49, 300] loss: 0.679\n",
      "[49, 360] loss: 0.686\n",
      "Epoch: 49 -> Loss: 0.862009227276\n",
      "Epoch: 49 -> Test Accuracy: 70.35\n",
      "[50, 60] loss: 0.659\n",
      "[50, 120] loss: 0.666\n",
      "[50, 180] loss: 0.662\n",
      "[50, 240] loss: 0.678\n",
      "[50, 300] loss: 0.684\n",
      "[50, 360] loss: 0.668\n",
      "Epoch: 50 -> Loss: 0.870974361897\n",
      "Epoch: 50 -> Test Accuracy: 69.77\n",
      "[51, 60] loss: 0.678\n",
      "[51, 120] loss: 0.667\n",
      "[51, 180] loss: 0.668\n",
      "[51, 240] loss: 0.667\n",
      "[51, 300] loss: 0.688\n",
      "[51, 360] loss: 0.658\n",
      "Epoch: 51 -> Loss: 0.787436246872\n",
      "Epoch: 51 -> Test Accuracy: 70.27\n",
      "[52, 60] loss: 0.678\n",
      "[52, 120] loss: 0.662\n",
      "[52, 180] loss: 0.662\n",
      "[52, 240] loss: 0.678\n",
      "[52, 300] loss: 0.674\n",
      "[52, 360] loss: 0.661\n",
      "Epoch: 52 -> Loss: 0.541746616364\n",
      "Epoch: 52 -> Test Accuracy: 69.9\n",
      "[53, 60] loss: 0.661\n",
      "[53, 120] loss: 0.664\n",
      "[53, 180] loss: 0.685\n",
      "[53, 240] loss: 0.651\n",
      "[53, 300] loss: 0.656\n",
      "[53, 360] loss: 0.678\n",
      "Epoch: 53 -> Loss: 0.55658352375\n",
      "Epoch: 53 -> Test Accuracy: 69.8\n",
      "[54, 60] loss: 0.655\n",
      "[54, 120] loss: 0.671\n",
      "[54, 180] loss: 0.671\n",
      "[54, 240] loss: 0.670\n",
      "[54, 300] loss: 0.664\n",
      "[54, 360] loss: 0.688\n",
      "Epoch: 54 -> Loss: 0.727522552013\n",
      "Epoch: 54 -> Test Accuracy: 69.89\n",
      "[55, 60] loss: 0.651\n",
      "[55, 120] loss: 0.655\n",
      "[55, 180] loss: 0.657\n",
      "[55, 240] loss: 0.659\n",
      "[55, 300] loss: 0.688\n",
      "[55, 360] loss: 0.681\n",
      "Epoch: 55 -> Loss: 0.950541198254\n",
      "Epoch: 55 -> Test Accuracy: 69.78\n",
      "[56, 60] loss: 0.681\n",
      "[56, 120] loss: 0.660\n",
      "[56, 180] loss: 0.670\n",
      "[56, 240] loss: 0.675\n",
      "[56, 300] loss: 0.680\n",
      "[56, 360] loss: 0.652\n",
      "Epoch: 56 -> Loss: 0.594933629036\n",
      "Epoch: 56 -> Test Accuracy: 69.07\n",
      "[57, 60] loss: 0.674\n",
      "[57, 120] loss: 0.673\n",
      "[57, 180] loss: 0.645\n",
      "[57, 240] loss: 0.674\n",
      "[57, 300] loss: 0.676\n",
      "[57, 360] loss: 0.675\n",
      "Epoch: 57 -> Loss: 0.766239225864\n",
      "Epoch: 57 -> Test Accuracy: 69.43\n",
      "[58, 60] loss: 0.660\n",
      "[58, 120] loss: 0.664\n",
      "[58, 180] loss: 0.670\n",
      "[58, 240] loss: 0.656\n",
      "[58, 300] loss: 0.674\n",
      "[58, 360] loss: 0.661\n",
      "Epoch: 58 -> Loss: 0.777118802071\n",
      "Epoch: 58 -> Test Accuracy: 70.72\n",
      "[59, 60] loss: 0.653\n",
      "[59, 120] loss: 0.661\n",
      "[59, 180] loss: 0.670\n",
      "[59, 240] loss: 0.673\n",
      "[59, 300] loss: 0.665\n",
      "[59, 360] loss: 0.672\n",
      "Epoch: 59 -> Loss: 0.701868593693\n",
      "Epoch: 59 -> Test Accuracy: 69.53\n",
      "[60, 60] loss: 0.655\n",
      "[60, 120] loss: 0.679\n",
      "[60, 180] loss: 0.673\n",
      "[60, 240] loss: 0.668\n",
      "[60, 300] loss: 0.666\n",
      "[60, 360] loss: 0.673\n",
      "Epoch: 60 -> Loss: 0.636992931366\n",
      "Epoch: 60 -> Test Accuracy: 69.28\n",
      "[61, 60] loss: 0.672\n",
      "[61, 120] loss: 0.652\n",
      "[61, 180] loss: 0.676\n",
      "[61, 240] loss: 0.682\n",
      "[61, 300] loss: 0.665\n",
      "[61, 360] loss: 0.677\n",
      "Epoch: 61 -> Loss: 0.704750478268\n",
      "Epoch: 61 -> Test Accuracy: 69.9\n",
      "[62, 60] loss: 0.654\n",
      "[62, 120] loss: 0.661\n",
      "[62, 180] loss: 0.668\n",
      "[62, 240] loss: 0.659\n",
      "[62, 300] loss: 0.673\n",
      "[62, 360] loss: 0.650\n",
      "Epoch: 62 -> Loss: 0.625927209854\n",
      "Epoch: 62 -> Test Accuracy: 70.0\n",
      "[63, 60] loss: 0.666\n",
      "[63, 120] loss: 0.651\n",
      "[63, 180] loss: 0.670\n",
      "[63, 240] loss: 0.679\n",
      "[63, 300] loss: 0.667\n",
      "[63, 360] loss: 0.658\n",
      "Epoch: 63 -> Loss: 0.570514380932\n",
      "Epoch: 63 -> Test Accuracy: 69.47\n",
      "[64, 60] loss: 0.644\n",
      "[64, 120] loss: 0.673\n",
      "[64, 180] loss: 0.676\n",
      "[64, 240] loss: 0.681\n",
      "[64, 300] loss: 0.666\n",
      "[64, 360] loss: 0.665\n",
      "Epoch: 64 -> Loss: 0.499749183655\n",
      "Epoch: 64 -> Test Accuracy: 70.13\n",
      "[65, 60] loss: 0.652\n",
      "[65, 120] loss: 0.667\n",
      "[65, 180] loss: 0.674\n",
      "[65, 240] loss: 0.673\n",
      "[65, 300] loss: 0.675\n",
      "[65, 360] loss: 0.663\n",
      "Epoch: 65 -> Loss: 0.502461075783\n",
      "Epoch: 65 -> Test Accuracy: 69.45\n",
      "[66, 60] loss: 0.663\n",
      "[66, 120] loss: 0.653\n",
      "[66, 180] loss: 0.678\n",
      "[66, 240] loss: 0.670\n",
      "[66, 300] loss: 0.656\n",
      "[66, 360] loss: 0.664\n",
      "Epoch: 66 -> Loss: 0.848683178425\n",
      "Epoch: 66 -> Test Accuracy: 70.13\n",
      "[67, 60] loss: 0.672\n",
      "[67, 120] loss: 0.651\n",
      "[67, 180] loss: 0.669\n",
      "[67, 240] loss: 0.673\n",
      "[67, 300] loss: 0.665\n",
      "[67, 360] loss: 0.658\n",
      "Epoch: 67 -> Loss: 0.666661262512\n",
      "Epoch: 67 -> Test Accuracy: 69.23\n",
      "[68, 60] loss: 0.674\n",
      "[68, 120] loss: 0.663\n",
      "[68, 180] loss: 0.672\n",
      "[68, 240] loss: 0.651\n",
      "[68, 300] loss: 0.642\n",
      "[68, 360] loss: 0.660\n",
      "Epoch: 68 -> Loss: 0.637833952904\n",
      "Epoch: 68 -> Test Accuracy: 69.41\n",
      "[69, 60] loss: 0.653\n",
      "[69, 120] loss: 0.670\n",
      "[69, 180] loss: 0.682\n",
      "[69, 240] loss: 0.656\n",
      "[69, 300] loss: 0.648\n",
      "[69, 360] loss: 0.656\n",
      "Epoch: 69 -> Loss: 0.776985645294\n",
      "Epoch: 69 -> Test Accuracy: 69.57\n",
      "[70, 60] loss: 0.649\n",
      "[70, 120] loss: 0.664\n",
      "[70, 180] loss: 0.653\n",
      "[70, 240] loss: 0.648\n",
      "[70, 300] loss: 0.656\n",
      "[70, 360] loss: 0.675\n",
      "Epoch: 70 -> Loss: 0.618579626083\n",
      "Epoch: 70 -> Test Accuracy: 68.91\n",
      "[71, 60] loss: 0.631\n",
      "[71, 120] loss: 0.601\n",
      "[71, 180] loss: 0.597\n",
      "[71, 240] loss: 0.607\n",
      "[71, 300] loss: 0.622\n",
      "[71, 360] loss: 0.591\n",
      "Epoch: 71 -> Loss: 0.650441706181\n",
      "Epoch: 71 -> Test Accuracy: 71.69\n",
      "[72, 60] loss: 0.572\n",
      "[72, 120] loss: 0.600\n",
      "[72, 180] loss: 0.592\n",
      "[72, 240] loss: 0.592\n",
      "[72, 300] loss: 0.583\n",
      "[72, 360] loss: 0.583\n",
      "Epoch: 72 -> Loss: 0.433293908834\n",
      "Epoch: 72 -> Test Accuracy: 72.05\n",
      "[73, 60] loss: 0.585\n",
      "[73, 120] loss: 0.570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73, 180] loss: 0.562\n",
      "[73, 240] loss: 0.580\n",
      "[73, 300] loss: 0.606\n",
      "[73, 360] loss: 0.581\n",
      "Epoch: 73 -> Loss: 0.507665276527\n",
      "Epoch: 73 -> Test Accuracy: 72.57\n",
      "[74, 60] loss: 0.572\n",
      "[74, 120] loss: 0.571\n",
      "[74, 180] loss: 0.565\n",
      "[74, 240] loss: 0.582\n",
      "[74, 300] loss: 0.585\n",
      "[74, 360] loss: 0.582\n",
      "Epoch: 74 -> Loss: 0.468992620707\n",
      "Epoch: 74 -> Test Accuracy: 71.98\n",
      "[75, 60] loss: 0.568\n",
      "[75, 120] loss: 0.586\n",
      "[75, 180] loss: 0.581\n",
      "[75, 240] loss: 0.591\n",
      "[75, 300] loss: 0.582\n",
      "[75, 360] loss: 0.568\n",
      "Epoch: 75 -> Loss: 0.697091221809\n",
      "Epoch: 75 -> Test Accuracy: 71.93\n",
      "[76, 60] loss: 0.579\n",
      "[76, 120] loss: 0.575\n",
      "[76, 180] loss: 0.576\n",
      "[76, 240] loss: 0.575\n",
      "[76, 300] loss: 0.556\n",
      "[76, 360] loss: 0.568\n",
      "Epoch: 76 -> Loss: 0.489638745785\n",
      "Epoch: 76 -> Test Accuracy: 71.98\n",
      "[77, 60] loss: 0.568\n",
      "[77, 120] loss: 0.579\n",
      "[77, 180] loss: 0.594\n",
      "[77, 240] loss: 0.558\n",
      "[77, 300] loss: 0.567\n",
      "[77, 360] loss: 0.570\n",
      "Epoch: 77 -> Loss: 0.700900971889\n",
      "Epoch: 77 -> Test Accuracy: 72.2\n",
      "[78, 60] loss: 0.581\n",
      "[78, 120] loss: 0.557\n",
      "[78, 180] loss: 0.583\n",
      "[78, 240] loss: 0.573\n",
      "[78, 300] loss: 0.588\n",
      "[78, 360] loss: 0.579\n",
      "Epoch: 78 -> Loss: 0.478714168072\n",
      "Epoch: 78 -> Test Accuracy: 72.27\n",
      "[79, 60] loss: 0.552\n",
      "[79, 120] loss: 0.562\n",
      "[79, 180] loss: 0.565\n",
      "[79, 240] loss: 0.576\n",
      "[79, 300] loss: 0.590\n",
      "[79, 360] loss: 0.569\n",
      "Epoch: 79 -> Loss: 0.65552431345\n",
      "Epoch: 79 -> Test Accuracy: 71.85\n",
      "[80, 60] loss: 0.551\n",
      "[80, 120] loss: 0.561\n",
      "[80, 180] loss: 0.554\n",
      "[80, 240] loss: 0.574\n",
      "[80, 300] loss: 0.580\n",
      "[80, 360] loss: 0.572\n",
      "Epoch: 80 -> Loss: 0.479294359684\n",
      "Epoch: 80 -> Test Accuracy: 71.93\n",
      "[81, 60] loss: 0.553\n",
      "[81, 120] loss: 0.582\n",
      "[81, 180] loss: 0.568\n",
      "[81, 240] loss: 0.564\n",
      "[81, 300] loss: 0.557\n",
      "[81, 360] loss: 0.574\n",
      "Epoch: 81 -> Loss: 0.622999310493\n",
      "Epoch: 81 -> Test Accuracy: 72.27\n",
      "[82, 60] loss: 0.563\n",
      "[82, 120] loss: 0.582\n",
      "[82, 180] loss: 0.566\n",
      "[82, 240] loss: 0.567\n",
      "[82, 300] loss: 0.567\n",
      "[82, 360] loss: 0.551\n",
      "Epoch: 82 -> Loss: 0.668743014336\n",
      "Epoch: 82 -> Test Accuracy: 72.15\n",
      "[83, 60] loss: 0.562\n",
      "[83, 120] loss: 0.559\n",
      "[83, 180] loss: 0.561\n",
      "[83, 240] loss: 0.571\n",
      "[83, 300] loss: 0.564\n",
      "[83, 360] loss: 0.562\n",
      "Epoch: 83 -> Loss: 0.531340360641\n",
      "Epoch: 83 -> Test Accuracy: 72.21\n",
      "[84, 60] loss: 0.559\n",
      "[84, 120] loss: 0.567\n",
      "[84, 180] loss: 0.571\n",
      "[84, 240] loss: 0.543\n",
      "[84, 300] loss: 0.559\n",
      "[84, 360] loss: 0.573\n",
      "Epoch: 84 -> Loss: 0.56624519825\n",
      "Epoch: 84 -> Test Accuracy: 72.07\n",
      "[85, 60] loss: 0.565\n",
      "[85, 120] loss: 0.539\n",
      "[85, 180] loss: 0.566\n",
      "[85, 240] loss: 0.576\n",
      "[85, 300] loss: 0.569\n",
      "[85, 360] loss: 0.560\n",
      "Epoch: 85 -> Loss: 0.53894418478\n",
      "Epoch: 85 -> Test Accuracy: 72.37\n",
      "[86, 60] loss: 0.546\n",
      "[86, 120] loss: 0.541\n",
      "[86, 180] loss: 0.517\n",
      "[86, 240] loss: 0.548\n",
      "[86, 300] loss: 0.544\n",
      "[86, 360] loss: 0.539\n",
      "Epoch: 86 -> Loss: 0.473050177097\n",
      "Epoch: 86 -> Test Accuracy: 72.99\n",
      "[87, 60] loss: 0.554\n",
      "[87, 120] loss: 0.528\n",
      "[87, 180] loss: 0.547\n",
      "[87, 240] loss: 0.535\n",
      "[87, 300] loss: 0.532\n",
      "[87, 360] loss: 0.525\n",
      "Epoch: 87 -> Loss: 0.397625356913\n",
      "Epoch: 87 -> Test Accuracy: 72.97\n",
      "[88, 60] loss: 0.545\n",
      "[88, 120] loss: 0.542\n",
      "[88, 180] loss: 0.536\n",
      "[88, 240] loss: 0.534\n",
      "[88, 300] loss: 0.535\n",
      "[88, 360] loss: 0.547\n",
      "Epoch: 88 -> Loss: 0.681548655033\n",
      "Epoch: 88 -> Test Accuracy: 72.89\n",
      "[89, 60] loss: 0.538\n",
      "[89, 120] loss: 0.531\n",
      "[89, 180] loss: 0.528\n",
      "[89, 240] loss: 0.551\n",
      "[89, 300] loss: 0.532\n",
      "[89, 360] loss: 0.531\n",
      "Epoch: 89 -> Loss: 0.711770892143\n",
      "Epoch: 89 -> Test Accuracy: 73.04\n",
      "[90, 60] loss: 0.515\n",
      "[90, 120] loss: 0.517\n",
      "[90, 180] loss: 0.517\n",
      "[90, 240] loss: 0.554\n",
      "[90, 300] loss: 0.555\n",
      "[90, 360] loss: 0.526\n",
      "Epoch: 90 -> Loss: 0.5637768507\n",
      "Epoch: 90 -> Test Accuracy: 73.09\n",
      "[91, 60] loss: 0.534\n",
      "[91, 120] loss: 0.525\n",
      "[91, 180] loss: 0.540\n",
      "[91, 240] loss: 0.536\n",
      "[91, 300] loss: 0.538\n",
      "[91, 360] loss: 0.529\n",
      "Epoch: 91 -> Loss: 0.591831743717\n",
      "Epoch: 91 -> Test Accuracy: 73.17\n",
      "[92, 60] loss: 0.516\n",
      "[92, 120] loss: 0.538\n",
      "[92, 180] loss: 0.529\n",
      "[92, 240] loss: 0.532\n",
      "[92, 300] loss: 0.539\n",
      "[92, 360] loss: 0.516\n",
      "Epoch: 92 -> Loss: 0.48245382309\n",
      "Epoch: 92 -> Test Accuracy: 73.09\n",
      "[93, 60] loss: 0.526\n",
      "[93, 120] loss: 0.535\n",
      "[93, 180] loss: 0.508\n",
      "[93, 240] loss: 0.540\n",
      "[93, 300] loss: 0.529\n",
      "[93, 360] loss: 0.528\n",
      "Epoch: 93 -> Loss: 0.50399273634\n",
      "Epoch: 93 -> Test Accuracy: 73.03\n",
      "[94, 60] loss: 0.521\n",
      "[94, 120] loss: 0.536\n",
      "[94, 180] loss: 0.523\n",
      "[94, 240] loss: 0.528\n",
      "[94, 300] loss: 0.528\n",
      "[94, 360] loss: 0.511\n",
      "Epoch: 94 -> Loss: 0.577066600323\n",
      "Epoch: 94 -> Test Accuracy: 73.03\n",
      "[95, 60] loss: 0.533\n",
      "[95, 120] loss: 0.516\n",
      "[95, 180] loss: 0.532\n",
      "[95, 240] loss: 0.526\n",
      "[95, 300] loss: 0.540\n",
      "[95, 360] loss: 0.529\n",
      "Epoch: 95 -> Loss: 0.459843575954\n",
      "Epoch: 95 -> Test Accuracy: 73.2\n",
      "[96, 60] loss: 0.522\n",
      "[96, 120] loss: 0.518\n",
      "[96, 180] loss: 0.519\n",
      "[96, 240] loss: 0.540\n",
      "[96, 300] loss: 0.543\n",
      "[96, 360] loss: 0.548\n",
      "Epoch: 96 -> Loss: 0.54055583477\n",
      "Epoch: 96 -> Test Accuracy: 72.86\n",
      "[97, 60] loss: 0.511\n",
      "[97, 120] loss: 0.528\n",
      "[97, 180] loss: 0.535\n",
      "[97, 240] loss: 0.525\n",
      "[97, 300] loss: 0.525\n",
      "[97, 360] loss: 0.539\n",
      "Epoch: 97 -> Loss: 0.423743009567\n",
      "Epoch: 97 -> Test Accuracy: 73.1\n",
      "[98, 60] loss: 0.496\n",
      "[98, 120] loss: 0.520\n",
      "[98, 180] loss: 0.545\n",
      "[98, 240] loss: 0.536\n",
      "[98, 300] loss: 0.526\n",
      "[98, 360] loss: 0.541\n",
      "Epoch: 98 -> Loss: 0.480708658695\n",
      "Epoch: 98 -> Test Accuracy: 73.12\n",
      "[99, 60] loss: 0.516\n",
      "[99, 120] loss: 0.529\n",
      "[99, 180] loss: 0.523\n",
      "[99, 240] loss: 0.522\n",
      "[99, 300] loss: 0.534\n",
      "[99, 360] loss: 0.531\n",
      "Epoch: 99 -> Loss: 0.461958795786\n",
      "Epoch: 99 -> Test Accuracy: 72.72\n",
      "[100, 60] loss: 0.539\n",
      "[100, 120] loss: 0.515\n",
      "[100, 180] loss: 0.522\n",
      "[100, 240] loss: 0.504\n",
      "[100, 300] loss: 0.539\n",
      "[100, 360] loss: 0.535\n",
      "Epoch: 100 -> Loss: 0.584442079067\n",
      "Epoch: 100 -> Test Accuracy: 72.95\n",
      "Finished Training\n",
      "[1, 60] loss: 2.214\n",
      "[1, 120] loss: 2.049\n",
      "[1, 180] loss: 1.996\n",
      "[1, 240] loss: 1.977\n",
      "[1, 300] loss: 1.940\n",
      "[1, 360] loss: 1.927\n",
      "Epoch: 1 -> Loss: 1.8604310751\n",
      "Epoch: 1 -> Test Accuracy: 28.05\n",
      "[2, 60] loss: 1.903\n",
      "[2, 120] loss: 1.901\n",
      "[2, 180] loss: 1.874\n",
      "[2, 240] loss: 1.895\n",
      "[2, 300] loss: 1.907\n",
      "[2, 360] loss: 1.871\n",
      "Epoch: 2 -> Loss: 1.90621447563\n",
      "Epoch: 2 -> Test Accuracy: 28.78\n",
      "[3, 60] loss: 1.867\n",
      "[3, 120] loss: 1.854\n",
      "[3, 180] loss: 1.831\n",
      "[3, 240] loss: 1.841\n",
      "[3, 300] loss: 1.840\n",
      "[3, 360] loss: 1.855\n",
      "Epoch: 3 -> Loss: 2.01152348518\n",
      "Epoch: 3 -> Test Accuracy: 31.2\n",
      "[4, 60] loss: 1.846\n",
      "[4, 120] loss: 1.818\n",
      "[4, 180] loss: 1.817\n",
      "[4, 240] loss: 1.829\n",
      "[4, 300] loss: 1.803\n",
      "[4, 360] loss: 1.813\n",
      "Epoch: 4 -> Loss: 1.77391648293\n",
      "Epoch: 4 -> Test Accuracy: 31.51\n",
      "[5, 60] loss: 1.805\n",
      "[5, 120] loss: 1.809\n",
      "[5, 180] loss: 1.818\n",
      "[5, 240] loss: 1.800\n",
      "[5, 300] loss: 1.814\n",
      "[5, 360] loss: 1.813\n",
      "Epoch: 5 -> Loss: 1.84095859528\n",
      "Epoch: 5 -> Test Accuracy: 30.72\n",
      "[6, 60] loss: 1.810\n",
      "[6, 120] loss: 1.813\n",
      "[6, 180] loss: 1.786\n",
      "[6, 240] loss: 1.787\n",
      "[6, 300] loss: 1.783\n",
      "[6, 360] loss: 1.795\n",
      "Epoch: 6 -> Loss: 1.80956053734\n",
      "Epoch: 6 -> Test Accuracy: 31.59\n",
      "[7, 60] loss: 1.795\n",
      "[7, 120] loss: 1.793\n",
      "[7, 180] loss: 1.782\n",
      "[7, 240] loss: 1.781\n",
      "[7, 300] loss: 1.783\n",
      "[7, 360] loss: 1.780\n",
      "Epoch: 7 -> Loss: 1.68344652653\n",
      "Epoch: 7 -> Test Accuracy: 32.64\n",
      "[8, 60] loss: 1.783\n",
      "[8, 120] loss: 1.786\n",
      "[8, 180] loss: 1.772\n",
      "[8, 240] loss: 1.785\n",
      "[8, 300] loss: 1.782\n",
      "[8, 360] loss: 1.775\n",
      "Epoch: 8 -> Loss: 1.95155739784\n",
      "Epoch: 8 -> Test Accuracy: 31.74\n",
      "[9, 60] loss: 1.790\n",
      "[9, 120] loss: 1.797\n",
      "[9, 180] loss: 1.782\n",
      "[9, 240] loss: 1.764\n",
      "[9, 300] loss: 1.763\n",
      "[9, 360] loss: 1.755\n",
      "Epoch: 9 -> Loss: 1.65217721462\n",
      "Epoch: 9 -> Test Accuracy: 31.68\n",
      "[10, 60] loss: 1.762\n",
      "[10, 120] loss: 1.765\n",
      "[10, 180] loss: 1.787\n",
      "[10, 240] loss: 1.762\n",
      "[10, 300] loss: 1.765\n",
      "[10, 360] loss: 1.762\n",
      "Epoch: 10 -> Loss: 1.7623115778\n",
      "Epoch: 10 -> Test Accuracy: 32.08\n",
      "[11, 60] loss: 1.760\n",
      "[11, 120] loss: 1.755\n",
      "[11, 180] loss: 1.768\n",
      "[11, 240] loss: 1.766\n",
      "[11, 300] loss: 1.759\n",
      "[11, 360] loss: 1.770\n",
      "Epoch: 11 -> Loss: 1.82536923885\n",
      "Epoch: 11 -> Test Accuracy: 33.46\n",
      "[12, 60] loss: 1.760\n",
      "[12, 120] loss: 1.748\n",
      "[12, 180] loss: 1.771\n",
      "[12, 240] loss: 1.751\n",
      "[12, 300] loss: 1.779\n",
      "[12, 360] loss: 1.779\n",
      "Epoch: 12 -> Loss: 1.71078562737\n",
      "Epoch: 12 -> Test Accuracy: 33.3\n",
      "[13, 60] loss: 1.762\n",
      "[13, 120] loss: 1.758\n",
      "[13, 180] loss: 1.759\n",
      "[13, 240] loss: 1.746\n",
      "[13, 300] loss: 1.762\n",
      "[13, 360] loss: 1.769\n",
      "Epoch: 13 -> Loss: 1.90622770786\n",
      "Epoch: 13 -> Test Accuracy: 31.82\n",
      "[14, 60] loss: 1.768\n",
      "[14, 120] loss: 1.745\n",
      "[14, 180] loss: 1.751\n",
      "[14, 240] loss: 1.781\n",
      "[14, 300] loss: 1.749\n",
      "[14, 360] loss: 1.749\n",
      "Epoch: 14 -> Loss: 1.65709972382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 -> Test Accuracy: 31.87\n",
      "[15, 60] loss: 1.754\n",
      "[15, 120] loss: 1.761\n",
      "[15, 180] loss: 1.761\n",
      "[15, 240] loss: 1.753\n",
      "[15, 300] loss: 1.748\n",
      "[15, 360] loss: 1.741\n",
      "Epoch: 15 -> Loss: 1.69936585426\n",
      "Epoch: 15 -> Test Accuracy: 32.17\n",
      "[16, 60] loss: 1.735\n",
      "[16, 120] loss: 1.762\n",
      "[16, 180] loss: 1.739\n",
      "[16, 240] loss: 1.763\n",
      "[16, 300] loss: 1.756\n",
      "[16, 360] loss: 1.750\n",
      "Epoch: 16 -> Loss: 1.72331047058\n",
      "Epoch: 16 -> Test Accuracy: 32.27\n",
      "[17, 60] loss: 1.731\n",
      "[17, 120] loss: 1.755\n",
      "[17, 180] loss: 1.768\n",
      "[17, 240] loss: 1.740\n",
      "[17, 300] loss: 1.754\n",
      "[17, 360] loss: 1.750\n",
      "Epoch: 17 -> Loss: 1.89817810059\n",
      "Epoch: 17 -> Test Accuracy: 32.75\n",
      "[18, 60] loss: 1.747\n",
      "[18, 120] loss: 1.741\n",
      "[18, 180] loss: 1.735\n",
      "[18, 240] loss: 1.752\n",
      "[18, 300] loss: 1.732\n",
      "[18, 360] loss: 1.734\n",
      "Epoch: 18 -> Loss: 1.71640241146\n",
      "Epoch: 18 -> Test Accuracy: 32.28\n",
      "[19, 60] loss: 1.741\n",
      "[19, 120] loss: 1.752\n",
      "[19, 180] loss: 1.739\n",
      "[19, 240] loss: 1.740\n",
      "[19, 300] loss: 1.726\n",
      "[19, 360] loss: 1.757\n",
      "Epoch: 19 -> Loss: 1.67088627815\n",
      "Epoch: 19 -> Test Accuracy: 33.38\n",
      "[20, 60] loss: 1.742\n",
      "[20, 120] loss: 1.722\n",
      "[20, 180] loss: 1.737\n",
      "[20, 240] loss: 1.745\n",
      "[20, 300] loss: 1.752\n",
      "[20, 360] loss: 1.755\n",
      "Epoch: 20 -> Loss: 1.6870855093\n",
      "Epoch: 20 -> Test Accuracy: 33.66\n",
      "[21, 60] loss: 1.734\n",
      "[21, 120] loss: 1.747\n",
      "[21, 180] loss: 1.740\n",
      "[21, 240] loss: 1.748\n",
      "[21, 300] loss: 1.751\n",
      "[21, 360] loss: 1.728\n",
      "Epoch: 21 -> Loss: 1.65784299374\n",
      "Epoch: 21 -> Test Accuracy: 32.86\n",
      "[22, 60] loss: 1.730\n",
      "[22, 120] loss: 1.740\n",
      "[22, 180] loss: 1.739\n",
      "[22, 240] loss: 1.752\n",
      "[22, 300] loss: 1.738\n",
      "[22, 360] loss: 1.729\n",
      "Epoch: 22 -> Loss: 1.66333198547\n",
      "Epoch: 22 -> Test Accuracy: 33.48\n",
      "[23, 60] loss: 1.724\n",
      "[23, 120] loss: 1.740\n",
      "[23, 180] loss: 1.744\n",
      "[23, 240] loss: 1.728\n",
      "[23, 300] loss: 1.752\n",
      "[23, 360] loss: 1.732\n",
      "Epoch: 23 -> Loss: 1.61421740055\n",
      "Epoch: 23 -> Test Accuracy: 32.46\n",
      "[24, 60] loss: 1.738\n",
      "[24, 120] loss: 1.732\n",
      "[24, 180] loss: 1.748\n",
      "[24, 240] loss: 1.736\n",
      "[24, 300] loss: 1.727\n",
      "[24, 360] loss: 1.734\n",
      "Epoch: 24 -> Loss: 1.80705857277\n",
      "Epoch: 24 -> Test Accuracy: 33.47\n",
      "[25, 60] loss: 1.732\n",
      "[25, 120] loss: 1.720\n",
      "[25, 180] loss: 1.733\n",
      "[25, 240] loss: 1.726\n",
      "[25, 300] loss: 1.729\n",
      "[25, 360] loss: 1.747\n",
      "Epoch: 25 -> Loss: 1.77019047737\n",
      "Epoch: 25 -> Test Accuracy: 32.12\n",
      "[26, 60] loss: 1.728\n",
      "[26, 120] loss: 1.739\n",
      "[26, 180] loss: 1.728\n",
      "[26, 240] loss: 1.749\n",
      "[26, 300] loss: 1.729\n",
      "[26, 360] loss: 1.727\n",
      "Epoch: 26 -> Loss: 1.72547507286\n",
      "Epoch: 26 -> Test Accuracy: 31.93\n",
      "[27, 60] loss: 1.725\n",
      "[27, 120] loss: 1.751\n",
      "[27, 180] loss: 1.726\n",
      "[27, 240] loss: 1.723\n",
      "[27, 300] loss: 1.720\n",
      "[27, 360] loss: 1.741\n",
      "Epoch: 27 -> Loss: 1.61325776577\n",
      "Epoch: 27 -> Test Accuracy: 33.15\n",
      "[28, 60] loss: 1.739\n",
      "[28, 120] loss: 1.732\n",
      "[28, 180] loss: 1.736\n",
      "[28, 240] loss: 1.739\n",
      "[28, 300] loss: 1.721\n",
      "[28, 360] loss: 1.737\n",
      "Epoch: 28 -> Loss: 1.82928490639\n",
      "Epoch: 28 -> Test Accuracy: 33.25\n",
      "[29, 60] loss: 1.735\n",
      "[29, 120] loss: 1.729\n",
      "[29, 180] loss: 1.721\n",
      "[29, 240] loss: 1.723\n",
      "[29, 300] loss: 1.727\n",
      "[29, 360] loss: 1.750\n",
      "Epoch: 29 -> Loss: 1.68453192711\n",
      "Epoch: 29 -> Test Accuracy: 32.91\n",
      "[30, 60] loss: 1.723\n",
      "[30, 120] loss: 1.736\n",
      "[30, 180] loss: 1.731\n",
      "[30, 240] loss: 1.736\n",
      "[30, 300] loss: 1.735\n",
      "[30, 360] loss: 1.747\n",
      "Epoch: 30 -> Loss: 1.63525652885\n",
      "Epoch: 30 -> Test Accuracy: 33.83\n",
      "[31, 60] loss: 1.736\n",
      "[31, 120] loss: 1.738\n",
      "[31, 180] loss: 1.713\n",
      "[31, 240] loss: 1.724\n",
      "[31, 300] loss: 1.732\n",
      "[31, 360] loss: 1.744\n",
      "Epoch: 31 -> Loss: 1.75808370113\n",
      "Epoch: 31 -> Test Accuracy: 32.84\n",
      "[32, 60] loss: 1.735\n",
      "[32, 120] loss: 1.728\n",
      "[32, 180] loss: 1.736\n",
      "[32, 240] loss: 1.723\n",
      "[32, 300] loss: 1.720\n",
      "[32, 360] loss: 1.745\n",
      "Epoch: 32 -> Loss: 1.80304694176\n",
      "Epoch: 32 -> Test Accuracy: 32.9\n",
      "[33, 60] loss: 1.756\n",
      "[33, 120] loss: 1.718\n",
      "[33, 180] loss: 1.721\n",
      "[33, 240] loss: 1.744\n",
      "[33, 300] loss: 1.730\n",
      "[33, 360] loss: 1.725\n",
      "Epoch: 33 -> Loss: 1.65935266018\n",
      "Epoch: 33 -> Test Accuracy: 33.25\n",
      "[34, 60] loss: 1.714\n",
      "[34, 120] loss: 1.737\n",
      "[34, 180] loss: 1.721\n",
      "[34, 240] loss: 1.727\n",
      "[34, 300] loss: 1.730\n",
      "[34, 360] loss: 1.724\n",
      "Epoch: 34 -> Loss: 1.84141027927\n",
      "Epoch: 34 -> Test Accuracy: 32.89\n",
      "[35, 60] loss: 1.728\n",
      "[35, 120] loss: 1.734\n",
      "[35, 180] loss: 1.725\n",
      "[35, 240] loss: 1.723\n",
      "[35, 300] loss: 1.736\n",
      "[35, 360] loss: 1.728\n",
      "Epoch: 35 -> Loss: 1.61475884914\n",
      "Epoch: 35 -> Test Accuracy: 33.59\n",
      "[36, 60] loss: 1.685\n",
      "[36, 120] loss: 1.650\n",
      "[36, 180] loss: 1.657\n",
      "[36, 240] loss: 1.648\n",
      "[36, 300] loss: 1.651\n",
      "[36, 360] loss: 1.629\n",
      "Epoch: 36 -> Loss: 1.50895571709\n",
      "Epoch: 36 -> Test Accuracy: 36.17\n",
      "[37, 60] loss: 1.636\n",
      "[37, 120] loss: 1.655\n",
      "[37, 180] loss: 1.634\n",
      "[37, 240] loss: 1.619\n",
      "[37, 300] loss: 1.622\n",
      "[37, 360] loss: 1.636\n",
      "Epoch: 37 -> Loss: 1.64864635468\n",
      "Epoch: 37 -> Test Accuracy: 36.87\n",
      "[38, 60] loss: 1.620\n",
      "[38, 120] loss: 1.628\n",
      "[38, 180] loss: 1.626\n",
      "[38, 240] loss: 1.630\n",
      "[38, 300] loss: 1.629\n",
      "[38, 360] loss: 1.640\n",
      "Epoch: 38 -> Loss: 1.7553498745\n",
      "Epoch: 38 -> Test Accuracy: 36.82\n",
      "[39, 60] loss: 1.620\n",
      "[39, 120] loss: 1.616\n",
      "[39, 180] loss: 1.633\n",
      "[39, 240] loss: 1.610\n",
      "[39, 300] loss: 1.604\n",
      "[39, 360] loss: 1.613\n",
      "Epoch: 39 -> Loss: 1.48079705238\n",
      "Epoch: 39 -> Test Accuracy: 36.44\n",
      "[40, 60] loss: 1.611\n",
      "[40, 120] loss: 1.633\n",
      "[40, 180] loss: 1.629\n",
      "[40, 240] loss: 1.618\n",
      "[40, 300] loss: 1.619\n",
      "[40, 360] loss: 1.631\n",
      "Epoch: 40 -> Loss: 1.6360296011\n",
      "Epoch: 40 -> Test Accuracy: 37.16\n",
      "[41, 60] loss: 1.617\n",
      "[41, 120] loss: 1.611\n",
      "[41, 180] loss: 1.622\n",
      "[41, 240] loss: 1.635\n",
      "[41, 300] loss: 1.623\n",
      "[41, 360] loss: 1.628\n",
      "Epoch: 41 -> Loss: 1.59301865101\n",
      "Epoch: 41 -> Test Accuracy: 35.98\n",
      "[42, 60] loss: 1.609\n",
      "[42, 120] loss: 1.609\n",
      "[42, 180] loss: 1.620\n",
      "[42, 240] loss: 1.608\n",
      "[42, 300] loss: 1.648\n",
      "[42, 360] loss: 1.616\n",
      "Epoch: 42 -> Loss: 1.5064470768\n",
      "Epoch: 42 -> Test Accuracy: 36.8\n",
      "[43, 60] loss: 1.604\n",
      "[43, 120] loss: 1.618\n",
      "[43, 180] loss: 1.613\n",
      "[43, 240] loss: 1.616\n",
      "[43, 300] loss: 1.633\n",
      "[43, 360] loss: 1.613\n",
      "Epoch: 43 -> Loss: 1.5967643261\n",
      "Epoch: 43 -> Test Accuracy: 36.55\n",
      "[44, 60] loss: 1.601\n",
      "[44, 120] loss: 1.633\n",
      "[44, 180] loss: 1.604\n",
      "[44, 240] loss: 1.618\n",
      "[44, 300] loss: 1.611\n",
      "[44, 360] loss: 1.618\n",
      "Epoch: 44 -> Loss: 1.44043040276\n",
      "Epoch: 44 -> Test Accuracy: 36.59\n",
      "[45, 60] loss: 1.621\n",
      "[45, 120] loss: 1.627\n",
      "[45, 180] loss: 1.613\n",
      "[45, 240] loss: 1.627\n",
      "[45, 300] loss: 1.615\n",
      "[45, 360] loss: 1.608\n",
      "Epoch: 45 -> Loss: 1.44151306152\n",
      "Epoch: 45 -> Test Accuracy: 36.08\n",
      "[46, 60] loss: 1.615\n",
      "[46, 120] loss: 1.619\n",
      "[46, 180] loss: 1.614\n",
      "[46, 240] loss: 1.624\n",
      "[46, 300] loss: 1.608\n",
      "[46, 360] loss: 1.624\n",
      "Epoch: 46 -> Loss: 1.4654405117\n",
      "Epoch: 46 -> Test Accuracy: 37.34\n",
      "[47, 60] loss: 1.600\n",
      "[47, 120] loss: 1.611\n",
      "[47, 180] loss: 1.622\n",
      "[47, 240] loss: 1.624\n",
      "[47, 300] loss: 1.601\n",
      "[47, 360] loss: 1.618\n",
      "Epoch: 47 -> Loss: 1.65048730373\n",
      "Epoch: 47 -> Test Accuracy: 37.27\n",
      "[48, 60] loss: 1.615\n",
      "[48, 120] loss: 1.608\n",
      "[48, 180] loss: 1.614\n",
      "[48, 240] loss: 1.629\n",
      "[48, 300] loss: 1.609\n",
      "[48, 360] loss: 1.618\n",
      "Epoch: 48 -> Loss: 1.6575139761\n",
      "Epoch: 48 -> Test Accuracy: 37.28\n",
      "[49, 60] loss: 1.611\n",
      "[49, 120] loss: 1.593\n",
      "[49, 180] loss: 1.611\n",
      "[49, 240] loss: 1.589\n",
      "[49, 300] loss: 1.610\n",
      "[49, 360] loss: 1.622\n",
      "Epoch: 49 -> Loss: 1.77917361259\n",
      "Epoch: 49 -> Test Accuracy: 37.13\n",
      "[50, 60] loss: 1.615\n",
      "[50, 120] loss: 1.628\n",
      "[50, 180] loss: 1.607\n",
      "[50, 240] loss: 1.617\n",
      "[50, 300] loss: 1.621\n",
      "[50, 360] loss: 1.608\n",
      "Epoch: 50 -> Loss: 1.73214530945\n",
      "Epoch: 50 -> Test Accuracy: 37.12\n",
      "[51, 60] loss: 1.630\n",
      "[51, 120] loss: 1.613\n",
      "[51, 180] loss: 1.604\n",
      "[51, 240] loss: 1.592\n",
      "[51, 300] loss: 1.614\n",
      "[51, 360] loss: 1.630\n",
      "Epoch: 51 -> Loss: 1.67292714119\n",
      "Epoch: 51 -> Test Accuracy: 37.15\n",
      "[52, 60] loss: 1.599\n",
      "[52, 120] loss: 1.626\n",
      "[52, 180] loss: 1.620\n",
      "[52, 240] loss: 1.619\n",
      "[52, 300] loss: 1.599\n",
      "[52, 360] loss: 1.611\n",
      "Epoch: 52 -> Loss: 1.69324946404\n",
      "Epoch: 52 -> Test Accuracy: 37.09\n",
      "[53, 60] loss: 1.603\n",
      "[53, 120] loss: 1.627\n",
      "[53, 180] loss: 1.619\n",
      "[53, 240] loss: 1.623\n",
      "[53, 300] loss: 1.604\n",
      "[53, 360] loss: 1.608\n",
      "Epoch: 53 -> Loss: 1.57044279575\n",
      "Epoch: 53 -> Test Accuracy: 36.88\n",
      "[54, 60] loss: 1.624\n",
      "[54, 120] loss: 1.597\n",
      "[54, 180] loss: 1.609\n",
      "[54, 240] loss: 1.617\n",
      "[54, 300] loss: 1.616\n",
      "[54, 360] loss: 1.597\n",
      "Epoch: 54 -> Loss: 1.48994576931\n",
      "Epoch: 54 -> Test Accuracy: 36.63\n",
      "[55, 60] loss: 1.627\n",
      "[55, 120] loss: 1.614\n",
      "[55, 180] loss: 1.603\n",
      "[55, 240] loss: 1.608\n",
      "[55, 300] loss: 1.597\n",
      "[55, 360] loss: 1.602\n",
      "Epoch: 55 -> Loss: 1.52291238308\n",
      "Epoch: 55 -> Test Accuracy: 37.27\n",
      "[56, 60] loss: 1.600\n",
      "[56, 120] loss: 1.610\n",
      "[56, 180] loss: 1.592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56, 240] loss: 1.628\n",
      "[56, 300] loss: 1.614\n",
      "[56, 360] loss: 1.590\n",
      "Epoch: 56 -> Loss: 1.59642672539\n",
      "Epoch: 56 -> Test Accuracy: 36.47\n",
      "[57, 60] loss: 1.610\n",
      "[57, 120] loss: 1.610\n",
      "[57, 180] loss: 1.623\n",
      "[57, 240] loss: 1.616\n",
      "[57, 300] loss: 1.611\n",
      "[57, 360] loss: 1.619\n",
      "Epoch: 57 -> Loss: 1.41619992256\n",
      "Epoch: 57 -> Test Accuracy: 36.8\n",
      "[58, 60] loss: 1.614\n",
      "[58, 120] loss: 1.598\n",
      "[58, 180] loss: 1.601\n",
      "[58, 240] loss: 1.607\n",
      "[58, 300] loss: 1.609\n",
      "[58, 360] loss: 1.606\n",
      "Epoch: 58 -> Loss: 1.74972033501\n",
      "Epoch: 58 -> Test Accuracy: 37.06\n",
      "[59, 60] loss: 1.599\n",
      "[59, 120] loss: 1.613\n",
      "[59, 180] loss: 1.613\n",
      "[59, 240] loss: 1.599\n",
      "[59, 300] loss: 1.600\n",
      "[59, 360] loss: 1.603\n",
      "Epoch: 59 -> Loss: 1.46792864799\n",
      "Epoch: 59 -> Test Accuracy: 37.2\n",
      "[60, 60] loss: 1.609\n",
      "[60, 120] loss: 1.597\n",
      "[60, 180] loss: 1.607\n",
      "[60, 240] loss: 1.617\n",
      "[60, 300] loss: 1.613\n",
      "[60, 360] loss: 1.594\n",
      "Epoch: 60 -> Loss: 1.64940416813\n",
      "Epoch: 60 -> Test Accuracy: 37.71\n",
      "[61, 60] loss: 1.598\n",
      "[61, 120] loss: 1.605\n",
      "[61, 180] loss: 1.618\n",
      "[61, 240] loss: 1.593\n",
      "[61, 300] loss: 1.607\n",
      "[61, 360] loss: 1.610\n",
      "Epoch: 61 -> Loss: 1.60195505619\n",
      "Epoch: 61 -> Test Accuracy: 37.24\n",
      "[62, 60] loss: 1.622\n",
      "[62, 120] loss: 1.630\n",
      "[62, 180] loss: 1.617\n",
      "[62, 240] loss: 1.609\n",
      "[62, 300] loss: 1.601\n",
      "[62, 360] loss: 1.608\n",
      "Epoch: 62 -> Loss: 1.44742178917\n",
      "Epoch: 62 -> Test Accuracy: 38.22\n",
      "[63, 60] loss: 1.601\n",
      "[63, 120] loss: 1.616\n",
      "[63, 180] loss: 1.603\n",
      "[63, 240] loss: 1.602\n",
      "[63, 300] loss: 1.607\n",
      "[63, 360] loss: 1.591\n",
      "Epoch: 63 -> Loss: 1.59758520126\n",
      "Epoch: 63 -> Test Accuracy: 37.01\n",
      "[64, 60] loss: 1.615\n",
      "[64, 120] loss: 1.619\n",
      "[64, 180] loss: 1.589\n",
      "[64, 240] loss: 1.575\n",
      "[64, 300] loss: 1.611\n",
      "[64, 360] loss: 1.611\n",
      "Epoch: 64 -> Loss: 1.66692757607\n",
      "Epoch: 64 -> Test Accuracy: 36.92\n",
      "[65, 60] loss: 1.621\n",
      "[65, 120] loss: 1.614\n",
      "[65, 180] loss: 1.600\n",
      "[65, 240] loss: 1.619\n",
      "[65, 300] loss: 1.598\n",
      "[65, 360] loss: 1.593\n",
      "Epoch: 65 -> Loss: 1.71082174778\n",
      "Epoch: 65 -> Test Accuracy: 37.46\n",
      "[66, 60] loss: 1.590\n",
      "[66, 120] loss: 1.606\n",
      "[66, 180] loss: 1.616\n",
      "[66, 240] loss: 1.603\n",
      "[66, 300] loss: 1.614\n",
      "[66, 360] loss: 1.585\n",
      "Epoch: 66 -> Loss: 1.44935011864\n",
      "Epoch: 66 -> Test Accuracy: 37.02\n",
      "[67, 60] loss: 1.589\n",
      "[67, 120] loss: 1.593\n",
      "[67, 180] loss: 1.602\n",
      "[67, 240] loss: 1.595\n",
      "[67, 300] loss: 1.599\n",
      "[67, 360] loss: 1.600\n",
      "Epoch: 67 -> Loss: 1.73988032341\n",
      "Epoch: 67 -> Test Accuracy: 38.31\n",
      "[68, 60] loss: 1.605\n",
      "[68, 120] loss: 1.599\n",
      "[68, 180] loss: 1.600\n",
      "[68, 240] loss: 1.606\n",
      "[68, 300] loss: 1.612\n",
      "[68, 360] loss: 1.603\n",
      "Epoch: 68 -> Loss: 1.61606729031\n",
      "Epoch: 68 -> Test Accuracy: 36.89\n",
      "[69, 60] loss: 1.593\n",
      "[69, 120] loss: 1.609\n",
      "[69, 180] loss: 1.599\n",
      "[69, 240] loss: 1.619\n",
      "[69, 300] loss: 1.598\n",
      "[69, 360] loss: 1.596\n",
      "Epoch: 69 -> Loss: 1.57076847553\n",
      "Epoch: 69 -> Test Accuracy: 37.65\n",
      "[70, 60] loss: 1.585\n",
      "[70, 120] loss: 1.598\n",
      "[70, 180] loss: 1.629\n",
      "[70, 240] loss: 1.598\n",
      "[70, 300] loss: 1.614\n",
      "[70, 360] loss: 1.608\n",
      "Epoch: 70 -> Loss: 1.53519022465\n",
      "Epoch: 70 -> Test Accuracy: 38.21\n",
      "[71, 60] loss: 1.581\n",
      "[71, 120] loss: 1.564\n",
      "[71, 180] loss: 1.546\n",
      "[71, 240] loss: 1.539\n",
      "[71, 300] loss: 1.525\n",
      "[71, 360] loss: 1.521\n",
      "Epoch: 71 -> Loss: 1.40903365612\n",
      "Epoch: 71 -> Test Accuracy: 39.35\n",
      "[72, 60] loss: 1.536\n",
      "[72, 120] loss: 1.541\n",
      "[72, 180] loss: 1.541\n",
      "[72, 240] loss: 1.535\n",
      "[72, 300] loss: 1.519\n",
      "[72, 360] loss: 1.513\n",
      "Epoch: 72 -> Loss: 1.59568893909\n",
      "Epoch: 72 -> Test Accuracy: 40.11\n",
      "[73, 60] loss: 1.530\n",
      "[73, 120] loss: 1.546\n",
      "[73, 180] loss: 1.520\n",
      "[73, 240] loss: 1.513\n",
      "[73, 300] loss: 1.530\n",
      "[73, 360] loss: 1.509\n",
      "Epoch: 73 -> Loss: 1.61519527435\n",
      "Epoch: 73 -> Test Accuracy: 39.63\n",
      "[74, 60] loss: 1.527\n",
      "[74, 120] loss: 1.516\n",
      "[74, 180] loss: 1.512\n",
      "[74, 240] loss: 1.533\n",
      "[74, 300] loss: 1.525\n",
      "[74, 360] loss: 1.519\n",
      "Epoch: 74 -> Loss: 1.62153208256\n",
      "Epoch: 74 -> Test Accuracy: 39.38\n",
      "[75, 60] loss: 1.521\n",
      "[75, 120] loss: 1.531\n",
      "[75, 180] loss: 1.518\n",
      "[75, 240] loss: 1.524\n",
      "[75, 300] loss: 1.528\n",
      "[75, 360] loss: 1.518\n",
      "Epoch: 75 -> Loss: 1.64270043373\n",
      "Epoch: 75 -> Test Accuracy: 39.79\n",
      "[76, 60] loss: 1.527\n",
      "[76, 120] loss: 1.540\n",
      "[76, 180] loss: 1.524\n",
      "[76, 240] loss: 1.516\n",
      "[76, 300] loss: 1.521\n",
      "[76, 360] loss: 1.516\n",
      "Epoch: 76 -> Loss: 1.38503694534\n",
      "Epoch: 76 -> Test Accuracy: 39.58\n",
      "[77, 60] loss: 1.526\n",
      "[77, 120] loss: 1.525\n",
      "[77, 180] loss: 1.513\n",
      "[77, 240] loss: 1.525\n",
      "[77, 300] loss: 1.516\n",
      "[77, 360] loss: 1.513\n",
      "Epoch: 77 -> Loss: 1.57491767406\n",
      "Epoch: 77 -> Test Accuracy: 39.61\n",
      "[78, 60] loss: 1.510\n",
      "[78, 120] loss: 1.531\n",
      "[78, 180] loss: 1.521\n",
      "[78, 240] loss: 1.502\n",
      "[78, 300] loss: 1.504\n",
      "[78, 360] loss: 1.534\n",
      "Epoch: 78 -> Loss: 1.41706991196\n",
      "Epoch: 78 -> Test Accuracy: 40.32\n",
      "[79, 60] loss: 1.519\n",
      "[79, 120] loss: 1.515\n",
      "[79, 180] loss: 1.532\n",
      "[79, 240] loss: 1.517\n",
      "[79, 300] loss: 1.524\n",
      "[79, 360] loss: 1.514\n",
      "Epoch: 79 -> Loss: 1.68056869507\n",
      "Epoch: 79 -> Test Accuracy: 39.88\n",
      "[80, 60] loss: 1.532\n",
      "[80, 120] loss: 1.513\n",
      "[80, 180] loss: 1.515\n",
      "[80, 240] loss: 1.528\n",
      "[80, 300] loss: 1.519\n",
      "[80, 360] loss: 1.522\n",
      "Epoch: 80 -> Loss: 1.48051083088\n",
      "Epoch: 80 -> Test Accuracy: 39.53\n",
      "[81, 60] loss: 1.499\n",
      "[81, 120] loss: 1.506\n",
      "[81, 180] loss: 1.522\n",
      "[81, 240] loss: 1.538\n",
      "[81, 300] loss: 1.511\n",
      "[81, 360] loss: 1.524\n",
      "Epoch: 81 -> Loss: 1.61613297462\n",
      "Epoch: 81 -> Test Accuracy: 39.85\n",
      "[82, 60] loss: 1.496\n",
      "[82, 120] loss: 1.532\n",
      "[82, 180] loss: 1.529\n",
      "[82, 240] loss: 1.502\n",
      "[82, 300] loss: 1.502\n",
      "[82, 360] loss: 1.502\n",
      "Epoch: 82 -> Loss: 1.58333134651\n",
      "Epoch: 82 -> Test Accuracy: 40.61\n",
      "[83, 60] loss: 1.511\n",
      "[83, 120] loss: 1.523\n",
      "[83, 180] loss: 1.527\n",
      "[83, 240] loss: 1.502\n",
      "[83, 300] loss: 1.493\n",
      "[83, 360] loss: 1.522\n",
      "Epoch: 83 -> Loss: 1.43415796757\n",
      "Epoch: 83 -> Test Accuracy: 40.3\n",
      "[84, 60] loss: 1.509\n",
      "[84, 120] loss: 1.498\n",
      "[84, 180] loss: 1.511\n",
      "[84, 240] loss: 1.521\n",
      "[84, 300] loss: 1.508\n",
      "[84, 360] loss: 1.507\n",
      "Epoch: 84 -> Loss: 1.57573115826\n",
      "Epoch: 84 -> Test Accuracy: 39.95\n",
      "[85, 60] loss: 1.512\n",
      "[85, 120] loss: 1.526\n",
      "[85, 180] loss: 1.493\n",
      "[85, 240] loss: 1.520\n",
      "[85, 300] loss: 1.524\n",
      "[85, 360] loss: 1.529\n",
      "Epoch: 85 -> Loss: 1.62138557434\n",
      "Epoch: 85 -> Test Accuracy: 39.91\n",
      "[86, 60] loss: 1.491\n",
      "[86, 120] loss: 1.502\n",
      "[86, 180] loss: 1.480\n",
      "[86, 240] loss: 1.491\n",
      "[86, 300] loss: 1.474\n",
      "[86, 360] loss: 1.494\n",
      "Epoch: 86 -> Loss: 1.42954528332\n",
      "Epoch: 86 -> Test Accuracy: 40.89\n",
      "[87, 60] loss: 1.483\n",
      "[87, 120] loss: 1.491\n",
      "[87, 180] loss: 1.495\n",
      "[87, 240] loss: 1.480\n",
      "[87, 300] loss: 1.479\n",
      "[87, 360] loss: 1.477\n",
      "Epoch: 87 -> Loss: 1.64681339264\n",
      "Epoch: 87 -> Test Accuracy: 41.2\n",
      "[88, 60] loss: 1.493\n",
      "[88, 120] loss: 1.484\n",
      "[88, 180] loss: 1.472\n",
      "[88, 240] loss: 1.482\n",
      "[88, 300] loss: 1.479\n",
      "[88, 360] loss: 1.487\n",
      "Epoch: 88 -> Loss: 1.52921783924\n",
      "Epoch: 88 -> Test Accuracy: 41.23\n",
      "[89, 60] loss: 1.464\n",
      "[89, 120] loss: 1.459\n",
      "[89, 180] loss: 1.481\n",
      "[89, 240] loss: 1.462\n",
      "[89, 300] loss: 1.473\n",
      "[89, 360] loss: 1.488\n",
      "Epoch: 89 -> Loss: 1.68559455872\n",
      "Epoch: 89 -> Test Accuracy: 41.22\n",
      "[90, 60] loss: 1.486\n",
      "[90, 120] loss: 1.482\n",
      "[90, 180] loss: 1.469\n",
      "[90, 240] loss: 1.485\n",
      "[90, 300] loss: 1.477\n",
      "[90, 360] loss: 1.481\n",
      "Epoch: 90 -> Loss: 1.41382873058\n",
      "Epoch: 90 -> Test Accuracy: 41.04\n",
      "[91, 60] loss: 1.468\n",
      "[91, 120] loss: 1.482\n",
      "[91, 180] loss: 1.477\n",
      "[91, 240] loss: 1.459\n",
      "[91, 300] loss: 1.486\n",
      "[91, 360] loss: 1.462\n",
      "Epoch: 91 -> Loss: 1.60775208473\n",
      "Epoch: 91 -> Test Accuracy: 41.05\n",
      "[92, 60] loss: 1.491\n",
      "[92, 120] loss: 1.473\n",
      "[92, 180] loss: 1.479\n",
      "[92, 240] loss: 1.491\n",
      "[92, 300] loss: 1.482\n",
      "[92, 360] loss: 1.469\n",
      "Epoch: 92 -> Loss: 1.58873331547\n",
      "Epoch: 92 -> Test Accuracy: 41.11\n",
      "[93, 60] loss: 1.475\n",
      "[93, 120] loss: 1.467\n",
      "[93, 180] loss: 1.483\n",
      "[93, 240] loss: 1.465\n",
      "[93, 300] loss: 1.471\n",
      "[93, 360] loss: 1.486\n",
      "Epoch: 93 -> Loss: 1.49997138977\n",
      "Epoch: 93 -> Test Accuracy: 41.44\n",
      "[94, 60] loss: 1.464\n",
      "[94, 120] loss: 1.452\n",
      "[94, 180] loss: 1.482\n",
      "[94, 240] loss: 1.480\n",
      "[94, 300] loss: 1.456\n",
      "[94, 360] loss: 1.490\n",
      "Epoch: 94 -> Loss: 1.53873956203\n",
      "Epoch: 94 -> Test Accuracy: 40.8\n",
      "[95, 60] loss: 1.460\n",
      "[95, 120] loss: 1.474\n",
      "[95, 180] loss: 1.475\n",
      "[95, 240] loss: 1.486\n",
      "[95, 300] loss: 1.463\n",
      "[95, 360] loss: 1.490\n",
      "Epoch: 95 -> Loss: 1.62093317509\n",
      "Epoch: 95 -> Test Accuracy: 41.69\n",
      "[96, 60] loss: 1.464\n",
      "[96, 120] loss: 1.474\n",
      "[96, 180] loss: 1.495\n",
      "[96, 240] loss: 1.480\n",
      "[96, 300] loss: 1.458\n",
      "[96, 360] loss: 1.476\n",
      "Epoch: 96 -> Loss: 1.43027710915\n",
      "Epoch: 96 -> Test Accuracy: 41.34\n",
      "[97, 60] loss: 1.457\n",
      "[97, 120] loss: 1.494\n",
      "[97, 180] loss: 1.471\n",
      "[97, 240] loss: 1.480\n",
      "[97, 300] loss: 1.468\n",
      "[97, 360] loss: 1.461\n",
      "Epoch: 97 -> Loss: 1.21867549419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97 -> Test Accuracy: 41.41\n",
      "[98, 60] loss: 1.489\n",
      "[98, 120] loss: 1.446\n",
      "[98, 180] loss: 1.464\n",
      "[98, 240] loss: 1.485\n",
      "[98, 300] loss: 1.485\n",
      "[98, 360] loss: 1.456\n",
      "Epoch: 98 -> Loss: 1.33560109138\n",
      "Epoch: 98 -> Test Accuracy: 41.2\n",
      "[99, 60] loss: 1.463\n",
      "[99, 120] loss: 1.476\n",
      "[99, 180] loss: 1.459\n",
      "[99, 240] loss: 1.502\n",
      "[99, 300] loss: 1.467\n",
      "[99, 360] loss: 1.459\n",
      "Epoch: 99 -> Loss: 1.43488943577\n",
      "Epoch: 99 -> Test Accuracy: 41.21\n",
      "[100, 60] loss: 1.484\n",
      "[100, 120] loss: 1.459\n",
      "[100, 180] loss: 1.469\n",
      "[100, 240] loss: 1.468\n",
      "[100, 300] loss: 1.479\n",
      "[100, 360] loss: 1.465\n",
      "Epoch: 100 -> Loss: 1.63368034363\n",
      "Epoch: 100 -> Test Accuracy: 41.48\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train ConvClassifiers on feature map of net_3block\n",
    "conv_block5_loss_log, _, conv_block5_test_accuracy_log, _, _ = tr.train_all_blocks(5, 10, [0.1, 0.02, 0.004, 0.0008], \n",
    "    [35, 70, 85, 100], 0.9, 5e-4, net_block5, criterion, trainloader, None, testloader, use_ConvClassifier=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save variables\n",
    "fm.save_variable([rot_block5_loss_log, rot_block5_test_accuracy_log, \n",
    "                  block5_loss_log, block5_test_accuracy_log, \n",
    "                  conv_block5_loss_log, conv_block5_test_accuracy_log], \"5_block_net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename files\n",
    "fm.add_block_to_name(5, [100, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised NIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In the code of the paper a 3 convolutional block RotNet was used for the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize networks\n",
    "net_class = RN.RotNet(num_classes=10, num_conv_block=3, add_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.751\n",
      "[1, 120] loss: 1.480\n",
      "[1, 180] loss: 1.339\n",
      "[1, 240] loss: 1.254\n",
      "[1, 300] loss: 1.175\n",
      "[1, 360] loss: 1.112\n",
      "Epoch: 1 -> Loss: 0.825036227703\n",
      "Epoch: 1 -> Test Accuracy: 60.62\n",
      "[2, 60] loss: 1.038\n",
      "[2, 120] loss: 0.998\n",
      "[2, 180] loss: 0.963\n",
      "[2, 240] loss: 0.930\n",
      "[2, 300] loss: 0.911\n",
      "[2, 360] loss: 0.883\n",
      "Epoch: 2 -> Loss: 0.775784909725\n",
      "Epoch: 2 -> Test Accuracy: 69.0\n",
      "[3, 60] loss: 0.800\n",
      "[3, 120] loss: 0.807\n",
      "[3, 180] loss: 0.783\n",
      "[3, 240] loss: 0.803\n",
      "[3, 300] loss: 0.791\n",
      "[3, 360] loss: 0.775\n",
      "Epoch: 3 -> Loss: 0.804202079773\n",
      "Epoch: 3 -> Test Accuracy: 72.79\n",
      "[4, 60] loss: 0.708\n",
      "[4, 120] loss: 0.718\n",
      "[4, 180] loss: 0.737\n",
      "[4, 240] loss: 0.714\n",
      "[4, 300] loss: 0.705\n",
      "[4, 360] loss: 0.708\n",
      "Epoch: 4 -> Loss: 0.555963754654\n",
      "Epoch: 4 -> Test Accuracy: 75.21\n",
      "[5, 60] loss: 0.648\n",
      "[5, 120] loss: 0.670\n",
      "[5, 180] loss: 0.670\n",
      "[5, 240] loss: 0.658\n",
      "[5, 300] loss: 0.669\n",
      "[5, 360] loss: 0.655\n",
      "Epoch: 5 -> Loss: 0.522774040699\n",
      "Epoch: 5 -> Test Accuracy: 75.59\n",
      "[6, 60] loss: 0.632\n",
      "[6, 120] loss: 0.638\n",
      "[6, 180] loss: 0.635\n",
      "[6, 240] loss: 0.631\n",
      "[6, 300] loss: 0.636\n",
      "[6, 360] loss: 0.617\n",
      "Epoch: 6 -> Loss: 0.645114660263\n",
      "Epoch: 6 -> Test Accuracy: 77.1\n",
      "[7, 60] loss: 0.598\n",
      "[7, 120] loss: 0.603\n",
      "[7, 180] loss: 0.604\n",
      "[7, 240] loss: 0.593\n",
      "[7, 300] loss: 0.605\n",
      "[7, 360] loss: 0.594\n",
      "Epoch: 7 -> Loss: 0.616147696972\n",
      "Epoch: 7 -> Test Accuracy: 77.37\n",
      "[8, 60] loss: 0.588\n",
      "[8, 120] loss: 0.577\n",
      "[8, 180] loss: 0.567\n",
      "[8, 240] loss: 0.556\n",
      "[8, 300] loss: 0.587\n",
      "[8, 360] loss: 0.568\n",
      "Epoch: 8 -> Loss: 0.573764920235\n",
      "Epoch: 8 -> Test Accuracy: 78.65\n",
      "[9, 60] loss: 0.524\n",
      "[9, 120] loss: 0.565\n",
      "[9, 180] loss: 0.547\n",
      "[9, 240] loss: 0.570\n",
      "[9, 300] loss: 0.547\n",
      "[9, 360] loss: 0.549\n",
      "Epoch: 9 -> Loss: 0.599540233612\n",
      "Epoch: 9 -> Test Accuracy: 79.55\n",
      "[10, 60] loss: 0.528\n",
      "[10, 120] loss: 0.548\n",
      "[10, 180] loss: 0.523\n",
      "[10, 240] loss: 0.549\n",
      "[10, 300] loss: 0.543\n",
      "[10, 360] loss: 0.568\n",
      "Epoch: 10 -> Loss: 0.459079831839\n",
      "Epoch: 10 -> Test Accuracy: 79.53\n",
      "[11, 60] loss: 0.512\n",
      "[11, 120] loss: 0.509\n",
      "[11, 180] loss: 0.520\n",
      "[11, 240] loss: 0.528\n",
      "[11, 300] loss: 0.552\n",
      "[11, 360] loss: 0.524\n",
      "Epoch: 11 -> Loss: 0.526621758938\n",
      "Epoch: 11 -> Test Accuracy: 79.39\n",
      "[12, 60] loss: 0.503\n",
      "[12, 120] loss: 0.503\n",
      "[12, 180] loss: 0.491\n",
      "[12, 240] loss: 0.546\n",
      "[12, 300] loss: 0.506\n",
      "[12, 360] loss: 0.537\n",
      "Epoch: 12 -> Loss: 0.492984056473\n",
      "Epoch: 12 -> Test Accuracy: 80.46\n",
      "[13, 60] loss: 0.488\n",
      "[13, 120] loss: 0.493\n",
      "[13, 180] loss: 0.512\n",
      "[13, 240] loss: 0.502\n",
      "[13, 300] loss: 0.521\n",
      "[13, 360] loss: 0.511\n",
      "Epoch: 13 -> Loss: 0.88372194767\n",
      "Epoch: 13 -> Test Accuracy: 80.23\n",
      "[14, 60] loss: 0.489\n",
      "[14, 120] loss: 0.492\n",
      "[14, 180] loss: 0.496\n",
      "[14, 240] loss: 0.493\n",
      "[14, 300] loss: 0.504\n",
      "[14, 360] loss: 0.482\n",
      "Epoch: 14 -> Loss: 0.431423246861\n",
      "Epoch: 14 -> Test Accuracy: 80.05\n",
      "[15, 60] loss: 0.496\n",
      "[15, 120] loss: 0.476\n",
      "[15, 180] loss: 0.500\n",
      "[15, 240] loss: 0.499\n",
      "[15, 300] loss: 0.473\n",
      "[15, 360] loss: 0.502\n",
      "Epoch: 15 -> Loss: 0.477042138577\n",
      "Epoch: 15 -> Test Accuracy: 80.66\n",
      "[16, 60] loss: 0.460\n",
      "[16, 120] loss: 0.495\n",
      "[16, 180] loss: 0.456\n",
      "[16, 240] loss: 0.480\n",
      "[16, 300] loss: 0.463\n",
      "[16, 360] loss: 0.492\n",
      "Epoch: 16 -> Loss: 0.489493042231\n",
      "Epoch: 16 -> Test Accuracy: 81.42\n",
      "[17, 60] loss: 0.481\n",
      "[17, 120] loss: 0.447\n",
      "[17, 180] loss: 0.472\n",
      "[17, 240] loss: 0.449\n",
      "[17, 300] loss: 0.476\n",
      "[17, 360] loss: 0.476\n",
      "Epoch: 17 -> Loss: 0.366201579571\n",
      "Epoch: 17 -> Test Accuracy: 81.96\n",
      "[18, 60] loss: 0.459\n",
      "[18, 120] loss: 0.470\n",
      "[18, 180] loss: 0.490\n",
      "[18, 240] loss: 0.457\n",
      "[18, 300] loss: 0.471\n",
      "[18, 360] loss: 0.464\n",
      "Epoch: 18 -> Loss: 0.637535214424\n",
      "Epoch: 18 -> Test Accuracy: 82.02\n",
      "[19, 60] loss: 0.436\n",
      "[19, 120] loss: 0.467\n",
      "[19, 180] loss: 0.462\n",
      "[19, 240] loss: 0.464\n",
      "[19, 300] loss: 0.457\n",
      "[19, 360] loss: 0.468\n",
      "Epoch: 19 -> Loss: 0.519069314003\n",
      "Epoch: 19 -> Test Accuracy: 82.46\n",
      "[20, 60] loss: 0.462\n",
      "[20, 120] loss: 0.441\n",
      "[20, 180] loss: 0.461\n",
      "[20, 240] loss: 0.458\n",
      "[20, 300] loss: 0.445\n",
      "[20, 360] loss: 0.462\n",
      "Epoch: 20 -> Loss: 0.585631966591\n",
      "Epoch: 20 -> Test Accuracy: 82.5\n",
      "[21, 60] loss: 0.439\n",
      "[21, 120] loss: 0.439\n",
      "[21, 180] loss: 0.454\n",
      "[21, 240] loss: 0.454\n",
      "[21, 300] loss: 0.471\n",
      "[21, 360] loss: 0.434\n",
      "Epoch: 21 -> Loss: 0.443163454533\n",
      "Epoch: 21 -> Test Accuracy: 81.27\n",
      "[22, 60] loss: 0.407\n",
      "[22, 120] loss: 0.436\n",
      "[22, 180] loss: 0.473\n",
      "[22, 240] loss: 0.449\n",
      "[22, 300] loss: 0.457\n",
      "[22, 360] loss: 0.440\n",
      "Epoch: 22 -> Loss: 0.397458344698\n",
      "Epoch: 22 -> Test Accuracy: 82.7\n",
      "[23, 60] loss: 0.421\n",
      "[23, 120] loss: 0.423\n",
      "[23, 180] loss: 0.455\n",
      "[23, 240] loss: 0.463\n",
      "[23, 300] loss: 0.432\n",
      "[23, 360] loss: 0.454\n",
      "Epoch: 23 -> Loss: 0.573688149452\n",
      "Epoch: 23 -> Test Accuracy: 81.06\n",
      "[24, 60] loss: 0.425\n",
      "[24, 120] loss: 0.408\n",
      "[24, 180] loss: 0.464\n",
      "[24, 240] loss: 0.438\n",
      "[24, 300] loss: 0.448\n",
      "[24, 360] loss: 0.435\n",
      "Epoch: 24 -> Loss: 0.485114812851\n",
      "Epoch: 24 -> Test Accuracy: 82.19\n",
      "[25, 60] loss: 0.425\n",
      "[25, 120] loss: 0.403\n",
      "[25, 180] loss: 0.429\n",
      "[25, 240] loss: 0.438\n",
      "[25, 300] loss: 0.437\n",
      "[25, 360] loss: 0.459\n",
      "Epoch: 25 -> Loss: 0.451935589314\n",
      "Epoch: 25 -> Test Accuracy: 82.87\n",
      "[26, 60] loss: 0.432\n",
      "[26, 120] loss: 0.423\n",
      "[26, 180] loss: 0.420\n",
      "[26, 240] loss: 0.435\n",
      "[26, 300] loss: 0.446\n",
      "[26, 360] loss: 0.417\n",
      "Epoch: 26 -> Loss: 0.521824896336\n",
      "Epoch: 26 -> Test Accuracy: 83.0\n",
      "[27, 60] loss: 0.420\n",
      "[27, 120] loss: 0.419\n",
      "[27, 180] loss: 0.432\n",
      "[27, 240] loss: 0.444\n",
      "[27, 300] loss: 0.419\n",
      "[27, 360] loss: 0.461\n",
      "Epoch: 27 -> Loss: 0.448279857635\n",
      "Epoch: 27 -> Test Accuracy: 82.64\n",
      "[28, 60] loss: 0.402\n",
      "[28, 120] loss: 0.403\n",
      "[28, 180] loss: 0.417\n",
      "[28, 240] loss: 0.444\n",
      "[28, 300] loss: 0.426\n",
      "[28, 360] loss: 0.435\n",
      "Epoch: 28 -> Loss: 0.296328753233\n",
      "Epoch: 28 -> Test Accuracy: 83.38\n",
      "[29, 60] loss: 0.413\n",
      "[29, 120] loss: 0.423\n",
      "[29, 180] loss: 0.419\n",
      "[29, 240] loss: 0.417\n",
      "[29, 300] loss: 0.442\n",
      "[29, 360] loss: 0.436\n",
      "Epoch: 29 -> Loss: 0.414182603359\n",
      "Epoch: 29 -> Test Accuracy: 82.96\n",
      "[30, 60] loss: 0.396\n",
      "[30, 120] loss: 0.418\n",
      "[30, 180] loss: 0.409\n",
      "[30, 240] loss: 0.423\n",
      "[30, 300] loss: 0.435\n",
      "[30, 360] loss: 0.423\n",
      "Epoch: 30 -> Loss: 0.492857694626\n",
      "Epoch: 30 -> Test Accuracy: 82.43\n",
      "[31, 60] loss: 0.415\n",
      "[31, 120] loss: 0.407\n",
      "[31, 180] loss: 0.405\n",
      "[31, 240] loss: 0.409\n",
      "[31, 300] loss: 0.420\n",
      "[31, 360] loss: 0.429\n",
      "Epoch: 31 -> Loss: 0.408995449543\n",
      "Epoch: 31 -> Test Accuracy: 82.86\n",
      "[32, 60] loss: 0.411\n",
      "[32, 120] loss: 0.404\n",
      "[32, 180] loss: 0.407\n",
      "[32, 240] loss: 0.423\n",
      "[32, 300] loss: 0.411\n",
      "[32, 360] loss: 0.425\n",
      "Epoch: 32 -> Loss: 0.489699691534\n",
      "Epoch: 32 -> Test Accuracy: 84.13\n",
      "[33, 60] loss: 0.380\n",
      "[33, 120] loss: 0.398\n",
      "[33, 180] loss: 0.428\n",
      "[33, 240] loss: 0.424\n",
      "[33, 300] loss: 0.423\n",
      "[33, 360] loss: 0.424\n",
      "Epoch: 33 -> Loss: 0.340313047171\n",
      "Epoch: 33 -> Test Accuracy: 82.46\n",
      "[34, 60] loss: 0.399\n",
      "[34, 120] loss: 0.399\n",
      "[34, 180] loss: 0.419\n",
      "[34, 240] loss: 0.405\n",
      "[34, 300] loss: 0.422\n",
      "[34, 360] loss: 0.435\n",
      "Epoch: 34 -> Loss: 0.443888813257\n",
      "Epoch: 34 -> Test Accuracy: 84.08\n",
      "[35, 60] loss: 0.397\n",
      "[35, 120] loss: 0.399\n",
      "[35, 180] loss: 0.400\n",
      "[35, 240] loss: 0.437\n",
      "[35, 300] loss: 0.420\n",
      "[35, 360] loss: 0.411\n",
      "Epoch: 35 -> Loss: 0.550703644753\n",
      "Epoch: 35 -> Test Accuracy: 84.29\n",
      "[36, 60] loss: 0.378\n",
      "[36, 120] loss: 0.415\n",
      "[36, 180] loss: 0.401\n",
      "[36, 240] loss: 0.413\n",
      "[36, 300] loss: 0.418\n",
      "[36, 360] loss: 0.405\n",
      "Epoch: 36 -> Loss: 0.388389289379\n",
      "Epoch: 36 -> Test Accuracy: 82.57\n",
      "[37, 60] loss: 0.395\n",
      "[37, 120] loss: 0.403\n",
      "[37, 180] loss: 0.417\n",
      "[37, 240] loss: 0.433\n",
      "[37, 300] loss: 0.428\n",
      "[37, 360] loss: 0.420\n",
      "Epoch: 37 -> Loss: 0.444215625525\n",
      "Epoch: 37 -> Test Accuracy: 83.28\n",
      "[38, 60] loss: 0.387\n",
      "[38, 120] loss: 0.392\n",
      "[38, 180] loss: 0.388\n",
      "[38, 240] loss: 0.398\n",
      "[38, 300] loss: 0.419\n",
      "[38, 360] loss: 0.420\n",
      "Epoch: 38 -> Loss: 0.378732860088\n",
      "Epoch: 38 -> Test Accuracy: 82.44\n",
      "[39, 60] loss: 0.387\n",
      "[39, 120] loss: 0.380\n",
      "[39, 180] loss: 0.399\n",
      "[39, 240] loss: 0.414\n",
      "[39, 300] loss: 0.413\n",
      "[39, 360] loss: 0.404\n",
      "Epoch: 39 -> Loss: 0.441468238831\n",
      "Epoch: 39 -> Test Accuracy: 83.92\n",
      "[40, 60] loss: 0.391\n",
      "[40, 120] loss: 0.384\n",
      "[40, 180] loss: 0.414\n",
      "[40, 240] loss: 0.404\n",
      "[40, 300] loss: 0.423\n",
      "[40, 360] loss: 0.417\n",
      "Epoch: 40 -> Loss: 0.44526296854\n",
      "Epoch: 40 -> Test Accuracy: 83.79\n",
      "[41, 60] loss: 0.391\n",
      "[41, 120] loss: 0.384\n",
      "[41, 180] loss: 0.414\n",
      "[41, 240] loss: 0.414\n",
      "[41, 300] loss: 0.413\n",
      "[41, 360] loss: 0.408\n",
      "Epoch: 41 -> Loss: 0.379072278738\n",
      "Epoch: 41 -> Test Accuracy: 83.75\n",
      "[42, 60] loss: 0.379\n",
      "[42, 120] loss: 0.404\n",
      "[42, 180] loss: 0.400\n",
      "[42, 240] loss: 0.424\n",
      "[42, 300] loss: 0.414\n",
      "[42, 360] loss: 0.398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.593099057674\n",
      "Epoch: 42 -> Test Accuracy: 83.77\n",
      "[43, 60] loss: 0.380\n",
      "[43, 120] loss: 0.389\n",
      "[43, 180] loss: 0.401\n",
      "[43, 240] loss: 0.431\n",
      "[43, 300] loss: 0.406\n",
      "[43, 360] loss: 0.399\n",
      "Epoch: 43 -> Loss: 0.20330825448\n",
      "Epoch: 43 -> Test Accuracy: 83.59\n",
      "[44, 60] loss: 0.359\n",
      "[44, 120] loss: 0.397\n",
      "[44, 180] loss: 0.400\n",
      "[44, 240] loss: 0.403\n",
      "[44, 300] loss: 0.405\n",
      "[44, 360] loss: 0.407\n",
      "Epoch: 44 -> Loss: 0.428490787745\n",
      "Epoch: 44 -> Test Accuracy: 84.12\n",
      "[45, 60] loss: 0.389\n",
      "[45, 120] loss: 0.412\n",
      "[45, 180] loss: 0.382\n",
      "[45, 240] loss: 0.397\n",
      "[45, 300] loss: 0.401\n",
      "[45, 360] loss: 0.413\n",
      "Epoch: 45 -> Loss: 0.486002355814\n",
      "Epoch: 45 -> Test Accuracy: 83.85\n",
      "[46, 60] loss: 0.398\n",
      "[46, 120] loss: 0.382\n",
      "[46, 180] loss: 0.416\n",
      "[46, 240] loss: 0.384\n",
      "[46, 300] loss: 0.406\n",
      "[46, 360] loss: 0.422\n",
      "Epoch: 46 -> Loss: 0.473516404629\n",
      "Epoch: 46 -> Test Accuracy: 82.9\n",
      "[47, 60] loss: 0.363\n",
      "[47, 120] loss: 0.402\n",
      "[47, 180] loss: 0.396\n",
      "[47, 240] loss: 0.389\n",
      "[47, 300] loss: 0.410\n",
      "[47, 360] loss: 0.407\n",
      "Epoch: 47 -> Loss: 0.30972841382\n",
      "Epoch: 47 -> Test Accuracy: 83.93\n",
      "[48, 60] loss: 0.361\n",
      "[48, 120] loss: 0.376\n",
      "[48, 180] loss: 0.410\n",
      "[48, 240] loss: 0.422\n",
      "[48, 300] loss: 0.400\n",
      "[48, 360] loss: 0.403\n",
      "Epoch: 48 -> Loss: 0.2999766469\n",
      "Epoch: 48 -> Test Accuracy: 84.31\n",
      "[49, 60] loss: 0.394\n",
      "[49, 120] loss: 0.380\n",
      "[49, 180] loss: 0.405\n",
      "[49, 240] loss: 0.398\n",
      "[49, 300] loss: 0.404\n",
      "[49, 360] loss: 0.381\n",
      "Epoch: 49 -> Loss: 0.502337992191\n",
      "Epoch: 49 -> Test Accuracy: 82.65\n",
      "[50, 60] loss: 0.372\n",
      "[50, 120] loss: 0.378\n",
      "[50, 180] loss: 0.397\n",
      "[50, 240] loss: 0.400\n",
      "[50, 300] loss: 0.384\n",
      "[50, 360] loss: 0.408\n",
      "Epoch: 50 -> Loss: 0.469843149185\n",
      "Epoch: 50 -> Test Accuracy: 85.27\n",
      "[51, 60] loss: 0.368\n",
      "[51, 120] loss: 0.398\n",
      "[51, 180] loss: 0.380\n",
      "[51, 240] loss: 0.404\n",
      "[51, 300] loss: 0.403\n",
      "[51, 360] loss: 0.399\n",
      "Epoch: 51 -> Loss: 0.491511195898\n",
      "Epoch: 51 -> Test Accuracy: 84.14\n",
      "[52, 60] loss: 0.367\n",
      "[52, 120] loss: 0.372\n",
      "[52, 180] loss: 0.385\n",
      "[52, 240] loss: 0.417\n",
      "[52, 300] loss: 0.391\n",
      "[52, 360] loss: 0.391\n",
      "Epoch: 52 -> Loss: 0.439156144857\n",
      "Epoch: 52 -> Test Accuracy: 84.07\n",
      "[53, 60] loss: 0.371\n",
      "[53, 120] loss: 0.373\n",
      "[53, 180] loss: 0.390\n",
      "[53, 240] loss: 0.409\n",
      "[53, 300] loss: 0.411\n",
      "[53, 360] loss: 0.411\n",
      "Epoch: 53 -> Loss: 0.396387606859\n",
      "Epoch: 53 -> Test Accuracy: 83.2\n",
      "[54, 60] loss: 0.372\n",
      "[54, 120] loss: 0.362\n",
      "[54, 180] loss: 0.393\n",
      "[54, 240] loss: 0.407\n",
      "[54, 300] loss: 0.382\n",
      "[54, 360] loss: 0.420\n",
      "Epoch: 54 -> Loss: 0.492816776037\n",
      "Epoch: 54 -> Test Accuracy: 83.64\n",
      "[55, 60] loss: 0.379\n",
      "[55, 120] loss: 0.402\n",
      "[55, 180] loss: 0.403\n",
      "[55, 240] loss: 0.368\n",
      "[55, 300] loss: 0.382\n",
      "[55, 360] loss: 0.406\n",
      "Epoch: 55 -> Loss: 0.495667219162\n",
      "Epoch: 55 -> Test Accuracy: 84.79\n",
      "[56, 60] loss: 0.371\n",
      "[56, 120] loss: 0.376\n",
      "[56, 180] loss: 0.375\n",
      "[56, 240] loss: 0.386\n",
      "[56, 300] loss: 0.389\n",
      "[56, 360] loss: 0.409\n",
      "Epoch: 56 -> Loss: 0.326176345348\n",
      "Epoch: 56 -> Test Accuracy: 84.16\n",
      "[57, 60] loss: 0.376\n",
      "[57, 120] loss: 0.373\n",
      "[57, 180] loss: 0.389\n",
      "[57, 240] loss: 0.400\n",
      "[57, 300] loss: 0.388\n",
      "[57, 360] loss: 0.378\n",
      "Epoch: 57 -> Loss: 0.519686937332\n",
      "Epoch: 57 -> Test Accuracy: 83.23\n",
      "[58, 60] loss: 0.384\n",
      "[58, 120] loss: 0.358\n",
      "[58, 180] loss: 0.385\n",
      "[58, 240] loss: 0.382\n",
      "[58, 300] loss: 0.399\n",
      "[58, 360] loss: 0.410\n",
      "Epoch: 58 -> Loss: 0.343048483133\n",
      "Epoch: 58 -> Test Accuracy: 84.65\n",
      "[59, 60] loss: 0.359\n",
      "[59, 120] loss: 0.384\n",
      "[59, 180] loss: 0.395\n",
      "[59, 240] loss: 0.391\n",
      "[59, 300] loss: 0.385\n",
      "[59, 360] loss: 0.396\n",
      "Epoch: 59 -> Loss: 0.461993128061\n",
      "Epoch: 59 -> Test Accuracy: 84.73\n",
      "[60, 60] loss: 0.362\n",
      "[60, 120] loss: 0.391\n",
      "[60, 180] loss: 0.386\n",
      "[60, 240] loss: 0.398\n",
      "[60, 300] loss: 0.393\n",
      "[60, 360] loss: 0.380\n",
      "Epoch: 60 -> Loss: 0.526801228523\n",
      "Epoch: 60 -> Test Accuracy: 81.88\n",
      "[61, 60] loss: 0.280\n",
      "[61, 120] loss: 0.221\n",
      "[61, 180] loss: 0.220\n",
      "[61, 240] loss: 0.225\n",
      "[61, 300] loss: 0.212\n",
      "[61, 360] loss: 0.205\n",
      "Epoch: 61 -> Loss: 0.132441371679\n",
      "Epoch: 61 -> Test Accuracy: 89.27\n",
      "[62, 60] loss: 0.168\n",
      "[62, 120] loss: 0.172\n",
      "[62, 180] loss: 0.173\n",
      "[62, 240] loss: 0.174\n",
      "[62, 300] loss: 0.188\n",
      "[62, 360] loss: 0.181\n",
      "Epoch: 62 -> Loss: 0.262564599514\n",
      "Epoch: 62 -> Test Accuracy: 89.49\n",
      "[63, 60] loss: 0.152\n",
      "[63, 120] loss: 0.166\n",
      "[63, 180] loss: 0.161\n",
      "[63, 240] loss: 0.155\n",
      "[63, 300] loss: 0.162\n",
      "[63, 360] loss: 0.162\n",
      "Epoch: 63 -> Loss: 0.164224550128\n",
      "Epoch: 63 -> Test Accuracy: 89.29\n",
      "[64, 60] loss: 0.137\n",
      "[64, 120] loss: 0.147\n",
      "[64, 180] loss: 0.144\n",
      "[64, 240] loss: 0.157\n",
      "[64, 300] loss: 0.156\n",
      "[64, 360] loss: 0.149\n",
      "Epoch: 64 -> Loss: 0.199184060097\n",
      "Epoch: 64 -> Test Accuracy: 89.32\n",
      "[65, 60] loss: 0.124\n",
      "[65, 120] loss: 0.140\n",
      "[65, 180] loss: 0.148\n",
      "[65, 240] loss: 0.131\n",
      "[65, 300] loss: 0.153\n",
      "[65, 360] loss: 0.149\n",
      "Epoch: 65 -> Loss: 0.127772569656\n",
      "Epoch: 65 -> Test Accuracy: 89.05\n",
      "[66, 60] loss: 0.118\n",
      "[66, 120] loss: 0.131\n",
      "[66, 180] loss: 0.138\n",
      "[66, 240] loss: 0.133\n",
      "[66, 300] loss: 0.139\n",
      "[66, 360] loss: 0.148\n",
      "Epoch: 66 -> Loss: 0.161133691669\n",
      "Epoch: 66 -> Test Accuracy: 89.35\n",
      "[67, 60] loss: 0.134\n",
      "[67, 120] loss: 0.125\n",
      "[67, 180] loss: 0.116\n",
      "[67, 240] loss: 0.138\n",
      "[67, 300] loss: 0.141\n",
      "[67, 360] loss: 0.137\n",
      "Epoch: 67 -> Loss: 0.153490871191\n",
      "Epoch: 67 -> Test Accuracy: 89.13\n",
      "[68, 60] loss: 0.126\n",
      "[68, 120] loss: 0.121\n",
      "[68, 180] loss: 0.128\n",
      "[68, 240] loss: 0.133\n",
      "[68, 300] loss: 0.129\n",
      "[68, 360] loss: 0.137\n",
      "Epoch: 68 -> Loss: 0.109140112996\n",
      "Epoch: 68 -> Test Accuracy: 88.57\n",
      "[69, 60] loss: 0.122\n",
      "[69, 120] loss: 0.120\n",
      "[69, 180] loss: 0.123\n",
      "[69, 240] loss: 0.130\n",
      "[69, 300] loss: 0.146\n",
      "[69, 360] loss: 0.140\n",
      "Epoch: 69 -> Loss: 0.161554858088\n",
      "Epoch: 69 -> Test Accuracy: 89.36\n",
      "[70, 60] loss: 0.120\n",
      "[70, 120] loss: 0.112\n",
      "[70, 180] loss: 0.129\n",
      "[70, 240] loss: 0.130\n",
      "[70, 300] loss: 0.132\n",
      "[70, 360] loss: 0.138\n",
      "Epoch: 70 -> Loss: 0.102998875082\n",
      "Epoch: 70 -> Test Accuracy: 88.62\n",
      "[71, 60] loss: 0.130\n",
      "[71, 120] loss: 0.116\n",
      "[71, 180] loss: 0.129\n",
      "[71, 240] loss: 0.134\n",
      "[71, 300] loss: 0.154\n",
      "[71, 360] loss: 0.139\n",
      "Epoch: 71 -> Loss: 0.152618929744\n",
      "Epoch: 71 -> Test Accuracy: 88.61\n",
      "[72, 60] loss: 0.118\n",
      "[72, 120] loss: 0.119\n",
      "[72, 180] loss: 0.134\n",
      "[72, 240] loss: 0.139\n",
      "[72, 300] loss: 0.149\n",
      "[72, 360] loss: 0.160\n",
      "Epoch: 72 -> Loss: 0.129081323743\n",
      "Epoch: 72 -> Test Accuracy: 88.7\n",
      "[73, 60] loss: 0.121\n",
      "[73, 120] loss: 0.134\n",
      "[73, 180] loss: 0.135\n",
      "[73, 240] loss: 0.123\n",
      "[73, 300] loss: 0.140\n",
      "[73, 360] loss: 0.133\n",
      "Epoch: 73 -> Loss: 0.137998253107\n",
      "Epoch: 73 -> Test Accuracy: 88.36\n",
      "[74, 60] loss: 0.118\n",
      "[74, 120] loss: 0.131\n",
      "[74, 180] loss: 0.118\n",
      "[74, 240] loss: 0.142\n",
      "[74, 300] loss: 0.147\n",
      "[74, 360] loss: 0.139\n",
      "Epoch: 74 -> Loss: 0.0809362605214\n",
      "Epoch: 74 -> Test Accuracy: 88.13\n",
      "[75, 60] loss: 0.124\n",
      "[75, 120] loss: 0.141\n",
      "[75, 180] loss: 0.150\n",
      "[75, 240] loss: 0.143\n",
      "[75, 300] loss: 0.158\n",
      "[75, 360] loss: 0.156\n",
      "Epoch: 75 -> Loss: 0.30938565731\n",
      "Epoch: 75 -> Test Accuracy: 87.59\n",
      "[76, 60] loss: 0.123\n",
      "[76, 120] loss: 0.126\n",
      "[76, 180] loss: 0.134\n",
      "[76, 240] loss: 0.132\n",
      "[76, 300] loss: 0.144\n",
      "[76, 360] loss: 0.143\n",
      "Epoch: 76 -> Loss: 0.158531919122\n",
      "Epoch: 76 -> Test Accuracy: 88.79\n",
      "[77, 60] loss: 0.121\n",
      "[77, 120] loss: 0.130\n",
      "[77, 180] loss: 0.139\n",
      "[77, 240] loss: 0.139\n",
      "[77, 300] loss: 0.147\n",
      "[77, 360] loss: 0.150\n",
      "Epoch: 77 -> Loss: 0.077156893909\n",
      "Epoch: 77 -> Test Accuracy: 88.3\n",
      "[78, 60] loss: 0.114\n",
      "[78, 120] loss: 0.127\n",
      "[78, 180] loss: 0.122\n",
      "[78, 240] loss: 0.136\n",
      "[78, 300] loss: 0.141\n",
      "[78, 360] loss: 0.156\n",
      "Epoch: 78 -> Loss: 0.336257785559\n",
      "Epoch: 78 -> Test Accuracy: 87.83\n",
      "[79, 60] loss: 0.147\n",
      "[79, 120] loss: 0.124\n",
      "[79, 180] loss: 0.135\n",
      "[79, 240] loss: 0.141\n",
      "[79, 300] loss: 0.143\n",
      "[79, 360] loss: 0.153\n",
      "Epoch: 79 -> Loss: 0.121548376977\n",
      "Epoch: 79 -> Test Accuracy: 87.59\n",
      "[80, 60] loss: 0.131\n",
      "[80, 120] loss: 0.127\n",
      "[80, 180] loss: 0.125\n",
      "[80, 240] loss: 0.139\n",
      "[80, 300] loss: 0.152\n",
      "[80, 360] loss: 0.163\n",
      "Epoch: 80 -> Loss: 0.0924355834723\n",
      "Epoch: 80 -> Test Accuracy: 88.42\n",
      "[81, 60] loss: 0.125\n",
      "[81, 120] loss: 0.123\n",
      "[81, 180] loss: 0.125\n",
      "[81, 240] loss: 0.140\n",
      "[81, 300] loss: 0.143\n",
      "[81, 360] loss: 0.139\n",
      "Epoch: 81 -> Loss: 0.144900158048\n",
      "Epoch: 81 -> Test Accuracy: 89.16\n",
      "[82, 60] loss: 0.118\n",
      "[82, 120] loss: 0.128\n",
      "[82, 180] loss: 0.138\n",
      "[82, 240] loss: 0.148\n",
      "[82, 300] loss: 0.148\n",
      "[82, 360] loss: 0.133\n",
      "Epoch: 82 -> Loss: 0.26424741745\n",
      "Epoch: 82 -> Test Accuracy: 87.97\n",
      "[83, 60] loss: 0.114\n",
      "[83, 120] loss: 0.126\n",
      "[83, 180] loss: 0.129\n",
      "[83, 240] loss: 0.136\n",
      "[83, 300] loss: 0.133\n",
      "[83, 360] loss: 0.149\n",
      "Epoch: 83 -> Loss: 0.19867387414\n",
      "Epoch: 83 -> Test Accuracy: 88.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.114\n",
      "[84, 120] loss: 0.121\n",
      "[84, 180] loss: 0.132\n",
      "[84, 240] loss: 0.132\n",
      "[84, 300] loss: 0.142\n",
      "[84, 360] loss: 0.158\n",
      "Epoch: 84 -> Loss: 0.0979826822877\n",
      "Epoch: 84 -> Test Accuracy: 88.32\n",
      "[85, 60] loss: 0.120\n",
      "[85, 120] loss: 0.130\n",
      "[85, 180] loss: 0.140\n",
      "[85, 240] loss: 0.146\n",
      "[85, 300] loss: 0.142\n",
      "[85, 360] loss: 0.143\n",
      "Epoch: 85 -> Loss: 0.166171133518\n",
      "Epoch: 85 -> Test Accuracy: 88.5\n",
      "[86, 60] loss: 0.119\n",
      "[86, 120] loss: 0.122\n",
      "[86, 180] loss: 0.136\n",
      "[86, 240] loss: 0.129\n",
      "[86, 300] loss: 0.135\n",
      "[86, 360] loss: 0.156\n",
      "Epoch: 86 -> Loss: 0.151281192899\n",
      "Epoch: 86 -> Test Accuracy: 88.61\n",
      "[87, 60] loss: 0.120\n",
      "[87, 120] loss: 0.109\n",
      "[87, 180] loss: 0.132\n",
      "[87, 240] loss: 0.128\n",
      "[87, 300] loss: 0.143\n",
      "[87, 360] loss: 0.142\n",
      "Epoch: 87 -> Loss: 0.173461005092\n",
      "Epoch: 87 -> Test Accuracy: 88.67\n",
      "[88, 60] loss: 0.116\n",
      "[88, 120] loss: 0.128\n",
      "[88, 180] loss: 0.130\n",
      "[88, 240] loss: 0.139\n",
      "[88, 300] loss: 0.140\n",
      "[88, 360] loss: 0.140\n",
      "Epoch: 88 -> Loss: 0.225553706288\n",
      "Epoch: 88 -> Test Accuracy: 88.07\n",
      "[89, 60] loss: 0.113\n",
      "[89, 120] loss: 0.125\n",
      "[89, 180] loss: 0.127\n",
      "[89, 240] loss: 0.136\n",
      "[89, 300] loss: 0.139\n",
      "[89, 360] loss: 0.137\n",
      "Epoch: 89 -> Loss: 0.165683954954\n",
      "Epoch: 89 -> Test Accuracy: 87.6\n",
      "[90, 60] loss: 0.106\n",
      "[90, 120] loss: 0.113\n",
      "[90, 180] loss: 0.122\n",
      "[90, 240] loss: 0.137\n",
      "[90, 300] loss: 0.142\n",
      "[90, 360] loss: 0.143\n",
      "Epoch: 90 -> Loss: 0.0895455107093\n",
      "Epoch: 90 -> Test Accuracy: 88.4\n",
      "[91, 60] loss: 0.130\n",
      "[91, 120] loss: 0.119\n",
      "[91, 180] loss: 0.124\n",
      "[91, 240] loss: 0.137\n",
      "[91, 300] loss: 0.147\n",
      "[91, 360] loss: 0.138\n",
      "Epoch: 91 -> Loss: 0.221307352185\n",
      "Epoch: 91 -> Test Accuracy: 87.88\n",
      "[92, 60] loss: 0.111\n",
      "[92, 120] loss: 0.126\n",
      "[92, 180] loss: 0.133\n",
      "[92, 240] loss: 0.129\n",
      "[92, 300] loss: 0.136\n",
      "[92, 360] loss: 0.138\n",
      "Epoch: 92 -> Loss: 0.268699020147\n",
      "Epoch: 92 -> Test Accuracy: 88.3\n",
      "[93, 60] loss: 0.110\n",
      "[93, 120] loss: 0.115\n",
      "[93, 180] loss: 0.137\n",
      "[93, 240] loss: 0.123\n",
      "[93, 300] loss: 0.136\n",
      "[93, 360] loss: 0.133\n",
      "Epoch: 93 -> Loss: 0.0883329063654\n",
      "Epoch: 93 -> Test Accuracy: 87.29\n",
      "[94, 60] loss: 0.134\n",
      "[94, 120] loss: 0.125\n",
      "[94, 180] loss: 0.128\n",
      "[94, 240] loss: 0.124\n",
      "[94, 300] loss: 0.128\n",
      "[94, 360] loss: 0.137\n",
      "Epoch: 94 -> Loss: 0.0805646926165\n",
      "Epoch: 94 -> Test Accuracy: 88.1\n",
      "[95, 60] loss: 0.104\n",
      "[95, 120] loss: 0.120\n",
      "[95, 180] loss: 0.114\n",
      "[95, 240] loss: 0.135\n",
      "[95, 300] loss: 0.135\n",
      "[95, 360] loss: 0.139\n",
      "Epoch: 95 -> Loss: 0.18209400773\n",
      "Epoch: 95 -> Test Accuracy: 88.31\n",
      "[96, 60] loss: 0.116\n",
      "[96, 120] loss: 0.110\n",
      "[96, 180] loss: 0.122\n",
      "[96, 240] loss: 0.127\n",
      "[96, 300] loss: 0.136\n",
      "[96, 360] loss: 0.130\n",
      "Epoch: 96 -> Loss: 0.0532575622201\n",
      "Epoch: 96 -> Test Accuracy: 88.14\n",
      "[97, 60] loss: 0.124\n",
      "[97, 120] loss: 0.130\n",
      "[97, 180] loss: 0.111\n",
      "[97, 240] loss: 0.112\n",
      "[97, 300] loss: 0.125\n",
      "[97, 360] loss: 0.142\n",
      "Epoch: 97 -> Loss: 0.068568430841\n",
      "Epoch: 97 -> Test Accuracy: 88.73\n",
      "[98, 60] loss: 0.114\n",
      "[98, 120] loss: 0.112\n",
      "[98, 180] loss: 0.123\n",
      "[98, 240] loss: 0.115\n",
      "[98, 300] loss: 0.132\n",
      "[98, 360] loss: 0.140\n",
      "Epoch: 98 -> Loss: 0.0740065425634\n",
      "Epoch: 98 -> Test Accuracy: 88.96\n",
      "[99, 60] loss: 0.116\n",
      "[99, 120] loss: 0.118\n",
      "[99, 180] loss: 0.119\n",
      "[99, 240] loss: 0.122\n",
      "[99, 300] loss: 0.134\n",
      "[99, 360] loss: 0.150\n",
      "Epoch: 99 -> Loss: 0.247417330742\n",
      "Epoch: 99 -> Test Accuracy: 87.67\n",
      "[100, 60] loss: 0.129\n",
      "[100, 120] loss: 0.113\n",
      "[100, 180] loss: 0.112\n",
      "[100, 240] loss: 0.136\n",
      "[100, 300] loss: 0.129\n",
      "[100, 360] loss: 0.130\n",
      "Epoch: 100 -> Loss: 0.089723482728\n",
      "Epoch: 100 -> Test Accuracy: 88.47\n",
      "[101, 60] loss: 0.115\n",
      "[101, 120] loss: 0.111\n",
      "[101, 180] loss: 0.128\n",
      "[101, 240] loss: 0.127\n",
      "[101, 300] loss: 0.132\n",
      "[101, 360] loss: 0.138\n",
      "Epoch: 101 -> Loss: 0.0839704573154\n",
      "Epoch: 101 -> Test Accuracy: 87.68\n",
      "[102, 60] loss: 0.102\n",
      "[102, 120] loss: 0.111\n",
      "[102, 180] loss: 0.131\n",
      "[102, 240] loss: 0.129\n",
      "[102, 300] loss: 0.149\n",
      "[102, 360] loss: 0.136\n",
      "Epoch: 102 -> Loss: 0.243998855352\n",
      "Epoch: 102 -> Test Accuracy: 88.61\n",
      "[103, 60] loss: 0.108\n",
      "[103, 120] loss: 0.103\n",
      "[103, 180] loss: 0.110\n",
      "[103, 240] loss: 0.125\n",
      "[103, 300] loss: 0.127\n",
      "[103, 360] loss: 0.141\n",
      "Epoch: 103 -> Loss: 0.0751181691885\n",
      "Epoch: 103 -> Test Accuracy: 88.23\n",
      "[104, 60] loss: 0.104\n",
      "[104, 120] loss: 0.108\n",
      "[104, 180] loss: 0.118\n",
      "[104, 240] loss: 0.121\n",
      "[104, 300] loss: 0.128\n",
      "[104, 360] loss: 0.125\n",
      "Epoch: 104 -> Loss: 0.214813321829\n",
      "Epoch: 104 -> Test Accuracy: 88.3\n",
      "[105, 60] loss: 0.101\n",
      "[105, 120] loss: 0.103\n",
      "[105, 180] loss: 0.115\n",
      "[105, 240] loss: 0.115\n",
      "[105, 300] loss: 0.131\n",
      "[105, 360] loss: 0.143\n",
      "Epoch: 105 -> Loss: 0.0993434637785\n",
      "Epoch: 105 -> Test Accuracy: 88.33\n",
      "[106, 60] loss: 0.107\n",
      "[106, 120] loss: 0.106\n",
      "[106, 180] loss: 0.107\n",
      "[106, 240] loss: 0.113\n",
      "[106, 300] loss: 0.138\n",
      "[106, 360] loss: 0.127\n",
      "Epoch: 106 -> Loss: 0.0725574865937\n",
      "Epoch: 106 -> Test Accuracy: 88.67\n",
      "[107, 60] loss: 0.105\n",
      "[107, 120] loss: 0.109\n",
      "[107, 180] loss: 0.116\n",
      "[107, 240] loss: 0.123\n",
      "[107, 300] loss: 0.137\n",
      "[107, 360] loss: 0.144\n",
      "Epoch: 107 -> Loss: 0.144227355719\n",
      "Epoch: 107 -> Test Accuracy: 88.15\n",
      "[108, 60] loss: 0.112\n",
      "[108, 120] loss: 0.117\n",
      "[108, 180] loss: 0.124\n",
      "[108, 240] loss: 0.120\n",
      "[108, 300] loss: 0.118\n",
      "[108, 360] loss: 0.136\n",
      "Epoch: 108 -> Loss: 0.162149980664\n",
      "Epoch: 108 -> Test Accuracy: 88.18\n",
      "[109, 60] loss: 0.099\n",
      "[109, 120] loss: 0.110\n",
      "[109, 180] loss: 0.120\n",
      "[109, 240] loss: 0.126\n",
      "[109, 300] loss: 0.121\n",
      "[109, 360] loss: 0.131\n",
      "Epoch: 109 -> Loss: 0.138436213136\n",
      "Epoch: 109 -> Test Accuracy: 88.29\n",
      "[110, 60] loss: 0.106\n",
      "[110, 120] loss: 0.102\n",
      "[110, 180] loss: 0.112\n",
      "[110, 240] loss: 0.108\n",
      "[110, 300] loss: 0.118\n",
      "[110, 360] loss: 0.121\n",
      "Epoch: 110 -> Loss: 0.143770366907\n",
      "Epoch: 110 -> Test Accuracy: 88.23\n",
      "[111, 60] loss: 0.110\n",
      "[111, 120] loss: 0.107\n",
      "[111, 180] loss: 0.112\n",
      "[111, 240] loss: 0.110\n",
      "[111, 300] loss: 0.114\n",
      "[111, 360] loss: 0.129\n",
      "Epoch: 111 -> Loss: 0.0900486707687\n",
      "Epoch: 111 -> Test Accuracy: 88.19\n",
      "[112, 60] loss: 0.109\n",
      "[112, 120] loss: 0.110\n",
      "[112, 180] loss: 0.114\n",
      "[112, 240] loss: 0.139\n",
      "[112, 300] loss: 0.118\n",
      "[112, 360] loss: 0.144\n",
      "Epoch: 112 -> Loss: 0.154474571347\n",
      "Epoch: 112 -> Test Accuracy: 88.19\n",
      "[113, 60] loss: 0.117\n",
      "[113, 120] loss: 0.109\n",
      "[113, 180] loss: 0.108\n",
      "[113, 240] loss: 0.112\n",
      "[113, 300] loss: 0.122\n",
      "[113, 360] loss: 0.144\n",
      "Epoch: 113 -> Loss: 0.0912730693817\n",
      "Epoch: 113 -> Test Accuracy: 88.45\n",
      "[114, 60] loss: 0.110\n",
      "[114, 120] loss: 0.099\n",
      "[114, 180] loss: 0.115\n",
      "[114, 240] loss: 0.118\n",
      "[114, 300] loss: 0.119\n",
      "[114, 360] loss: 0.124\n",
      "Epoch: 114 -> Loss: 0.0848844274879\n",
      "Epoch: 114 -> Test Accuracy: 88.53\n",
      "[115, 60] loss: 0.117\n",
      "[115, 120] loss: 0.120\n",
      "[115, 180] loss: 0.108\n",
      "[115, 240] loss: 0.121\n",
      "[115, 300] loss: 0.129\n",
      "[115, 360] loss: 0.141\n",
      "Epoch: 115 -> Loss: 0.103536307812\n",
      "Epoch: 115 -> Test Accuracy: 88.43\n",
      "[116, 60] loss: 0.105\n",
      "[116, 120] loss: 0.105\n",
      "[116, 180] loss: 0.112\n",
      "[116, 240] loss: 0.122\n",
      "[116, 300] loss: 0.122\n",
      "[116, 360] loss: 0.126\n",
      "Epoch: 116 -> Loss: 0.16309531033\n",
      "Epoch: 116 -> Test Accuracy: 87.61\n",
      "[117, 60] loss: 0.103\n",
      "[117, 120] loss: 0.114\n",
      "[117, 180] loss: 0.112\n",
      "[117, 240] loss: 0.111\n",
      "[117, 300] loss: 0.123\n",
      "[117, 360] loss: 0.138\n",
      "Epoch: 117 -> Loss: 0.0620582923293\n",
      "Epoch: 117 -> Test Accuracy: 88.72\n",
      "[118, 60] loss: 0.103\n",
      "[118, 120] loss: 0.113\n",
      "[118, 180] loss: 0.116\n",
      "[118, 240] loss: 0.108\n",
      "[118, 300] loss: 0.116\n",
      "[118, 360] loss: 0.115\n",
      "Epoch: 118 -> Loss: 0.087500795722\n",
      "Epoch: 118 -> Test Accuracy: 87.27\n",
      "[119, 60] loss: 0.106\n",
      "[119, 120] loss: 0.114\n",
      "[119, 180] loss: 0.126\n",
      "[119, 240] loss: 0.104\n",
      "[119, 300] loss: 0.103\n",
      "[119, 360] loss: 0.122\n",
      "Epoch: 119 -> Loss: 0.0654944702983\n",
      "Epoch: 119 -> Test Accuracy: 88.68\n",
      "[120, 60] loss: 0.111\n",
      "[120, 120] loss: 0.101\n",
      "[120, 180] loss: 0.114\n",
      "[120, 240] loss: 0.118\n",
      "[120, 300] loss: 0.132\n",
      "[120, 360] loss: 0.132\n",
      "Epoch: 120 -> Loss: 0.14968085289\n",
      "Epoch: 120 -> Test Accuracy: 88.67\n",
      "[121, 60] loss: 0.075\n",
      "[121, 120] loss: 0.054\n",
      "[121, 180] loss: 0.051\n",
      "[121, 240] loss: 0.042\n",
      "[121, 300] loss: 0.044\n",
      "[121, 360] loss: 0.042\n",
      "Epoch: 121 -> Loss: 0.0615567862988\n",
      "Epoch: 121 -> Test Accuracy: 91.2\n",
      "[122, 60] loss: 0.031\n",
      "[122, 120] loss: 0.034\n",
      "[122, 180] loss: 0.030\n",
      "[122, 240] loss: 0.029\n",
      "[122, 300] loss: 0.031\n",
      "[122, 360] loss: 0.032\n",
      "Epoch: 122 -> Loss: 0.0204253550619\n",
      "Epoch: 122 -> Test Accuracy: 91.56\n",
      "[123, 60] loss: 0.025\n",
      "[123, 120] loss: 0.026\n",
      "[123, 180] loss: 0.026\n",
      "[123, 240] loss: 0.026\n",
      "[123, 300] loss: 0.025\n",
      "[123, 360] loss: 0.026\n",
      "Epoch: 123 -> Loss: 0.0279893390834\n",
      "Epoch: 123 -> Test Accuracy: 91.57\n",
      "[124, 60] loss: 0.022\n",
      "[124, 120] loss: 0.022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[124, 180] loss: 0.021\n",
      "[124, 240] loss: 0.020\n",
      "[124, 300] loss: 0.020\n",
      "[124, 360] loss: 0.022\n",
      "Epoch: 124 -> Loss: 0.00913160480559\n",
      "Epoch: 124 -> Test Accuracy: 91.3\n",
      "[125, 60] loss: 0.019\n",
      "[125, 120] loss: 0.019\n",
      "[125, 180] loss: 0.019\n",
      "[125, 240] loss: 0.020\n",
      "[125, 300] loss: 0.020\n",
      "[125, 360] loss: 0.021\n",
      "Epoch: 125 -> Loss: 0.0156837590039\n",
      "Epoch: 125 -> Test Accuracy: 91.25\n",
      "[126, 60] loss: 0.020\n",
      "[126, 120] loss: 0.019\n",
      "[126, 180] loss: 0.019\n",
      "[126, 240] loss: 0.018\n",
      "[126, 300] loss: 0.015\n",
      "[126, 360] loss: 0.020\n",
      "Epoch: 126 -> Loss: 0.00777263054624\n",
      "Epoch: 126 -> Test Accuracy: 91.32\n",
      "[127, 60] loss: 0.016\n",
      "[127, 120] loss: 0.017\n",
      "[127, 180] loss: 0.016\n",
      "[127, 240] loss: 0.016\n",
      "[127, 300] loss: 0.018\n",
      "[127, 360] loss: 0.017\n",
      "Epoch: 127 -> Loss: 0.0105040315539\n",
      "Epoch: 127 -> Test Accuracy: 91.21\n",
      "[128, 60] loss: 0.016\n",
      "[128, 120] loss: 0.016\n",
      "[128, 180] loss: 0.016\n",
      "[128, 240] loss: 0.015\n",
      "[128, 300] loss: 0.015\n",
      "[128, 360] loss: 0.015\n",
      "Epoch: 128 -> Loss: 0.0326036699116\n",
      "Epoch: 128 -> Test Accuracy: 91.28\n",
      "[129, 60] loss: 0.016\n",
      "[129, 120] loss: 0.015\n",
      "[129, 180] loss: 0.015\n",
      "[129, 240] loss: 0.015\n",
      "[129, 300] loss: 0.016\n",
      "[129, 360] loss: 0.016\n",
      "Epoch: 129 -> Loss: 0.0272331349552\n",
      "Epoch: 129 -> Test Accuracy: 91.44\n",
      "[130, 60] loss: 0.014\n",
      "[130, 120] loss: 0.014\n",
      "[130, 180] loss: 0.014\n",
      "[130, 240] loss: 0.016\n",
      "[130, 300] loss: 0.015\n",
      "[130, 360] loss: 0.015\n",
      "Epoch: 130 -> Loss: 0.0103903533891\n",
      "Epoch: 130 -> Test Accuracy: 91.29\n",
      "[131, 60] loss: 0.013\n",
      "[131, 120] loss: 0.014\n",
      "[131, 180] loss: 0.014\n",
      "[131, 240] loss: 0.014\n",
      "[131, 300] loss: 0.013\n",
      "[131, 360] loss: 0.015\n",
      "Epoch: 131 -> Loss: 0.0119562689215\n",
      "Epoch: 131 -> Test Accuracy: 91.25\n",
      "[132, 60] loss: 0.013\n",
      "[132, 120] loss: 0.015\n",
      "[132, 180] loss: 0.013\n",
      "[132, 240] loss: 0.014\n",
      "[132, 300] loss: 0.013\n",
      "[132, 360] loss: 0.014\n",
      "Epoch: 132 -> Loss: 0.0209854543209\n",
      "Epoch: 132 -> Test Accuracy: 91.25\n",
      "[133, 60] loss: 0.014\n",
      "[133, 120] loss: 0.013\n",
      "[133, 180] loss: 0.012\n",
      "[133, 240] loss: 0.013\n",
      "[133, 300] loss: 0.012\n",
      "[133, 360] loss: 0.012\n",
      "Epoch: 133 -> Loss: 0.0246900375932\n",
      "Epoch: 133 -> Test Accuracy: 91.32\n",
      "[134, 60] loss: 0.012\n",
      "[134, 120] loss: 0.011\n",
      "[134, 180] loss: 0.013\n",
      "[134, 240] loss: 0.012\n",
      "[134, 300] loss: 0.012\n",
      "[134, 360] loss: 0.014\n",
      "Epoch: 134 -> Loss: 0.014113759622\n",
      "Epoch: 134 -> Test Accuracy: 91.12\n",
      "[135, 60] loss: 0.011\n",
      "[135, 120] loss: 0.010\n",
      "[135, 180] loss: 0.012\n",
      "[135, 240] loss: 0.012\n",
      "[135, 300] loss: 0.011\n",
      "[135, 360] loss: 0.011\n",
      "Epoch: 135 -> Loss: 0.0275889132172\n",
      "Epoch: 135 -> Test Accuracy: 91.17\n",
      "[136, 60] loss: 0.012\n",
      "[136, 120] loss: 0.012\n",
      "[136, 180] loss: 0.010\n",
      "[136, 240] loss: 0.011\n",
      "[136, 300] loss: 0.011\n",
      "[136, 360] loss: 0.011\n",
      "Epoch: 136 -> Loss: 0.0197756737471\n",
      "Epoch: 136 -> Test Accuracy: 91.07\n",
      "[137, 60] loss: 0.011\n",
      "[137, 120] loss: 0.011\n",
      "[137, 180] loss: 0.011\n",
      "[137, 240] loss: 0.011\n",
      "[137, 300] loss: 0.010\n",
      "[137, 360] loss: 0.011\n",
      "Epoch: 137 -> Loss: 0.0155540648848\n",
      "Epoch: 137 -> Test Accuracy: 91.52\n",
      "[138, 60] loss: 0.011\n",
      "[138, 120] loss: 0.011\n",
      "[138, 180] loss: 0.011\n",
      "[138, 240] loss: 0.010\n",
      "[138, 300] loss: 0.011\n",
      "[138, 360] loss: 0.010\n",
      "Epoch: 138 -> Loss: 0.00844640098512\n",
      "Epoch: 138 -> Test Accuracy: 91.52\n",
      "[139, 60] loss: 0.010\n",
      "[139, 120] loss: 0.010\n",
      "[139, 180] loss: 0.011\n",
      "[139, 240] loss: 0.011\n",
      "[139, 300] loss: 0.011\n",
      "[139, 360] loss: 0.010\n",
      "Epoch: 139 -> Loss: 0.0280493143946\n",
      "Epoch: 139 -> Test Accuracy: 91.36\n",
      "[140, 60] loss: 0.011\n",
      "[140, 120] loss: 0.010\n",
      "[140, 180] loss: 0.012\n",
      "[140, 240] loss: 0.011\n",
      "[140, 300] loss: 0.012\n",
      "[140, 360] loss: 0.011\n",
      "Epoch: 140 -> Loss: 0.00766073446721\n",
      "Epoch: 140 -> Test Accuracy: 91.4\n",
      "[141, 60] loss: 0.010\n",
      "[141, 120] loss: 0.010\n",
      "[141, 180] loss: 0.010\n",
      "[141, 240] loss: 0.011\n",
      "[141, 300] loss: 0.011\n",
      "[141, 360] loss: 0.010\n",
      "Epoch: 141 -> Loss: 0.0104625821114\n",
      "Epoch: 141 -> Test Accuracy: 91.31\n",
      "[142, 60] loss: 0.011\n",
      "[142, 120] loss: 0.009\n",
      "[142, 180] loss: 0.010\n",
      "[142, 240] loss: 0.012\n",
      "[142, 300] loss: 0.009\n",
      "[142, 360] loss: 0.011\n",
      "Epoch: 142 -> Loss: 0.00761454086751\n",
      "Epoch: 142 -> Test Accuracy: 91.44\n",
      "[143, 60] loss: 0.010\n",
      "[143, 120] loss: 0.009\n",
      "[143, 180] loss: 0.010\n",
      "[143, 240] loss: 0.010\n",
      "[143, 300] loss: 0.011\n",
      "[143, 360] loss: 0.010\n",
      "Epoch: 143 -> Loss: 0.0193831622601\n",
      "Epoch: 143 -> Test Accuracy: 91.42\n",
      "[144, 60] loss: 0.011\n",
      "[144, 120] loss: 0.010\n",
      "[144, 180] loss: 0.009\n",
      "[144, 240] loss: 0.009\n",
      "[144, 300] loss: 0.010\n",
      "[144, 360] loss: 0.009\n",
      "Epoch: 144 -> Loss: 0.00670862803236\n",
      "Epoch: 144 -> Test Accuracy: 91.32\n",
      "[145, 60] loss: 0.010\n",
      "[145, 120] loss: 0.010\n",
      "[145, 180] loss: 0.009\n",
      "[145, 240] loss: 0.010\n",
      "[145, 300] loss: 0.011\n",
      "[145, 360] loss: 0.011\n",
      "Epoch: 145 -> Loss: 0.0103610632941\n",
      "Epoch: 145 -> Test Accuracy: 91.4\n",
      "[146, 60] loss: 0.010\n",
      "[146, 120] loss: 0.009\n",
      "[146, 180] loss: 0.009\n",
      "[146, 240] loss: 0.010\n",
      "[146, 300] loss: 0.009\n",
      "[146, 360] loss: 0.009\n",
      "Epoch: 146 -> Loss: 0.00978915672749\n",
      "Epoch: 146 -> Test Accuracy: 91.5\n",
      "[147, 60] loss: 0.009\n",
      "[147, 120] loss: 0.010\n",
      "[147, 180] loss: 0.009\n",
      "[147, 240] loss: 0.009\n",
      "[147, 300] loss: 0.010\n",
      "[147, 360] loss: 0.009\n",
      "Epoch: 147 -> Loss: 0.0133479358628\n",
      "Epoch: 147 -> Test Accuracy: 91.39\n",
      "[148, 60] loss: 0.009\n",
      "[148, 120] loss: 0.009\n",
      "[148, 180] loss: 0.009\n",
      "[148, 240] loss: 0.009\n",
      "[148, 300] loss: 0.008\n",
      "[148, 360] loss: 0.009\n",
      "Epoch: 148 -> Loss: 0.0146847125143\n",
      "Epoch: 148 -> Test Accuracy: 91.49\n",
      "[149, 60] loss: 0.008\n",
      "[149, 120] loss: 0.009\n",
      "[149, 180] loss: 0.010\n",
      "[149, 240] loss: 0.009\n",
      "[149, 300] loss: 0.009\n",
      "[149, 360] loss: 0.009\n",
      "Epoch: 149 -> Loss: 0.0182967539877\n",
      "Epoch: 149 -> Test Accuracy: 91.29\n",
      "[150, 60] loss: 0.009\n",
      "[150, 120] loss: 0.009\n",
      "[150, 180] loss: 0.008\n",
      "[150, 240] loss: 0.008\n",
      "[150, 300] loss: 0.009\n",
      "[150, 360] loss: 0.010\n",
      "Epoch: 150 -> Loss: 0.0112588824704\n",
      "Epoch: 150 -> Test Accuracy: 91.47\n",
      "[151, 60] loss: 0.010\n",
      "[151, 120] loss: 0.009\n",
      "[151, 180] loss: 0.009\n",
      "[151, 240] loss: 0.009\n",
      "[151, 300] loss: 0.009\n",
      "[151, 360] loss: 0.009\n",
      "Epoch: 151 -> Loss: 0.00795558094978\n",
      "Epoch: 151 -> Test Accuracy: 91.39\n",
      "[152, 60] loss: 0.009\n",
      "[152, 120] loss: 0.009\n",
      "[152, 180] loss: 0.008\n",
      "[152, 240] loss: 0.008\n",
      "[152, 300] loss: 0.009\n",
      "[152, 360] loss: 0.009\n",
      "Epoch: 152 -> Loss: 0.00826269388199\n",
      "Epoch: 152 -> Test Accuracy: 91.09\n",
      "[153, 60] loss: 0.009\n",
      "[153, 120] loss: 0.010\n",
      "[153, 180] loss: 0.009\n",
      "[153, 240] loss: 0.008\n",
      "[153, 300] loss: 0.009\n",
      "[153, 360] loss: 0.009\n",
      "Epoch: 153 -> Loss: 0.0122916577384\n",
      "Epoch: 153 -> Test Accuracy: 91.09\n",
      "[154, 60] loss: 0.009\n",
      "[154, 120] loss: 0.008\n",
      "[154, 180] loss: 0.008\n",
      "[154, 240] loss: 0.008\n",
      "[154, 300] loss: 0.009\n",
      "[154, 360] loss: 0.009\n",
      "Epoch: 154 -> Loss: 0.0158297717571\n",
      "Epoch: 154 -> Test Accuracy: 91.09\n",
      "[155, 60] loss: 0.008\n",
      "[155, 120] loss: 0.009\n",
      "[155, 180] loss: 0.010\n",
      "[155, 240] loss: 0.009\n",
      "[155, 300] loss: 0.009\n",
      "[155, 360] loss: 0.009\n",
      "Epoch: 155 -> Loss: 0.0062848450616\n",
      "Epoch: 155 -> Test Accuracy: 91.14\n",
      "[156, 60] loss: 0.009\n",
      "[156, 120] loss: 0.008\n",
      "[156, 180] loss: 0.009\n",
      "[156, 240] loss: 0.009\n",
      "[156, 300] loss: 0.009\n",
      "[156, 360] loss: 0.009\n",
      "Epoch: 156 -> Loss: 0.00874519906938\n",
      "Epoch: 156 -> Test Accuracy: 91.34\n",
      "[157, 60] loss: 0.009\n",
      "[157, 120] loss: 0.008\n",
      "[157, 180] loss: 0.009\n",
      "[157, 240] loss: 0.008\n",
      "[157, 300] loss: 0.009\n",
      "[157, 360] loss: 0.008\n",
      "Epoch: 157 -> Loss: 0.0130544928834\n",
      "Epoch: 157 -> Test Accuracy: 91.1\n",
      "[158, 60] loss: 0.008\n",
      "[158, 120] loss: 0.009\n",
      "[158, 180] loss: 0.008\n",
      "[158, 240] loss: 0.009\n",
      "[158, 300] loss: 0.008\n",
      "[158, 360] loss: 0.009\n",
      "Epoch: 158 -> Loss: 0.0168238095939\n",
      "Epoch: 158 -> Test Accuracy: 91.31\n",
      "[159, 60] loss: 0.009\n",
      "[159, 120] loss: 0.008\n",
      "[159, 180] loss: 0.008\n",
      "[159, 240] loss: 0.008\n",
      "[159, 300] loss: 0.008\n",
      "[159, 360] loss: 0.010\n",
      "Epoch: 159 -> Loss: 0.00392565131187\n",
      "Epoch: 159 -> Test Accuracy: 91.2\n",
      "[160, 60] loss: 0.008\n",
      "[160, 120] loss: 0.008\n",
      "[160, 180] loss: 0.008\n",
      "[160, 240] loss: 0.008\n",
      "[160, 300] loss: 0.009\n",
      "[160, 360] loss: 0.008\n",
      "Epoch: 160 -> Loss: 0.00465139141306\n",
      "Epoch: 160 -> Test Accuracy: 91.41\n",
      "[161, 60] loss: 0.007\n",
      "[161, 120] loss: 0.007\n",
      "[161, 180] loss: 0.007\n",
      "[161, 240] loss: 0.008\n",
      "[161, 300] loss: 0.008\n",
      "[161, 360] loss: 0.007\n",
      "Epoch: 161 -> Loss: 0.00661711674184\n",
      "Epoch: 161 -> Test Accuracy: 91.22\n",
      "[162, 60] loss: 0.008\n",
      "[162, 120] loss: 0.007\n",
      "[162, 180] loss: 0.007\n",
      "[162, 240] loss: 0.007\n",
      "[162, 300] loss: 0.007\n",
      "[162, 360] loss: 0.007\n",
      "Epoch: 162 -> Loss: 0.00278571853414\n",
      "Epoch: 162 -> Test Accuracy: 91.34\n",
      "[163, 60] loss: 0.007\n",
      "[163, 120] loss: 0.007\n",
      "[163, 180] loss: 0.007\n",
      "[163, 240] loss: 0.008\n",
      "[163, 300] loss: 0.007\n",
      "[163, 360] loss: 0.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 163 -> Loss: 0.012463092804\n",
      "Epoch: 163 -> Test Accuracy: 91.39\n",
      "[164, 60] loss: 0.006\n",
      "[164, 120] loss: 0.007\n",
      "[164, 180] loss: 0.007\n",
      "[164, 240] loss: 0.006\n",
      "[164, 300] loss: 0.007\n",
      "[164, 360] loss: 0.007\n",
      "Epoch: 164 -> Loss: 0.03215944767\n",
      "Epoch: 164 -> Test Accuracy: 91.28\n",
      "[165, 60] loss: 0.007\n",
      "[165, 120] loss: 0.006\n",
      "[165, 180] loss: 0.007\n",
      "[165, 240] loss: 0.006\n",
      "[165, 300] loss: 0.007\n",
      "[165, 360] loss: 0.007\n",
      "Epoch: 165 -> Loss: 0.0114584919065\n",
      "Epoch: 165 -> Test Accuracy: 91.31\n",
      "[166, 60] loss: 0.007\n",
      "[166, 120] loss: 0.006\n",
      "[166, 180] loss: 0.006\n",
      "[166, 240] loss: 0.007\n",
      "[166, 300] loss: 0.007\n",
      "[166, 360] loss: 0.007\n",
      "Epoch: 166 -> Loss: 0.00599935650826\n",
      "Epoch: 166 -> Test Accuracy: 91.39\n",
      "[167, 60] loss: 0.007\n",
      "[167, 120] loss: 0.006\n",
      "[167, 180] loss: 0.007\n",
      "[167, 240] loss: 0.006\n",
      "[167, 300] loss: 0.006\n",
      "[167, 360] loss: 0.007\n",
      "Epoch: 167 -> Loss: 0.00732953567058\n",
      "Epoch: 167 -> Test Accuracy: 91.35\n",
      "[168, 60] loss: 0.006\n",
      "[168, 120] loss: 0.007\n",
      "[168, 180] loss: 0.006\n",
      "[168, 240] loss: 0.006\n",
      "[168, 300] loss: 0.006\n",
      "[168, 360] loss: 0.007\n",
      "Epoch: 168 -> Loss: 0.0101614054292\n",
      "Epoch: 168 -> Test Accuracy: 91.38\n",
      "[169, 60] loss: 0.007\n",
      "[169, 120] loss: 0.006\n",
      "[169, 180] loss: 0.006\n",
      "[169, 240] loss: 0.006\n",
      "[169, 300] loss: 0.007\n",
      "[169, 360] loss: 0.007\n",
      "Epoch: 169 -> Loss: 0.0114369038492\n",
      "Epoch: 169 -> Test Accuracy: 91.44\n",
      "[170, 60] loss: 0.007\n",
      "[170, 120] loss: 0.007\n",
      "[170, 180] loss: 0.007\n",
      "[170, 240] loss: 0.007\n",
      "[170, 300] loss: 0.007\n",
      "[170, 360] loss: 0.007\n",
      "Epoch: 170 -> Loss: 0.0217247419059\n",
      "Epoch: 170 -> Test Accuracy: 91.27\n",
      "[171, 60] loss: 0.007\n",
      "[171, 120] loss: 0.006\n",
      "[171, 180] loss: 0.006\n",
      "[171, 240] loss: 0.007\n",
      "[171, 300] loss: 0.007\n",
      "[171, 360] loss: 0.007\n",
      "Epoch: 171 -> Loss: 0.00443744659424\n",
      "Epoch: 171 -> Test Accuracy: 91.35\n",
      "[172, 60] loss: 0.006\n",
      "[172, 120] loss: 0.007\n",
      "[172, 180] loss: 0.006\n",
      "[172, 240] loss: 0.007\n",
      "[172, 300] loss: 0.006\n",
      "[172, 360] loss: 0.006\n",
      "Epoch: 172 -> Loss: 0.0275138020515\n",
      "Epoch: 172 -> Test Accuracy: 91.45\n",
      "[173, 60] loss: 0.006\n",
      "[173, 120] loss: 0.007\n",
      "[173, 180] loss: 0.006\n",
      "[173, 240] loss: 0.006\n",
      "[173, 300] loss: 0.006\n",
      "[173, 360] loss: 0.006\n",
      "Epoch: 173 -> Loss: 0.00900883041322\n",
      "Epoch: 173 -> Test Accuracy: 91.31\n",
      "[174, 60] loss: 0.006\n",
      "[174, 120] loss: 0.007\n",
      "[174, 180] loss: 0.006\n",
      "[174, 240] loss: 0.006\n",
      "[174, 300] loss: 0.007\n",
      "[174, 360] loss: 0.007\n",
      "Epoch: 174 -> Loss: 0.00365487346426\n",
      "Epoch: 174 -> Test Accuracy: 91.32\n",
      "[175, 60] loss: 0.006\n",
      "[175, 120] loss: 0.006\n",
      "[175, 180] loss: 0.006\n",
      "[175, 240] loss: 0.007\n",
      "[175, 300] loss: 0.006\n",
      "[175, 360] loss: 0.006\n",
      "Epoch: 175 -> Loss: 0.00441812258214\n",
      "Epoch: 175 -> Test Accuracy: 91.28\n",
      "[176, 60] loss: 0.006\n",
      "[176, 120] loss: 0.007\n",
      "[176, 180] loss: 0.006\n",
      "[176, 240] loss: 0.006\n",
      "[176, 300] loss: 0.006\n",
      "[176, 360] loss: 0.006\n",
      "Epoch: 176 -> Loss: 0.00915683526546\n",
      "Epoch: 176 -> Test Accuracy: 91.42\n",
      "[177, 60] loss: 0.007\n",
      "[177, 120] loss: 0.007\n",
      "[177, 180] loss: 0.006\n",
      "[177, 240] loss: 0.006\n",
      "[177, 300] loss: 0.007\n",
      "[177, 360] loss: 0.007\n",
      "Epoch: 177 -> Loss: 0.00952087063342\n",
      "Epoch: 177 -> Test Accuracy: 91.3\n",
      "[178, 60] loss: 0.007\n",
      "[178, 120] loss: 0.006\n",
      "[178, 180] loss: 0.006\n",
      "[178, 240] loss: 0.007\n",
      "[178, 300] loss: 0.007\n",
      "[178, 360] loss: 0.007\n",
      "Epoch: 178 -> Loss: 0.00619597453624\n",
      "Epoch: 178 -> Test Accuracy: 91.36\n",
      "[179, 60] loss: 0.006\n",
      "[179, 120] loss: 0.006\n",
      "[179, 180] loss: 0.006\n",
      "[179, 240] loss: 0.007\n",
      "[179, 300] loss: 0.007\n",
      "[179, 360] loss: 0.007\n",
      "Epoch: 179 -> Loss: 0.0256325509399\n",
      "Epoch: 179 -> Test Accuracy: 91.39\n",
      "[180, 60] loss: 0.007\n",
      "[180, 120] loss: 0.006\n",
      "[180, 180] loss: 0.007\n",
      "[180, 240] loss: 0.007\n",
      "[180, 300] loss: 0.006\n",
      "[180, 360] loss: 0.007\n",
      "Epoch: 180 -> Loss: 0.015832144767\n",
      "Epoch: 180 -> Test Accuracy: 91.37\n",
      "[181, 60] loss: 0.006\n",
      "[181, 120] loss: 0.007\n",
      "[181, 180] loss: 0.006\n",
      "[181, 240] loss: 0.007\n",
      "[181, 300] loss: 0.006\n",
      "[181, 360] loss: 0.006\n",
      "Epoch: 181 -> Loss: 0.00802031159401\n",
      "Epoch: 181 -> Test Accuracy: 91.45\n",
      "[182, 60] loss: 0.006\n",
      "[182, 120] loss: 0.006\n",
      "[182, 180] loss: 0.007\n",
      "[182, 240] loss: 0.007\n",
      "[182, 300] loss: 0.007\n",
      "[182, 360] loss: 0.006\n",
      "Epoch: 182 -> Loss: 0.00346255302429\n",
      "Epoch: 182 -> Test Accuracy: 91.33\n",
      "[183, 60] loss: 0.007\n",
      "[183, 120] loss: 0.006\n",
      "[183, 180] loss: 0.007\n",
      "[183, 240] loss: 0.006\n",
      "[183, 300] loss: 0.007\n",
      "[183, 360] loss: 0.007\n",
      "Epoch: 183 -> Loss: 0.00269183516502\n",
      "Epoch: 183 -> Test Accuracy: 91.29\n",
      "[184, 60] loss: 0.006\n",
      "[184, 120] loss: 0.007\n",
      "[184, 180] loss: 0.007\n",
      "[184, 240] loss: 0.006\n",
      "[184, 300] loss: 0.006\n",
      "[184, 360] loss: 0.007\n",
      "Epoch: 184 -> Loss: 0.00428304076195\n",
      "Epoch: 184 -> Test Accuracy: 91.36\n",
      "[185, 60] loss: 0.006\n",
      "[185, 120] loss: 0.006\n",
      "[185, 180] loss: 0.006\n",
      "[185, 240] loss: 0.005\n",
      "[185, 300] loss: 0.007\n",
      "[185, 360] loss: 0.006\n",
      "Epoch: 185 -> Loss: 0.0199624300003\n",
      "Epoch: 185 -> Test Accuracy: 91.39\n",
      "[186, 60] loss: 0.006\n",
      "[186, 120] loss: 0.007\n",
      "[186, 180] loss: 0.006\n",
      "[186, 240] loss: 0.007\n",
      "[186, 300] loss: 0.006\n",
      "[186, 360] loss: 0.007\n",
      "Epoch: 186 -> Loss: 0.00353973498568\n",
      "Epoch: 186 -> Test Accuracy: 91.43\n",
      "[187, 60] loss: 0.006\n",
      "[187, 120] loss: 0.007\n",
      "[187, 180] loss: 0.007\n",
      "[187, 240] loss: 0.006\n",
      "[187, 300] loss: 0.006\n",
      "[187, 360] loss: 0.006\n",
      "Epoch: 187 -> Loss: 0.00540779810399\n",
      "Epoch: 187 -> Test Accuracy: 91.32\n",
      "[188, 60] loss: 0.006\n",
      "[188, 120] loss: 0.006\n",
      "[188, 180] loss: 0.006\n",
      "[188, 240] loss: 0.007\n",
      "[188, 300] loss: 0.006\n",
      "[188, 360] loss: 0.006\n",
      "Epoch: 188 -> Loss: 0.0149178653955\n",
      "Epoch: 188 -> Test Accuracy: 91.22\n",
      "[189, 60] loss: 0.007\n",
      "[189, 120] loss: 0.006\n",
      "[189, 180] loss: 0.006\n",
      "[189, 240] loss: 0.006\n",
      "[189, 300] loss: 0.007\n",
      "[189, 360] loss: 0.006\n",
      "Epoch: 189 -> Loss: 0.00651356577873\n",
      "Epoch: 189 -> Test Accuracy: 91.27\n",
      "[190, 60] loss: 0.006\n",
      "[190, 120] loss: 0.007\n",
      "[190, 180] loss: 0.006\n",
      "[190, 240] loss: 0.006\n",
      "[190, 300] loss: 0.006\n",
      "[190, 360] loss: 0.007\n",
      "Epoch: 190 -> Loss: 0.00353185529821\n",
      "Epoch: 190 -> Test Accuracy: 91.45\n",
      "[191, 60] loss: 0.006\n",
      "[191, 120] loss: 0.006\n",
      "[191, 180] loss: 0.006\n",
      "[191, 240] loss: 0.006\n",
      "[191, 300] loss: 0.006\n",
      "[191, 360] loss: 0.006\n",
      "Epoch: 191 -> Loss: 0.00702169537544\n",
      "Epoch: 191 -> Test Accuracy: 91.41\n",
      "[192, 60] loss: 0.006\n",
      "[192, 120] loss: 0.006\n",
      "[192, 180] loss: 0.006\n",
      "[192, 240] loss: 0.007\n",
      "[192, 300] loss: 0.006\n",
      "[192, 360] loss: 0.006\n",
      "Epoch: 192 -> Loss: 0.00991275347769\n",
      "Epoch: 192 -> Test Accuracy: 91.21\n",
      "[193, 60] loss: 0.006\n",
      "[193, 120] loss: 0.006\n",
      "[193, 180] loss: 0.007\n",
      "[193, 240] loss: 0.006\n",
      "[193, 300] loss: 0.006\n",
      "[193, 360] loss: 0.006\n",
      "Epoch: 193 -> Loss: 0.00395756959915\n",
      "Epoch: 193 -> Test Accuracy: 91.26\n",
      "[194, 60] loss: 0.006\n",
      "[194, 120] loss: 0.006\n",
      "[194, 180] loss: 0.005\n",
      "[194, 240] loss: 0.007\n",
      "[194, 300] loss: 0.006\n",
      "[194, 360] loss: 0.006\n",
      "Epoch: 194 -> Loss: 0.00577930826694\n",
      "Epoch: 194 -> Test Accuracy: 91.35\n",
      "[195, 60] loss: 0.006\n",
      "[195, 120] loss: 0.006\n",
      "[195, 180] loss: 0.006\n",
      "[195, 240] loss: 0.007\n",
      "[195, 300] loss: 0.006\n",
      "[195, 360] loss: 0.007\n",
      "Epoch: 195 -> Loss: 0.00489818444476\n",
      "Epoch: 195 -> Test Accuracy: 91.38\n",
      "[196, 60] loss: 0.006\n",
      "[196, 120] loss: 0.006\n",
      "[196, 180] loss: 0.006\n",
      "[196, 240] loss: 0.006\n",
      "[196, 300] loss: 0.006\n",
      "[196, 360] loss: 0.006\n",
      "Epoch: 196 -> Loss: 0.0073150456883\n",
      "Epoch: 196 -> Test Accuracy: 91.33\n",
      "[197, 60] loss: 0.006\n",
      "[197, 120] loss: 0.007\n",
      "[197, 180] loss: 0.006\n",
      "[197, 240] loss: 0.006\n",
      "[197, 300] loss: 0.006\n",
      "[197, 360] loss: 0.006\n",
      "Epoch: 197 -> Loss: 0.017292862758\n",
      "Epoch: 197 -> Test Accuracy: 91.25\n",
      "[198, 60] loss: 0.006\n",
      "[198, 120] loss: 0.006\n",
      "[198, 180] loss: 0.006\n",
      "[198, 240] loss: 0.006\n",
      "[198, 300] loss: 0.006\n",
      "[198, 360] loss: 0.007\n",
      "Epoch: 198 -> Loss: 0.00433322181925\n",
      "Epoch: 198 -> Test Accuracy: 91.31\n",
      "[199, 60] loss: 0.006\n",
      "[199, 120] loss: 0.006\n",
      "[199, 180] loss: 0.006\n",
      "[199, 240] loss: 0.006\n",
      "[199, 300] loss: 0.006\n",
      "[199, 360] loss: 0.006\n",
      "Epoch: 199 -> Loss: 0.00762056699023\n",
      "Epoch: 199 -> Test Accuracy: 91.29\n",
      "[200, 60] loss: 0.006\n",
      "[200, 120] loss: 0.006\n",
      "[200, 180] loss: 0.007\n",
      "[200, 240] loss: 0.006\n",
      "[200, 300] loss: 0.006\n",
      "[200, 360] loss: 0.007\n",
      "Epoch: 200 -> Loss: 0.0176921673119\n",
      "Epoch: 200 -> Test Accuracy: 91.39\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train 3 block RotNet on classification task\n",
    "class_NIN_loss_log, _, class_NIN_test_accuracy_log, _, _ = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], \n",
    "    [60, 120, 160, 200], 0.9, 5e-4, net_class, criterion, trainloader, None, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save variables\n",
    "fm.save_variable([class_NIN_loss_log, class_NIN_test_accuracy_log], \"supervised_NIN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize networks\n",
    "semi_net = fm.load_net(\"RotNet_rotation_200_4_block_net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 -> Loss: 2.1992418766\n",
      "Epoch: 1 -> Test Accuracy: 40.72\n",
      "Epoch: 2 -> Loss: 1.25360822678\n",
      "Epoch: 2 -> Test Accuracy: 50.21\n",
      "Epoch: 3 -> Loss: 0.949498295784\n",
      "Epoch: 3 -> Test Accuracy: 53.53\n",
      "Epoch: 4 -> Loss: 0.62757062912\n",
      "Epoch: 4 -> Test Accuracy: 55.36\n",
      "Epoch: 5 -> Loss: 0.481527328491\n",
      "Epoch: 5 -> Test Accuracy: 57.63\n",
      "Epoch: 6 -> Loss: 0.460844159126\n",
      "Epoch: 6 -> Test Accuracy: 58.93\n",
      "Epoch: 7 -> Loss: 0.318598896265\n",
      "Epoch: 7 -> Test Accuracy: 60.19\n",
      "Epoch: 8 -> Loss: 0.213707759976\n",
      "Epoch: 8 -> Test Accuracy: 60.57\n",
      "Epoch: 9 -> Loss: 0.180244058371\n",
      "Epoch: 9 -> Test Accuracy: 60.78\n",
      "Epoch: 10 -> Loss: 0.0976581647992\n",
      "Epoch: 10 -> Test Accuracy: 60.77\n",
      "Epoch: 11 -> Loss: 0.118126921356\n",
      "Epoch: 11 -> Test Accuracy: 60.87\n",
      "Epoch: 12 -> Loss: 0.0888189077377\n",
      "Epoch: 12 -> Test Accuracy: 61.2\n",
      "Epoch: 13 -> Loss: 0.0779830217361\n",
      "Epoch: 13 -> Test Accuracy: 61.22\n",
      "Epoch: 14 -> Loss: 0.0497829467058\n",
      "Epoch: 14 -> Test Accuracy: 61.35\n",
      "Epoch: 15 -> Loss: 0.0414481908083\n",
      "Epoch: 15 -> Test Accuracy: 61.12\n",
      "Epoch: 16 -> Loss: 0.0410651043057\n",
      "Epoch: 16 -> Test Accuracy: 61.45\n",
      "Epoch: 17 -> Loss: 0.0220119692385\n",
      "Epoch: 17 -> Test Accuracy: 61.36\n",
      "Epoch: 18 -> Loss: 0.0256252028048\n",
      "Epoch: 18 -> Test Accuracy: 61.26\n",
      "Epoch: 19 -> Loss: 0.0355320125818\n",
      "Epoch: 19 -> Test Accuracy: 61.02\n",
      "Epoch: 20 -> Loss: 0.0246333610266\n",
      "Epoch: 20 -> Test Accuracy: 60.86\n",
      "Epoch: 21 -> Loss: 0.0228027570993\n",
      "Epoch: 21 -> Test Accuracy: 60.97\n",
      "Epoch: 22 -> Loss: 0.0124514503404\n",
      "Epoch: 22 -> Test Accuracy: 60.99\n",
      "Epoch: 23 -> Loss: 0.0303650703281\n",
      "Epoch: 23 -> Test Accuracy: 61.03\n",
      "Epoch: 24 -> Loss: 0.0232528783381\n",
      "Epoch: 24 -> Test Accuracy: 61.12\n",
      "Epoch: 25 -> Loss: 0.02858710289\n",
      "Epoch: 25 -> Test Accuracy: 61.06\n",
      "Epoch: 26 -> Loss: 0.0101954936981\n",
      "Epoch: 26 -> Test Accuracy: 61.16\n",
      "Epoch: 27 -> Loss: 0.0166025683284\n",
      "Epoch: 27 -> Test Accuracy: 61.1\n",
      "Epoch: 28 -> Loss: 0.0267471540719\n",
      "Epoch: 28 -> Test Accuracy: 61.12\n",
      "Epoch: 29 -> Loss: 0.011169956997\n",
      "Epoch: 29 -> Test Accuracy: 61.32\n",
      "Epoch: 30 -> Loss: 0.0139168761671\n",
      "Epoch: 30 -> Test Accuracy: 61.57\n",
      "Epoch: 31 -> Loss: 0.00866344198585\n",
      "Epoch: 31 -> Test Accuracy: 61.69\n",
      "Epoch: 32 -> Loss: 0.00785085186362\n",
      "Epoch: 32 -> Test Accuracy: 61.68\n",
      "Epoch: 33 -> Loss: 0.0114568276331\n",
      "Epoch: 33 -> Test Accuracy: 61.78\n",
      "Epoch: 34 -> Loss: 0.00751512590796\n",
      "Epoch: 34 -> Test Accuracy: 61.84\n",
      "Epoch: 35 -> Loss: 0.0111706918105\n",
      "Epoch: 35 -> Test Accuracy: 61.9\n",
      "Epoch: 36 -> Loss: 0.0084424354136\n",
      "Epoch: 36 -> Test Accuracy: 61.91\n",
      "Epoch: 37 -> Loss: 0.00888669490814\n",
      "Epoch: 37 -> Test Accuracy: 61.93\n",
      "Epoch: 38 -> Loss: 0.00565805705264\n",
      "Epoch: 38 -> Test Accuracy: 61.92\n",
      "Epoch: 39 -> Loss: 0.0273974668235\n",
      "Epoch: 39 -> Test Accuracy: 61.96\n",
      "Epoch: 40 -> Loss: 0.0105382138863\n",
      "Epoch: 40 -> Test Accuracy: 61.98\n",
      "Epoch: 41 -> Loss: 0.00930751673877\n",
      "Epoch: 41 -> Test Accuracy: 61.99\n",
      "Epoch: 42 -> Loss: 0.00797546561807\n",
      "Epoch: 42 -> Test Accuracy: 61.96\n",
      "Epoch: 43 -> Loss: 0.00775059079751\n",
      "Epoch: 43 -> Test Accuracy: 61.94\n",
      "Epoch: 44 -> Loss: 0.00939406268299\n",
      "Epoch: 44 -> Test Accuracy: 61.96\n",
      "Epoch: 45 -> Loss: 0.00706287892535\n",
      "Epoch: 45 -> Test Accuracy: 61.92\n",
      "Epoch: 46 -> Loss: 0.00592125114053\n",
      "Epoch: 46 -> Test Accuracy: 61.91\n",
      "Epoch: 47 -> Loss: 0.0115663474426\n",
      "Epoch: 47 -> Test Accuracy: 61.95\n",
      "Epoch: 48 -> Loss: 0.008948802948\n",
      "Epoch: 48 -> Test Accuracy: 61.92\n",
      "Epoch: 49 -> Loss: 0.00881134159863\n",
      "Epoch: 49 -> Test Accuracy: 61.88\n",
      "Epoch: 50 -> Loss: 0.00637343851849\n",
      "Epoch: 50 -> Test Accuracy: 61.89\n",
      "Epoch: 51 -> Loss: 0.00838818773627\n",
      "Epoch: 51 -> Test Accuracy: 61.87\n",
      "Epoch: 52 -> Loss: 0.0108570856974\n",
      "Epoch: 52 -> Test Accuracy: 61.84\n",
      "Epoch: 53 -> Loss: 0.00826783291996\n",
      "Epoch: 53 -> Test Accuracy: 61.83\n",
      "Epoch: 54 -> Loss: 0.00623401021585\n",
      "Epoch: 54 -> Test Accuracy: 61.88\n",
      "Epoch: 55 -> Loss: 0.00759538030252\n",
      "Epoch: 55 -> Test Accuracy: 61.91\n",
      "Epoch: 56 -> Loss: 0.00704165967181\n",
      "Epoch: 56 -> Test Accuracy: 61.91\n",
      "Epoch: 57 -> Loss: 0.0049074026756\n",
      "Epoch: 57 -> Test Accuracy: 61.93\n",
      "Epoch: 58 -> Loss: 0.00934123340994\n",
      "Epoch: 58 -> Test Accuracy: 61.92\n",
      "Epoch: 59 -> Loss: 0.00784795824438\n",
      "Epoch: 59 -> Test Accuracy: 61.88\n",
      "Epoch: 60 -> Loss: 0.00648692576215\n",
      "Epoch: 60 -> Test Accuracy: 61.87\n",
      "Epoch: 61 -> Loss: 0.00670198583975\n",
      "Epoch: 61 -> Test Accuracy: 61.83\n",
      "Epoch: 62 -> Loss: 0.00724553409964\n",
      "Epoch: 62 -> Test Accuracy: 61.76\n",
      "Epoch: 63 -> Loss: 0.00931278243661\n",
      "Epoch: 63 -> Test Accuracy: 61.75\n",
      "Epoch: 64 -> Loss: 0.00597092183307\n",
      "Epoch: 64 -> Test Accuracy: 61.72\n",
      "Epoch: 65 -> Loss: 0.00823919661343\n",
      "Epoch: 65 -> Test Accuracy: 61.69\n",
      "Epoch: 66 -> Loss: 0.00900183152407\n",
      "Epoch: 66 -> Test Accuracy: 61.7\n",
      "Epoch: 67 -> Loss: 0.00894965045154\n",
      "Epoch: 67 -> Test Accuracy: 61.71\n",
      "Epoch: 68 -> Loss: 0.00865663401783\n",
      "Epoch: 68 -> Test Accuracy: 61.73\n",
      "Epoch: 69 -> Loss: 0.00604829518124\n",
      "Epoch: 69 -> Test Accuracy: 61.73\n",
      "Epoch: 70 -> Loss: 0.00578663079068\n",
      "Epoch: 70 -> Test Accuracy: 61.74\n",
      "Epoch: 71 -> Loss: 0.00689665460959\n",
      "Epoch: 71 -> Test Accuracy: 61.73\n",
      "Epoch: 72 -> Loss: 0.00890737771988\n",
      "Epoch: 72 -> Test Accuracy: 61.72\n",
      "Epoch: 73 -> Loss: 0.00419269688427\n",
      "Epoch: 73 -> Test Accuracy: 61.7\n",
      "Epoch: 74 -> Loss: 0.0118338866159\n",
      "Epoch: 74 -> Test Accuracy: 61.7\n",
      "Epoch: 75 -> Loss: 0.0063406759873\n",
      "Epoch: 75 -> Test Accuracy: 61.7\n",
      "Epoch: 76 -> Loss: 0.00797849241644\n",
      "Epoch: 76 -> Test Accuracy: 61.71\n",
      "Epoch: 77 -> Loss: 0.00517002074048\n",
      "Epoch: 77 -> Test Accuracy: 61.71\n",
      "Epoch: 78 -> Loss: 0.00531083997339\n",
      "Epoch: 78 -> Test Accuracy: 61.7\n",
      "Epoch: 79 -> Loss: 0.00848156865686\n",
      "Epoch: 79 -> Test Accuracy: 61.68\n",
      "Epoch: 80 -> Loss: 0.00886460766196\n",
      "Epoch: 80 -> Test Accuracy: 61.69\n",
      "Epoch: 81 -> Loss: 0.00818217452615\n",
      "Epoch: 81 -> Test Accuracy: 61.68\n",
      "Epoch: 82 -> Loss: 0.00530713796616\n",
      "Epoch: 82 -> Test Accuracy: 61.7\n",
      "Epoch: 83 -> Loss: 0.00822689104825\n",
      "Epoch: 83 -> Test Accuracy: 61.68\n",
      "Epoch: 84 -> Loss: 0.0052377381362\n",
      "Epoch: 84 -> Test Accuracy: 61.69\n",
      "Epoch: 85 -> Loss: 0.00691503938287\n",
      "Epoch: 85 -> Test Accuracy: 61.68\n",
      "Epoch: 86 -> Loss: 0.00689099915326\n",
      "Epoch: 86 -> Test Accuracy: 61.68\n",
      "Epoch: 87 -> Loss: 0.00898767821491\n",
      "Epoch: 87 -> Test Accuracy: 61.68\n",
      "Epoch: 88 -> Loss: 0.0106632905081\n",
      "Epoch: 88 -> Test Accuracy: 61.68\n",
      "Epoch: 89 -> Loss: 0.00730260880664\n",
      "Epoch: 89 -> Test Accuracy: 61.68\n",
      "Epoch: 90 -> Loss: 0.00439033238217\n",
      "Epoch: 90 -> Test Accuracy: 61.67\n",
      "Epoch: 91 -> Loss: 0.00779146607965\n",
      "Epoch: 91 -> Test Accuracy: 61.67\n",
      "Epoch: 92 -> Loss: 0.00980709027499\n",
      "Epoch: 92 -> Test Accuracy: 61.67\n",
      "Epoch: 93 -> Loss: 0.00889190658927\n",
      "Epoch: 93 -> Test Accuracy: 61.67\n",
      "Epoch: 94 -> Loss: 0.00830175448209\n",
      "Epoch: 94 -> Test Accuracy: 61.68\n",
      "Epoch: 95 -> Loss: 0.0061966907233\n",
      "Epoch: 95 -> Test Accuracy: 61.68\n",
      "Epoch: 96 -> Loss: 0.00608649523929\n",
      "Epoch: 96 -> Test Accuracy: 61.68\n",
      "Epoch: 97 -> Loss: 0.00505287759006\n",
      "Epoch: 97 -> Test Accuracy: 61.68\n",
      "Epoch: 98 -> Loss: 0.0056461491622\n",
      "Epoch: 98 -> Test Accuracy: 61.68\n",
      "Epoch: 99 -> Loss: 0.0104322768748\n",
      "Epoch: 99 -> Test Accuracy: 61.67\n",
      "Epoch: 100 -> Loss: 0.00568590546027\n",
      "Epoch: 100 -> Test Accuracy: 61.67\n",
      "Finished Training\n",
      "Epoch: 1 -> Loss: 2.27249789238\n",
      "Epoch: 1 -> Test Accuracy: 19.26\n",
      "Epoch: 2 -> Loss: 2.18658161163\n",
      "Epoch: 2 -> Test Accuracy: 23.44\n",
      "Epoch: 3 -> Loss: 2.06780290604\n",
      "Epoch: 3 -> Test Accuracy: 21.21\n",
      "Epoch: 4 -> Loss: 2.06581830978\n",
      "Epoch: 4 -> Test Accuracy: 25.2\n",
      "Epoch: 5 -> Loss: 1.891954422\n",
      "Epoch: 5 -> Test Accuracy: 24.13\n",
      "Epoch: 6 -> Loss: 1.89315712452\n",
      "Epoch: 6 -> Test Accuracy: 23.0\n",
      "Epoch: 7 -> Loss: 1.79598939419\n",
      "Epoch: 7 -> Test Accuracy: 26.42\n",
      "Epoch: 8 -> Loss: 1.65708971024\n",
      "Epoch: 8 -> Test Accuracy: 25.31\n",
      "Epoch: 9 -> Loss: 1.54993009567\n",
      "Epoch: 9 -> Test Accuracy: 27.61\n",
      "Epoch: 10 -> Loss: 1.46957743168\n",
      "Epoch: 10 -> Test Accuracy: 28.08\n",
      "Epoch: 11 -> Loss: 1.7039129734\n",
      "Epoch: 11 -> Test Accuracy: 24.01\n",
      "Epoch: 12 -> Loss: 1.60443139076\n",
      "Epoch: 12 -> Test Accuracy: 28.61\n",
      "Epoch: 13 -> Loss: 1.32916712761\n",
      "Epoch: 13 -> Test Accuracy: 30.13\n",
      "Epoch: 14 -> Loss: 1.28267550468\n",
      "Epoch: 14 -> Test Accuracy: 23.41\n",
      "Epoch: 15 -> Loss: 1.22062540054\n",
      "Epoch: 15 -> Test Accuracy: 28.86\n",
      "Epoch: 16 -> Loss: 1.14039182663\n",
      "Epoch: 16 -> Test Accuracy: 29.98\n",
      "Epoch: 17 -> Loss: 1.02063429356\n",
      "Epoch: 17 -> Test Accuracy: 32.34\n",
      "Epoch: 18 -> Loss: 0.945815742016\n",
      "Epoch: 18 -> Test Accuracy: 29.92\n",
      "Epoch: 19 -> Loss: 0.811134159565\n",
      "Epoch: 19 -> Test Accuracy: 29.48\n",
      "Epoch: 20 -> Loss: 0.874511837959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 -> Test Accuracy: 28.75\n",
      "Epoch: 21 -> Loss: 0.948741614819\n",
      "Epoch: 21 -> Test Accuracy: 29.45\n",
      "Epoch: 22 -> Loss: 0.931711852551\n",
      "Epoch: 22 -> Test Accuracy: 30.44\n",
      "Epoch: 23 -> Loss: 0.869188129902\n",
      "Epoch: 23 -> Test Accuracy: 30.7\n",
      "Epoch: 24 -> Loss: 0.583420753479\n",
      "Epoch: 24 -> Test Accuracy: 31.01\n",
      "Epoch: 25 -> Loss: 0.650334239006\n",
      "Epoch: 25 -> Test Accuracy: 31.08\n",
      "Epoch: 26 -> Loss: 0.495277136564\n",
      "Epoch: 26 -> Test Accuracy: 29.84\n",
      "Epoch: 27 -> Loss: 0.530931055546\n",
      "Epoch: 27 -> Test Accuracy: 30.49\n",
      "Epoch: 28 -> Loss: 0.479001671076\n",
      "Epoch: 28 -> Test Accuracy: 30.51\n",
      "Epoch: 29 -> Loss: 0.338510364294\n",
      "Epoch: 29 -> Test Accuracy: 31.03\n",
      "Epoch: 30 -> Loss: 0.475204825401\n",
      "Epoch: 30 -> Test Accuracy: 33.27\n",
      "Epoch: 31 -> Loss: 0.409424722195\n",
      "Epoch: 31 -> Test Accuracy: 30.28\n",
      "Epoch: 32 -> Loss: 0.349939644337\n",
      "Epoch: 32 -> Test Accuracy: 31.13\n",
      "Epoch: 33 -> Loss: 0.40071734786\n",
      "Epoch: 33 -> Test Accuracy: 28.65\n",
      "Epoch: 34 -> Loss: 0.376473635435\n",
      "Epoch: 34 -> Test Accuracy: 31.01\n",
      "Epoch: 35 -> Loss: 0.332409530878\n",
      "Epoch: 35 -> Test Accuracy: 28.51\n",
      "Epoch: 36 -> Loss: 0.258910059929\n",
      "Epoch: 36 -> Test Accuracy: 31.92\n",
      "Epoch: 37 -> Loss: 0.365677177906\n",
      "Epoch: 37 -> Test Accuracy: 30.69\n",
      "Epoch: 38 -> Loss: 0.272037029266\n",
      "Epoch: 38 -> Test Accuracy: 30.4\n",
      "Epoch: 39 -> Loss: 0.246913775802\n",
      "Epoch: 39 -> Test Accuracy: 32.2\n",
      "Epoch: 40 -> Loss: 0.297453731298\n",
      "Epoch: 40 -> Test Accuracy: 31.22\n",
      "Epoch: 41 -> Loss: 0.330309540033\n",
      "Epoch: 41 -> Test Accuracy: 32.05\n",
      "Epoch: 42 -> Loss: 0.239035233855\n",
      "Epoch: 42 -> Test Accuracy: 32.82\n",
      "Epoch: 43 -> Loss: 0.186815321445\n",
      "Epoch: 43 -> Test Accuracy: 31.91\n",
      "Epoch: 44 -> Loss: 0.129873305559\n",
      "Epoch: 44 -> Test Accuracy: 32.7\n",
      "Epoch: 45 -> Loss: 0.0910927504301\n",
      "Epoch: 45 -> Test Accuracy: 32.49\n",
      "Epoch: 46 -> Loss: 0.0975508764386\n",
      "Epoch: 46 -> Test Accuracy: 32.25\n",
      "Epoch: 47 -> Loss: 0.0866598263383\n",
      "Epoch: 47 -> Test Accuracy: 32.31\n",
      "Epoch: 48 -> Loss: 0.152510508895\n",
      "Epoch: 48 -> Test Accuracy: 31.89\n",
      "Epoch: 49 -> Loss: 0.209157019854\n",
      "Epoch: 49 -> Test Accuracy: 32.95\n",
      "Epoch: 50 -> Loss: 0.132039040327\n",
      "Epoch: 50 -> Test Accuracy: 32.91\n",
      "Epoch: 51 -> Loss: 0.0572256371379\n",
      "Epoch: 51 -> Test Accuracy: 32.78\n",
      "Epoch: 52 -> Loss: 0.110983975232\n",
      "Epoch: 52 -> Test Accuracy: 32.29\n",
      "Epoch: 53 -> Loss: 0.108816586435\n",
      "Epoch: 53 -> Test Accuracy: 31.43\n",
      "Epoch: 54 -> Loss: 0.176247417927\n",
      "Epoch: 54 -> Test Accuracy: 30.63\n",
      "Epoch: 55 -> Loss: 0.0959919244051\n",
      "Epoch: 55 -> Test Accuracy: 30.63\n",
      "Epoch: 56 -> Loss: 0.140414506197\n",
      "Epoch: 56 -> Test Accuracy: 30.35\n",
      "Epoch: 57 -> Loss: 0.132772386074\n",
      "Epoch: 57 -> Test Accuracy: 32.5\n",
      "Epoch: 58 -> Loss: 0.0660610720515\n",
      "Epoch: 58 -> Test Accuracy: 31.89\n",
      "Epoch: 59 -> Loss: 0.143335625529\n",
      "Epoch: 59 -> Test Accuracy: 31.27\n",
      "Epoch: 60 -> Loss: 0.103009954095\n",
      "Epoch: 60 -> Test Accuracy: 32.46\n",
      "Epoch: 61 -> Loss: 0.068049184978\n",
      "Epoch: 61 -> Test Accuracy: 32.49\n",
      "Epoch: 62 -> Loss: 0.0295206569135\n",
      "Epoch: 62 -> Test Accuracy: 32.61\n",
      "Epoch: 63 -> Loss: 0.0488787218928\n",
      "Epoch: 63 -> Test Accuracy: 32.86\n",
      "Epoch: 64 -> Loss: 0.0323862507939\n",
      "Epoch: 64 -> Test Accuracy: 32.72\n",
      "Epoch: 65 -> Loss: 0.0255516506732\n",
      "Epoch: 65 -> Test Accuracy: 32.98\n",
      "Epoch: 66 -> Loss: 0.019795358181\n",
      "Epoch: 66 -> Test Accuracy: 33.14\n",
      "Epoch: 67 -> Loss: 0.0264374818653\n",
      "Epoch: 67 -> Test Accuracy: 33.32\n",
      "Epoch: 68 -> Loss: 0.0309703424573\n",
      "Epoch: 68 -> Test Accuracy: 33.21\n",
      "Epoch: 69 -> Loss: 0.0286380182952\n",
      "Epoch: 69 -> Test Accuracy: 33.29\n",
      "Epoch: 70 -> Loss: 0.0157162416726\n",
      "Epoch: 70 -> Test Accuracy: 33.23\n",
      "Epoch: 71 -> Loss: 0.0174439623952\n",
      "Epoch: 71 -> Test Accuracy: 33.26\n",
      "Epoch: 72 -> Loss: 0.0338215269148\n",
      "Epoch: 72 -> Test Accuracy: 33.2\n",
      "Epoch: 73 -> Loss: 0.0154508417472\n",
      "Epoch: 73 -> Test Accuracy: 33.02\n",
      "Epoch: 74 -> Loss: 0.0234833229333\n",
      "Epoch: 74 -> Test Accuracy: 32.96\n",
      "Epoch: 75 -> Loss: 0.00947361532599\n",
      "Epoch: 75 -> Test Accuracy: 32.85\n",
      "Epoch: 76 -> Loss: 0.0195023491979\n",
      "Epoch: 76 -> Test Accuracy: 33.03\n",
      "Epoch: 77 -> Loss: 0.00932059064507\n",
      "Epoch: 77 -> Test Accuracy: 33.04\n",
      "Epoch: 78 -> Loss: 0.00977662578225\n",
      "Epoch: 78 -> Test Accuracy: 32.92\n",
      "Epoch: 79 -> Loss: 0.00953464396298\n",
      "Epoch: 79 -> Test Accuracy: 32.87\n",
      "Epoch: 80 -> Loss: 0.00998693704605\n",
      "Epoch: 80 -> Test Accuracy: 32.77\n",
      "Epoch: 81 -> Loss: 0.0140571929514\n",
      "Epoch: 81 -> Test Accuracy: 32.68\n",
      "Epoch: 82 -> Loss: 0.0128385359421\n",
      "Epoch: 82 -> Test Accuracy: 32.77\n",
      "Epoch: 83 -> Loss: 0.0132583184168\n",
      "Epoch: 83 -> Test Accuracy: 32.93\n",
      "Epoch: 84 -> Loss: 0.0140424435958\n",
      "Epoch: 84 -> Test Accuracy: 32.86\n",
      "Epoch: 85 -> Loss: 0.0214111879468\n",
      "Epoch: 85 -> Test Accuracy: 32.73\n",
      "Epoch: 86 -> Loss: 0.0116218198091\n",
      "Epoch: 86 -> Test Accuracy: 32.86\n",
      "Epoch: 87 -> Loss: 0.0114888288081\n",
      "Epoch: 87 -> Test Accuracy: 32.85\n",
      "Epoch: 88 -> Loss: 0.00649483315647\n",
      "Epoch: 88 -> Test Accuracy: 32.84\n",
      "Epoch: 89 -> Loss: 0.00624048709869\n",
      "Epoch: 89 -> Test Accuracy: 32.85\n",
      "Epoch: 90 -> Loss: 0.0102006001398\n",
      "Epoch: 90 -> Test Accuracy: 32.93\n",
      "Epoch: 91 -> Loss: 0.00734939193353\n",
      "Epoch: 91 -> Test Accuracy: 33.05\n",
      "Epoch: 92 -> Loss: 0.0108789140359\n",
      "Epoch: 92 -> Test Accuracy: 32.97\n",
      "Epoch: 93 -> Loss: 0.00982717704028\n",
      "Epoch: 93 -> Test Accuracy: 33.09\n",
      "Epoch: 94 -> Loss: 0.0131967859343\n",
      "Epoch: 94 -> Test Accuracy: 33.15\n",
      "Epoch: 95 -> Loss: 0.00754622602835\n",
      "Epoch: 95 -> Test Accuracy: 33.22\n",
      "Epoch: 96 -> Loss: 0.00833824649453\n",
      "Epoch: 96 -> Test Accuracy: 33.12\n",
      "Epoch: 97 -> Loss: 0.0231350660324\n",
      "Epoch: 97 -> Test Accuracy: 33.17\n",
      "Epoch: 98 -> Loss: 0.00944589916617\n",
      "Epoch: 98 -> Test Accuracy: 33.17\n",
      "Epoch: 99 -> Loss: 0.0167779400945\n",
      "Epoch: 99 -> Test Accuracy: 33.23\n",
      "Epoch: 100 -> Loss: 0.0109569430351\n",
      "Epoch: 100 -> Test Accuracy: 33.3\n",
      "Epoch: 101 -> Loss: 0.0090262228623\n",
      "Epoch: 101 -> Test Accuracy: 33.29\n",
      "Epoch: 102 -> Loss: 0.00733293406665\n",
      "Epoch: 102 -> Test Accuracy: 33.36\n",
      "Epoch: 103 -> Loss: 0.00978540070355\n",
      "Epoch: 103 -> Test Accuracy: 33.21\n",
      "Epoch: 104 -> Loss: 0.00776006095111\n",
      "Epoch: 104 -> Test Accuracy: 33.15\n",
      "Epoch: 105 -> Loss: 0.00485428841785\n",
      "Epoch: 105 -> Test Accuracy: 33.13\n",
      "Epoch: 106 -> Loss: 0.00692227156833\n",
      "Epoch: 106 -> Test Accuracy: 33.18\n",
      "Epoch: 107 -> Loss: 0.0145516199991\n",
      "Epoch: 107 -> Test Accuracy: 33.18\n",
      "Epoch: 108 -> Loss: 0.0065232780762\n",
      "Epoch: 108 -> Test Accuracy: 33.2\n",
      "Epoch: 109 -> Loss: 0.00973659753799\n",
      "Epoch: 109 -> Test Accuracy: 33.24\n",
      "Epoch: 110 -> Loss: 0.00667347526178\n",
      "Epoch: 110 -> Test Accuracy: 33.17\n",
      "Epoch: 111 -> Loss: 0.005863904953\n",
      "Epoch: 111 -> Test Accuracy: 33.17\n",
      "Epoch: 112 -> Loss: 0.0066345334053\n",
      "Epoch: 112 -> Test Accuracy: 33.21\n",
      "Epoch: 113 -> Loss: 0.00600856542587\n",
      "Epoch: 113 -> Test Accuracy: 33.28\n",
      "Epoch: 114 -> Loss: 0.00767195876688\n",
      "Epoch: 114 -> Test Accuracy: 33.21\n",
      "Epoch: 115 -> Loss: 0.0120690660551\n",
      "Epoch: 115 -> Test Accuracy: 33.3\n",
      "Epoch: 116 -> Loss: 0.00445118220523\n",
      "Epoch: 116 -> Test Accuracy: 33.32\n",
      "Epoch: 117 -> Loss: 0.00682576512918\n",
      "Epoch: 117 -> Test Accuracy: 33.34\n",
      "Epoch: 118 -> Loss: 0.0115545094013\n",
      "Epoch: 118 -> Test Accuracy: 33.37\n",
      "Epoch: 119 -> Loss: 0.00404347293079\n",
      "Epoch: 119 -> Test Accuracy: 33.45\n",
      "Epoch: 120 -> Loss: 0.00829115137458\n",
      "Epoch: 120 -> Test Accuracy: 33.58\n",
      "Epoch: 121 -> Loss: 0.00744054047391\n",
      "Epoch: 121 -> Test Accuracy: 33.56\n",
      "Epoch: 122 -> Loss: 0.0116795171052\n",
      "Epoch: 122 -> Test Accuracy: 33.54\n",
      "Epoch: 123 -> Loss: 0.00386478495784\n",
      "Epoch: 123 -> Test Accuracy: 33.54\n",
      "Epoch: 124 -> Loss: 0.0139240026474\n",
      "Epoch: 124 -> Test Accuracy: 33.52\n",
      "Epoch: 125 -> Loss: 0.00385524821468\n",
      "Epoch: 125 -> Test Accuracy: 33.5\n",
      "Epoch: 126 -> Loss: 0.0049882796593\n",
      "Epoch: 126 -> Test Accuracy: 33.51\n",
      "Epoch: 127 -> Loss: 0.00605397764593\n",
      "Epoch: 127 -> Test Accuracy: 33.52\n",
      "Epoch: 128 -> Loss: 0.00458223931491\n",
      "Epoch: 128 -> Test Accuracy: 33.54\n",
      "Epoch: 129 -> Loss: 0.00612482102588\n",
      "Epoch: 129 -> Test Accuracy: 33.51\n",
      "Epoch: 130 -> Loss: 0.0088344020769\n",
      "Epoch: 130 -> Test Accuracy: 33.53\n",
      "Epoch: 131 -> Loss: 0.0051029920578\n",
      "Epoch: 131 -> Test Accuracy: 33.52\n",
      "Epoch: 132 -> Loss: 0.00408239476383\n",
      "Epoch: 132 -> Test Accuracy: 33.51\n",
      "Epoch: 133 -> Loss: 0.00719536654651\n",
      "Epoch: 133 -> Test Accuracy: 33.52\n",
      "Epoch: 134 -> Loss: 0.00480751181021\n",
      "Epoch: 134 -> Test Accuracy: 33.5\n",
      "Epoch: 135 -> Loss: 0.00568112405017\n",
      "Epoch: 135 -> Test Accuracy: 33.5\n",
      "Epoch: 136 -> Loss: 0.00524291070178\n",
      "Epoch: 136 -> Test Accuracy: 33.51\n",
      "Epoch: 137 -> Loss: 0.00464428775012\n",
      "Epoch: 137 -> Test Accuracy: 33.5\n",
      "Epoch: 138 -> Loss: 0.00526128197089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 138 -> Test Accuracy: 33.5\n",
      "Epoch: 139 -> Loss: 0.00422385660931\n",
      "Epoch: 139 -> Test Accuracy: 33.48\n",
      "Epoch: 140 -> Loss: 0.00757612101734\n",
      "Epoch: 140 -> Test Accuracy: 33.45\n",
      "Epoch: 141 -> Loss: 0.00782237481326\n",
      "Epoch: 141 -> Test Accuracy: 33.46\n",
      "Epoch: 142 -> Loss: 0.00492163514718\n",
      "Epoch: 142 -> Test Accuracy: 33.48\n",
      "Epoch: 143 -> Loss: 0.0108833573759\n",
      "Epoch: 143 -> Test Accuracy: 33.46\n",
      "Epoch: 144 -> Loss: 0.00434049637988\n",
      "Epoch: 144 -> Test Accuracy: 33.47\n",
      "Epoch: 145 -> Loss: 0.00675307400525\n",
      "Epoch: 145 -> Test Accuracy: 33.51\n",
      "Epoch: 146 -> Loss: 0.00457634544\n",
      "Epoch: 146 -> Test Accuracy: 33.49\n",
      "Epoch: 147 -> Loss: 0.00417333841324\n",
      "Epoch: 147 -> Test Accuracy: 33.47\n",
      "Epoch: 148 -> Loss: 0.00461537949741\n",
      "Epoch: 148 -> Test Accuracy: 33.48\n",
      "Epoch: 149 -> Loss: 0.00940836127847\n",
      "Epoch: 149 -> Test Accuracy: 33.47\n",
      "Epoch: 150 -> Loss: 0.0037887361832\n",
      "Epoch: 150 -> Test Accuracy: 33.43\n",
      "Epoch: 151 -> Loss: 0.00704176537693\n",
      "Epoch: 151 -> Test Accuracy: 33.44\n",
      "Epoch: 152 -> Loss: 0.00583470519632\n",
      "Epoch: 152 -> Test Accuracy: 33.45\n",
      "Epoch: 153 -> Loss: 0.00525141414255\n",
      "Epoch: 153 -> Test Accuracy: 33.48\n",
      "Epoch: 154 -> Loss: 0.00546124251559\n",
      "Epoch: 154 -> Test Accuracy: 33.5\n",
      "Epoch: 155 -> Loss: 0.00640307553113\n",
      "Epoch: 155 -> Test Accuracy: 33.46\n",
      "Epoch: 156 -> Loss: 0.00598384952173\n",
      "Epoch: 156 -> Test Accuracy: 33.44\n",
      "Epoch: 157 -> Loss: 0.00366792408749\n",
      "Epoch: 157 -> Test Accuracy: 33.39\n",
      "Epoch: 158 -> Loss: 0.00489409081638\n",
      "Epoch: 158 -> Test Accuracy: 33.36\n",
      "Epoch: 159 -> Loss: 0.00436055660248\n",
      "Epoch: 159 -> Test Accuracy: 33.37\n",
      "Epoch: 160 -> Loss: 0.00440093548968\n",
      "Epoch: 160 -> Test Accuracy: 33.38\n",
      "Epoch: 161 -> Loss: 0.00551768159494\n",
      "Epoch: 161 -> Test Accuracy: 33.38\n",
      "Epoch: 162 -> Loss: 0.00693592103198\n",
      "Epoch: 162 -> Test Accuracy: 33.38\n",
      "Epoch: 163 -> Loss: 0.0044279564172\n",
      "Epoch: 163 -> Test Accuracy: 33.38\n",
      "Epoch: 164 -> Loss: 0.0045872926712\n",
      "Epoch: 164 -> Test Accuracy: 33.39\n",
      "Epoch: 165 -> Loss: 0.00521266460419\n",
      "Epoch: 165 -> Test Accuracy: 33.39\n",
      "Epoch: 166 -> Loss: 0.0050285924226\n",
      "Epoch: 166 -> Test Accuracy: 33.39\n",
      "Epoch: 167 -> Loss: 0.0036683678627\n",
      "Epoch: 167 -> Test Accuracy: 33.39\n",
      "Epoch: 168 -> Loss: 0.00727958790958\n",
      "Epoch: 168 -> Test Accuracy: 33.39\n",
      "Epoch: 169 -> Loss: 0.00400931946933\n",
      "Epoch: 169 -> Test Accuracy: 33.39\n",
      "Epoch: 170 -> Loss: 0.00650462182239\n",
      "Epoch: 170 -> Test Accuracy: 33.39\n",
      "Epoch: 171 -> Loss: 0.00683243386447\n",
      "Epoch: 171 -> Test Accuracy: 33.4\n",
      "Epoch: 172 -> Loss: 0.0045762527734\n",
      "Epoch: 172 -> Test Accuracy: 33.39\n",
      "Epoch: 173 -> Loss: 0.00511803245172\n",
      "Epoch: 173 -> Test Accuracy: 33.39\n",
      "Epoch: 174 -> Loss: 0.00717591587454\n",
      "Epoch: 174 -> Test Accuracy: 33.39\n",
      "Epoch: 175 -> Loss: 0.00832330528647\n",
      "Epoch: 175 -> Test Accuracy: 33.39\n",
      "Epoch: 176 -> Loss: 0.00354497297667\n",
      "Epoch: 176 -> Test Accuracy: 33.4\n",
      "Epoch: 177 -> Loss: 0.00355851650238\n",
      "Epoch: 177 -> Test Accuracy: 33.38\n",
      "Epoch: 178 -> Loss: 0.00469863414764\n",
      "Epoch: 178 -> Test Accuracy: 33.38\n",
      "Epoch: 179 -> Loss: 0.00486535485834\n",
      "Epoch: 179 -> Test Accuracy: 33.38\n",
      "Epoch: 180 -> Loss: 0.0102856559679\n",
      "Epoch: 180 -> Test Accuracy: 33.38\n",
      "Epoch: 181 -> Loss: 0.00657374970615\n",
      "Epoch: 181 -> Test Accuracy: 33.39\n",
      "Epoch: 182 -> Loss: 0.00367120909505\n",
      "Epoch: 182 -> Test Accuracy: 33.39\n",
      "Epoch: 183 -> Loss: 0.00407609669492\n",
      "Epoch: 183 -> Test Accuracy: 33.39\n",
      "Epoch: 184 -> Loss: 0.00512996641919\n",
      "Epoch: 184 -> Test Accuracy: 33.39\n",
      "Epoch: 185 -> Loss: 0.00498712062836\n",
      "Epoch: 185 -> Test Accuracy: 33.39\n",
      "Epoch: 186 -> Loss: 0.00610105181113\n",
      "Epoch: 186 -> Test Accuracy: 33.39\n",
      "Epoch: 187 -> Loss: 0.00582842016593\n",
      "Epoch: 187 -> Test Accuracy: 33.39\n",
      "Epoch: 188 -> Loss: 0.00661266501993\n",
      "Epoch: 188 -> Test Accuracy: 33.39\n",
      "Epoch: 189 -> Loss: 0.00592651637271\n",
      "Epoch: 189 -> Test Accuracy: 33.39\n",
      "Epoch: 190 -> Loss: 0.00581815512851\n",
      "Epoch: 190 -> Test Accuracy: 33.39\n",
      "Epoch: 191 -> Loss: 0.00549773359671\n",
      "Epoch: 191 -> Test Accuracy: 33.38\n",
      "Epoch: 192 -> Loss: 0.0129278833047\n",
      "Epoch: 192 -> Test Accuracy: 33.38\n",
      "Epoch: 193 -> Loss: 0.0152161978185\n",
      "Epoch: 193 -> Test Accuracy: 33.41\n",
      "Epoch: 194 -> Loss: 0.00564012909308\n",
      "Epoch: 194 -> Test Accuracy: 33.42\n",
      "Epoch: 195 -> Loss: 0.00886078644544\n",
      "Epoch: 195 -> Test Accuracy: 33.42\n",
      "Epoch: 196 -> Loss: 0.00526430225\n",
      "Epoch: 196 -> Test Accuracy: 33.43\n",
      "Epoch: 197 -> Loss: 0.00462973117828\n",
      "Epoch: 197 -> Test Accuracy: 33.41\n",
      "Epoch: 198 -> Loss: 0.00565792433918\n",
      "Epoch: 198 -> Test Accuracy: 33.42\n",
      "Epoch: 199 -> Loss: 0.0052722627297\n",
      "Epoch: 199 -> Test Accuracy: 33.42\n",
      "Epoch: 200 -> Loss: 0.00693464931101\n",
      "Epoch: 200 -> Test Accuracy: 33.42\n",
      "Finished Training\n",
      "Epoch: 1 -> Loss: 1.23228180408\n",
      "Epoch: 1 -> Test Accuracy: 56.22\n",
      "Epoch: 2 -> Loss: 0.903755903244\n",
      "Epoch: 2 -> Test Accuracy: 64.19\n",
      "Epoch: 3 -> Loss: 0.608038067818\n",
      "Epoch: 3 -> Test Accuracy: 64.86\n",
      "Epoch: 4 -> Loss: 0.510831415653\n",
      "Epoch: 4 -> Test Accuracy: 68.78\n",
      "Epoch: 5 -> Loss: 0.397419512272\n",
      "Epoch: 5 -> Test Accuracy: 69.27\n",
      "Epoch: 6 -> Loss: 0.397990107536\n",
      "Epoch: 6 -> Test Accuracy: 69.62\n",
      "Epoch: 7 -> Loss: 0.238818705082\n",
      "Epoch: 7 -> Test Accuracy: 69.57\n",
      "Epoch: 8 -> Loss: 0.212207615376\n",
      "Epoch: 8 -> Test Accuracy: 69.58\n",
      "Epoch: 9 -> Loss: 0.235055521131\n",
      "Epoch: 9 -> Test Accuracy: 68.91\n",
      "Epoch: 10 -> Loss: 0.203405365348\n",
      "Epoch: 10 -> Test Accuracy: 69.35\n",
      "Epoch: 11 -> Loss: 0.0941282585263\n",
      "Epoch: 11 -> Test Accuracy: 68.96\n",
      "Epoch: 12 -> Loss: 0.151610851288\n",
      "Epoch: 12 -> Test Accuracy: 69.32\n",
      "Epoch: 13 -> Loss: 0.12627710402\n",
      "Epoch: 13 -> Test Accuracy: 68.92\n",
      "Epoch: 14 -> Loss: 0.09765227139\n",
      "Epoch: 14 -> Test Accuracy: 69.73\n",
      "Epoch: 15 -> Loss: 0.0521144494414\n",
      "Epoch: 15 -> Test Accuracy: 70.05\n",
      "Epoch: 16 -> Loss: 0.0430850721896\n",
      "Epoch: 16 -> Test Accuracy: 70.45\n",
      "Epoch: 17 -> Loss: 0.0424443073571\n",
      "Epoch: 17 -> Test Accuracy: 70.25\n",
      "Epoch: 18 -> Loss: 0.0390545353293\n",
      "Epoch: 18 -> Test Accuracy: 69.62\n",
      "Epoch: 19 -> Loss: 0.0559340715408\n",
      "Epoch: 19 -> Test Accuracy: 69.86\n",
      "Epoch: 20 -> Loss: 0.0275694858283\n",
      "Epoch: 20 -> Test Accuracy: 70.4\n",
      "Epoch: 21 -> Loss: 0.0212242230773\n",
      "Epoch: 21 -> Test Accuracy: 70.79\n",
      "Epoch: 22 -> Loss: 0.0220940578729\n",
      "Epoch: 22 -> Test Accuracy: 70.44\n",
      "Epoch: 23 -> Loss: 0.0253821481019\n",
      "Epoch: 23 -> Test Accuracy: 70.15\n",
      "Epoch: 24 -> Loss: 0.0361870117486\n",
      "Epoch: 24 -> Test Accuracy: 70.06\n",
      "Epoch: 25 -> Loss: 0.0105072949082\n",
      "Epoch: 25 -> Test Accuracy: 69.9\n",
      "Epoch: 26 -> Loss: 0.0281738545746\n",
      "Epoch: 26 -> Test Accuracy: 70.55\n",
      "Epoch: 27 -> Loss: 0.0219558291137\n",
      "Epoch: 27 -> Test Accuracy: 70.31\n",
      "Epoch: 28 -> Loss: 0.0207806006074\n",
      "Epoch: 28 -> Test Accuracy: 70.26\n",
      "Epoch: 29 -> Loss: 0.0245444457978\n",
      "Epoch: 29 -> Test Accuracy: 69.92\n",
      "Epoch: 30 -> Loss: 0.0212737806141\n",
      "Epoch: 30 -> Test Accuracy: 70.4\n",
      "Epoch: 31 -> Loss: 0.0270195882767\n",
      "Epoch: 31 -> Test Accuracy: 70.41\n",
      "Epoch: 32 -> Loss: 0.0176553819329\n",
      "Epoch: 32 -> Test Accuracy: 69.93\n",
      "Epoch: 33 -> Loss: 0.0128499129787\n",
      "Epoch: 33 -> Test Accuracy: 70.72\n",
      "Epoch: 34 -> Loss: 0.0166346449405\n",
      "Epoch: 34 -> Test Accuracy: 70.78\n",
      "Epoch: 35 -> Loss: 0.00913929007947\n",
      "Epoch: 35 -> Test Accuracy: 70.16\n",
      "Epoch: 36 -> Loss: 0.00897621177137\n",
      "Epoch: 36 -> Test Accuracy: 70.55\n",
      "Epoch: 37 -> Loss: 0.0155281834304\n",
      "Epoch: 37 -> Test Accuracy: 70.7\n",
      "Epoch: 38 -> Loss: 0.00772665115073\n",
      "Epoch: 38 -> Test Accuracy: 70.76\n",
      "Epoch: 39 -> Loss: 0.00486875511706\n",
      "Epoch: 39 -> Test Accuracy: 70.68\n",
      "Epoch: 40 -> Loss: 0.00955580268055\n",
      "Epoch: 40 -> Test Accuracy: 70.88\n",
      "Epoch: 41 -> Loss: 0.0103616854176\n",
      "Epoch: 41 -> Test Accuracy: 70.92\n",
      "Epoch: 42 -> Loss: 0.00895405281335\n",
      "Epoch: 42 -> Test Accuracy: 70.89\n",
      "Epoch: 43 -> Loss: 0.0091882487759\n",
      "Epoch: 43 -> Test Accuracy: 70.93\n",
      "Epoch: 44 -> Loss: 0.00510248774663\n",
      "Epoch: 44 -> Test Accuracy: 70.98\n",
      "Epoch: 45 -> Loss: 0.00903421640396\n",
      "Epoch: 45 -> Test Accuracy: 70.99\n",
      "Epoch: 46 -> Loss: 0.00978920049965\n",
      "Epoch: 46 -> Test Accuracy: 71.05\n",
      "Epoch: 47 -> Loss: 0.00770680699497\n",
      "Epoch: 47 -> Test Accuracy: 71.05\n",
      "Epoch: 48 -> Loss: 0.0055154976435\n",
      "Epoch: 48 -> Test Accuracy: 71.12\n",
      "Epoch: 49 -> Loss: 0.00883828662336\n",
      "Epoch: 49 -> Test Accuracy: 71.14\n",
      "Epoch: 50 -> Loss: 0.00528219109401\n",
      "Epoch: 50 -> Test Accuracy: 71.16\n",
      "Epoch: 51 -> Loss: 0.0110837565735\n",
      "Epoch: 51 -> Test Accuracy: 71.22\n",
      "Epoch: 52 -> Loss: 0.00896917376667\n",
      "Epoch: 52 -> Test Accuracy: 71.25\n",
      "Epoch: 53 -> Loss: 0.00833268370479\n",
      "Epoch: 53 -> Test Accuracy: 71.21\n",
      "Epoch: 54 -> Loss: 0.00872628483921\n",
      "Epoch: 54 -> Test Accuracy: 71.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55 -> Loss: 0.00788806937635\n",
      "Epoch: 55 -> Test Accuracy: 71.2\n",
      "Epoch: 56 -> Loss: 0.00546456314623\n",
      "Epoch: 56 -> Test Accuracy: 71.17\n",
      "Epoch: 57 -> Loss: 0.0255545191467\n",
      "Epoch: 57 -> Test Accuracy: 71.11\n",
      "Epoch: 58 -> Loss: 0.0102572627366\n",
      "Epoch: 58 -> Test Accuracy: 71.17\n",
      "Epoch: 59 -> Loss: 0.00920040346682\n",
      "Epoch: 59 -> Test Accuracy: 71.09\n",
      "Epoch: 60 -> Loss: 0.00655400753021\n",
      "Epoch: 60 -> Test Accuracy: 71.15\n",
      "Epoch: 61 -> Loss: 0.00766201643273\n",
      "Epoch: 61 -> Test Accuracy: 71.26\n",
      "Epoch: 62 -> Loss: 0.0107051227242\n",
      "Epoch: 62 -> Test Accuracy: 71.26\n",
      "Epoch: 63 -> Loss: 0.00476559763774\n",
      "Epoch: 63 -> Test Accuracy: 71.34\n",
      "Epoch: 64 -> Loss: 0.00601513590664\n",
      "Epoch: 64 -> Test Accuracy: 71.32\n",
      "Epoch: 65 -> Loss: 0.00635406142101\n",
      "Epoch: 65 -> Test Accuracy: 71.26\n",
      "Epoch: 66 -> Loss: 0.00865513086319\n",
      "Epoch: 66 -> Test Accuracy: 71.24\n",
      "Epoch: 67 -> Loss: 0.0061973836273\n",
      "Epoch: 67 -> Test Accuracy: 71.32\n",
      "Epoch: 68 -> Loss: 0.00733599998057\n",
      "Epoch: 68 -> Test Accuracy: 71.36\n",
      "Epoch: 69 -> Loss: 0.00518591143191\n",
      "Epoch: 69 -> Test Accuracy: 71.34\n",
      "Epoch: 70 -> Loss: 0.00440034968778\n",
      "Epoch: 70 -> Test Accuracy: 71.58\n",
      "Epoch: 71 -> Loss: 0.00623135827482\n",
      "Epoch: 71 -> Test Accuracy: 71.55\n",
      "Epoch: 72 -> Loss: 0.00401103962213\n",
      "Epoch: 72 -> Test Accuracy: 71.5\n",
      "Epoch: 73 -> Loss: 0.00388430641033\n",
      "Epoch: 73 -> Test Accuracy: 71.47\n",
      "Epoch: 74 -> Loss: 0.00582393771037\n",
      "Epoch: 74 -> Test Accuracy: 71.47\n",
      "Epoch: 75 -> Loss: 0.011393437162\n",
      "Epoch: 75 -> Test Accuracy: 71.47\n",
      "Epoch: 76 -> Loss: 0.00715751387179\n",
      "Epoch: 76 -> Test Accuracy: 71.47\n",
      "Epoch: 77 -> Loss: 0.0110413888469\n",
      "Epoch: 77 -> Test Accuracy: 71.43\n",
      "Epoch: 78 -> Loss: 0.00464172102511\n",
      "Epoch: 78 -> Test Accuracy: 71.39\n",
      "Epoch: 79 -> Loss: 0.0109197450802\n",
      "Epoch: 79 -> Test Accuracy: 71.4\n",
      "Epoch: 80 -> Loss: 0.00645300047472\n",
      "Epoch: 80 -> Test Accuracy: 71.41\n",
      "Epoch: 81 -> Loss: 0.00527241593227\n",
      "Epoch: 81 -> Test Accuracy: 71.42\n",
      "Epoch: 82 -> Loss: 0.00532373553142\n",
      "Epoch: 82 -> Test Accuracy: 71.44\n",
      "Epoch: 83 -> Loss: 0.00467206444591\n",
      "Epoch: 83 -> Test Accuracy: 71.43\n",
      "Epoch: 84 -> Loss: 0.0083185294643\n",
      "Epoch: 84 -> Test Accuracy: 71.45\n",
      "Epoch: 85 -> Loss: 0.013695015572\n",
      "Epoch: 85 -> Test Accuracy: 71.39\n",
      "Epoch: 86 -> Loss: 0.00487465132028\n",
      "Epoch: 86 -> Test Accuracy: 71.4\n",
      "Epoch: 87 -> Loss: 0.00491425162181\n",
      "Epoch: 87 -> Test Accuracy: 71.4\n",
      "Epoch: 88 -> Loss: 0.00945886969566\n",
      "Epoch: 88 -> Test Accuracy: 71.41\n",
      "Epoch: 89 -> Loss: 0.00524829002097\n",
      "Epoch: 89 -> Test Accuracy: 71.41\n",
      "Epoch: 90 -> Loss: 0.00885963905603\n",
      "Epoch: 90 -> Test Accuracy: 71.42\n",
      "Epoch: 91 -> Loss: 0.0105357859284\n",
      "Epoch: 91 -> Test Accuracy: 71.42\n",
      "Epoch: 92 -> Loss: 0.00908646639436\n",
      "Epoch: 92 -> Test Accuracy: 71.42\n",
      "Epoch: 93 -> Loss: 0.00581737654284\n",
      "Epoch: 93 -> Test Accuracy: 71.42\n",
      "Epoch: 94 -> Loss: 0.0069538904354\n",
      "Epoch: 94 -> Test Accuracy: 71.44\n",
      "Epoch: 95 -> Loss: 0.00720048416406\n",
      "Epoch: 95 -> Test Accuracy: 71.4\n",
      "Epoch: 96 -> Loss: 0.00697491271421\n",
      "Epoch: 96 -> Test Accuracy: 71.39\n",
      "Epoch: 97 -> Loss: 0.00736071495339\n",
      "Epoch: 97 -> Test Accuracy: 71.42\n",
      "Epoch: 98 -> Loss: 0.0048691262491\n",
      "Epoch: 98 -> Test Accuracy: 71.43\n",
      "Epoch: 99 -> Loss: 0.00599306821823\n",
      "Epoch: 99 -> Test Accuracy: 71.44\n",
      "Epoch: 100 -> Loss: 0.00716873304918\n",
      "Epoch: 100 -> Test Accuracy: 71.44\n",
      "Finished Training\n",
      "Epoch: 1 -> Loss: 2.03324747086\n",
      "Epoch: 1 -> Test Accuracy: 24.2\n",
      "Epoch: 2 -> Loss: 1.90362727642\n",
      "Epoch: 2 -> Test Accuracy: 28.77\n",
      "Epoch: 3 -> Loss: 1.72655439377\n",
      "Epoch: 3 -> Test Accuracy: 34.99\n",
      "Epoch: 4 -> Loss: 1.57878935337\n",
      "Epoch: 4 -> Test Accuracy: 34.3\n",
      "Epoch: 5 -> Loss: 1.52861917019\n",
      "Epoch: 5 -> Test Accuracy: 37.16\n",
      "Epoch: 6 -> Loss: 1.54896104336\n",
      "Epoch: 6 -> Test Accuracy: 40.0\n",
      "Epoch: 7 -> Loss: 1.44726133347\n",
      "Epoch: 7 -> Test Accuracy: 39.76\n",
      "Epoch: 8 -> Loss: 1.37566936016\n",
      "Epoch: 8 -> Test Accuracy: 43.16\n",
      "Epoch: 9 -> Loss: 1.34258389473\n",
      "Epoch: 9 -> Test Accuracy: 42.46\n",
      "Epoch: 10 -> Loss: 1.2197726965\n",
      "Epoch: 10 -> Test Accuracy: 45.16\n",
      "Epoch: 11 -> Loss: 1.31248545647\n",
      "Epoch: 11 -> Test Accuracy: 44.05\n",
      "Epoch: 12 -> Loss: 1.33868873119\n",
      "Epoch: 12 -> Test Accuracy: 43.35\n",
      "Epoch: 13 -> Loss: 1.26953232288\n",
      "Epoch: 13 -> Test Accuracy: 43.86\n",
      "Epoch: 14 -> Loss: 1.14655303955\n",
      "Epoch: 14 -> Test Accuracy: 46.6\n",
      "Epoch: 15 -> Loss: 0.988393783569\n",
      "Epoch: 15 -> Test Accuracy: 44.66\n",
      "Epoch: 16 -> Loss: 1.00269007683\n",
      "Epoch: 16 -> Test Accuracy: 46.94\n",
      "Epoch: 17 -> Loss: 1.04037773609\n",
      "Epoch: 17 -> Test Accuracy: 47.45\n",
      "Epoch: 18 -> Loss: 0.727957308292\n",
      "Epoch: 18 -> Test Accuracy: 47.93\n",
      "Epoch: 19 -> Loss: 0.803151845932\n",
      "Epoch: 19 -> Test Accuracy: 46.9\n",
      "Epoch: 20 -> Loss: 0.902499854565\n",
      "Epoch: 20 -> Test Accuracy: 48.56\n",
      "Epoch: 21 -> Loss: 0.75921857357\n",
      "Epoch: 21 -> Test Accuracy: 45.04\n",
      "Epoch: 22 -> Loss: 0.792897164822\n",
      "Epoch: 22 -> Test Accuracy: 47.19\n",
      "Epoch: 23 -> Loss: 0.720752954483\n",
      "Epoch: 23 -> Test Accuracy: 50.65\n",
      "Epoch: 24 -> Loss: 0.808699011803\n",
      "Epoch: 24 -> Test Accuracy: 49.55\n",
      "Epoch: 25 -> Loss: 0.769821047783\n",
      "Epoch: 25 -> Test Accuracy: 48.19\n",
      "Epoch: 26 -> Loss: 0.599165320396\n",
      "Epoch: 26 -> Test Accuracy: 48.92\n",
      "Epoch: 27 -> Loss: 0.613128662109\n",
      "Epoch: 27 -> Test Accuracy: 47.35\n",
      "Epoch: 28 -> Loss: 0.622849822044\n",
      "Epoch: 28 -> Test Accuracy: 47.08\n",
      "Epoch: 29 -> Loss: 0.492921620607\n",
      "Epoch: 29 -> Test Accuracy: 51.07\n",
      "Epoch: 30 -> Loss: 0.386013180017\n",
      "Epoch: 30 -> Test Accuracy: 48.84\n",
      "Epoch: 31 -> Loss: 0.645495116711\n",
      "Epoch: 31 -> Test Accuracy: 46.38\n",
      "Epoch: 32 -> Loss: 0.536471247673\n",
      "Epoch: 32 -> Test Accuracy: 49.89\n",
      "Epoch: 33 -> Loss: 0.329470783472\n",
      "Epoch: 33 -> Test Accuracy: 49.28\n",
      "Epoch: 34 -> Loss: 0.512998521328\n",
      "Epoch: 34 -> Test Accuracy: 48.47\n",
      "Epoch: 35 -> Loss: 0.495329082012\n",
      "Epoch: 35 -> Test Accuracy: 50.76\n",
      "Epoch: 36 -> Loss: 0.435809493065\n",
      "Epoch: 36 -> Test Accuracy: 47.68\n",
      "Epoch: 37 -> Loss: 0.438357293606\n",
      "Epoch: 37 -> Test Accuracy: 48.44\n",
      "Epoch: 38 -> Loss: 0.32427585125\n",
      "Epoch: 38 -> Test Accuracy: 50.3\n",
      "Epoch: 39 -> Loss: 0.229767397046\n",
      "Epoch: 39 -> Test Accuracy: 48.32\n",
      "Epoch: 40 -> Loss: 0.316120117903\n",
      "Epoch: 40 -> Test Accuracy: 49.38\n",
      "Epoch: 41 -> Loss: 0.373222202063\n",
      "Epoch: 41 -> Test Accuracy: 51.05\n",
      "Epoch: 42 -> Loss: 0.35919713974\n",
      "Epoch: 42 -> Test Accuracy: 50.52\n",
      "Epoch: 43 -> Loss: 0.204516753554\n",
      "Epoch: 43 -> Test Accuracy: 50.28\n",
      "Epoch: 44 -> Loss: 0.273675501347\n",
      "Epoch: 44 -> Test Accuracy: 50.49\n",
      "Epoch: 45 -> Loss: 0.158045843244\n",
      "Epoch: 45 -> Test Accuracy: 50.23\n",
      "Epoch: 46 -> Loss: 0.210152372718\n",
      "Epoch: 46 -> Test Accuracy: 51.46\n",
      "Epoch: 47 -> Loss: 0.0786407738924\n",
      "Epoch: 47 -> Test Accuracy: 51.73\n",
      "Epoch: 48 -> Loss: 0.110795907676\n",
      "Epoch: 48 -> Test Accuracy: 51.1\n",
      "Epoch: 49 -> Loss: 0.172106638551\n",
      "Epoch: 49 -> Test Accuracy: 47.61\n",
      "Epoch: 50 -> Loss: 0.27514731884\n",
      "Epoch: 50 -> Test Accuracy: 50.75\n",
      "Epoch: 51 -> Loss: 0.212641581893\n",
      "Epoch: 51 -> Test Accuracy: 49.83\n",
      "Epoch: 52 -> Loss: 0.111345618963\n",
      "Epoch: 52 -> Test Accuracy: 49.91\n",
      "Epoch: 53 -> Loss: 0.129646375775\n",
      "Epoch: 53 -> Test Accuracy: 50.8\n",
      "Epoch: 54 -> Loss: 0.076391287148\n",
      "Epoch: 54 -> Test Accuracy: 52.05\n",
      "Epoch: 55 -> Loss: 0.0914010703564\n",
      "Epoch: 55 -> Test Accuracy: 50.06\n",
      "Epoch: 56 -> Loss: 0.129418984056\n",
      "Epoch: 56 -> Test Accuracy: 51.0\n",
      "Epoch: 57 -> Loss: 0.139579311013\n",
      "Epoch: 57 -> Test Accuracy: 51.76\n",
      "Epoch: 58 -> Loss: 0.0467310398817\n",
      "Epoch: 58 -> Test Accuracy: 50.94\n",
      "Epoch: 59 -> Loss: 0.20532168448\n",
      "Epoch: 59 -> Test Accuracy: 50.37\n",
      "Epoch: 60 -> Loss: 0.0519213862717\n",
      "Epoch: 60 -> Test Accuracy: 50.26\n",
      "Epoch: 61 -> Loss: 0.0465354770422\n",
      "Epoch: 61 -> Test Accuracy: 52.37\n",
      "Epoch: 62 -> Loss: 0.0228066444397\n",
      "Epoch: 62 -> Test Accuracy: 52.32\n",
      "Epoch: 63 -> Loss: 0.0180767308921\n",
      "Epoch: 63 -> Test Accuracy: 52.53\n",
      "Epoch: 64 -> Loss: 0.0175051223487\n",
      "Epoch: 64 -> Test Accuracy: 52.49\n",
      "Epoch: 65 -> Loss: 0.00969408079982\n",
      "Epoch: 65 -> Test Accuracy: 52.67\n",
      "Epoch: 66 -> Loss: 0.0169107280672\n",
      "Epoch: 66 -> Test Accuracy: 52.72\n",
      "Epoch: 67 -> Loss: 0.00969924405217\n",
      "Epoch: 67 -> Test Accuracy: 53.12\n",
      "Epoch: 68 -> Loss: 0.00978723820299\n",
      "Epoch: 68 -> Test Accuracy: 53.18\n",
      "Epoch: 69 -> Loss: 0.00920523144305\n",
      "Epoch: 69 -> Test Accuracy: 52.83\n",
      "Epoch: 70 -> Loss: 0.0084798745811\n",
      "Epoch: 70 -> Test Accuracy: 52.83\n",
      "Epoch: 71 -> Loss: 0.00690103508532\n",
      "Epoch: 71 -> Test Accuracy: 52.82\n",
      "Epoch: 72 -> Loss: 0.00664096139371\n",
      "Epoch: 72 -> Test Accuracy: 52.98\n",
      "Epoch: 73 -> Loss: 0.00934621039778\n",
      "Epoch: 73 -> Test Accuracy: 52.92\n",
      "Epoch: 74 -> Loss: 0.013814673759\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74 -> Test Accuracy: 53.12\n",
      "Epoch: 75 -> Loss: 0.0133948875591\n",
      "Epoch: 75 -> Test Accuracy: 52.85\n",
      "Epoch: 76 -> Loss: 0.00839868374169\n",
      "Epoch: 76 -> Test Accuracy: 52.87\n",
      "Epoch: 77 -> Loss: 0.0084963394329\n",
      "Epoch: 77 -> Test Accuracy: 53.22\n",
      "Epoch: 78 -> Loss: 0.00737501587719\n",
      "Epoch: 78 -> Test Accuracy: 53.17\n",
      "Epoch: 79 -> Loss: 0.0110773723572\n",
      "Epoch: 79 -> Test Accuracy: 53.25\n",
      "Epoch: 80 -> Loss: 0.00879410561174\n",
      "Epoch: 80 -> Test Accuracy: 53.26\n",
      "Epoch: 81 -> Loss: 0.0130020566285\n",
      "Epoch: 81 -> Test Accuracy: 53.1\n",
      "Epoch: 82 -> Loss: 0.00690402416512\n",
      "Epoch: 82 -> Test Accuracy: 52.89\n",
      "Epoch: 83 -> Loss: 0.0114755583927\n",
      "Epoch: 83 -> Test Accuracy: 53.21\n",
      "Epoch: 84 -> Loss: 0.00637876056135\n",
      "Epoch: 84 -> Test Accuracy: 53.21\n",
      "Epoch: 85 -> Loss: 0.00438362360001\n",
      "Epoch: 85 -> Test Accuracy: 53.21\n",
      "Epoch: 86 -> Loss: 0.0122922156006\n",
      "Epoch: 86 -> Test Accuracy: 53.27\n",
      "Epoch: 87 -> Loss: 0.00887689180672\n",
      "Epoch: 87 -> Test Accuracy: 53.37\n",
      "Epoch: 88 -> Loss: 0.0137259000912\n",
      "Epoch: 88 -> Test Accuracy: 53.31\n",
      "Epoch: 89 -> Loss: 0.00647115241736\n",
      "Epoch: 89 -> Test Accuracy: 53.16\n",
      "Epoch: 90 -> Loss: 0.00786117836833\n",
      "Epoch: 90 -> Test Accuracy: 52.72\n",
      "Epoch: 91 -> Loss: 0.00656936736777\n",
      "Epoch: 91 -> Test Accuracy: 52.83\n",
      "Epoch: 92 -> Loss: 0.00495171546936\n",
      "Epoch: 92 -> Test Accuracy: 52.89\n",
      "Epoch: 93 -> Loss: 0.00936747062951\n",
      "Epoch: 93 -> Test Accuracy: 53.12\n",
      "Epoch: 94 -> Loss: 0.0065628150478\n",
      "Epoch: 94 -> Test Accuracy: 53.09\n",
      "Epoch: 95 -> Loss: 0.00529805989936\n",
      "Epoch: 95 -> Test Accuracy: 53.1\n",
      "Epoch: 96 -> Loss: 0.00498132966459\n",
      "Epoch: 96 -> Test Accuracy: 52.96\n",
      "Epoch: 97 -> Loss: 0.00563468364999\n",
      "Epoch: 97 -> Test Accuracy: 53.03\n",
      "Epoch: 98 -> Loss: 0.00973847694695\n",
      "Epoch: 98 -> Test Accuracy: 53.1\n",
      "Epoch: 99 -> Loss: 0.00738205341622\n",
      "Epoch: 99 -> Test Accuracy: 53.18\n",
      "Epoch: 100 -> Loss: 0.00463082222268\n",
      "Epoch: 100 -> Test Accuracy: 53.18\n",
      "Epoch: 101 -> Loss: 0.00391811132431\n",
      "Epoch: 101 -> Test Accuracy: 53.14\n",
      "Epoch: 102 -> Loss: 0.00862826313823\n",
      "Epoch: 102 -> Test Accuracy: 53.18\n",
      "Epoch: 103 -> Loss: 0.00328752631322\n",
      "Epoch: 103 -> Test Accuracy: 53.13\n",
      "Epoch: 104 -> Loss: 0.00448711542413\n",
      "Epoch: 104 -> Test Accuracy: 53.05\n",
      "Epoch: 105 -> Loss: 0.00942156370729\n",
      "Epoch: 105 -> Test Accuracy: 53.1\n",
      "Epoch: 106 -> Loss: 0.00922140292823\n",
      "Epoch: 106 -> Test Accuracy: 53.24\n",
      "Epoch: 107 -> Loss: 0.00353319360875\n",
      "Epoch: 107 -> Test Accuracy: 53.18\n",
      "Epoch: 108 -> Loss: 0.00635982491076\n",
      "Epoch: 108 -> Test Accuracy: 53.4\n",
      "Epoch: 109 -> Loss: 0.0133653692901\n",
      "Epoch: 109 -> Test Accuracy: 53.64\n",
      "Epoch: 110 -> Loss: 0.00605596043169\n",
      "Epoch: 110 -> Test Accuracy: 53.61\n",
      "Epoch: 111 -> Loss: 0.00361425150186\n",
      "Epoch: 111 -> Test Accuracy: 53.73\n",
      "Epoch: 112 -> Loss: 0.00514339935035\n",
      "Epoch: 112 -> Test Accuracy: 53.75\n",
      "Epoch: 113 -> Loss: 0.00364286173135\n",
      "Epoch: 113 -> Test Accuracy: 53.67\n",
      "Epoch: 114 -> Loss: 0.00292287883349\n",
      "Epoch: 114 -> Test Accuracy: 53.58\n",
      "Epoch: 115 -> Loss: 0.00446794601157\n",
      "Epoch: 115 -> Test Accuracy: 53.45\n",
      "Epoch: 116 -> Loss: 0.0104188136756\n",
      "Epoch: 116 -> Test Accuracy: 53.34\n",
      "Epoch: 117 -> Loss: 0.00635721581057\n",
      "Epoch: 117 -> Test Accuracy: 53.56\n",
      "Epoch: 118 -> Loss: 0.00675781397149\n",
      "Epoch: 118 -> Test Accuracy: 53.53\n",
      "Epoch: 119 -> Loss: 0.00489655369893\n",
      "Epoch: 119 -> Test Accuracy: 53.46\n",
      "Epoch: 120 -> Loss: 0.00415840977803\n",
      "Epoch: 120 -> Test Accuracy: 53.52\n",
      "Epoch: 121 -> Loss: 0.00485801231116\n",
      "Epoch: 121 -> Test Accuracy: 53.44\n",
      "Epoch: 122 -> Loss: 0.00658615259454\n",
      "Epoch: 122 -> Test Accuracy: 53.39\n",
      "Epoch: 123 -> Loss: 0.00555249350145\n",
      "Epoch: 123 -> Test Accuracy: 53.36\n",
      "Epoch: 124 -> Loss: 0.00335048255511\n",
      "Epoch: 124 -> Test Accuracy: 53.3\n",
      "Epoch: 125 -> Loss: 0.00530496006832\n",
      "Epoch: 125 -> Test Accuracy: 53.28\n",
      "Epoch: 126 -> Loss: 0.00332113401964\n",
      "Epoch: 126 -> Test Accuracy: 53.29\n",
      "Epoch: 127 -> Loss: 0.0046452190727\n",
      "Epoch: 127 -> Test Accuracy: 53.3\n",
      "Epoch: 128 -> Loss: 0.00489619607106\n",
      "Epoch: 128 -> Test Accuracy: 53.32\n",
      "Epoch: 129 -> Loss: 0.00466095004231\n",
      "Epoch: 129 -> Test Accuracy: 53.37\n",
      "Epoch: 130 -> Loss: 0.00563665525988\n",
      "Epoch: 130 -> Test Accuracy: 53.36\n",
      "Epoch: 131 -> Loss: 0.00683191185817\n",
      "Epoch: 131 -> Test Accuracy: 53.31\n",
      "Epoch: 132 -> Loss: 0.0132419969887\n",
      "Epoch: 132 -> Test Accuracy: 53.3\n",
      "Epoch: 133 -> Loss: 0.00399278663099\n",
      "Epoch: 133 -> Test Accuracy: 53.37\n",
      "Epoch: 134 -> Loss: 0.00488137733191\n",
      "Epoch: 134 -> Test Accuracy: 53.42\n",
      "Epoch: 135 -> Loss: 0.00478550093248\n",
      "Epoch: 135 -> Test Accuracy: 53.43\n",
      "Epoch: 136 -> Loss: 0.0055581512861\n",
      "Epoch: 136 -> Test Accuracy: 53.4\n",
      "Epoch: 137 -> Loss: 0.00479375384748\n",
      "Epoch: 137 -> Test Accuracy: 53.33\n",
      "Epoch: 138 -> Loss: 0.00405004387721\n",
      "Epoch: 138 -> Test Accuracy: 53.34\n",
      "Epoch: 139 -> Loss: 0.00416706176475\n",
      "Epoch: 139 -> Test Accuracy: 53.39\n",
      "Epoch: 140 -> Loss: 0.0064367284067\n",
      "Epoch: 140 -> Test Accuracy: 53.48\n",
      "Epoch: 141 -> Loss: 0.00521815288812\n",
      "Epoch: 141 -> Test Accuracy: 53.48\n",
      "Epoch: 142 -> Loss: 0.0044506052509\n",
      "Epoch: 142 -> Test Accuracy: 53.56\n",
      "Epoch: 143 -> Loss: 0.00516773201525\n",
      "Epoch: 143 -> Test Accuracy: 53.52\n",
      "Epoch: 144 -> Loss: 0.00357604492456\n",
      "Epoch: 144 -> Test Accuracy: 53.58\n",
      "Epoch: 145 -> Loss: 0.00628985790536\n",
      "Epoch: 145 -> Test Accuracy: 53.61\n",
      "Epoch: 146 -> Loss: 0.00329155195504\n",
      "Epoch: 146 -> Test Accuracy: 53.59\n",
      "Epoch: 147 -> Loss: 0.00453274976462\n",
      "Epoch: 147 -> Test Accuracy: 53.56\n",
      "Epoch: 148 -> Loss: 0.00538858072832\n",
      "Epoch: 148 -> Test Accuracy: 53.59\n",
      "Epoch: 149 -> Loss: 0.00430074101314\n",
      "Epoch: 149 -> Test Accuracy: 53.55\n",
      "Epoch: 150 -> Loss: 0.00289648771286\n",
      "Epoch: 150 -> Test Accuracy: 53.58\n",
      "Epoch: 151 -> Loss: 0.00249715498649\n",
      "Epoch: 151 -> Test Accuracy: 53.65\n",
      "Epoch: 152 -> Loss: 0.00767645006999\n",
      "Epoch: 152 -> Test Accuracy: 53.63\n",
      "Epoch: 153 -> Loss: 0.00388391665183\n",
      "Epoch: 153 -> Test Accuracy: 53.62\n",
      "Epoch: 154 -> Loss: 0.00525099504739\n",
      "Epoch: 154 -> Test Accuracy: 53.6\n",
      "Epoch: 155 -> Loss: 0.00703579187393\n",
      "Epoch: 155 -> Test Accuracy: 53.61\n",
      "Epoch: 156 -> Loss: 0.00520838238299\n",
      "Epoch: 156 -> Test Accuracy: 53.62\n",
      "Epoch: 157 -> Loss: 0.00346968276426\n",
      "Epoch: 157 -> Test Accuracy: 53.55\n",
      "Epoch: 158 -> Loss: 0.00298650446348\n",
      "Epoch: 158 -> Test Accuracy: 53.53\n",
      "Epoch: 159 -> Loss: 0.00323796737939\n",
      "Epoch: 159 -> Test Accuracy: 53.55\n",
      "Epoch: 160 -> Loss: 0.00611539091915\n",
      "Epoch: 160 -> Test Accuracy: 53.57\n",
      "Epoch: 161 -> Loss: 0.00491266511381\n",
      "Epoch: 161 -> Test Accuracy: 53.58\n",
      "Epoch: 162 -> Loss: 0.00260276068002\n",
      "Epoch: 162 -> Test Accuracy: 53.56\n",
      "Epoch: 163 -> Loss: 0.00349142448977\n",
      "Epoch: 163 -> Test Accuracy: 53.55\n",
      "Epoch: 164 -> Loss: 0.00668664183468\n",
      "Epoch: 164 -> Test Accuracy: 53.52\n",
      "Epoch: 165 -> Loss: 0.00382275297306\n",
      "Epoch: 165 -> Test Accuracy: 53.55\n",
      "Epoch: 166 -> Loss: 0.00273751746863\n",
      "Epoch: 166 -> Test Accuracy: 53.55\n",
      "Epoch: 167 -> Loss: 0.00464595295489\n",
      "Epoch: 167 -> Test Accuracy: 53.56\n",
      "Epoch: 168 -> Loss: 0.00201149634086\n",
      "Epoch: 168 -> Test Accuracy: 53.54\n",
      "Epoch: 169 -> Loss: 0.00228861672804\n",
      "Epoch: 169 -> Test Accuracy: 53.58\n",
      "Epoch: 170 -> Loss: 0.0022044731304\n",
      "Epoch: 170 -> Test Accuracy: 53.56\n",
      "Epoch: 171 -> Loss: 0.00541653065011\n",
      "Epoch: 171 -> Test Accuracy: 53.55\n",
      "Epoch: 172 -> Loss: 0.00478961830959\n",
      "Epoch: 172 -> Test Accuracy: 53.54\n",
      "Epoch: 173 -> Loss: 0.00341762485914\n",
      "Epoch: 173 -> Test Accuracy: 53.53\n",
      "Epoch: 174 -> Loss: 0.00339911994524\n",
      "Epoch: 174 -> Test Accuracy: 53.54\n",
      "Epoch: 175 -> Loss: 0.00356933707371\n",
      "Epoch: 175 -> Test Accuracy: 53.54\n",
      "Epoch: 176 -> Loss: 0.00366109609604\n",
      "Epoch: 176 -> Test Accuracy: 53.53\n",
      "Epoch: 177 -> Loss: 0.00509373936802\n",
      "Epoch: 177 -> Test Accuracy: 53.51\n",
      "Epoch: 178 -> Loss: 0.00426760083064\n",
      "Epoch: 178 -> Test Accuracy: 53.54\n",
      "Epoch: 179 -> Loss: 0.00460535287857\n",
      "Epoch: 179 -> Test Accuracy: 53.55\n",
      "Epoch: 180 -> Loss: 0.00312993628904\n",
      "Epoch: 180 -> Test Accuracy: 53.56\n",
      "Epoch: 181 -> Loss: 0.00310581014492\n",
      "Epoch: 181 -> Test Accuracy: 53.55\n",
      "Epoch: 182 -> Loss: 0.00419929856434\n",
      "Epoch: 182 -> Test Accuracy: 53.54\n",
      "Epoch: 183 -> Loss: 0.00663878815249\n",
      "Epoch: 183 -> Test Accuracy: 53.55\n",
      "Epoch: 184 -> Loss: 0.00718869175762\n",
      "Epoch: 184 -> Test Accuracy: 53.56\n",
      "Epoch: 185 -> Loss: 0.0031815492548\n",
      "Epoch: 185 -> Test Accuracy: 53.54\n",
      "Epoch: 186 -> Loss: 0.00530346529558\n",
      "Epoch: 186 -> Test Accuracy: 53.53\n",
      "Epoch: 187 -> Loss: 0.00856376625597\n",
      "Epoch: 187 -> Test Accuracy: 53.54\n",
      "Epoch: 188 -> Loss: 0.00510734785348\n",
      "Epoch: 188 -> Test Accuracy: 53.52\n",
      "Epoch: 189 -> Loss: 0.00389522779733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 189 -> Test Accuracy: 53.54\n",
      "Epoch: 190 -> Loss: 0.00510119460523\n",
      "Epoch: 190 -> Test Accuracy: 53.54\n",
      "Epoch: 191 -> Loss: 0.0034768122714\n",
      "Epoch: 191 -> Test Accuracy: 53.55\n",
      "Epoch: 192 -> Loss: 0.00397043023258\n",
      "Epoch: 192 -> Test Accuracy: 53.55\n",
      "Epoch: 193 -> Loss: 0.00316552934237\n",
      "Epoch: 193 -> Test Accuracy: 53.55\n",
      "Epoch: 194 -> Loss: 0.00477760098875\n",
      "Epoch: 194 -> Test Accuracy: 53.56\n",
      "Epoch: 195 -> Loss: 0.0050658127293\n",
      "Epoch: 195 -> Test Accuracy: 53.55\n",
      "Epoch: 196 -> Loss: 0.00505871046335\n",
      "Epoch: 196 -> Test Accuracy: 53.55\n",
      "Epoch: 197 -> Loss: 0.00483699049801\n",
      "Epoch: 197 -> Test Accuracy: 53.54\n",
      "Epoch: 198 -> Loss: 0.00280246837065\n",
      "Epoch: 198 -> Test Accuracy: 53.54\n",
      "Epoch: 199 -> Loss: 0.00455846684054\n",
      "Epoch: 199 -> Test Accuracy: 53.53\n",
      "Epoch: 200 -> Loss: 0.00357549008913\n",
      "Epoch: 200 -> Test Accuracy: 53.53\n",
      "Finished Training\n",
      "Epoch: 1 -> Loss: 0.517976045609\n",
      "Epoch: 1 -> Test Accuracy: 69.58\n",
      "Epoch: 2 -> Loss: 0.781946778297\n",
      "Epoch: 2 -> Test Accuracy: 71.63\n",
      "Epoch: 3 -> Loss: 0.658085227013\n",
      "Epoch: 3 -> Test Accuracy: 73.73\n",
      "Epoch: 4 -> Loss: 0.422341555357\n",
      "Epoch: 4 -> Test Accuracy: 74.29\n",
      "Epoch: 5 -> Loss: 0.38326728344\n",
      "Epoch: 5 -> Test Accuracy: 74.42\n",
      "Epoch: 6 -> Loss: 0.495403051376\n",
      "Epoch: 6 -> Test Accuracy: 74.79\n",
      "Epoch: 7 -> Loss: 0.344527482986\n",
      "Epoch: 7 -> Test Accuracy: 74.49\n",
      "Epoch: 8 -> Loss: 0.328863710165\n",
      "Epoch: 8 -> Test Accuracy: 74.99\n",
      "Epoch: 9 -> Loss: 0.278964042664\n",
      "Epoch: 9 -> Test Accuracy: 75.41\n",
      "Epoch: 10 -> Loss: 0.204149112105\n",
      "Epoch: 10 -> Test Accuracy: 76.51\n",
      "Epoch: 11 -> Loss: 0.343283444643\n",
      "Epoch: 11 -> Test Accuracy: 74.8\n",
      "Epoch: 12 -> Loss: 0.0596515387297\n",
      "Epoch: 12 -> Test Accuracy: 75.48\n",
      "Epoch: 13 -> Loss: 0.119124598801\n",
      "Epoch: 13 -> Test Accuracy: 76.6\n",
      "Epoch: 14 -> Loss: 0.125065654516\n",
      "Epoch: 14 -> Test Accuracy: 75.88\n",
      "Epoch: 15 -> Loss: 0.50246065855\n",
      "Epoch: 15 -> Test Accuracy: 74.63\n",
      "Epoch: 16 -> Loss: 0.171127408743\n",
      "Epoch: 16 -> Test Accuracy: 76.62\n",
      "Epoch: 17 -> Loss: 0.0486190766096\n",
      "Epoch: 17 -> Test Accuracy: 76.21\n",
      "Epoch: 18 -> Loss: 0.196042135358\n",
      "Epoch: 18 -> Test Accuracy: 75.68\n",
      "Epoch: 19 -> Loss: 0.18176870048\n",
      "Epoch: 19 -> Test Accuracy: 75.93\n",
      "Epoch: 20 -> Loss: 0.21883584559\n",
      "Epoch: 20 -> Test Accuracy: 76.08\n",
      "Epoch: 21 -> Loss: 0.124486498535\n",
      "Epoch: 21 -> Test Accuracy: 76.85\n",
      "Epoch: 22 -> Loss: 0.116574935615\n",
      "Epoch: 22 -> Test Accuracy: 76.67\n",
      "Epoch: 23 -> Loss: 0.166994333267\n",
      "Epoch: 23 -> Test Accuracy: 76.28\n",
      "Epoch: 24 -> Loss: 0.0385816693306\n",
      "Epoch: 24 -> Test Accuracy: 76.44\n",
      "Epoch: 25 -> Loss: 0.0303149223328\n",
      "Epoch: 25 -> Test Accuracy: 77.43\n",
      "Epoch: 26 -> Loss: 0.0973063856363\n",
      "Epoch: 26 -> Test Accuracy: 76.32\n",
      "Epoch: 27 -> Loss: 0.172537654638\n",
      "Epoch: 27 -> Test Accuracy: 77.47\n",
      "Epoch: 28 -> Loss: 0.0238407105207\n",
      "Epoch: 28 -> Test Accuracy: 76.29\n",
      "Epoch: 29 -> Loss: 0.023043513298\n",
      "Epoch: 29 -> Test Accuracy: 77.1\n",
      "Epoch: 30 -> Loss: 0.017884016037\n",
      "Epoch: 30 -> Test Accuracy: 77.85\n",
      "Epoch: 31 -> Loss: 0.0668086782098\n",
      "Epoch: 31 -> Test Accuracy: 76.75\n",
      "Epoch: 32 -> Loss: 0.0434112399817\n",
      "Epoch: 32 -> Test Accuracy: 77.42\n",
      "Epoch: 33 -> Loss: 0.213342905045\n",
      "Epoch: 33 -> Test Accuracy: 76.34\n",
      "Epoch: 34 -> Loss: 0.197705253959\n",
      "Epoch: 34 -> Test Accuracy: 75.69\n",
      "Epoch: 35 -> Loss: 0.200658813119\n",
      "Epoch: 35 -> Test Accuracy: 76.85\n",
      "Epoch: 36 -> Loss: 0.0824746415019\n",
      "Epoch: 36 -> Test Accuracy: 78.41\n",
      "Epoch: 37 -> Loss: 0.0295458585024\n",
      "Epoch: 37 -> Test Accuracy: 78.52\n",
      "Epoch: 38 -> Loss: 0.0259458571672\n",
      "Epoch: 38 -> Test Accuracy: 78.92\n",
      "Epoch: 39 -> Loss: 0.0146289616823\n",
      "Epoch: 39 -> Test Accuracy: 78.84\n",
      "Epoch: 40 -> Loss: 0.0123410224915\n",
      "Epoch: 40 -> Test Accuracy: 78.91\n",
      "Epoch: 41 -> Loss: 0.036522179842\n",
      "Epoch: 41 -> Test Accuracy: 78.75\n",
      "Epoch: 42 -> Loss: 0.0169758498669\n",
      "Epoch: 42 -> Test Accuracy: 78.83\n",
      "Epoch: 43 -> Loss: 0.080331876874\n",
      "Epoch: 43 -> Test Accuracy: 78.85\n",
      "Epoch: 44 -> Loss: 0.00580006837845\n",
      "Epoch: 44 -> Test Accuracy: 78.79\n",
      "Epoch: 45 -> Loss: 0.0257037431002\n",
      "Epoch: 45 -> Test Accuracy: 79.12\n",
      "Epoch: 46 -> Loss: 0.0312541276217\n",
      "Epoch: 46 -> Test Accuracy: 78.85\n",
      "Epoch: 47 -> Loss: 0.0132047384977\n",
      "Epoch: 47 -> Test Accuracy: 78.98\n",
      "Epoch: 48 -> Loss: 0.020357131958\n",
      "Epoch: 48 -> Test Accuracy: 79.0\n",
      "Epoch: 49 -> Loss: 0.0179976373911\n",
      "Epoch: 49 -> Test Accuracy: 78.95\n",
      "Epoch: 50 -> Loss: 0.00579857826233\n",
      "Epoch: 50 -> Test Accuracy: 78.86\n",
      "Epoch: 51 -> Loss: 0.00544239580631\n",
      "Epoch: 51 -> Test Accuracy: 78.97\n",
      "Epoch: 52 -> Loss: 0.0719033628702\n",
      "Epoch: 52 -> Test Accuracy: 78.8\n",
      "Epoch: 53 -> Loss: 0.0356164202094\n",
      "Epoch: 53 -> Test Accuracy: 78.77\n",
      "Epoch: 54 -> Loss: 0.0360272526741\n",
      "Epoch: 54 -> Test Accuracy: 79.01\n",
      "Epoch: 55 -> Loss: 0.0140759199858\n",
      "Epoch: 55 -> Test Accuracy: 78.94\n",
      "Epoch: 56 -> Loss: 0.00754779577255\n",
      "Epoch: 56 -> Test Accuracy: 78.97\n",
      "Epoch: 57 -> Loss: 0.0533907711506\n",
      "Epoch: 57 -> Test Accuracy: 78.83\n",
      "Epoch: 58 -> Loss: 0.0102167576551\n",
      "Epoch: 58 -> Test Accuracy: 78.76\n",
      "Epoch: 59 -> Loss: 0.0273775458336\n",
      "Epoch: 59 -> Test Accuracy: 78.84\n",
      "Epoch: 60 -> Loss: 0.00740957260132\n",
      "Epoch: 60 -> Test Accuracy: 78.83\n",
      "Epoch: 61 -> Loss: 0.0191149264574\n",
      "Epoch: 61 -> Test Accuracy: 78.88\n",
      "Epoch: 62 -> Loss: 0.0263730809093\n",
      "Epoch: 62 -> Test Accuracy: 78.8\n",
      "Epoch: 63 -> Loss: 0.0142485499382\n",
      "Epoch: 63 -> Test Accuracy: 79.16\n",
      "Epoch: 64 -> Loss: 0.0174070000648\n",
      "Epoch: 64 -> Test Accuracy: 78.91\n",
      "Epoch: 65 -> Loss: 0.00691521167755\n",
      "Epoch: 65 -> Test Accuracy: 78.96\n",
      "Epoch: 66 -> Loss: 0.009924441576\n",
      "Epoch: 66 -> Test Accuracy: 78.91\n",
      "Epoch: 67 -> Loss: 0.042328171432\n",
      "Epoch: 67 -> Test Accuracy: 78.83\n",
      "Epoch: 68 -> Loss: 0.0174216628075\n",
      "Epoch: 68 -> Test Accuracy: 78.83\n",
      "Epoch: 69 -> Loss: 0.105877205729\n",
      "Epoch: 69 -> Test Accuracy: 78.59\n",
      "Epoch: 70 -> Loss: 0.00894872844219\n",
      "Epoch: 70 -> Test Accuracy: 78.65\n",
      "Epoch: 71 -> Loss: 0.018729403615\n",
      "Epoch: 71 -> Test Accuracy: 78.7\n",
      "Epoch: 72 -> Loss: 0.0586016476154\n",
      "Epoch: 72 -> Test Accuracy: 78.67\n",
      "Epoch: 73 -> Loss: 0.020110309124\n",
      "Epoch: 73 -> Test Accuracy: 78.79\n",
      "Epoch: 74 -> Loss: 0.047985330224\n",
      "Epoch: 74 -> Test Accuracy: 78.8\n",
      "Epoch: 75 -> Loss: 0.0393522754312\n",
      "Epoch: 75 -> Test Accuracy: 78.92\n",
      "Epoch: 76 -> Loss: 0.011761084199\n",
      "Epoch: 76 -> Test Accuracy: 78.9\n",
      "Epoch: 77 -> Loss: 0.0363613069057\n",
      "Epoch: 77 -> Test Accuracy: 78.91\n",
      "Epoch: 78 -> Loss: 0.0158055126667\n",
      "Epoch: 78 -> Test Accuracy: 78.87\n",
      "Epoch: 79 -> Loss: 0.0719065219164\n",
      "Epoch: 79 -> Test Accuracy: 78.8\n",
      "Epoch: 80 -> Loss: 0.0167437791824\n",
      "Epoch: 80 -> Test Accuracy: 78.81\n",
      "Epoch: 81 -> Loss: 0.0118113011122\n",
      "Epoch: 81 -> Test Accuracy: 78.85\n",
      "Epoch: 82 -> Loss: 0.0512816011906\n",
      "Epoch: 82 -> Test Accuracy: 78.76\n",
      "Epoch: 83 -> Loss: 0.0250134915113\n",
      "Epoch: 83 -> Test Accuracy: 78.8\n",
      "Epoch: 84 -> Loss: 0.049402281642\n",
      "Epoch: 84 -> Test Accuracy: 78.81\n",
      "Epoch: 85 -> Loss: 0.032021805644\n",
      "Epoch: 85 -> Test Accuracy: 78.77\n",
      "Epoch: 86 -> Loss: 0.0591614544392\n",
      "Epoch: 86 -> Test Accuracy: 78.78\n",
      "Epoch: 87 -> Loss: 0.00436550378799\n",
      "Epoch: 87 -> Test Accuracy: 78.76\n",
      "Epoch: 88 -> Loss: 0.00413736701012\n",
      "Epoch: 88 -> Test Accuracy: 78.78\n",
      "Epoch: 89 -> Loss: 0.00571598112583\n",
      "Epoch: 89 -> Test Accuracy: 78.77\n",
      "Epoch: 90 -> Loss: 0.00786285102367\n",
      "Epoch: 90 -> Test Accuracy: 78.77\n",
      "Epoch: 91 -> Loss: 0.0283974856138\n",
      "Epoch: 91 -> Test Accuracy: 78.79\n",
      "Epoch: 92 -> Loss: 0.00824975967407\n",
      "Epoch: 92 -> Test Accuracy: 78.77\n",
      "Epoch: 93 -> Loss: 0.272505551577\n",
      "Epoch: 93 -> Test Accuracy: 78.8\n",
      "Epoch: 94 -> Loss: 0.0240275412798\n",
      "Epoch: 94 -> Test Accuracy: 78.82\n",
      "Epoch: 95 -> Loss: 0.0713768228889\n",
      "Epoch: 95 -> Test Accuracy: 78.84\n",
      "Epoch: 96 -> Loss: 0.0273525565863\n",
      "Epoch: 96 -> Test Accuracy: 78.88\n",
      "Epoch: 97 -> Loss: 0.0251575261354\n",
      "Epoch: 97 -> Test Accuracy: 78.89\n",
      "Epoch: 98 -> Loss: 0.0300183296204\n",
      "Epoch: 98 -> Test Accuracy: 78.84\n",
      "Epoch: 99 -> Loss: 0.0294151604176\n",
      "Epoch: 99 -> Test Accuracy: 78.87\n",
      "Epoch: 100 -> Loss: 0.0810821652412\n",
      "Epoch: 100 -> Test Accuracy: 78.86\n",
      "Finished Training\n",
      "Epoch: 1 -> Loss: 1.99176597595\n",
      "Epoch: 1 -> Test Accuracy: 29.24\n",
      "Epoch: 2 -> Loss: 1.36076033115\n",
      "Epoch: 2 -> Test Accuracy: 36.62\n",
      "Epoch: 3 -> Loss: 1.45828318596\n",
      "Epoch: 3 -> Test Accuracy: 40.9\n",
      "Epoch: 4 -> Loss: 1.42562747002\n",
      "Epoch: 4 -> Test Accuracy: 41.9\n",
      "Epoch: 5 -> Loss: 1.14608263969\n",
      "Epoch: 5 -> Test Accuracy: 47.33\n",
      "Epoch: 6 -> Loss: 1.01060605049\n",
      "Epoch: 6 -> Test Accuracy: 46.88\n",
      "Epoch: 7 -> Loss: 1.14130747318\n",
      "Epoch: 7 -> Test Accuracy: 51.47\n",
      "Epoch: 8 -> Loss: 1.17780685425\n",
      "Epoch: 8 -> Test Accuracy: 54.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 -> Loss: 1.1194473505\n",
      "Epoch: 9 -> Test Accuracy: 55.24\n",
      "Epoch: 10 -> Loss: 1.0874222517\n",
      "Epoch: 10 -> Test Accuracy: 50.62\n",
      "Epoch: 11 -> Loss: 0.801134228706\n",
      "Epoch: 11 -> Test Accuracy: 56.34\n",
      "Epoch: 12 -> Loss: 0.841047048569\n",
      "Epoch: 12 -> Test Accuracy: 56.33\n",
      "Epoch: 13 -> Loss: 1.09872746468\n",
      "Epoch: 13 -> Test Accuracy: 58.92\n",
      "Epoch: 14 -> Loss: 1.0185174942\n",
      "Epoch: 14 -> Test Accuracy: 59.76\n",
      "Epoch: 15 -> Loss: 1.05079221725\n",
      "Epoch: 15 -> Test Accuracy: 56.51\n",
      "Epoch: 16 -> Loss: 0.874284565449\n",
      "Epoch: 16 -> Test Accuracy: 60.92\n",
      "Epoch: 17 -> Loss: 1.00002765656\n",
      "Epoch: 17 -> Test Accuracy: 58.71\n",
      "Epoch: 18 -> Loss: 0.871154427528\n",
      "Epoch: 18 -> Test Accuracy: 61.15\n",
      "Epoch: 19 -> Loss: 0.575191140175\n",
      "Epoch: 19 -> Test Accuracy: 60.51\n",
      "Epoch: 20 -> Loss: 0.544365167618\n",
      "Epoch: 20 -> Test Accuracy: 62.08\n",
      "Epoch: 21 -> Loss: 0.679085850716\n",
      "Epoch: 21 -> Test Accuracy: 62.25\n",
      "Epoch: 22 -> Loss: 0.568395912647\n",
      "Epoch: 22 -> Test Accuracy: 61.76\n",
      "Epoch: 23 -> Loss: 0.643550157547\n",
      "Epoch: 23 -> Test Accuracy: 60.44\n",
      "Epoch: 24 -> Loss: 0.482303321362\n",
      "Epoch: 24 -> Test Accuracy: 62.46\n",
      "Epoch: 25 -> Loss: 0.697788894176\n",
      "Epoch: 25 -> Test Accuracy: 60.23\n",
      "Epoch: 26 -> Loss: 0.637454628944\n",
      "Epoch: 26 -> Test Accuracy: 63.13\n",
      "Epoch: 27 -> Loss: 0.462010145187\n",
      "Epoch: 27 -> Test Accuracy: 62.95\n",
      "Epoch: 28 -> Loss: 0.481016933918\n",
      "Epoch: 28 -> Test Accuracy: 59.49\n",
      "Epoch: 29 -> Loss: 0.598208725452\n",
      "Epoch: 29 -> Test Accuracy: 63.78\n",
      "Epoch: 30 -> Loss: 0.688030481339\n",
      "Epoch: 30 -> Test Accuracy: 62.76\n",
      "Epoch: 31 -> Loss: 0.682828366756\n",
      "Epoch: 31 -> Test Accuracy: 62.99\n",
      "Epoch: 32 -> Loss: 0.322947919369\n",
      "Epoch: 32 -> Test Accuracy: 66.36\n",
      "Epoch: 33 -> Loss: 1.02523601055\n",
      "Epoch: 33 -> Test Accuracy: 59.3\n",
      "Epoch: 34 -> Loss: 0.756962418556\n",
      "Epoch: 34 -> Test Accuracy: 64.66\n",
      "Epoch: 35 -> Loss: 0.388144999743\n",
      "Epoch: 35 -> Test Accuracy: 63.1\n",
      "Epoch: 36 -> Loss: 0.38250246644\n",
      "Epoch: 36 -> Test Accuracy: 64.58\n",
      "Epoch: 37 -> Loss: 0.311292886734\n",
      "Epoch: 37 -> Test Accuracy: 65.19\n",
      "Epoch: 38 -> Loss: 0.924100458622\n",
      "Epoch: 38 -> Test Accuracy: 63.89\n",
      "Epoch: 39 -> Loss: 0.400578439236\n",
      "Epoch: 39 -> Test Accuracy: 61.79\n",
      "Epoch: 40 -> Loss: 0.488262623549\n",
      "Epoch: 40 -> Test Accuracy: 62.69\n",
      "Epoch: 41 -> Loss: 0.461495637894\n",
      "Epoch: 41 -> Test Accuracy: 65.23\n",
      "Epoch: 42 -> Loss: 0.602663636208\n",
      "Epoch: 42 -> Test Accuracy: 66.6\n",
      "Epoch: 43 -> Loss: 0.587162494659\n",
      "Epoch: 43 -> Test Accuracy: 65.04\n",
      "Epoch: 44 -> Loss: 0.204404994845\n",
      "Epoch: 44 -> Test Accuracy: 66.11\n",
      "Epoch: 45 -> Loss: 0.267689794302\n",
      "Epoch: 45 -> Test Accuracy: 65.07\n",
      "Epoch: 46 -> Loss: 0.175919741392\n",
      "Epoch: 46 -> Test Accuracy: 66.16\n",
      "Epoch: 47 -> Loss: 0.243935346603\n",
      "Epoch: 47 -> Test Accuracy: 66.94\n",
      "Epoch: 48 -> Loss: 0.329679936171\n",
      "Epoch: 48 -> Test Accuracy: 66.45\n",
      "Epoch: 49 -> Loss: 0.396349549294\n",
      "Epoch: 49 -> Test Accuracy: 65.23\n",
      "Epoch: 50 -> Loss: 0.388061523438\n",
      "Epoch: 50 -> Test Accuracy: 65.12\n",
      "Epoch: 51 -> Loss: 0.261760741472\n",
      "Epoch: 51 -> Test Accuracy: 64.66\n",
      "Epoch: 52 -> Loss: 0.218246594071\n",
      "Epoch: 52 -> Test Accuracy: 66.37\n",
      "Epoch: 53 -> Loss: 0.51573073864\n",
      "Epoch: 53 -> Test Accuracy: 67.25\n",
      "Epoch: 54 -> Loss: 0.201220452785\n",
      "Epoch: 54 -> Test Accuracy: 67.65\n",
      "Epoch: 55 -> Loss: 0.294989287853\n",
      "Epoch: 55 -> Test Accuracy: 66.35\n",
      "Epoch: 56 -> Loss: 0.358420073986\n",
      "Epoch: 56 -> Test Accuracy: 64.84\n",
      "Epoch: 57 -> Loss: 0.152656644583\n",
      "Epoch: 57 -> Test Accuracy: 67.46\n",
      "Epoch: 58 -> Loss: 0.152692556381\n",
      "Epoch: 58 -> Test Accuracy: 68.57\n",
      "Epoch: 59 -> Loss: 0.307595133781\n",
      "Epoch: 59 -> Test Accuracy: 68.94\n",
      "Epoch: 60 -> Loss: 0.296410828829\n",
      "Epoch: 60 -> Test Accuracy: 66.63\n",
      "Epoch: 61 -> Loss: 0.211256444454\n",
      "Epoch: 61 -> Test Accuracy: 70.92\n",
      "Epoch: 62 -> Loss: 0.0882220342755\n",
      "Epoch: 62 -> Test Accuracy: 71.46\n",
      "Epoch: 63 -> Loss: 0.075991243124\n",
      "Epoch: 63 -> Test Accuracy: 71.7\n",
      "Epoch: 64 -> Loss: 0.0443870723248\n",
      "Epoch: 64 -> Test Accuracy: 71.46\n",
      "Epoch: 65 -> Loss: 0.0396638661623\n",
      "Epoch: 65 -> Test Accuracy: 71.5\n",
      "Epoch: 66 -> Loss: 0.101876631379\n",
      "Epoch: 66 -> Test Accuracy: 71.29\n",
      "Epoch: 67 -> Loss: 0.0169695466757\n",
      "Epoch: 67 -> Test Accuracy: 71.65\n",
      "Epoch: 68 -> Loss: 0.148661330342\n",
      "Epoch: 68 -> Test Accuracy: 71.54\n",
      "Epoch: 69 -> Loss: 0.0809916555882\n",
      "Epoch: 69 -> Test Accuracy: 71.37\n",
      "Epoch: 70 -> Loss: 0.0453627556562\n",
      "Epoch: 70 -> Test Accuracy: 71.04\n",
      "Epoch: 71 -> Loss: 0.0114609897137\n",
      "Epoch: 71 -> Test Accuracy: 71.31\n",
      "Epoch: 72 -> Loss: 0.0444956868887\n",
      "Epoch: 72 -> Test Accuracy: 71.67\n",
      "Epoch: 73 -> Loss: 0.0149751678109\n",
      "Epoch: 73 -> Test Accuracy: 71.23\n",
      "Epoch: 74 -> Loss: 0.0284271240234\n",
      "Epoch: 74 -> Test Accuracy: 70.94\n",
      "Epoch: 75 -> Loss: 0.0826717987657\n",
      "Epoch: 75 -> Test Accuracy: 71.32\n",
      "Epoch: 76 -> Loss: 0.00849987566471\n",
      "Epoch: 76 -> Test Accuracy: 71.28\n",
      "Epoch: 77 -> Loss: 0.0587046742439\n",
      "Epoch: 77 -> Test Accuracy: 71.58\n",
      "Epoch: 78 -> Loss: 0.159832373261\n",
      "Epoch: 78 -> Test Accuracy: 71.2\n",
      "Epoch: 79 -> Loss: 0.0400970652699\n",
      "Epoch: 79 -> Test Accuracy: 71.53\n",
      "Epoch: 80 -> Loss: 0.0157641619444\n",
      "Epoch: 80 -> Test Accuracy: 72.07\n",
      "Epoch: 81 -> Loss: 0.00981138646603\n",
      "Epoch: 81 -> Test Accuracy: 71.57\n",
      "Epoch: 82 -> Loss: 0.00516906380653\n",
      "Epoch: 82 -> Test Accuracy: 71.48\n",
      "Epoch: 83 -> Loss: 0.0189691483974\n",
      "Epoch: 83 -> Test Accuracy: 71.06\n",
      "Epoch: 84 -> Loss: 0.00928276777267\n",
      "Epoch: 84 -> Test Accuracy: 71.07\n",
      "Epoch: 85 -> Loss: 0.0211859941483\n",
      "Epoch: 85 -> Test Accuracy: 71.2\n",
      "Epoch: 86 -> Loss: 0.0132207274437\n",
      "Epoch: 86 -> Test Accuracy: 71.09\n",
      "Epoch: 87 -> Loss: 0.0292555391788\n",
      "Epoch: 87 -> Test Accuracy: 71.58\n",
      "Epoch: 88 -> Loss: 0.0146893560886\n",
      "Epoch: 88 -> Test Accuracy: 71.34\n",
      "Epoch: 89 -> Loss: 0.0129366517067\n",
      "Epoch: 89 -> Test Accuracy: 71.83\n",
      "Epoch: 90 -> Loss: 0.0163704231381\n",
      "Epoch: 90 -> Test Accuracy: 71.06\n",
      "Epoch: 91 -> Loss: 0.0103717595339\n",
      "Epoch: 91 -> Test Accuracy: 71.18\n",
      "Epoch: 92 -> Loss: 0.0801379457116\n",
      "Epoch: 92 -> Test Accuracy: 71.22\n",
      "Epoch: 93 -> Loss: 0.00827842950821\n",
      "Epoch: 93 -> Test Accuracy: 71.47\n",
      "Epoch: 94 -> Loss: 0.026276320219\n",
      "Epoch: 94 -> Test Accuracy: 71.39\n",
      "Epoch: 95 -> Loss: 0.0190530866385\n",
      "Epoch: 95 -> Test Accuracy: 71.75\n",
      "Epoch: 96 -> Loss: 0.116545259953\n",
      "Epoch: 96 -> Test Accuracy: 71.52\n",
      "Epoch: 97 -> Loss: 0.0872508585453\n",
      "Epoch: 97 -> Test Accuracy: 71.45\n",
      "Epoch: 98 -> Loss: 0.00737568736076\n",
      "Epoch: 98 -> Test Accuracy: 71.33\n",
      "Epoch: 99 -> Loss: 0.00239384174347\n",
      "Epoch: 99 -> Test Accuracy: 71.39\n",
      "Epoch: 100 -> Loss: 0.0297908559442\n",
      "Epoch: 100 -> Test Accuracy: 71.42\n",
      "Epoch: 101 -> Loss: 0.014688834548\n",
      "Epoch: 101 -> Test Accuracy: 71.2\n",
      "Epoch: 102 -> Loss: 0.00511446595192\n",
      "Epoch: 102 -> Test Accuracy: 71.3\n",
      "Epoch: 103 -> Loss: 0.0145294368267\n",
      "Epoch: 103 -> Test Accuracy: 71.17\n",
      "Epoch: 104 -> Loss: 0.00756520032883\n",
      "Epoch: 104 -> Test Accuracy: 71.56\n",
      "Epoch: 105 -> Loss: 0.00991412997246\n",
      "Epoch: 105 -> Test Accuracy: 71.38\n",
      "Epoch: 106 -> Loss: 0.0208507329226\n",
      "Epoch: 106 -> Test Accuracy: 71.31\n",
      "Epoch: 107 -> Loss: 0.0443057715893\n",
      "Epoch: 107 -> Test Accuracy: 71.19\n",
      "Epoch: 108 -> Loss: 0.01333335042\n",
      "Epoch: 108 -> Test Accuracy: 71.26\n",
      "Epoch: 109 -> Loss: 0.0127560347319\n",
      "Epoch: 109 -> Test Accuracy: 71.41\n",
      "Epoch: 110 -> Loss: 0.0222973525524\n",
      "Epoch: 110 -> Test Accuracy: 71.24\n",
      "Epoch: 111 -> Loss: 0.264614462852\n",
      "Epoch: 111 -> Test Accuracy: 71.05\n",
      "Epoch: 112 -> Loss: 0.0678313076496\n",
      "Epoch: 112 -> Test Accuracy: 70.57\n",
      "Epoch: 113 -> Loss: 0.0274949967861\n",
      "Epoch: 113 -> Test Accuracy: 70.69\n",
      "Epoch: 114 -> Loss: 0.0103445649147\n",
      "Epoch: 114 -> Test Accuracy: 70.51\n",
      "Epoch: 115 -> Loss: 0.0251030623913\n",
      "Epoch: 115 -> Test Accuracy: 70.73\n",
      "Epoch: 116 -> Loss: 0.0276616066694\n",
      "Epoch: 116 -> Test Accuracy: 71.01\n",
      "Epoch: 117 -> Loss: 0.0186435580254\n",
      "Epoch: 117 -> Test Accuracy: 71.04\n",
      "Epoch: 118 -> Loss: 0.0408878177404\n",
      "Epoch: 118 -> Test Accuracy: 71.22\n",
      "Epoch: 119 -> Loss: 0.0200499594212\n",
      "Epoch: 119 -> Test Accuracy: 71.46\n",
      "Epoch: 120 -> Loss: 0.0320639908314\n",
      "Epoch: 120 -> Test Accuracy: 71.08\n",
      "Epoch: 121 -> Loss: 0.00658909976482\n",
      "Epoch: 121 -> Test Accuracy: 71.19\n",
      "Epoch: 122 -> Loss: 0.00748679041862\n",
      "Epoch: 122 -> Test Accuracy: 71.16\n",
      "Epoch: 123 -> Loss: 0.00614309310913\n",
      "Epoch: 123 -> Test Accuracy: 71.14\n",
      "Epoch: 124 -> Loss: 0.0056467205286\n",
      "Epoch: 124 -> Test Accuracy: 71.29\n",
      "Epoch: 125 -> Loss: 0.048030488193\n",
      "Epoch: 125 -> Test Accuracy: 71.43\n",
      "Epoch: 126 -> Loss: 0.0152081400156\n",
      "Epoch: 126 -> Test Accuracy: 71.35\n",
      "Epoch: 127 -> Loss: 0.0074890255928\n",
      "Epoch: 127 -> Test Accuracy: 71.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 128 -> Loss: 0.0064785182476\n",
      "Epoch: 128 -> Test Accuracy: 71.59\n",
      "Epoch: 129 -> Loss: 0.00232408940792\n",
      "Epoch: 129 -> Test Accuracy: 71.64\n",
      "Epoch: 130 -> Loss: 0.0267313420773\n",
      "Epoch: 130 -> Test Accuracy: 71.66\n",
      "Epoch: 131 -> Loss: 0.00780560076237\n",
      "Epoch: 131 -> Test Accuracy: 71.62\n",
      "Epoch: 132 -> Loss: 0.00449998676777\n",
      "Epoch: 132 -> Test Accuracy: 71.54\n",
      "Epoch: 133 -> Loss: 0.0210587531328\n",
      "Epoch: 133 -> Test Accuracy: 71.62\n",
      "Epoch: 134 -> Loss: 0.0115064829588\n",
      "Epoch: 134 -> Test Accuracy: 71.66\n",
      "Epoch: 135 -> Loss: 0.0174776762724\n",
      "Epoch: 135 -> Test Accuracy: 71.78\n",
      "Epoch: 136 -> Loss: 0.0617851167917\n",
      "Epoch: 136 -> Test Accuracy: 71.74\n",
      "Epoch: 137 -> Loss: 0.155162021518\n",
      "Epoch: 137 -> Test Accuracy: 71.6\n",
      "Epoch: 138 -> Loss: 0.00836832821369\n",
      "Epoch: 138 -> Test Accuracy: 71.27\n",
      "Epoch: 139 -> Loss: 0.0279927253723\n",
      "Epoch: 139 -> Test Accuracy: 71.26\n",
      "Epoch: 140 -> Loss: 0.0139201581478\n",
      "Epoch: 140 -> Test Accuracy: 71.32\n",
      "Epoch: 141 -> Loss: 0.0322176292539\n",
      "Epoch: 141 -> Test Accuracy: 71.35\n",
      "Epoch: 142 -> Loss: 0.0338862985373\n",
      "Epoch: 142 -> Test Accuracy: 71.5\n",
      "Epoch: 143 -> Loss: 0.0119145065546\n",
      "Epoch: 143 -> Test Accuracy: 71.48\n",
      "Epoch: 144 -> Loss: 0.0145933926105\n",
      "Epoch: 144 -> Test Accuracy: 71.52\n",
      "Epoch: 145 -> Loss: 0.00454692542553\n",
      "Epoch: 145 -> Test Accuracy: 71.59\n",
      "Epoch: 146 -> Loss: 0.0254308879375\n",
      "Epoch: 146 -> Test Accuracy: 71.55\n",
      "Epoch: 147 -> Loss: 0.00879219174385\n",
      "Epoch: 147 -> Test Accuracy: 71.61\n",
      "Epoch: 148 -> Loss: 0.0339777171612\n",
      "Epoch: 148 -> Test Accuracy: 71.7\n",
      "Epoch: 149 -> Loss: 0.00774623453617\n",
      "Epoch: 149 -> Test Accuracy: 71.51\n",
      "Epoch: 150 -> Loss: 0.010976716876\n",
      "Epoch: 150 -> Test Accuracy: 71.5\n",
      "Epoch: 151 -> Loss: 0.156375706196\n",
      "Epoch: 151 -> Test Accuracy: 71.46\n",
      "Epoch: 152 -> Loss: 0.00997626781464\n",
      "Epoch: 152 -> Test Accuracy: 71.27\n",
      "Epoch: 153 -> Loss: 0.0347768366337\n",
      "Epoch: 153 -> Test Accuracy: 71.29\n",
      "Epoch: 154 -> Loss: 0.00833851099014\n",
      "Epoch: 154 -> Test Accuracy: 71.23\n",
      "Epoch: 155 -> Loss: 0.0548955649137\n",
      "Epoch: 155 -> Test Accuracy: 71.26\n",
      "Epoch: 156 -> Loss: 0.0096345692873\n",
      "Epoch: 156 -> Test Accuracy: 71.39\n",
      "Epoch: 157 -> Loss: 0.0166476964951\n",
      "Epoch: 157 -> Test Accuracy: 71.33\n",
      "Epoch: 158 -> Loss: 0.00523549318314\n",
      "Epoch: 158 -> Test Accuracy: 71.43\n",
      "Epoch: 159 -> Loss: 0.00567774474621\n",
      "Epoch: 159 -> Test Accuracy: 71.43\n",
      "Epoch: 160 -> Loss: 0.0100941509008\n",
      "Epoch: 160 -> Test Accuracy: 71.37\n",
      "Epoch: 161 -> Loss: 0.00751079618931\n",
      "Epoch: 161 -> Test Accuracy: 71.42\n",
      "Epoch: 162 -> Loss: 0.0310110747814\n",
      "Epoch: 162 -> Test Accuracy: 71.43\n",
      "Epoch: 163 -> Loss: 0.168790325522\n",
      "Epoch: 163 -> Test Accuracy: 71.44\n",
      "Epoch: 164 -> Loss: 0.0329375714064\n",
      "Epoch: 164 -> Test Accuracy: 71.46\n",
      "Epoch: 165 -> Loss: 0.0122923702002\n",
      "Epoch: 165 -> Test Accuracy: 71.44\n",
      "Epoch: 166 -> Loss: 0.00423537194729\n",
      "Epoch: 166 -> Test Accuracy: 71.45\n",
      "Epoch: 167 -> Loss: 0.0302345603704\n",
      "Epoch: 167 -> Test Accuracy: 71.47\n",
      "Epoch: 168 -> Loss: 0.0929442048073\n",
      "Epoch: 168 -> Test Accuracy: 71.53\n",
      "Epoch: 169 -> Loss: 0.00687873363495\n",
      "Epoch: 169 -> Test Accuracy: 71.46\n",
      "Epoch: 170 -> Loss: 0.0444523245096\n",
      "Epoch: 170 -> Test Accuracy: 71.49\n",
      "Epoch: 171 -> Loss: 0.0615257620811\n",
      "Epoch: 171 -> Test Accuracy: 71.5\n",
      "Epoch: 172 -> Loss: 0.00952957570553\n",
      "Epoch: 172 -> Test Accuracy: 71.53\n",
      "Epoch: 173 -> Loss: 0.00535207986832\n",
      "Epoch: 173 -> Test Accuracy: 71.49\n",
      "Epoch: 174 -> Loss: 0.0524493902922\n",
      "Epoch: 174 -> Test Accuracy: 71.55\n",
      "Epoch: 175 -> Loss: 0.00484512746334\n",
      "Epoch: 175 -> Test Accuracy: 71.54\n",
      "Epoch: 176 -> Loss: 0.0273762494326\n",
      "Epoch: 176 -> Test Accuracy: 71.6\n",
      "Epoch: 177 -> Loss: 0.0198364257812\n",
      "Epoch: 177 -> Test Accuracy: 71.54\n",
      "Epoch: 178 -> Loss: 0.0153575986624\n",
      "Epoch: 178 -> Test Accuracy: 71.54\n",
      "Epoch: 179 -> Loss: 0.0143886655569\n",
      "Epoch: 179 -> Test Accuracy: 71.48\n",
      "Epoch: 180 -> Loss: 0.0247615873814\n",
      "Epoch: 180 -> Test Accuracy: 71.43\n",
      "Epoch: 181 -> Loss: 0.108251996338\n",
      "Epoch: 181 -> Test Accuracy: 71.51\n",
      "Epoch: 182 -> Loss: 0.00833128392696\n",
      "Epoch: 182 -> Test Accuracy: 71.51\n",
      "Epoch: 183 -> Loss: 0.00940936803818\n",
      "Epoch: 183 -> Test Accuracy: 71.45\n",
      "Epoch: 184 -> Loss: 0.00224831700325\n",
      "Epoch: 184 -> Test Accuracy: 71.5\n",
      "Epoch: 185 -> Loss: 0.00907221436501\n",
      "Epoch: 185 -> Test Accuracy: 71.48\n",
      "Epoch: 186 -> Loss: 0.00817878544331\n",
      "Epoch: 186 -> Test Accuracy: 71.52\n",
      "Epoch: 187 -> Loss: 0.0067912042141\n",
      "Epoch: 187 -> Test Accuracy: 71.5\n",
      "Epoch: 188 -> Loss: 0.00502680242062\n",
      "Epoch: 188 -> Test Accuracy: 71.47\n",
      "Epoch: 189 -> Loss: 0.0425862371922\n",
      "Epoch: 189 -> Test Accuracy: 71.43\n",
      "Epoch: 190 -> Loss: 0.0113620012999\n",
      "Epoch: 190 -> Test Accuracy: 71.46\n",
      "Epoch: 191 -> Loss: 0.0240911394358\n",
      "Epoch: 191 -> Test Accuracy: 71.45\n",
      "Epoch: 192 -> Loss: 0.00469319522381\n",
      "Epoch: 192 -> Test Accuracy: 71.47\n",
      "Epoch: 193 -> Loss: 0.0109018981457\n",
      "Epoch: 193 -> Test Accuracy: 71.51\n",
      "Epoch: 194 -> Loss: 0.0232766866684\n",
      "Epoch: 194 -> Test Accuracy: 71.5\n",
      "Epoch: 195 -> Loss: 0.00562258064747\n",
      "Epoch: 195 -> Test Accuracy: 71.52\n",
      "Epoch: 196 -> Loss: 0.159997433424\n",
      "Epoch: 196 -> Test Accuracy: 71.43\n",
      "Epoch: 197 -> Loss: 0.0105831176043\n",
      "Epoch: 197 -> Test Accuracy: 71.5\n",
      "Epoch: 198 -> Loss: 0.0154107958078\n",
      "Epoch: 198 -> Test Accuracy: 71.53\n",
      "Epoch: 199 -> Loss: 0.117458090186\n",
      "Epoch: 199 -> Test Accuracy: 71.53\n",
      "Epoch: 200 -> Loss: 0.0241212397814\n",
      "Epoch: 200 -> Test Accuracy: 71.51\n",
      "Finished Training\n",
      "[1, 60] loss: 0.938\n",
      "Epoch: 1 -> Loss: 1.18767702579\n",
      "Epoch: 1 -> Test Accuracy: 73.45\n",
      "[2, 60] loss: 0.567\n",
      "Epoch: 2 -> Loss: 0.442924886942\n",
      "Epoch: 2 -> Test Accuracy: 76.33\n",
      "[3, 60] loss: 0.483\n",
      "Epoch: 3 -> Loss: 0.717516720295\n",
      "Epoch: 3 -> Test Accuracy: 76.23\n",
      "[4, 60] loss: 0.433\n",
      "Epoch: 4 -> Loss: 1.12348794937\n",
      "Epoch: 4 -> Test Accuracy: 75.46\n",
      "[5, 60] loss: 0.413\n",
      "Epoch: 5 -> Loss: 0.167875885963\n",
      "Epoch: 5 -> Test Accuracy: 78.28\n",
      "[6, 60] loss: 0.350\n",
      "Epoch: 6 -> Loss: 0.419703215361\n",
      "Epoch: 6 -> Test Accuracy: 78.87\n",
      "[7, 60] loss: 0.336\n",
      "Epoch: 7 -> Loss: 0.142131671309\n",
      "Epoch: 7 -> Test Accuracy: 79.34\n",
      "[8, 60] loss: 0.294\n",
      "Epoch: 8 -> Loss: 0.451493293047\n",
      "Epoch: 8 -> Test Accuracy: 78.73\n",
      "[9, 60] loss: 0.286\n",
      "Epoch: 9 -> Loss: 0.210499435663\n",
      "Epoch: 9 -> Test Accuracy: 78.45\n",
      "[10, 60] loss: 0.254\n",
      "Epoch: 10 -> Loss: 0.592295050621\n",
      "Epoch: 10 -> Test Accuracy: 79.32\n",
      "[11, 60] loss: 0.248\n",
      "Epoch: 11 -> Loss: 0.227784648538\n",
      "Epoch: 11 -> Test Accuracy: 79.1\n",
      "[12, 60] loss: 0.223\n",
      "Epoch: 12 -> Loss: 0.380731523037\n",
      "Epoch: 12 -> Test Accuracy: 77.65\n",
      "[13, 60] loss: 0.217\n",
      "Epoch: 13 -> Loss: 0.130041062832\n",
      "Epoch: 13 -> Test Accuracy: 78.23\n",
      "[14, 60] loss: 0.201\n",
      "Epoch: 14 -> Loss: 0.474431216717\n",
      "Epoch: 14 -> Test Accuracy: 78.97\n",
      "[15, 60] loss: 0.209\n",
      "Epoch: 15 -> Loss: 0.336907446384\n",
      "Epoch: 15 -> Test Accuracy: 78.77\n",
      "[16, 60] loss: 0.194\n",
      "Epoch: 16 -> Loss: 0.151825621724\n",
      "Epoch: 16 -> Test Accuracy: 79.16\n",
      "[17, 60] loss: 0.173\n",
      "Epoch: 17 -> Loss: 0.238361611962\n",
      "Epoch: 17 -> Test Accuracy: 79.47\n",
      "[18, 60] loss: 0.169\n",
      "Epoch: 18 -> Loss: 0.118225902319\n",
      "Epoch: 18 -> Test Accuracy: 78.35\n",
      "[19, 60] loss: 0.162\n",
      "Epoch: 19 -> Loss: 0.048670232296\n",
      "Epoch: 19 -> Test Accuracy: 80.9\n",
      "[20, 60] loss: 0.130\n",
      "Epoch: 20 -> Loss: 0.0954020321369\n",
      "Epoch: 20 -> Test Accuracy: 79.25\n",
      "[21, 60] loss: 0.133\n",
      "Epoch: 21 -> Loss: 0.143276453018\n",
      "Epoch: 21 -> Test Accuracy: 79.72\n",
      "[22, 60] loss: 0.138\n",
      "Epoch: 22 -> Loss: 0.316691607237\n",
      "Epoch: 22 -> Test Accuracy: 78.32\n",
      "[23, 60] loss: 0.154\n",
      "Epoch: 23 -> Loss: 0.187384366989\n",
      "Epoch: 23 -> Test Accuracy: 79.16\n",
      "[24, 60] loss: 0.136\n",
      "Epoch: 24 -> Loss: 0.630028963089\n",
      "Epoch: 24 -> Test Accuracy: 77.28\n",
      "[25, 60] loss: 0.213\n",
      "Epoch: 25 -> Loss: 0.386630654335\n",
      "Epoch: 25 -> Test Accuracy: 76.68\n",
      "[26, 60] loss: 0.176\n",
      "Epoch: 26 -> Loss: 0.414119243622\n",
      "Epoch: 26 -> Test Accuracy: 79.36\n",
      "[27, 60] loss: 0.138\n",
      "Epoch: 27 -> Loss: 0.148689627647\n",
      "Epoch: 27 -> Test Accuracy: 80.08\n",
      "[28, 60] loss: 0.116\n",
      "Epoch: 28 -> Loss: 0.182817041874\n",
      "Epoch: 28 -> Test Accuracy: 79.19\n",
      "[29, 60] loss: 0.120\n",
      "Epoch: 29 -> Loss: 0.0431238114834\n",
      "Epoch: 29 -> Test Accuracy: 78.4\n",
      "[30, 60] loss: 0.099\n",
      "Epoch: 30 -> Loss: 0.171017602086\n",
      "Epoch: 30 -> Test Accuracy: 78.63\n",
      "[31, 60] loss: 0.100\n",
      "Epoch: 31 -> Loss: 0.0680250525475\n",
      "Epoch: 31 -> Test Accuracy: 79.35\n",
      "[32, 60] loss: 0.104\n",
      "Epoch: 32 -> Loss: 0.15799471736\n",
      "Epoch: 32 -> Test Accuracy: 79.79\n",
      "[33, 60] loss: 0.112\n",
      "Epoch: 33 -> Loss: 0.785507678986\n",
      "Epoch: 33 -> Test Accuracy: 78.19\n",
      "[34, 60] loss: 0.159\n",
      "Epoch: 34 -> Loss: 0.284263908863\n",
      "Epoch: 34 -> Test Accuracy: 78.98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35, 60] loss: 0.123\n",
      "Epoch: 35 -> Loss: 0.0118582546711\n",
      "Epoch: 35 -> Test Accuracy: 79.96\n",
      "[36, 60] loss: 0.074\n",
      "Epoch: 36 -> Loss: 0.0981639921665\n",
      "Epoch: 36 -> Test Accuracy: 81.42\n",
      "[37, 60] loss: 0.047\n",
      "Epoch: 37 -> Loss: 0.129876330495\n",
      "Epoch: 37 -> Test Accuracy: 82.09\n",
      "[38, 60] loss: 0.042\n",
      "Epoch: 38 -> Loss: 0.0703936219215\n",
      "Epoch: 38 -> Test Accuracy: 82.13\n",
      "[39, 60] loss: 0.035\n",
      "Epoch: 39 -> Loss: 0.361490488052\n",
      "Epoch: 39 -> Test Accuracy: 82.41\n",
      "[40, 60] loss: 0.039\n",
      "Epoch: 40 -> Loss: 0.0307986736298\n",
      "Epoch: 40 -> Test Accuracy: 81.84\n",
      "[41, 60] loss: 0.029\n",
      "Epoch: 41 -> Loss: 0.0751132071018\n",
      "Epoch: 41 -> Test Accuracy: 82.14\n",
      "[42, 60] loss: 0.030\n",
      "Epoch: 42 -> Loss: 0.202570453286\n",
      "Epoch: 42 -> Test Accuracy: 81.97\n",
      "[43, 60] loss: 0.029\n",
      "Epoch: 43 -> Loss: 0.133155375719\n",
      "Epoch: 43 -> Test Accuracy: 82.34\n",
      "[44, 60] loss: 0.028\n",
      "Epoch: 44 -> Loss: 0.0582230389118\n",
      "Epoch: 44 -> Test Accuracy: 82.12\n",
      "[45, 60] loss: 0.025\n",
      "Epoch: 45 -> Loss: 0.0510275363922\n",
      "Epoch: 45 -> Test Accuracy: 82.28\n",
      "[46, 60] loss: 0.022\n",
      "Epoch: 46 -> Loss: 0.597634196281\n",
      "Epoch: 46 -> Test Accuracy: 82.05\n",
      "[47, 60] loss: 0.031\n",
      "Epoch: 47 -> Loss: 0.168126106262\n",
      "Epoch: 47 -> Test Accuracy: 81.77\n",
      "[48, 60] loss: 0.022\n",
      "Epoch: 48 -> Loss: 0.247330158949\n",
      "Epoch: 48 -> Test Accuracy: 82.0\n",
      "[49, 60] loss: 0.027\n",
      "Epoch: 49 -> Loss: 0.0111747384071\n",
      "Epoch: 49 -> Test Accuracy: 81.93\n",
      "[50, 60] loss: 0.021\n",
      "Epoch: 50 -> Loss: 0.00629377365112\n",
      "Epoch: 50 -> Test Accuracy: 82.27\n",
      "[51, 60] loss: 0.020\n",
      "Epoch: 51 -> Loss: 0.290069580078\n",
      "Epoch: 51 -> Test Accuracy: 82.29\n",
      "[52, 60] loss: 0.022\n",
      "Epoch: 52 -> Loss: 0.0416841208935\n",
      "Epoch: 52 -> Test Accuracy: 82.46\n",
      "[53, 60] loss: 0.018\n",
      "Epoch: 53 -> Loss: 0.120237708092\n",
      "Epoch: 53 -> Test Accuracy: 82.3\n",
      "[54, 60] loss: 0.019\n",
      "Epoch: 54 -> Loss: 0.00594729185104\n",
      "Epoch: 54 -> Test Accuracy: 82.11\n",
      "[55, 60] loss: 0.017\n",
      "Epoch: 55 -> Loss: 0.09610709548\n",
      "Epoch: 55 -> Test Accuracy: 82.32\n",
      "[56, 60] loss: 0.018\n",
      "Epoch: 56 -> Loss: 0.0148078203201\n",
      "Epoch: 56 -> Test Accuracy: 82.37\n",
      "[57, 60] loss: 0.016\n",
      "Epoch: 57 -> Loss: 0.0427280664444\n",
      "Epoch: 57 -> Test Accuracy: 82.25\n",
      "[58, 60] loss: 0.017\n",
      "Epoch: 58 -> Loss: 0.031501069665\n",
      "Epoch: 58 -> Test Accuracy: 82.41\n",
      "[59, 60] loss: 0.016\n",
      "Epoch: 59 -> Loss: 0.0592806637287\n",
      "Epoch: 59 -> Test Accuracy: 82.2\n",
      "[60, 60] loss: 0.016\n",
      "Epoch: 60 -> Loss: 0.144242584705\n",
      "Epoch: 60 -> Test Accuracy: 82.24\n",
      "[61, 60] loss: 0.022\n",
      "Epoch: 61 -> Loss: 0.0598346292973\n",
      "Epoch: 61 -> Test Accuracy: 82.16\n",
      "[62, 60] loss: 0.016\n",
      "Epoch: 62 -> Loss: 0.0212300419807\n",
      "Epoch: 62 -> Test Accuracy: 82.69\n",
      "[63, 60] loss: 0.017\n",
      "Epoch: 63 -> Loss: 0.0416815578938\n",
      "Epoch: 63 -> Test Accuracy: 82.36\n",
      "[64, 60] loss: 0.016\n",
      "Epoch: 64 -> Loss: 0.0872786939144\n",
      "Epoch: 64 -> Test Accuracy: 82.22\n",
      "[65, 60] loss: 0.018\n",
      "Epoch: 65 -> Loss: 0.155515193939\n",
      "Epoch: 65 -> Test Accuracy: 82.04\n",
      "[66, 60] loss: 0.018\n",
      "Epoch: 66 -> Loss: 0.0211002230644\n",
      "Epoch: 66 -> Test Accuracy: 82.19\n",
      "[67, 60] loss: 0.016\n",
      "Epoch: 67 -> Loss: 0.010782122612\n",
      "Epoch: 67 -> Test Accuracy: 82.42\n",
      "[68, 60] loss: 0.015\n",
      "Epoch: 68 -> Loss: 0.170958012342\n",
      "Epoch: 68 -> Test Accuracy: 82.21\n",
      "[69, 60] loss: 0.020\n",
      "Epoch: 69 -> Loss: 0.144271373749\n",
      "Epoch: 69 -> Test Accuracy: 81.94\n",
      "[70, 60] loss: 0.017\n",
      "Epoch: 70 -> Loss: 0.139695331454\n",
      "Epoch: 70 -> Test Accuracy: 81.85\n",
      "[71, 60] loss: 0.013\n",
      "Epoch: 71 -> Loss: 0.0194418132305\n",
      "Epoch: 71 -> Test Accuracy: 82.14\n",
      "[72, 60] loss: 0.012\n",
      "Epoch: 72 -> Loss: 0.178683146834\n",
      "Epoch: 72 -> Test Accuracy: 82.35\n",
      "[73, 60] loss: 0.015\n",
      "Epoch: 73 -> Loss: 0.0172862708569\n",
      "Epoch: 73 -> Test Accuracy: 82.52\n",
      "[74, 60] loss: 0.012\n",
      "Epoch: 74 -> Loss: 0.0133208632469\n",
      "Epoch: 74 -> Test Accuracy: 82.44\n",
      "[75, 60] loss: 0.013\n",
      "Epoch: 75 -> Loss: 0.167397990823\n",
      "Epoch: 75 -> Test Accuracy: 82.48\n",
      "[76, 60] loss: 0.013\n",
      "Epoch: 76 -> Loss: 0.103705346584\n",
      "Epoch: 76 -> Test Accuracy: 82.5\n",
      "[77, 60] loss: 0.012\n",
      "Epoch: 77 -> Loss: 0.0884469151497\n",
      "Epoch: 77 -> Test Accuracy: 82.4\n",
      "[78, 60] loss: 0.012\n",
      "Epoch: 78 -> Loss: 0.0739714801311\n",
      "Epoch: 78 -> Test Accuracy: 82.43\n",
      "[79, 60] loss: 0.011\n",
      "Epoch: 79 -> Loss: 0.0458299517632\n",
      "Epoch: 79 -> Test Accuracy: 82.36\n",
      "[80, 60] loss: 0.012\n",
      "Epoch: 80 -> Loss: 0.0515764951706\n",
      "Epoch: 80 -> Test Accuracy: 82.31\n",
      "[81, 60] loss: 0.011\n",
      "Epoch: 81 -> Loss: 0.132997080684\n",
      "Epoch: 81 -> Test Accuracy: 82.48\n",
      "[82, 60] loss: 0.011\n",
      "Epoch: 82 -> Loss: 0.0447616279125\n",
      "Epoch: 82 -> Test Accuracy: 82.48\n",
      "[83, 60] loss: 0.012\n",
      "Epoch: 83 -> Loss: 0.109954103827\n",
      "Epoch: 83 -> Test Accuracy: 82.41\n",
      "[84, 60] loss: 0.012\n",
      "Epoch: 84 -> Loss: 0.190352901816\n",
      "Epoch: 84 -> Test Accuracy: 82.37\n",
      "[85, 60] loss: 0.013\n",
      "Epoch: 85 -> Loss: 0.0311732888222\n",
      "Epoch: 85 -> Test Accuracy: 82.24\n",
      "[86, 60] loss: 0.012\n",
      "Epoch: 86 -> Loss: 0.0163831710815\n",
      "Epoch: 86 -> Test Accuracy: 82.26\n",
      "[87, 60] loss: 0.011\n",
      "Epoch: 87 -> Loss: 0.0504576563835\n",
      "Epoch: 87 -> Test Accuracy: 82.31\n",
      "[88, 60] loss: 0.012\n",
      "Epoch: 88 -> Loss: 0.0408283472061\n",
      "Epoch: 88 -> Test Accuracy: 82.31\n",
      "[89, 60] loss: 0.013\n",
      "Epoch: 89 -> Loss: 0.0583709180355\n",
      "Epoch: 89 -> Test Accuracy: 82.26\n",
      "[90, 60] loss: 0.011\n",
      "Epoch: 90 -> Loss: 0.0191749036312\n",
      "Epoch: 90 -> Test Accuracy: 82.27\n",
      "[91, 60] loss: 0.010\n",
      "Epoch: 91 -> Loss: 0.185779780149\n",
      "Epoch: 91 -> Test Accuracy: 82.29\n",
      "[92, 60] loss: 0.011\n",
      "Epoch: 92 -> Loss: 0.212909027934\n",
      "Epoch: 92 -> Test Accuracy: 82.26\n",
      "[93, 60] loss: 0.011\n",
      "Epoch: 93 -> Loss: 0.0961538106203\n",
      "Epoch: 93 -> Test Accuracy: 82.26\n",
      "[94, 60] loss: 0.011\n",
      "Epoch: 94 -> Loss: 0.155835315585\n",
      "Epoch: 94 -> Test Accuracy: 82.22\n",
      "[95, 60] loss: 0.010\n",
      "Epoch: 95 -> Loss: 0.0352356135845\n",
      "Epoch: 95 -> Test Accuracy: 82.2\n",
      "[96, 60] loss: 0.011\n",
      "Epoch: 96 -> Loss: 0.0515415668488\n",
      "Epoch: 96 -> Test Accuracy: 82.28\n",
      "[97, 60] loss: 0.011\n",
      "Epoch: 97 -> Loss: 0.0340076982975\n",
      "Epoch: 97 -> Test Accuracy: 82.28\n",
      "[98, 60] loss: 0.011\n",
      "Epoch: 98 -> Loss: 0.0163683593273\n",
      "Epoch: 98 -> Test Accuracy: 82.4\n",
      "[99, 60] loss: 0.011\n",
      "Epoch: 99 -> Loss: 0.0365780889988\n",
      "Epoch: 99 -> Test Accuracy: 82.39\n",
      "[100, 60] loss: 0.010\n",
      "Epoch: 100 -> Loss: 0.0818717926741\n",
      "Epoch: 100 -> Test Accuracy: 82.37\n",
      "Finished Training\n",
      "[1, 60] loss: 1.773\n",
      "Epoch: 1 -> Loss: 1.39637684822\n",
      "Epoch: 1 -> Test Accuracy: 39.2\n",
      "[2, 60] loss: 1.414\n",
      "Epoch: 2 -> Loss: 1.61242318153\n",
      "Epoch: 2 -> Test Accuracy: 48.88\n",
      "[3, 60] loss: 1.257\n",
      "Epoch: 3 -> Loss: 0.986036717892\n",
      "Epoch: 3 -> Test Accuracy: 51.43\n",
      "[4, 60] loss: 1.123\n",
      "Epoch: 4 -> Loss: 1.16729235649\n",
      "Epoch: 4 -> Test Accuracy: 50.82\n",
      "[5, 60] loss: 1.065\n",
      "Epoch: 5 -> Loss: 1.20785880089\n",
      "Epoch: 5 -> Test Accuracy: 52.34\n",
      "[6, 60] loss: 0.995\n",
      "Epoch: 6 -> Loss: 0.8540776968\n",
      "Epoch: 6 -> Test Accuracy: 57.56\n",
      "[7, 60] loss: 0.955\n",
      "Epoch: 7 -> Loss: 1.55866253376\n",
      "Epoch: 7 -> Test Accuracy: 57.69\n",
      "[8, 60] loss: 0.931\n",
      "Epoch: 8 -> Loss: 0.733534455299\n",
      "Epoch: 8 -> Test Accuracy: 65.32\n",
      "[9, 60] loss: 0.858\n",
      "Epoch: 9 -> Loss: 1.12717592716\n",
      "Epoch: 9 -> Test Accuracy: 58.27\n",
      "[10, 60] loss: 0.824\n",
      "Epoch: 10 -> Loss: 1.12642645836\n",
      "Epoch: 10 -> Test Accuracy: 64.93\n",
      "[11, 60] loss: 0.794\n",
      "Epoch: 11 -> Loss: 0.483515530825\n",
      "Epoch: 11 -> Test Accuracy: 67.08\n",
      "[12, 60] loss: 0.748\n",
      "Epoch: 12 -> Loss: 0.443886160851\n",
      "Epoch: 12 -> Test Accuracy: 67.44\n",
      "[13, 60] loss: 0.711\n",
      "Epoch: 13 -> Loss: 1.12184977531\n",
      "Epoch: 13 -> Test Accuracy: 56.76\n",
      "[14, 60] loss: 0.750\n",
      "Epoch: 14 -> Loss: 0.844667673111\n",
      "Epoch: 14 -> Test Accuracy: 66.65\n",
      "[15, 60] loss: 0.706\n",
      "Epoch: 15 -> Loss: 0.609946131706\n",
      "Epoch: 15 -> Test Accuracy: 66.38\n",
      "[16, 60] loss: 0.666\n",
      "Epoch: 16 -> Loss: 0.875188052654\n",
      "Epoch: 16 -> Test Accuracy: 68.4\n",
      "[17, 60] loss: 0.648\n",
      "Epoch: 17 -> Loss: 0.34452983737\n",
      "Epoch: 17 -> Test Accuracy: 69.69\n",
      "[18, 60] loss: 0.608\n",
      "Epoch: 18 -> Loss: 0.798074185848\n",
      "Epoch: 18 -> Test Accuracy: 69.12\n",
      "[19, 60] loss: 0.615\n",
      "Epoch: 19 -> Loss: 0.379672348499\n",
      "Epoch: 19 -> Test Accuracy: 69.27\n",
      "[20, 60] loss: 0.603\n",
      "Epoch: 20 -> Loss: 0.555045366287\n",
      "Epoch: 20 -> Test Accuracy: 67.52\n",
      "[21, 60] loss: 0.577\n",
      "Epoch: 21 -> Loss: 0.856527745724\n",
      "Epoch: 21 -> Test Accuracy: 62.4\n",
      "[22, 60] loss: 0.627\n",
      "Epoch: 22 -> Loss: 0.866166949272\n",
      "Epoch: 22 -> Test Accuracy: 65.27\n",
      "[23, 60] loss: 0.595\n",
      "Epoch: 23 -> Loss: 0.442987203598\n",
      "Epoch: 23 -> Test Accuracy: 72.18\n",
      "[24, 60] loss: 0.517\n",
      "Epoch: 24 -> Loss: 0.662600874901\n",
      "Epoch: 24 -> Test Accuracy: 68.29\n",
      "[25, 60] loss: 0.545\n",
      "Epoch: 25 -> Loss: 0.761811256409\n",
      "Epoch: 25 -> Test Accuracy: 72.18\n",
      "[26, 60] loss: 0.532\n",
      "Epoch: 26 -> Loss: 0.472498089075\n",
      "Epoch: 26 -> Test Accuracy: 72.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 60] loss: 0.503\n",
      "Epoch: 27 -> Loss: 0.436843186617\n",
      "Epoch: 27 -> Test Accuracy: 71.16\n",
      "[28, 60] loss: 0.498\n",
      "Epoch: 28 -> Loss: 0.40888556838\n",
      "Epoch: 28 -> Test Accuracy: 68.33\n",
      "[29, 60] loss: 0.496\n",
      "Epoch: 29 -> Loss: 0.46608376503\n",
      "Epoch: 29 -> Test Accuracy: 72.78\n",
      "[30, 60] loss: 0.469\n",
      "Epoch: 30 -> Loss: 0.496684551239\n",
      "Epoch: 30 -> Test Accuracy: 72.77\n",
      "[31, 60] loss: 0.457\n",
      "Epoch: 31 -> Loss: 0.927001714706\n",
      "Epoch: 31 -> Test Accuracy: 70.21\n",
      "[32, 60] loss: 0.529\n",
      "Epoch: 32 -> Loss: 0.465313196182\n",
      "Epoch: 32 -> Test Accuracy: 70.26\n",
      "[33, 60] loss: 0.447\n",
      "Epoch: 33 -> Loss: 0.92650437355\n",
      "Epoch: 33 -> Test Accuracy: 73.01\n",
      "[34, 60] loss: 0.490\n",
      "Epoch: 34 -> Loss: 0.708776950836\n",
      "Epoch: 34 -> Test Accuracy: 71.72\n",
      "[35, 60] loss: 0.449\n",
      "Epoch: 35 -> Loss: 0.460135221481\n",
      "Epoch: 35 -> Test Accuracy: 73.69\n",
      "[36, 60] loss: 0.421\n",
      "Epoch: 36 -> Loss: 0.980567038059\n",
      "Epoch: 36 -> Test Accuracy: 72.06\n",
      "[37, 60] loss: 0.430\n",
      "Epoch: 37 -> Loss: 0.724665403366\n",
      "Epoch: 37 -> Test Accuracy: 73.77\n",
      "[38, 60] loss: 0.439\n",
      "Epoch: 38 -> Loss: 0.418136924505\n",
      "Epoch: 38 -> Test Accuracy: 74.84\n",
      "[39, 60] loss: 0.402\n",
      "Epoch: 39 -> Loss: 0.611367940903\n",
      "Epoch: 39 -> Test Accuracy: 72.76\n",
      "[40, 60] loss: 0.410\n",
      "Epoch: 40 -> Loss: 0.226563513279\n",
      "Epoch: 40 -> Test Accuracy: 73.75\n",
      "[41, 60] loss: 0.372\n",
      "Epoch: 41 -> Loss: 1.09354794025\n",
      "Epoch: 41 -> Test Accuracy: 68.59\n",
      "[42, 60] loss: 0.507\n",
      "Epoch: 42 -> Loss: 0.387050002813\n",
      "Epoch: 42 -> Test Accuracy: 72.31\n",
      "[43, 60] loss: 0.395\n",
      "Epoch: 43 -> Loss: 0.387142896652\n",
      "Epoch: 43 -> Test Accuracy: 74.83\n",
      "[44, 60] loss: 0.383\n",
      "Epoch: 44 -> Loss: 0.738548457623\n",
      "Epoch: 44 -> Test Accuracy: 75.13\n",
      "[45, 60] loss: 0.378\n",
      "Epoch: 45 -> Loss: 0.302593946457\n",
      "Epoch: 45 -> Test Accuracy: 74.38\n",
      "[46, 60] loss: 0.360\n",
      "Epoch: 46 -> Loss: 0.367996513844\n",
      "Epoch: 46 -> Test Accuracy: 74.21\n",
      "[47, 60] loss: 0.347\n",
      "Epoch: 47 -> Loss: 0.208282262087\n",
      "Epoch: 47 -> Test Accuracy: 72.35\n",
      "[48, 60] loss: 0.345\n",
      "Epoch: 48 -> Loss: 0.845485687256\n",
      "Epoch: 48 -> Test Accuracy: 71.24\n",
      "[49, 60] loss: 0.414\n",
      "Epoch: 49 -> Loss: 0.996834456921\n",
      "Epoch: 49 -> Test Accuracy: 71.83\n",
      "[50, 60] loss: 0.397\n",
      "Epoch: 50 -> Loss: 0.708211779594\n",
      "Epoch: 50 -> Test Accuracy: 74.76\n",
      "[51, 60] loss: 0.383\n",
      "Epoch: 51 -> Loss: 0.549862623215\n",
      "Epoch: 51 -> Test Accuracy: 73.71\n",
      "[52, 60] loss: 0.317\n",
      "Epoch: 52 -> Loss: 0.630576431751\n",
      "Epoch: 52 -> Test Accuracy: 73.15\n",
      "[53, 60] loss: 0.359\n",
      "Epoch: 53 -> Loss: 0.192704737186\n",
      "Epoch: 53 -> Test Accuracy: 75.68\n",
      "[54, 60] loss: 0.326\n",
      "Epoch: 54 -> Loss: 0.558045864105\n",
      "Epoch: 54 -> Test Accuracy: 72.03\n",
      "[55, 60] loss: 0.342\n",
      "Epoch: 55 -> Loss: 0.350576937199\n",
      "Epoch: 55 -> Test Accuracy: 75.38\n",
      "[56, 60] loss: 0.324\n",
      "Epoch: 56 -> Loss: 0.922991633415\n",
      "Epoch: 56 -> Test Accuracy: 68.7\n",
      "[57, 60] loss: 0.407\n",
      "Epoch: 57 -> Loss: 0.689913332462\n",
      "Epoch: 57 -> Test Accuracy: 73.74\n",
      "[58, 60] loss: 0.334\n",
      "Epoch: 58 -> Loss: 0.262450158596\n",
      "Epoch: 58 -> Test Accuracy: 75.44\n",
      "[59, 60] loss: 0.269\n",
      "Epoch: 59 -> Loss: 0.166655987501\n",
      "Epoch: 59 -> Test Accuracy: 76.0\n",
      "[60, 60] loss: 0.302\n",
      "Epoch: 60 -> Loss: 1.04309177399\n",
      "Epoch: 60 -> Test Accuracy: 70.33\n",
      "[61, 60] loss: 0.184\n",
      "Epoch: 61 -> Loss: 0.166531503201\n",
      "Epoch: 61 -> Test Accuracy: 80.11\n",
      "[62, 60] loss: 0.100\n",
      "Epoch: 62 -> Loss: 0.148359268904\n",
      "Epoch: 62 -> Test Accuracy: 80.83\n",
      "[63, 60] loss: 0.081\n",
      "Epoch: 63 -> Loss: 0.185215234756\n",
      "Epoch: 63 -> Test Accuracy: 81.24\n",
      "[64, 60] loss: 0.070\n",
      "Epoch: 64 -> Loss: 0.0530636012554\n",
      "Epoch: 64 -> Test Accuracy: 80.87\n",
      "[65, 60] loss: 0.059\n",
      "Epoch: 65 -> Loss: 0.208093434572\n",
      "Epoch: 65 -> Test Accuracy: 81.03\n",
      "[66, 60] loss: 0.057\n",
      "Epoch: 66 -> Loss: 0.0929650068283\n",
      "Epoch: 66 -> Test Accuracy: 80.79\n",
      "[67, 60] loss: 0.047\n",
      "Epoch: 67 -> Loss: 0.175947859883\n",
      "Epoch: 67 -> Test Accuracy: 80.6\n",
      "[68, 60] loss: 0.042\n",
      "Epoch: 68 -> Loss: 0.303386062384\n",
      "Epoch: 68 -> Test Accuracy: 80.37\n",
      "[69, 60] loss: 0.053\n",
      "Epoch: 69 -> Loss: 0.176481246948\n",
      "Epoch: 69 -> Test Accuracy: 80.5\n",
      "[70, 60] loss: 0.043\n",
      "Epoch: 70 -> Loss: 0.327036052942\n",
      "Epoch: 70 -> Test Accuracy: 80.35\n",
      "[71, 60] loss: 0.049\n",
      "Epoch: 71 -> Loss: 0.0700607597828\n",
      "Epoch: 71 -> Test Accuracy: 80.77\n",
      "[72, 60] loss: 0.036\n",
      "Epoch: 72 -> Loss: 0.0799880474806\n",
      "Epoch: 72 -> Test Accuracy: 80.92\n",
      "[73, 60] loss: 0.035\n",
      "Epoch: 73 -> Loss: 0.0720694363117\n",
      "Epoch: 73 -> Test Accuracy: 80.43\n",
      "[74, 60] loss: 0.032\n",
      "Epoch: 74 -> Loss: 0.21764472127\n",
      "Epoch: 74 -> Test Accuracy: 80.26\n",
      "[75, 60] loss: 0.037\n",
      "Epoch: 75 -> Loss: 0.0573479533195\n",
      "Epoch: 75 -> Test Accuracy: 81.21\n",
      "[76, 60] loss: 0.030\n",
      "Epoch: 76 -> Loss: 0.0689170509577\n",
      "Epoch: 76 -> Test Accuracy: 80.7\n",
      "[77, 60] loss: 0.031\n",
      "Epoch: 77 -> Loss: 0.0248456299305\n",
      "Epoch: 77 -> Test Accuracy: 80.39\n",
      "[78, 60] loss: 0.023\n",
      "Epoch: 78 -> Loss: 0.0580821931362\n",
      "Epoch: 78 -> Test Accuracy: 80.57\n",
      "[79, 60] loss: 0.023\n",
      "Epoch: 79 -> Loss: 0.205361574888\n",
      "Epoch: 79 -> Test Accuracy: 80.45\n",
      "[80, 60] loss: 0.032\n",
      "Epoch: 80 -> Loss: 0.126359447837\n",
      "Epoch: 80 -> Test Accuracy: 80.68\n",
      "[81, 60] loss: 0.027\n",
      "Epoch: 81 -> Loss: 0.061612278223\n",
      "Epoch: 81 -> Test Accuracy: 80.14\n",
      "[82, 60] loss: 0.023\n",
      "Epoch: 82 -> Loss: 0.0695194900036\n",
      "Epoch: 82 -> Test Accuracy: 80.07\n",
      "[83, 60] loss: 0.025\n",
      "Epoch: 83 -> Loss: 0.0670720934868\n",
      "Epoch: 83 -> Test Accuracy: 80.46\n",
      "[84, 60] loss: 0.021\n",
      "Epoch: 84 -> Loss: 0.022901147604\n",
      "Epoch: 84 -> Test Accuracy: 80.67\n",
      "[85, 60] loss: 0.017\n",
      "Epoch: 85 -> Loss: 0.0868547856808\n",
      "Epoch: 85 -> Test Accuracy: 80.53\n",
      "[86, 60] loss: 0.022\n",
      "Epoch: 86 -> Loss: 0.347231984138\n",
      "Epoch: 86 -> Test Accuracy: 79.79\n",
      "[87, 60] loss: 0.030\n",
      "Epoch: 87 -> Loss: 0.0399845838547\n",
      "Epoch: 87 -> Test Accuracy: 80.77\n",
      "[88, 60] loss: 0.020\n",
      "Epoch: 88 -> Loss: 0.0385382473469\n",
      "Epoch: 88 -> Test Accuracy: 80.43\n",
      "[89, 60] loss: 0.019\n",
      "Epoch: 89 -> Loss: 0.0235059261322\n",
      "Epoch: 89 -> Test Accuracy: 80.49\n",
      "[90, 60] loss: 0.017\n",
      "Epoch: 90 -> Loss: 0.330083459616\n",
      "Epoch: 90 -> Test Accuracy: 80.67\n",
      "[91, 60] loss: 0.053\n",
      "Epoch: 91 -> Loss: 0.117743596435\n",
      "Epoch: 91 -> Test Accuracy: 80.52\n",
      "[92, 60] loss: 0.032\n",
      "Epoch: 92 -> Loss: 0.114468723536\n",
      "Epoch: 92 -> Test Accuracy: 80.03\n",
      "[93, 60] loss: 0.026\n",
      "Epoch: 93 -> Loss: 0.0163318812847\n",
      "Epoch: 93 -> Test Accuracy: 80.08\n",
      "[94, 60] loss: 0.019\n",
      "Epoch: 94 -> Loss: 0.193412154913\n",
      "Epoch: 94 -> Test Accuracy: 80.3\n",
      "[95, 60] loss: 0.034\n",
      "Epoch: 95 -> Loss: 0.354096651077\n",
      "Epoch: 95 -> Test Accuracy: 79.67\n",
      "[96, 60] loss: 0.042\n",
      "Epoch: 96 -> Loss: 0.31805112958\n",
      "Epoch: 96 -> Test Accuracy: 79.77\n",
      "[97, 60] loss: 0.058\n",
      "Epoch: 97 -> Loss: 0.175361335278\n",
      "Epoch: 97 -> Test Accuracy: 79.55\n",
      "[98, 60] loss: 0.037\n",
      "Epoch: 98 -> Loss: 0.0168239474297\n",
      "Epoch: 98 -> Test Accuracy: 79.91\n",
      "[99, 60] loss: 0.021\n",
      "Epoch: 99 -> Loss: 0.333975553513\n",
      "Epoch: 99 -> Test Accuracy: 79.08\n",
      "[100, 60] loss: 0.058\n",
      "Epoch: 100 -> Loss: 0.130249559879\n",
      "Epoch: 100 -> Test Accuracy: 79.8\n",
      "[101, 60] loss: 0.029\n",
      "Epoch: 101 -> Loss: 0.0521829724312\n",
      "Epoch: 101 -> Test Accuracy: 80.34\n",
      "[102, 60] loss: 0.020\n",
      "Epoch: 102 -> Loss: 0.087061226368\n",
      "Epoch: 102 -> Test Accuracy: 79.51\n",
      "[103, 60] loss: 0.030\n",
      "Epoch: 103 -> Loss: 0.0874740034342\n",
      "Epoch: 103 -> Test Accuracy: 79.49\n",
      "[104, 60] loss: 0.022\n",
      "Epoch: 104 -> Loss: 0.038327306509\n",
      "Epoch: 104 -> Test Accuracy: 80.22\n",
      "[105, 60] loss: 0.015\n",
      "Epoch: 105 -> Loss: 0.0093896985054\n",
      "Epoch: 105 -> Test Accuracy: 79.84\n",
      "[106, 60] loss: 0.014\n",
      "Epoch: 106 -> Loss: 0.0790112167597\n",
      "Epoch: 106 -> Test Accuracy: 80.33\n",
      "[107, 60] loss: 0.019\n",
      "Epoch: 107 -> Loss: 0.030585706234\n",
      "Epoch: 107 -> Test Accuracy: 79.33\n",
      "[108, 60] loss: 0.018\n",
      "Epoch: 108 -> Loss: 0.0593613684177\n",
      "Epoch: 108 -> Test Accuracy: 79.9\n",
      "[109, 60] loss: 0.018\n",
      "Epoch: 109 -> Loss: 0.0490646660328\n",
      "Epoch: 109 -> Test Accuracy: 80.28\n",
      "[110, 60] loss: 0.017\n",
      "Epoch: 110 -> Loss: 0.605028629303\n",
      "Epoch: 110 -> Test Accuracy: 77.5\n",
      "[111, 60] loss: 0.131\n",
      "Epoch: 111 -> Loss: 0.0627608895302\n",
      "Epoch: 111 -> Test Accuracy: 78.96\n",
      "[112, 60] loss: 0.046\n",
      "Epoch: 112 -> Loss: 0.116281151772\n",
      "Epoch: 112 -> Test Accuracy: 80.4\n",
      "[113, 60] loss: 0.032\n",
      "Epoch: 113 -> Loss: 0.334836989641\n",
      "Epoch: 113 -> Test Accuracy: 78.38\n",
      "[114, 60] loss: 0.067\n",
      "Epoch: 114 -> Loss: 0.017364948988\n",
      "Epoch: 114 -> Test Accuracy: 80.26\n",
      "[115, 60] loss: 0.032\n",
      "Epoch: 115 -> Loss: 0.0295217633247\n",
      "Epoch: 115 -> Test Accuracy: 79.56\n",
      "[116, 60] loss: 0.024\n",
      "Epoch: 116 -> Loss: 0.152551278472\n",
      "Epoch: 116 -> Test Accuracy: 80.38\n",
      "[117, 60] loss: 0.041\n",
      "Epoch: 117 -> Loss: 0.0248022675514\n",
      "Epoch: 117 -> Test Accuracy: 80.14\n",
      "[118, 60] loss: 0.025\n",
      "Epoch: 118 -> Loss: 0.181105941534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 118 -> Test Accuracy: 79.07\n",
      "[119, 60] loss: 0.064\n",
      "Epoch: 119 -> Loss: 0.00866675376892\n",
      "Epoch: 119 -> Test Accuracy: 79.56\n",
      "[120, 60] loss: 0.027\n",
      "Epoch: 120 -> Loss: 0.0768614262342\n",
      "Epoch: 120 -> Test Accuracy: 80.24\n",
      "[121, 60] loss: 0.018\n",
      "Epoch: 121 -> Loss: 0.378518640995\n",
      "Epoch: 121 -> Test Accuracy: 81.05\n",
      "[122, 60] loss: 0.015\n",
      "Epoch: 122 -> Loss: 0.8582457304\n",
      "Epoch: 122 -> Test Accuracy: 80.72\n",
      "[123, 60] loss: 0.017\n",
      "Epoch: 123 -> Loss: 0.0294105708599\n",
      "Epoch: 123 -> Test Accuracy: 80.38\n",
      "[124, 60] loss: 0.011\n",
      "Epoch: 124 -> Loss: 0.0331971049309\n",
      "Epoch: 124 -> Test Accuracy: 81.01\n",
      "[125, 60] loss: 0.009\n",
      "Epoch: 125 -> Loss: 0.038932800293\n",
      "Epoch: 125 -> Test Accuracy: 80.83\n",
      "[126, 60] loss: 0.009\n",
      "Epoch: 126 -> Loss: 0.0617565512657\n",
      "Epoch: 126 -> Test Accuracy: 80.93\n",
      "[127, 60] loss: 0.009\n",
      "Epoch: 127 -> Loss: 0.0119981467724\n",
      "Epoch: 127 -> Test Accuracy: 80.87\n",
      "[128, 60] loss: 0.007\n",
      "Epoch: 128 -> Loss: 0.154736220837\n",
      "Epoch: 128 -> Test Accuracy: 81.21\n",
      "[129, 60] loss: 0.010\n",
      "Epoch: 129 -> Loss: 0.00848937034607\n",
      "Epoch: 129 -> Test Accuracy: 81.29\n",
      "[130, 60] loss: 0.008\n",
      "Epoch: 130 -> Loss: 0.136036723852\n",
      "Epoch: 130 -> Test Accuracy: 81.11\n",
      "[131, 60] loss: 0.010\n",
      "Epoch: 131 -> Loss: 0.0555328428745\n",
      "Epoch: 131 -> Test Accuracy: 81.02\n",
      "[132, 60] loss: 0.007\n",
      "Epoch: 132 -> Loss: 0.0101339221001\n",
      "Epoch: 132 -> Test Accuracy: 81.19\n",
      "[133, 60] loss: 0.007\n",
      "Epoch: 133 -> Loss: 0.0193474888802\n",
      "Epoch: 133 -> Test Accuracy: 81.27\n",
      "[134, 60] loss: 0.007\n",
      "Epoch: 134 -> Loss: 0.0820344090462\n",
      "Epoch: 134 -> Test Accuracy: 80.99\n",
      "[135, 60] loss: 0.007\n",
      "Epoch: 135 -> Loss: 0.0694439411163\n",
      "Epoch: 135 -> Test Accuracy: 81.1\n",
      "[136, 60] loss: 0.007\n",
      "Epoch: 136 -> Loss: 0.0143128633499\n",
      "Epoch: 136 -> Test Accuracy: 81.05\n",
      "[137, 60] loss: 0.007\n",
      "Epoch: 137 -> Loss: 0.00632217526436\n",
      "Epoch: 137 -> Test Accuracy: 81.08\n",
      "[138, 60] loss: 0.007\n",
      "Epoch: 138 -> Loss: 0.0949960052967\n",
      "Epoch: 138 -> Test Accuracy: 81.13\n",
      "[139, 60] loss: 0.008\n",
      "Epoch: 139 -> Loss: 0.0251607000828\n",
      "Epoch: 139 -> Test Accuracy: 81.19\n",
      "[140, 60] loss: 0.007\n",
      "Epoch: 140 -> Loss: 0.152198851109\n",
      "Epoch: 140 -> Test Accuracy: 81.27\n",
      "[141, 60] loss: 0.008\n",
      "Epoch: 141 -> Loss: 0.0153052806854\n",
      "Epoch: 141 -> Test Accuracy: 81.16\n",
      "[142, 60] loss: 0.006\n",
      "Epoch: 142 -> Loss: 0.0134702324867\n",
      "Epoch: 142 -> Test Accuracy: 81.07\n",
      "[143, 60] loss: 0.007\n",
      "Epoch: 143 -> Loss: 0.0895454585552\n",
      "Epoch: 143 -> Test Accuracy: 81.05\n",
      "[144, 60] loss: 0.007\n",
      "Epoch: 144 -> Loss: 0.0337889790535\n",
      "Epoch: 144 -> Test Accuracy: 81.13\n",
      "[145, 60] loss: 0.008\n",
      "Epoch: 145 -> Loss: 0.0105313658714\n",
      "Epoch: 145 -> Test Accuracy: 81.27\n",
      "[146, 60] loss: 0.006\n",
      "Epoch: 146 -> Loss: 0.0473247766495\n",
      "Epoch: 146 -> Test Accuracy: 81.14\n",
      "[147, 60] loss: 0.006\n",
      "Epoch: 147 -> Loss: 0.0321169793606\n",
      "Epoch: 147 -> Test Accuracy: 81.34\n",
      "[148, 60] loss: 0.005\n",
      "Epoch: 148 -> Loss: 0.224108174443\n",
      "Epoch: 148 -> Test Accuracy: 81.24\n",
      "[149, 60] loss: 0.011\n",
      "Epoch: 149 -> Loss: 0.0483855456114\n",
      "Epoch: 149 -> Test Accuracy: 80.97\n",
      "[150, 60] loss: 0.006\n",
      "Epoch: 150 -> Loss: 0.124082550406\n",
      "Epoch: 150 -> Test Accuracy: 81.04\n",
      "[151, 60] loss: 0.006\n",
      "Epoch: 151 -> Loss: 0.0267632603645\n",
      "Epoch: 151 -> Test Accuracy: 80.73\n",
      "[152, 60] loss: 0.006\n",
      "Epoch: 152 -> Loss: 0.150065153837\n",
      "Epoch: 152 -> Test Accuracy: 80.97\n",
      "[153, 60] loss: 0.007\n",
      "Epoch: 153 -> Loss: 0.0128812193871\n",
      "Epoch: 153 -> Test Accuracy: 80.72\n",
      "[154, 60] loss: 0.006\n",
      "Epoch: 154 -> Loss: 0.499873399734\n",
      "Epoch: 154 -> Test Accuracy: 80.94\n",
      "[155, 60] loss: 0.010\n",
      "Epoch: 155 -> Loss: 0.0875641852617\n",
      "Epoch: 155 -> Test Accuracy: 80.91\n",
      "[156, 60] loss: 0.008\n",
      "Epoch: 156 -> Loss: 0.133348464966\n",
      "Epoch: 156 -> Test Accuracy: 80.91\n",
      "[157, 60] loss: 0.007\n",
      "Epoch: 157 -> Loss: 0.00689828395844\n",
      "Epoch: 157 -> Test Accuracy: 81.08\n",
      "[158, 60] loss: 0.006\n",
      "Epoch: 158 -> Loss: 0.0192039906979\n",
      "Epoch: 158 -> Test Accuracy: 81.19\n",
      "[159, 60] loss: 0.006\n",
      "Epoch: 159 -> Loss: 0.0126265287399\n",
      "Epoch: 159 -> Test Accuracy: 81.32\n",
      "[160, 60] loss: 0.005\n",
      "Epoch: 160 -> Loss: 0.0271755754948\n",
      "Epoch: 160 -> Test Accuracy: 81.29\n",
      "[161, 60] loss: 0.006\n",
      "Epoch: 161 -> Loss: 0.246920317411\n",
      "Epoch: 161 -> Test Accuracy: 81.24\n",
      "[162, 60] loss: 0.005\n",
      "Epoch: 162 -> Loss: 0.235553026199\n",
      "Epoch: 162 -> Test Accuracy: 81.22\n",
      "[163, 60] loss: 0.005\n",
      "Epoch: 163 -> Loss: 0.0227527618408\n",
      "Epoch: 163 -> Test Accuracy: 81.2\n",
      "[164, 60] loss: 0.006\n",
      "Epoch: 164 -> Loss: 0.322237640619\n",
      "Epoch: 164 -> Test Accuracy: 81.24\n",
      "[165, 60] loss: 0.005\n",
      "Epoch: 165 -> Loss: 0.0170261859894\n",
      "Epoch: 165 -> Test Accuracy: 81.27\n",
      "[166, 60] loss: 0.005\n",
      "Epoch: 166 -> Loss: 0.021741181612\n",
      "Epoch: 166 -> Test Accuracy: 81.29\n",
      "[167, 60] loss: 0.005\n",
      "Epoch: 167 -> Loss: 0.00409480929375\n",
      "Epoch: 167 -> Test Accuracy: 81.23\n",
      "[168, 60] loss: 0.005\n",
      "Epoch: 168 -> Loss: 0.00470471382141\n",
      "Epoch: 168 -> Test Accuracy: 81.28\n",
      "[169, 60] loss: 0.005\n",
      "Epoch: 169 -> Loss: 0.0404222607613\n",
      "Epoch: 169 -> Test Accuracy: 81.33\n",
      "[170, 60] loss: 0.005\n",
      "Epoch: 170 -> Loss: 0.0367503464222\n",
      "Epoch: 170 -> Test Accuracy: 81.37\n",
      "[171, 60] loss: 0.005\n",
      "Epoch: 171 -> Loss: 0.62538433075\n",
      "Epoch: 171 -> Test Accuracy: 81.27\n",
      "[172, 60] loss: 0.005\n",
      "Epoch: 172 -> Loss: 0.0132876932621\n",
      "Epoch: 172 -> Test Accuracy: 81.37\n",
      "[173, 60] loss: 0.006\n",
      "Epoch: 173 -> Loss: 0.0607613623142\n",
      "Epoch: 173 -> Test Accuracy: 81.37\n",
      "[174, 60] loss: 0.005\n",
      "Epoch: 174 -> Loss: 0.0295112729073\n",
      "Epoch: 174 -> Test Accuracy: 81.26\n",
      "[175, 60] loss: 0.005\n",
      "Epoch: 175 -> Loss: 0.179972574115\n",
      "Epoch: 175 -> Test Accuracy: 81.23\n",
      "[176, 60] loss: 0.005\n",
      "Epoch: 176 -> Loss: 0.272391170263\n",
      "Epoch: 176 -> Test Accuracy: 81.29\n",
      "[177, 60] loss: 0.005\n",
      "Epoch: 177 -> Loss: 0.0212894082069\n",
      "Epoch: 177 -> Test Accuracy: 81.4\n",
      "[178, 60] loss: 0.005\n",
      "Epoch: 178 -> Loss: 0.0103616416454\n",
      "Epoch: 178 -> Test Accuracy: 81.41\n",
      "[179, 60] loss: 0.005\n",
      "Epoch: 179 -> Loss: 0.0807244628668\n",
      "Epoch: 179 -> Test Accuracy: 81.33\n",
      "[180, 60] loss: 0.005\n",
      "Epoch: 180 -> Loss: 0.0026288330555\n",
      "Epoch: 180 -> Test Accuracy: 81.33\n",
      "[181, 60] loss: 0.005\n",
      "Epoch: 181 -> Loss: 0.0365392267704\n",
      "Epoch: 181 -> Test Accuracy: 81.28\n",
      "[182, 60] loss: 0.005\n",
      "Epoch: 182 -> Loss: 0.174597024918\n",
      "Epoch: 182 -> Test Accuracy: 81.27\n",
      "[183, 60] loss: 0.005\n",
      "Epoch: 183 -> Loss: 0.0235088169575\n",
      "Epoch: 183 -> Test Accuracy: 81.24\n",
      "[184, 60] loss: 0.005\n",
      "Epoch: 184 -> Loss: 0.118139356375\n",
      "Epoch: 184 -> Test Accuracy: 81.28\n",
      "[185, 60] loss: 0.004\n",
      "Epoch: 185 -> Loss: 0.534371972084\n",
      "Epoch: 185 -> Test Accuracy: 81.31\n",
      "[186, 60] loss: 0.005\n",
      "Epoch: 186 -> Loss: 0.00921711325645\n",
      "Epoch: 186 -> Test Accuracy: 81.19\n",
      "[187, 60] loss: 0.005\n",
      "Epoch: 187 -> Loss: 0.0236695110798\n",
      "Epoch: 187 -> Test Accuracy: 81.23\n",
      "[188, 60] loss: 0.005\n",
      "Epoch: 188 -> Loss: 0.00469049811363\n",
      "Epoch: 188 -> Test Accuracy: 81.22\n",
      "[189, 60] loss: 0.005\n",
      "Epoch: 189 -> Loss: 0.00903850793839\n",
      "Epoch: 189 -> Test Accuracy: 81.2\n",
      "[190, 60] loss: 0.005\n",
      "Epoch: 190 -> Loss: 0.0561411380768\n",
      "Epoch: 190 -> Test Accuracy: 81.3\n",
      "[191, 60] loss: 0.005\n",
      "Epoch: 191 -> Loss: 0.00500473380089\n",
      "Epoch: 191 -> Test Accuracy: 81.27\n",
      "[192, 60] loss: 0.005\n",
      "Epoch: 192 -> Loss: 0.0297300219536\n",
      "Epoch: 192 -> Test Accuracy: 81.26\n",
      "[193, 60] loss: 0.005\n",
      "Epoch: 193 -> Loss: 0.15143981576\n",
      "Epoch: 193 -> Test Accuracy: 81.26\n",
      "[194, 60] loss: 0.005\n",
      "Epoch: 194 -> Loss: 0.0315331816673\n",
      "Epoch: 194 -> Test Accuracy: 81.35\n",
      "[195, 60] loss: 0.004\n",
      "Epoch: 195 -> Loss: 0.0156123042107\n",
      "Epoch: 195 -> Test Accuracy: 81.4\n",
      "[196, 60] loss: 0.005\n",
      "Epoch: 196 -> Loss: 0.0269106626511\n",
      "Epoch: 196 -> Test Accuracy: 81.3\n",
      "[197, 60] loss: 0.005\n",
      "Epoch: 197 -> Loss: 0.00404390692711\n",
      "Epoch: 197 -> Test Accuracy: 81.3\n",
      "[198, 60] loss: 0.005\n",
      "Epoch: 198 -> Loss: 0.00726145505905\n",
      "Epoch: 198 -> Test Accuracy: 81.28\n",
      "[199, 60] loss: 0.005\n",
      "Epoch: 199 -> Loss: 0.115644574165\n",
      "Epoch: 199 -> Test Accuracy: 81.28\n",
      "[200, 60] loss: 0.004\n",
      "Epoch: 200 -> Loss: 0.0092601776123\n",
      "Epoch: 200 -> Test Accuracy: 81.11\n",
      "Finished Training\n",
      "[1, 60] loss: 0.969\n",
      "[1, 120] loss: 0.635\n",
      "[1, 180] loss: 0.579\n",
      "[1, 240] loss: 0.540\n",
      "[1, 300] loss: 0.539\n",
      "[1, 360] loss: 0.522\n",
      "Epoch: 1 -> Loss: 0.599990904331\n",
      "Epoch: 1 -> Test Accuracy: 80.33\n",
      "[2, 60] loss: 0.476\n",
      "[2, 120] loss: 0.441\n",
      "[2, 180] loss: 0.451\n",
      "[2, 240] loss: 0.452\n",
      "[2, 300] loss: 0.433\n",
      "[2, 360] loss: 0.434\n",
      "Epoch: 2 -> Loss: 0.487504810095\n",
      "Epoch: 2 -> Test Accuracy: 81.55\n",
      "[3, 60] loss: 0.392\n",
      "[3, 120] loss: 0.398\n",
      "[3, 180] loss: 0.411\n",
      "[3, 240] loss: 0.376\n",
      "[3, 300] loss: 0.390\n",
      "[3, 360] loss: 0.414\n",
      "Epoch: 3 -> Loss: 0.398299694061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 -> Test Accuracy: 82.12\n",
      "[4, 60] loss: 0.366\n",
      "[4, 120] loss: 0.352\n",
      "[4, 180] loss: 0.375\n",
      "[4, 240] loss: 0.388\n",
      "[4, 300] loss: 0.379\n",
      "[4, 360] loss: 0.379\n",
      "Epoch: 4 -> Loss: 0.39485090971\n",
      "Epoch: 4 -> Test Accuracy: 82.66\n",
      "[5, 60] loss: 0.328\n",
      "[5, 120] loss: 0.339\n",
      "[5, 180] loss: 0.352\n",
      "[5, 240] loss: 0.357\n",
      "[5, 300] loss: 0.356\n",
      "[5, 360] loss: 0.359\n",
      "Epoch: 5 -> Loss: 0.330547869205\n",
      "Epoch: 5 -> Test Accuracy: 82.89\n",
      "[6, 60] loss: 0.315\n",
      "[6, 120] loss: 0.343\n",
      "[6, 180] loss: 0.343\n",
      "[6, 240] loss: 0.347\n",
      "[6, 300] loss: 0.327\n",
      "[6, 360] loss: 0.327\n",
      "Epoch: 6 -> Loss: 0.408696323633\n",
      "Epoch: 6 -> Test Accuracy: 83.08\n",
      "[7, 60] loss: 0.307\n",
      "[7, 120] loss: 0.322\n",
      "[7, 180] loss: 0.335\n",
      "[7, 240] loss: 0.332\n",
      "[7, 300] loss: 0.319\n",
      "[7, 360] loss: 0.339\n",
      "Epoch: 7 -> Loss: 0.356509029865\n",
      "Epoch: 7 -> Test Accuracy: 84.29\n",
      "[8, 60] loss: 0.296\n",
      "[8, 120] loss: 0.316\n",
      "[8, 180] loss: 0.321\n",
      "[8, 240] loss: 0.331\n",
      "[8, 300] loss: 0.330\n",
      "[8, 360] loss: 0.318\n",
      "Epoch: 8 -> Loss: 0.348937690258\n",
      "Epoch: 8 -> Test Accuracy: 83.04\n",
      "[9, 60] loss: 0.299\n",
      "[9, 120] loss: 0.296\n",
      "[9, 180] loss: 0.318\n",
      "[9, 240] loss: 0.317\n",
      "[9, 300] loss: 0.310\n",
      "[9, 360] loss: 0.338\n",
      "Epoch: 9 -> Loss: 0.178177446127\n",
      "Epoch: 9 -> Test Accuracy: 83.33\n",
      "[10, 60] loss: 0.286\n",
      "[10, 120] loss: 0.283\n",
      "[10, 180] loss: 0.302\n",
      "[10, 240] loss: 0.308\n",
      "[10, 300] loss: 0.308\n",
      "[10, 360] loss: 0.316\n",
      "Epoch: 10 -> Loss: 0.238031953573\n",
      "Epoch: 10 -> Test Accuracy: 83.22\n",
      "[11, 60] loss: 0.288\n",
      "[11, 120] loss: 0.288\n",
      "[11, 180] loss: 0.302\n",
      "[11, 240] loss: 0.270\n",
      "[11, 300] loss: 0.316\n",
      "[11, 360] loss: 0.321\n",
      "Epoch: 11 -> Loss: 0.418235391378\n",
      "Epoch: 11 -> Test Accuracy: 83.52\n",
      "[12, 60] loss: 0.273\n",
      "[12, 120] loss: 0.281\n",
      "[12, 180] loss: 0.280\n",
      "[12, 240] loss: 0.293\n",
      "[12, 300] loss: 0.304\n",
      "[12, 360] loss: 0.304\n",
      "Epoch: 12 -> Loss: 0.273054301739\n",
      "Epoch: 12 -> Test Accuracy: 83.71\n",
      "[13, 60] loss: 0.272\n",
      "[13, 120] loss: 0.291\n",
      "[13, 180] loss: 0.278\n",
      "[13, 240] loss: 0.299\n",
      "[13, 300] loss: 0.301\n",
      "[13, 360] loss: 0.305\n",
      "Epoch: 13 -> Loss: 0.444410562515\n",
      "Epoch: 13 -> Test Accuracy: 84.47\n",
      "[14, 60] loss: 0.270\n",
      "[14, 120] loss: 0.283\n",
      "[14, 180] loss: 0.288\n",
      "[14, 240] loss: 0.289\n",
      "[14, 300] loss: 0.299\n",
      "[14, 360] loss: 0.289\n",
      "Epoch: 14 -> Loss: 0.2566626966\n",
      "Epoch: 14 -> Test Accuracy: 83.3\n",
      "[15, 60] loss: 0.261\n",
      "[15, 120] loss: 0.269\n",
      "[15, 180] loss: 0.292\n",
      "[15, 240] loss: 0.304\n",
      "[15, 300] loss: 0.300\n",
      "[15, 360] loss: 0.290\n",
      "Epoch: 15 -> Loss: 0.290591299534\n",
      "Epoch: 15 -> Test Accuracy: 84.13\n",
      "[16, 60] loss: 0.271\n",
      "[16, 120] loss: 0.278\n",
      "[16, 180] loss: 0.278\n",
      "[16, 240] loss: 0.283\n",
      "[16, 300] loss: 0.299\n",
      "[16, 360] loss: 0.284\n",
      "Epoch: 16 -> Loss: 0.414299398661\n",
      "Epoch: 16 -> Test Accuracy: 84.57\n",
      "[17, 60] loss: 0.262\n",
      "[17, 120] loss: 0.265\n",
      "[17, 180] loss: 0.295\n",
      "[17, 240] loss: 0.289\n",
      "[17, 300] loss: 0.284\n",
      "[17, 360] loss: 0.270\n",
      "Epoch: 17 -> Loss: 0.258014470339\n",
      "Epoch: 17 -> Test Accuracy: 83.74\n",
      "[18, 60] loss: 0.255\n",
      "[18, 120] loss: 0.270\n",
      "[18, 180] loss: 0.278\n",
      "[18, 240] loss: 0.277\n",
      "[18, 300] loss: 0.296\n",
      "[18, 360] loss: 0.295\n",
      "Epoch: 18 -> Loss: 0.260183632374\n",
      "Epoch: 18 -> Test Accuracy: 84.62\n",
      "[19, 60] loss: 0.254\n",
      "[19, 120] loss: 0.266\n",
      "[19, 180] loss: 0.285\n",
      "[19, 240] loss: 0.265\n",
      "[19, 300] loss: 0.291\n",
      "[19, 360] loss: 0.298\n",
      "Epoch: 19 -> Loss: 0.222553521395\n",
      "Epoch: 19 -> Test Accuracy: 84.27\n",
      "[20, 60] loss: 0.263\n",
      "[20, 120] loss: 0.252\n",
      "[20, 180] loss: 0.288\n",
      "[20, 240] loss: 0.288\n",
      "[20, 300] loss: 0.288\n",
      "[20, 360] loss: 0.283\n",
      "Epoch: 20 -> Loss: 0.207355216146\n",
      "Epoch: 20 -> Test Accuracy: 85.15\n",
      "[21, 60] loss: 0.251\n",
      "[21, 120] loss: 0.264\n",
      "[21, 180] loss: 0.265\n",
      "[21, 240] loss: 0.269\n",
      "[21, 300] loss: 0.274\n",
      "[21, 360] loss: 0.290\n",
      "Epoch: 21 -> Loss: 0.265392720699\n",
      "Epoch: 21 -> Test Accuracy: 83.51\n",
      "[22, 60] loss: 0.268\n",
      "[22, 120] loss: 0.266\n",
      "[22, 180] loss: 0.268\n",
      "[22, 240] loss: 0.274\n",
      "[22, 300] loss: 0.283\n",
      "[22, 360] loss: 0.280\n",
      "Epoch: 22 -> Loss: 0.230514094234\n",
      "Epoch: 22 -> Test Accuracy: 84.22\n",
      "[23, 60] loss: 0.242\n",
      "[23, 120] loss: 0.261\n",
      "[23, 180] loss: 0.270\n",
      "[23, 240] loss: 0.272\n",
      "[23, 300] loss: 0.274\n",
      "[23, 360] loss: 0.278\n",
      "Epoch: 23 -> Loss: 0.163375049829\n",
      "Epoch: 23 -> Test Accuracy: 84.01\n",
      "[24, 60] loss: 0.248\n",
      "[24, 120] loss: 0.257\n",
      "[24, 180] loss: 0.267\n",
      "[24, 240] loss: 0.276\n",
      "[24, 300] loss: 0.271\n",
      "[24, 360] loss: 0.286\n",
      "Epoch: 24 -> Loss: 0.260457992554\n",
      "Epoch: 24 -> Test Accuracy: 84.0\n",
      "[25, 60] loss: 0.233\n",
      "[25, 120] loss: 0.258\n",
      "[25, 180] loss: 0.265\n",
      "[25, 240] loss: 0.269\n",
      "[25, 300] loss: 0.285\n",
      "[25, 360] loss: 0.282\n",
      "Epoch: 25 -> Loss: 0.321277737617\n",
      "Epoch: 25 -> Test Accuracy: 83.77\n",
      "[26, 60] loss: 0.241\n",
      "[26, 120] loss: 0.256\n",
      "[26, 180] loss: 0.281\n",
      "[26, 240] loss: 0.274\n",
      "[26, 300] loss: 0.278\n",
      "[26, 360] loss: 0.263\n",
      "Epoch: 26 -> Loss: 0.308645397425\n",
      "Epoch: 26 -> Test Accuracy: 83.78\n",
      "[27, 60] loss: 0.241\n",
      "[27, 120] loss: 0.260\n",
      "[27, 180] loss: 0.256\n",
      "[27, 240] loss: 0.281\n",
      "[27, 300] loss: 0.287\n",
      "[27, 360] loss: 0.273\n",
      "Epoch: 27 -> Loss: 0.291223734617\n",
      "Epoch: 27 -> Test Accuracy: 84.18\n",
      "[28, 60] loss: 0.250\n",
      "[28, 120] loss: 0.252\n",
      "[28, 180] loss: 0.267\n",
      "[28, 240] loss: 0.262\n",
      "[28, 300] loss: 0.281\n",
      "[28, 360] loss: 0.279\n",
      "Epoch: 28 -> Loss: 0.262935101986\n",
      "Epoch: 28 -> Test Accuracy: 84.5\n",
      "[29, 60] loss: 0.248\n",
      "[29, 120] loss: 0.243\n",
      "[29, 180] loss: 0.272\n",
      "[29, 240] loss: 0.257\n",
      "[29, 300] loss: 0.279\n",
      "[29, 360] loss: 0.273\n",
      "Epoch: 29 -> Loss: 0.146514579654\n",
      "Epoch: 29 -> Test Accuracy: 84.24\n",
      "[30, 60] loss: 0.240\n",
      "[30, 120] loss: 0.254\n",
      "[30, 180] loss: 0.253\n",
      "[30, 240] loss: 0.268\n",
      "[30, 300] loss: 0.252\n",
      "[30, 360] loss: 0.278\n",
      "Epoch: 30 -> Loss: 0.252816617489\n",
      "Epoch: 30 -> Test Accuracy: 83.96\n",
      "[31, 60] loss: 0.249\n",
      "[31, 120] loss: 0.262\n",
      "[31, 180] loss: 0.250\n",
      "[31, 240] loss: 0.254\n",
      "[31, 300] loss: 0.282\n",
      "[31, 360] loss: 0.285\n",
      "Epoch: 31 -> Loss: 0.176797196269\n",
      "Epoch: 31 -> Test Accuracy: 84.09\n",
      "[32, 60] loss: 0.254\n",
      "[32, 120] loss: 0.258\n",
      "[32, 180] loss: 0.253\n",
      "[32, 240] loss: 0.260\n",
      "[32, 300] loss: 0.275\n",
      "[32, 360] loss: 0.287\n",
      "Epoch: 32 -> Loss: 0.316643357277\n",
      "Epoch: 32 -> Test Accuracy: 84.22\n",
      "[33, 60] loss: 0.237\n",
      "[33, 120] loss: 0.250\n",
      "[33, 180] loss: 0.258\n",
      "[33, 240] loss: 0.281\n",
      "[33, 300] loss: 0.278\n",
      "[33, 360] loss: 0.268\n",
      "Epoch: 33 -> Loss: 0.262636721134\n",
      "Epoch: 33 -> Test Accuracy: 83.21\n",
      "[34, 60] loss: 0.236\n",
      "[34, 120] loss: 0.241\n",
      "[34, 180] loss: 0.262\n",
      "[34, 240] loss: 0.268\n",
      "[34, 300] loss: 0.278\n",
      "[34, 360] loss: 0.271\n",
      "Epoch: 34 -> Loss: 0.355369985104\n",
      "Epoch: 34 -> Test Accuracy: 84.02\n",
      "[35, 60] loss: 0.257\n",
      "[35, 120] loss: 0.239\n",
      "[35, 180] loss: 0.257\n",
      "[35, 240] loss: 0.270\n",
      "[35, 300] loss: 0.277\n",
      "[35, 360] loss: 0.274\n",
      "Epoch: 35 -> Loss: 0.25914555788\n",
      "Epoch: 35 -> Test Accuracy: 84.61\n",
      "[36, 60] loss: 0.215\n",
      "[36, 120] loss: 0.173\n",
      "[36, 180] loss: 0.179\n",
      "[36, 240] loss: 0.172\n",
      "[36, 300] loss: 0.161\n",
      "[36, 360] loss: 0.160\n",
      "Epoch: 36 -> Loss: 0.104544207454\n",
      "Epoch: 36 -> Test Accuracy: 87.04\n",
      "[37, 60] loss: 0.135\n",
      "[37, 120] loss: 0.149\n",
      "[37, 180] loss: 0.150\n",
      "[37, 240] loss: 0.145\n",
      "[37, 300] loss: 0.144\n",
      "[37, 360] loss: 0.144\n",
      "Epoch: 37 -> Loss: 0.229348450899\n",
      "Epoch: 37 -> Test Accuracy: 86.63\n",
      "[38, 60] loss: 0.125\n",
      "[38, 120] loss: 0.125\n",
      "[38, 180] loss: 0.133\n",
      "[38, 240] loss: 0.125\n",
      "[38, 300] loss: 0.137\n",
      "[38, 360] loss: 0.131\n",
      "Epoch: 38 -> Loss: 0.138389334083\n",
      "Epoch: 38 -> Test Accuracy: 86.96\n",
      "[39, 60] loss: 0.121\n",
      "[39, 120] loss: 0.127\n",
      "[39, 180] loss: 0.122\n",
      "[39, 240] loss: 0.132\n",
      "[39, 300] loss: 0.122\n",
      "[39, 360] loss: 0.131\n",
      "Epoch: 39 -> Loss: 0.0633326470852\n",
      "Epoch: 39 -> Test Accuracy: 87.16\n",
      "[40, 60] loss: 0.108\n",
      "[40, 120] loss: 0.111\n",
      "[40, 180] loss: 0.114\n",
      "[40, 240] loss: 0.117\n",
      "[40, 300] loss: 0.121\n",
      "[40, 360] loss: 0.127\n",
      "Epoch: 40 -> Loss: 0.168409585953\n",
      "Epoch: 40 -> Test Accuracy: 87.16\n",
      "[41, 60] loss: 0.111\n",
      "[41, 120] loss: 0.109\n",
      "[41, 180] loss: 0.114\n",
      "[41, 240] loss: 0.113\n",
      "[41, 300] loss: 0.113\n",
      "[41, 360] loss: 0.115\n",
      "Epoch: 41 -> Loss: 0.0821808725595\n",
      "Epoch: 41 -> Test Accuracy: 86.62\n",
      "[42, 60] loss: 0.101\n",
      "[42, 120] loss: 0.099\n",
      "[42, 180] loss: 0.114\n",
      "[42, 240] loss: 0.112\n",
      "[42, 300] loss: 0.116\n",
      "[42, 360] loss: 0.112\n",
      "Epoch: 42 -> Loss: 0.120568931103\n",
      "Epoch: 42 -> Test Accuracy: 86.51\n",
      "[43, 60] loss: 0.100\n",
      "[43, 120] loss: 0.100\n",
      "[43, 180] loss: 0.102\n",
      "[43, 240] loss: 0.102\n",
      "[43, 300] loss: 0.110\n",
      "[43, 360] loss: 0.117\n",
      "Epoch: 43 -> Loss: 0.103142634034\n",
      "Epoch: 43 -> Test Accuracy: 86.59\n",
      "[44, 60] loss: 0.100\n",
      "[44, 120] loss: 0.102\n",
      "[44, 180] loss: 0.100\n",
      "[44, 240] loss: 0.105\n",
      "[44, 300] loss: 0.110\n",
      "[44, 360] loss: 0.121\n",
      "Epoch: 44 -> Loss: 0.101813293993\n",
      "Epoch: 44 -> Test Accuracy: 86.83\n",
      "[45, 60] loss: 0.093\n",
      "[45, 120] loss: 0.096\n",
      "[45, 180] loss: 0.103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45, 240] loss: 0.101\n",
      "[45, 300] loss: 0.105\n",
      "[45, 360] loss: 0.112\n",
      "Epoch: 45 -> Loss: 0.11424215138\n",
      "Epoch: 45 -> Test Accuracy: 86.36\n",
      "[46, 60] loss: 0.100\n",
      "[46, 120] loss: 0.095\n",
      "[46, 180] loss: 0.108\n",
      "[46, 240] loss: 0.116\n",
      "[46, 300] loss: 0.112\n",
      "[46, 360] loss: 0.117\n",
      "Epoch: 46 -> Loss: 0.105249211192\n",
      "Epoch: 46 -> Test Accuracy: 86.45\n",
      "[47, 60] loss: 0.096\n",
      "[47, 120] loss: 0.101\n",
      "[47, 180] loss: 0.101\n",
      "[47, 240] loss: 0.103\n",
      "[47, 300] loss: 0.108\n",
      "[47, 360] loss: 0.110\n",
      "Epoch: 47 -> Loss: 0.117482021451\n",
      "Epoch: 47 -> Test Accuracy: 85.42\n",
      "[48, 60] loss: 0.092\n",
      "[48, 120] loss: 0.104\n",
      "[48, 180] loss: 0.097\n",
      "[48, 240] loss: 0.100\n",
      "[48, 300] loss: 0.112\n",
      "[48, 360] loss: 0.111\n",
      "Epoch: 48 -> Loss: 0.166472107172\n",
      "Epoch: 48 -> Test Accuracy: 86.43\n",
      "[49, 60] loss: 0.095\n",
      "[49, 120] loss: 0.100\n",
      "[49, 180] loss: 0.097\n",
      "[49, 240] loss: 0.103\n",
      "[49, 300] loss: 0.112\n",
      "[49, 360] loss: 0.107\n",
      "Epoch: 49 -> Loss: 0.151865303516\n",
      "Epoch: 49 -> Test Accuracy: 86.68\n",
      "[50, 60] loss: 0.102\n",
      "[50, 120] loss: 0.095\n",
      "[50, 180] loss: 0.105\n",
      "[50, 240] loss: 0.114\n",
      "[50, 300] loss: 0.116\n",
      "[50, 360] loss: 0.114\n",
      "Epoch: 50 -> Loss: 0.106735609472\n",
      "Epoch: 50 -> Test Accuracy: 86.44\n",
      "[51, 60] loss: 0.096\n",
      "[51, 120] loss: 0.106\n",
      "[51, 180] loss: 0.105\n",
      "[51, 240] loss: 0.113\n",
      "[51, 300] loss: 0.113\n",
      "[51, 360] loss: 0.116\n",
      "Epoch: 51 -> Loss: 0.214350789785\n",
      "Epoch: 51 -> Test Accuracy: 86.63\n",
      "[52, 60] loss: 0.098\n",
      "[52, 120] loss: 0.097\n",
      "[52, 180] loss: 0.100\n",
      "[52, 240] loss: 0.120\n",
      "[52, 300] loss: 0.114\n",
      "[52, 360] loss: 0.119\n",
      "Epoch: 52 -> Loss: 0.153602093458\n",
      "Epoch: 52 -> Test Accuracy: 86.41\n",
      "[53, 60] loss: 0.103\n",
      "[53, 120] loss: 0.101\n",
      "[53, 180] loss: 0.103\n",
      "[53, 240] loss: 0.113\n",
      "[53, 300] loss: 0.112\n",
      "[53, 360] loss: 0.116\n",
      "Epoch: 53 -> Loss: 0.1313277632\n",
      "Epoch: 53 -> Test Accuracy: 86.42\n",
      "[54, 60] loss: 0.098\n",
      "[54, 120] loss: 0.093\n",
      "[54, 180] loss: 0.108\n",
      "[54, 240] loss: 0.111\n",
      "[54, 300] loss: 0.116\n",
      "[54, 360] loss: 0.114\n",
      "Epoch: 54 -> Loss: 0.0909260213375\n",
      "Epoch: 54 -> Test Accuracy: 86.5\n",
      "[55, 60] loss: 0.098\n",
      "[55, 120] loss: 0.105\n",
      "[55, 180] loss: 0.106\n",
      "[55, 240] loss: 0.111\n",
      "[55, 300] loss: 0.113\n",
      "[55, 360] loss: 0.118\n",
      "Epoch: 55 -> Loss: 0.196861252189\n",
      "Epoch: 55 -> Test Accuracy: 86.68\n",
      "[56, 60] loss: 0.092\n",
      "[56, 120] loss: 0.096\n",
      "[56, 180] loss: 0.106\n",
      "[56, 240] loss: 0.105\n",
      "[56, 300] loss: 0.112\n",
      "[56, 360] loss: 0.110\n",
      "Epoch: 56 -> Loss: 0.0819648057222\n",
      "Epoch: 56 -> Test Accuracy: 86.17\n",
      "[57, 60] loss: 0.094\n",
      "[57, 120] loss: 0.100\n",
      "[57, 180] loss: 0.101\n",
      "[57, 240] loss: 0.106\n",
      "[57, 300] loss: 0.105\n",
      "[57, 360] loss: 0.110\n",
      "Epoch: 57 -> Loss: 0.223959282041\n",
      "Epoch: 57 -> Test Accuracy: 86.28\n",
      "[58, 60] loss: 0.099\n",
      "[58, 120] loss: 0.096\n",
      "[58, 180] loss: 0.111\n",
      "[58, 240] loss: 0.114\n",
      "[58, 300] loss: 0.108\n",
      "[58, 360] loss: 0.112\n",
      "Epoch: 58 -> Loss: 0.149874016643\n",
      "Epoch: 58 -> Test Accuracy: 86.12\n",
      "[59, 60] loss: 0.102\n",
      "[59, 120] loss: 0.102\n",
      "[59, 180] loss: 0.095\n",
      "[59, 240] loss: 0.103\n",
      "[59, 300] loss: 0.117\n",
      "[59, 360] loss: 0.113\n",
      "Epoch: 59 -> Loss: 0.0869215577841\n",
      "Epoch: 59 -> Test Accuracy: 86.67\n",
      "[60, 60] loss: 0.104\n",
      "[60, 120] loss: 0.101\n",
      "[60, 180] loss: 0.105\n",
      "[60, 240] loss: 0.106\n",
      "[60, 300] loss: 0.113\n",
      "[60, 360] loss: 0.120\n",
      "Epoch: 60 -> Loss: 0.119786277413\n",
      "Epoch: 60 -> Test Accuracy: 85.77\n",
      "[61, 60] loss: 0.094\n",
      "[61, 120] loss: 0.106\n",
      "[61, 180] loss: 0.103\n",
      "[61, 240] loss: 0.103\n",
      "[61, 300] loss: 0.102\n",
      "[61, 360] loss: 0.109\n",
      "Epoch: 61 -> Loss: 0.180221885443\n",
      "Epoch: 61 -> Test Accuracy: 86.53\n",
      "[62, 60] loss: 0.100\n",
      "[62, 120] loss: 0.099\n",
      "[62, 180] loss: 0.097\n",
      "[62, 240] loss: 0.109\n",
      "[62, 300] loss: 0.100\n",
      "[62, 360] loss: 0.115\n",
      "Epoch: 62 -> Loss: 0.0962690487504\n",
      "Epoch: 62 -> Test Accuracy: 85.48\n",
      "[63, 60] loss: 0.089\n",
      "[63, 120] loss: 0.101\n",
      "[63, 180] loss: 0.106\n",
      "[63, 240] loss: 0.097\n",
      "[63, 300] loss: 0.102\n",
      "[63, 360] loss: 0.114\n",
      "Epoch: 63 -> Loss: 0.187185049057\n",
      "Epoch: 63 -> Test Accuracy: 85.62\n",
      "[64, 60] loss: 0.100\n",
      "[64, 120] loss: 0.098\n",
      "[64, 180] loss: 0.096\n",
      "[64, 240] loss: 0.107\n",
      "[64, 300] loss: 0.111\n",
      "[64, 360] loss: 0.123\n",
      "Epoch: 64 -> Loss: 0.115998804569\n",
      "Epoch: 64 -> Test Accuracy: 85.98\n",
      "[65, 60] loss: 0.098\n",
      "[65, 120] loss: 0.094\n",
      "[65, 180] loss: 0.108\n",
      "[65, 240] loss: 0.106\n",
      "[65, 300] loss: 0.111\n",
      "[65, 360] loss: 0.108\n",
      "Epoch: 65 -> Loss: 0.110286399722\n",
      "Epoch: 65 -> Test Accuracy: 85.91\n",
      "[66, 60] loss: 0.099\n",
      "[66, 120] loss: 0.099\n",
      "[66, 180] loss: 0.101\n",
      "[66, 240] loss: 0.106\n",
      "[66, 300] loss: 0.105\n",
      "[66, 360] loss: 0.107\n",
      "Epoch: 66 -> Loss: 0.0931174606085\n",
      "Epoch: 66 -> Test Accuracy: 86.34\n",
      "[67, 60] loss: 0.099\n",
      "[67, 120] loss: 0.097\n",
      "[67, 180] loss: 0.100\n",
      "[67, 240] loss: 0.099\n",
      "[67, 300] loss: 0.111\n",
      "[67, 360] loss: 0.109\n",
      "Epoch: 67 -> Loss: 0.109300851822\n",
      "Epoch: 67 -> Test Accuracy: 86.04\n",
      "[68, 60] loss: 0.089\n",
      "[68, 120] loss: 0.100\n",
      "[68, 180] loss: 0.104\n",
      "[68, 240] loss: 0.100\n",
      "[68, 300] loss: 0.111\n",
      "[68, 360] loss: 0.116\n",
      "Epoch: 68 -> Loss: 0.127044886351\n",
      "Epoch: 68 -> Test Accuracy: 86.17\n",
      "[69, 60] loss: 0.097\n",
      "[69, 120] loss: 0.095\n",
      "[69, 180] loss: 0.105\n",
      "[69, 240] loss: 0.103\n",
      "[69, 300] loss: 0.105\n",
      "[69, 360] loss: 0.115\n",
      "Epoch: 69 -> Loss: 0.0878264755011\n",
      "Epoch: 69 -> Test Accuracy: 85.92\n",
      "[70, 60] loss: 0.086\n",
      "[70, 120] loss: 0.089\n",
      "[70, 180] loss: 0.095\n",
      "[70, 240] loss: 0.104\n",
      "[70, 300] loss: 0.116\n",
      "[70, 360] loss: 0.116\n",
      "Epoch: 70 -> Loss: 0.222460463643\n",
      "Epoch: 70 -> Test Accuracy: 86.2\n",
      "[71, 60] loss: 0.074\n",
      "[71, 120] loss: 0.069\n",
      "[71, 180] loss: 0.065\n",
      "[71, 240] loss: 0.063\n",
      "[71, 300] loss: 0.060\n",
      "[71, 360] loss: 0.061\n",
      "Epoch: 71 -> Loss: 0.0430721417069\n",
      "Epoch: 71 -> Test Accuracy: 87.43\n",
      "[72, 60] loss: 0.056\n",
      "[72, 120] loss: 0.053\n",
      "[72, 180] loss: 0.051\n",
      "[72, 240] loss: 0.055\n",
      "[72, 300] loss: 0.052\n",
      "[72, 360] loss: 0.049\n",
      "Epoch: 72 -> Loss: 0.020739370957\n",
      "Epoch: 72 -> Test Accuracy: 87.36\n",
      "[73, 60] loss: 0.052\n",
      "[73, 120] loss: 0.048\n",
      "[73, 180] loss: 0.049\n",
      "[73, 240] loss: 0.053\n",
      "[73, 300] loss: 0.048\n",
      "[73, 360] loss: 0.046\n",
      "Epoch: 73 -> Loss: 0.0618956275284\n",
      "Epoch: 73 -> Test Accuracy: 87.28\n",
      "[74, 60] loss: 0.043\n",
      "[74, 120] loss: 0.043\n",
      "[74, 180] loss: 0.046\n",
      "[74, 240] loss: 0.044\n",
      "[74, 300] loss: 0.043\n",
      "[74, 360] loss: 0.044\n",
      "Epoch: 74 -> Loss: 0.0227687302977\n",
      "Epoch: 74 -> Test Accuracy: 87.54\n",
      "[75, 60] loss: 0.041\n",
      "[75, 120] loss: 0.041\n",
      "[75, 180] loss: 0.043\n",
      "[75, 240] loss: 0.046\n",
      "[75, 300] loss: 0.042\n",
      "[75, 360] loss: 0.044\n",
      "Epoch: 75 -> Loss: 0.0328320674598\n",
      "Epoch: 75 -> Test Accuracy: 87.6\n",
      "[76, 60] loss: 0.038\n",
      "[76, 120] loss: 0.038\n",
      "[76, 180] loss: 0.038\n",
      "[76, 240] loss: 0.041\n",
      "[76, 300] loss: 0.038\n",
      "[76, 360] loss: 0.038\n",
      "Epoch: 76 -> Loss: 0.0473690852523\n",
      "Epoch: 76 -> Test Accuracy: 87.6\n",
      "[77, 60] loss: 0.037\n",
      "[77, 120] loss: 0.037\n",
      "[77, 180] loss: 0.039\n",
      "[77, 240] loss: 0.036\n",
      "[77, 300] loss: 0.040\n",
      "[77, 360] loss: 0.040\n",
      "Epoch: 77 -> Loss: 0.058449883014\n",
      "Epoch: 77 -> Test Accuracy: 87.58\n",
      "[78, 60] loss: 0.035\n",
      "[78, 120] loss: 0.035\n",
      "[78, 180] loss: 0.035\n",
      "[78, 240] loss: 0.035\n",
      "[78, 300] loss: 0.038\n",
      "[78, 360] loss: 0.035\n",
      "Epoch: 78 -> Loss: 0.0412540845573\n",
      "Epoch: 78 -> Test Accuracy: 87.62\n",
      "[79, 60] loss: 0.034\n",
      "[79, 120] loss: 0.033\n",
      "[79, 180] loss: 0.035\n",
      "[79, 240] loss: 0.035\n",
      "[79, 300] loss: 0.037\n",
      "[79, 360] loss: 0.035\n",
      "Epoch: 79 -> Loss: 0.0276602990925\n",
      "Epoch: 79 -> Test Accuracy: 87.6\n",
      "[80, 60] loss: 0.036\n",
      "[80, 120] loss: 0.032\n",
      "[80, 180] loss: 0.036\n",
      "[80, 240] loss: 0.036\n",
      "[80, 300] loss: 0.033\n",
      "[80, 360] loss: 0.033\n",
      "Epoch: 80 -> Loss: 0.0294917374849\n",
      "Epoch: 80 -> Test Accuracy: 87.6\n",
      "[81, 60] loss: 0.031\n",
      "[81, 120] loss: 0.030\n",
      "[81, 180] loss: 0.037\n",
      "[81, 240] loss: 0.032\n",
      "[81, 300] loss: 0.034\n",
      "[81, 360] loss: 0.035\n",
      "Epoch: 81 -> Loss: 0.0334602966905\n",
      "Epoch: 81 -> Test Accuracy: 87.65\n",
      "[82, 60] loss: 0.035\n",
      "[82, 120] loss: 0.031\n",
      "[82, 180] loss: 0.036\n",
      "[82, 240] loss: 0.032\n",
      "[82, 300] loss: 0.033\n",
      "[82, 360] loss: 0.034\n",
      "Epoch: 82 -> Loss: 0.0632911995053\n",
      "Epoch: 82 -> Test Accuracy: 87.48\n",
      "[83, 60] loss: 0.031\n",
      "[83, 120] loss: 0.031\n",
      "[83, 180] loss: 0.032\n",
      "[83, 240] loss: 0.031\n",
      "[83, 300] loss: 0.034\n",
      "[83, 360] loss: 0.033\n",
      "Epoch: 83 -> Loss: 0.0298355165869\n",
      "Epoch: 83 -> Test Accuracy: 87.47\n",
      "[84, 60] loss: 0.030\n",
      "[84, 120] loss: 0.031\n",
      "[84, 180] loss: 0.029\n",
      "[84, 240] loss: 0.033\n",
      "[84, 300] loss: 0.030\n",
      "[84, 360] loss: 0.031\n",
      "Epoch: 84 -> Loss: 0.033080495894\n",
      "Epoch: 84 -> Test Accuracy: 87.8\n",
      "[85, 60] loss: 0.031\n",
      "[85, 120] loss: 0.030\n",
      "[85, 180] loss: 0.030\n",
      "[85, 240] loss: 0.032\n",
      "[85, 300] loss: 0.030\n",
      "[85, 360] loss: 0.029\n",
      "Epoch: 85 -> Loss: 0.0695144832134\n",
      "Epoch: 85 -> Test Accuracy: 87.42\n",
      "[86, 60] loss: 0.029\n",
      "[86, 120] loss: 0.027\n",
      "[86, 180] loss: 0.026\n",
      "[86, 240] loss: 0.027\n",
      "[86, 300] loss: 0.026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86, 360] loss: 0.030\n",
      "Epoch: 86 -> Loss: 0.0289681646973\n",
      "Epoch: 86 -> Test Accuracy: 87.38\n",
      "[87, 60] loss: 0.027\n",
      "[87, 120] loss: 0.028\n",
      "[87, 180] loss: 0.027\n",
      "[87, 240] loss: 0.025\n",
      "[87, 300] loss: 0.028\n",
      "[87, 360] loss: 0.029\n",
      "Epoch: 87 -> Loss: 0.0202650167048\n",
      "Epoch: 87 -> Test Accuracy: 87.52\n",
      "[88, 60] loss: 0.025\n",
      "[88, 120] loss: 0.026\n",
      "[88, 180] loss: 0.027\n",
      "[88, 240] loss: 0.027\n",
      "[88, 300] loss: 0.026\n",
      "[88, 360] loss: 0.027\n",
      "Epoch: 88 -> Loss: 0.0447271168232\n",
      "Epoch: 88 -> Test Accuracy: 87.69\n",
      "[89, 60] loss: 0.025\n",
      "[89, 120] loss: 0.024\n",
      "[89, 180] loss: 0.027\n",
      "[89, 240] loss: 0.027\n",
      "[89, 300] loss: 0.027\n",
      "[89, 360] loss: 0.028\n",
      "Epoch: 89 -> Loss: 0.0322693362832\n",
      "Epoch: 89 -> Test Accuracy: 87.67\n",
      "[90, 60] loss: 0.024\n",
      "[90, 120] loss: 0.025\n",
      "[90, 180] loss: 0.027\n",
      "[90, 240] loss: 0.025\n",
      "[90, 300] loss: 0.029\n",
      "[90, 360] loss: 0.025\n",
      "Epoch: 90 -> Loss: 0.0308546181768\n",
      "Epoch: 90 -> Test Accuracy: 87.72\n",
      "[91, 60] loss: 0.024\n",
      "[91, 120] loss: 0.027\n",
      "[91, 180] loss: 0.025\n",
      "[91, 240] loss: 0.027\n",
      "[91, 300] loss: 0.025\n",
      "[91, 360] loss: 0.027\n",
      "Epoch: 91 -> Loss: 0.0650048404932\n",
      "Epoch: 91 -> Test Accuracy: 87.66\n",
      "[92, 60] loss: 0.027\n",
      "[92, 120] loss: 0.025\n",
      "[92, 180] loss: 0.026\n",
      "[92, 240] loss: 0.024\n",
      "[92, 300] loss: 0.026\n",
      "[92, 360] loss: 0.025\n",
      "Epoch: 92 -> Loss: 0.0337723866105\n",
      "Epoch: 92 -> Test Accuracy: 87.72\n",
      "[93, 60] loss: 0.026\n",
      "[93, 120] loss: 0.026\n",
      "[93, 180] loss: 0.026\n",
      "[93, 240] loss: 0.025\n",
      "[93, 300] loss: 0.027\n",
      "[93, 360] loss: 0.025\n",
      "Epoch: 93 -> Loss: 0.0518565960228\n",
      "Epoch: 93 -> Test Accuracy: 87.63\n",
      "[94, 60] loss: 0.026\n",
      "[94, 120] loss: 0.027\n",
      "[94, 180] loss: 0.026\n",
      "[94, 240] loss: 0.024\n",
      "[94, 300] loss: 0.029\n",
      "[94, 360] loss: 0.023\n",
      "Epoch: 94 -> Loss: 0.0261407587677\n",
      "Epoch: 94 -> Test Accuracy: 87.56\n",
      "[95, 60] loss: 0.025\n",
      "[95, 120] loss: 0.028\n",
      "[95, 180] loss: 0.025\n",
      "[95, 240] loss: 0.026\n",
      "[95, 300] loss: 0.027\n",
      "[95, 360] loss: 0.025\n",
      "Epoch: 95 -> Loss: 0.0199766755104\n",
      "Epoch: 95 -> Test Accuracy: 87.69\n",
      "[96, 60] loss: 0.026\n",
      "[96, 120] loss: 0.026\n",
      "[96, 180] loss: 0.025\n",
      "[96, 240] loss: 0.027\n",
      "[96, 300] loss: 0.023\n",
      "[96, 360] loss: 0.025\n",
      "Epoch: 96 -> Loss: 0.022153545171\n",
      "Epoch: 96 -> Test Accuracy: 87.57\n",
      "[97, 60] loss: 0.025\n",
      "[97, 120] loss: 0.025\n",
      "[97, 180] loss: 0.025\n",
      "[97, 240] loss: 0.026\n",
      "[97, 300] loss: 0.026\n",
      "[97, 360] loss: 0.025\n",
      "Epoch: 97 -> Loss: 0.0429147109389\n",
      "Epoch: 97 -> Test Accuracy: 87.65\n",
      "[98, 60] loss: 0.027\n",
      "[98, 120] loss: 0.024\n",
      "[98, 180] loss: 0.025\n",
      "[98, 240] loss: 0.026\n",
      "[98, 300] loss: 0.025\n",
      "[98, 360] loss: 0.026\n",
      "Epoch: 98 -> Loss: 0.0238744262606\n",
      "Epoch: 98 -> Test Accuracy: 87.73\n",
      "[99, 60] loss: 0.025\n",
      "[99, 120] loss: 0.023\n",
      "[99, 180] loss: 0.024\n",
      "[99, 240] loss: 0.026\n",
      "[99, 300] loss: 0.022\n",
      "[99, 360] loss: 0.025\n",
      "Epoch: 99 -> Loss: 0.0245468616486\n",
      "Epoch: 99 -> Test Accuracy: 87.67\n",
      "[100, 60] loss: 0.026\n",
      "[100, 120] loss: 0.027\n",
      "[100, 180] loss: 0.024\n",
      "[100, 240] loss: 0.023\n",
      "[100, 300] loss: 0.024\n",
      "[100, 360] loss: 0.024\n",
      "Epoch: 100 -> Loss: 0.0229381676763\n",
      "Epoch: 100 -> Test Accuracy: 87.56\n",
      "Finished Training\n",
      "[1, 60] loss: 1.801\n",
      "[1, 120] loss: 1.532\n",
      "[1, 180] loss: 1.368\n",
      "[1, 240] loss: 1.248\n",
      "[1, 300] loss: 1.177\n",
      "[1, 360] loss: 1.121\n",
      "Epoch: 1 -> Loss: 0.938544750214\n",
      "Epoch: 1 -> Test Accuracy: 60.79\n",
      "[2, 60] loss: 1.053\n",
      "[2, 120] loss: 1.014\n",
      "[2, 180] loss: 0.970\n",
      "[2, 240] loss: 0.929\n",
      "[2, 300] loss: 0.928\n",
      "[2, 360] loss: 0.886\n",
      "Epoch: 2 -> Loss: 1.07145953178\n",
      "Epoch: 2 -> Test Accuracy: 68.69\n",
      "[3, 60] loss: 0.827\n",
      "[3, 120] loss: 0.830\n",
      "[3, 180] loss: 0.801\n",
      "[3, 240] loss: 0.781\n",
      "[3, 300] loss: 0.796\n",
      "[3, 360] loss: 0.781\n",
      "Epoch: 3 -> Loss: 0.640021145344\n",
      "Epoch: 3 -> Test Accuracy: 71.58\n",
      "[4, 60] loss: 0.722\n",
      "[4, 120] loss: 0.733\n",
      "[4, 180] loss: 0.726\n",
      "[4, 240] loss: 0.716\n",
      "[4, 300] loss: 0.700\n",
      "[4, 360] loss: 0.709\n",
      "Epoch: 4 -> Loss: 0.702589631081\n",
      "Epoch: 4 -> Test Accuracy: 74.25\n",
      "[5, 60] loss: 0.671\n",
      "[5, 120] loss: 0.665\n",
      "[5, 180] loss: 0.701\n",
      "[5, 240] loss: 0.667\n",
      "[5, 300] loss: 0.657\n",
      "[5, 360] loss: 0.638\n",
      "Epoch: 5 -> Loss: 0.467271000147\n",
      "Epoch: 5 -> Test Accuracy: 74.26\n",
      "[6, 60] loss: 0.633\n",
      "[6, 120] loss: 0.641\n",
      "[6, 180] loss: 0.648\n",
      "[6, 240] loss: 0.613\n",
      "[6, 300] loss: 0.649\n",
      "[6, 360] loss: 0.622\n",
      "Epoch: 6 -> Loss: 0.775640189648\n",
      "Epoch: 6 -> Test Accuracy: 74.67\n",
      "[7, 60] loss: 0.607\n",
      "[7, 120] loss: 0.608\n",
      "[7, 180] loss: 0.586\n",
      "[7, 240] loss: 0.616\n",
      "[7, 300] loss: 0.593\n",
      "[7, 360] loss: 0.582\n",
      "Epoch: 7 -> Loss: 0.666434109211\n",
      "Epoch: 7 -> Test Accuracy: 76.09\n",
      "[8, 60] loss: 0.579\n",
      "[8, 120] loss: 0.567\n",
      "[8, 180] loss: 0.574\n",
      "[8, 240] loss: 0.575\n",
      "[8, 300] loss: 0.577\n",
      "[8, 360] loss: 0.587\n",
      "Epoch: 8 -> Loss: 0.506928563118\n",
      "Epoch: 8 -> Test Accuracy: 79.07\n",
      "[9, 60] loss: 0.537\n",
      "[9, 120] loss: 0.557\n",
      "[9, 180] loss: 0.556\n",
      "[9, 240] loss: 0.566\n",
      "[9, 300] loss: 0.562\n",
      "[9, 360] loss: 0.598\n",
      "Epoch: 9 -> Loss: 0.38289386034\n",
      "Epoch: 9 -> Test Accuracy: 78.83\n",
      "[10, 60] loss: 0.522\n",
      "[10, 120] loss: 0.535\n",
      "[10, 180] loss: 0.551\n",
      "[10, 240] loss: 0.527\n",
      "[10, 300] loss: 0.568\n",
      "[10, 360] loss: 0.547\n",
      "Epoch: 10 -> Loss: 0.599443435669\n",
      "Epoch: 10 -> Test Accuracy: 78.14\n",
      "[11, 60] loss: 0.520\n",
      "[11, 120] loss: 0.526\n",
      "[11, 180] loss: 0.520\n",
      "[11, 240] loss: 0.529\n",
      "[11, 300] loss: 0.526\n",
      "[11, 360] loss: 0.560\n",
      "Epoch: 11 -> Loss: 0.325302362442\n",
      "Epoch: 11 -> Test Accuracy: 79.92\n",
      "[12, 60] loss: 0.523\n",
      "[12, 120] loss: 0.503\n",
      "[12, 180] loss: 0.507\n",
      "[12, 240] loss: 0.493\n",
      "[12, 300] loss: 0.511\n",
      "[12, 360] loss: 0.530\n",
      "Epoch: 12 -> Loss: 0.545344471931\n",
      "Epoch: 12 -> Test Accuracy: 79.69\n",
      "[13, 60] loss: 0.502\n",
      "[13, 120] loss: 0.498\n",
      "[13, 180] loss: 0.517\n",
      "[13, 240] loss: 0.530\n",
      "[13, 300] loss: 0.492\n",
      "[13, 360] loss: 0.525\n",
      "Epoch: 13 -> Loss: 0.500981926918\n",
      "Epoch: 13 -> Test Accuracy: 80.92\n",
      "[14, 60] loss: 0.469\n",
      "[14, 120] loss: 0.479\n",
      "[14, 180] loss: 0.493\n",
      "[14, 240] loss: 0.499\n",
      "[14, 300] loss: 0.512\n",
      "[14, 360] loss: 0.524\n",
      "Epoch: 14 -> Loss: 0.554654955864\n",
      "Epoch: 14 -> Test Accuracy: 81.3\n",
      "[15, 60] loss: 0.471\n",
      "[15, 120] loss: 0.486\n",
      "[15, 180] loss: 0.484\n",
      "[15, 240] loss: 0.493\n",
      "[15, 300] loss: 0.507\n",
      "[15, 360] loss: 0.493\n",
      "Epoch: 15 -> Loss: 0.538033366203\n",
      "Epoch: 15 -> Test Accuracy: 81.36\n",
      "[16, 60] loss: 0.470\n",
      "[16, 120] loss: 0.478\n",
      "[16, 180] loss: 0.482\n",
      "[16, 240] loss: 0.473\n",
      "[16, 300] loss: 0.498\n",
      "[16, 360] loss: 0.475\n",
      "Epoch: 16 -> Loss: 0.462744176388\n",
      "Epoch: 16 -> Test Accuracy: 79.92\n",
      "[17, 60] loss: 0.458\n",
      "[17, 120] loss: 0.475\n",
      "[17, 180] loss: 0.476\n",
      "[17, 240] loss: 0.474\n",
      "[17, 300] loss: 0.497\n",
      "[17, 360] loss: 0.497\n",
      "Epoch: 17 -> Loss: 0.525552153587\n",
      "Epoch: 17 -> Test Accuracy: 80.26\n",
      "[18, 60] loss: 0.452\n",
      "[18, 120] loss: 0.467\n",
      "[18, 180] loss: 0.466\n",
      "[18, 240] loss: 0.481\n",
      "[18, 300] loss: 0.461\n",
      "[18, 360] loss: 0.474\n",
      "Epoch: 18 -> Loss: 0.420210987329\n",
      "Epoch: 18 -> Test Accuracy: 81.4\n",
      "[19, 60] loss: 0.425\n",
      "[19, 120] loss: 0.470\n",
      "[19, 180] loss: 0.438\n",
      "[19, 240] loss: 0.455\n",
      "[19, 300] loss: 0.470\n",
      "[19, 360] loss: 0.472\n",
      "Epoch: 19 -> Loss: 0.391266644001\n",
      "Epoch: 19 -> Test Accuracy: 81.67\n",
      "[20, 60] loss: 0.453\n",
      "[20, 120] loss: 0.458\n",
      "[20, 180] loss: 0.470\n",
      "[20, 240] loss: 0.464\n",
      "[20, 300] loss: 0.437\n",
      "[20, 360] loss: 0.478\n",
      "Epoch: 20 -> Loss: 0.360482543707\n",
      "Epoch: 20 -> Test Accuracy: 82.51\n",
      "[21, 60] loss: 0.431\n",
      "[21, 120] loss: 0.452\n",
      "[21, 180] loss: 0.450\n",
      "[21, 240] loss: 0.449\n",
      "[21, 300] loss: 0.428\n",
      "[21, 360] loss: 0.471\n",
      "Epoch: 21 -> Loss: 0.4215079844\n",
      "Epoch: 21 -> Test Accuracy: 83.17\n",
      "[22, 60] loss: 0.414\n",
      "[22, 120] loss: 0.432\n",
      "[22, 180] loss: 0.449\n",
      "[22, 240] loss: 0.462\n",
      "[22, 300] loss: 0.445\n",
      "[22, 360] loss: 0.456\n",
      "Epoch: 22 -> Loss: 0.698278665543\n",
      "Epoch: 22 -> Test Accuracy: 82.46\n",
      "[23, 60] loss: 0.408\n",
      "[23, 120] loss: 0.450\n",
      "[23, 180] loss: 0.438\n",
      "[23, 240] loss: 0.445\n",
      "[23, 300] loss: 0.452\n",
      "[23, 360] loss: 0.451\n",
      "Epoch: 23 -> Loss: 0.318342715502\n",
      "Epoch: 23 -> Test Accuracy: 81.39\n",
      "[24, 60] loss: 0.427\n",
      "[24, 120] loss: 0.442\n",
      "[24, 180] loss: 0.428\n",
      "[24, 240] loss: 0.446\n",
      "[24, 300] loss: 0.446\n",
      "[24, 360] loss: 0.459\n",
      "Epoch: 24 -> Loss: 0.5905559659\n",
      "Epoch: 24 -> Test Accuracy: 81.76\n",
      "[25, 60] loss: 0.420\n",
      "[25, 120] loss: 0.419\n",
      "[25, 180] loss: 0.442\n",
      "[25, 240] loss: 0.434\n",
      "[25, 300] loss: 0.438\n",
      "[25, 360] loss: 0.469\n",
      "Epoch: 25 -> Loss: 0.427928626537\n",
      "Epoch: 25 -> Test Accuracy: 81.22\n",
      "[26, 60] loss: 0.403\n",
      "[26, 120] loss: 0.427\n",
      "[26, 180] loss: 0.447\n",
      "[26, 240] loss: 0.450\n",
      "[26, 300] loss: 0.433\n",
      "[26, 360] loss: 0.445\n",
      "Epoch: 26 -> Loss: 0.513880610466\n",
      "Epoch: 26 -> Test Accuracy: 83.17\n",
      "[27, 60] loss: 0.420\n",
      "[27, 120] loss: 0.428\n",
      "[27, 180] loss: 0.437\n",
      "[27, 240] loss: 0.425\n",
      "[27, 300] loss: 0.431\n",
      "[27, 360] loss: 0.450\n",
      "Epoch: 27 -> Loss: 0.392382353544\n",
      "Epoch: 27 -> Test Accuracy: 80.36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, 60] loss: 0.411\n",
      "[28, 120] loss: 0.425\n",
      "[28, 180] loss: 0.439\n",
      "[28, 240] loss: 0.427\n",
      "[28, 300] loss: 0.415\n",
      "[28, 360] loss: 0.461\n",
      "Epoch: 28 -> Loss: 0.368227303028\n",
      "Epoch: 28 -> Test Accuracy: 82.59\n",
      "[29, 60] loss: 0.428\n",
      "[29, 120] loss: 0.409\n",
      "[29, 180] loss: 0.431\n",
      "[29, 240] loss: 0.432\n",
      "[29, 300] loss: 0.439\n",
      "[29, 360] loss: 0.434\n",
      "Epoch: 29 -> Loss: 0.340874284506\n",
      "Epoch: 29 -> Test Accuracy: 81.51\n",
      "[30, 60] loss: 0.396\n",
      "[30, 120] loss: 0.419\n",
      "[30, 180] loss: 0.418\n",
      "[30, 240] loss: 0.427\n",
      "[30, 300] loss: 0.440\n",
      "[30, 360] loss: 0.437\n",
      "Epoch: 30 -> Loss: 0.372979491949\n",
      "Epoch: 30 -> Test Accuracy: 83.53\n",
      "[31, 60] loss: 0.378\n",
      "[31, 120] loss: 0.410\n",
      "[31, 180] loss: 0.416\n",
      "[31, 240] loss: 0.445\n",
      "[31, 300] loss: 0.414\n",
      "[31, 360] loss: 0.425\n",
      "Epoch: 31 -> Loss: 0.482057899237\n",
      "Epoch: 31 -> Test Accuracy: 82.84\n",
      "[32, 60] loss: 0.415\n",
      "[32, 120] loss: 0.408\n",
      "[32, 180] loss: 0.414\n",
      "[32, 240] loss: 0.428\n",
      "[32, 300] loss: 0.438\n",
      "[32, 360] loss: 0.408\n",
      "Epoch: 32 -> Loss: 0.370775550604\n",
      "Epoch: 32 -> Test Accuracy: 82.93\n",
      "[33, 60] loss: 0.386\n",
      "[33, 120] loss: 0.387\n",
      "[33, 180] loss: 0.431\n",
      "[33, 240] loss: 0.429\n",
      "[33, 300] loss: 0.429\n",
      "[33, 360] loss: 0.423\n",
      "Epoch: 33 -> Loss: 0.44975233078\n",
      "Epoch: 33 -> Test Accuracy: 82.26\n",
      "[34, 60] loss: 0.388\n",
      "[34, 120] loss: 0.402\n",
      "[34, 180] loss: 0.425\n",
      "[34, 240] loss: 0.409\n",
      "[34, 300] loss: 0.418\n",
      "[34, 360] loss: 0.433\n",
      "Epoch: 34 -> Loss: 0.328498184681\n",
      "Epoch: 34 -> Test Accuracy: 82.23\n",
      "[35, 60] loss: 0.386\n",
      "[35, 120] loss: 0.421\n",
      "[35, 180] loss: 0.423\n",
      "[35, 240] loss: 0.414\n",
      "[35, 300] loss: 0.430\n",
      "[35, 360] loss: 0.424\n",
      "Epoch: 35 -> Loss: 0.459103524685\n",
      "Epoch: 35 -> Test Accuracy: 83.15\n",
      "[36, 60] loss: 0.399\n",
      "[36, 120] loss: 0.407\n",
      "[36, 180] loss: 0.403\n",
      "[36, 240] loss: 0.421\n",
      "[36, 300] loss: 0.420\n",
      "[36, 360] loss: 0.412\n",
      "Epoch: 36 -> Loss: 0.751988768578\n",
      "Epoch: 36 -> Test Accuracy: 82.6\n",
      "[37, 60] loss: 0.401\n",
      "[37, 120] loss: 0.393\n",
      "[37, 180] loss: 0.415\n",
      "[37, 240] loss: 0.425\n",
      "[37, 300] loss: 0.405\n",
      "[37, 360] loss: 0.410\n",
      "Epoch: 37 -> Loss: 0.497308433056\n",
      "Epoch: 37 -> Test Accuracy: 82.48\n",
      "[38, 60] loss: 0.408\n",
      "[38, 120] loss: 0.416\n",
      "[38, 180] loss: 0.407\n",
      "[38, 240] loss: 0.403\n",
      "[38, 300] loss: 0.407\n",
      "[38, 360] loss: 0.422\n",
      "Epoch: 38 -> Loss: 0.550114035606\n",
      "Epoch: 38 -> Test Accuracy: 83.0\n",
      "[39, 60] loss: 0.373\n",
      "[39, 120] loss: 0.407\n",
      "[39, 180] loss: 0.391\n",
      "[39, 240] loss: 0.402\n",
      "[39, 300] loss: 0.421\n",
      "[39, 360] loss: 0.425\n",
      "Epoch: 39 -> Loss: 0.24778957665\n",
      "Epoch: 39 -> Test Accuracy: 81.69\n",
      "[40, 60] loss: 0.394\n",
      "[40, 120] loss: 0.402\n",
      "[40, 180] loss: 0.406\n",
      "[40, 240] loss: 0.414\n",
      "[40, 300] loss: 0.396\n",
      "[40, 360] loss: 0.412\n",
      "Epoch: 40 -> Loss: 0.461419910192\n",
      "Epoch: 40 -> Test Accuracy: 83.06\n",
      "[41, 60] loss: 0.372\n",
      "[41, 120] loss: 0.398\n",
      "[41, 180] loss: 0.392\n",
      "[41, 240] loss: 0.432\n",
      "[41, 300] loss: 0.413\n",
      "[41, 360] loss: 0.417\n",
      "Epoch: 41 -> Loss: 0.412946939468\n",
      "Epoch: 41 -> Test Accuracy: 83.61\n",
      "[42, 60] loss: 0.396\n",
      "[42, 120] loss: 0.372\n",
      "[42, 180] loss: 0.397\n",
      "[42, 240] loss: 0.407\n",
      "[42, 300] loss: 0.420\n",
      "[42, 360] loss: 0.403\n",
      "Epoch: 42 -> Loss: 0.569940567017\n",
      "Epoch: 42 -> Test Accuracy: 84.43\n",
      "[43, 60] loss: 0.369\n",
      "[43, 120] loss: 0.382\n",
      "[43, 180] loss: 0.423\n",
      "[43, 240] loss: 0.425\n",
      "[43, 300] loss: 0.412\n",
      "[43, 360] loss: 0.399\n",
      "Epoch: 43 -> Loss: 0.412780702114\n",
      "Epoch: 43 -> Test Accuracy: 82.91\n",
      "[44, 60] loss: 0.383\n",
      "[44, 120] loss: 0.384\n",
      "[44, 180] loss: 0.416\n",
      "[44, 240] loss: 0.388\n",
      "[44, 300] loss: 0.396\n",
      "[44, 360] loss: 0.408\n",
      "Epoch: 44 -> Loss: 0.31546831131\n",
      "Epoch: 44 -> Test Accuracy: 83.56\n",
      "[45, 60] loss: 0.381\n",
      "[45, 120] loss: 0.407\n",
      "[45, 180] loss: 0.399\n",
      "[45, 240] loss: 0.386\n",
      "[45, 300] loss: 0.414\n",
      "[45, 360] loss: 0.414\n",
      "Epoch: 45 -> Loss: 0.460624843836\n",
      "Epoch: 45 -> Test Accuracy: 82.76\n",
      "[46, 60] loss: 0.372\n",
      "[46, 120] loss: 0.396\n",
      "[46, 180] loss: 0.386\n",
      "[46, 240] loss: 0.414\n",
      "[46, 300] loss: 0.399\n",
      "[46, 360] loss: 0.411\n",
      "Epoch: 46 -> Loss: 0.30645737052\n",
      "Epoch: 46 -> Test Accuracy: 83.53\n",
      "[47, 60] loss: 0.371\n",
      "[47, 120] loss: 0.388\n",
      "[47, 180] loss: 0.390\n",
      "[47, 240] loss: 0.418\n",
      "[47, 300] loss: 0.421\n",
      "[47, 360] loss: 0.416\n",
      "Epoch: 47 -> Loss: 0.469060719013\n",
      "Epoch: 47 -> Test Accuracy: 82.95\n",
      "[48, 60] loss: 0.367\n",
      "[48, 120] loss: 0.399\n",
      "[48, 180] loss: 0.412\n",
      "[48, 240] loss: 0.399\n",
      "[48, 300] loss: 0.392\n",
      "[48, 360] loss: 0.413\n",
      "Epoch: 48 -> Loss: 0.432163417339\n",
      "Epoch: 48 -> Test Accuracy: 83.3\n",
      "[49, 60] loss: 0.376\n",
      "[49, 120] loss: 0.390\n",
      "[49, 180] loss: 0.387\n",
      "[49, 240] loss: 0.416\n",
      "[49, 300] loss: 0.398\n",
      "[49, 360] loss: 0.394\n",
      "Epoch: 49 -> Loss: 0.384488195181\n",
      "Epoch: 49 -> Test Accuracy: 82.1\n",
      "[50, 60] loss: 0.365\n",
      "[50, 120] loss: 0.401\n",
      "[50, 180] loss: 0.395\n",
      "[50, 240] loss: 0.400\n",
      "[50, 300] loss: 0.421\n",
      "[50, 360] loss: 0.407\n",
      "Epoch: 50 -> Loss: 0.411138951778\n",
      "Epoch: 50 -> Test Accuracy: 84.12\n",
      "[51, 60] loss: 0.356\n",
      "[51, 120] loss: 0.371\n",
      "[51, 180] loss: 0.405\n",
      "[51, 240] loss: 0.402\n",
      "[51, 300] loss: 0.416\n",
      "[51, 360] loss: 0.406\n",
      "Epoch: 51 -> Loss: 0.475225120783\n",
      "Epoch: 51 -> Test Accuracy: 83.37\n",
      "[52, 60] loss: 0.362\n",
      "[52, 120] loss: 0.397\n",
      "[52, 180] loss: 0.380\n",
      "[52, 240] loss: 0.402\n",
      "[52, 300] loss: 0.397\n",
      "[52, 360] loss: 0.408\n",
      "Epoch: 52 -> Loss: 0.329698324203\n",
      "Epoch: 52 -> Test Accuracy: 83.34\n",
      "[53, 60] loss: 0.375\n",
      "[53, 120] loss: 0.385\n",
      "[53, 180] loss: 0.380\n",
      "[53, 240] loss: 0.396\n",
      "[53, 300] loss: 0.402\n",
      "[53, 360] loss: 0.401\n",
      "Epoch: 53 -> Loss: 0.395060956478\n",
      "Epoch: 53 -> Test Accuracy: 85.21\n",
      "[54, 60] loss: 0.377\n",
      "[54, 120] loss: 0.390\n",
      "[54, 180] loss: 0.386\n",
      "[54, 240] loss: 0.410\n",
      "[54, 300] loss: 0.405\n",
      "[54, 360] loss: 0.397\n",
      "Epoch: 54 -> Loss: 0.435635089874\n",
      "Epoch: 54 -> Test Accuracy: 82.9\n",
      "[55, 60] loss: 0.372\n",
      "[55, 120] loss: 0.376\n",
      "[55, 180] loss: 0.379\n",
      "[55, 240] loss: 0.388\n",
      "[55, 300] loss: 0.382\n",
      "[55, 360] loss: 0.409\n",
      "Epoch: 55 -> Loss: 0.42573133111\n",
      "Epoch: 55 -> Test Accuracy: 83.88\n",
      "[56, 60] loss: 0.372\n",
      "[56, 120] loss: 0.377\n",
      "[56, 180] loss: 0.375\n",
      "[56, 240] loss: 0.410\n",
      "[56, 300] loss: 0.410\n",
      "[56, 360] loss: 0.412\n",
      "Epoch: 56 -> Loss: 0.312332093716\n",
      "Epoch: 56 -> Test Accuracy: 83.83\n",
      "[57, 60] loss: 0.380\n",
      "[57, 120] loss: 0.374\n",
      "[57, 180] loss: 0.396\n",
      "[57, 240] loss: 0.386\n",
      "[57, 300] loss: 0.388\n",
      "[57, 360] loss: 0.391\n",
      "Epoch: 57 -> Loss: 0.424531877041\n",
      "Epoch: 57 -> Test Accuracy: 83.6\n",
      "[58, 60] loss: 0.367\n",
      "[58, 120] loss: 0.374\n",
      "[58, 180] loss: 0.381\n",
      "[58, 240] loss: 0.410\n",
      "[58, 300] loss: 0.410\n",
      "[58, 360] loss: 0.404\n",
      "Epoch: 58 -> Loss: 0.390975475311\n",
      "Epoch: 58 -> Test Accuracy: 82.96\n",
      "[59, 60] loss: 0.379\n",
      "[59, 120] loss: 0.389\n",
      "[59, 180] loss: 0.376\n",
      "[59, 240] loss: 0.395\n",
      "[59, 300] loss: 0.384\n",
      "[59, 360] loss: 0.385\n",
      "Epoch: 59 -> Loss: 0.385980993509\n",
      "Epoch: 59 -> Test Accuracy: 84.02\n",
      "[60, 60] loss: 0.391\n",
      "[60, 120] loss: 0.373\n",
      "[60, 180] loss: 0.377\n",
      "[60, 240] loss: 0.377\n",
      "[60, 300] loss: 0.405\n",
      "[60, 360] loss: 0.399\n",
      "Epoch: 60 -> Loss: 0.684829056263\n",
      "Epoch: 60 -> Test Accuracy: 83.98\n",
      "[61, 60] loss: 0.275\n",
      "[61, 120] loss: 0.241\n",
      "[61, 180] loss: 0.216\n",
      "[61, 240] loss: 0.214\n",
      "[61, 300] loss: 0.196\n",
      "[61, 360] loss: 0.197\n",
      "Epoch: 61 -> Loss: 0.202611684799\n",
      "Epoch: 61 -> Test Accuracy: 89.53\n",
      "[62, 60] loss: 0.179\n",
      "[62, 120] loss: 0.175\n",
      "[62, 180] loss: 0.162\n",
      "[62, 240] loss: 0.182\n",
      "[62, 300] loss: 0.188\n",
      "[62, 360] loss: 0.176\n",
      "Epoch: 62 -> Loss: 0.107293941081\n",
      "Epoch: 62 -> Test Accuracy: 89.63\n",
      "[63, 60] loss: 0.148\n",
      "[63, 120] loss: 0.151\n",
      "[63, 180] loss: 0.162\n",
      "[63, 240] loss: 0.167\n",
      "[63, 300] loss: 0.159\n",
      "[63, 360] loss: 0.160\n",
      "Epoch: 63 -> Loss: 0.0861823782325\n",
      "Epoch: 63 -> Test Accuracy: 89.03\n",
      "[64, 60] loss: 0.135\n",
      "[64, 120] loss: 0.148\n",
      "[64, 180] loss: 0.151\n",
      "[64, 240] loss: 0.146\n",
      "[64, 300] loss: 0.149\n",
      "[64, 360] loss: 0.153\n",
      "Epoch: 64 -> Loss: 0.12840488553\n",
      "Epoch: 64 -> Test Accuracy: 89.51\n",
      "[65, 60] loss: 0.126\n",
      "[65, 120] loss: 0.131\n",
      "[65, 180] loss: 0.138\n",
      "[65, 240] loss: 0.148\n",
      "[65, 300] loss: 0.162\n",
      "[65, 360] loss: 0.142\n",
      "Epoch: 65 -> Loss: 0.142228171229\n",
      "Epoch: 65 -> Test Accuracy: 89.44\n",
      "[66, 60] loss: 0.128\n",
      "[66, 120] loss: 0.133\n",
      "[66, 180] loss: 0.130\n",
      "[66, 240] loss: 0.145\n",
      "[66, 300] loss: 0.144\n",
      "[66, 360] loss: 0.138\n",
      "Epoch: 66 -> Loss: 0.140437170863\n",
      "Epoch: 66 -> Test Accuracy: 89.38\n",
      "[67, 60] loss: 0.125\n",
      "[67, 120] loss: 0.122\n",
      "[67, 180] loss: 0.136\n",
      "[67, 240] loss: 0.147\n",
      "[67, 300] loss: 0.139\n",
      "[67, 360] loss: 0.140\n",
      "Epoch: 67 -> Loss: 0.0549235753715\n",
      "Epoch: 67 -> Test Accuracy: 89.45\n",
      "[68, 60] loss: 0.123\n",
      "[68, 120] loss: 0.121\n",
      "[68, 180] loss: 0.139\n",
      "[68, 240] loss: 0.127\n",
      "[68, 300] loss: 0.144\n",
      "[68, 360] loss: 0.148\n",
      "Epoch: 68 -> Loss: 0.0817070528865\n",
      "Epoch: 68 -> Test Accuracy: 89.63\n",
      "[69, 60] loss: 0.120\n",
      "[69, 120] loss: 0.116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69, 180] loss: 0.124\n",
      "[69, 240] loss: 0.133\n",
      "[69, 300] loss: 0.142\n",
      "[69, 360] loss: 0.139\n",
      "Epoch: 69 -> Loss: 0.21241530776\n",
      "Epoch: 69 -> Test Accuracy: 89.57\n",
      "[70, 60] loss: 0.123\n",
      "[70, 120] loss: 0.116\n",
      "[70, 180] loss: 0.128\n",
      "[70, 240] loss: 0.125\n",
      "[70, 300] loss: 0.139\n",
      "[70, 360] loss: 0.139\n",
      "Epoch: 70 -> Loss: 0.166151300073\n",
      "Epoch: 70 -> Test Accuracy: 88.83\n",
      "[71, 60] loss: 0.113\n",
      "[71, 120] loss: 0.130\n",
      "[71, 180] loss: 0.125\n",
      "[71, 240] loss: 0.143\n",
      "[71, 300] loss: 0.140\n",
      "[71, 360] loss: 0.144\n",
      "Epoch: 71 -> Loss: 0.167607396841\n",
      "Epoch: 71 -> Test Accuracy: 88.95\n",
      "[72, 60] loss: 0.131\n",
      "[72, 120] loss: 0.135\n",
      "[72, 180] loss: 0.137\n",
      "[72, 240] loss: 0.124\n",
      "[72, 300] loss: 0.149\n",
      "[72, 360] loss: 0.158\n",
      "Epoch: 72 -> Loss: 0.0815150886774\n",
      "Epoch: 72 -> Test Accuracy: 88.72\n",
      "[73, 60] loss: 0.118\n",
      "[73, 120] loss: 0.121\n",
      "[73, 180] loss: 0.130\n",
      "[73, 240] loss: 0.139\n",
      "[73, 300] loss: 0.136\n",
      "[73, 360] loss: 0.145\n",
      "Epoch: 73 -> Loss: 0.083897896111\n",
      "Epoch: 73 -> Test Accuracy: 89.06\n",
      "[74, 60] loss: 0.113\n",
      "[74, 120] loss: 0.112\n",
      "[74, 180] loss: 0.135\n",
      "[74, 240] loss: 0.140\n",
      "[74, 300] loss: 0.147\n",
      "[74, 360] loss: 0.150\n",
      "Epoch: 74 -> Loss: 0.124432660639\n",
      "Epoch: 74 -> Test Accuracy: 88.5\n",
      "[75, 60] loss: 0.121\n",
      "[75, 120] loss: 0.134\n",
      "[75, 180] loss: 0.136\n",
      "[75, 240] loss: 0.141\n",
      "[75, 300] loss: 0.155\n",
      "[75, 360] loss: 0.157\n",
      "Epoch: 75 -> Loss: 0.132649928331\n",
      "Epoch: 75 -> Test Accuracy: 88.59\n",
      "[76, 60] loss: 0.122\n",
      "[76, 120] loss: 0.123\n",
      "[76, 180] loss: 0.139\n",
      "[76, 240] loss: 0.150\n",
      "[76, 300] loss: 0.138\n",
      "[76, 360] loss: 0.143\n",
      "Epoch: 76 -> Loss: 0.297365665436\n",
      "Epoch: 76 -> Test Accuracy: 89.06\n",
      "[77, 60] loss: 0.129\n",
      "[77, 120] loss: 0.124\n",
      "[77, 180] loss: 0.142\n",
      "[77, 240] loss: 0.137\n",
      "[77, 300] loss: 0.145\n",
      "[77, 360] loss: 0.155\n",
      "Epoch: 77 -> Loss: 0.135415911674\n",
      "Epoch: 77 -> Test Accuracy: 89.06\n",
      "[78, 60] loss: 0.113\n",
      "[78, 120] loss: 0.112\n",
      "[78, 180] loss: 0.128\n",
      "[78, 240] loss: 0.133\n",
      "[78, 300] loss: 0.150\n",
      "[78, 360] loss: 0.149\n",
      "Epoch: 78 -> Loss: 0.209286734462\n",
      "Epoch: 78 -> Test Accuracy: 88.19\n",
      "[79, 60] loss: 0.135\n",
      "[79, 120] loss: 0.126\n",
      "[79, 180] loss: 0.137\n",
      "[79, 240] loss: 0.149\n",
      "[79, 300] loss: 0.153\n",
      "[79, 360] loss: 0.152\n",
      "Epoch: 79 -> Loss: 0.169591575861\n",
      "Epoch: 79 -> Test Accuracy: 89.01\n",
      "[80, 60] loss: 0.126\n",
      "[80, 120] loss: 0.135\n",
      "[80, 180] loss: 0.134\n",
      "[80, 240] loss: 0.141\n",
      "[80, 300] loss: 0.137\n",
      "[80, 360] loss: 0.144\n",
      "Epoch: 80 -> Loss: 0.155597522855\n",
      "Epoch: 80 -> Test Accuracy: 88.93\n",
      "[81, 60] loss: 0.124\n",
      "[81, 120] loss: 0.137\n",
      "[81, 180] loss: 0.133\n",
      "[81, 240] loss: 0.128\n",
      "[81, 300] loss: 0.153\n",
      "[81, 360] loss: 0.158\n",
      "Epoch: 81 -> Loss: 0.26280015707\n",
      "Epoch: 81 -> Test Accuracy: 87.33\n",
      "[82, 60] loss: 0.129\n",
      "[82, 120] loss: 0.120\n",
      "[82, 180] loss: 0.125\n",
      "[82, 240] loss: 0.142\n",
      "[82, 300] loss: 0.144\n",
      "[82, 360] loss: 0.136\n",
      "Epoch: 82 -> Loss: 0.146314948797\n",
      "Epoch: 82 -> Test Accuracy: 88.44\n",
      "[83, 60] loss: 0.113\n",
      "[83, 120] loss: 0.129\n",
      "[83, 180] loss: 0.131\n",
      "[83, 240] loss: 0.139\n",
      "[83, 300] loss: 0.134\n",
      "[83, 360] loss: 0.155\n",
      "Epoch: 83 -> Loss: 0.12083029747\n",
      "Epoch: 83 -> Test Accuracy: 88.37\n",
      "[84, 60] loss: 0.116\n",
      "[84, 120] loss: 0.112\n",
      "[84, 180] loss: 0.131\n",
      "[84, 240] loss: 0.144\n",
      "[84, 300] loss: 0.136\n",
      "[84, 360] loss: 0.133\n",
      "Epoch: 84 -> Loss: 0.227545589209\n",
      "Epoch: 84 -> Test Accuracy: 87.32\n",
      "[85, 60] loss: 0.131\n",
      "[85, 120] loss: 0.130\n",
      "[85, 180] loss: 0.127\n",
      "[85, 240] loss: 0.151\n",
      "[85, 300] loss: 0.140\n",
      "[85, 360] loss: 0.144\n",
      "Epoch: 85 -> Loss: 0.139389276505\n",
      "Epoch: 85 -> Test Accuracy: 87.72\n",
      "[86, 60] loss: 0.129\n",
      "[86, 120] loss: 0.125\n",
      "[86, 180] loss: 0.137\n",
      "[86, 240] loss: 0.144\n",
      "[86, 300] loss: 0.138\n",
      "[86, 360] loss: 0.130\n",
      "Epoch: 86 -> Loss: 0.229381948709\n",
      "Epoch: 86 -> Test Accuracy: 88.01\n",
      "[87, 60] loss: 0.136\n",
      "[87, 120] loss: 0.123\n",
      "[87, 180] loss: 0.134\n",
      "[87, 240] loss: 0.139\n",
      "[87, 300] loss: 0.143\n",
      "[87, 360] loss: 0.146\n",
      "Epoch: 87 -> Loss: 0.130107939243\n",
      "Epoch: 87 -> Test Accuracy: 89.04\n",
      "[88, 60] loss: 0.127\n",
      "[88, 120] loss: 0.116\n",
      "[88, 180] loss: 0.128\n",
      "[88, 240] loss: 0.138\n",
      "[88, 300] loss: 0.144\n",
      "[88, 360] loss: 0.140\n",
      "Epoch: 88 -> Loss: 0.263493895531\n",
      "Epoch: 88 -> Test Accuracy: 88.76\n",
      "[89, 60] loss: 0.115\n",
      "[89, 120] loss: 0.112\n",
      "[89, 180] loss: 0.124\n",
      "[89, 240] loss: 0.130\n",
      "[89, 300] loss: 0.123\n",
      "[89, 360] loss: 0.140\n",
      "Epoch: 89 -> Loss: 0.192091152072\n",
      "Epoch: 89 -> Test Accuracy: 87.93\n",
      "[90, 60] loss: 0.116\n",
      "[90, 120] loss: 0.127\n",
      "[90, 180] loss: 0.114\n",
      "[90, 240] loss: 0.131\n",
      "[90, 300] loss: 0.145\n",
      "[90, 360] loss: 0.139\n",
      "Epoch: 90 -> Loss: 0.137090399861\n",
      "Epoch: 90 -> Test Accuracy: 88.14\n",
      "[91, 60] loss: 0.135\n",
      "[91, 120] loss: 0.124\n",
      "[91, 180] loss: 0.128\n",
      "[91, 240] loss: 0.142\n",
      "[91, 300] loss: 0.144\n",
      "[91, 360] loss: 0.137\n",
      "Epoch: 91 -> Loss: 0.111630678177\n",
      "Epoch: 91 -> Test Accuracy: 87.99\n",
      "[92, 60] loss: 0.116\n",
      "[92, 120] loss: 0.114\n",
      "[92, 180] loss: 0.118\n",
      "[92, 240] loss: 0.129\n",
      "[92, 300] loss: 0.125\n",
      "[92, 360] loss: 0.155\n",
      "Epoch: 92 -> Loss: 0.201749756932\n",
      "Epoch: 92 -> Test Accuracy: 88.47\n",
      "[93, 60] loss: 0.106\n",
      "[93, 120] loss: 0.114\n",
      "[93, 180] loss: 0.117\n",
      "[93, 240] loss: 0.146\n",
      "[93, 300] loss: 0.133\n",
      "[93, 360] loss: 0.137\n",
      "Epoch: 93 -> Loss: 0.126006886363\n",
      "Epoch: 93 -> Test Accuracy: 87.95\n",
      "[94, 60] loss: 0.110\n",
      "[94, 120] loss: 0.112\n",
      "[94, 180] loss: 0.125\n",
      "[94, 240] loss: 0.131\n",
      "[94, 300] loss: 0.135\n",
      "[94, 360] loss: 0.142\n",
      "Epoch: 94 -> Loss: 0.102847054601\n",
      "Epoch: 94 -> Test Accuracy: 88.65\n",
      "[95, 60] loss: 0.113\n",
      "[95, 120] loss: 0.111\n",
      "[95, 180] loss: 0.121\n",
      "[95, 240] loss: 0.128\n",
      "[95, 300] loss: 0.131\n",
      "[95, 360] loss: 0.151\n",
      "Epoch: 95 -> Loss: 0.16706636548\n",
      "Epoch: 95 -> Test Accuracy: 88.69\n",
      "[96, 60] loss: 0.113\n",
      "[96, 120] loss: 0.114\n",
      "[96, 180] loss: 0.127\n",
      "[96, 240] loss: 0.123\n",
      "[96, 300] loss: 0.147\n",
      "[96, 360] loss: 0.134\n",
      "Epoch: 96 -> Loss: 0.21862450242\n",
      "Epoch: 96 -> Test Accuracy: 88.42\n",
      "[97, 60] loss: 0.129\n",
      "[97, 120] loss: 0.106\n",
      "[97, 180] loss: 0.117\n",
      "[97, 240] loss: 0.128\n",
      "[97, 300] loss: 0.146\n",
      "[97, 360] loss: 0.145\n",
      "Epoch: 97 -> Loss: 0.129501864314\n",
      "Epoch: 97 -> Test Accuracy: 88.34\n",
      "[98, 60] loss: 0.105\n",
      "[98, 120] loss: 0.116\n",
      "[98, 180] loss: 0.119\n",
      "[98, 240] loss: 0.133\n",
      "[98, 300] loss: 0.131\n",
      "[98, 360] loss: 0.135\n",
      "Epoch: 98 -> Loss: 0.193670362234\n",
      "Epoch: 98 -> Test Accuracy: 87.93\n",
      "[99, 60] loss: 0.126\n",
      "[99, 120] loss: 0.124\n",
      "[99, 180] loss: 0.116\n",
      "[99, 240] loss: 0.127\n",
      "[99, 300] loss: 0.142\n",
      "[99, 360] loss: 0.133\n",
      "Epoch: 99 -> Loss: 0.0936287716031\n",
      "Epoch: 99 -> Test Accuracy: 88.75\n",
      "[100, 60] loss: 0.109\n",
      "[100, 120] loss: 0.102\n",
      "[100, 180] loss: 0.124\n",
      "[100, 240] loss: 0.147\n",
      "[100, 300] loss: 0.135\n",
      "[100, 360] loss: 0.134\n",
      "Epoch: 100 -> Loss: 0.196033358574\n",
      "Epoch: 100 -> Test Accuracy: 88.32\n",
      "[101, 60] loss: 0.114\n",
      "[101, 120] loss: 0.108\n",
      "[101, 180] loss: 0.122\n",
      "[101, 240] loss: 0.121\n",
      "[101, 300] loss: 0.125\n",
      "[101, 360] loss: 0.148\n",
      "Epoch: 101 -> Loss: 0.13508605957\n",
      "Epoch: 101 -> Test Accuracy: 88.06\n",
      "[102, 60] loss: 0.123\n",
      "[102, 120] loss: 0.106\n",
      "[102, 180] loss: 0.126\n",
      "[102, 240] loss: 0.118\n",
      "[102, 300] loss: 0.126\n",
      "[102, 360] loss: 0.129\n",
      "Epoch: 102 -> Loss: 0.149552881718\n",
      "Epoch: 102 -> Test Accuracy: 89.03\n",
      "[103, 60] loss: 0.109\n",
      "[103, 120] loss: 0.112\n",
      "[103, 180] loss: 0.123\n",
      "[103, 240] loss: 0.126\n",
      "[103, 300] loss: 0.127\n",
      "[103, 360] loss: 0.136\n",
      "Epoch: 103 -> Loss: 0.0611979067326\n",
      "Epoch: 103 -> Test Accuracy: 89.06\n",
      "[104, 60] loss: 0.113\n",
      "[104, 120] loss: 0.105\n",
      "[104, 180] loss: 0.120\n",
      "[104, 240] loss: 0.129\n",
      "[104, 300] loss: 0.135\n",
      "[104, 360] loss: 0.130\n",
      "Epoch: 104 -> Loss: 0.0889701172709\n",
      "Epoch: 104 -> Test Accuracy: 89.04\n",
      "[105, 60] loss: 0.119\n",
      "[105, 120] loss: 0.120\n",
      "[105, 180] loss: 0.123\n",
      "[105, 240] loss: 0.136\n",
      "[105, 300] loss: 0.132\n",
      "[105, 360] loss: 0.137\n",
      "Epoch: 105 -> Loss: 0.149314925075\n",
      "Epoch: 105 -> Test Accuracy: 88.92\n",
      "[106, 60] loss: 0.104\n",
      "[106, 120] loss: 0.112\n",
      "[106, 180] loss: 0.122\n",
      "[106, 240] loss: 0.133\n",
      "[106, 300] loss: 0.125\n",
      "[106, 360] loss: 0.111\n",
      "Epoch: 106 -> Loss: 0.174326390028\n",
      "Epoch: 106 -> Test Accuracy: 89.67\n",
      "[107, 60] loss: 0.111\n",
      "[107, 120] loss: 0.098\n",
      "[107, 180] loss: 0.107\n",
      "[107, 240] loss: 0.121\n",
      "[107, 300] loss: 0.122\n",
      "[107, 360] loss: 0.133\n",
      "Epoch: 107 -> Loss: 0.108680680394\n",
      "Epoch: 107 -> Test Accuracy: 88.51\n",
      "[108, 60] loss: 0.108\n",
      "[108, 120] loss: 0.110\n",
      "[108, 180] loss: 0.122\n",
      "[108, 240] loss: 0.125\n",
      "[108, 300] loss: 0.120\n",
      "[108, 360] loss: 0.130\n",
      "Epoch: 108 -> Loss: 0.162829294801\n",
      "Epoch: 108 -> Test Accuracy: 88.1\n",
      "[109, 60] loss: 0.101\n",
      "[109, 120] loss: 0.110\n",
      "[109, 180] loss: 0.131\n",
      "[109, 240] loss: 0.118\n",
      "[109, 300] loss: 0.121\n",
      "[109, 360] loss: 0.130\n",
      "Epoch: 109 -> Loss: 0.083873167634\n",
      "Epoch: 109 -> Test Accuracy: 88.37\n",
      "[110, 60] loss: 0.103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[110, 120] loss: 0.111\n",
      "[110, 180] loss: 0.115\n",
      "[110, 240] loss: 0.114\n",
      "[110, 300] loss: 0.126\n",
      "[110, 360] loss: 0.136\n",
      "Epoch: 110 -> Loss: 0.198725804687\n",
      "Epoch: 110 -> Test Accuracy: 89.22\n",
      "[111, 60] loss: 0.100\n",
      "[111, 120] loss: 0.117\n",
      "[111, 180] loss: 0.113\n",
      "[111, 240] loss: 0.127\n",
      "[111, 300] loss: 0.149\n",
      "[111, 360] loss: 0.139\n",
      "Epoch: 111 -> Loss: 0.181658118963\n",
      "Epoch: 111 -> Test Accuracy: 88.22\n",
      "[112, 60] loss: 0.112\n",
      "[112, 120] loss: 0.118\n",
      "[112, 180] loss: 0.120\n",
      "[112, 240] loss: 0.114\n",
      "[112, 300] loss: 0.131\n",
      "[112, 360] loss: 0.128\n",
      "Epoch: 112 -> Loss: 0.162451073527\n",
      "Epoch: 112 -> Test Accuracy: 89.05\n",
      "[113, 60] loss: 0.110\n",
      "[113, 120] loss: 0.113\n",
      "[113, 180] loss: 0.111\n",
      "[113, 240] loss: 0.116\n",
      "[113, 300] loss: 0.128\n",
      "[113, 360] loss: 0.129\n",
      "Epoch: 113 -> Loss: 0.118588209152\n",
      "Epoch: 113 -> Test Accuracy: 89.06\n",
      "[114, 60] loss: 0.106\n",
      "[114, 120] loss: 0.113\n",
      "[114, 180] loss: 0.116\n",
      "[114, 240] loss: 0.124\n",
      "[114, 300] loss: 0.128\n",
      "[114, 360] loss: 0.134\n",
      "Epoch: 114 -> Loss: 0.142578884959\n",
      "Epoch: 114 -> Test Accuracy: 87.87\n",
      "[115, 60] loss: 0.108\n",
      "[115, 120] loss: 0.110\n",
      "[115, 180] loss: 0.103\n",
      "[115, 240] loss: 0.105\n",
      "[115, 300] loss: 0.124\n",
      "[115, 360] loss: 0.131\n",
      "Epoch: 115 -> Loss: 0.205169916153\n",
      "Epoch: 115 -> Test Accuracy: 88.23\n",
      "[116, 60] loss: 0.110\n",
      "[116, 120] loss: 0.097\n",
      "[116, 180] loss: 0.093\n",
      "[116, 240] loss: 0.116\n",
      "[116, 300] loss: 0.128\n",
      "[116, 360] loss: 0.147\n",
      "Epoch: 116 -> Loss: 0.167852669954\n",
      "Epoch: 116 -> Test Accuracy: 88.45\n",
      "[117, 60] loss: 0.108\n",
      "[117, 120] loss: 0.118\n",
      "[117, 180] loss: 0.102\n",
      "[117, 240] loss: 0.112\n",
      "[117, 300] loss: 0.118\n",
      "[117, 360] loss: 0.126\n",
      "Epoch: 117 -> Loss: 0.236267521977\n",
      "Epoch: 117 -> Test Accuracy: 87.78\n",
      "[118, 60] loss: 0.109\n",
      "[118, 120] loss: 0.108\n",
      "[118, 180] loss: 0.112\n",
      "[118, 240] loss: 0.121\n",
      "[118, 300] loss: 0.124\n",
      "[118, 360] loss: 0.135\n",
      "Epoch: 118 -> Loss: 0.185353726149\n",
      "Epoch: 118 -> Test Accuracy: 88.69\n",
      "[119, 60] loss: 0.110\n",
      "[119, 120] loss: 0.101\n",
      "[119, 180] loss: 0.093\n",
      "[119, 240] loss: 0.107\n",
      "[119, 300] loss: 0.114\n",
      "[119, 360] loss: 0.125\n",
      "Epoch: 119 -> Loss: 0.173399016261\n",
      "Epoch: 119 -> Test Accuracy: 89.23\n",
      "[120, 60] loss: 0.112\n",
      "[120, 120] loss: 0.103\n",
      "[120, 180] loss: 0.114\n",
      "[120, 240] loss: 0.120\n",
      "[120, 300] loss: 0.129\n",
      "[120, 360] loss: 0.134\n",
      "Epoch: 120 -> Loss: 0.146505460143\n",
      "Epoch: 120 -> Test Accuracy: 88.65\n",
      "[121, 60] loss: 0.082\n",
      "[121, 120] loss: 0.059\n",
      "[121, 180] loss: 0.054\n",
      "[121, 240] loss: 0.045\n",
      "[121, 300] loss: 0.041\n",
      "[121, 360] loss: 0.040\n",
      "Epoch: 121 -> Loss: 0.0201989654452\n",
      "Epoch: 121 -> Test Accuracy: 91.26\n",
      "[122, 60] loss: 0.033\n",
      "[122, 120] loss: 0.033\n",
      "[122, 180] loss: 0.031\n",
      "[122, 240] loss: 0.031\n",
      "[122, 300] loss: 0.032\n",
      "[122, 360] loss: 0.032\n",
      "Epoch: 122 -> Loss: 0.0149300750345\n",
      "Epoch: 122 -> Test Accuracy: 91.19\n",
      "[123, 60] loss: 0.025\n",
      "[123, 120] loss: 0.026\n",
      "[123, 180] loss: 0.028\n",
      "[123, 240] loss: 0.025\n",
      "[123, 300] loss: 0.026\n",
      "[123, 360] loss: 0.026\n",
      "Epoch: 123 -> Loss: 0.0331051461399\n",
      "Epoch: 123 -> Test Accuracy: 91.3\n",
      "[124, 60] loss: 0.023\n",
      "[124, 120] loss: 0.022\n",
      "[124, 180] loss: 0.024\n",
      "[124, 240] loss: 0.023\n",
      "[124, 300] loss: 0.022\n",
      "[124, 360] loss: 0.021\n",
      "Epoch: 124 -> Loss: 0.0364554338157\n",
      "Epoch: 124 -> Test Accuracy: 91.34\n",
      "[125, 60] loss: 0.018\n",
      "[125, 120] loss: 0.021\n",
      "[125, 180] loss: 0.017\n",
      "[125, 240] loss: 0.019\n",
      "[125, 300] loss: 0.020\n",
      "[125, 360] loss: 0.022\n",
      "Epoch: 125 -> Loss: 0.00955842714757\n",
      "Epoch: 125 -> Test Accuracy: 91.53\n",
      "[126, 60] loss: 0.018\n",
      "[126, 120] loss: 0.018\n",
      "[126, 180] loss: 0.020\n",
      "[126, 240] loss: 0.018\n",
      "[126, 300] loss: 0.019\n",
      "[126, 360] loss: 0.020\n",
      "Epoch: 126 -> Loss: 0.0162406619638\n",
      "Epoch: 126 -> Test Accuracy: 91.5\n",
      "[127, 60] loss: 0.019\n",
      "[127, 120] loss: 0.017\n",
      "[127, 180] loss: 0.018\n",
      "[127, 240] loss: 0.017\n",
      "[127, 300] loss: 0.017\n",
      "[127, 360] loss: 0.017\n",
      "Epoch: 127 -> Loss: 0.0266072750092\n",
      "Epoch: 127 -> Test Accuracy: 91.42\n",
      "[128, 60] loss: 0.017\n",
      "[128, 120] loss: 0.016\n",
      "[128, 180] loss: 0.015\n",
      "[128, 240] loss: 0.017\n",
      "[128, 300] loss: 0.018\n",
      "[128, 360] loss: 0.016\n",
      "Epoch: 128 -> Loss: 0.0256255604327\n",
      "Epoch: 128 -> Test Accuracy: 91.49\n",
      "[129, 60] loss: 0.014\n",
      "[129, 120] loss: 0.014\n",
      "[129, 180] loss: 0.015\n",
      "[129, 240] loss: 0.015\n",
      "[129, 300] loss: 0.014\n",
      "[129, 360] loss: 0.014\n",
      "Epoch: 129 -> Loss: 0.0141494926065\n",
      "Epoch: 129 -> Test Accuracy: 91.44\n",
      "[130, 60] loss: 0.015\n",
      "[130, 120] loss: 0.017\n",
      "[130, 180] loss: 0.015\n",
      "[130, 240] loss: 0.013\n",
      "[130, 300] loss: 0.015\n",
      "[130, 360] loss: 0.014\n",
      "Epoch: 130 -> Loss: 0.00574296107516\n",
      "Epoch: 130 -> Test Accuracy: 91.33\n",
      "[131, 60] loss: 0.014\n",
      "[131, 120] loss: 0.014\n",
      "[131, 180] loss: 0.013\n",
      "[131, 240] loss: 0.014\n",
      "[131, 300] loss: 0.015\n",
      "[131, 360] loss: 0.013\n",
      "Epoch: 131 -> Loss: 0.0152603806928\n",
      "Epoch: 131 -> Test Accuracy: 91.43\n",
      "[132, 60] loss: 0.012\n",
      "[132, 120] loss: 0.013\n",
      "[132, 180] loss: 0.014\n",
      "[132, 240] loss: 0.012\n",
      "[132, 300] loss: 0.014\n",
      "[132, 360] loss: 0.015\n",
      "Epoch: 132 -> Loss: 0.0102112712339\n",
      "Epoch: 132 -> Test Accuracy: 91.53\n",
      "[133, 60] loss: 0.013\n",
      "[133, 120] loss: 0.012\n",
      "[133, 180] loss: 0.012\n",
      "[133, 240] loss: 0.013\n",
      "[133, 300] loss: 0.013\n",
      "[133, 360] loss: 0.013\n",
      "Epoch: 133 -> Loss: 0.00602269778028\n",
      "Epoch: 133 -> Test Accuracy: 91.53\n",
      "[134, 60] loss: 0.012\n",
      "[134, 120] loss: 0.012\n",
      "[134, 180] loss: 0.013\n",
      "[134, 240] loss: 0.014\n",
      "[134, 300] loss: 0.013\n",
      "[134, 360] loss: 0.014\n",
      "Epoch: 134 -> Loss: 0.00538192410022\n",
      "Epoch: 134 -> Test Accuracy: 91.6\n",
      "[135, 60] loss: 0.012\n",
      "[135, 120] loss: 0.011\n",
      "[135, 180] loss: 0.012\n",
      "[135, 240] loss: 0.011\n",
      "[135, 300] loss: 0.012\n",
      "[135, 360] loss: 0.013\n",
      "Epoch: 135 -> Loss: 0.00722922664136\n",
      "Epoch: 135 -> Test Accuracy: 91.45\n",
      "[136, 60] loss: 0.013\n",
      "[136, 120] loss: 0.010\n",
      "[136, 180] loss: 0.010\n",
      "[136, 240] loss: 0.013\n",
      "[136, 300] loss: 0.012\n",
      "[136, 360] loss: 0.012\n",
      "Epoch: 136 -> Loss: 0.00468860287219\n",
      "Epoch: 136 -> Test Accuracy: 91.67\n",
      "[137, 60] loss: 0.012\n",
      "[137, 120] loss: 0.011\n",
      "[137, 180] loss: 0.011\n",
      "[137, 240] loss: 0.011\n",
      "[137, 300] loss: 0.011\n",
      "[137, 360] loss: 0.013\n",
      "Epoch: 137 -> Loss: 0.0204970128834\n",
      "Epoch: 137 -> Test Accuracy: 91.53\n",
      "[138, 60] loss: 0.011\n",
      "[138, 120] loss: 0.011\n",
      "[138, 180] loss: 0.010\n",
      "[138, 240] loss: 0.011\n",
      "[138, 300] loss: 0.011\n",
      "[138, 360] loss: 0.012\n",
      "Epoch: 138 -> Loss: 0.00797003507614\n",
      "Epoch: 138 -> Test Accuracy: 91.56\n",
      "[139, 60] loss: 0.011\n",
      "[139, 120] loss: 0.010\n",
      "[139, 180] loss: 0.010\n",
      "[139, 240] loss: 0.010\n",
      "[139, 300] loss: 0.011\n",
      "[139, 360] loss: 0.011\n",
      "Epoch: 139 -> Loss: 0.0278520230204\n",
      "Epoch: 139 -> Test Accuracy: 91.52\n",
      "[140, 60] loss: 0.011\n",
      "[140, 120] loss: 0.012\n",
      "[140, 180] loss: 0.011\n",
      "[140, 240] loss: 0.011\n",
      "[140, 300] loss: 0.011\n",
      "[140, 360] loss: 0.010\n",
      "Epoch: 140 -> Loss: 0.00350975990295\n",
      "Epoch: 140 -> Test Accuracy: 91.52\n",
      "[141, 60] loss: 0.010\n",
      "[141, 120] loss: 0.012\n",
      "[141, 180] loss: 0.010\n",
      "[141, 240] loss: 0.012\n",
      "[141, 300] loss: 0.011\n",
      "[141, 360] loss: 0.011\n",
      "Epoch: 141 -> Loss: 0.0121670542285\n",
      "Epoch: 141 -> Test Accuracy: 91.71\n",
      "[142, 60] loss: 0.010\n",
      "[142, 120] loss: 0.009\n",
      "[142, 180] loss: 0.010\n",
      "[142, 240] loss: 0.010\n",
      "[142, 300] loss: 0.009\n",
      "[142, 360] loss: 0.010\n",
      "Epoch: 142 -> Loss: 0.00886491499841\n",
      "Epoch: 142 -> Test Accuracy: 91.58\n",
      "[143, 60] loss: 0.010\n",
      "[143, 120] loss: 0.010\n",
      "[143, 180] loss: 0.010\n",
      "[143, 240] loss: 0.011\n",
      "[143, 300] loss: 0.010\n",
      "[143, 360] loss: 0.010\n",
      "Epoch: 143 -> Loss: 0.0111482441425\n",
      "Epoch: 143 -> Test Accuracy: 91.44\n",
      "[144, 60] loss: 0.010\n",
      "[144, 120] loss: 0.009\n",
      "[144, 180] loss: 0.010\n",
      "[144, 240] loss: 0.009\n",
      "[144, 300] loss: 0.010\n",
      "[144, 360] loss: 0.010\n",
      "Epoch: 144 -> Loss: 0.0168181657791\n",
      "Epoch: 144 -> Test Accuracy: 91.47\n",
      "[145, 60] loss: 0.010\n",
      "[145, 120] loss: 0.009\n",
      "[145, 180] loss: 0.011\n",
      "[145, 240] loss: 0.011\n",
      "[145, 300] loss: 0.011\n",
      "[145, 360] loss: 0.009\n",
      "Epoch: 145 -> Loss: 0.00389587879181\n",
      "Epoch: 145 -> Test Accuracy: 91.44\n",
      "[146, 60] loss: 0.010\n",
      "[146, 120] loss: 0.009\n",
      "[146, 180] loss: 0.009\n",
      "[146, 240] loss: 0.008\n",
      "[146, 300] loss: 0.010\n",
      "[146, 360] loss: 0.010\n",
      "Epoch: 146 -> Loss: 0.00804376602173\n",
      "Epoch: 146 -> Test Accuracy: 91.41\n",
      "[147, 60] loss: 0.009\n",
      "[147, 120] loss: 0.009\n",
      "[147, 180] loss: 0.010\n",
      "[147, 240] loss: 0.009\n",
      "[147, 300] loss: 0.010\n",
      "[147, 360] loss: 0.010\n",
      "Epoch: 147 -> Loss: 0.00352920894511\n",
      "Epoch: 147 -> Test Accuracy: 91.4\n",
      "[148, 60] loss: 0.009\n",
      "[148, 120] loss: 0.010\n",
      "[148, 180] loss: 0.010\n",
      "[148, 240] loss: 0.009\n",
      "[148, 300] loss: 0.009\n",
      "[148, 360] loss: 0.011\n",
      "Epoch: 148 -> Loss: 0.0096907671541\n",
      "Epoch: 148 -> Test Accuracy: 91.45\n",
      "[149, 60] loss: 0.009\n",
      "[149, 120] loss: 0.011\n",
      "[149, 180] loss: 0.009\n",
      "[149, 240] loss: 0.010\n",
      "[149, 300] loss: 0.009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[149, 360] loss: 0.008\n",
      "Epoch: 149 -> Loss: 0.00937450490892\n",
      "Epoch: 149 -> Test Accuracy: 91.6\n",
      "[150, 60] loss: 0.008\n",
      "[150, 120] loss: 0.009\n",
      "[150, 180] loss: 0.009\n",
      "[150, 240] loss: 0.009\n",
      "[150, 300] loss: 0.009\n",
      "[150, 360] loss: 0.009\n",
      "Epoch: 150 -> Loss: 0.0093620121479\n",
      "Epoch: 150 -> Test Accuracy: 91.55\n",
      "[151, 60] loss: 0.009\n",
      "[151, 120] loss: 0.008\n",
      "[151, 180] loss: 0.009\n",
      "[151, 240] loss: 0.010\n",
      "[151, 300] loss: 0.010\n",
      "[151, 360] loss: 0.010\n",
      "Epoch: 151 -> Loss: 0.0233277864754\n",
      "Epoch: 151 -> Test Accuracy: 91.83\n",
      "[152, 60] loss: 0.010\n",
      "[152, 120] loss: 0.008\n",
      "[152, 180] loss: 0.009\n",
      "[152, 240] loss: 0.010\n",
      "[152, 300] loss: 0.010\n",
      "[152, 360] loss: 0.009\n",
      "Epoch: 152 -> Loss: 0.00585313420743\n",
      "Epoch: 152 -> Test Accuracy: 91.83\n",
      "[153, 60] loss: 0.009\n",
      "[153, 120] loss: 0.009\n",
      "[153, 180] loss: 0.008\n",
      "[153, 240] loss: 0.009\n",
      "[153, 300] loss: 0.009\n",
      "[153, 360] loss: 0.010\n",
      "Epoch: 153 -> Loss: 0.0230761114508\n",
      "Epoch: 153 -> Test Accuracy: 91.78\n",
      "[154, 60] loss: 0.008\n",
      "[154, 120] loss: 0.009\n",
      "[154, 180] loss: 0.009\n",
      "[154, 240] loss: 0.008\n",
      "[154, 300] loss: 0.008\n",
      "[154, 360] loss: 0.010\n",
      "Epoch: 154 -> Loss: 0.0183357410133\n",
      "Epoch: 154 -> Test Accuracy: 91.55\n",
      "[155, 60] loss: 0.009\n",
      "[155, 120] loss: 0.009\n",
      "[155, 180] loss: 0.009\n",
      "[155, 240] loss: 0.009\n",
      "[155, 300] loss: 0.008\n",
      "[155, 360] loss: 0.008\n",
      "Epoch: 155 -> Loss: 0.0130016263574\n",
      "Epoch: 155 -> Test Accuracy: 91.48\n",
      "[156, 60] loss: 0.009\n",
      "[156, 120] loss: 0.009\n",
      "[156, 180] loss: 0.009\n",
      "[156, 240] loss: 0.009\n",
      "[156, 300] loss: 0.009\n",
      "[156, 360] loss: 0.009\n",
      "Epoch: 156 -> Loss: 0.0111366687343\n",
      "Epoch: 156 -> Test Accuracy: 91.56\n",
      "[157, 60] loss: 0.009\n",
      "[157, 120] loss: 0.009\n",
      "[157, 180] loss: 0.009\n",
      "[157, 240] loss: 0.010\n",
      "[157, 300] loss: 0.010\n",
      "[157, 360] loss: 0.009\n",
      "Epoch: 157 -> Loss: 0.0112751778215\n",
      "Epoch: 157 -> Test Accuracy: 91.43\n",
      "[158, 60] loss: 0.009\n",
      "[158, 120] loss: 0.008\n",
      "[158, 180] loss: 0.009\n",
      "[158, 240] loss: 0.010\n",
      "[158, 300] loss: 0.010\n",
      "[158, 360] loss: 0.009\n",
      "Epoch: 158 -> Loss: 0.0147038577124\n",
      "Epoch: 158 -> Test Accuracy: 91.7\n",
      "[159, 60] loss: 0.008\n",
      "[159, 120] loss: 0.008\n",
      "[159, 180] loss: 0.008\n",
      "[159, 240] loss: 0.009\n",
      "[159, 300] loss: 0.009\n",
      "[159, 360] loss: 0.009\n",
      "Epoch: 159 -> Loss: 0.0175522714853\n",
      "Epoch: 159 -> Test Accuracy: 91.4\n",
      "[160, 60] loss: 0.009\n",
      "[160, 120] loss: 0.008\n",
      "[160, 180] loss: 0.008\n",
      "[160, 240] loss: 0.010\n",
      "[160, 300] loss: 0.008\n",
      "[160, 360] loss: 0.009\n",
      "Epoch: 160 -> Loss: 0.0125051736832\n",
      "Epoch: 160 -> Test Accuracy: 91.58\n",
      "[161, 60] loss: 0.008\n",
      "[161, 120] loss: 0.009\n",
      "[161, 180] loss: 0.008\n",
      "[161, 240] loss: 0.008\n",
      "[161, 300] loss: 0.008\n",
      "[161, 360] loss: 0.008\n",
      "Epoch: 161 -> Loss: 0.00754342367873\n",
      "Epoch: 161 -> Test Accuracy: 91.45\n",
      "[162, 60] loss: 0.007\n",
      "[162, 120] loss: 0.007\n",
      "[162, 180] loss: 0.008\n",
      "[162, 240] loss: 0.008\n",
      "[162, 300] loss: 0.008\n",
      "[162, 360] loss: 0.007\n",
      "Epoch: 162 -> Loss: 0.0165983177722\n",
      "Epoch: 162 -> Test Accuracy: 91.49\n",
      "[163, 60] loss: 0.006\n",
      "[163, 120] loss: 0.006\n",
      "[163, 180] loss: 0.008\n",
      "[163, 240] loss: 0.007\n",
      "[163, 300] loss: 0.007\n",
      "[163, 360] loss: 0.007\n",
      "Epoch: 163 -> Loss: 0.0219592954963\n",
      "Epoch: 163 -> Test Accuracy: 91.58\n",
      "[164, 60] loss: 0.008\n",
      "[164, 120] loss: 0.007\n",
      "[164, 180] loss: 0.006\n",
      "[164, 240] loss: 0.007\n",
      "[164, 300] loss: 0.007\n",
      "[164, 360] loss: 0.007\n",
      "Epoch: 164 -> Loss: 0.0203408990055\n",
      "Epoch: 164 -> Test Accuracy: 91.62\n",
      "[165, 60] loss: 0.007\n",
      "[165, 120] loss: 0.007\n",
      "[165, 180] loss: 0.007\n",
      "[165, 240] loss: 0.007\n",
      "[165, 300] loss: 0.007\n",
      "[165, 360] loss: 0.006\n",
      "Epoch: 165 -> Loss: 0.00942289829254\n",
      "Epoch: 165 -> Test Accuracy: 91.58\n",
      "[166, 60] loss: 0.006\n",
      "[166, 120] loss: 0.006\n",
      "[166, 180] loss: 0.007\n",
      "[166, 240] loss: 0.006\n",
      "[166, 300] loss: 0.007\n",
      "[166, 360] loss: 0.007\n",
      "Epoch: 166 -> Loss: 0.0138512132689\n",
      "Epoch: 166 -> Test Accuracy: 91.6\n",
      "[167, 60] loss: 0.006\n",
      "[167, 120] loss: 0.007\n",
      "[167, 180] loss: 0.006\n",
      "[167, 240] loss: 0.008\n",
      "[167, 300] loss: 0.007\n",
      "[167, 360] loss: 0.007\n",
      "Epoch: 167 -> Loss: 0.00756393093616\n",
      "Epoch: 167 -> Test Accuracy: 91.64\n",
      "[168, 60] loss: 0.007\n",
      "[168, 120] loss: 0.007\n",
      "[168, 180] loss: 0.007\n",
      "[168, 240] loss: 0.006\n",
      "[168, 300] loss: 0.006\n",
      "[168, 360] loss: 0.007\n",
      "Epoch: 168 -> Loss: 0.00938782654703\n",
      "Epoch: 168 -> Test Accuracy: 91.63\n",
      "[169, 60] loss: 0.007\n",
      "[169, 120] loss: 0.006\n",
      "[169, 180] loss: 0.006\n",
      "[169, 240] loss: 0.007\n",
      "[169, 300] loss: 0.006\n",
      "[169, 360] loss: 0.006\n",
      "Epoch: 169 -> Loss: 0.0103661715984\n",
      "Epoch: 169 -> Test Accuracy: 91.7\n",
      "[170, 60] loss: 0.007\n",
      "[170, 120] loss: 0.007\n",
      "[170, 180] loss: 0.006\n",
      "[170, 240] loss: 0.007\n",
      "[170, 300] loss: 0.006\n",
      "[170, 360] loss: 0.007\n",
      "Epoch: 170 -> Loss: 0.00467484584078\n",
      "Epoch: 170 -> Test Accuracy: 91.5\n",
      "[171, 60] loss: 0.007\n",
      "[171, 120] loss: 0.006\n",
      "[171, 180] loss: 0.006\n",
      "[171, 240] loss: 0.006\n",
      "[171, 300] loss: 0.007\n",
      "[171, 360] loss: 0.007\n",
      "Epoch: 171 -> Loss: 0.00826844014227\n",
      "Epoch: 171 -> Test Accuracy: 91.49\n",
      "[172, 60] loss: 0.007\n",
      "[172, 120] loss: 0.006\n",
      "[172, 180] loss: 0.007\n",
      "[172, 240] loss: 0.006\n",
      "[172, 300] loss: 0.007\n",
      "[172, 360] loss: 0.006\n",
      "Epoch: 172 -> Loss: 0.00288450717926\n",
      "Epoch: 172 -> Test Accuracy: 91.61\n",
      "[173, 60] loss: 0.006\n",
      "[173, 120] loss: 0.006\n",
      "[173, 180] loss: 0.007\n",
      "[173, 240] loss: 0.006\n",
      "[173, 300] loss: 0.007\n",
      "[173, 360] loss: 0.006\n",
      "Epoch: 173 -> Loss: 0.00525614013895\n",
      "Epoch: 173 -> Test Accuracy: 91.69\n",
      "[174, 60] loss: 0.006\n",
      "[174, 120] loss: 0.007\n",
      "[174, 180] loss: 0.006\n",
      "[174, 240] loss: 0.007\n",
      "[174, 300] loss: 0.006\n",
      "[174, 360] loss: 0.007\n",
      "Epoch: 174 -> Loss: 0.0163894109428\n",
      "Epoch: 174 -> Test Accuracy: 91.57\n",
      "[175, 60] loss: 0.007\n",
      "[175, 120] loss: 0.006\n",
      "[175, 180] loss: 0.006\n",
      "[175, 240] loss: 0.007\n",
      "[175, 300] loss: 0.007\n",
      "[175, 360] loss: 0.006\n",
      "Epoch: 175 -> Loss: 0.0158800967038\n",
      "Epoch: 175 -> Test Accuracy: 91.6\n",
      "[176, 60] loss: 0.006\n",
      "[176, 120] loss: 0.006\n",
      "[176, 180] loss: 0.007\n",
      "[176, 240] loss: 0.007\n",
      "[176, 300] loss: 0.006\n",
      "[176, 360] loss: 0.007\n",
      "Epoch: 176 -> Loss: 0.00688719749451\n",
      "Epoch: 176 -> Test Accuracy: 91.74\n",
      "[177, 60] loss: 0.006\n",
      "[177, 120] loss: 0.007\n",
      "[177, 180] loss: 0.006\n",
      "[177, 240] loss: 0.006\n",
      "[177, 300] loss: 0.006\n",
      "[177, 360] loss: 0.006\n",
      "Epoch: 177 -> Loss: 0.00810313224792\n",
      "Epoch: 177 -> Test Accuracy: 91.71\n",
      "[178, 60] loss: 0.006\n",
      "[178, 120] loss: 0.007\n",
      "[178, 180] loss: 0.007\n",
      "[178, 240] loss: 0.006\n",
      "[178, 300] loss: 0.006\n",
      "[178, 360] loss: 0.007\n",
      "Epoch: 178 -> Loss: 0.00647676596418\n",
      "Epoch: 178 -> Test Accuracy: 91.65\n",
      "[179, 60] loss: 0.007\n",
      "[179, 120] loss: 0.006\n",
      "[179, 180] loss: 0.007\n",
      "[179, 240] loss: 0.007\n",
      "[179, 300] loss: 0.006\n",
      "[179, 360] loss: 0.007\n",
      "Epoch: 179 -> Loss: 0.00778213143349\n",
      "Epoch: 179 -> Test Accuracy: 91.64\n",
      "[180, 60] loss: 0.006\n",
      "[180, 120] loss: 0.006\n",
      "[180, 180] loss: 0.006\n",
      "[180, 240] loss: 0.007\n",
      "[180, 300] loss: 0.006\n",
      "[180, 360] loss: 0.007\n",
      "Epoch: 180 -> Loss: 0.00328329205513\n",
      "Epoch: 180 -> Test Accuracy: 91.8\n",
      "[181, 60] loss: 0.007\n",
      "[181, 120] loss: 0.006\n",
      "[181, 180] loss: 0.007\n",
      "[181, 240] loss: 0.007\n",
      "[181, 300] loss: 0.006\n",
      "[181, 360] loss: 0.006\n",
      "Epoch: 181 -> Loss: 0.0125318644568\n",
      "Epoch: 181 -> Test Accuracy: 91.6\n",
      "[182, 60] loss: 0.006\n",
      "[182, 120] loss: 0.006\n",
      "[182, 180] loss: 0.006\n",
      "[182, 240] loss: 0.006\n",
      "[182, 300] loss: 0.006\n",
      "[182, 360] loss: 0.006\n",
      "Epoch: 182 -> Loss: 0.0082436921075\n",
      "Epoch: 182 -> Test Accuracy: 91.72\n",
      "[183, 60] loss: 0.006\n",
      "[183, 120] loss: 0.006\n",
      "[183, 180] loss: 0.006\n",
      "[183, 240] loss: 0.006\n",
      "[183, 300] loss: 0.007\n",
      "[183, 360] loss: 0.006\n",
      "Epoch: 183 -> Loss: 0.0194735471159\n",
      "Epoch: 183 -> Test Accuracy: 91.71\n",
      "[184, 60] loss: 0.007\n",
      "[184, 120] loss: 0.006\n",
      "[184, 180] loss: 0.006\n",
      "[184, 240] loss: 0.006\n",
      "[184, 300] loss: 0.006\n",
      "[184, 360] loss: 0.007\n",
      "Epoch: 184 -> Loss: 0.00485741486773\n",
      "Epoch: 184 -> Test Accuracy: 91.74\n",
      "[185, 60] loss: 0.006\n",
      "[185, 120] loss: 0.006\n",
      "[185, 180] loss: 0.006\n",
      "[185, 240] loss: 0.006\n",
      "[185, 300] loss: 0.006\n",
      "[185, 360] loss: 0.007\n",
      "Epoch: 185 -> Loss: 0.00470224022865\n",
      "Epoch: 185 -> Test Accuracy: 91.7\n",
      "[186, 60] loss: 0.006\n",
      "[186, 120] loss: 0.006\n",
      "[186, 180] loss: 0.007\n",
      "[186, 240] loss: 0.006\n",
      "[186, 300] loss: 0.006\n",
      "[186, 360] loss: 0.006\n",
      "Epoch: 186 -> Loss: 0.0158434510231\n",
      "Epoch: 186 -> Test Accuracy: 91.71\n",
      "[187, 60] loss: 0.006\n",
      "[187, 120] loss: 0.007\n",
      "[187, 180] loss: 0.006\n",
      "[187, 240] loss: 0.007\n",
      "[187, 300] loss: 0.006\n",
      "[187, 360] loss: 0.006\n",
      "Epoch: 187 -> Loss: 0.0109576554969\n",
      "Epoch: 187 -> Test Accuracy: 91.72\n",
      "[188, 60] loss: 0.006\n",
      "[188, 120] loss: 0.007\n",
      "[188, 180] loss: 0.006\n",
      "[188, 240] loss: 0.006\n",
      "[188, 300] loss: 0.006\n",
      "[188, 360] loss: 0.007\n",
      "Epoch: 188 -> Loss: 0.00712598580867\n",
      "Epoch: 188 -> Test Accuracy: 91.62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[189, 60] loss: 0.006\n",
      "[189, 120] loss: 0.006\n",
      "[189, 180] loss: 0.006\n",
      "[189, 240] loss: 0.007\n",
      "[189, 300] loss: 0.006\n",
      "[189, 360] loss: 0.006\n",
      "Epoch: 189 -> Loss: 0.00674162525684\n",
      "Epoch: 189 -> Test Accuracy: 91.64\n",
      "[190, 60] loss: 0.006\n",
      "[190, 120] loss: 0.006\n",
      "[190, 180] loss: 0.006\n",
      "[190, 240] loss: 0.006\n",
      "[190, 300] loss: 0.007\n",
      "[190, 360] loss: 0.006\n",
      "Epoch: 190 -> Loss: 0.00866503734142\n",
      "Epoch: 190 -> Test Accuracy: 91.63\n",
      "[191, 60] loss: 0.006\n",
      "[191, 120] loss: 0.007\n",
      "[191, 180] loss: 0.007\n",
      "[191, 240] loss: 0.006\n",
      "[191, 300] loss: 0.006\n",
      "[191, 360] loss: 0.006\n",
      "Epoch: 191 -> Loss: 0.00852023996413\n",
      "Epoch: 191 -> Test Accuracy: 91.59\n",
      "[192, 60] loss: 0.006\n",
      "[192, 120] loss: 0.006\n",
      "[192, 180] loss: 0.007\n",
      "[192, 240] loss: 0.006\n",
      "[192, 300] loss: 0.007\n",
      "[192, 360] loss: 0.006\n",
      "Epoch: 192 -> Loss: 0.0124972881749\n",
      "Epoch: 192 -> Test Accuracy: 91.74\n",
      "[193, 60] loss: 0.005\n",
      "[193, 120] loss: 0.006\n",
      "[193, 180] loss: 0.007\n",
      "[193, 240] loss: 0.006\n",
      "[193, 300] loss: 0.006\n",
      "[193, 360] loss: 0.006\n",
      "Epoch: 193 -> Loss: 0.00945932231843\n",
      "Epoch: 193 -> Test Accuracy: 91.57\n",
      "[194, 60] loss: 0.006\n",
      "[194, 120] loss: 0.006\n",
      "[194, 180] loss: 0.006\n",
      "[194, 240] loss: 0.006\n",
      "[194, 300] loss: 0.006\n",
      "[194, 360] loss: 0.007\n",
      "Epoch: 194 -> Loss: 0.0133071336895\n",
      "Epoch: 194 -> Test Accuracy: 91.54\n",
      "[195, 60] loss: 0.006\n",
      "[195, 120] loss: 0.007\n",
      "[195, 180] loss: 0.006\n",
      "[195, 240] loss: 0.006\n",
      "[195, 300] loss: 0.006\n",
      "[195, 360] loss: 0.006\n",
      "Epoch: 195 -> Loss: 0.0137794138864\n",
      "Epoch: 195 -> Test Accuracy: 91.5\n",
      "[196, 60] loss: 0.006\n",
      "[196, 120] loss: 0.007\n",
      "[196, 180] loss: 0.006\n",
      "[196, 240] loss: 0.006\n",
      "[196, 300] loss: 0.006\n",
      "[196, 360] loss: 0.007\n",
      "Epoch: 196 -> Loss: 0.00571876764297\n",
      "Epoch: 196 -> Test Accuracy: 91.57\n",
      "[197, 60] loss: 0.006\n",
      "[197, 120] loss: 0.007\n",
      "[197, 180] loss: 0.006\n",
      "[197, 240] loss: 0.006\n",
      "[197, 300] loss: 0.006\n",
      "[197, 360] loss: 0.006\n",
      "Epoch: 197 -> Loss: 0.0115517256781\n",
      "Epoch: 197 -> Test Accuracy: 91.72\n",
      "[198, 60] loss: 0.006\n",
      "[198, 120] loss: 0.006\n",
      "[198, 180] loss: 0.006\n",
      "[198, 240] loss: 0.007\n",
      "[198, 300] loss: 0.006\n",
      "[198, 360] loss: 0.007\n",
      "Epoch: 198 -> Loss: 0.0099995136261\n",
      "Epoch: 198 -> Test Accuracy: 91.57\n",
      "[199, 60] loss: 0.006\n",
      "[199, 120] loss: 0.005\n",
      "[199, 180] loss: 0.007\n",
      "[199, 240] loss: 0.007\n",
      "[199, 300] loss: 0.007\n",
      "[199, 360] loss: 0.006\n",
      "Epoch: 199 -> Loss: 0.00570183992386\n",
      "Epoch: 199 -> Test Accuracy: 91.66\n",
      "[200, 60] loss: 0.006\n",
      "[200, 120] loss: 0.006\n",
      "[200, 180] loss: 0.007\n",
      "[200, 240] loss: 0.006\n",
      "[200, 300] loss: 0.007\n",
      "[200, 360] loss: 0.006\n",
      "Epoch: 200 -> Loss: 0.0103160589933\n",
      "Epoch: 200 -> Test Accuracy: 91.57\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "semi_loss_log, semi_accuracy_log, super_loss_log, super_accuracy_log = tr.train_semi([20, 100, 400, 1000, 5000], 10, \n",
    "    trainset, testset, 128, [0.1, 0.02, 0.004, 0.0008], [35, 70, 85, 100], [0.1, 0.02, 0.004, 0.0008],\n",
    "               [60, 120, 160, 200], 0.9, 5e-4, semi_net, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save variables\n",
    "fm.save_variable([semi_loss_log, semi_accuracy_log, super_loss_log, super_accuracy_log], \"semi-supervised\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Test Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RotNet model with 3 Convolutional Blocks:\n",
      "\n",
      "\n",
      "Evaluating Rotation Task:\n",
      "Test Accuracy:  92.190 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of original :  92.100 %\n",
      "Test Accuracy of 90 rotation :  92.110 %\n",
      "Test Accuracy of 180 rotation :  92.140 %\n",
      "Test Accuracy of 270 rotation :  92.410 %\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Starting to evaluate Non-Linear Classifier:\n",
      "\n",
      "\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 1:\n",
      "Test Accuracy:  83.280 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  85.100 %\n",
      "Test Accuracy of car :  91.400 %\n",
      "Test Accuracy of bird :  76.900 %\n",
      "Test Accuracy of cat :  69.000 %\n",
      "Test Accuracy of deer :  79.700 %\n",
      "Test Accuracy of dog :  72.900 %\n",
      "Test Accuracy of frog :  89.500 %\n",
      "Test Accuracy of horse :  86.300 %\n",
      "Test Accuracy of ship :  91.100 %\n",
      "Test Accuracy of truck :  90.900 %\n",
      "\n",
      "\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 2:\n",
      "Test Accuracy:  86.510 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  87.300 %\n",
      "Test Accuracy of car :  92.600 %\n",
      "Test Accuracy of bird :  82.400 %\n",
      "Test Accuracy of cat :  77.100 %\n",
      "Test Accuracy of deer :  86.600 %\n",
      "Test Accuracy of dog :  77.600 %\n",
      "Test Accuracy of frog :  90.400 %\n",
      "Test Accuracy of horse :  88.600 %\n",
      "Test Accuracy of ship :  92.400 %\n",
      "Test Accuracy of truck :  90.100 %\n",
      "\n",
      "\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 3:\n",
      "Test Accuracy:  54.070 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  61.800 %\n",
      "Test Accuracy of car :  59.200 %\n",
      "Test Accuracy of bird :  43.100 %\n",
      "Test Accuracy of cat :  36.500 %\n",
      "Test Accuracy of deer :  50.300 %\n",
      "Test Accuracy of dog :  51.100 %\n",
      "Test Accuracy of frog :  61.300 %\n",
      "Test Accuracy of horse :  54.600 %\n",
      "Test Accuracy of ship :  60.000 %\n",
      "Test Accuracy of truck :  62.800 %\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Starting to evaluate Convolutional Classifier:\n",
      "\n",
      "\n",
      "Evaluating Convolutional Classifier on Convolutional Block 1\n",
      "Test Accuracy:  86.850 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  88.300 %\n",
      "Test Accuracy of car :  93.900 %\n",
      "Test Accuracy of bird :  80.200 %\n",
      "Test Accuracy of cat :  76.900 %\n",
      "Test Accuracy of deer :  86.700 %\n",
      "Test Accuracy of dog :  78.400 %\n",
      "Test Accuracy of frog :  92.500 %\n",
      "Test Accuracy of horse :  89.200 %\n",
      "Test Accuracy of ship :  91.500 %\n",
      "Test Accuracy of truck :  90.900 %\n",
      "\n",
      "\n",
      "Evaluating Convolutional Classifier on Convolutional Block 2\n",
      "Test Accuracy:  88.820 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  89.200 %\n",
      "Test Accuracy of car :  94.000 %\n",
      "Test Accuracy of bird :  84.400 %\n",
      "Test Accuracy of cat :  79.900 %\n",
      "Test Accuracy of deer :  89.800 %\n",
      "Test Accuracy of dog :  83.400 %\n",
      "Test Accuracy of frog :  92.200 %\n",
      "Test Accuracy of horse :  90.000 %\n",
      "Test Accuracy of ship :  93.300 %\n",
      "Test Accuracy of truck :  92.000 %\n",
      "\n",
      "\n",
      "Evaluating Convolutional Classifier on Convolutional Block 3\n",
      "Test Accuracy:  61.910 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  64.700 %\n",
      "Test Accuracy of car :  64.500 %\n",
      "Test Accuracy of bird :  51.100 %\n",
      "Test Accuracy of cat :  49.300 %\n",
      "Test Accuracy of deer :  61.200 %\n",
      "Test Accuracy of dog :  55.300 %\n",
      "Test Accuracy of frog :  71.600 %\n",
      "Test Accuracy of horse :  61.400 %\n",
      "Test Accuracy of ship :  67.900 %\n",
      "Test Accuracy of truck :  72.100 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy ConvClassifier ConvBlock 1': 86.85,\n",
       " 'Accuracy ConvClassifier ConvBlock 2': 88.82,\n",
       " 'Accuracy ConvClassifier ConvBlock 3': 61.91,\n",
       " 'Accuracy Non-Linear ConvBlock 1': 83.28,\n",
       " 'Accuracy Non-Linear ConvBlock 2': 86.51,\n",
       " 'Accuracy Non-Linear ConvBlock 3': 54.07,\n",
       " 'Accuracy Rotation Task': 92.19,\n",
       " 'Class Accuracy ConvClassifier ConvBlock 1': [88.3,\n",
       "  93.9,\n",
       "  80.2,\n",
       "  76.9,\n",
       "  86.7,\n",
       "  78.4,\n",
       "  92.5,\n",
       "  89.2,\n",
       "  91.5,\n",
       "  90.9],\n",
       " 'Class Accuracy ConvClassifier ConvBlock 2': [89.2,\n",
       "  94.0,\n",
       "  84.4,\n",
       "  79.9,\n",
       "  89.8,\n",
       "  83.4,\n",
       "  92.2,\n",
       "  90.0,\n",
       "  93.3,\n",
       "  92.0],\n",
       " 'Class Accuracy ConvClassifier ConvBlock 3': [64.7,\n",
       "  64.5,\n",
       "  51.1,\n",
       "  49.3,\n",
       "  61.2,\n",
       "  55.3,\n",
       "  71.6,\n",
       "  61.4,\n",
       "  67.9,\n",
       "  72.1],\n",
       " 'Class Accuracy Non-Linear ConvBlock 1': [85.1,\n",
       "  91.4,\n",
       "  76.9,\n",
       "  69.0,\n",
       "  79.7,\n",
       "  72.9,\n",
       "  89.5,\n",
       "  86.3,\n",
       "  91.1,\n",
       "  90.9],\n",
       " 'Class Accuracy Non-Linear ConvBlock 2': [87.3,\n",
       "  92.6,\n",
       "  82.4,\n",
       "  77.1,\n",
       "  86.6,\n",
       "  77.6,\n",
       "  90.4,\n",
       "  88.6,\n",
       "  92.4,\n",
       "  90.1],\n",
       " 'Class Accuracy Non-Linear ConvBlock 3': [61.8,\n",
       "  59.2,\n",
       "  43.1,\n",
       "  36.5,\n",
       "  50.3,\n",
       "  51.1,\n",
       "  61.3,\n",
       "  54.6,\n",
       "  60.0,\n",
       "  62.8],\n",
       " 'Class Accuracy Rotation Task': [92.1, 92.11, 92.14, 92.41]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 ConvBlock RotNet model and Classifiers\n",
    "ev.evaluate_all(3, testloader, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RotNet model with 4 Convolutional Blocks:\n",
      "\n",
      "\n",
      "Evaluating Rotation Task:\n",
      "Test Accuracy:  92.013 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of original :  91.790 %\n",
      "Test Accuracy of 90 rotation :  92.080 %\n",
      "Test Accuracy of 180 rotation :  91.950 %\n",
      "Test Accuracy of 270 rotation :  92.230 %\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Starting to evaluate Non-Linear Classifier:\n",
      "\n",
      "\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 1:\n",
      "Test Accuracy:  82.730 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  85.700 %\n",
      "Test Accuracy of car :  87.800 %\n",
      "Test Accuracy of bird :  76.200 %\n",
      "Test Accuracy of cat :  68.400 %\n",
      "Test Accuracy of deer :  80.100 %\n",
      "Test Accuracy of dog :  72.900 %\n",
      "Test Accuracy of frog :  89.100 %\n",
      "Test Accuracy of horse :  87.800 %\n",
      "Test Accuracy of ship :  90.900 %\n",
      "Test Accuracy of truck :  88.400 %\n",
      "\n",
      "\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 2:\n",
      "Test Accuracy:  85.530 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  87.600 %\n",
      "Test Accuracy of car :  91.400 %\n",
      "Test Accuracy of bird :  80.800 %\n",
      "Test Accuracy of cat :  76.700 %\n",
      "Test Accuracy of deer :  83.600 %\n",
      "Test Accuracy of dog :  76.900 %\n",
      "Test Accuracy of frog :  89.500 %\n",
      "Test Accuracy of horse :  89.000 %\n",
      "Test Accuracy of ship :  90.200 %\n",
      "Test Accuracy of truck :  89.600 %\n",
      "\n",
      "\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 3:\n",
      "Test Accuracy:  80.990 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  80.700 %\n",
      "Test Accuracy of car :  85.800 %\n",
      "Test Accuracy of bird :  77.000 %\n",
      "Test Accuracy of cat :  71.100 %\n",
      "Test Accuracy of deer :  79.400 %\n",
      "Test Accuracy of dog :  73.500 %\n",
      "Test Accuracy of frog :  85.900 %\n",
      "Test Accuracy of horse :  86.100 %\n",
      "Test Accuracy of ship :  87.400 %\n",
      "Test Accuracy of truck :  83.000 %\n",
      "\n",
      "\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 4:\n",
      "Test Accuracy:  43.200 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  55.800 %\n",
      "Test Accuracy of car :  45.100 %\n",
      "Test Accuracy of bird :  32.000 %\n",
      "Test Accuracy of cat :  30.800 %\n",
      "Test Accuracy of deer :  31.600 %\n",
      "Test Accuracy of dog :  40.100 %\n",
      "Test Accuracy of frog :  56.600 %\n",
      "Test Accuracy of horse :  43.100 %\n",
      "Test Accuracy of ship :  51.500 %\n",
      "Test Accuracy of truck :  45.400 %\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Starting to evaluate Convolutional Classifier:\n",
      "\n",
      "\n",
      "Evaluating Convolutional Classifier on Convolutional Block 1\n",
      "Test Accuracy:  85.190 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  86.000 %\n",
      "Test Accuracy of car :  92.500 %\n",
      "Test Accuracy of bird :  79.200 %\n",
      "Test Accuracy of cat :  73.500 %\n",
      "Test Accuracy of deer :  82.500 %\n",
      "Test Accuracy of dog :  79.700 %\n",
      "Test Accuracy of frog :  90.400 %\n",
      "Test Accuracy of horse :  86.800 %\n",
      "Test Accuracy of ship :  91.300 %\n",
      "Test Accuracy of truck :  90.000 %\n",
      "\n",
      "\n",
      "Evaluating Convolutional Classifier on Convolutional Block 2\n",
      "Test Accuracy:  87.510 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  89.400 %\n",
      "Test Accuracy of car :  92.000 %\n",
      "Test Accuracy of bird :  83.100 %\n",
      "Test Accuracy of cat :  78.300 %\n",
      "Test Accuracy of deer :  88.900 %\n",
      "Test Accuracy of dog :  80.500 %\n",
      "Test Accuracy of frog :  91.000 %\n",
      "Test Accuracy of horse :  90.400 %\n",
      "Test Accuracy of ship :  91.200 %\n",
      "Test Accuracy of truck :  90.300 %\n",
      "\n",
      "\n",
      "Evaluating Convolutional Classifier on Convolutional Block 3\n",
      "Test Accuracy:  82.660 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  83.500 %\n",
      "Test Accuracy of car :  86.600 %\n",
      "Test Accuracy of bird :  76.000 %\n",
      "Test Accuracy of cat :  74.500 %\n",
      "Test Accuracy of deer :  83.000 %\n",
      "Test Accuracy of dog :  74.900 %\n",
      "Test Accuracy of frog :  88.300 %\n",
      "Test Accuracy of horse :  85.000 %\n",
      "Test Accuracy of ship :  87.000 %\n",
      "Test Accuracy of truck :  87.800 %\n",
      "\n",
      "\n",
      "Evaluating Convolutional Classifier on Convolutional Block 4\n",
      "Test Accuracy:  50.910 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  60.500 %\n",
      "Test Accuracy of car :  53.500 %\n",
      "Test Accuracy of bird :  39.500 %\n",
      "Test Accuracy of cat :  38.000 %\n",
      "Test Accuracy of deer :  36.600 %\n",
      "Test Accuracy of dog :  49.200 %\n",
      "Test Accuracy of frog :  65.000 %\n",
      "Test Accuracy of horse :  52.600 %\n",
      "Test Accuracy of ship :  63.000 %\n",
      "Test Accuracy of truck :  51.200 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy ConvClassifier ConvBlock 1': 85.19,\n",
       " 'Accuracy ConvClassifier ConvBlock 2': 87.51,\n",
       " 'Accuracy ConvClassifier ConvBlock 3': 82.66,\n",
       " 'Accuracy ConvClassifier ConvBlock 4': 50.91,\n",
       " 'Accuracy Non-Linear ConvBlock 1': 82.73,\n",
       " 'Accuracy Non-Linear ConvBlock 2': 85.53,\n",
       " 'Accuracy Non-Linear ConvBlock 3': 80.99,\n",
       " 'Accuracy Non-Linear ConvBlock 4': 43.2,\n",
       " 'Accuracy Rotation Task': 92.0125,\n",
       " 'Class Accuracy ConvClassifier ConvBlock 1': [86.0,\n",
       "  92.5,\n",
       "  79.2,\n",
       "  73.5,\n",
       "  82.5,\n",
       "  79.7,\n",
       "  90.4,\n",
       "  86.8,\n",
       "  91.3,\n",
       "  90.0],\n",
       " 'Class Accuracy ConvClassifier ConvBlock 2': [89.4,\n",
       "  92.0,\n",
       "  83.1,\n",
       "  78.3,\n",
       "  88.9,\n",
       "  80.5,\n",
       "  91.0,\n",
       "  90.4,\n",
       "  91.2,\n",
       "  90.3],\n",
       " 'Class Accuracy ConvClassifier ConvBlock 3': [83.5,\n",
       "  86.6,\n",
       "  76.0,\n",
       "  74.5,\n",
       "  83.0,\n",
       "  74.9,\n",
       "  88.3,\n",
       "  85.0,\n",
       "  87.0,\n",
       "  87.8],\n",
       " 'Class Accuracy ConvClassifier ConvBlock 4': [60.5,\n",
       "  53.5,\n",
       "  39.5,\n",
       "  38.0,\n",
       "  36.6,\n",
       "  49.2,\n",
       "  65.0,\n",
       "  52.6,\n",
       "  63.0,\n",
       "  51.2],\n",
       " 'Class Accuracy Non-Linear ConvBlock 1': [85.7,\n",
       "  87.8,\n",
       "  76.2,\n",
       "  68.4,\n",
       "  80.1,\n",
       "  72.9,\n",
       "  89.1,\n",
       "  87.8,\n",
       "  90.9,\n",
       "  88.4],\n",
       " 'Class Accuracy Non-Linear ConvBlock 2': [87.6,\n",
       "  91.4,\n",
       "  80.8,\n",
       "  76.7,\n",
       "  83.6,\n",
       "  76.9,\n",
       "  89.5,\n",
       "  89.0,\n",
       "  90.2,\n",
       "  89.6],\n",
       " 'Class Accuracy Non-Linear ConvBlock 3': [80.7,\n",
       "  85.8,\n",
       "  77.0,\n",
       "  71.1,\n",
       "  79.4,\n",
       "  73.5,\n",
       "  85.9,\n",
       "  86.1,\n",
       "  87.4,\n",
       "  83.0],\n",
       " 'Class Accuracy Non-Linear ConvBlock 4': [55.8,\n",
       "  45.1,\n",
       "  32.0,\n",
       "  30.8,\n",
       "  31.6,\n",
       "  40.1,\n",
       "  56.6,\n",
       "  43.1,\n",
       "  51.5,\n",
       "  45.4],\n",
       " 'Class Accuracy Rotation Task': [91.79, 92.08, 91.95, 92.23]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 ConvBlock RotNet model and Classifiers\n",
    "ev.evaluate_all(4, testloader, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RotNet model with 5 Convolutional Blocks:\n",
      "\n",
      "\n",
      "Evaluating Rotation Task:\n",
      "Test Accuracy:  92.088 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of original :  92.380 %\n",
      "Test Accuracy of 90 rotation :  92.150 %\n",
      "Test Accuracy of 180 rotation :  91.850 %\n",
      "Test Accuracy of 270 rotation :  91.970 %\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Starting to evaluate Non-Linear Classifier:\n",
      "\n",
      "\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 1:\n",
      "Test Accuracy:  82.990 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  82.700 %\n",
      "Test Accuracy of car :  90.200 %\n",
      "Test Accuracy of bird :  77.800 %\n",
      "Test Accuracy of cat :  68.300 %\n",
      "Test Accuracy of deer :  79.100 %\n",
      "Test Accuracy of dog :  73.500 %\n",
      "Test Accuracy of frog :  88.600 %\n",
      "Test Accuracy of horse :  88.000 %\n",
      "Test Accuracy of ship :  91.800 %\n",
      "Test Accuracy of truck :  89.900 %\n",
      "\n",
      "\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 2:\n",
      "Test Accuracy:  86.610 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  88.900 %\n",
      "Test Accuracy of car :  92.700 %\n",
      "Test Accuracy of bird :  82.300 %\n",
      "Test Accuracy of cat :  74.200 %\n",
      "Test Accuracy of deer :  84.800 %\n",
      "Test Accuracy of dog :  79.800 %\n",
      "Test Accuracy of frog :  90.700 %\n",
      "Test Accuracy of horse :  88.600 %\n",
      "Test Accuracy of ship :  92.000 %\n",
      "Test Accuracy of truck :  92.100 %\n",
      "\n",
      "\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 3:\n",
      "Test Accuracy:  82.970 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  83.700 %\n",
      "Test Accuracy of car :  90.000 %\n",
      "Test Accuracy of bird :  77.300 %\n",
      "Test Accuracy of cat :  73.800 %\n",
      "Test Accuracy of deer :  80.500 %\n",
      "Test Accuracy of dog :  73.900 %\n",
      "Test Accuracy of frog :  87.700 %\n",
      "Test Accuracy of horse :  85.300 %\n",
      "Test Accuracy of ship :  90.300 %\n",
      "Test Accuracy of truck :  87.200 %\n",
      "\n",
      "\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 4:\n",
      "Test Accuracy:  69.830 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  78.000 %\n",
      "Test Accuracy of car :  73.600 %\n",
      "Test Accuracy of bird :  60.800 %\n",
      "Test Accuracy of cat :  54.600 %\n",
      "Test Accuracy of deer :  67.200 %\n",
      "Test Accuracy of dog :  59.500 %\n",
      "Test Accuracy of frog :  79.400 %\n",
      "Test Accuracy of horse :  73.900 %\n",
      "Test Accuracy of ship :  75.700 %\n",
      "Test Accuracy of truck :  75.600 %\n",
      "\n",
      "\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 5:\n",
      "Test Accuracy:  36.900 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  44.700 %\n",
      "Test Accuracy of car :  39.400 %\n",
      "Test Accuracy of bird :  29.400 %\n",
      "Test Accuracy of cat :  26.200 %\n",
      "Test Accuracy of deer :  24.300 %\n",
      "Test Accuracy of dog :  31.500 %\n",
      "Test Accuracy of frog :  42.900 %\n",
      "Test Accuracy of horse :  40.200 %\n",
      "Test Accuracy of ship :  47.900 %\n",
      "Test Accuracy of truck :  42.500 %\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Starting to evaluate Convolutional Classifier:\n",
      "\n",
      "\n",
      "Evaluating Convolutional Classifier on Convolutional Block 1\n",
      "Test Accuracy:  86.150 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  89.500 %\n",
      "Test Accuracy of car :  93.000 %\n",
      "Test Accuracy of bird :  79.100 %\n",
      "Test Accuracy of cat :  73.000 %\n",
      "Test Accuracy of deer :  86.400 %\n",
      "Test Accuracy of dog :  79.900 %\n",
      "Test Accuracy of frog :  90.700 %\n",
      "Test Accuracy of horse :  88.300 %\n",
      "Test Accuracy of ship :  90.700 %\n",
      "Test Accuracy of truck :  90.900 %\n",
      "\n",
      "\n",
      "Evaluating Convolutional Classifier on Convolutional Block 2\n",
      "Test Accuracy:  88.370 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  88.900 %\n",
      "Test Accuracy of car :  92.700 %\n",
      "Test Accuracy of bird :  84.400 %\n",
      "Test Accuracy of cat :  79.700 %\n",
      "Test Accuracy of deer :  87.900 %\n",
      "Test Accuracy of dog :  81.500 %\n",
      "Test Accuracy of frog :  91.500 %\n",
      "Test Accuracy of horse :  88.900 %\n",
      "Test Accuracy of ship :  94.300 %\n",
      "Test Accuracy of truck :  93.900 %\n",
      "\n",
      "\n",
      "Evaluating Convolutional Classifier on Convolutional Block 3\n",
      "Test Accuracy:  85.150 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  86.800 %\n",
      "Test Accuracy of car :  90.700 %\n",
      "Test Accuracy of bird :  79.000 %\n",
      "Test Accuracy of cat :  76.600 %\n",
      "Test Accuracy of deer :  84.900 %\n",
      "Test Accuracy of dog :  76.100 %\n",
      "Test Accuracy of frog :  89.800 %\n",
      "Test Accuracy of horse :  87.400 %\n",
      "Test Accuracy of ship :  90.500 %\n",
      "Test Accuracy of truck :  89.700 %\n",
      "\n",
      "\n",
      "Evaluating Convolutional Classifier on Convolutional Block 4\n",
      "Test Accuracy:  72.950 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  78.400 %\n",
      "Test Accuracy of car :  77.300 %\n",
      "Test Accuracy of bird :  63.700 %\n",
      "Test Accuracy of cat :  61.500 %\n",
      "Test Accuracy of deer :  72.900 %\n",
      "Test Accuracy of dog :  65.000 %\n",
      "Test Accuracy of frog :  81.600 %\n",
      "Test Accuracy of horse :  75.700 %\n",
      "Test Accuracy of ship :  76.100 %\n",
      "Test Accuracy of truck :  77.300 %\n",
      "\n",
      "\n",
      "Evaluating Convolutional Classifier on Convolutional Block 5\n",
      "Test Accuracy:  41.480 %\n",
      "Accuracy per class:\n",
      "Test Accuracy of plane :  49.200 %\n",
      "Test Accuracy of car :  44.200 %\n",
      "Test Accuracy of bird :  33.700 %\n",
      "Test Accuracy of cat :  33.900 %\n",
      "Test Accuracy of deer :  27.800 %\n",
      "Test Accuracy of dog :  35.900 %\n",
      "Test Accuracy of frog :  52.300 %\n",
      "Test Accuracy of horse :  41.400 %\n",
      "Test Accuracy of ship :  50.000 %\n",
      "Test Accuracy of truck :  46.400 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy ConvClassifier ConvBlock 1': 86.15,\n",
       " 'Accuracy ConvClassifier ConvBlock 2': 88.37,\n",
       " 'Accuracy ConvClassifier ConvBlock 3': 85.15,\n",
       " 'Accuracy ConvClassifier ConvBlock 4': 72.95,\n",
       " 'Accuracy ConvClassifier ConvBlock 5': 41.48,\n",
       " 'Accuracy Non-Linear ConvBlock 1': 82.99,\n",
       " 'Accuracy Non-Linear ConvBlock 2': 86.61,\n",
       " 'Accuracy Non-Linear ConvBlock 3': 82.97,\n",
       " 'Accuracy Non-Linear ConvBlock 4': 69.83,\n",
       " 'Accuracy Non-Linear ConvBlock 5': 36.9,\n",
       " 'Accuracy Rotation Task': 92.0875,\n",
       " 'Class Accuracy ConvClassifier ConvBlock 1': [89.5,\n",
       "  93.0,\n",
       "  79.1,\n",
       "  73.0,\n",
       "  86.4,\n",
       "  79.9,\n",
       "  90.7,\n",
       "  88.3,\n",
       "  90.7,\n",
       "  90.9],\n",
       " 'Class Accuracy ConvClassifier ConvBlock 2': [88.9,\n",
       "  92.7,\n",
       "  84.4,\n",
       "  79.7,\n",
       "  87.9,\n",
       "  81.5,\n",
       "  91.5,\n",
       "  88.9,\n",
       "  94.3,\n",
       "  93.9],\n",
       " 'Class Accuracy ConvClassifier ConvBlock 3': [86.8,\n",
       "  90.7,\n",
       "  79.0,\n",
       "  76.6,\n",
       "  84.9,\n",
       "  76.1,\n",
       "  89.8,\n",
       "  87.4,\n",
       "  90.5,\n",
       "  89.7],\n",
       " 'Class Accuracy ConvClassifier ConvBlock 4': [78.4,\n",
       "  77.3,\n",
       "  63.7,\n",
       "  61.5,\n",
       "  72.9,\n",
       "  65.0,\n",
       "  81.6,\n",
       "  75.7,\n",
       "  76.1,\n",
       "  77.3],\n",
       " 'Class Accuracy ConvClassifier ConvBlock 5': [49.2,\n",
       "  44.2,\n",
       "  33.7,\n",
       "  33.9,\n",
       "  27.8,\n",
       "  35.9,\n",
       "  52.3,\n",
       "  41.4,\n",
       "  50.0,\n",
       "  46.4],\n",
       " 'Class Accuracy Non-Linear ConvBlock 1': [82.7,\n",
       "  90.2,\n",
       "  77.8,\n",
       "  68.3,\n",
       "  79.1,\n",
       "  73.5,\n",
       "  88.6,\n",
       "  88.0,\n",
       "  91.8,\n",
       "  89.9],\n",
       " 'Class Accuracy Non-Linear ConvBlock 2': [88.9,\n",
       "  92.7,\n",
       "  82.3,\n",
       "  74.2,\n",
       "  84.8,\n",
       "  79.8,\n",
       "  90.7,\n",
       "  88.6,\n",
       "  92.0,\n",
       "  92.1],\n",
       " 'Class Accuracy Non-Linear ConvBlock 3': [83.7,\n",
       "  90.0,\n",
       "  77.3,\n",
       "  73.8,\n",
       "  80.5,\n",
       "  73.9,\n",
       "  87.7,\n",
       "  85.3,\n",
       "  90.3,\n",
       "  87.2],\n",
       " 'Class Accuracy Non-Linear ConvBlock 4': [78.0,\n",
       "  73.6,\n",
       "  60.8,\n",
       "  54.6,\n",
       "  67.2,\n",
       "  59.5,\n",
       "  79.4,\n",
       "  73.9,\n",
       "  75.7,\n",
       "  75.6],\n",
       " 'Class Accuracy Non-Linear ConvBlock 5': [44.7,\n",
       "  39.4,\n",
       "  29.4,\n",
       "  26.2,\n",
       "  24.3,\n",
       "  31.5,\n",
       "  42.9,\n",
       "  40.2,\n",
       "  47.9,\n",
       "  42.5],\n",
       " 'Class Accuracy Rotation Task': [92.38, 92.15, 91.85, 91.97]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 ConvBlock RotNet model and Classifiers\n",
    "ev.evaluate_all(5, testloader, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Supervised NIN Classification Task:\n",
      "Test Accuracy:  91.390 %\n",
      "Test Accuracy of plane :  91.600 %\n",
      "Test Accuracy of car :  95.900 %\n",
      "Test Accuracy of bird :  87.000 %\n",
      "Test Accuracy of cat :  83.200 %\n",
      "Test Accuracy of deer :  92.100 %\n",
      "Test Accuracy of dog :  85.500 %\n",
      "Test Accuracy of frog :  94.800 %\n",
      "Test Accuracy of horse :  93.900 %\n",
      "Test Accuracy of ship :  94.700 %\n",
      "Test Accuracy of truck :  95.200 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy Supervised NIN': 91.39,\n",
       " 'Class Accuracy Supervised NIN': [91.6,\n",
       "  95.9,\n",
       "  87.0,\n",
       "  83.2,\n",
       "  92.1,\n",
       "  85.5,\n",
       "  94.8,\n",
       "  93.9,\n",
       "  94.7,\n",
       "  95.2]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supervised NIN\n",
    "ev.evaluate_all(0, testloader, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Semi-supervised Learning Experiment:\n",
      "\n",
      "\n",
      "Evaluating Semi-supervised experiment with 20 images per class:\n",
      "Test Accuracy:  61.670 %\n",
      "Test Accuracy of plane :  59.500 %\n",
      "Test Accuracy of car :  72.100 %\n",
      "Test Accuracy of bird :  44.700 %\n",
      "Test Accuracy of cat :  42.600 %\n",
      "Test Accuracy of deer :  57.200 %\n",
      "Test Accuracy of dog :  60.100 %\n",
      "Test Accuracy of frog :  77.800 %\n",
      "Test Accuracy of horse :  59.600 %\n",
      "Test Accuracy of ship :  67.300 %\n",
      "Test Accuracy of truck :  75.800 %\n",
      "\n",
      "\n",
      "Evaluating supervised NIN experiment with 20 images per class:\n",
      "Test Accuracy:  11.560 %\n",
      "Test Accuracy of plane :  39.000 %\n",
      "Test Accuracy of car :  39.400 %\n",
      "Test Accuracy of bird :  20.100 %\n",
      "Test Accuracy of cat :  23.500 %\n",
      "Test Accuracy of deer :  26.500 %\n",
      "Test Accuracy of dog :  25.100 %\n",
      "Test Accuracy of frog :  42.700 %\n",
      "Test Accuracy of horse :  38.100 %\n",
      "Test Accuracy of ship :  44.000 %\n",
      "Test Accuracy of truck :  35.800 %\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Semi-supervised experiment with 100 images per class:\n",
      "Test Accuracy:  71.440 %\n",
      "Test Accuracy of plane :  70.500 %\n",
      "Test Accuracy of car :  82.200 %\n",
      "Test Accuracy of bird :  58.000 %\n",
      "Test Accuracy of cat :  58.200 %\n",
      "Test Accuracy of deer :  65.900 %\n",
      "Test Accuracy of dog :  66.600 %\n",
      "Test Accuracy of frog :  79.900 %\n",
      "Test Accuracy of horse :  73.500 %\n",
      "Test Accuracy of ship :  78.200 %\n",
      "Test Accuracy of truck :  81.400 %\n",
      "\n",
      "\n",
      "Evaluating supervised NIN experiment with 100 images per class:\n",
      "Test Accuracy:  9.690 %\n",
      "Test Accuracy of plane :  53.900 %\n",
      "Test Accuracy of car :  61.300 %\n",
      "Test Accuracy of bird :  37.600 %\n",
      "Test Accuracy of cat :  40.700 %\n",
      "Test Accuracy of deer :  46.100 %\n",
      "Test Accuracy of dog :  43.900 %\n",
      "Test Accuracy of frog :  57.500 %\n",
      "Test Accuracy of horse :  61.400 %\n",
      "Test Accuracy of ship :  67.300 %\n",
      "Test Accuracy of truck :  65.600 %\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Semi-supervised experiment with 400 images per class:\n",
      "Test Accuracy:  78.860 %\n",
      "Test Accuracy of plane :  79.100 %\n",
      "Test Accuracy of car :  88.700 %\n",
      "Test Accuracy of bird :  71.200 %\n",
      "Test Accuracy of cat :  64.600 %\n",
      "Test Accuracy of deer :  78.100 %\n",
      "Test Accuracy of dog :  71.300 %\n",
      "Test Accuracy of frog :  86.100 %\n",
      "Test Accuracy of horse :  80.800 %\n",
      "Test Accuracy of ship :  85.800 %\n",
      "Test Accuracy of truck :  82.900 %\n",
      "\n",
      "\n",
      "Evaluating supervised NIN experiment with 400 images per class:\n",
      "Test Accuracy:  9.830 %\n",
      "Test Accuracy of plane :  71.800 %\n",
      "Test Accuracy of car :  82.900 %\n",
      "Test Accuracy of bird :  56.900 %\n",
      "Test Accuracy of cat :  54.700 %\n",
      "Test Accuracy of deer :  69.600 %\n",
      "Test Accuracy of dog :  63.800 %\n",
      "Test Accuracy of frog :  77.700 %\n",
      "Test Accuracy of horse :  74.200 %\n",
      "Test Accuracy of ship :  82.900 %\n",
      "Test Accuracy of truck :  80.600 %\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Semi-supervised experiment with 1000 images per class:\n",
      "Test Accuracy:  82.370 %\n",
      "Test Accuracy of plane :  82.800 %\n",
      "Test Accuracy of car :  89.000 %\n",
      "Test Accuracy of bird :  77.000 %\n",
      "Test Accuracy of cat :  71.500 %\n",
      "Test Accuracy of deer :  81.900 %\n",
      "Test Accuracy of dog :  74.400 %\n",
      "Test Accuracy of frog :  88.000 %\n",
      "Test Accuracy of horse :  83.300 %\n",
      "Test Accuracy of ship :  87.700 %\n",
      "Test Accuracy of truck :  88.100 %\n",
      "\n",
      "\n",
      "Evaluating supervised NIN experiment with 1000 images per class:\n",
      "Test Accuracy:  10.040 %\n",
      "Test Accuracy of plane :  82.100 %\n",
      "Test Accuracy of car :  91.500 %\n",
      "Test Accuracy of bird :  69.900 %\n",
      "Test Accuracy of cat :  64.300 %\n",
      "Test Accuracy of deer :  79.300 %\n",
      "Test Accuracy of dog :  73.300 %\n",
      "Test Accuracy of frog :  85.200 %\n",
      "Test Accuracy of horse :  87.000 %\n",
      "Test Accuracy of ship :  89.500 %\n",
      "Test Accuracy of truck :  89.000 %\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Evaluating Semi-supervised experiment with 5000 images per class:\n",
      "Test Accuracy:  87.560 %\n",
      "Test Accuracy of plane :  88.400 %\n",
      "Test Accuracy of car :  92.900 %\n",
      "Test Accuracy of bird :  81.800 %\n",
      "Test Accuracy of cat :  79.200 %\n",
      "Test Accuracy of deer :  89.000 %\n",
      "Test Accuracy of dog :  81.400 %\n",
      "Test Accuracy of frog :  92.000 %\n",
      "Test Accuracy of horse :  89.100 %\n",
      "Test Accuracy of ship :  91.800 %\n",
      "Test Accuracy of truck :  90.000 %\n",
      "\n",
      "\n",
      "Evaluating supervised NIN experiment with 5000 images per class:\n",
      "Test Accuracy:  9.940 %\n",
      "Test Accuracy of plane :  92.100 %\n",
      "Test Accuracy of car :  96.600 %\n",
      "Test Accuracy of bird :  87.800 %\n",
      "Test Accuracy of cat :  82.400 %\n",
      "Test Accuracy of deer :  92.100 %\n",
      "Test Accuracy of dog :  85.800 %\n",
      "Test Accuracy of frog :  94.600 %\n",
      "Test Accuracy of horse :  94.200 %\n",
      "Test Accuracy of ship :  95.800 %\n",
      "Test Accuracy of truck :  94.300 %\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy Semi-supervised 100': 71.44,\n",
       " 'Accuracy Semi-supervised 1000': 82.37,\n",
       " 'Accuracy Semi-supervised 20': 61.67,\n",
       " 'Accuracy Semi-supervised 400': 78.86,\n",
       " 'Accuracy Semi-supervised 5000': 87.56,\n",
       " 'Accuracy Supervised NIN 100': 9.69,\n",
       " 'Accuracy Supervised NIN 1000': 10.04,\n",
       " 'Accuracy Supervised NIN 20': 11.56,\n",
       " 'Accuracy Supervised NIN 400': 9.83,\n",
       " 'Accuracy Supervised NIN 5000': 9.94,\n",
       " 'Class Accuracy Semi-supervised 100': [70.5,\n",
       "  82.2,\n",
       "  58.0,\n",
       "  58.2,\n",
       "  65.9,\n",
       "  66.6,\n",
       "  79.9,\n",
       "  73.5,\n",
       "  78.2,\n",
       "  81.4],\n",
       " 'Class Accuracy Semi-supervised 1000': [82.8,\n",
       "  89.0,\n",
       "  77.0,\n",
       "  71.5,\n",
       "  81.9,\n",
       "  74.4,\n",
       "  88.0,\n",
       "  83.3,\n",
       "  87.7,\n",
       "  88.1],\n",
       " 'Class Accuracy Semi-supervised 20': [59.5,\n",
       "  72.1,\n",
       "  44.7,\n",
       "  42.6,\n",
       "  57.2,\n",
       "  60.1,\n",
       "  77.8,\n",
       "  59.6,\n",
       "  67.3,\n",
       "  75.8],\n",
       " 'Class Accuracy Semi-supervised 400': [79.1,\n",
       "  88.7,\n",
       "  71.2,\n",
       "  64.6,\n",
       "  78.1,\n",
       "  71.3,\n",
       "  86.1,\n",
       "  80.8,\n",
       "  85.8,\n",
       "  82.9],\n",
       " 'Class Accuracy Semi-supervised 5000': [88.4,\n",
       "  92.9,\n",
       "  81.8,\n",
       "  79.2,\n",
       "  89.0,\n",
       "  81.4,\n",
       "  92.0,\n",
       "  89.1,\n",
       "  91.8,\n",
       "  90.0],\n",
       " 'Class Accuracy Supervised NIN 100': [53.9,\n",
       "  61.3,\n",
       "  37.6,\n",
       "  40.7,\n",
       "  46.1,\n",
       "  43.9,\n",
       "  57.5,\n",
       "  61.4,\n",
       "  67.3,\n",
       "  65.6],\n",
       " 'Class Accuracy Supervised NIN 1000': [82.1,\n",
       "  91.5,\n",
       "  69.9,\n",
       "  64.3,\n",
       "  79.3,\n",
       "  73.3,\n",
       "  85.2,\n",
       "  87.0,\n",
       "  89.5,\n",
       "  89.0],\n",
       " 'Class Accuracy Supervised NIN 20': [39.0,\n",
       "  39.4,\n",
       "  20.1,\n",
       "  23.5,\n",
       "  26.5,\n",
       "  25.1,\n",
       "  42.7,\n",
       "  38.1,\n",
       "  44.0,\n",
       "  35.8],\n",
       " 'Class Accuracy Supervised NIN 400': [71.8,\n",
       "  82.9,\n",
       "  56.9,\n",
       "  54.7,\n",
       "  69.6,\n",
       "  63.8,\n",
       "  77.7,\n",
       "  74.2,\n",
       "  82.9,\n",
       "  80.6],\n",
       " 'Class Accuracy Supervised NIN 5000': [92.1,\n",
       "  96.6,\n",
       "  87.8,\n",
       "  82.4,\n",
       "  92.1,\n",
       "  85.8,\n",
       "  94.6,\n",
       "  94.2,\n",
       "  95.8,\n",
       "  94.3]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# semi-supervised\n",
    "ev.evaluate_all(-1, testloader, classes, semi=[20, 100, 400, 1000, 5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.plot_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
