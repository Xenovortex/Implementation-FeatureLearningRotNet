{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from functionalities import dataloader as dl\n",
    "from functionalities import evaluater as ev\n",
    "from functionalities import filemanager as fm\n",
    "from functionalities import trainer as tr\n",
    "from architecture import RotNet as RN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset, testset, classes = dl.load_cifar(\"./datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, validloader, testloader = dl.make_dataloaders(trainset, testset, 0, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Loss Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RotNet for Rotation Task and Classifiers on Feature Maps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set rot classes\n",
    "rot_classes = ['original', '90 rotation', '180 rotation', '270 rotation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Block RotNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "net_block3 = RN.RotNet(num_classes=4, num_conv_block=3, add_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.142\n",
      "[1, 120] loss: 0.996\n",
      "[1, 180] loss: 0.930\n",
      "[1, 240] loss: 0.867\n",
      "[1, 300] loss: 0.823\n",
      "[1, 360] loss: 0.784\n",
      "Epoch: 1 -> Loss: 0.799242377281\n",
      "Epoch: 1 -> Test Accuracy: 68.7775\n",
      "[2, 60] loss: 0.734\n",
      "[2, 120] loss: 0.715\n",
      "[2, 180] loss: 0.690\n",
      "[2, 240] loss: 0.671\n",
      "[2, 300] loss: 0.653\n",
      "[2, 360] loss: 0.625\n",
      "Epoch: 2 -> Loss: 0.661760509014\n",
      "Epoch: 2 -> Test Accuracy: 75.8925\n",
      "[3, 60] loss: 0.589\n",
      "[3, 120] loss: 0.603\n",
      "[3, 180] loss: 0.597\n",
      "[3, 240] loss: 0.573\n",
      "[3, 300] loss: 0.570\n",
      "[3, 360] loss: 0.568\n",
      "Epoch: 3 -> Loss: 0.699417948723\n",
      "Epoch: 3 -> Test Accuracy: 76.22\n",
      "[4, 60] loss: 0.527\n",
      "[4, 120] loss: 0.529\n",
      "[4, 180] loss: 0.553\n",
      "[4, 240] loss: 0.538\n",
      "[4, 300] loss: 0.515\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "rot_block3_loss_log, rot_block3_valid_accuracy_log, rot_block3_test_accuracy_log, rot_block3_max_accuracy, \\\n",
    "rot_block3_best_epoch = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], [60, 120, 160, 200], 0.9, 5e-4, net_block3, \n",
    "                                             criterion, trainloader, None, testloader, rot=['90', '180', '270'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_net_block3 = True\n",
    "\n",
    "if load_net_block3:\n",
    "    net_block3 = fm.load_net(\"RotNet_rotation_200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 2.162\n",
      "[1, 120] loss: 1.231\n",
      "[1, 180] loss: 1.133\n",
      "[1, 240] loss: 1.057\n",
      "[1, 300] loss: 1.026\n",
      "[1, 360] loss: 0.982\n",
      "Epoch: 1 -> Loss: 0.990146994591\n",
      "Epoch: 1 -> Test Accuracy: 68.47\n",
      "[2, 60] loss: 0.915\n",
      "[2, 120] loss: 0.919\n",
      "[2, 180] loss: 0.883\n",
      "[2, 240] loss: 0.892\n",
      "[2, 300] loss: 0.867\n",
      "[2, 360] loss: 0.856\n",
      "Epoch: 2 -> Loss: 0.903752207756\n",
      "Epoch: 2 -> Test Accuracy: 72.74\n",
      "[3, 60] loss: 0.817\n",
      "[3, 120] loss: 0.817\n",
      "[3, 180] loss: 0.798\n",
      "[3, 240] loss: 0.801\n",
      "[3, 300] loss: 0.777\n",
      "[3, 360] loss: 0.791\n",
      "Epoch: 3 -> Loss: 0.756074309349\n",
      "Epoch: 3 -> Test Accuracy: 74.23\n",
      "[4, 60] loss: 0.747\n",
      "[4, 120] loss: 0.754\n",
      "[4, 180] loss: 0.741\n",
      "[4, 240] loss: 0.724\n",
      "[4, 300] loss: 0.756\n",
      "[4, 360] loss: 0.727\n",
      "Epoch: 4 -> Loss: 0.601166129112\n",
      "Epoch: 4 -> Test Accuracy: 75.25\n",
      "[5, 60] loss: 0.719\n",
      "[5, 120] loss: 0.715\n",
      "[5, 180] loss: 0.713\n",
      "[5, 240] loss: 0.711\n",
      "[5, 300] loss: 0.700\n",
      "[5, 360] loss: 0.715\n",
      "Epoch: 5 -> Loss: 0.765639603138\n",
      "Epoch: 5 -> Test Accuracy: 76.35\n",
      "[6, 60] loss: 0.679\n",
      "[6, 120] loss: 0.675\n",
      "[6, 180] loss: 0.702\n",
      "[6, 240] loss: 0.689\n",
      "[6, 300] loss: 0.703\n",
      "[6, 360] loss: 0.695\n",
      "Epoch: 6 -> Loss: 0.599988400936\n",
      "Epoch: 6 -> Test Accuracy: 75.51\n",
      "[7, 60] loss: 0.656\n",
      "[7, 120] loss: 0.663\n",
      "[7, 180] loss: 0.675\n",
      "[7, 240] loss: 0.658\n",
      "[7, 300] loss: 0.701\n",
      "[7, 360] loss: 0.670\n",
      "Epoch: 7 -> Loss: 0.54879128933\n",
      "Epoch: 7 -> Test Accuracy: 76.08\n",
      "[8, 60] loss: 0.642\n",
      "[8, 120] loss: 0.646\n",
      "[8, 180] loss: 0.666\n",
      "[8, 240] loss: 0.660\n",
      "[8, 300] loss: 0.656\n",
      "[8, 360] loss: 0.642\n",
      "Epoch: 8 -> Loss: 0.689035236835\n",
      "Epoch: 8 -> Test Accuracy: 77.22\n",
      "[9, 60] loss: 0.641\n",
      "[9, 120] loss: 0.641\n",
      "[9, 180] loss: 0.635\n",
      "[9, 240] loss: 0.629\n",
      "[9, 300] loss: 0.662\n",
      "[9, 360] loss: 0.651\n",
      "Epoch: 9 -> Loss: 0.722569465637\n",
      "Epoch: 9 -> Test Accuracy: 77.48\n",
      "[10, 60] loss: 0.624\n",
      "[10, 120] loss: 0.616\n",
      "[10, 180] loss: 0.624\n",
      "[10, 240] loss: 0.635\n",
      "[10, 300] loss: 0.646\n",
      "[10, 360] loss: 0.630\n",
      "Epoch: 10 -> Loss: 0.512164950371\n",
      "Epoch: 10 -> Test Accuracy: 77.84\n",
      "[11, 60] loss: 0.609\n",
      "[11, 120] loss: 0.621\n",
      "[11, 180] loss: 0.632\n",
      "[11, 240] loss: 0.618\n",
      "[11, 300] loss: 0.630\n",
      "[11, 360] loss: 0.643\n",
      "Epoch: 11 -> Loss: 0.713616549969\n",
      "Epoch: 11 -> Test Accuracy: 78.05\n",
      "[12, 60] loss: 0.610\n",
      "[12, 120] loss: 0.619\n",
      "[12, 180] loss: 0.636\n",
      "[12, 240] loss: 0.632\n",
      "[12, 300] loss: 0.629\n",
      "[12, 360] loss: 0.609\n",
      "Epoch: 12 -> Loss: 0.59201157093\n",
      "Epoch: 12 -> Test Accuracy: 78.3\n",
      "[13, 60] loss: 0.607\n",
      "[13, 120] loss: 0.595\n",
      "[13, 180] loss: 0.614\n",
      "[13, 240] loss: 0.621\n",
      "[13, 300] loss: 0.598\n",
      "[13, 360] loss: 0.630\n",
      "Epoch: 13 -> Loss: 0.613505959511\n",
      "Epoch: 13 -> Test Accuracy: 77.94\n",
      "[14, 60] loss: 0.595\n",
      "[14, 120] loss: 0.596\n",
      "[14, 180] loss: 0.602\n",
      "[14, 240] loss: 0.615\n",
      "[14, 300] loss: 0.621\n",
      "[14, 360] loss: 0.615\n",
      "Epoch: 14 -> Loss: 0.740029454231\n",
      "Epoch: 14 -> Test Accuracy: 78.04\n",
      "[15, 60] loss: 0.603\n",
      "[15, 120] loss: 0.606\n",
      "[15, 180] loss: 0.588\n",
      "[15, 240] loss: 0.603\n",
      "[15, 300] loss: 0.611\n",
      "[15, 360] loss: 0.618\n",
      "Epoch: 15 -> Loss: 0.588313221931\n",
      "Epoch: 15 -> Test Accuracy: 78.08\n",
      "[16, 60] loss: 0.578\n",
      "[16, 120] loss: 0.591\n",
      "[16, 180] loss: 0.589\n",
      "[16, 240] loss: 0.615\n",
      "[16, 300] loss: 0.594\n",
      "[16, 360] loss: 0.600\n",
      "Epoch: 16 -> Loss: 0.657024085522\n",
      "Epoch: 16 -> Test Accuracy: 78.94\n",
      "[17, 60] loss: 0.590\n",
      "[17, 120] loss: 0.577\n",
      "[17, 180] loss: 0.597\n",
      "[17, 240] loss: 0.594\n",
      "[17, 300] loss: 0.608\n",
      "[17, 360] loss: 0.604\n",
      "Epoch: 17 -> Loss: 0.722378492355\n",
      "Epoch: 17 -> Test Accuracy: 78.55\n",
      "[18, 60] loss: 0.579\n",
      "[18, 120] loss: 0.579\n",
      "[18, 180] loss: 0.602\n",
      "[18, 240] loss: 0.599\n",
      "[18, 300] loss: 0.601\n",
      "[18, 360] loss: 0.603\n",
      "Epoch: 18 -> Loss: 0.557040691376\n",
      "Epoch: 18 -> Test Accuracy: 78.35\n",
      "[19, 60] loss: 0.566\n",
      "[19, 120] loss: 0.578\n",
      "[19, 180] loss: 0.612\n",
      "[19, 240] loss: 0.601\n",
      "[19, 300] loss: 0.607\n",
      "[19, 360] loss: 0.603\n",
      "Epoch: 19 -> Loss: 0.616155326366\n",
      "Epoch: 19 -> Test Accuracy: 78.37\n",
      "[20, 60] loss: 0.561\n",
      "[20, 120] loss: 0.563\n",
      "[20, 180] loss: 0.583\n",
      "[20, 240] loss: 0.619\n",
      "[20, 300] loss: 0.588\n",
      "[20, 360] loss: 0.597\n",
      "Epoch: 20 -> Loss: 0.564059078693\n",
      "Epoch: 20 -> Test Accuracy: 78.77\n",
      "[21, 60] loss: 0.522\n",
      "[21, 120] loss: 0.491\n",
      "[21, 180] loss: 0.511\n",
      "[21, 240] loss: 0.479\n",
      "[21, 300] loss: 0.478\n",
      "[21, 360] loss: 0.472\n",
      "Epoch: 21 -> Loss: 0.605414748192\n",
      "Epoch: 21 -> Test Accuracy: 81.0\n",
      "[22, 60] loss: 0.460\n",
      "[22, 120] loss: 0.453\n",
      "[22, 180] loss: 0.463\n",
      "[22, 240] loss: 0.446\n",
      "[22, 300] loss: 0.447\n",
      "[22, 360] loss: 0.462\n",
      "Epoch: 22 -> Loss: 0.385712653399\n",
      "Epoch: 22 -> Test Accuracy: 81.33\n",
      "[23, 60] loss: 0.441\n",
      "[23, 120] loss: 0.433\n",
      "[23, 180] loss: 0.446\n",
      "[23, 240] loss: 0.439\n",
      "[23, 300] loss: 0.420\n",
      "[23, 360] loss: 0.439\n",
      "Epoch: 23 -> Loss: 0.479295343161\n",
      "Epoch: 23 -> Test Accuracy: 81.58\n",
      "[24, 60] loss: 0.408\n",
      "[24, 120] loss: 0.418\n",
      "[24, 180] loss: 0.434\n",
      "[24, 240] loss: 0.413\n",
      "[24, 300] loss: 0.432\n",
      "[24, 360] loss: 0.436\n",
      "Epoch: 24 -> Loss: 0.398633927107\n",
      "Epoch: 24 -> Test Accuracy: 81.78\n",
      "[25, 60] loss: 0.407\n",
      "[25, 120] loss: 0.421\n",
      "[25, 180] loss: 0.417\n",
      "[25, 240] loss: 0.436\n",
      "[25, 300] loss: 0.435\n",
      "[25, 360] loss: 0.416\n",
      "Epoch: 25 -> Loss: 0.349233448505\n",
      "Epoch: 25 -> Test Accuracy: 81.38\n",
      "[26, 60] loss: 0.399\n",
      "[26, 120] loss: 0.407\n",
      "[26, 180] loss: 0.399\n",
      "[26, 240] loss: 0.416\n",
      "[26, 300] loss: 0.402\n",
      "[26, 360] loss: 0.412\n",
      "Epoch: 26 -> Loss: 0.635837614536\n",
      "Epoch: 26 -> Test Accuracy: 81.64\n",
      "[27, 60] loss: 0.396\n",
      "[27, 120] loss: 0.399\n",
      "[27, 180] loss: 0.415\n",
      "[27, 240] loss: 0.397\n",
      "[27, 300] loss: 0.396\n",
      "[27, 360] loss: 0.405\n",
      "Epoch: 27 -> Loss: 0.247348025441\n",
      "Epoch: 27 -> Test Accuracy: 82.16\n",
      "[28, 60] loss: 0.388\n",
      "[28, 120] loss: 0.397\n",
      "[28, 180] loss: 0.389\n",
      "[28, 240] loss: 0.407\n",
      "[28, 300] loss: 0.420\n",
      "[28, 360] loss: 0.389\n",
      "Epoch: 28 -> Loss: 0.439525365829\n",
      "Epoch: 28 -> Test Accuracy: 81.96\n",
      "[29, 60] loss: 0.391\n",
      "[29, 120] loss: 0.397\n",
      "[29, 180] loss: 0.395\n",
      "[29, 240] loss: 0.394\n",
      "[29, 300] loss: 0.400\n",
      "[29, 360] loss: 0.402\n",
      "Epoch: 29 -> Loss: 0.426328361034\n",
      "Epoch: 29 -> Test Accuracy: 82.33\n",
      "[30, 60] loss: 0.383\n",
      "[30, 120] loss: 0.370\n",
      "[30, 180] loss: 0.380\n",
      "[30, 240] loss: 0.391\n",
      "[30, 300] loss: 0.413\n",
      "[30, 360] loss: 0.418\n",
      "Epoch: 30 -> Loss: 0.495209932327\n",
      "Epoch: 30 -> Test Accuracy: 81.92\n",
      "[31, 60] loss: 0.389\n",
      "[31, 120] loss: 0.391\n",
      "[31, 180] loss: 0.392\n",
      "[31, 240] loss: 0.400\n",
      "[31, 300] loss: 0.393\n",
      "[31, 360] loss: 0.395\n",
      "Epoch: 31 -> Loss: 0.42753559351\n",
      "Epoch: 31 -> Test Accuracy: 81.79\n",
      "[32, 60] loss: 0.373\n",
      "[32, 120] loss: 0.387\n",
      "[32, 180] loss: 0.395\n",
      "[32, 240] loss: 0.388\n",
      "[32, 300] loss: 0.392\n",
      "[32, 360] loss: 0.387\n",
      "Epoch: 32 -> Loss: 0.37325873971\n",
      "Epoch: 32 -> Test Accuracy: 81.84\n",
      "[33, 60] loss: 0.373\n",
      "[33, 120] loss: 0.383\n",
      "[33, 180] loss: 0.390\n",
      "[33, 240] loss: 0.392\n",
      "[33, 300] loss: 0.398\n",
      "[33, 360] loss: 0.380\n",
      "Epoch: 33 -> Loss: 0.3280595541\n",
      "Epoch: 33 -> Test Accuracy: 82.0\n",
      "[34, 60] loss: 0.373\n",
      "[34, 120] loss: 0.383\n",
      "[34, 180] loss: 0.380\n",
      "[34, 240] loss: 0.383\n",
      "[34, 300] loss: 0.402\n",
      "[34, 360] loss: 0.393\n",
      "Epoch: 34 -> Loss: 0.441644012928\n",
      "Epoch: 34 -> Test Accuracy: 81.62\n",
      "[35, 60] loss: 0.365\n",
      "[35, 120] loss: 0.388\n",
      "[35, 180] loss: 0.388\n",
      "[35, 240] loss: 0.394\n",
      "[35, 300] loss: 0.372\n",
      "[35, 360] loss: 0.382\n",
      "Epoch: 35 -> Loss: 0.30990087986\n",
      "Epoch: 35 -> Test Accuracy: 81.7\n",
      "[36, 60] loss: 0.368\n",
      "[36, 120] loss: 0.366\n",
      "[36, 180] loss: 0.389\n",
      "[36, 240] loss: 0.401\n",
      "[36, 300] loss: 0.390\n",
      "[36, 360] loss: 0.379\n",
      "Epoch: 36 -> Loss: 0.488119274378\n",
      "Epoch: 36 -> Test Accuracy: 81.53\n",
      "[37, 60] loss: 0.370\n",
      "[37, 120] loss: 0.357\n",
      "[37, 180] loss: 0.383\n",
      "[37, 240] loss: 0.382\n",
      "[37, 300] loss: 0.383\n",
      "[37, 360] loss: 0.405\n",
      "Epoch: 37 -> Loss: 0.566225290298\n",
      "Epoch: 37 -> Test Accuracy: 81.84\n",
      "[38, 60] loss: 0.372\n",
      "[38, 120] loss: 0.374\n",
      "[38, 180] loss: 0.358\n",
      "[38, 240] loss: 0.378\n",
      "[38, 300] loss: 0.391\n",
      "[38, 360] loss: 0.391\n",
      "Epoch: 38 -> Loss: 0.460942596197\n",
      "Epoch: 38 -> Test Accuracy: 81.84\n",
      "[39, 60] loss: 0.357\n",
      "[39, 120] loss: 0.367\n",
      "[39, 180] loss: 0.363\n",
      "[39, 240] loss: 0.377\n",
      "[39, 300] loss: 0.378\n",
      "[39, 360] loss: 0.391\n",
      "Epoch: 39 -> Loss: 0.293903648853\n",
      "Epoch: 39 -> Test Accuracy: 81.33\n",
      "[40, 60] loss: 0.354\n",
      "[40, 120] loss: 0.368\n",
      "[40, 180] loss: 0.382\n",
      "[40, 240] loss: 0.367\n",
      "[40, 300] loss: 0.395\n",
      "[40, 360] loss: 0.390\n",
      "Epoch: 40 -> Loss: 0.529256463051\n",
      "Epoch: 40 -> Test Accuracy: 81.7\n",
      "[41, 60] loss: 0.363\n",
      "[41, 120] loss: 0.321\n",
      "[41, 180] loss: 0.336\n",
      "[41, 240] loss: 0.334\n",
      "[41, 300] loss: 0.339\n",
      "[41, 360] loss: 0.325\n",
      "Epoch: 41 -> Loss: 0.245809912682\n",
      "Epoch: 41 -> Test Accuracy: 82.77\n",
      "[42, 60] loss: 0.315\n",
      "[42, 120] loss: 0.314\n",
      "[42, 180] loss: 0.316\n",
      "[42, 240] loss: 0.319\n",
      "[42, 300] loss: 0.321\n",
      "[42, 360] loss: 0.318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.173453181982\n",
      "Epoch: 42 -> Test Accuracy: 83.14\n",
      "[43, 60] loss: 0.312\n",
      "[43, 120] loss: 0.310\n",
      "[43, 180] loss: 0.291\n",
      "[43, 240] loss: 0.292\n",
      "[43, 300] loss: 0.300\n",
      "[43, 360] loss: 0.308\n",
      "Epoch: 43 -> Loss: 0.450003147125\n",
      "Epoch: 43 -> Test Accuracy: 82.91\n",
      "[44, 60] loss: 0.300\n",
      "[44, 120] loss: 0.281\n",
      "[44, 180] loss: 0.298\n",
      "[44, 240] loss: 0.281\n",
      "[44, 300] loss: 0.304\n",
      "[44, 360] loss: 0.294\n",
      "Epoch: 44 -> Loss: 0.404316902161\n",
      "Epoch: 44 -> Test Accuracy: 83.25\n",
      "[45, 60] loss: 0.282\n",
      "[45, 120] loss: 0.300\n",
      "[45, 180] loss: 0.287\n",
      "[45, 240] loss: 0.289\n",
      "[45, 300] loss: 0.288\n",
      "[45, 360] loss: 0.288\n",
      "Epoch: 45 -> Loss: 0.344729572535\n",
      "Epoch: 45 -> Test Accuracy: 83.13\n",
      "[46, 60] loss: 0.288\n",
      "[46, 120] loss: 0.272\n",
      "[46, 180] loss: 0.281\n",
      "[46, 240] loss: 0.283\n",
      "[46, 300] loss: 0.277\n",
      "[46, 360] loss: 0.281\n",
      "Epoch: 46 -> Loss: 0.297571182251\n",
      "Epoch: 46 -> Test Accuracy: 83.18\n",
      "[47, 60] loss: 0.289\n",
      "[47, 120] loss: 0.276\n",
      "[47, 180] loss: 0.270\n",
      "[47, 240] loss: 0.262\n",
      "[47, 300] loss: 0.272\n",
      "[47, 360] loss: 0.267\n",
      "Epoch: 47 -> Loss: 0.307625681162\n",
      "Epoch: 47 -> Test Accuracy: 83.29\n",
      "[48, 60] loss: 0.275\n",
      "[48, 120] loss: 0.273\n",
      "[48, 180] loss: 0.264\n",
      "[48, 240] loss: 0.282\n",
      "[48, 300] loss: 0.279\n",
      "[48, 360] loss: 0.278\n",
      "Epoch: 48 -> Loss: 0.268704563379\n",
      "Epoch: 48 -> Test Accuracy: 83.34\n",
      "[49, 60] loss: 0.269\n",
      "[49, 120] loss: 0.281\n",
      "[49, 180] loss: 0.285\n",
      "[49, 240] loss: 0.274\n",
      "[49, 300] loss: 0.273\n",
      "[49, 360] loss: 0.272\n",
      "Epoch: 49 -> Loss: 0.383261531591\n",
      "Epoch: 49 -> Test Accuracy: 83.4\n",
      "[50, 60] loss: 0.267\n",
      "[50, 120] loss: 0.280\n",
      "[50, 180] loss: 0.263\n",
      "[50, 240] loss: 0.264\n",
      "[50, 300] loss: 0.270\n",
      "[50, 360] loss: 0.254\n",
      "Epoch: 50 -> Loss: 0.208925366402\n",
      "Epoch: 50 -> Test Accuracy: 83.44\n",
      "[51, 60] loss: 0.277\n",
      "[51, 120] loss: 0.273\n",
      "[51, 180] loss: 0.267\n",
      "[51, 240] loss: 0.267\n",
      "[51, 300] loss: 0.260\n",
      "[51, 360] loss: 0.259\n",
      "Epoch: 51 -> Loss: 0.3048222363\n",
      "Epoch: 51 -> Test Accuracy: 83.37\n",
      "[52, 60] loss: 0.278\n",
      "[52, 120] loss: 0.257\n",
      "[52, 180] loss: 0.251\n",
      "[52, 240] loss: 0.261\n",
      "[52, 300] loss: 0.271\n",
      "[52, 360] loss: 0.268\n",
      "Epoch: 52 -> Loss: 0.305587232113\n",
      "Epoch: 52 -> Test Accuracy: 83.33\n",
      "[53, 60] loss: 0.260\n",
      "[53, 120] loss: 0.254\n",
      "[53, 180] loss: 0.262\n",
      "[53, 240] loss: 0.259\n",
      "[53, 300] loss: 0.264\n",
      "[53, 360] loss: 0.264\n",
      "Epoch: 53 -> Loss: 0.379165053368\n",
      "Epoch: 53 -> Test Accuracy: 83.41\n",
      "[54, 60] loss: 0.259\n",
      "[54, 120] loss: 0.260\n",
      "[54, 180] loss: 0.262\n",
      "[54, 240] loss: 0.251\n",
      "[54, 300] loss: 0.254\n",
      "[54, 360] loss: 0.260\n",
      "Epoch: 54 -> Loss: 0.30886015296\n",
      "Epoch: 54 -> Test Accuracy: 83.4\n",
      "[55, 60] loss: 0.274\n",
      "[55, 120] loss: 0.257\n",
      "[55, 180] loss: 0.245\n",
      "[55, 240] loss: 0.259\n",
      "[55, 300] loss: 0.268\n",
      "[55, 360] loss: 0.264\n",
      "Epoch: 55 -> Loss: 0.285019725561\n",
      "Epoch: 55 -> Test Accuracy: 83.33\n",
      "[56, 60] loss: 0.259\n",
      "[56, 120] loss: 0.261\n",
      "[56, 180] loss: 0.258\n",
      "[56, 240] loss: 0.255\n",
      "[56, 300] loss: 0.252\n",
      "[56, 360] loss: 0.245\n",
      "Epoch: 56 -> Loss: 0.273119837046\n",
      "Epoch: 56 -> Test Accuracy: 83.42\n",
      "[57, 60] loss: 0.258\n",
      "[57, 120] loss: 0.262\n",
      "[57, 180] loss: 0.255\n",
      "[57, 240] loss: 0.262\n",
      "[57, 300] loss: 0.251\n",
      "[57, 360] loss: 0.263\n",
      "Epoch: 57 -> Loss: 0.233887270093\n",
      "Epoch: 57 -> Test Accuracy: 83.37\n",
      "[58, 60] loss: 0.263\n",
      "[58, 120] loss: 0.249\n",
      "[58, 180] loss: 0.240\n",
      "[58, 240] loss: 0.264\n",
      "[58, 300] loss: 0.262\n",
      "[58, 360] loss: 0.261\n",
      "Epoch: 58 -> Loss: 0.224438384175\n",
      "Epoch: 58 -> Test Accuracy: 83.26\n",
      "[59, 60] loss: 0.250\n",
      "[59, 120] loss: 0.240\n",
      "[59, 180] loss: 0.258\n",
      "[59, 240] loss: 0.269\n",
      "[59, 300] loss: 0.261\n",
      "[59, 360] loss: 0.259\n",
      "Epoch: 59 -> Loss: 0.273801386356\n",
      "Epoch: 59 -> Test Accuracy: 83.31\n",
      "[60, 60] loss: 0.262\n",
      "[60, 120] loss: 0.249\n",
      "[60, 180] loss: 0.258\n",
      "[60, 240] loss: 0.252\n",
      "[60, 300] loss: 0.256\n",
      "[60, 360] loss: 0.248\n",
      "Epoch: 60 -> Loss: 0.377781927586\n",
      "Epoch: 60 -> Test Accuracy: 83.4\n",
      "[61, 60] loss: 0.250\n",
      "[61, 120] loss: 0.246\n",
      "[61, 180] loss: 0.268\n",
      "[61, 240] loss: 0.259\n",
      "[61, 300] loss: 0.241\n",
      "[61, 360] loss: 0.258\n",
      "Epoch: 61 -> Loss: 0.183611422777\n",
      "Epoch: 61 -> Test Accuracy: 83.41\n",
      "[62, 60] loss: 0.253\n",
      "[62, 120] loss: 0.250\n",
      "[62, 180] loss: 0.255\n",
      "[62, 240] loss: 0.251\n",
      "[62, 300] loss: 0.247\n",
      "[62, 360] loss: 0.252\n",
      "Epoch: 62 -> Loss: 0.238436222076\n",
      "Epoch: 62 -> Test Accuracy: 83.41\n",
      "[63, 60] loss: 0.242\n",
      "[63, 120] loss: 0.255\n",
      "[63, 180] loss: 0.250\n",
      "[63, 240] loss: 0.248\n",
      "[63, 300] loss: 0.256\n",
      "[63, 360] loss: 0.247\n",
      "Epoch: 63 -> Loss: 0.214379429817\n",
      "Epoch: 63 -> Test Accuracy: 83.43\n",
      "[64, 60] loss: 0.241\n",
      "[64, 120] loss: 0.245\n",
      "[64, 180] loss: 0.248\n",
      "[64, 240] loss: 0.257\n",
      "[64, 300] loss: 0.246\n",
      "[64, 360] loss: 0.240\n",
      "Epoch: 64 -> Loss: 0.167256265879\n",
      "Epoch: 64 -> Test Accuracy: 83.38\n",
      "[65, 60] loss: 0.249\n",
      "[65, 120] loss: 0.249\n",
      "[65, 180] loss: 0.253\n",
      "[65, 240] loss: 0.241\n",
      "[65, 300] loss: 0.248\n",
      "[65, 360] loss: 0.249\n",
      "Epoch: 65 -> Loss: 0.197989732027\n",
      "Epoch: 65 -> Test Accuracy: 83.53\n",
      "[66, 60] loss: 0.241\n",
      "[66, 120] loss: 0.243\n",
      "[66, 180] loss: 0.254\n",
      "[66, 240] loss: 0.229\n",
      "[66, 300] loss: 0.243\n",
      "[66, 360] loss: 0.259\n",
      "Epoch: 66 -> Loss: 0.270983248949\n",
      "Epoch: 66 -> Test Accuracy: 83.39\n",
      "[67, 60] loss: 0.255\n",
      "[67, 120] loss: 0.245\n",
      "[67, 180] loss: 0.242\n",
      "[67, 240] loss: 0.234\n",
      "[67, 300] loss: 0.245\n",
      "[67, 360] loss: 0.247\n",
      "Epoch: 67 -> Loss: 0.275005787611\n",
      "Epoch: 67 -> Test Accuracy: 83.32\n",
      "[68, 60] loss: 0.240\n",
      "[68, 120] loss: 0.251\n",
      "[68, 180] loss: 0.250\n",
      "[68, 240] loss: 0.236\n",
      "[68, 300] loss: 0.242\n",
      "[68, 360] loss: 0.240\n",
      "Epoch: 68 -> Loss: 0.258368730545\n",
      "Epoch: 68 -> Test Accuracy: 83.49\n",
      "[69, 60] loss: 0.245\n",
      "[69, 120] loss: 0.240\n",
      "[69, 180] loss: 0.234\n",
      "[69, 240] loss: 0.247\n",
      "[69, 300] loss: 0.258\n",
      "[69, 360] loss: 0.245\n",
      "Epoch: 69 -> Loss: 0.427489459515\n",
      "Epoch: 69 -> Test Accuracy: 83.38\n",
      "[70, 60] loss: 0.247\n",
      "[70, 120] loss: 0.248\n",
      "[70, 180] loss: 0.247\n",
      "[70, 240] loss: 0.238\n",
      "[70, 300] loss: 0.252\n",
      "[70, 360] loss: 0.240\n",
      "Epoch: 70 -> Loss: 0.166559383273\n",
      "Epoch: 70 -> Test Accuracy: 83.28\n",
      "[71, 60] loss: 0.250\n",
      "[71, 120] loss: 0.244\n",
      "[71, 180] loss: 0.247\n",
      "[71, 240] loss: 0.244\n",
      "[71, 300] loss: 0.235\n",
      "[71, 360] loss: 0.236\n",
      "Epoch: 71 -> Loss: 0.452302157879\n",
      "Epoch: 71 -> Test Accuracy: 83.32\n",
      "[72, 60] loss: 0.229\n",
      "[72, 120] loss: 0.240\n",
      "[72, 180] loss: 0.236\n",
      "[72, 240] loss: 0.246\n",
      "[72, 300] loss: 0.242\n",
      "[72, 360] loss: 0.233\n",
      "Epoch: 72 -> Loss: 0.305540710688\n",
      "Epoch: 72 -> Test Accuracy: 83.2\n",
      "[73, 60] loss: 0.239\n",
      "[73, 120] loss: 0.243\n",
      "[73, 180] loss: 0.243\n",
      "[73, 240] loss: 0.239\n",
      "[73, 300] loss: 0.247\n",
      "[73, 360] loss: 0.230\n",
      "Epoch: 73 -> Loss: 0.335854500532\n",
      "Epoch: 73 -> Test Accuracy: 83.4\n",
      "[74, 60] loss: 0.230\n",
      "[74, 120] loss: 0.236\n",
      "[74, 180] loss: 0.240\n",
      "[74, 240] loss: 0.247\n",
      "[74, 300] loss: 0.240\n",
      "[74, 360] loss: 0.236\n",
      "Epoch: 74 -> Loss: 0.158597797155\n",
      "Epoch: 74 -> Test Accuracy: 83.31\n",
      "[75, 60] loss: 0.235\n",
      "[75, 120] loss: 0.242\n",
      "[75, 180] loss: 0.240\n",
      "[75, 240] loss: 0.241\n",
      "[75, 300] loss: 0.241\n",
      "[75, 360] loss: 0.237\n",
      "Epoch: 75 -> Loss: 0.318218797445\n",
      "Epoch: 75 -> Test Accuracy: 83.38\n",
      "[76, 60] loss: 0.239\n",
      "[76, 120] loss: 0.248\n",
      "[76, 180] loss: 0.237\n",
      "[76, 240] loss: 0.234\n",
      "[76, 300] loss: 0.244\n",
      "[76, 360] loss: 0.224\n",
      "Epoch: 76 -> Loss: 0.286716163158\n",
      "Epoch: 76 -> Test Accuracy: 83.43\n",
      "[77, 60] loss: 0.236\n",
      "[77, 120] loss: 0.245\n",
      "[77, 180] loss: 0.241\n",
      "[77, 240] loss: 0.230\n",
      "[77, 300] loss: 0.234\n",
      "[77, 360] loss: 0.227\n",
      "Epoch: 77 -> Loss: 0.290097177029\n",
      "Epoch: 77 -> Test Accuracy: 83.26\n",
      "[78, 60] loss: 0.241\n",
      "[78, 120] loss: 0.235\n",
      "[78, 180] loss: 0.246\n",
      "[78, 240] loss: 0.235\n",
      "[78, 300] loss: 0.238\n",
      "[78, 360] loss: 0.224\n",
      "Epoch: 78 -> Loss: 0.234265044332\n",
      "Epoch: 78 -> Test Accuracy: 83.32\n",
      "[79, 60] loss: 0.251\n",
      "[79, 120] loss: 0.231\n",
      "[79, 180] loss: 0.238\n",
      "[79, 240] loss: 0.225\n",
      "[79, 300] loss: 0.234\n",
      "[79, 360] loss: 0.228\n",
      "Epoch: 79 -> Loss: 0.210692614317\n",
      "Epoch: 79 -> Test Accuracy: 83.44\n",
      "[80, 60] loss: 0.231\n",
      "[80, 120] loss: 0.239\n",
      "[80, 180] loss: 0.247\n",
      "[80, 240] loss: 0.228\n",
      "[80, 300] loss: 0.233\n",
      "[80, 360] loss: 0.227\n",
      "Epoch: 80 -> Loss: 0.248990729451\n",
      "Epoch: 80 -> Test Accuracy: 83.3\n",
      "[81, 60] loss: 0.231\n",
      "[81, 120] loss: 0.231\n",
      "[81, 180] loss: 0.228\n",
      "[81, 240] loss: 0.238\n",
      "[81, 300] loss: 0.237\n",
      "[81, 360] loss: 0.238\n",
      "Epoch: 81 -> Loss: 0.227644920349\n",
      "Epoch: 81 -> Test Accuracy: 83.39\n",
      "[82, 60] loss: 0.222\n",
      "[82, 120] loss: 0.231\n",
      "[82, 180] loss: 0.222\n",
      "[82, 240] loss: 0.237\n",
      "[82, 300] loss: 0.233\n",
      "[82, 360] loss: 0.233\n",
      "Epoch: 82 -> Loss: 0.220370575786\n",
      "Epoch: 82 -> Test Accuracy: 83.38\n",
      "[83, 60] loss: 0.233\n",
      "[83, 120] loss: 0.231\n",
      "[83, 180] loss: 0.228\n",
      "[83, 240] loss: 0.230\n",
      "[83, 300] loss: 0.232\n",
      "[83, 360] loss: 0.233\n",
      "Epoch: 83 -> Loss: 0.100116893649\n",
      "Epoch: 83 -> Test Accuracy: 83.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.217\n",
      "[84, 120] loss: 0.230\n",
      "[84, 180] loss: 0.224\n",
      "[84, 240] loss: 0.220\n",
      "[84, 300] loss: 0.240\n",
      "[84, 360] loss: 0.232\n",
      "Epoch: 84 -> Loss: 0.252890765667\n",
      "Epoch: 84 -> Test Accuracy: 83.23\n",
      "[85, 60] loss: 0.224\n",
      "[85, 120] loss: 0.232\n",
      "[85, 180] loss: 0.230\n",
      "[85, 240] loss: 0.233\n",
      "[85, 300] loss: 0.220\n",
      "[85, 360] loss: 0.227\n",
      "Epoch: 85 -> Loss: 0.411238521338\n",
      "Epoch: 85 -> Test Accuracy: 83.36\n",
      "[86, 60] loss: 0.233\n",
      "[86, 120] loss: 0.223\n",
      "[86, 180] loss: 0.228\n",
      "[86, 240] loss: 0.225\n",
      "[86, 300] loss: 0.209\n",
      "[86, 360] loss: 0.220\n",
      "Epoch: 86 -> Loss: 0.225403144956\n",
      "Epoch: 86 -> Test Accuracy: 83.32\n",
      "[87, 60] loss: 0.222\n",
      "[87, 120] loss: 0.220\n",
      "[87, 180] loss: 0.226\n",
      "[87, 240] loss: 0.231\n",
      "[87, 300] loss: 0.228\n",
      "[87, 360] loss: 0.211\n",
      "Epoch: 87 -> Loss: 0.223494291306\n",
      "Epoch: 87 -> Test Accuracy: 83.32\n",
      "[88, 60] loss: 0.233\n",
      "[88, 120] loss: 0.223\n",
      "[88, 180] loss: 0.234\n",
      "[88, 240] loss: 0.223\n",
      "[88, 300] loss: 0.223\n",
      "[88, 360] loss: 0.225\n",
      "Epoch: 88 -> Loss: 0.289132535458\n",
      "Epoch: 88 -> Test Accuracy: 83.28\n",
      "[89, 60] loss: 0.226\n",
      "[89, 120] loss: 0.227\n",
      "[89, 180] loss: 0.219\n",
      "[89, 240] loss: 0.231\n",
      "[89, 300] loss: 0.235\n",
      "[89, 360] loss: 0.220\n",
      "Epoch: 89 -> Loss: 0.183604389429\n",
      "Epoch: 89 -> Test Accuracy: 83.27\n",
      "[90, 60] loss: 0.242\n",
      "[90, 120] loss: 0.226\n",
      "[90, 180] loss: 0.221\n",
      "[90, 240] loss: 0.230\n",
      "[90, 300] loss: 0.215\n",
      "[90, 360] loss: 0.226\n",
      "Epoch: 90 -> Loss: 0.297460615635\n",
      "Epoch: 90 -> Test Accuracy: 83.28\n",
      "[91, 60] loss: 0.214\n",
      "[91, 120] loss: 0.221\n",
      "[91, 180] loss: 0.222\n",
      "[91, 240] loss: 0.230\n",
      "[91, 300] loss: 0.223\n",
      "[91, 360] loss: 0.224\n",
      "Epoch: 91 -> Loss: 0.184289395809\n",
      "Epoch: 91 -> Test Accuracy: 83.21\n",
      "[92, 60] loss: 0.219\n",
      "[92, 120] loss: 0.218\n",
      "[92, 180] loss: 0.228\n",
      "[92, 240] loss: 0.226\n",
      "[92, 300] loss: 0.226\n",
      "[92, 360] loss: 0.230\n",
      "Epoch: 92 -> Loss: 0.134510785341\n",
      "Epoch: 92 -> Test Accuracy: 83.06\n",
      "[93, 60] loss: 0.218\n",
      "[93, 120] loss: 0.215\n",
      "[93, 180] loss: 0.238\n",
      "[93, 240] loss: 0.227\n",
      "[93, 300] loss: 0.214\n",
      "[93, 360] loss: 0.227\n",
      "Epoch: 93 -> Loss: 0.350413262844\n",
      "Epoch: 93 -> Test Accuracy: 83.16\n",
      "[94, 60] loss: 0.222\n",
      "[94, 120] loss: 0.217\n",
      "[94, 180] loss: 0.216\n",
      "[94, 240] loss: 0.220\n",
      "[94, 300] loss: 0.227\n",
      "[94, 360] loss: 0.210\n",
      "Epoch: 94 -> Loss: 0.186244145036\n",
      "Epoch: 94 -> Test Accuracy: 83.24\n",
      "[95, 60] loss: 0.224\n",
      "[95, 120] loss: 0.217\n",
      "[95, 180] loss: 0.213\n",
      "[95, 240] loss: 0.222\n",
      "[95, 300] loss: 0.214\n",
      "[95, 360] loss: 0.224\n",
      "Epoch: 95 -> Loss: 0.143851593137\n",
      "Epoch: 95 -> Test Accuracy: 83.26\n",
      "[96, 60] loss: 0.212\n",
      "[96, 120] loss: 0.201\n",
      "[96, 180] loss: 0.234\n",
      "[96, 240] loss: 0.221\n",
      "[96, 300] loss: 0.219\n",
      "[96, 360] loss: 0.229\n",
      "Epoch: 96 -> Loss: 0.417388141155\n",
      "Epoch: 96 -> Test Accuracy: 83.29\n",
      "[97, 60] loss: 0.224\n",
      "[97, 120] loss: 0.217\n",
      "[97, 180] loss: 0.223\n",
      "[97, 240] loss: 0.209\n",
      "[97, 300] loss: 0.219\n",
      "[97, 360] loss: 0.218\n",
      "Epoch: 97 -> Loss: 0.229695647955\n",
      "Epoch: 97 -> Test Accuracy: 83.21\n",
      "[98, 60] loss: 0.227\n",
      "[98, 120] loss: 0.221\n",
      "[98, 180] loss: 0.210\n",
      "[98, 240] loss: 0.212\n",
      "[98, 300] loss: 0.214\n",
      "[98, 360] loss: 0.222\n",
      "Epoch: 98 -> Loss: 0.245625212789\n",
      "Epoch: 98 -> Test Accuracy: 83.2\n",
      "[99, 60] loss: 0.215\n",
      "[99, 120] loss: 0.210\n",
      "[99, 180] loss: 0.217\n",
      "[99, 240] loss: 0.230\n",
      "[99, 300] loss: 0.223\n",
      "[99, 360] loss: 0.218\n",
      "Epoch: 99 -> Loss: 0.218556687236\n",
      "Epoch: 99 -> Test Accuracy: 83.38\n",
      "[100, 60] loss: 0.212\n",
      "[100, 120] loss: 0.203\n",
      "[100, 180] loss: 0.209\n",
      "[100, 240] loss: 0.207\n",
      "[100, 300] loss: 0.220\n",
      "[100, 360] loss: 0.220\n",
      "Epoch: 100 -> Loss: 0.225704461336\n",
      "Epoch: 100 -> Test Accuracy: 83.22\n",
      "Finished Training\n",
      "[1, 60] loss: 1.666\n",
      "[1, 120] loss: 0.812\n",
      "[1, 180] loss: 0.760\n",
      "[1, 240] loss: 0.708\n",
      "[1, 300] loss: 0.678\n",
      "[1, 360] loss: 0.640\n",
      "Epoch: 1 -> Loss: 0.528734326363\n",
      "Epoch: 1 -> Test Accuracy: 78.85\n",
      "[2, 60] loss: 0.557\n",
      "[2, 120] loss: 0.612\n",
      "[2, 180] loss: 0.585\n",
      "[2, 240] loss: 0.576\n",
      "[2, 300] loss: 0.569\n",
      "[2, 360] loss: 0.545\n",
      "Epoch: 2 -> Loss: 0.748282909393\n",
      "Epoch: 2 -> Test Accuracy: 80.63\n",
      "[3, 60] loss: 0.518\n",
      "[3, 120] loss: 0.519\n",
      "[3, 180] loss: 0.505\n",
      "[3, 240] loss: 0.524\n",
      "[3, 300] loss: 0.526\n",
      "[3, 360] loss: 0.516\n",
      "Epoch: 3 -> Loss: 0.471897512674\n",
      "Epoch: 3 -> Test Accuracy: 81.69\n",
      "[4, 60] loss: 0.487\n",
      "[4, 120] loss: 0.487\n",
      "[4, 180] loss: 0.493\n",
      "[4, 240] loss: 0.463\n",
      "[4, 300] loss: 0.497\n",
      "[4, 360] loss: 0.470\n",
      "Epoch: 4 -> Loss: 0.407703459263\n",
      "Epoch: 4 -> Test Accuracy: 82.45\n",
      "[5, 60] loss: 0.454\n",
      "[5, 120] loss: 0.467\n",
      "[5, 180] loss: 0.466\n",
      "[5, 240] loss: 0.438\n",
      "[5, 300] loss: 0.464\n",
      "[5, 360] loss: 0.472\n",
      "Epoch: 5 -> Loss: 0.376129329205\n",
      "Epoch: 5 -> Test Accuracy: 82.05\n",
      "[6, 60] loss: 0.435\n",
      "[6, 120] loss: 0.441\n",
      "[6, 180] loss: 0.431\n",
      "[6, 240] loss: 0.445\n",
      "[6, 300] loss: 0.447\n",
      "[6, 360] loss: 0.448\n",
      "Epoch: 6 -> Loss: 0.412799924612\n",
      "Epoch: 6 -> Test Accuracy: 82.91\n",
      "[7, 60] loss: 0.405\n",
      "[7, 120] loss: 0.425\n",
      "[7, 180] loss: 0.428\n",
      "[7, 240] loss: 0.421\n",
      "[7, 300] loss: 0.425\n",
      "[7, 360] loss: 0.442\n",
      "Epoch: 7 -> Loss: 0.435140609741\n",
      "Epoch: 7 -> Test Accuracy: 83.02\n",
      "[8, 60] loss: 0.396\n",
      "[8, 120] loss: 0.427\n",
      "[8, 180] loss: 0.413\n",
      "[8, 240] loss: 0.409\n",
      "[8, 300] loss: 0.421\n",
      "[8, 360] loss: 0.441\n",
      "Epoch: 8 -> Loss: 0.49392747879\n",
      "Epoch: 8 -> Test Accuracy: 82.99\n",
      "[9, 60] loss: 0.389\n",
      "[9, 120] loss: 0.395\n",
      "[9, 180] loss: 0.414\n",
      "[9, 240] loss: 0.430\n",
      "[9, 300] loss: 0.403\n",
      "[9, 360] loss: 0.415\n",
      "Epoch: 9 -> Loss: 0.324830144644\n",
      "Epoch: 9 -> Test Accuracy: 83.33\n",
      "[10, 60] loss: 0.391\n",
      "[10, 120] loss: 0.398\n",
      "[10, 180] loss: 0.396\n",
      "[10, 240] loss: 0.407\n",
      "[10, 300] loss: 0.410\n",
      "[10, 360] loss: 0.410\n",
      "Epoch: 10 -> Loss: 0.459988892078\n",
      "Epoch: 10 -> Test Accuracy: 83.49\n",
      "[11, 60] loss: 0.379\n",
      "[11, 120] loss: 0.389\n",
      "[11, 180] loss: 0.406\n",
      "[11, 240] loss: 0.400\n",
      "[11, 300] loss: 0.399\n",
      "[11, 360] loss: 0.401\n",
      "Epoch: 11 -> Loss: 0.477080047131\n",
      "Epoch: 11 -> Test Accuracy: 84.12\n",
      "[12, 60] loss: 0.383\n",
      "[12, 120] loss: 0.381\n",
      "[12, 180] loss: 0.375\n",
      "[12, 240] loss: 0.392\n",
      "[12, 300] loss: 0.406\n",
      "[12, 360] loss: 0.394\n",
      "Epoch: 12 -> Loss: 0.370262026787\n",
      "Epoch: 12 -> Test Accuracy: 83.97\n",
      "[13, 60] loss: 0.363\n",
      "[13, 120] loss: 0.378\n",
      "[13, 180] loss: 0.382\n",
      "[13, 240] loss: 0.390\n",
      "[13, 300] loss: 0.414\n",
      "[13, 360] loss: 0.404\n",
      "Epoch: 13 -> Loss: 0.539183974266\n",
      "Epoch: 13 -> Test Accuracy: 83.58\n",
      "[14, 60] loss: 0.351\n",
      "[14, 120] loss: 0.378\n",
      "[14, 180] loss: 0.384\n",
      "[14, 240] loss: 0.393\n",
      "[14, 300] loss: 0.392\n",
      "[14, 360] loss: 0.395\n",
      "Epoch: 14 -> Loss: 0.392552495003\n",
      "Epoch: 14 -> Test Accuracy: 84.32\n",
      "[15, 60] loss: 0.371\n",
      "[15, 120] loss: 0.370\n",
      "[15, 180] loss: 0.381\n",
      "[15, 240] loss: 0.373\n",
      "[15, 300] loss: 0.374\n",
      "[15, 360] loss: 0.391\n",
      "Epoch: 15 -> Loss: 0.276484012604\n",
      "Epoch: 15 -> Test Accuracy: 83.06\n",
      "[16, 60] loss: 0.367\n",
      "[16, 120] loss: 0.359\n",
      "[16, 180] loss: 0.363\n",
      "[16, 240] loss: 0.384\n",
      "[16, 300] loss: 0.387\n",
      "[16, 360] loss: 0.377\n",
      "Epoch: 16 -> Loss: 0.377467572689\n",
      "Epoch: 16 -> Test Accuracy: 83.77\n",
      "[17, 60] loss: 0.352\n",
      "[17, 120] loss: 0.374\n",
      "[17, 180] loss: 0.385\n",
      "[17, 240] loss: 0.378\n",
      "[17, 300] loss: 0.384\n",
      "[17, 360] loss: 0.378\n",
      "Epoch: 17 -> Loss: 0.353844493628\n",
      "Epoch: 17 -> Test Accuracy: 83.37\n",
      "[18, 60] loss: 0.367\n",
      "[18, 120] loss: 0.365\n",
      "[18, 180] loss: 0.380\n",
      "[18, 240] loss: 0.374\n",
      "[18, 300] loss: 0.390\n",
      "[18, 360] loss: 0.384\n",
      "Epoch: 18 -> Loss: 0.506995856762\n",
      "Epoch: 18 -> Test Accuracy: 83.85\n",
      "[19, 60] loss: 0.361\n",
      "[19, 120] loss: 0.363\n",
      "[19, 180] loss: 0.381\n",
      "[19, 240] loss: 0.373\n",
      "[19, 300] loss: 0.383\n",
      "[19, 360] loss: 0.385\n",
      "Epoch: 19 -> Loss: 0.240659594536\n",
      "Epoch: 19 -> Test Accuracy: 83.89\n",
      "[20, 60] loss: 0.325\n",
      "[20, 120] loss: 0.368\n",
      "[20, 180] loss: 0.368\n",
      "[20, 240] loss: 0.391\n",
      "[20, 300] loss: 0.386\n",
      "[20, 360] loss: 0.368\n",
      "Epoch: 20 -> Loss: 0.429391950369\n",
      "Epoch: 20 -> Test Accuracy: 83.28\n",
      "[21, 60] loss: 0.315\n",
      "[21, 120] loss: 0.310\n",
      "[21, 180] loss: 0.290\n",
      "[21, 240] loss: 0.303\n",
      "[21, 300] loss: 0.289\n",
      "[21, 360] loss: 0.278\n",
      "Epoch: 21 -> Loss: 0.269509881735\n",
      "Epoch: 21 -> Test Accuracy: 85.41\n",
      "[22, 60] loss: 0.266\n",
      "[22, 120] loss: 0.270\n",
      "[22, 180] loss: 0.254\n",
      "[22, 240] loss: 0.271\n",
      "[22, 300] loss: 0.258\n",
      "[22, 360] loss: 0.262\n",
      "Epoch: 22 -> Loss: 0.218567803502\n",
      "Epoch: 22 -> Test Accuracy: 85.31\n",
      "[23, 60] loss: 0.242\n",
      "[23, 120] loss: 0.251\n",
      "[23, 180] loss: 0.246\n",
      "[23, 240] loss: 0.250\n",
      "[23, 300] loss: 0.260\n",
      "[23, 360] loss: 0.245\n",
      "Epoch: 23 -> Loss: 0.261430084705\n",
      "Epoch: 23 -> Test Accuracy: 85.73\n",
      "[24, 60] loss: 0.240\n",
      "[24, 120] loss: 0.245\n",
      "[24, 180] loss: 0.245\n",
      "[24, 240] loss: 0.224\n",
      "[24, 300] loss: 0.226\n",
      "[24, 360] loss: 0.235\n",
      "Epoch: 24 -> Loss: 0.329823851585\n",
      "Epoch: 24 -> Test Accuracy: 85.79\n",
      "[25, 60] loss: 0.216\n",
      "[25, 120] loss: 0.225\n",
      "[25, 180] loss: 0.225\n",
      "[25, 240] loss: 0.232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 300] loss: 0.223\n",
      "[25, 360] loss: 0.224\n",
      "Epoch: 25 -> Loss: 0.322388321161\n",
      "Epoch: 25 -> Test Accuracy: 85.65\n",
      "[26, 60] loss: 0.214\n",
      "[26, 120] loss: 0.225\n",
      "[26, 180] loss: 0.212\n",
      "[26, 240] loss: 0.231\n",
      "[26, 300] loss: 0.225\n",
      "[26, 360] loss: 0.222\n",
      "Epoch: 26 -> Loss: 0.386886686087\n",
      "Epoch: 26 -> Test Accuracy: 85.59\n",
      "[27, 60] loss: 0.208\n",
      "[27, 120] loss: 0.220\n",
      "[27, 180] loss: 0.208\n",
      "[27, 240] loss: 0.209\n",
      "[27, 300] loss: 0.217\n",
      "[27, 360] loss: 0.210\n",
      "Epoch: 27 -> Loss: 0.34619101882\n",
      "Epoch: 27 -> Test Accuracy: 85.71\n",
      "[28, 60] loss: 0.198\n",
      "[28, 120] loss: 0.215\n",
      "[28, 180] loss: 0.216\n",
      "[28, 240] loss: 0.208\n",
      "[28, 300] loss: 0.214\n",
      "[28, 360] loss: 0.204\n",
      "Epoch: 28 -> Loss: 0.256702274084\n",
      "Epoch: 28 -> Test Accuracy: 85.66\n",
      "[29, 60] loss: 0.194\n",
      "[29, 120] loss: 0.201\n",
      "[29, 180] loss: 0.199\n",
      "[29, 240] loss: 0.207\n",
      "[29, 300] loss: 0.215\n",
      "[29, 360] loss: 0.215\n",
      "Epoch: 29 -> Loss: 0.249454781413\n",
      "Epoch: 29 -> Test Accuracy: 85.64\n",
      "[30, 60] loss: 0.189\n",
      "[30, 120] loss: 0.199\n",
      "[30, 180] loss: 0.202\n",
      "[30, 240] loss: 0.216\n",
      "[30, 300] loss: 0.212\n",
      "[30, 360] loss: 0.198\n",
      "Epoch: 30 -> Loss: 0.105788983405\n",
      "Epoch: 30 -> Test Accuracy: 85.44\n",
      "[31, 60] loss: 0.190\n",
      "[31, 120] loss: 0.196\n",
      "[31, 180] loss: 0.204\n",
      "[31, 240] loss: 0.196\n",
      "[31, 300] loss: 0.194\n",
      "[31, 360] loss: 0.208\n",
      "Epoch: 31 -> Loss: 0.0999970063567\n",
      "Epoch: 31 -> Test Accuracy: 85.75\n",
      "[32, 60] loss: 0.198\n",
      "[32, 120] loss: 0.196\n",
      "[32, 180] loss: 0.196\n",
      "[32, 240] loss: 0.211\n",
      "[32, 300] loss: 0.200\n",
      "[32, 360] loss: 0.199\n",
      "Epoch: 32 -> Loss: 0.154513895512\n",
      "Epoch: 32 -> Test Accuracy: 85.61\n",
      "[33, 60] loss: 0.181\n",
      "[33, 120] loss: 0.213\n",
      "[33, 180] loss: 0.209\n",
      "[33, 240] loss: 0.189\n",
      "[33, 300] loss: 0.202\n",
      "[33, 360] loss: 0.209\n",
      "Epoch: 33 -> Loss: 0.258195340633\n",
      "Epoch: 33 -> Test Accuracy: 85.25\n",
      "[34, 60] loss: 0.191\n",
      "[34, 120] loss: 0.191\n",
      "[34, 180] loss: 0.204\n",
      "[34, 240] loss: 0.203\n",
      "[34, 300] loss: 0.209\n",
      "[34, 360] loss: 0.199\n",
      "Epoch: 34 -> Loss: 0.375159293413\n",
      "Epoch: 34 -> Test Accuracy: 85.46\n",
      "[35, 60] loss: 0.190\n",
      "[35, 120] loss: 0.180\n",
      "[35, 180] loss: 0.197\n",
      "[35, 240] loss: 0.198\n",
      "[35, 300] loss: 0.208\n",
      "[35, 360] loss: 0.209\n",
      "Epoch: 35 -> Loss: 0.306605398655\n",
      "Epoch: 35 -> Test Accuracy: 85.26\n",
      "[36, 60] loss: 0.193\n",
      "[36, 120] loss: 0.196\n",
      "[36, 180] loss: 0.208\n",
      "[36, 240] loss: 0.186\n",
      "[36, 300] loss: 0.204\n",
      "[36, 360] loss: 0.204\n",
      "Epoch: 36 -> Loss: 0.290996193886\n",
      "Epoch: 36 -> Test Accuracy: 85.63\n",
      "[37, 60] loss: 0.183\n",
      "[37, 120] loss: 0.185\n",
      "[37, 180] loss: 0.190\n",
      "[37, 240] loss: 0.202\n",
      "[37, 300] loss: 0.204\n",
      "[37, 360] loss: 0.200\n",
      "Epoch: 37 -> Loss: 0.293617725372\n",
      "Epoch: 37 -> Test Accuracy: 85.53\n",
      "[38, 60] loss: 0.185\n",
      "[38, 120] loss: 0.189\n",
      "[38, 180] loss: 0.201\n",
      "[38, 240] loss: 0.198\n",
      "[38, 300] loss: 0.201\n",
      "[38, 360] loss: 0.203\n",
      "Epoch: 38 -> Loss: 0.189019560814\n",
      "Epoch: 38 -> Test Accuracy: 85.07\n",
      "[39, 60] loss: 0.184\n",
      "[39, 120] loss: 0.179\n",
      "[39, 180] loss: 0.198\n",
      "[39, 240] loss: 0.200\n",
      "[39, 300] loss: 0.212\n",
      "[39, 360] loss: 0.193\n",
      "Epoch: 39 -> Loss: 0.26672872901\n",
      "Epoch: 39 -> Test Accuracy: 85.26\n",
      "[40, 60] loss: 0.183\n",
      "[40, 120] loss: 0.183\n",
      "[40, 180] loss: 0.197\n",
      "[40, 240] loss: 0.178\n",
      "[40, 300] loss: 0.205\n",
      "[40, 360] loss: 0.204\n",
      "Epoch: 40 -> Loss: 0.395910412073\n",
      "Epoch: 40 -> Test Accuracy: 85.27\n",
      "[41, 60] loss: 0.179\n",
      "[41, 120] loss: 0.160\n",
      "[41, 180] loss: 0.159\n",
      "[41, 240] loss: 0.152\n",
      "[41, 300] loss: 0.158\n",
      "[41, 360] loss: 0.156\n",
      "Epoch: 41 -> Loss: 0.0943783000112\n",
      "Epoch: 41 -> Test Accuracy: 86.13\n",
      "[42, 60] loss: 0.153\n",
      "[42, 120] loss: 0.140\n",
      "[42, 180] loss: 0.151\n",
      "[42, 240] loss: 0.155\n",
      "[42, 300] loss: 0.148\n",
      "[42, 360] loss: 0.144\n",
      "Epoch: 42 -> Loss: 0.122677065432\n",
      "Epoch: 42 -> Test Accuracy: 86.33\n",
      "[43, 60] loss: 0.136\n",
      "[43, 120] loss: 0.143\n",
      "[43, 180] loss: 0.146\n",
      "[43, 240] loss: 0.134\n",
      "[43, 300] loss: 0.138\n",
      "[43, 360] loss: 0.138\n",
      "Epoch: 43 -> Loss: 0.0947639122605\n",
      "Epoch: 43 -> Test Accuracy: 86.25\n",
      "[44, 60] loss: 0.123\n",
      "[44, 120] loss: 0.133\n",
      "[44, 180] loss: 0.132\n",
      "[44, 240] loss: 0.137\n",
      "[44, 300] loss: 0.134\n",
      "[44, 360] loss: 0.137\n",
      "Epoch: 44 -> Loss: 0.0986238270998\n",
      "Epoch: 44 -> Test Accuracy: 86.31\n",
      "[45, 60] loss: 0.124\n",
      "[45, 120] loss: 0.126\n",
      "[45, 180] loss: 0.118\n",
      "[45, 240] loss: 0.123\n",
      "[45, 300] loss: 0.125\n",
      "[45, 360] loss: 0.133\n",
      "Epoch: 45 -> Loss: 0.122785553336\n",
      "Epoch: 45 -> Test Accuracy: 86.28\n",
      "[46, 60] loss: 0.119\n",
      "[46, 120] loss: 0.121\n",
      "[46, 180] loss: 0.122\n",
      "[46, 240] loss: 0.117\n",
      "[46, 300] loss: 0.112\n",
      "[46, 360] loss: 0.120\n",
      "Epoch: 46 -> Loss: 0.129695028067\n",
      "Epoch: 46 -> Test Accuracy: 86.34\n",
      "[47, 60] loss: 0.109\n",
      "[47, 120] loss: 0.123\n",
      "[47, 180] loss: 0.120\n",
      "[47, 240] loss: 0.126\n",
      "[47, 300] loss: 0.114\n",
      "[47, 360] loss: 0.111\n",
      "Epoch: 47 -> Loss: 0.11444824934\n",
      "Epoch: 47 -> Test Accuracy: 86.44\n",
      "[48, 60] loss: 0.113\n",
      "[48, 120] loss: 0.122\n",
      "[48, 180] loss: 0.117\n",
      "[48, 240] loss: 0.112\n",
      "[48, 300] loss: 0.110\n",
      "[48, 360] loss: 0.116\n",
      "Epoch: 48 -> Loss: 0.107685253024\n",
      "Epoch: 48 -> Test Accuracy: 86.55\n",
      "[49, 60] loss: 0.108\n",
      "[49, 120] loss: 0.115\n",
      "[49, 180] loss: 0.116\n",
      "[49, 240] loss: 0.113\n",
      "[49, 300] loss: 0.119\n",
      "[49, 360] loss: 0.113\n",
      "Epoch: 49 -> Loss: 0.113089598715\n",
      "Epoch: 49 -> Test Accuracy: 86.42\n",
      "[50, 60] loss: 0.115\n",
      "[50, 120] loss: 0.112\n",
      "[50, 180] loss: 0.108\n",
      "[50, 240] loss: 0.107\n",
      "[50, 300] loss: 0.110\n",
      "[50, 360] loss: 0.102\n",
      "Epoch: 50 -> Loss: 0.142826527357\n",
      "Epoch: 50 -> Test Accuracy: 86.49\n",
      "[51, 60] loss: 0.105\n",
      "[51, 120] loss: 0.107\n",
      "[51, 180] loss: 0.115\n",
      "[51, 240] loss: 0.112\n",
      "[51, 300] loss: 0.116\n",
      "[51, 360] loss: 0.113\n",
      "Epoch: 51 -> Loss: 0.112693808973\n",
      "Epoch: 51 -> Test Accuracy: 86.48\n",
      "[52, 60] loss: 0.106\n",
      "[52, 120] loss: 0.111\n",
      "[52, 180] loss: 0.118\n",
      "[52, 240] loss: 0.112\n",
      "[52, 300] loss: 0.109\n",
      "[52, 360] loss: 0.111\n",
      "Epoch: 52 -> Loss: 0.102873206139\n",
      "Epoch: 52 -> Test Accuracy: 86.51\n",
      "[53, 60] loss: 0.109\n",
      "[53, 120] loss: 0.104\n",
      "[53, 180] loss: 0.107\n",
      "[53, 240] loss: 0.109\n",
      "[53, 300] loss: 0.116\n",
      "[53, 360] loss: 0.108\n",
      "Epoch: 53 -> Loss: 0.165378883481\n",
      "Epoch: 53 -> Test Accuracy: 86.52\n",
      "[54, 60] loss: 0.111\n",
      "[54, 120] loss: 0.110\n",
      "[54, 180] loss: 0.107\n",
      "[54, 240] loss: 0.115\n",
      "[54, 300] loss: 0.106\n",
      "[54, 360] loss: 0.106\n",
      "Epoch: 54 -> Loss: 0.20932674408\n",
      "Epoch: 54 -> Test Accuracy: 86.52\n",
      "[55, 60] loss: 0.103\n",
      "[55, 120] loss: 0.108\n",
      "[55, 180] loss: 0.098\n",
      "[55, 240] loss: 0.106\n",
      "[55, 300] loss: 0.110\n",
      "[55, 360] loss: 0.105\n",
      "Epoch: 55 -> Loss: 0.0778907984495\n",
      "Epoch: 55 -> Test Accuracy: 86.51\n",
      "[56, 60] loss: 0.107\n",
      "[56, 120] loss: 0.105\n",
      "[56, 180] loss: 0.115\n",
      "[56, 240] loss: 0.105\n",
      "[56, 300] loss: 0.111\n",
      "[56, 360] loss: 0.097\n",
      "Epoch: 56 -> Loss: 0.0608037933707\n",
      "Epoch: 56 -> Test Accuracy: 86.58\n",
      "[57, 60] loss: 0.097\n",
      "[57, 120] loss: 0.109\n",
      "[57, 180] loss: 0.104\n",
      "[57, 240] loss: 0.103\n",
      "[57, 300] loss: 0.105\n",
      "[57, 360] loss: 0.107\n",
      "Epoch: 57 -> Loss: 0.154722213745\n",
      "Epoch: 57 -> Test Accuracy: 86.51\n",
      "[58, 60] loss: 0.106\n",
      "[58, 120] loss: 0.106\n",
      "[58, 180] loss: 0.102\n",
      "[58, 240] loss: 0.096\n",
      "[58, 300] loss: 0.102\n",
      "[58, 360] loss: 0.100\n",
      "Epoch: 58 -> Loss: 0.0871781185269\n",
      "Epoch: 58 -> Test Accuracy: 86.48\n",
      "[59, 60] loss: 0.103\n",
      "[59, 120] loss: 0.111\n",
      "[59, 180] loss: 0.107\n",
      "[59, 240] loss: 0.109\n",
      "[59, 300] loss: 0.098\n",
      "[59, 360] loss: 0.095\n",
      "Epoch: 59 -> Loss: 0.110949575901\n",
      "Epoch: 59 -> Test Accuracy: 86.54\n",
      "[60, 60] loss: 0.100\n",
      "[60, 120] loss: 0.107\n",
      "[60, 180] loss: 0.101\n",
      "[60, 240] loss: 0.101\n",
      "[60, 300] loss: 0.098\n",
      "[60, 360] loss: 0.101\n",
      "Epoch: 60 -> Loss: 0.114571347833\n",
      "Epoch: 60 -> Test Accuracy: 86.47\n",
      "[61, 60] loss: 0.101\n",
      "[61, 120] loss: 0.102\n",
      "[61, 180] loss: 0.101\n",
      "[61, 240] loss: 0.109\n",
      "[61, 300] loss: 0.101\n",
      "[61, 360] loss: 0.100\n",
      "Epoch: 61 -> Loss: 0.0882179290056\n",
      "Epoch: 61 -> Test Accuracy: 86.59\n",
      "[62, 60] loss: 0.104\n",
      "[62, 120] loss: 0.104\n",
      "[62, 180] loss: 0.100\n",
      "[62, 240] loss: 0.099\n",
      "[62, 300] loss: 0.098\n",
      "[62, 360] loss: 0.090\n",
      "Epoch: 62 -> Loss: 0.0816664248705\n",
      "Epoch: 62 -> Test Accuracy: 86.68\n",
      "[63, 60] loss: 0.107\n",
      "[63, 120] loss: 0.098\n",
      "[63, 180] loss: 0.099\n",
      "[63, 240] loss: 0.102\n",
      "[63, 300] loss: 0.100\n",
      "[63, 360] loss: 0.101\n",
      "Epoch: 63 -> Loss: 0.0926828533411\n",
      "Epoch: 63 -> Test Accuracy: 86.65\n",
      "[64, 60] loss: 0.100\n",
      "[64, 120] loss: 0.094\n",
      "[64, 180] loss: 0.097\n",
      "[64, 240] loss: 0.097\n",
      "[64, 300] loss: 0.096\n",
      "[64, 360] loss: 0.103\n",
      "Epoch: 64 -> Loss: 0.0782715827227\n",
      "Epoch: 64 -> Test Accuracy: 86.57\n",
      "[65, 60] loss: 0.092\n",
      "[65, 120] loss: 0.110\n",
      "[65, 180] loss: 0.090\n",
      "[65, 240] loss: 0.098\n",
      "[65, 300] loss: 0.099\n",
      "[65, 360] loss: 0.106\n",
      "Epoch: 65 -> Loss: 0.117500737309\n",
      "Epoch: 65 -> Test Accuracy: 86.53\n",
      "[66, 60] loss: 0.102\n",
      "[66, 120] loss: 0.090\n",
      "[66, 180] loss: 0.086\n",
      "[66, 240] loss: 0.100\n",
      "[66, 300] loss: 0.095\n",
      "[66, 360] loss: 0.096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Loss: 0.0875278636813\n",
      "Epoch: 66 -> Test Accuracy: 86.62\n",
      "[67, 60] loss: 0.090\n",
      "[67, 120] loss: 0.093\n",
      "[67, 180] loss: 0.097\n",
      "[67, 240] loss: 0.098\n",
      "[67, 300] loss: 0.095\n",
      "[67, 360] loss: 0.091\n",
      "Epoch: 67 -> Loss: 0.279062747955\n",
      "Epoch: 67 -> Test Accuracy: 86.56\n",
      "[68, 60] loss: 0.097\n",
      "[68, 120] loss: 0.097\n",
      "[68, 180] loss: 0.091\n",
      "[68, 240] loss: 0.100\n",
      "[68, 300] loss: 0.092\n",
      "[68, 360] loss: 0.095\n",
      "Epoch: 68 -> Loss: 0.0385071113706\n",
      "Epoch: 68 -> Test Accuracy: 86.58\n",
      "[69, 60] loss: 0.096\n",
      "[69, 120] loss: 0.086\n",
      "[69, 180] loss: 0.098\n",
      "[69, 240] loss: 0.095\n",
      "[69, 300] loss: 0.095\n",
      "[69, 360] loss: 0.100\n",
      "Epoch: 69 -> Loss: 0.0830150395632\n",
      "Epoch: 69 -> Test Accuracy: 86.55\n",
      "[70, 60] loss: 0.092\n",
      "[70, 120] loss: 0.095\n",
      "[70, 180] loss: 0.092\n",
      "[70, 240] loss: 0.100\n",
      "[70, 300] loss: 0.098\n",
      "[70, 360] loss: 0.091\n",
      "Epoch: 70 -> Loss: 0.147570535541\n",
      "Epoch: 70 -> Test Accuracy: 86.54\n",
      "[71, 60] loss: 0.092\n",
      "[71, 120] loss: 0.095\n",
      "[71, 180] loss: 0.094\n",
      "[71, 240] loss: 0.097\n",
      "[71, 300] loss: 0.087\n",
      "[71, 360] loss: 0.095\n",
      "Epoch: 71 -> Loss: 0.166447415948\n",
      "Epoch: 71 -> Test Accuracy: 86.56\n",
      "[72, 60] loss: 0.091\n",
      "[72, 120] loss: 0.090\n",
      "[72, 180] loss: 0.091\n",
      "[72, 240] loss: 0.097\n",
      "[72, 300] loss: 0.088\n",
      "[72, 360] loss: 0.086\n",
      "Epoch: 72 -> Loss: 0.131402149796\n",
      "Epoch: 72 -> Test Accuracy: 86.53\n",
      "[73, 60] loss: 0.094\n",
      "[73, 120] loss: 0.086\n",
      "[73, 180] loss: 0.087\n",
      "[73, 240] loss: 0.086\n",
      "[73, 300] loss: 0.099\n",
      "[73, 360] loss: 0.099\n",
      "Epoch: 73 -> Loss: 0.0341930016875\n",
      "Epoch: 73 -> Test Accuracy: 86.45\n",
      "[74, 60] loss: 0.091\n",
      "[74, 120] loss: 0.090\n",
      "[74, 180] loss: 0.092\n",
      "[74, 240] loss: 0.100\n",
      "[74, 300] loss: 0.092\n",
      "[74, 360] loss: 0.086\n",
      "Epoch: 74 -> Loss: 0.0816075205803\n",
      "Epoch: 74 -> Test Accuracy: 86.45\n",
      "[75, 60] loss: 0.090\n",
      "[75, 120] loss: 0.096\n",
      "[75, 180] loss: 0.093\n",
      "[75, 240] loss: 0.093\n",
      "[75, 300] loss: 0.091\n",
      "[75, 360] loss: 0.084\n",
      "Epoch: 75 -> Loss: 0.135517299175\n",
      "Epoch: 75 -> Test Accuracy: 86.44\n",
      "[76, 60] loss: 0.089\n",
      "[76, 120] loss: 0.090\n",
      "[76, 180] loss: 0.090\n",
      "[76, 240] loss: 0.092\n",
      "[76, 300] loss: 0.089\n",
      "[76, 360] loss: 0.091\n",
      "Epoch: 76 -> Loss: 0.124477602541\n",
      "Epoch: 76 -> Test Accuracy: 86.47\n",
      "[77, 60] loss: 0.087\n",
      "[77, 120] loss: 0.092\n",
      "[77, 180] loss: 0.089\n",
      "[77, 240] loss: 0.086\n",
      "[77, 300] loss: 0.097\n",
      "[77, 360] loss: 0.087\n",
      "Epoch: 77 -> Loss: 0.0466269478202\n",
      "Epoch: 77 -> Test Accuracy: 86.4\n",
      "[78, 60] loss: 0.094\n",
      "[78, 120] loss: 0.088\n",
      "[78, 180] loss: 0.084\n",
      "[78, 240] loss: 0.086\n",
      "[78, 300] loss: 0.099\n",
      "[78, 360] loss: 0.087\n",
      "Epoch: 78 -> Loss: 0.0827061161399\n",
      "Epoch: 78 -> Test Accuracy: 86.6\n",
      "[79, 60] loss: 0.081\n",
      "[79, 120] loss: 0.094\n",
      "[79, 180] loss: 0.083\n",
      "[79, 240] loss: 0.091\n",
      "[79, 300] loss: 0.089\n",
      "[79, 360] loss: 0.088\n",
      "Epoch: 79 -> Loss: 0.0839433148503\n",
      "Epoch: 79 -> Test Accuracy: 86.58\n",
      "[80, 60] loss: 0.086\n",
      "[80, 120] loss: 0.095\n",
      "[80, 180] loss: 0.086\n",
      "[80, 240] loss: 0.093\n",
      "[80, 300] loss: 0.088\n",
      "[80, 360] loss: 0.082\n",
      "Epoch: 80 -> Loss: 0.117639183998\n",
      "Epoch: 80 -> Test Accuracy: 86.41\n",
      "[81, 60] loss: 0.092\n",
      "[81, 120] loss: 0.090\n",
      "[81, 180] loss: 0.088\n",
      "[81, 240] loss: 0.092\n",
      "[81, 300] loss: 0.090\n",
      "[81, 360] loss: 0.090\n",
      "Epoch: 81 -> Loss: 0.0283928867429\n",
      "Epoch: 81 -> Test Accuracy: 86.4\n",
      "[82, 60] loss: 0.093\n",
      "[82, 120] loss: 0.084\n",
      "[82, 180] loss: 0.084\n",
      "[82, 240] loss: 0.084\n",
      "[82, 300] loss: 0.093\n",
      "[82, 360] loss: 0.087\n",
      "Epoch: 82 -> Loss: 0.178500145674\n",
      "Epoch: 82 -> Test Accuracy: 86.38\n",
      "[83, 60] loss: 0.079\n",
      "[83, 120] loss: 0.084\n",
      "[83, 180] loss: 0.089\n",
      "[83, 240] loss: 0.087\n",
      "[83, 300] loss: 0.083\n",
      "[83, 360] loss: 0.081\n",
      "Epoch: 83 -> Loss: 0.0440602749586\n",
      "Epoch: 83 -> Test Accuracy: 86.36\n",
      "[84, 60] loss: 0.084\n",
      "[84, 120] loss: 0.081\n",
      "[84, 180] loss: 0.082\n",
      "[84, 240] loss: 0.089\n",
      "[84, 300] loss: 0.082\n",
      "[84, 360] loss: 0.089\n",
      "Epoch: 84 -> Loss: 0.143937140703\n",
      "Epoch: 84 -> Test Accuracy: 86.44\n",
      "[85, 60] loss: 0.086\n",
      "[85, 120] loss: 0.083\n",
      "[85, 180] loss: 0.090\n",
      "[85, 240] loss: 0.093\n",
      "[85, 300] loss: 0.083\n",
      "[85, 360] loss: 0.080\n",
      "Epoch: 85 -> Loss: 0.141636013985\n",
      "Epoch: 85 -> Test Accuracy: 86.55\n",
      "[86, 60] loss: 0.085\n",
      "[86, 120] loss: 0.085\n",
      "[86, 180] loss: 0.087\n",
      "[86, 240] loss: 0.085\n",
      "[86, 300] loss: 0.081\n",
      "[86, 360] loss: 0.089\n",
      "Epoch: 86 -> Loss: 0.0997038856149\n",
      "Epoch: 86 -> Test Accuracy: 86.49\n",
      "[87, 60] loss: 0.083\n",
      "[87, 120] loss: 0.080\n",
      "[87, 180] loss: 0.083\n",
      "[87, 240] loss: 0.085\n",
      "[87, 300] loss: 0.083\n",
      "[87, 360] loss: 0.078\n",
      "Epoch: 87 -> Loss: 0.126808017492\n",
      "Epoch: 87 -> Test Accuracy: 86.44\n",
      "[88, 60] loss: 0.081\n",
      "[88, 120] loss: 0.077\n",
      "[88, 180] loss: 0.077\n",
      "[88, 240] loss: 0.081\n",
      "[88, 300] loss: 0.085\n",
      "[88, 360] loss: 0.082\n",
      "Epoch: 88 -> Loss: 0.0658229589462\n",
      "Epoch: 88 -> Test Accuracy: 86.46\n",
      "[89, 60] loss: 0.086\n",
      "[89, 120] loss: 0.090\n",
      "[89, 180] loss: 0.085\n",
      "[89, 240] loss: 0.082\n",
      "[89, 300] loss: 0.077\n",
      "[89, 360] loss: 0.086\n",
      "Epoch: 89 -> Loss: 0.0564866252244\n",
      "Epoch: 89 -> Test Accuracy: 86.42\n",
      "[90, 60] loss: 0.083\n",
      "[90, 120] loss: 0.080\n",
      "[90, 180] loss: 0.083\n",
      "[90, 240] loss: 0.085\n",
      "[90, 300] loss: 0.076\n",
      "[90, 360] loss: 0.085\n",
      "Epoch: 90 -> Loss: 0.116924032569\n",
      "Epoch: 90 -> Test Accuracy: 86.32\n",
      "[91, 60] loss: 0.076\n",
      "[91, 120] loss: 0.083\n",
      "[91, 180] loss: 0.079\n",
      "[91, 240] loss: 0.081\n",
      "[91, 300] loss: 0.079\n",
      "[91, 360] loss: 0.081\n",
      "Epoch: 91 -> Loss: 0.0986568406224\n",
      "Epoch: 91 -> Test Accuracy: 86.43\n",
      "[92, 60] loss: 0.079\n",
      "[92, 120] loss: 0.077\n",
      "[92, 180] loss: 0.078\n",
      "[92, 240] loss: 0.077\n",
      "[92, 300] loss: 0.080\n",
      "[92, 360] loss: 0.083\n",
      "Epoch: 92 -> Loss: 0.146330758929\n",
      "Epoch: 92 -> Test Accuracy: 86.48\n",
      "[93, 60] loss: 0.081\n",
      "[93, 120] loss: 0.090\n",
      "[93, 180] loss: 0.080\n",
      "[93, 240] loss: 0.083\n",
      "[93, 300] loss: 0.083\n",
      "[93, 360] loss: 0.074\n",
      "Epoch: 93 -> Loss: 0.0758383870125\n",
      "Epoch: 93 -> Test Accuracy: 86.36\n",
      "[94, 60] loss: 0.073\n",
      "[94, 120] loss: 0.086\n",
      "[94, 180] loss: 0.080\n",
      "[94, 240] loss: 0.082\n",
      "[94, 300] loss: 0.079\n",
      "[94, 360] loss: 0.080\n",
      "Epoch: 94 -> Loss: 0.0661194100976\n",
      "Epoch: 94 -> Test Accuracy: 86.51\n",
      "[95, 60] loss: 0.075\n",
      "[95, 120] loss: 0.082\n",
      "[95, 180] loss: 0.080\n",
      "[95, 240] loss: 0.076\n",
      "[95, 300] loss: 0.081\n",
      "[95, 360] loss: 0.076\n",
      "Epoch: 95 -> Loss: 0.188063040376\n",
      "Epoch: 95 -> Test Accuracy: 86.35\n",
      "[96, 60] loss: 0.076\n",
      "[96, 120] loss: 0.084\n",
      "[96, 180] loss: 0.082\n",
      "[96, 240] loss: 0.080\n",
      "[96, 300] loss: 0.077\n",
      "[96, 360] loss: 0.072\n",
      "Epoch: 96 -> Loss: 0.0441781058908\n",
      "Epoch: 96 -> Test Accuracy: 86.32\n",
      "[97, 60] loss: 0.071\n",
      "[97, 120] loss: 0.077\n",
      "[97, 180] loss: 0.076\n",
      "[97, 240] loss: 0.073\n",
      "[97, 300] loss: 0.075\n",
      "[97, 360] loss: 0.082\n",
      "Epoch: 97 -> Loss: 0.052395761013\n",
      "Epoch: 97 -> Test Accuracy: 86.45\n",
      "[98, 60] loss: 0.073\n",
      "[98, 120] loss: 0.074\n",
      "[98, 180] loss: 0.073\n",
      "[98, 240] loss: 0.072\n",
      "[98, 300] loss: 0.075\n",
      "[98, 360] loss: 0.079\n",
      "Epoch: 98 -> Loss: 0.111148074269\n",
      "Epoch: 98 -> Test Accuracy: 86.42\n",
      "[99, 60] loss: 0.074\n",
      "[99, 120] loss: 0.073\n",
      "[99, 180] loss: 0.075\n",
      "[99, 240] loss: 0.078\n",
      "[99, 300] loss: 0.073\n",
      "[99, 360] loss: 0.073\n",
      "Epoch: 99 -> Loss: 0.0655280798674\n",
      "Epoch: 99 -> Test Accuracy: 86.26\n",
      "[100, 60] loss: 0.070\n",
      "[100, 120] loss: 0.072\n",
      "[100, 180] loss: 0.077\n",
      "[100, 240] loss: 0.081\n",
      "[100, 300] loss: 0.076\n",
      "[100, 360] loss: 0.079\n",
      "Epoch: 100 -> Loss: 0.115976274014\n",
      "Epoch: 100 -> Test Accuracy: 86.44\n",
      "Finished Training\n",
      "[1, 60] loss: 2.676\n",
      "[1, 120] loss: 1.847\n",
      "[1, 180] loss: 1.769\n",
      "[1, 240] loss: 1.736\n",
      "[1, 300] loss: 1.703\n",
      "[1, 360] loss: 1.691\n",
      "Epoch: 1 -> Loss: 1.52364873886\n",
      "Epoch: 1 -> Test Accuracy: 37.53\n",
      "[2, 60] loss: 1.661\n",
      "[2, 120] loss: 1.643\n",
      "[2, 180] loss: 1.634\n",
      "[2, 240] loss: 1.620\n",
      "[2, 300] loss: 1.630\n",
      "[2, 360] loss: 1.596\n",
      "Epoch: 2 -> Loss: 1.39410424232\n",
      "Epoch: 2 -> Test Accuracy: 39.48\n",
      "[3, 60] loss: 1.602\n",
      "[3, 120] loss: 1.561\n",
      "[3, 180] loss: 1.581\n",
      "[3, 240] loss: 1.553\n",
      "[3, 300] loss: 1.564\n",
      "[3, 360] loss: 1.556\n",
      "Epoch: 3 -> Loss: 1.59475851059\n",
      "Epoch: 3 -> Test Accuracy: 41.27\n",
      "[4, 60] loss: 1.542\n",
      "[4, 120] loss: 1.537\n",
      "[4, 180] loss: 1.551\n",
      "[4, 240] loss: 1.532\n",
      "[4, 300] loss: 1.536\n",
      "[4, 360] loss: 1.531\n",
      "Epoch: 4 -> Loss: 1.56952428818\n",
      "Epoch: 4 -> Test Accuracy: 42.17\n",
      "[5, 60] loss: 1.505\n",
      "[5, 120] loss: 1.523\n",
      "[5, 180] loss: 1.512\n",
      "[5, 240] loss: 1.520\n",
      "[5, 300] loss: 1.516\n",
      "[5, 360] loss: 1.520\n",
      "Epoch: 5 -> Loss: 1.53929758072\n",
      "Epoch: 5 -> Test Accuracy: 42.9\n",
      "[6, 60] loss: 1.516\n",
      "[6, 120] loss: 1.509\n",
      "[6, 180] loss: 1.493\n",
      "[6, 240] loss: 1.486\n",
      "[6, 300] loss: 1.500\n",
      "[6, 360] loss: 1.506\n",
      "Epoch: 6 -> Loss: 1.54099071026\n",
      "Epoch: 6 -> Test Accuracy: 43.5\n",
      "[7, 60] loss: 1.478\n",
      "[7, 120] loss: 1.515\n",
      "[7, 180] loss: 1.476\n",
      "[7, 240] loss: 1.496\n",
      "[7, 300] loss: 1.495\n",
      "[7, 360] loss: 1.466\n",
      "Epoch: 7 -> Loss: 1.50421857834\n",
      "Epoch: 7 -> Test Accuracy: 43.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 60] loss: 1.487\n",
      "[8, 120] loss: 1.479\n",
      "[8, 180] loss: 1.488\n",
      "[8, 240] loss: 1.475\n",
      "[8, 300] loss: 1.487\n",
      "[8, 360] loss: 1.480\n",
      "Epoch: 8 -> Loss: 1.39841389656\n",
      "Epoch: 8 -> Test Accuracy: 44.18\n",
      "[9, 60] loss: 1.474\n",
      "[9, 120] loss: 1.471\n",
      "[9, 180] loss: 1.499\n",
      "[9, 240] loss: 1.486\n",
      "[9, 300] loss: 1.474\n",
      "[9, 360] loss: 1.473\n",
      "Epoch: 9 -> Loss: 1.40985012054\n",
      "Epoch: 9 -> Test Accuracy: 44.87\n",
      "[10, 60] loss: 1.468\n",
      "[10, 120] loss: 1.463\n",
      "[10, 180] loss: 1.460\n",
      "[10, 240] loss: 1.483\n",
      "[10, 300] loss: 1.447\n",
      "[10, 360] loss: 1.469\n",
      "Epoch: 10 -> Loss: 1.56842362881\n",
      "Epoch: 10 -> Test Accuracy: 43.93\n",
      "[11, 60] loss: 1.469\n",
      "[11, 120] loss: 1.460\n",
      "[11, 180] loss: 1.476\n",
      "[11, 240] loss: 1.464\n",
      "[11, 300] loss: 1.467\n",
      "[11, 360] loss: 1.446\n",
      "Epoch: 11 -> Loss: 1.55275261402\n",
      "Epoch: 11 -> Test Accuracy: 44.59\n",
      "[12, 60] loss: 1.471\n",
      "[12, 120] loss: 1.435\n",
      "[12, 180] loss: 1.458\n",
      "[12, 240] loss: 1.470\n",
      "[12, 300] loss: 1.470\n",
      "[12, 360] loss: 1.465\n",
      "Epoch: 12 -> Loss: 1.53223562241\n",
      "Epoch: 12 -> Test Accuracy: 44.68\n",
      "[13, 60] loss: 1.473\n",
      "[13, 120] loss: 1.474\n",
      "[13, 180] loss: 1.448\n",
      "[13, 240] loss: 1.459\n",
      "[13, 300] loss: 1.474\n",
      "[13, 360] loss: 1.465\n",
      "Epoch: 13 -> Loss: 1.45059394836\n",
      "Epoch: 13 -> Test Accuracy: 44.06\n",
      "[14, 60] loss: 1.456\n",
      "[14, 120] loss: 1.473\n",
      "[14, 180] loss: 1.456\n",
      "[14, 240] loss: 1.460\n",
      "[14, 300] loss: 1.449\n",
      "[14, 360] loss: 1.455\n",
      "Epoch: 14 -> Loss: 1.60295009613\n",
      "Epoch: 14 -> Test Accuracy: 44.67\n",
      "[15, 60] loss: 1.468\n",
      "[15, 120] loss: 1.435\n",
      "[15, 180] loss: 1.452\n",
      "[15, 240] loss: 1.460\n",
      "[15, 300] loss: 1.457\n",
      "[15, 360] loss: 1.439\n",
      "Epoch: 15 -> Loss: 1.56296885014\n",
      "Epoch: 15 -> Test Accuracy: 44.76\n",
      "[16, 60] loss: 1.438\n",
      "[16, 120] loss: 1.449\n",
      "[16, 180] loss: 1.471\n",
      "[16, 240] loss: 1.459\n",
      "[16, 300] loss: 1.451\n",
      "[16, 360] loss: 1.455\n",
      "Epoch: 16 -> Loss: 1.60495281219\n",
      "Epoch: 16 -> Test Accuracy: 45.25\n",
      "[17, 60] loss: 1.447\n",
      "[17, 120] loss: 1.431\n",
      "[17, 180] loss: 1.455\n",
      "[17, 240] loss: 1.478\n",
      "[17, 300] loss: 1.450\n",
      "[17, 360] loss: 1.450\n",
      "Epoch: 17 -> Loss: 1.3824365139\n",
      "Epoch: 17 -> Test Accuracy: 44.85\n",
      "[18, 60] loss: 1.461\n",
      "[18, 120] loss: 1.446\n",
      "[18, 180] loss: 1.471\n",
      "[18, 240] loss: 1.437\n",
      "[18, 300] loss: 1.457\n",
      "[18, 360] loss: 1.444\n",
      "Epoch: 18 -> Loss: 1.41462767124\n",
      "Epoch: 18 -> Test Accuracy: 45.03\n",
      "[19, 60] loss: 1.451\n",
      "[19, 120] loss: 1.448\n",
      "[19, 180] loss: 1.467\n",
      "[19, 240] loss: 1.423\n",
      "[19, 300] loss: 1.441\n",
      "[19, 360] loss: 1.473\n",
      "Epoch: 19 -> Loss: 1.51573812962\n",
      "Epoch: 19 -> Test Accuracy: 44.37\n",
      "[20, 60] loss: 1.436\n",
      "[20, 120] loss: 1.453\n",
      "[20, 180] loss: 1.425\n",
      "[20, 240] loss: 1.471\n",
      "[20, 300] loss: 1.459\n",
      "[20, 360] loss: 1.451\n",
      "Epoch: 20 -> Loss: 1.47630524635\n",
      "Epoch: 20 -> Test Accuracy: 43.78\n",
      "[21, 60] loss: 1.409\n",
      "[21, 120] loss: 1.367\n",
      "[21, 180] loss: 1.358\n",
      "[21, 240] loss: 1.373\n",
      "[21, 300] loss: 1.361\n",
      "[21, 360] loss: 1.336\n",
      "Epoch: 21 -> Loss: 1.30584740639\n",
      "Epoch: 21 -> Test Accuracy: 48.16\n",
      "[22, 60] loss: 1.339\n",
      "[22, 120] loss: 1.321\n",
      "[22, 180] loss: 1.328\n",
      "[22, 240] loss: 1.325\n",
      "[22, 300] loss: 1.337\n",
      "[22, 360] loss: 1.341\n",
      "Epoch: 22 -> Loss: 1.34226715565\n",
      "Epoch: 22 -> Test Accuracy: 48.58\n",
      "[23, 60] loss: 1.316\n",
      "[23, 120] loss: 1.318\n",
      "[23, 180] loss: 1.302\n",
      "[23, 240] loss: 1.338\n",
      "[23, 300] loss: 1.317\n",
      "[23, 360] loss: 1.312\n",
      "Epoch: 23 -> Loss: 1.28418838978\n",
      "Epoch: 23 -> Test Accuracy: 49.0\n",
      "[24, 60] loss: 1.332\n",
      "[24, 120] loss: 1.320\n",
      "[24, 180] loss: 1.310\n",
      "[24, 240] loss: 1.314\n",
      "[24, 300] loss: 1.297\n",
      "[24, 360] loss: 1.318\n",
      "Epoch: 24 -> Loss: 1.45560765266\n",
      "Epoch: 24 -> Test Accuracy: 49.54\n",
      "[25, 60] loss: 1.303\n",
      "[25, 120] loss: 1.291\n",
      "[25, 180] loss: 1.306\n",
      "[25, 240] loss: 1.292\n",
      "[25, 300] loss: 1.294\n",
      "[25, 360] loss: 1.292\n",
      "Epoch: 25 -> Loss: 1.37691283226\n",
      "Epoch: 25 -> Test Accuracy: 48.88\n",
      "[26, 60] loss: 1.295\n",
      "[26, 120] loss: 1.302\n",
      "[26, 180] loss: 1.293\n",
      "[26, 240] loss: 1.293\n",
      "[26, 300] loss: 1.297\n",
      "[26, 360] loss: 1.306\n",
      "Epoch: 26 -> Loss: 1.1634786129\n",
      "Epoch: 26 -> Test Accuracy: 49.75\n",
      "[27, 60] loss: 1.288\n",
      "[27, 120] loss: 1.297\n",
      "[27, 180] loss: 1.277\n",
      "[27, 240] loss: 1.305\n",
      "[27, 300] loss: 1.300\n",
      "[27, 360] loss: 1.311\n",
      "Epoch: 27 -> Loss: 1.36242198944\n",
      "Epoch: 27 -> Test Accuracy: 49.05\n",
      "[28, 60] loss: 1.299\n",
      "[28, 120] loss: 1.290\n",
      "[28, 180] loss: 1.291\n",
      "[28, 240] loss: 1.287\n",
      "[28, 300] loss: 1.298\n",
      "[28, 360] loss: 1.287\n",
      "Epoch: 28 -> Loss: 1.25336778164\n",
      "Epoch: 28 -> Test Accuracy: 49.76\n",
      "[29, 60] loss: 1.287\n",
      "[29, 120] loss: 1.303\n",
      "[29, 180] loss: 1.278\n",
      "[29, 240] loss: 1.325\n",
      "[29, 300] loss: 1.302\n",
      "[29, 360] loss: 1.293\n",
      "Epoch: 29 -> Loss: 1.3518807888\n",
      "Epoch: 29 -> Test Accuracy: 49.73\n",
      "[30, 60] loss: 1.288\n",
      "[30, 120] loss: 1.282\n",
      "[30, 180] loss: 1.307\n",
      "[30, 240] loss: 1.306\n",
      "[30, 300] loss: 1.297\n",
      "[30, 360] loss: 1.277\n",
      "Epoch: 30 -> Loss: 1.23199999332\n",
      "Epoch: 30 -> Test Accuracy: 49.13\n",
      "[31, 60] loss: 1.280\n",
      "[31, 120] loss: 1.299\n",
      "[31, 180] loss: 1.293\n",
      "[31, 240] loss: 1.300\n",
      "[31, 300] loss: 1.304\n",
      "[31, 360] loss: 1.290\n",
      "Epoch: 31 -> Loss: 1.19559311867\n",
      "Epoch: 31 -> Test Accuracy: 49.63\n",
      "[32, 60] loss: 1.295\n",
      "[32, 120] loss: 1.297\n",
      "[32, 180] loss: 1.282\n",
      "[32, 240] loss: 1.289\n",
      "[32, 300] loss: 1.289\n",
      "[32, 360] loss: 1.319\n",
      "Epoch: 32 -> Loss: 1.56193220615\n",
      "Epoch: 32 -> Test Accuracy: 50.07\n",
      "[33, 60] loss: 1.275\n",
      "[33, 120] loss: 1.282\n",
      "[33, 180] loss: 1.305\n",
      "[33, 240] loss: 1.299\n",
      "[33, 300] loss: 1.275\n",
      "[33, 360] loss: 1.291\n",
      "Epoch: 33 -> Loss: 1.4914098978\n",
      "Epoch: 33 -> Test Accuracy: 49.37\n",
      "[34, 60] loss: 1.268\n",
      "[34, 120] loss: 1.290\n",
      "[34, 180] loss: 1.299\n",
      "[34, 240] loss: 1.311\n",
      "[34, 300] loss: 1.265\n",
      "[34, 360] loss: 1.300\n",
      "Epoch: 34 -> Loss: 1.40532243252\n",
      "Epoch: 34 -> Test Accuracy: 49.98\n",
      "[35, 60] loss: 1.263\n",
      "[35, 120] loss: 1.294\n",
      "[35, 180] loss: 1.260\n",
      "[35, 240] loss: 1.316\n",
      "[35, 300] loss: 1.308\n",
      "[35, 360] loss: 1.291\n",
      "Epoch: 35 -> Loss: 1.11464571953\n",
      "Epoch: 35 -> Test Accuracy: 49.84\n",
      "[36, 60] loss: 1.269\n",
      "[36, 120] loss: 1.282\n",
      "[36, 180] loss: 1.288\n",
      "[36, 240] loss: 1.291\n",
      "[36, 300] loss: 1.298\n",
      "[36, 360] loss: 1.298\n",
      "Epoch: 36 -> Loss: 1.22665953636\n",
      "Epoch: 36 -> Test Accuracy: 49.74\n",
      "[37, 60] loss: 1.271\n",
      "[37, 120] loss: 1.287\n",
      "[37, 180] loss: 1.279\n",
      "[37, 240] loss: 1.285\n",
      "[37, 300] loss: 1.300\n",
      "[37, 360] loss: 1.277\n",
      "Epoch: 37 -> Loss: 1.38238608837\n",
      "Epoch: 37 -> Test Accuracy: 49.46\n",
      "[38, 60] loss: 1.303\n",
      "[38, 120] loss: 1.269\n",
      "[38, 180] loss: 1.273\n",
      "[38, 240] loss: 1.280\n",
      "[38, 300] loss: 1.281\n",
      "[38, 360] loss: 1.278\n",
      "Epoch: 38 -> Loss: 1.46829009056\n",
      "Epoch: 38 -> Test Accuracy: 49.7\n",
      "[39, 60] loss: 1.274\n",
      "[39, 120] loss: 1.282\n",
      "[39, 180] loss: 1.293\n",
      "[39, 240] loss: 1.286\n",
      "[39, 300] loss: 1.285\n",
      "[39, 360] loss: 1.298\n",
      "Epoch: 39 -> Loss: 1.38687849045\n",
      "Epoch: 39 -> Test Accuracy: 49.82\n",
      "[40, 60] loss: 1.278\n",
      "[40, 120] loss: 1.277\n",
      "[40, 180] loss: 1.278\n",
      "[40, 240] loss: 1.277\n",
      "[40, 300] loss: 1.289\n",
      "[40, 360] loss: 1.299\n",
      "Epoch: 40 -> Loss: 1.26408076286\n",
      "Epoch: 40 -> Test Accuracy: 50.36\n",
      "[41, 60] loss: 1.251\n",
      "[41, 120] loss: 1.233\n",
      "[41, 180] loss: 1.229\n",
      "[41, 240] loss: 1.229\n",
      "[41, 300] loss: 1.231\n",
      "[41, 360] loss: 1.208\n",
      "Epoch: 41 -> Loss: 1.44304168224\n",
      "Epoch: 41 -> Test Accuracy: 52.01\n",
      "[42, 60] loss: 1.227\n",
      "[42, 120] loss: 1.216\n",
      "[42, 180] loss: 1.214\n",
      "[42, 240] loss: 1.206\n",
      "[42, 300] loss: 1.206\n",
      "[42, 360] loss: 1.209\n",
      "Epoch: 42 -> Loss: 1.24358153343\n",
      "Epoch: 42 -> Test Accuracy: 52.34\n",
      "[43, 60] loss: 1.217\n",
      "[43, 120] loss: 1.204\n",
      "[43, 180] loss: 1.198\n",
      "[43, 240] loss: 1.198\n",
      "[43, 300] loss: 1.186\n",
      "[43, 360] loss: 1.187\n",
      "Epoch: 43 -> Loss: 1.12743115425\n",
      "Epoch: 43 -> Test Accuracy: 52.41\n",
      "[44, 60] loss: 1.206\n",
      "[44, 120] loss: 1.194\n",
      "[44, 180] loss: 1.199\n",
      "[44, 240] loss: 1.178\n",
      "[44, 300] loss: 1.208\n",
      "[44, 360] loss: 1.206\n",
      "Epoch: 44 -> Loss: 1.01291584969\n",
      "Epoch: 44 -> Test Accuracy: 52.66\n",
      "[45, 60] loss: 1.189\n",
      "[45, 120] loss: 1.195\n",
      "[45, 180] loss: 1.203\n",
      "[45, 240] loss: 1.222\n",
      "[45, 300] loss: 1.178\n",
      "[45, 360] loss: 1.192\n",
      "Epoch: 45 -> Loss: 1.1227915287\n",
      "Epoch: 45 -> Test Accuracy: 52.35\n",
      "[46, 60] loss: 1.177\n",
      "[46, 120] loss: 1.186\n",
      "[46, 180] loss: 1.180\n",
      "[46, 240] loss: 1.171\n",
      "[46, 300] loss: 1.173\n",
      "[46, 360] loss: 1.187\n",
      "Epoch: 46 -> Loss: 1.30463385582\n",
      "Epoch: 46 -> Test Accuracy: 53.23\n",
      "[47, 60] loss: 1.179\n",
      "[47, 120] loss: 1.185\n",
      "[47, 180] loss: 1.178\n",
      "[47, 240] loss: 1.166\n",
      "[47, 300] loss: 1.182\n",
      "[47, 360] loss: 1.161\n",
      "Epoch: 47 -> Loss: 1.29994130135\n",
      "Epoch: 47 -> Test Accuracy: 53.2\n",
      "[48, 60] loss: 1.170\n",
      "[48, 120] loss: 1.176\n",
      "[48, 180] loss: 1.169\n",
      "[48, 240] loss: 1.180\n",
      "[48, 300] loss: 1.165\n",
      "[48, 360] loss: 1.155\n",
      "Epoch: 48 -> Loss: 1.22175383568\n",
      "Epoch: 48 -> Test Accuracy: 53.45\n",
      "[49, 60] loss: 1.170\n",
      "[49, 120] loss: 1.165\n",
      "[49, 180] loss: 1.170\n",
      "[49, 240] loss: 1.177\n",
      "[49, 300] loss: 1.165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 360] loss: 1.176\n",
      "Epoch: 49 -> Loss: 1.12264847755\n",
      "Epoch: 49 -> Test Accuracy: 53.43\n",
      "[50, 60] loss: 1.160\n",
      "[50, 120] loss: 1.153\n",
      "[50, 180] loss: 1.169\n",
      "[50, 240] loss: 1.190\n",
      "[50, 300] loss: 1.155\n",
      "[50, 360] loss: 1.153\n",
      "Epoch: 50 -> Loss: 1.2540705204\n",
      "Epoch: 50 -> Test Accuracy: 53.44\n",
      "[51, 60] loss: 1.178\n",
      "[51, 120] loss: 1.159\n",
      "[51, 180] loss: 1.162\n",
      "[51, 240] loss: 1.160\n",
      "[51, 300] loss: 1.167\n",
      "[51, 360] loss: 1.167\n",
      "Epoch: 51 -> Loss: 1.0436899662\n",
      "Epoch: 51 -> Test Accuracy: 54.03\n",
      "[52, 60] loss: 1.161\n",
      "[52, 120] loss: 1.167\n",
      "[52, 180] loss: 1.169\n",
      "[52, 240] loss: 1.169\n",
      "[52, 300] loss: 1.182\n",
      "[52, 360] loss: 1.158\n",
      "Epoch: 52 -> Loss: 1.2312848568\n",
      "Epoch: 52 -> Test Accuracy: 53.62\n",
      "[53, 60] loss: 1.157\n",
      "[53, 120] loss: 1.176\n",
      "[53, 180] loss: 1.160\n",
      "[53, 240] loss: 1.145\n",
      "[53, 300] loss: 1.174\n",
      "[53, 360] loss: 1.146\n",
      "Epoch: 53 -> Loss: 0.86311852932\n",
      "Epoch: 53 -> Test Accuracy: 53.58\n",
      "[54, 60] loss: 1.151\n",
      "[54, 120] loss: 1.180\n",
      "[54, 180] loss: 1.166\n",
      "[54, 240] loss: 1.151\n",
      "[54, 300] loss: 1.160\n",
      "[54, 360] loss: 1.180\n",
      "Epoch: 54 -> Loss: 1.30519127846\n",
      "Epoch: 54 -> Test Accuracy: 53.26\n",
      "[55, 60] loss: 1.166\n",
      "[55, 120] loss: 1.171\n",
      "[55, 180] loss: 1.161\n",
      "[55, 240] loss: 1.151\n",
      "[55, 300] loss: 1.153\n",
      "[55, 360] loss: 1.162\n",
      "Epoch: 55 -> Loss: 1.16083908081\n",
      "Epoch: 55 -> Test Accuracy: 53.59\n",
      "[56, 60] loss: 1.149\n",
      "[56, 120] loss: 1.154\n",
      "[56, 180] loss: 1.164\n",
      "[56, 240] loss: 1.150\n",
      "[56, 300] loss: 1.154\n",
      "[56, 360] loss: 1.146\n",
      "Epoch: 56 -> Loss: 0.965551376343\n",
      "Epoch: 56 -> Test Accuracy: 53.4\n",
      "[57, 60] loss: 1.174\n",
      "[57, 120] loss: 1.161\n",
      "[57, 180] loss: 1.151\n",
      "[57, 240] loss: 1.146\n",
      "[57, 300] loss: 1.153\n",
      "[57, 360] loss: 1.141\n",
      "Epoch: 57 -> Loss: 0.99353569746\n",
      "Epoch: 57 -> Test Accuracy: 53.71\n",
      "[58, 60] loss: 1.143\n",
      "[58, 120] loss: 1.153\n",
      "[58, 180] loss: 1.165\n",
      "[58, 240] loss: 1.156\n",
      "[58, 300] loss: 1.165\n",
      "[58, 360] loss: 1.146\n",
      "Epoch: 58 -> Loss: 1.19122099876\n",
      "Epoch: 58 -> Test Accuracy: 53.8\n",
      "[59, 60] loss: 1.146\n",
      "[59, 120] loss: 1.149\n",
      "[59, 180] loss: 1.149\n",
      "[59, 240] loss: 1.157\n",
      "[59, 300] loss: 1.156\n",
      "[59, 360] loss: 1.177\n",
      "Epoch: 59 -> Loss: 1.34651267529\n",
      "Epoch: 59 -> Test Accuracy: 53.65\n",
      "[60, 60] loss: 1.157\n",
      "[60, 120] loss: 1.148\n",
      "[60, 180] loss: 1.165\n",
      "[60, 240] loss: 1.148\n",
      "[60, 300] loss: 1.152\n",
      "[60, 360] loss: 1.147\n",
      "Epoch: 60 -> Loss: 1.29902338982\n",
      "Epoch: 60 -> Test Accuracy: 53.96\n",
      "[61, 60] loss: 1.168\n",
      "[61, 120] loss: 1.143\n",
      "[61, 180] loss: 1.165\n",
      "[61, 240] loss: 1.160\n",
      "[61, 300] loss: 1.157\n",
      "[61, 360] loss: 1.141\n",
      "Epoch: 61 -> Loss: 0.988267600536\n",
      "Epoch: 61 -> Test Accuracy: 53.5\n",
      "[62, 60] loss: 1.143\n",
      "[62, 120] loss: 1.135\n",
      "[62, 180] loss: 1.170\n",
      "[62, 240] loss: 1.171\n",
      "[62, 300] loss: 1.140\n",
      "[62, 360] loss: 1.147\n",
      "Epoch: 62 -> Loss: 1.20420229435\n",
      "Epoch: 62 -> Test Accuracy: 53.7\n",
      "[63, 60] loss: 1.144\n",
      "[63, 120] loss: 1.159\n",
      "[63, 180] loss: 1.139\n",
      "[63, 240] loss: 1.148\n",
      "[63, 300] loss: 1.177\n",
      "[63, 360] loss: 1.137\n",
      "Epoch: 63 -> Loss: 1.22136712074\n",
      "Epoch: 63 -> Test Accuracy: 53.91\n",
      "[64, 60] loss: 1.168\n",
      "[64, 120] loss: 1.159\n",
      "[64, 180] loss: 1.129\n",
      "[64, 240] loss: 1.147\n",
      "[64, 300] loss: 1.139\n",
      "[64, 360] loss: 1.145\n",
      "Epoch: 64 -> Loss: 0.9995418787\n",
      "Epoch: 64 -> Test Accuracy: 53.91\n",
      "[65, 60] loss: 1.141\n",
      "[65, 120] loss: 1.153\n",
      "[65, 180] loss: 1.143\n",
      "[65, 240] loss: 1.143\n",
      "[65, 300] loss: 1.142\n",
      "[65, 360] loss: 1.162\n",
      "Epoch: 65 -> Loss: 1.08076930046\n",
      "Epoch: 65 -> Test Accuracy: 53.83\n",
      "[66, 60] loss: 1.152\n",
      "[66, 120] loss: 1.158\n",
      "[66, 180] loss: 1.136\n",
      "[66, 240] loss: 1.166\n",
      "[66, 300] loss: 1.139\n",
      "[66, 360] loss: 1.136\n",
      "Epoch: 66 -> Loss: 1.03643941879\n",
      "Epoch: 66 -> Test Accuracy: 54.08\n",
      "[67, 60] loss: 1.147\n",
      "[67, 120] loss: 1.146\n",
      "[67, 180] loss: 1.146\n",
      "[67, 240] loss: 1.146\n",
      "[67, 300] loss: 1.175\n",
      "[67, 360] loss: 1.161\n",
      "Epoch: 67 -> Loss: 1.27927052975\n",
      "Epoch: 67 -> Test Accuracy: 53.85\n",
      "[68, 60] loss: 1.147\n",
      "[68, 120] loss: 1.157\n",
      "[68, 180] loss: 1.143\n",
      "[68, 240] loss: 1.148\n",
      "[68, 300] loss: 1.144\n",
      "[68, 360] loss: 1.142\n",
      "Epoch: 68 -> Loss: 1.25751423836\n",
      "Epoch: 68 -> Test Accuracy: 54.13\n",
      "[69, 60] loss: 1.139\n",
      "[69, 120] loss: 1.168\n",
      "[69, 180] loss: 1.138\n",
      "[69, 240] loss: 1.135\n",
      "[69, 300] loss: 1.144\n",
      "[69, 360] loss: 1.156\n",
      "Epoch: 69 -> Loss: 1.22045636177\n",
      "Epoch: 69 -> Test Accuracy: 53.83\n",
      "[70, 60] loss: 1.147\n",
      "[70, 120] loss: 1.151\n",
      "[70, 180] loss: 1.150\n",
      "[70, 240] loss: 1.146\n",
      "[70, 300] loss: 1.122\n",
      "[70, 360] loss: 1.148\n",
      "Epoch: 70 -> Loss: 0.950262904167\n",
      "Epoch: 70 -> Test Accuracy: 53.65\n",
      "[71, 60] loss: 1.157\n",
      "[71, 120] loss: 1.127\n",
      "[71, 180] loss: 1.151\n",
      "[71, 240] loss: 1.178\n",
      "[71, 300] loss: 1.143\n",
      "[71, 360] loss: 1.138\n",
      "Epoch: 71 -> Loss: 1.02964651585\n",
      "Epoch: 71 -> Test Accuracy: 53.83\n",
      "[72, 60] loss: 1.148\n",
      "[72, 120] loss: 1.133\n",
      "[72, 180] loss: 1.111\n",
      "[72, 240] loss: 1.155\n",
      "[72, 300] loss: 1.140\n",
      "[72, 360] loss: 1.150\n",
      "Epoch: 72 -> Loss: 1.14374279976\n",
      "Epoch: 72 -> Test Accuracy: 53.86\n",
      "[73, 60] loss: 1.153\n",
      "[73, 120] loss: 1.143\n",
      "[73, 180] loss: 1.142\n",
      "[73, 240] loss: 1.153\n",
      "[73, 300] loss: 1.147\n",
      "[73, 360] loss: 1.131\n",
      "Epoch: 73 -> Loss: 1.16744399071\n",
      "Epoch: 73 -> Test Accuracy: 54.07\n",
      "[74, 60] loss: 1.158\n",
      "[74, 120] loss: 1.133\n",
      "[74, 180] loss: 1.138\n",
      "[74, 240] loss: 1.133\n",
      "[74, 300] loss: 1.146\n",
      "[74, 360] loss: 1.149\n",
      "Epoch: 74 -> Loss: 1.03210711479\n",
      "Epoch: 74 -> Test Accuracy: 54.0\n",
      "[75, 60] loss: 1.164\n",
      "[75, 120] loss: 1.152\n",
      "[75, 180] loss: 1.138\n",
      "[75, 240] loss: 1.140\n",
      "[75, 300] loss: 1.150\n",
      "[75, 360] loss: 1.133\n",
      "Epoch: 75 -> Loss: 1.02564013004\n",
      "Epoch: 75 -> Test Accuracy: 54.04\n",
      "[76, 60] loss: 1.143\n",
      "[76, 120] loss: 1.143\n",
      "[76, 180] loss: 1.151\n",
      "[76, 240] loss: 1.154\n",
      "[76, 300] loss: 1.141\n",
      "[76, 360] loss: 1.124\n",
      "Epoch: 76 -> Loss: 1.23263084888\n",
      "Epoch: 76 -> Test Accuracy: 53.89\n",
      "[77, 60] loss: 1.150\n",
      "[77, 120] loss: 1.124\n",
      "[77, 180] loss: 1.140\n",
      "[77, 240] loss: 1.142\n",
      "[77, 300] loss: 1.158\n",
      "[77, 360] loss: 1.141\n",
      "Epoch: 77 -> Loss: 1.18999922276\n",
      "Epoch: 77 -> Test Accuracy: 53.84\n",
      "[78, 60] loss: 1.155\n",
      "[78, 120] loss: 1.133\n",
      "[78, 180] loss: 1.122\n",
      "[78, 240] loss: 1.139\n",
      "[78, 300] loss: 1.140\n",
      "[78, 360] loss: 1.128\n",
      "Epoch: 78 -> Loss: 1.32205367088\n",
      "Epoch: 78 -> Test Accuracy: 54.32\n",
      "[79, 60] loss: 1.131\n",
      "[79, 120] loss: 1.133\n",
      "[79, 180] loss: 1.135\n",
      "[79, 240] loss: 1.133\n",
      "[79, 300] loss: 1.143\n",
      "[79, 360] loss: 1.133\n",
      "Epoch: 79 -> Loss: 1.37259197235\n",
      "Epoch: 79 -> Test Accuracy: 54.06\n",
      "[80, 60] loss: 1.140\n",
      "[80, 120] loss: 1.138\n",
      "[80, 180] loss: 1.134\n",
      "[80, 240] loss: 1.142\n",
      "[80, 300] loss: 1.138\n",
      "[80, 360] loss: 1.143\n",
      "Epoch: 80 -> Loss: 1.33836054802\n",
      "Epoch: 80 -> Test Accuracy: 54.11\n",
      "[81, 60] loss: 1.124\n",
      "[81, 120] loss: 1.129\n",
      "[81, 180] loss: 1.115\n",
      "[81, 240] loss: 1.129\n",
      "[81, 300] loss: 1.133\n",
      "[81, 360] loss: 1.139\n",
      "Epoch: 81 -> Loss: 1.20920598507\n",
      "Epoch: 81 -> Test Accuracy: 54.22\n",
      "[82, 60] loss: 1.137\n",
      "[82, 120] loss: 1.121\n",
      "[82, 180] loss: 1.137\n",
      "[82, 240] loss: 1.123\n",
      "[82, 300] loss: 1.130\n",
      "[82, 360] loss: 1.138\n",
      "Epoch: 82 -> Loss: 1.04067492485\n",
      "Epoch: 82 -> Test Accuracy: 54.1\n",
      "[83, 60] loss: 1.148\n",
      "[83, 120] loss: 1.122\n",
      "[83, 180] loss: 1.136\n",
      "[83, 240] loss: 1.121\n",
      "[83, 300] loss: 1.143\n",
      "[83, 360] loss: 1.120\n",
      "Epoch: 83 -> Loss: 0.943351387978\n",
      "Epoch: 83 -> Test Accuracy: 53.93\n",
      "[84, 60] loss: 1.137\n",
      "[84, 120] loss: 1.151\n",
      "[84, 180] loss: 1.133\n",
      "[84, 240] loss: 1.129\n",
      "[84, 300] loss: 1.113\n",
      "[84, 360] loss: 1.156\n",
      "Epoch: 84 -> Loss: 1.18425834179\n",
      "Epoch: 84 -> Test Accuracy: 54.27\n",
      "[85, 60] loss: 1.129\n",
      "[85, 120] loss: 1.138\n",
      "[85, 180] loss: 1.128\n",
      "[85, 240] loss: 1.122\n",
      "[85, 300] loss: 1.136\n",
      "[85, 360] loss: 1.120\n",
      "Epoch: 85 -> Loss: 1.11996746063\n",
      "Epoch: 85 -> Test Accuracy: 54.32\n",
      "[86, 60] loss: 1.113\n",
      "[86, 120] loss: 1.146\n",
      "[86, 180] loss: 1.143\n",
      "[86, 240] loss: 1.121\n",
      "[86, 300] loss: 1.129\n",
      "[86, 360] loss: 1.126\n",
      "Epoch: 86 -> Loss: 1.20799696445\n",
      "Epoch: 86 -> Test Accuracy: 54.29\n",
      "[87, 60] loss: 1.121\n",
      "[87, 120] loss: 1.155\n",
      "[87, 180] loss: 1.140\n",
      "[87, 240] loss: 1.110\n",
      "[87, 300] loss: 1.139\n",
      "[87, 360] loss: 1.111\n",
      "Epoch: 87 -> Loss: 1.35962677002\n",
      "Epoch: 87 -> Test Accuracy: 53.95\n",
      "[88, 60] loss: 1.128\n",
      "[88, 120] loss: 1.134\n",
      "[88, 180] loss: 1.123\n",
      "[88, 240] loss: 1.125\n",
      "[88, 300] loss: 1.125\n",
      "[88, 360] loss: 1.157\n",
      "Epoch: 88 -> Loss: 1.12541782856\n",
      "Epoch: 88 -> Test Accuracy: 54.1\n",
      "[89, 60] loss: 1.123\n",
      "[89, 120] loss: 1.137\n",
      "[89, 180] loss: 1.129\n",
      "[89, 240] loss: 1.122\n",
      "[89, 300] loss: 1.126\n",
      "[89, 360] loss: 1.142\n",
      "Epoch: 89 -> Loss: 1.39412915707\n",
      "Epoch: 89 -> Test Accuracy: 54.15\n",
      "[90, 60] loss: 1.132\n",
      "[90, 120] loss: 1.128\n",
      "[90, 180] loss: 1.126\n",
      "[90, 240] loss: 1.121\n",
      "[90, 300] loss: 1.118\n",
      "[90, 360] loss: 1.138\n",
      "Epoch: 90 -> Loss: 1.15801095963\n",
      "Epoch: 90 -> Test Accuracy: 54.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[91, 60] loss: 1.156\n",
      "[91, 120] loss: 1.133\n",
      "[91, 180] loss: 1.121\n",
      "[91, 240] loss: 1.136\n",
      "[91, 300] loss: 1.130\n",
      "[91, 360] loss: 1.132\n",
      "Epoch: 91 -> Loss: 1.09939694405\n",
      "Epoch: 91 -> Test Accuracy: 54.37\n",
      "[92, 60] loss: 1.145\n",
      "[92, 120] loss: 1.118\n",
      "[92, 180] loss: 1.112\n",
      "[92, 240] loss: 1.145\n",
      "[92, 300] loss: 1.108\n",
      "[92, 360] loss: 1.145\n",
      "Epoch: 92 -> Loss: 1.24633836746\n",
      "Epoch: 92 -> Test Accuracy: 54.29\n",
      "[93, 60] loss: 1.136\n",
      "[93, 120] loss: 1.124\n",
      "[93, 180] loss: 1.138\n",
      "[93, 240] loss: 1.124\n",
      "[93, 300] loss: 1.132\n",
      "[93, 360] loss: 1.119\n",
      "Epoch: 93 -> Loss: 1.10955047607\n",
      "Epoch: 93 -> Test Accuracy: 54.27\n",
      "[94, 60] loss: 1.124\n",
      "[94, 120] loss: 1.106\n",
      "[94, 180] loss: 1.142\n",
      "[94, 240] loss: 1.140\n",
      "[94, 300] loss: 1.127\n",
      "[94, 360] loss: 1.129\n",
      "Epoch: 94 -> Loss: 1.20155501366\n",
      "Epoch: 94 -> Test Accuracy: 54.45\n",
      "[95, 60] loss: 1.118\n",
      "[95, 120] loss: 1.138\n",
      "[95, 180] loss: 1.129\n",
      "[95, 240] loss: 1.133\n",
      "[95, 300] loss: 1.136\n",
      "[95, 360] loss: 1.130\n",
      "Epoch: 95 -> Loss: 0.918730735779\n",
      "Epoch: 95 -> Test Accuracy: 54.25\n",
      "[96, 60] loss: 1.128\n",
      "[96, 120] loss: 1.116\n",
      "[96, 180] loss: 1.140\n",
      "[96, 240] loss: 1.123\n",
      "[96, 300] loss: 1.131\n",
      "[96, 360] loss: 1.123\n",
      "Epoch: 96 -> Loss: 1.27564752102\n",
      "Epoch: 96 -> Test Accuracy: 54.17\n",
      "[97, 60] loss: 1.124\n",
      "[97, 120] loss: 1.123\n",
      "[97, 180] loss: 1.106\n",
      "[97, 240] loss: 1.115\n",
      "[97, 300] loss: 1.139\n",
      "[97, 360] loss: 1.128\n",
      "Epoch: 97 -> Loss: 1.06130695343\n",
      "Epoch: 97 -> Test Accuracy: 54.37\n",
      "[98, 60] loss: 1.107\n",
      "[98, 120] loss: 1.128\n",
      "[98, 180] loss: 1.112\n",
      "[98, 240] loss: 1.138\n",
      "[98, 300] loss: 1.127\n",
      "[98, 360] loss: 1.142\n",
      "Epoch: 98 -> Loss: 1.23829877377\n",
      "Epoch: 98 -> Test Accuracy: 54.01\n",
      "[99, 60] loss: 1.135\n",
      "[99, 120] loss: 1.138\n",
      "[99, 180] loss: 1.130\n",
      "[99, 240] loss: 1.126\n",
      "[99, 300] loss: 1.100\n",
      "[99, 360] loss: 1.136\n",
      "Epoch: 99 -> Loss: 1.20202481747\n",
      "Epoch: 99 -> Test Accuracy: 54.47\n",
      "[100, 60] loss: 1.106\n",
      "[100, 120] loss: 1.110\n",
      "[100, 180] loss: 1.129\n",
      "[100, 240] loss: 1.139\n",
      "[100, 300] loss: 1.121\n",
      "[100, 360] loss: 1.133\n",
      "Epoch: 100 -> Loss: 1.06607985497\n",
      "Epoch: 100 -> Test Accuracy: 54.4\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train NonLinearClassifiers on feature map of net_3block\n",
    "block3_loss_log, block3_valid_accuracy_log, block3_test_accuracy_log, block3_max_accuracy, block3_best_epoch = \\\n",
    "tr.train_all_blocks(3, 10, [0.1, 0.02, 0.004, 0.0008], [20, 40, 45, 100], 0.9, 5e-4, net_block3, criterion, trainloader,\n",
    "                    None, testloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.374\n",
      "[1, 120] loss: 1.050\n",
      "[1, 180] loss: 0.957\n",
      "[1, 240] loss: 0.862\n",
      "[1, 300] loss: 0.838\n",
      "[1, 360] loss: 0.808\n",
      "Epoch: 1 -> Loss: 0.63659965992\n",
      "Epoch: 1 -> Test Accuracy: 70.46\n",
      "[2, 60] loss: 0.771\n",
      "[2, 120] loss: 0.728\n",
      "[2, 180] loss: 0.704\n",
      "[2, 240] loss: 0.710\n",
      "[2, 300] loss: 0.678\n",
      "[2, 360] loss: 0.675\n",
      "Epoch: 2 -> Loss: 0.590440273285\n",
      "Epoch: 2 -> Test Accuracy: 74.6\n",
      "[3, 60] loss: 0.625\n",
      "[3, 120] loss: 0.622\n",
      "[3, 180] loss: 0.636\n",
      "[3, 240] loss: 0.620\n",
      "[3, 300] loss: 0.621\n",
      "[3, 360] loss: 0.609\n",
      "Epoch: 3 -> Loss: 0.644072651863\n",
      "Epoch: 3 -> Test Accuracy: 76.04\n",
      "[4, 60] loss: 0.586\n",
      "[4, 120] loss: 0.572\n",
      "[4, 180] loss: 0.580\n",
      "[4, 240] loss: 0.575\n",
      "[4, 300] loss: 0.572\n",
      "[4, 360] loss: 0.593\n",
      "Epoch: 4 -> Loss: 0.765754640102\n",
      "Epoch: 4 -> Test Accuracy: 76.93\n",
      "[5, 60] loss: 0.547\n",
      "[5, 120] loss: 0.544\n",
      "[5, 180] loss: 0.551\n",
      "[5, 240] loss: 0.558\n",
      "[5, 300] loss: 0.539\n",
      "[5, 360] loss: 0.541\n",
      "Epoch: 5 -> Loss: 0.542672753334\n",
      "Epoch: 5 -> Test Accuracy: 76.63\n",
      "[6, 60] loss: 0.510\n",
      "[6, 120] loss: 0.507\n",
      "[6, 180] loss: 0.534\n",
      "[6, 240] loss: 0.532\n",
      "[6, 300] loss: 0.532\n",
      "[6, 360] loss: 0.529\n",
      "Epoch: 6 -> Loss: 0.503697037697\n",
      "Epoch: 6 -> Test Accuracy: 78.91\n",
      "[7, 60] loss: 0.486\n",
      "[7, 120] loss: 0.507\n",
      "[7, 180] loss: 0.493\n",
      "[7, 240] loss: 0.523\n",
      "[7, 300] loss: 0.510\n",
      "[7, 360] loss: 0.502\n",
      "Epoch: 7 -> Loss: 0.546703517437\n",
      "Epoch: 7 -> Test Accuracy: 78.89\n",
      "[8, 60] loss: 0.453\n",
      "[8, 120] loss: 0.496\n",
      "[8, 180] loss: 0.494\n",
      "[8, 240] loss: 0.487\n",
      "[8, 300] loss: 0.492\n",
      "[8, 360] loss: 0.503\n",
      "Epoch: 8 -> Loss: 0.43971657753\n",
      "Epoch: 8 -> Test Accuracy: 78.28\n",
      "[9, 60] loss: 0.455\n",
      "[9, 120] loss: 0.490\n",
      "[9, 180] loss: 0.499\n",
      "[9, 240] loss: 0.476\n",
      "[9, 300] loss: 0.482\n",
      "[9, 360] loss: 0.471\n",
      "Epoch: 9 -> Loss: 0.414271056652\n",
      "Epoch: 9 -> Test Accuracy: 78.48\n",
      "[10, 60] loss: 0.467\n",
      "[10, 120] loss: 0.465\n",
      "[10, 180] loss: 0.485\n",
      "[10, 240] loss: 0.470\n",
      "[10, 300] loss: 0.473\n",
      "[10, 360] loss: 0.480\n",
      "Epoch: 10 -> Loss: 0.446189492941\n",
      "Epoch: 10 -> Test Accuracy: 78.7\n",
      "[11, 60] loss: 0.453\n",
      "[11, 120] loss: 0.447\n",
      "[11, 180] loss: 0.459\n",
      "[11, 240] loss: 0.479\n",
      "[11, 300] loss: 0.465\n",
      "[11, 360] loss: 0.484\n",
      "Epoch: 11 -> Loss: 0.414189338684\n",
      "Epoch: 11 -> Test Accuracy: 80.15\n",
      "[12, 60] loss: 0.432\n",
      "[12, 120] loss: 0.477\n",
      "[12, 180] loss: 0.453\n",
      "[12, 240] loss: 0.474\n",
      "[12, 300] loss: 0.476\n",
      "[12, 360] loss: 0.464\n",
      "Epoch: 12 -> Loss: 0.361120402813\n",
      "Epoch: 12 -> Test Accuracy: 80.28\n",
      "[13, 60] loss: 0.431\n",
      "[13, 120] loss: 0.447\n",
      "[13, 180] loss: 0.460\n",
      "[13, 240] loss: 0.472\n",
      "[13, 300] loss: 0.447\n",
      "[13, 360] loss: 0.470\n",
      "Epoch: 13 -> Loss: 0.378367811441\n",
      "Epoch: 13 -> Test Accuracy: 80.21\n",
      "[14, 60] loss: 0.447\n",
      "[14, 120] loss: 0.451\n",
      "[14, 180] loss: 0.443\n",
      "[14, 240] loss: 0.449\n",
      "[14, 300] loss: 0.465\n",
      "[14, 360] loss: 0.437\n",
      "Epoch: 14 -> Loss: 0.513517558575\n",
      "Epoch: 14 -> Test Accuracy: 80.91\n",
      "[15, 60] loss: 0.421\n",
      "[15, 120] loss: 0.423\n",
      "[15, 180] loss: 0.444\n",
      "[15, 240] loss: 0.459\n",
      "[15, 300] loss: 0.466\n",
      "[15, 360] loss: 0.440\n",
      "Epoch: 15 -> Loss: 0.491457045078\n",
      "Epoch: 15 -> Test Accuracy: 81.72\n",
      "[16, 60] loss: 0.420\n",
      "[16, 120] loss: 0.435\n",
      "[16, 180] loss: 0.431\n",
      "[16, 240] loss: 0.440\n",
      "[16, 300] loss: 0.468\n",
      "[16, 360] loss: 0.443\n",
      "Epoch: 16 -> Loss: 0.504543602467\n",
      "Epoch: 16 -> Test Accuracy: 80.76\n",
      "[17, 60] loss: 0.411\n",
      "[17, 120] loss: 0.426\n",
      "[17, 180] loss: 0.429\n",
      "[17, 240] loss: 0.446\n",
      "[17, 300] loss: 0.445\n",
      "[17, 360] loss: 0.449\n",
      "Epoch: 17 -> Loss: 0.349052190781\n",
      "Epoch: 17 -> Test Accuracy: 80.85\n",
      "[18, 60] loss: 0.406\n",
      "[18, 120] loss: 0.445\n",
      "[18, 180] loss: 0.446\n",
      "[18, 240] loss: 0.424\n",
      "[18, 300] loss: 0.438\n",
      "[18, 360] loss: 0.434\n",
      "Epoch: 18 -> Loss: 0.462182849646\n",
      "Epoch: 18 -> Test Accuracy: 80.33\n",
      "[19, 60] loss: 0.399\n",
      "[19, 120] loss: 0.412\n",
      "[19, 180] loss: 0.434\n",
      "[19, 240] loss: 0.421\n",
      "[19, 300] loss: 0.431\n",
      "[19, 360] loss: 0.444\n",
      "Epoch: 19 -> Loss: 0.518607616425\n",
      "Epoch: 19 -> Test Accuracy: 80.74\n",
      "[20, 60] loss: 0.405\n",
      "[20, 120] loss: 0.417\n",
      "[20, 180] loss: 0.425\n",
      "[20, 240] loss: 0.442\n",
      "[20, 300] loss: 0.430\n",
      "[20, 360] loss: 0.423\n",
      "Epoch: 20 -> Loss: 0.42939466238\n",
      "Epoch: 20 -> Test Accuracy: 80.73\n",
      "[21, 60] loss: 0.407\n",
      "[21, 120] loss: 0.420\n",
      "[21, 180] loss: 0.419\n",
      "[21, 240] loss: 0.419\n",
      "[21, 300] loss: 0.428\n",
      "[21, 360] loss: 0.452\n",
      "Epoch: 21 -> Loss: 0.456162452698\n",
      "Epoch: 21 -> Test Accuracy: 81.55\n",
      "[22, 60] loss: 0.416\n",
      "[22, 120] loss: 0.408\n",
      "[22, 180] loss: 0.436\n",
      "[22, 240] loss: 0.436\n",
      "[22, 300] loss: 0.427\n",
      "[22, 360] loss: 0.421\n",
      "Epoch: 22 -> Loss: 0.453614890575\n",
      "Epoch: 22 -> Test Accuracy: 81.25\n",
      "[23, 60] loss: 0.395\n",
      "[23, 120] loss: 0.423\n",
      "[23, 180] loss: 0.420\n",
      "[23, 240] loss: 0.420\n",
      "[23, 300] loss: 0.426\n",
      "[23, 360] loss: 0.426\n",
      "Epoch: 23 -> Loss: 0.323362737894\n",
      "Epoch: 23 -> Test Accuracy: 80.9\n",
      "[24, 60] loss: 0.387\n",
      "[24, 120] loss: 0.396\n",
      "[24, 180] loss: 0.405\n",
      "[24, 240] loss: 0.442\n",
      "[24, 300] loss: 0.421\n",
      "[24, 360] loss: 0.418\n",
      "Epoch: 24 -> Loss: 0.426096916199\n",
      "Epoch: 24 -> Test Accuracy: 81.28\n",
      "[25, 60] loss: 0.400\n",
      "[25, 120] loss: 0.399\n",
      "[25, 180] loss: 0.433\n",
      "[25, 240] loss: 0.429\n",
      "[25, 300] loss: 0.416\n",
      "[25, 360] loss: 0.422\n",
      "Epoch: 25 -> Loss: 0.435714572668\n",
      "Epoch: 25 -> Test Accuracy: 81.82\n",
      "[26, 60] loss: 0.417\n",
      "[26, 120] loss: 0.409\n",
      "[26, 180] loss: 0.410\n",
      "[26, 240] loss: 0.396\n",
      "[26, 300] loss: 0.434\n",
      "[26, 360] loss: 0.429\n",
      "Epoch: 26 -> Loss: 0.438722848892\n",
      "Epoch: 26 -> Test Accuracy: 80.59\n",
      "[27, 60] loss: 0.401\n",
      "[27, 120] loss: 0.405\n",
      "[27, 180] loss: 0.395\n",
      "[27, 240] loss: 0.420\n",
      "[27, 300] loss: 0.422\n",
      "[27, 360] loss: 0.418\n",
      "Epoch: 27 -> Loss: 0.510386288166\n",
      "Epoch: 27 -> Test Accuracy: 81.3\n",
      "[28, 60] loss: 0.389\n",
      "[28, 120] loss: 0.403\n",
      "[28, 180] loss: 0.397\n",
      "[28, 240] loss: 0.424\n",
      "[28, 300] loss: 0.424\n",
      "[28, 360] loss: 0.416\n",
      "Epoch: 28 -> Loss: 0.591870963573\n",
      "Epoch: 28 -> Test Accuracy: 81.63\n",
      "[29, 60] loss: 0.393\n",
      "[29, 120] loss: 0.407\n",
      "[29, 180] loss: 0.408\n",
      "[29, 240] loss: 0.416\n",
      "[29, 300] loss: 0.437\n",
      "[29, 360] loss: 0.422\n",
      "Epoch: 29 -> Loss: 0.470284938812\n",
      "Epoch: 29 -> Test Accuracy: 81.05\n",
      "[30, 60] loss: 0.392\n",
      "[30, 120] loss: 0.420\n",
      "[30, 180] loss: 0.413\n",
      "[30, 240] loss: 0.403\n",
      "[30, 300] loss: 0.422\n",
      "[30, 360] loss: 0.417\n",
      "Epoch: 30 -> Loss: 0.338780462742\n",
      "Epoch: 30 -> Test Accuracy: 81.88\n",
      "[31, 60] loss: 0.394\n",
      "[31, 120] loss: 0.397\n",
      "[31, 180] loss: 0.409\n",
      "[31, 240] loss: 0.409\n",
      "[31, 300] loss: 0.412\n",
      "[31, 360] loss: 0.438\n",
      "Epoch: 31 -> Loss: 0.55278891325\n",
      "Epoch: 31 -> Test Accuracy: 80.29\n",
      "[32, 60] loss: 0.407\n",
      "[32, 120] loss: 0.392\n",
      "[32, 180] loss: 0.416\n",
      "[32, 240] loss: 0.412\n",
      "[32, 300] loss: 0.417\n",
      "[32, 360] loss: 0.414\n",
      "Epoch: 32 -> Loss: 0.559100329876\n",
      "Epoch: 32 -> Test Accuracy: 81.75\n",
      "[33, 60] loss: 0.396\n",
      "[33, 120] loss: 0.411\n",
      "[33, 180] loss: 0.397\n",
      "[33, 240] loss: 0.403\n",
      "[33, 300] loss: 0.409\n",
      "[33, 360] loss: 0.411\n",
      "Epoch: 33 -> Loss: 0.489230215549\n",
      "Epoch: 33 -> Test Accuracy: 82.38\n",
      "[34, 60] loss: 0.387\n",
      "[34, 120] loss: 0.397\n",
      "[34, 180] loss: 0.410\n",
      "[34, 240] loss: 0.409\n",
      "[34, 300] loss: 0.419\n",
      "[34, 360] loss: 0.425\n",
      "Epoch: 34 -> Loss: 0.317865610123\n",
      "Epoch: 34 -> Test Accuracy: 80.74\n",
      "[35, 60] loss: 0.379\n",
      "[35, 120] loss: 0.383\n",
      "[35, 180] loss: 0.413\n",
      "[35, 240] loss: 0.404\n",
      "[35, 300] loss: 0.405\n",
      "[35, 360] loss: 0.430\n",
      "Epoch: 35 -> Loss: 0.422428756952\n",
      "Epoch: 35 -> Test Accuracy: 80.59\n",
      "[36, 60] loss: 0.343\n",
      "[36, 120] loss: 0.294\n",
      "[36, 180] loss: 0.289\n",
      "[36, 240] loss: 0.288\n",
      "[36, 300] loss: 0.270\n",
      "[36, 360] loss: 0.270\n",
      "Epoch: 36 -> Loss: 0.268454790115\n",
      "Epoch: 36 -> Test Accuracy: 85.73\n",
      "[37, 60] loss: 0.260\n",
      "[37, 120] loss: 0.257\n",
      "[37, 180] loss: 0.253\n",
      "[37, 240] loss: 0.253\n",
      "[37, 300] loss: 0.245\n",
      "[37, 360] loss: 0.258\n",
      "Epoch: 37 -> Loss: 0.169141709805\n",
      "Epoch: 37 -> Test Accuracy: 85.79\n",
      "[38, 60] loss: 0.227\n",
      "[38, 120] loss: 0.251\n",
      "[38, 180] loss: 0.233\n",
      "[38, 240] loss: 0.248\n",
      "[38, 300] loss: 0.247\n",
      "[38, 360] loss: 0.245\n",
      "Epoch: 38 -> Loss: 0.305655777454\n",
      "Epoch: 38 -> Test Accuracy: 85.54\n",
      "[39, 60] loss: 0.223\n",
      "[39, 120] loss: 0.230\n",
      "[39, 180] loss: 0.231\n",
      "[39, 240] loss: 0.234\n",
      "[39, 300] loss: 0.238\n",
      "[39, 360] loss: 0.242\n",
      "Epoch: 39 -> Loss: 0.215076804161\n",
      "Epoch: 39 -> Test Accuracy: 85.35\n",
      "[40, 60] loss: 0.217\n",
      "[40, 120] loss: 0.244\n",
      "[40, 180] loss: 0.227\n",
      "[40, 240] loss: 0.227\n",
      "[40, 300] loss: 0.226\n",
      "[40, 360] loss: 0.232\n",
      "Epoch: 40 -> Loss: 0.176822140813\n",
      "Epoch: 40 -> Test Accuracy: 85.42\n",
      "[41, 60] loss: 0.210\n",
      "[41, 120] loss: 0.204\n",
      "[41, 180] loss: 0.223\n",
      "[41, 240] loss: 0.238\n",
      "[41, 300] loss: 0.227\n",
      "[41, 360] loss: 0.233\n",
      "Epoch: 41 -> Loss: 0.246323943138\n",
      "Epoch: 41 -> Test Accuracy: 85.62\n",
      "[42, 60] loss: 0.207\n",
      "[42, 120] loss: 0.213\n",
      "[42, 180] loss: 0.215\n",
      "[42, 240] loss: 0.223\n",
      "[42, 300] loss: 0.227\n",
      "[42, 360] loss: 0.241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.209055811167\n",
      "Epoch: 42 -> Test Accuracy: 85.82\n",
      "[43, 60] loss: 0.221\n",
      "[43, 120] loss: 0.206\n",
      "[43, 180] loss: 0.227\n",
      "[43, 240] loss: 0.218\n",
      "[43, 300] loss: 0.225\n",
      "[43, 360] loss: 0.240\n",
      "Epoch: 43 -> Loss: 0.235760971904\n",
      "Epoch: 43 -> Test Accuracy: 85.02\n",
      "[44, 60] loss: 0.216\n",
      "[44, 120] loss: 0.205\n",
      "[44, 180] loss: 0.222\n",
      "[44, 240] loss: 0.215\n",
      "[44, 300] loss: 0.214\n",
      "[44, 360] loss: 0.228\n",
      "Epoch: 44 -> Loss: 0.25627759099\n",
      "Epoch: 44 -> Test Accuracy: 85.23\n",
      "[45, 60] loss: 0.201\n",
      "[45, 120] loss: 0.211\n",
      "[45, 180] loss: 0.209\n",
      "[45, 240] loss: 0.227\n",
      "[45, 300] loss: 0.234\n",
      "[45, 360] loss: 0.233\n",
      "Epoch: 45 -> Loss: 0.1993355304\n",
      "Epoch: 45 -> Test Accuracy: 84.66\n",
      "[46, 60] loss: 0.196\n",
      "[46, 120] loss: 0.209\n",
      "[46, 180] loss: 0.209\n",
      "[46, 240] loss: 0.227\n",
      "[46, 300] loss: 0.226\n",
      "[46, 360] loss: 0.226\n",
      "Epoch: 46 -> Loss: 0.3314473629\n",
      "Epoch: 46 -> Test Accuracy: 84.89\n",
      "[47, 60] loss: 0.212\n",
      "[47, 120] loss: 0.218\n",
      "[47, 180] loss: 0.208\n",
      "[47, 240] loss: 0.222\n",
      "[47, 300] loss: 0.216\n",
      "[47, 360] loss: 0.227\n",
      "Epoch: 47 -> Loss: 0.331350177526\n",
      "Epoch: 47 -> Test Accuracy: 84.43\n",
      "[48, 60] loss: 0.204\n",
      "[48, 120] loss: 0.214\n",
      "[48, 180] loss: 0.225\n",
      "[48, 240] loss: 0.221\n",
      "[48, 300] loss: 0.216\n",
      "[48, 360] loss: 0.230\n",
      "Epoch: 48 -> Loss: 0.342667013407\n",
      "Epoch: 48 -> Test Accuracy: 84.76\n",
      "[49, 60] loss: 0.211\n",
      "[49, 120] loss: 0.212\n",
      "[49, 180] loss: 0.212\n",
      "[49, 240] loss: 0.231\n",
      "[49, 300] loss: 0.224\n",
      "[49, 360] loss: 0.227\n",
      "Epoch: 49 -> Loss: 0.280825674534\n",
      "Epoch: 49 -> Test Accuracy: 84.83\n",
      "[50, 60] loss: 0.212\n",
      "[50, 120] loss: 0.202\n",
      "[50, 180] loss: 0.214\n",
      "[50, 240] loss: 0.222\n",
      "[50, 300] loss: 0.223\n",
      "[50, 360] loss: 0.216\n",
      "Epoch: 50 -> Loss: 0.248834446073\n",
      "Epoch: 50 -> Test Accuracy: 84.58\n",
      "[51, 60] loss: 0.200\n",
      "[51, 120] loss: 0.214\n",
      "[51, 180] loss: 0.208\n",
      "[51, 240] loss: 0.215\n",
      "[51, 300] loss: 0.231\n",
      "[51, 360] loss: 0.228\n",
      "Epoch: 51 -> Loss: 0.4022539258\n",
      "Epoch: 51 -> Test Accuracy: 84.97\n",
      "[52, 60] loss: 0.199\n",
      "[52, 120] loss: 0.201\n",
      "[52, 180] loss: 0.211\n",
      "[52, 240] loss: 0.211\n",
      "[52, 300] loss: 0.231\n",
      "[52, 360] loss: 0.234\n",
      "Epoch: 52 -> Loss: 0.286320537329\n",
      "Epoch: 52 -> Test Accuracy: 84.27\n",
      "[53, 60] loss: 0.219\n",
      "[53, 120] loss: 0.211\n",
      "[53, 180] loss: 0.233\n",
      "[53, 240] loss: 0.214\n",
      "[53, 300] loss: 0.239\n",
      "[53, 360] loss: 0.226\n",
      "Epoch: 53 -> Loss: 0.137172818184\n",
      "Epoch: 53 -> Test Accuracy: 85.33\n",
      "[54, 60] loss: 0.201\n",
      "[54, 120] loss: 0.196\n",
      "[54, 180] loss: 0.215\n",
      "[54, 240] loss: 0.229\n",
      "[54, 300] loss: 0.215\n",
      "[54, 360] loss: 0.223\n",
      "Epoch: 54 -> Loss: 0.311880260706\n",
      "Epoch: 54 -> Test Accuracy: 83.85\n",
      "[55, 60] loss: 0.199\n",
      "[55, 120] loss: 0.200\n",
      "[55, 180] loss: 0.215\n",
      "[55, 240] loss: 0.218\n",
      "[55, 300] loss: 0.231\n",
      "[55, 360] loss: 0.221\n",
      "Epoch: 55 -> Loss: 0.289727568626\n",
      "Epoch: 55 -> Test Accuracy: 84.21\n",
      "[56, 60] loss: 0.201\n",
      "[56, 120] loss: 0.199\n",
      "[56, 180] loss: 0.214\n",
      "[56, 240] loss: 0.214\n",
      "[56, 300] loss: 0.237\n",
      "[56, 360] loss: 0.230\n",
      "Epoch: 56 -> Loss: 0.225950285792\n",
      "Epoch: 56 -> Test Accuracy: 84.46\n",
      "[57, 60] loss: 0.202\n",
      "[57, 120] loss: 0.213\n",
      "[57, 180] loss: 0.204\n",
      "[57, 240] loss: 0.222\n",
      "[57, 300] loss: 0.220\n",
      "[57, 360] loss: 0.226\n",
      "Epoch: 57 -> Loss: 0.186190158129\n",
      "Epoch: 57 -> Test Accuracy: 84.25\n",
      "[58, 60] loss: 0.205\n",
      "[58, 120] loss: 0.206\n",
      "[58, 180] loss: 0.212\n",
      "[58, 240] loss: 0.224\n",
      "[58, 300] loss: 0.221\n",
      "[58, 360] loss: 0.234\n",
      "Epoch: 58 -> Loss: 0.206921011209\n",
      "Epoch: 58 -> Test Accuracy: 84.94\n",
      "[59, 60] loss: 0.200\n",
      "[59, 120] loss: 0.203\n",
      "[59, 180] loss: 0.208\n",
      "[59, 240] loss: 0.219\n",
      "[59, 300] loss: 0.216\n",
      "[59, 360] loss: 0.229\n",
      "Epoch: 59 -> Loss: 0.303188979626\n",
      "Epoch: 59 -> Test Accuracy: 84.57\n",
      "[60, 60] loss: 0.204\n",
      "[60, 120] loss: 0.207\n",
      "[60, 180] loss: 0.209\n",
      "[60, 240] loss: 0.217\n",
      "[60, 300] loss: 0.218\n",
      "[60, 360] loss: 0.222\n",
      "Epoch: 60 -> Loss: 0.392939418554\n",
      "Epoch: 60 -> Test Accuracy: 84.38\n",
      "[61, 60] loss: 0.205\n",
      "[61, 120] loss: 0.212\n",
      "[61, 180] loss: 0.200\n",
      "[61, 240] loss: 0.223\n",
      "[61, 300] loss: 0.225\n",
      "[61, 360] loss: 0.222\n",
      "Epoch: 61 -> Loss: 0.237357616425\n",
      "Epoch: 61 -> Test Accuracy: 84.59\n",
      "[62, 60] loss: 0.207\n",
      "[62, 120] loss: 0.207\n",
      "[62, 180] loss: 0.220\n",
      "[62, 240] loss: 0.197\n",
      "[62, 300] loss: 0.220\n",
      "[62, 360] loss: 0.223\n",
      "Epoch: 62 -> Loss: 0.11495475471\n",
      "Epoch: 62 -> Test Accuracy: 84.58\n",
      "[63, 60] loss: 0.186\n",
      "[63, 120] loss: 0.203\n",
      "[63, 180] loss: 0.210\n",
      "[63, 240] loss: 0.211\n",
      "[63, 300] loss: 0.223\n",
      "[63, 360] loss: 0.240\n",
      "Epoch: 63 -> Loss: 0.23812623322\n",
      "Epoch: 63 -> Test Accuracy: 84.83\n",
      "[64, 60] loss: 0.201\n",
      "[64, 120] loss: 0.205\n",
      "[64, 180] loss: 0.212\n",
      "[64, 240] loss: 0.228\n",
      "[64, 300] loss: 0.220\n",
      "[64, 360] loss: 0.226\n",
      "Epoch: 64 -> Loss: 0.285827368498\n",
      "Epoch: 64 -> Test Accuracy: 84.49\n",
      "[65, 60] loss: 0.204\n",
      "[65, 120] loss: 0.204\n",
      "[65, 180] loss: 0.221\n",
      "[65, 240] loss: 0.210\n",
      "[65, 300] loss: 0.216\n",
      "[65, 360] loss: 0.223\n",
      "Epoch: 65 -> Loss: 0.279049962759\n",
      "Epoch: 65 -> Test Accuracy: 83.72\n",
      "[66, 60] loss: 0.201\n",
      "[66, 120] loss: 0.195\n",
      "[66, 180] loss: 0.208\n",
      "[66, 240] loss: 0.222\n",
      "[66, 300] loss: 0.220\n",
      "[66, 360] loss: 0.222\n",
      "Epoch: 66 -> Loss: 0.191832870245\n",
      "Epoch: 66 -> Test Accuracy: 84.86\n",
      "[67, 60] loss: 0.198\n",
      "[67, 120] loss: 0.200\n",
      "[67, 180] loss: 0.197\n",
      "[67, 240] loss: 0.217\n",
      "[67, 300] loss: 0.223\n",
      "[67, 360] loss: 0.211\n",
      "Epoch: 67 -> Loss: 0.264807701111\n",
      "Epoch: 67 -> Test Accuracy: 84.05\n",
      "[68, 60] loss: 0.195\n",
      "[68, 120] loss: 0.200\n",
      "[68, 180] loss: 0.209\n",
      "[68, 240] loss: 0.207\n",
      "[68, 300] loss: 0.222\n",
      "[68, 360] loss: 0.219\n",
      "Epoch: 68 -> Loss: 0.163993149996\n",
      "Epoch: 68 -> Test Accuracy: 84.64\n",
      "[69, 60] loss: 0.192\n",
      "[69, 120] loss: 0.194\n",
      "[69, 180] loss: 0.195\n",
      "[69, 240] loss: 0.218\n",
      "[69, 300] loss: 0.210\n",
      "[69, 360] loss: 0.229\n",
      "Epoch: 69 -> Loss: 0.318559467793\n",
      "Epoch: 69 -> Test Accuracy: 84.3\n",
      "[70, 60] loss: 0.203\n",
      "[70, 120] loss: 0.202\n",
      "[70, 180] loss: 0.203\n",
      "[70, 240] loss: 0.206\n",
      "[70, 300] loss: 0.222\n",
      "[70, 360] loss: 0.217\n",
      "Epoch: 70 -> Loss: 0.189769595861\n",
      "Epoch: 70 -> Test Accuracy: 84.55\n",
      "[71, 60] loss: 0.177\n",
      "[71, 120] loss: 0.145\n",
      "[71, 180] loss: 0.142\n",
      "[71, 240] loss: 0.141\n",
      "[71, 300] loss: 0.140\n",
      "[71, 360] loss: 0.136\n",
      "Epoch: 71 -> Loss: 0.122569844127\n",
      "Epoch: 71 -> Test Accuracy: 86.71\n",
      "[72, 60] loss: 0.133\n",
      "[72, 120] loss: 0.122\n",
      "[72, 180] loss: 0.133\n",
      "[72, 240] loss: 0.132\n",
      "[72, 300] loss: 0.133\n",
      "[72, 360] loss: 0.125\n",
      "Epoch: 72 -> Loss: 0.108536973596\n",
      "Epoch: 72 -> Test Accuracy: 86.67\n",
      "[73, 60] loss: 0.120\n",
      "[73, 120] loss: 0.119\n",
      "[73, 180] loss: 0.131\n",
      "[73, 240] loss: 0.116\n",
      "[73, 300] loss: 0.118\n",
      "[73, 360] loss: 0.122\n",
      "Epoch: 73 -> Loss: 0.18188598752\n",
      "Epoch: 73 -> Test Accuracy: 86.44\n",
      "[74, 60] loss: 0.116\n",
      "[74, 120] loss: 0.122\n",
      "[74, 180] loss: 0.118\n",
      "[74, 240] loss: 0.115\n",
      "[74, 300] loss: 0.118\n",
      "[74, 360] loss: 0.115\n",
      "Epoch: 74 -> Loss: 0.137860566378\n",
      "Epoch: 74 -> Test Accuracy: 86.64\n",
      "[75, 60] loss: 0.110\n",
      "[75, 120] loss: 0.114\n",
      "[75, 180] loss: 0.110\n",
      "[75, 240] loss: 0.113\n",
      "[75, 300] loss: 0.116\n",
      "[75, 360] loss: 0.115\n",
      "Epoch: 75 -> Loss: 0.105905927718\n",
      "Epoch: 75 -> Test Accuracy: 86.72\n",
      "[76, 60] loss: 0.100\n",
      "[76, 120] loss: 0.117\n",
      "[76, 180] loss: 0.108\n",
      "[76, 240] loss: 0.113\n",
      "[76, 300] loss: 0.112\n",
      "[76, 360] loss: 0.112\n",
      "Epoch: 76 -> Loss: 0.0607820823789\n",
      "Epoch: 76 -> Test Accuracy: 86.37\n",
      "[77, 60] loss: 0.110\n",
      "[77, 120] loss: 0.104\n",
      "[77, 180] loss: 0.103\n",
      "[77, 240] loss: 0.110\n",
      "[77, 300] loss: 0.110\n",
      "[77, 360] loss: 0.104\n",
      "Epoch: 77 -> Loss: 0.132395222783\n",
      "Epoch: 77 -> Test Accuracy: 86.27\n",
      "[78, 60] loss: 0.103\n",
      "[78, 120] loss: 0.101\n",
      "[78, 180] loss: 0.103\n",
      "[78, 240] loss: 0.110\n",
      "[78, 300] loss: 0.107\n",
      "[78, 360] loss: 0.110\n",
      "Epoch: 78 -> Loss: 0.117419458926\n",
      "Epoch: 78 -> Test Accuracy: 86.28\n",
      "[79, 60] loss: 0.104\n",
      "[79, 120] loss: 0.102\n",
      "[79, 180] loss: 0.103\n",
      "[79, 240] loss: 0.104\n",
      "[79, 300] loss: 0.102\n",
      "[79, 360] loss: 0.105\n",
      "Epoch: 79 -> Loss: 0.15276107192\n",
      "Epoch: 79 -> Test Accuracy: 86.2\n",
      "[80, 60] loss: 0.100\n",
      "[80, 120] loss: 0.094\n",
      "[80, 180] loss: 0.103\n",
      "[80, 240] loss: 0.112\n",
      "[80, 300] loss: 0.102\n",
      "[80, 360] loss: 0.105\n",
      "Epoch: 80 -> Loss: 0.119407735765\n",
      "Epoch: 80 -> Test Accuracy: 86.44\n",
      "[81, 60] loss: 0.096\n",
      "[81, 120] loss: 0.103\n",
      "[81, 180] loss: 0.099\n",
      "[81, 240] loss: 0.101\n",
      "[81, 300] loss: 0.103\n",
      "[81, 360] loss: 0.103\n",
      "Epoch: 81 -> Loss: 0.0858628004789\n",
      "Epoch: 81 -> Test Accuracy: 86.05\n",
      "[82, 60] loss: 0.097\n",
      "[82, 120] loss: 0.096\n",
      "[82, 180] loss: 0.103\n",
      "[82, 240] loss: 0.097\n",
      "[82, 300] loss: 0.100\n",
      "[82, 360] loss: 0.100\n",
      "Epoch: 82 -> Loss: 0.0708743929863\n",
      "Epoch: 82 -> Test Accuracy: 86.25\n",
      "[83, 60] loss: 0.093\n",
      "[83, 120] loss: 0.096\n",
      "[83, 180] loss: 0.100\n",
      "[83, 240] loss: 0.099\n",
      "[83, 300] loss: 0.099\n",
      "[83, 360] loss: 0.100\n",
      "Epoch: 83 -> Loss: 0.124390289187\n",
      "Epoch: 83 -> Test Accuracy: 85.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.093\n",
      "[84, 120] loss: 0.091\n",
      "[84, 180] loss: 0.099\n",
      "[84, 240] loss: 0.095\n",
      "[84, 300] loss: 0.097\n",
      "[84, 360] loss: 0.098\n",
      "Epoch: 84 -> Loss: 0.0945960283279\n",
      "Epoch: 84 -> Test Accuracy: 86.35\n",
      "[85, 60] loss: 0.090\n",
      "[85, 120] loss: 0.096\n",
      "[85, 180] loss: 0.095\n",
      "[85, 240] loss: 0.094\n",
      "[85, 300] loss: 0.097\n",
      "[85, 360] loss: 0.099\n",
      "Epoch: 85 -> Loss: 0.103628352284\n",
      "Epoch: 85 -> Test Accuracy: 86.37\n",
      "[86, 60] loss: 0.089\n",
      "[86, 120] loss: 0.084\n",
      "[86, 180] loss: 0.087\n",
      "[86, 240] loss: 0.084\n",
      "[86, 300] loss: 0.085\n",
      "[86, 360] loss: 0.079\n",
      "Epoch: 86 -> Loss: 0.0823184922338\n",
      "Epoch: 86 -> Test Accuracy: 86.45\n",
      "[87, 60] loss: 0.081\n",
      "[87, 120] loss: 0.081\n",
      "[87, 180] loss: 0.083\n",
      "[87, 240] loss: 0.082\n",
      "[87, 300] loss: 0.082\n",
      "[87, 360] loss: 0.085\n",
      "Epoch: 87 -> Loss: 0.0493204221129\n",
      "Epoch: 87 -> Test Accuracy: 86.58\n",
      "[88, 60] loss: 0.076\n",
      "[88, 120] loss: 0.083\n",
      "[88, 180] loss: 0.082\n",
      "[88, 240] loss: 0.082\n",
      "[88, 300] loss: 0.083\n",
      "[88, 360] loss: 0.081\n",
      "Epoch: 88 -> Loss: 0.0890489220619\n",
      "Epoch: 88 -> Test Accuracy: 86.28\n",
      "[89, 60] loss: 0.078\n",
      "[89, 120] loss: 0.076\n",
      "[89, 180] loss: 0.083\n",
      "[89, 240] loss: 0.083\n",
      "[89, 300] loss: 0.083\n",
      "[89, 360] loss: 0.083\n",
      "Epoch: 89 -> Loss: 0.0973655432463\n",
      "Epoch: 89 -> Test Accuracy: 86.44\n",
      "[90, 60] loss: 0.078\n",
      "[90, 120] loss: 0.076\n",
      "[90, 180] loss: 0.082\n",
      "[90, 240] loss: 0.080\n",
      "[90, 300] loss: 0.083\n",
      "[90, 360] loss: 0.081\n",
      "Epoch: 90 -> Loss: 0.0615415386856\n",
      "Epoch: 90 -> Test Accuracy: 86.51\n",
      "[91, 60] loss: 0.076\n",
      "[91, 120] loss: 0.078\n",
      "[91, 180] loss: 0.081\n",
      "[91, 240] loss: 0.082\n",
      "[91, 300] loss: 0.077\n",
      "[91, 360] loss: 0.079\n",
      "Epoch: 91 -> Loss: 0.0855847001076\n",
      "Epoch: 91 -> Test Accuracy: 86.58\n",
      "[92, 60] loss: 0.080\n",
      "[92, 120] loss: 0.082\n",
      "[92, 180] loss: 0.075\n",
      "[92, 240] loss: 0.079\n",
      "[92, 300] loss: 0.079\n",
      "[92, 360] loss: 0.085\n",
      "Epoch: 92 -> Loss: 0.115367136896\n",
      "Epoch: 92 -> Test Accuracy: 86.47\n",
      "[93, 60] loss: 0.075\n",
      "[93, 120] loss: 0.073\n",
      "[93, 180] loss: 0.081\n",
      "[93, 240] loss: 0.078\n",
      "[93, 300] loss: 0.082\n",
      "[93, 360] loss: 0.085\n",
      "Epoch: 93 -> Loss: 0.0794607773423\n",
      "Epoch: 93 -> Test Accuracy: 86.66\n",
      "[94, 60] loss: 0.078\n",
      "[94, 120] loss: 0.086\n",
      "[94, 180] loss: 0.080\n",
      "[94, 240] loss: 0.080\n",
      "[94, 300] loss: 0.078\n",
      "[94, 360] loss: 0.072\n",
      "Epoch: 94 -> Loss: 0.0955606848001\n",
      "Epoch: 94 -> Test Accuracy: 86.48\n",
      "[95, 60] loss: 0.073\n",
      "[95, 120] loss: 0.080\n",
      "[95, 180] loss: 0.082\n",
      "[95, 240] loss: 0.075\n",
      "[95, 300] loss: 0.077\n",
      "[95, 360] loss: 0.074\n",
      "Epoch: 95 -> Loss: 0.124243021011\n",
      "Epoch: 95 -> Test Accuracy: 86.49\n",
      "[96, 60] loss: 0.075\n",
      "[96, 120] loss: 0.079\n",
      "[96, 180] loss: 0.077\n",
      "[96, 240] loss: 0.079\n",
      "[96, 300] loss: 0.080\n",
      "[96, 360] loss: 0.078\n",
      "Epoch: 96 -> Loss: 0.0881551131606\n",
      "Epoch: 96 -> Test Accuracy: 86.53\n",
      "[97, 60] loss: 0.079\n",
      "[97, 120] loss: 0.072\n",
      "[97, 180] loss: 0.083\n",
      "[97, 240] loss: 0.079\n",
      "[97, 300] loss: 0.080\n",
      "[97, 360] loss: 0.078\n",
      "Epoch: 97 -> Loss: 0.0843740329146\n",
      "Epoch: 97 -> Test Accuracy: 86.38\n",
      "[98, 60] loss: 0.075\n",
      "[98, 120] loss: 0.077\n",
      "[98, 180] loss: 0.079\n",
      "[98, 240] loss: 0.077\n",
      "[98, 300] loss: 0.080\n",
      "[98, 360] loss: 0.081\n",
      "Epoch: 98 -> Loss: 0.0883877053857\n",
      "Epoch: 98 -> Test Accuracy: 86.37\n",
      "[99, 60] loss: 0.078\n",
      "[99, 120] loss: 0.074\n",
      "[99, 180] loss: 0.072\n",
      "[99, 240] loss: 0.076\n",
      "[99, 300] loss: 0.077\n",
      "[99, 360] loss: 0.075\n",
      "Epoch: 99 -> Loss: 0.0689230263233\n",
      "Epoch: 99 -> Test Accuracy: 86.24\n",
      "[100, 60] loss: 0.077\n",
      "[100, 120] loss: 0.078\n",
      "[100, 180] loss: 0.077\n",
      "[100, 240] loss: 0.081\n",
      "[100, 300] loss: 0.074\n",
      "[100, 360] loss: 0.074\n",
      "Epoch: 100 -> Loss: 0.0696019679308\n",
      "Epoch: 100 -> Test Accuracy: 86.51\n",
      "Finished Training\n",
      "[1, 60] loss: 0.901\n",
      "[1, 120] loss: 0.623\n",
      "[1, 180] loss: 0.570\n",
      "[1, 240] loss: 0.538\n",
      "[1, 300] loss: 0.513\n",
      "[1, 360] loss: 0.502\n",
      "Epoch: 1 -> Loss: 0.565721869469\n",
      "Epoch: 1 -> Test Accuracy: 80.51\n",
      "[2, 60] loss: 0.445\n",
      "[2, 120] loss: 0.466\n",
      "[2, 180] loss: 0.449\n",
      "[2, 240] loss: 0.432\n",
      "[2, 300] loss: 0.447\n",
      "[2, 360] loss: 0.424\n",
      "Epoch: 2 -> Loss: 0.455359876156\n",
      "Epoch: 2 -> Test Accuracy: 82.34\n",
      "[3, 60] loss: 0.402\n",
      "[3, 120] loss: 0.401\n",
      "[3, 180] loss: 0.397\n",
      "[3, 240] loss: 0.395\n",
      "[3, 300] loss: 0.414\n",
      "[3, 360] loss: 0.385\n",
      "Epoch: 3 -> Loss: 0.308501303196\n",
      "Epoch: 3 -> Test Accuracy: 83.23\n",
      "[4, 60] loss: 0.380\n",
      "[4, 120] loss: 0.372\n",
      "[4, 180] loss: 0.384\n",
      "[4, 240] loss: 0.369\n",
      "[4, 300] loss: 0.374\n",
      "[4, 360] loss: 0.388\n",
      "Epoch: 4 -> Loss: 0.36497426033\n",
      "Epoch: 4 -> Test Accuracy: 83.84\n",
      "[5, 60] loss: 0.346\n",
      "[5, 120] loss: 0.349\n",
      "[5, 180] loss: 0.365\n",
      "[5, 240] loss: 0.359\n",
      "[5, 300] loss: 0.353\n",
      "[5, 360] loss: 0.352\n",
      "Epoch: 5 -> Loss: 0.513005852699\n",
      "Epoch: 5 -> Test Accuracy: 84.04\n",
      "[6, 60] loss: 0.334\n",
      "[6, 120] loss: 0.332\n",
      "[6, 180] loss: 0.348\n",
      "[6, 240] loss: 0.332\n",
      "[6, 300] loss: 0.341\n",
      "[6, 360] loss: 0.357\n",
      "Epoch: 6 -> Loss: 0.385494410992\n",
      "Epoch: 6 -> Test Accuracy: 84.99\n",
      "[7, 60] loss: 0.316\n",
      "[7, 120] loss: 0.322\n",
      "[7, 180] loss: 0.332\n",
      "[7, 240] loss: 0.331\n",
      "[7, 300] loss: 0.345\n",
      "[7, 360] loss: 0.338\n",
      "Epoch: 7 -> Loss: 0.341755777597\n",
      "Epoch: 7 -> Test Accuracy: 84.83\n",
      "[8, 60] loss: 0.316\n",
      "[8, 120] loss: 0.310\n",
      "[8, 180] loss: 0.307\n",
      "[8, 240] loss: 0.330\n",
      "[8, 300] loss: 0.321\n",
      "[8, 360] loss: 0.343\n",
      "Epoch: 8 -> Loss: 0.244279310107\n",
      "Epoch: 8 -> Test Accuracy: 85.0\n",
      "[9, 60] loss: 0.288\n",
      "[9, 120] loss: 0.323\n",
      "[9, 180] loss: 0.303\n",
      "[9, 240] loss: 0.312\n",
      "[9, 300] loss: 0.323\n",
      "[9, 360] loss: 0.332\n",
      "Epoch: 9 -> Loss: 0.402080923319\n",
      "Epoch: 9 -> Test Accuracy: 84.76\n",
      "[10, 60] loss: 0.303\n",
      "[10, 120] loss: 0.306\n",
      "[10, 180] loss: 0.314\n",
      "[10, 240] loss: 0.321\n",
      "[10, 300] loss: 0.336\n",
      "[10, 360] loss: 0.309\n",
      "Epoch: 10 -> Loss: 0.325409144163\n",
      "Epoch: 10 -> Test Accuracy: 85.19\n",
      "[11, 60] loss: 0.288\n",
      "[11, 120] loss: 0.296\n",
      "[11, 180] loss: 0.317\n",
      "[11, 240] loss: 0.304\n",
      "[11, 300] loss: 0.317\n",
      "[11, 360] loss: 0.317\n",
      "Epoch: 11 -> Loss: 0.263535737991\n",
      "Epoch: 11 -> Test Accuracy: 85.35\n",
      "[12, 60] loss: 0.283\n",
      "[12, 120] loss: 0.285\n",
      "[12, 180] loss: 0.304\n",
      "[12, 240] loss: 0.314\n",
      "[12, 300] loss: 0.304\n",
      "[12, 360] loss: 0.312\n",
      "Epoch: 12 -> Loss: 0.329572200775\n",
      "Epoch: 12 -> Test Accuracy: 85.49\n",
      "[13, 60] loss: 0.283\n",
      "[13, 120] loss: 0.279\n",
      "[13, 180] loss: 0.287\n",
      "[13, 240] loss: 0.302\n",
      "[13, 300] loss: 0.312\n",
      "[13, 360] loss: 0.306\n",
      "Epoch: 13 -> Loss: 0.32151260972\n",
      "Epoch: 13 -> Test Accuracy: 84.93\n",
      "[14, 60] loss: 0.277\n",
      "[14, 120] loss: 0.273\n",
      "[14, 180] loss: 0.298\n",
      "[14, 240] loss: 0.299\n",
      "[14, 300] loss: 0.303\n",
      "[14, 360] loss: 0.295\n",
      "Epoch: 14 -> Loss: 0.295053064823\n",
      "Epoch: 14 -> Test Accuracy: 85.16\n",
      "[15, 60] loss: 0.255\n",
      "[15, 120] loss: 0.277\n",
      "[15, 180] loss: 0.292\n",
      "[15, 240] loss: 0.315\n",
      "[15, 300] loss: 0.296\n",
      "[15, 360] loss: 0.305\n",
      "Epoch: 15 -> Loss: 0.409368902445\n",
      "Epoch: 15 -> Test Accuracy: 85.91\n",
      "[16, 60] loss: 0.259\n",
      "[16, 120] loss: 0.279\n",
      "[16, 180] loss: 0.288\n",
      "[16, 240] loss: 0.306\n",
      "[16, 300] loss: 0.292\n",
      "[16, 360] loss: 0.303\n",
      "Epoch: 16 -> Loss: 0.352615863085\n",
      "Epoch: 16 -> Test Accuracy: 85.97\n",
      "[17, 60] loss: 0.250\n",
      "[17, 120] loss: 0.275\n",
      "[17, 180] loss: 0.298\n",
      "[17, 240] loss: 0.263\n",
      "[17, 300] loss: 0.301\n",
      "[17, 360] loss: 0.299\n",
      "Epoch: 17 -> Loss: 0.322307497263\n",
      "Epoch: 17 -> Test Accuracy: 85.47\n",
      "[18, 60] loss: 0.265\n",
      "[18, 120] loss: 0.266\n",
      "[18, 180] loss: 0.286\n",
      "[18, 240] loss: 0.280\n",
      "[18, 300] loss: 0.292\n",
      "[18, 360] loss: 0.307\n",
      "Epoch: 18 -> Loss: 0.378385126591\n",
      "Epoch: 18 -> Test Accuracy: 85.27\n",
      "[19, 60] loss: 0.247\n",
      "[19, 120] loss: 0.257\n",
      "[19, 180] loss: 0.281\n",
      "[19, 240] loss: 0.299\n",
      "[19, 300] loss: 0.302\n",
      "[19, 360] loss: 0.300\n",
      "Epoch: 19 -> Loss: 0.226461485028\n",
      "Epoch: 19 -> Test Accuracy: 85.44\n",
      "[20, 60] loss: 0.265\n",
      "[20, 120] loss: 0.269\n",
      "[20, 180] loss: 0.275\n",
      "[20, 240] loss: 0.268\n",
      "[20, 300] loss: 0.289\n",
      "[20, 360] loss: 0.301\n",
      "Epoch: 20 -> Loss: 0.267578065395\n",
      "Epoch: 20 -> Test Accuracy: 85.05\n",
      "[21, 60] loss: 0.260\n",
      "[21, 120] loss: 0.266\n",
      "[21, 180] loss: 0.278\n",
      "[21, 240] loss: 0.303\n",
      "[21, 300] loss: 0.295\n",
      "[21, 360] loss: 0.299\n",
      "Epoch: 21 -> Loss: 0.344430208206\n",
      "Epoch: 21 -> Test Accuracy: 86.0\n",
      "[22, 60] loss: 0.251\n",
      "[22, 120] loss: 0.259\n",
      "[22, 180] loss: 0.283\n",
      "[22, 240] loss: 0.273\n",
      "[22, 300] loss: 0.283\n",
      "[22, 360] loss: 0.306\n",
      "Epoch: 22 -> Loss: 0.344394624233\n",
      "Epoch: 22 -> Test Accuracy: 86.02\n",
      "[23, 60] loss: 0.258\n",
      "[23, 120] loss: 0.254\n",
      "[23, 180] loss: 0.274\n",
      "[23, 240] loss: 0.285\n",
      "[23, 300] loss: 0.288\n",
      "[23, 360] loss: 0.305\n",
      "Epoch: 23 -> Loss: 0.336735337973\n",
      "Epoch: 23 -> Test Accuracy: 86.02\n",
      "[24, 60] loss: 0.272\n",
      "[24, 120] loss: 0.272\n",
      "[24, 180] loss: 0.254\n",
      "[24, 240] loss: 0.285\n",
      "[24, 300] loss: 0.287\n",
      "[24, 360] loss: 0.300\n",
      "Epoch: 24 -> Loss: 0.356309950352\n",
      "Epoch: 24 -> Test Accuracy: 85.62\n",
      "[25, 60] loss: 0.249\n",
      "[25, 120] loss: 0.271\n",
      "[25, 180] loss: 0.254\n",
      "[25, 240] loss: 0.289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 300] loss: 0.282\n",
      "[25, 360] loss: 0.296\n",
      "Epoch: 25 -> Loss: 0.341488003731\n",
      "Epoch: 25 -> Test Accuracy: 85.97\n",
      "[26, 60] loss: 0.252\n",
      "[26, 120] loss: 0.267\n",
      "[26, 180] loss: 0.262\n",
      "[26, 240] loss: 0.279\n",
      "[26, 300] loss: 0.278\n",
      "[26, 360] loss: 0.284\n",
      "Epoch: 26 -> Loss: 0.319442749023\n",
      "Epoch: 26 -> Test Accuracy: 85.25\n",
      "[27, 60] loss: 0.254\n",
      "[27, 120] loss: 0.259\n",
      "[27, 180] loss: 0.287\n",
      "[27, 240] loss: 0.274\n",
      "[27, 300] loss: 0.284\n",
      "[27, 360] loss: 0.278\n",
      "Epoch: 27 -> Loss: 0.226982995868\n",
      "Epoch: 27 -> Test Accuracy: 85.75\n",
      "[28, 60] loss: 0.241\n",
      "[28, 120] loss: 0.253\n",
      "[28, 180] loss: 0.277\n",
      "[28, 240] loss: 0.272\n",
      "[28, 300] loss: 0.276\n",
      "[28, 360] loss: 0.285\n",
      "Epoch: 28 -> Loss: 0.29738420248\n",
      "Epoch: 28 -> Test Accuracy: 85.2\n",
      "[29, 60] loss: 0.255\n",
      "[29, 120] loss: 0.263\n",
      "[29, 180] loss: 0.283\n",
      "[29, 240] loss: 0.271\n",
      "[29, 300] loss: 0.288\n",
      "[29, 360] loss: 0.284\n",
      "Epoch: 29 -> Loss: 0.231850743294\n",
      "Epoch: 29 -> Test Accuracy: 86.49\n",
      "[30, 60] loss: 0.255\n",
      "[30, 120] loss: 0.247\n",
      "[30, 180] loss: 0.255\n",
      "[30, 240] loss: 0.277\n",
      "[30, 300] loss: 0.293\n",
      "[30, 360] loss: 0.283\n",
      "Epoch: 30 -> Loss: 0.310887873173\n",
      "Epoch: 30 -> Test Accuracy: 85.41\n",
      "[31, 60] loss: 0.258\n",
      "[31, 120] loss: 0.248\n",
      "[31, 180] loss: 0.268\n",
      "[31, 240] loss: 0.273\n",
      "[31, 300] loss: 0.281\n",
      "[31, 360] loss: 0.289\n",
      "Epoch: 31 -> Loss: 0.420926660299\n",
      "Epoch: 31 -> Test Accuracy: 85.96\n",
      "[32, 60] loss: 0.236\n",
      "[32, 120] loss: 0.243\n",
      "[32, 180] loss: 0.266\n",
      "[32, 240] loss: 0.267\n",
      "[32, 300] loss: 0.286\n",
      "[32, 360] loss: 0.274\n",
      "Epoch: 32 -> Loss: 0.2804453969\n",
      "Epoch: 32 -> Test Accuracy: 85.96\n",
      "[33, 60] loss: 0.245\n",
      "[33, 120] loss: 0.257\n",
      "[33, 180] loss: 0.278\n",
      "[33, 240] loss: 0.278\n",
      "[33, 300] loss: 0.284\n",
      "[33, 360] loss: 0.289\n",
      "Epoch: 33 -> Loss: 0.407581865788\n",
      "Epoch: 33 -> Test Accuracy: 85.37\n",
      "[34, 60] loss: 0.253\n",
      "[34, 120] loss: 0.268\n",
      "[34, 180] loss: 0.271\n",
      "[34, 240] loss: 0.273\n",
      "[34, 300] loss: 0.281\n",
      "[34, 360] loss: 0.276\n",
      "Epoch: 34 -> Loss: 0.203279212117\n",
      "Epoch: 34 -> Test Accuracy: 85.79\n",
      "[35, 60] loss: 0.248\n",
      "[35, 120] loss: 0.258\n",
      "[35, 180] loss: 0.266\n",
      "[35, 240] loss: 0.280\n",
      "[35, 300] loss: 0.284\n",
      "[35, 360] loss: 0.267\n",
      "Epoch: 35 -> Loss: 0.249962732196\n",
      "Epoch: 35 -> Test Accuracy: 85.94\n",
      "[36, 60] loss: 0.211\n",
      "[36, 120] loss: 0.179\n",
      "[36, 180] loss: 0.169\n",
      "[36, 240] loss: 0.175\n",
      "[36, 300] loss: 0.178\n",
      "[36, 360] loss: 0.174\n",
      "Epoch: 36 -> Loss: 0.119632601738\n",
      "Epoch: 36 -> Test Accuracy: 88.42\n",
      "[37, 60] loss: 0.156\n",
      "[37, 120] loss: 0.144\n",
      "[37, 180] loss: 0.153\n",
      "[37, 240] loss: 0.154\n",
      "[37, 300] loss: 0.144\n",
      "[37, 360] loss: 0.146\n",
      "Epoch: 37 -> Loss: 0.0853560268879\n",
      "Epoch: 37 -> Test Accuracy: 88.37\n",
      "[38, 60] loss: 0.123\n",
      "[38, 120] loss: 0.141\n",
      "[38, 180] loss: 0.143\n",
      "[38, 240] loss: 0.141\n",
      "[38, 300] loss: 0.147\n",
      "[38, 360] loss: 0.149\n",
      "Epoch: 38 -> Loss: 0.195482254028\n",
      "Epoch: 38 -> Test Accuracy: 87.74\n",
      "[39, 60] loss: 0.125\n",
      "[39, 120] loss: 0.129\n",
      "[39, 180] loss: 0.121\n",
      "[39, 240] loss: 0.136\n",
      "[39, 300] loss: 0.135\n",
      "[39, 360] loss: 0.129\n",
      "Epoch: 39 -> Loss: 0.129564166069\n",
      "Epoch: 39 -> Test Accuracy: 88.01\n",
      "[40, 60] loss: 0.119\n",
      "[40, 120] loss: 0.114\n",
      "[40, 180] loss: 0.120\n",
      "[40, 240] loss: 0.129\n",
      "[40, 300] loss: 0.134\n",
      "[40, 360] loss: 0.121\n",
      "Epoch: 40 -> Loss: 0.192290261388\n",
      "Epoch: 40 -> Test Accuracy: 88.01\n",
      "[41, 60] loss: 0.116\n",
      "[41, 120] loss: 0.108\n",
      "[41, 180] loss: 0.122\n",
      "[41, 240] loss: 0.113\n",
      "[41, 300] loss: 0.119\n",
      "[41, 360] loss: 0.135\n",
      "Epoch: 41 -> Loss: 0.171708106995\n",
      "Epoch: 41 -> Test Accuracy: 87.93\n",
      "[42, 60] loss: 0.106\n",
      "[42, 120] loss: 0.115\n",
      "[42, 180] loss: 0.111\n",
      "[42, 240] loss: 0.118\n",
      "[42, 300] loss: 0.125\n",
      "[42, 360] loss: 0.123\n",
      "Epoch: 42 -> Loss: 0.1343857795\n",
      "Epoch: 42 -> Test Accuracy: 87.97\n",
      "[43, 60] loss: 0.103\n",
      "[43, 120] loss: 0.109\n",
      "[43, 180] loss: 0.109\n",
      "[43, 240] loss: 0.113\n",
      "[43, 300] loss: 0.104\n",
      "[43, 360] loss: 0.123\n",
      "Epoch: 43 -> Loss: 0.0949309021235\n",
      "Epoch: 43 -> Test Accuracy: 87.99\n",
      "[44, 60] loss: 0.106\n",
      "[44, 120] loss: 0.115\n",
      "[44, 180] loss: 0.108\n",
      "[44, 240] loss: 0.118\n",
      "[44, 300] loss: 0.121\n",
      "[44, 360] loss: 0.118\n",
      "Epoch: 44 -> Loss: 0.06109598279\n",
      "Epoch: 44 -> Test Accuracy: 88.13\n",
      "[45, 60] loss: 0.094\n",
      "[45, 120] loss: 0.104\n",
      "[45, 180] loss: 0.120\n",
      "[45, 240] loss: 0.107\n",
      "[45, 300] loss: 0.119\n",
      "[45, 360] loss: 0.128\n",
      "Epoch: 45 -> Loss: 0.115737617016\n",
      "Epoch: 45 -> Test Accuracy: 87.47\n",
      "[46, 60] loss: 0.096\n",
      "[46, 120] loss: 0.104\n",
      "[46, 180] loss: 0.113\n",
      "[46, 240] loss: 0.113\n",
      "[46, 300] loss: 0.127\n",
      "[46, 360] loss: 0.127\n",
      "Epoch: 46 -> Loss: 0.0859613120556\n",
      "Epoch: 46 -> Test Accuracy: 87.83\n",
      "[47, 60] loss: 0.108\n",
      "[47, 120] loss: 0.101\n",
      "[47, 180] loss: 0.113\n",
      "[47, 240] loss: 0.112\n",
      "[47, 300] loss: 0.120\n",
      "[47, 360] loss: 0.128\n",
      "Epoch: 47 -> Loss: 0.0733428150415\n",
      "Epoch: 47 -> Test Accuracy: 87.56\n",
      "[48, 60] loss: 0.098\n",
      "[48, 120] loss: 0.113\n",
      "[48, 180] loss: 0.111\n",
      "[48, 240] loss: 0.113\n",
      "[48, 300] loss: 0.116\n",
      "[48, 360] loss: 0.120\n",
      "Epoch: 48 -> Loss: 0.131920963526\n",
      "Epoch: 48 -> Test Accuracy: 87.14\n",
      "[49, 60] loss: 0.096\n",
      "[49, 120] loss: 0.108\n",
      "[49, 180] loss: 0.109\n",
      "[49, 240] loss: 0.109\n",
      "[49, 300] loss: 0.122\n",
      "[49, 360] loss: 0.115\n",
      "Epoch: 49 -> Loss: 0.226884797215\n",
      "Epoch: 49 -> Test Accuracy: 88.12\n",
      "[50, 60] loss: 0.099\n",
      "[50, 120] loss: 0.100\n",
      "[50, 180] loss: 0.113\n",
      "[50, 240] loss: 0.115\n",
      "[50, 300] loss: 0.119\n",
      "[50, 360] loss: 0.119\n",
      "Epoch: 50 -> Loss: 0.164265871048\n",
      "Epoch: 50 -> Test Accuracy: 87.31\n",
      "[51, 60] loss: 0.112\n",
      "[51, 120] loss: 0.094\n",
      "[51, 180] loss: 0.106\n",
      "[51, 240] loss: 0.113\n",
      "[51, 300] loss: 0.110\n",
      "[51, 360] loss: 0.115\n",
      "Epoch: 51 -> Loss: 0.0622524023056\n",
      "Epoch: 51 -> Test Accuracy: 87.47\n",
      "[52, 60] loss: 0.100\n",
      "[52, 120] loss: 0.107\n",
      "[52, 180] loss: 0.114\n",
      "[52, 240] loss: 0.112\n",
      "[52, 300] loss: 0.119\n",
      "[52, 360] loss: 0.110\n",
      "Epoch: 52 -> Loss: 0.212100937963\n",
      "Epoch: 52 -> Test Accuracy: 87.12\n",
      "[53, 60] loss: 0.115\n",
      "[53, 120] loss: 0.106\n",
      "[53, 180] loss: 0.104\n",
      "[53, 240] loss: 0.109\n",
      "[53, 300] loss: 0.125\n",
      "[53, 360] loss: 0.120\n",
      "Epoch: 53 -> Loss: 0.140857577324\n",
      "Epoch: 53 -> Test Accuracy: 87.53\n",
      "[54, 60] loss: 0.097\n",
      "[54, 120] loss: 0.099\n",
      "[54, 180] loss: 0.108\n",
      "[54, 240] loss: 0.113\n",
      "[54, 300] loss: 0.121\n",
      "[54, 360] loss: 0.122\n",
      "Epoch: 54 -> Loss: 0.0839306861162\n",
      "Epoch: 54 -> Test Accuracy: 87.46\n",
      "[55, 60] loss: 0.107\n",
      "[55, 120] loss: 0.104\n",
      "[55, 180] loss: 0.104\n",
      "[55, 240] loss: 0.114\n",
      "[55, 300] loss: 0.122\n",
      "[55, 360] loss: 0.129\n",
      "Epoch: 55 -> Loss: 0.215591877699\n",
      "Epoch: 55 -> Test Accuracy: 87.09\n",
      "[56, 60] loss: 0.102\n",
      "[56, 120] loss: 0.104\n",
      "[56, 180] loss: 0.114\n",
      "[56, 240] loss: 0.111\n",
      "[56, 300] loss: 0.116\n",
      "[56, 360] loss: 0.126\n",
      "Epoch: 56 -> Loss: 0.132235243917\n",
      "Epoch: 56 -> Test Accuracy: 86.96\n",
      "[57, 60] loss: 0.104\n",
      "[57, 120] loss: 0.104\n",
      "[57, 180] loss: 0.100\n",
      "[57, 240] loss: 0.106\n",
      "[57, 300] loss: 0.123\n",
      "[57, 360] loss: 0.128\n",
      "Epoch: 57 -> Loss: 0.142843514681\n",
      "Epoch: 57 -> Test Accuracy: 86.99\n",
      "[58, 60] loss: 0.101\n",
      "[58, 120] loss: 0.102\n",
      "[58, 180] loss: 0.102\n",
      "[58, 240] loss: 0.109\n",
      "[58, 300] loss: 0.113\n",
      "[58, 360] loss: 0.111\n",
      "Epoch: 58 -> Loss: 0.119543932378\n",
      "Epoch: 58 -> Test Accuracy: 87.03\n",
      "[59, 60] loss: 0.105\n",
      "[59, 120] loss: 0.109\n",
      "[59, 180] loss: 0.105\n",
      "[59, 240] loss: 0.111\n",
      "[59, 300] loss: 0.125\n",
      "[59, 360] loss: 0.118\n",
      "Epoch: 59 -> Loss: 0.153853207827\n",
      "Epoch: 59 -> Test Accuracy: 87.38\n",
      "[60, 60] loss: 0.101\n",
      "[60, 120] loss: 0.094\n",
      "[60, 180] loss: 0.108\n",
      "[60, 240] loss: 0.118\n",
      "[60, 300] loss: 0.118\n",
      "[60, 360] loss: 0.116\n",
      "Epoch: 60 -> Loss: 0.127626314759\n",
      "Epoch: 60 -> Test Accuracy: 87.32\n",
      "[61, 60] loss: 0.107\n",
      "[61, 120] loss: 0.107\n",
      "[61, 180] loss: 0.107\n",
      "[61, 240] loss: 0.116\n",
      "[61, 300] loss: 0.129\n",
      "[61, 360] loss: 0.121\n",
      "Epoch: 61 -> Loss: 0.193615972996\n",
      "Epoch: 61 -> Test Accuracy: 87.36\n",
      "[62, 60] loss: 0.103\n",
      "[62, 120] loss: 0.104\n",
      "[62, 180] loss: 0.105\n",
      "[62, 240] loss: 0.104\n",
      "[62, 300] loss: 0.116\n",
      "[62, 360] loss: 0.119\n",
      "Epoch: 62 -> Loss: 0.055776912719\n",
      "Epoch: 62 -> Test Accuracy: 87.46\n",
      "[63, 60] loss: 0.108\n",
      "[63, 120] loss: 0.101\n",
      "[63, 180] loss: 0.121\n",
      "[63, 240] loss: 0.111\n",
      "[63, 300] loss: 0.114\n",
      "[63, 360] loss: 0.122\n",
      "Epoch: 63 -> Loss: 0.076981946826\n",
      "Epoch: 63 -> Test Accuracy: 86.64\n",
      "[64, 60] loss: 0.097\n",
      "[64, 120] loss: 0.103\n",
      "[64, 180] loss: 0.104\n",
      "[64, 240] loss: 0.111\n",
      "[64, 300] loss: 0.115\n",
      "[64, 360] loss: 0.117\n",
      "Epoch: 64 -> Loss: 0.177823826671\n",
      "Epoch: 64 -> Test Accuracy: 87.29\n",
      "[65, 60] loss: 0.103\n",
      "[65, 120] loss: 0.098\n",
      "[65, 180] loss: 0.103\n",
      "[65, 240] loss: 0.107\n",
      "[65, 300] loss: 0.112\n",
      "[65, 360] loss: 0.114\n",
      "Epoch: 65 -> Loss: 0.0930973142385\n",
      "Epoch: 65 -> Test Accuracy: 87.07\n",
      "[66, 60] loss: 0.110\n",
      "[66, 120] loss: 0.106\n",
      "[66, 180] loss: 0.106\n",
      "[66, 240] loss: 0.109\n",
      "[66, 300] loss: 0.120\n",
      "[66, 360] loss: 0.118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Loss: 0.136515721679\n",
      "Epoch: 66 -> Test Accuracy: 87.22\n",
      "[67, 60] loss: 0.104\n",
      "[67, 120] loss: 0.091\n",
      "[67, 180] loss: 0.103\n",
      "[67, 240] loss: 0.112\n",
      "[67, 300] loss: 0.109\n",
      "[67, 360] loss: 0.114\n",
      "Epoch: 67 -> Loss: 0.0738821774721\n",
      "Epoch: 67 -> Test Accuracy: 87.26\n",
      "[68, 60] loss: 0.099\n",
      "[68, 120] loss: 0.095\n",
      "[68, 180] loss: 0.106\n",
      "[68, 240] loss: 0.102\n",
      "[68, 300] loss: 0.111\n",
      "[68, 360] loss: 0.119\n",
      "Epoch: 68 -> Loss: 0.1126562953\n",
      "Epoch: 68 -> Test Accuracy: 87.04\n",
      "[69, 60] loss: 0.094\n",
      "[69, 120] loss: 0.106\n",
      "[69, 180] loss: 0.099\n",
      "[69, 240] loss: 0.103\n",
      "[69, 300] loss: 0.115\n",
      "[69, 360] loss: 0.114\n",
      "Epoch: 69 -> Loss: 0.14923466742\n",
      "Epoch: 69 -> Test Accuracy: 87.26\n",
      "[70, 60] loss: 0.101\n",
      "[70, 120] loss: 0.117\n",
      "[70, 180] loss: 0.106\n",
      "[70, 240] loss: 0.105\n",
      "[70, 300] loss: 0.118\n",
      "[70, 360] loss: 0.115\n",
      "Epoch: 70 -> Loss: 0.100658461452\n",
      "Epoch: 70 -> Test Accuracy: 87.71\n",
      "[71, 60] loss: 0.086\n",
      "[71, 120] loss: 0.068\n",
      "[71, 180] loss: 0.070\n",
      "[71, 240] loss: 0.067\n",
      "[71, 300] loss: 0.064\n",
      "[71, 360] loss: 0.065\n",
      "Epoch: 71 -> Loss: 0.0766341090202\n",
      "Epoch: 71 -> Test Accuracy: 88.48\n",
      "[72, 60] loss: 0.057\n",
      "[72, 120] loss: 0.056\n",
      "[72, 180] loss: 0.056\n",
      "[72, 240] loss: 0.055\n",
      "[72, 300] loss: 0.058\n",
      "[72, 360] loss: 0.055\n",
      "Epoch: 72 -> Loss: 0.026934588328\n",
      "Epoch: 72 -> Test Accuracy: 88.64\n",
      "[73, 60] loss: 0.050\n",
      "[73, 120] loss: 0.052\n",
      "[73, 180] loss: 0.048\n",
      "[73, 240] loss: 0.050\n",
      "[73, 300] loss: 0.055\n",
      "[73, 360] loss: 0.052\n",
      "Epoch: 73 -> Loss: 0.0855546593666\n",
      "Epoch: 73 -> Test Accuracy: 88.69\n",
      "[74, 60] loss: 0.044\n",
      "[74, 120] loss: 0.046\n",
      "[74, 180] loss: 0.050\n",
      "[74, 240] loss: 0.051\n",
      "[74, 300] loss: 0.049\n",
      "[74, 360] loss: 0.045\n",
      "Epoch: 74 -> Loss: 0.0328740701079\n",
      "Epoch: 74 -> Test Accuracy: 88.61\n",
      "[75, 60] loss: 0.045\n",
      "[75, 120] loss: 0.045\n",
      "[75, 180] loss: 0.045\n",
      "[75, 240] loss: 0.048\n",
      "[75, 300] loss: 0.048\n",
      "[75, 360] loss: 0.046\n",
      "Epoch: 75 -> Loss: 0.0486175827682\n",
      "Epoch: 75 -> Test Accuracy: 88.65\n",
      "[76, 60] loss: 0.044\n",
      "[76, 120] loss: 0.046\n",
      "[76, 180] loss: 0.042\n",
      "[76, 240] loss: 0.041\n",
      "[76, 300] loss: 0.042\n",
      "[76, 360] loss: 0.042\n",
      "Epoch: 76 -> Loss: 0.0170862618834\n",
      "Epoch: 76 -> Test Accuracy: 88.72\n",
      "[77, 60] loss: 0.038\n",
      "[77, 120] loss: 0.041\n",
      "[77, 180] loss: 0.040\n",
      "[77, 240] loss: 0.042\n",
      "[77, 300] loss: 0.041\n",
      "[77, 360] loss: 0.043\n",
      "Epoch: 77 -> Loss: 0.0513725355268\n",
      "Epoch: 77 -> Test Accuracy: 88.51\n",
      "[78, 60] loss: 0.037\n",
      "[78, 120] loss: 0.039\n",
      "[78, 180] loss: 0.044\n",
      "[78, 240] loss: 0.041\n",
      "[78, 300] loss: 0.043\n",
      "[78, 360] loss: 0.036\n",
      "Epoch: 78 -> Loss: 0.0347908362746\n",
      "Epoch: 78 -> Test Accuracy: 88.65\n",
      "[79, 60] loss: 0.038\n",
      "[79, 120] loss: 0.040\n",
      "[79, 180] loss: 0.036\n",
      "[79, 240] loss: 0.039\n",
      "[79, 300] loss: 0.042\n",
      "[79, 360] loss: 0.041\n",
      "Epoch: 79 -> Loss: 0.0522440969944\n",
      "Epoch: 79 -> Test Accuracy: 88.64\n",
      "[80, 60] loss: 0.040\n",
      "[80, 120] loss: 0.039\n",
      "[80, 180] loss: 0.038\n",
      "[80, 240] loss: 0.039\n",
      "[80, 300] loss: 0.038\n",
      "[80, 360] loss: 0.038\n",
      "Epoch: 80 -> Loss: 0.0512919947505\n",
      "Epoch: 80 -> Test Accuracy: 88.83\n",
      "[81, 60] loss: 0.035\n",
      "[81, 120] loss: 0.036\n",
      "[81, 180] loss: 0.035\n",
      "[81, 240] loss: 0.036\n",
      "[81, 300] loss: 0.040\n",
      "[81, 360] loss: 0.038\n",
      "Epoch: 81 -> Loss: 0.0375687964261\n",
      "Epoch: 81 -> Test Accuracy: 88.64\n",
      "[82, 60] loss: 0.036\n",
      "[82, 120] loss: 0.036\n",
      "[82, 180] loss: 0.036\n",
      "[82, 240] loss: 0.039\n",
      "[82, 300] loss: 0.037\n",
      "[82, 360] loss: 0.033\n",
      "Epoch: 82 -> Loss: 0.055635817349\n",
      "Epoch: 82 -> Test Accuracy: 88.85\n",
      "[83, 60] loss: 0.032\n",
      "[83, 120] loss: 0.033\n",
      "[83, 180] loss: 0.035\n",
      "[83, 240] loss: 0.032\n",
      "[83, 300] loss: 0.038\n",
      "[83, 360] loss: 0.036\n",
      "Epoch: 83 -> Loss: 0.061122380197\n",
      "Epoch: 83 -> Test Accuracy: 88.8\n",
      "[84, 60] loss: 0.036\n",
      "[84, 120] loss: 0.037\n",
      "[84, 180] loss: 0.034\n",
      "[84, 240] loss: 0.036\n",
      "[84, 300] loss: 0.034\n",
      "[84, 360] loss: 0.037\n",
      "Epoch: 84 -> Loss: 0.0287474505603\n",
      "Epoch: 84 -> Test Accuracy: 88.54\n",
      "[85, 60] loss: 0.034\n",
      "[85, 120] loss: 0.034\n",
      "[85, 180] loss: 0.033\n",
      "[85, 240] loss: 0.033\n",
      "[85, 300] loss: 0.035\n",
      "[85, 360] loss: 0.031\n",
      "Epoch: 85 -> Loss: 0.0754595547915\n",
      "Epoch: 85 -> Test Accuracy: 88.71\n",
      "[86, 60] loss: 0.030\n",
      "[86, 120] loss: 0.030\n",
      "[86, 180] loss: 0.030\n",
      "[86, 240] loss: 0.029\n",
      "[86, 300] loss: 0.031\n",
      "[86, 360] loss: 0.031\n",
      "Epoch: 86 -> Loss: 0.0340866670012\n",
      "Epoch: 86 -> Test Accuracy: 88.89\n",
      "[87, 60] loss: 0.028\n",
      "[87, 120] loss: 0.028\n",
      "[87, 180] loss: 0.029\n",
      "[87, 240] loss: 0.031\n",
      "[87, 300] loss: 0.030\n",
      "[87, 360] loss: 0.028\n",
      "Epoch: 87 -> Loss: 0.0324410349131\n",
      "Epoch: 87 -> Test Accuracy: 88.73\n",
      "[88, 60] loss: 0.028\n",
      "[88, 120] loss: 0.030\n",
      "[88, 180] loss: 0.030\n",
      "[88, 240] loss: 0.027\n",
      "[88, 300] loss: 0.030\n",
      "[88, 360] loss: 0.028\n",
      "Epoch: 88 -> Loss: 0.065881177783\n",
      "Epoch: 88 -> Test Accuracy: 88.88\n",
      "[89, 60] loss: 0.029\n",
      "[89, 120] loss: 0.029\n",
      "[89, 180] loss: 0.028\n",
      "[89, 240] loss: 0.030\n",
      "[89, 300] loss: 0.028\n",
      "[89, 360] loss: 0.028\n",
      "Epoch: 89 -> Loss: 0.049420684576\n",
      "Epoch: 89 -> Test Accuracy: 88.83\n",
      "[90, 60] loss: 0.031\n",
      "[90, 120] loss: 0.031\n",
      "[90, 180] loss: 0.026\n",
      "[90, 240] loss: 0.028\n",
      "[90, 300] loss: 0.031\n",
      "[90, 360] loss: 0.029\n",
      "Epoch: 90 -> Loss: 0.0625891536474\n",
      "Epoch: 90 -> Test Accuracy: 88.87\n",
      "[91, 60] loss: 0.026\n",
      "[91, 120] loss: 0.030\n",
      "[91, 180] loss: 0.029\n",
      "[91, 240] loss: 0.030\n",
      "[91, 300] loss: 0.026\n",
      "[91, 360] loss: 0.026\n",
      "Epoch: 91 -> Loss: 0.0224617384374\n",
      "Epoch: 91 -> Test Accuracy: 88.78\n",
      "[92, 60] loss: 0.029\n",
      "[92, 120] loss: 0.029\n",
      "[92, 180] loss: 0.028\n",
      "[92, 240] loss: 0.026\n",
      "[92, 300] loss: 0.029\n",
      "[92, 360] loss: 0.028\n",
      "Epoch: 92 -> Loss: 0.0500334501266\n",
      "Epoch: 92 -> Test Accuracy: 88.83\n",
      "[93, 60] loss: 0.028\n",
      "[93, 120] loss: 0.031\n",
      "[93, 180] loss: 0.028\n",
      "[93, 240] loss: 0.027\n",
      "[93, 300] loss: 0.028\n",
      "[93, 360] loss: 0.027\n",
      "Epoch: 93 -> Loss: 0.0204849950969\n",
      "Epoch: 93 -> Test Accuracy: 88.77\n",
      "[94, 60] loss: 0.025\n",
      "[94, 120] loss: 0.029\n",
      "[94, 180] loss: 0.028\n",
      "[94, 240] loss: 0.027\n",
      "[94, 300] loss: 0.026\n",
      "[94, 360] loss: 0.027\n",
      "Epoch: 94 -> Loss: 0.0232417397201\n",
      "Epoch: 94 -> Test Accuracy: 88.79\n",
      "[95, 60] loss: 0.027\n",
      "[95, 120] loss: 0.027\n",
      "[95, 180] loss: 0.026\n",
      "[95, 240] loss: 0.029\n",
      "[95, 300] loss: 0.027\n",
      "[95, 360] loss: 0.025\n",
      "Epoch: 95 -> Loss: 0.026712898165\n",
      "Epoch: 95 -> Test Accuracy: 88.82\n",
      "[96, 60] loss: 0.027\n",
      "[96, 120] loss: 0.026\n",
      "[96, 180] loss: 0.029\n",
      "[96, 240] loss: 0.028\n",
      "[96, 300] loss: 0.026\n",
      "[96, 360] loss: 0.027\n",
      "Epoch: 96 -> Loss: 0.0248846709728\n",
      "Epoch: 96 -> Test Accuracy: 88.93\n",
      "[97, 60] loss: 0.027\n",
      "[97, 120] loss: 0.026\n",
      "[97, 180] loss: 0.026\n",
      "[97, 240] loss: 0.028\n",
      "[97, 300] loss: 0.030\n",
      "[97, 360] loss: 0.025\n",
      "Epoch: 97 -> Loss: 0.0314652696252\n",
      "Epoch: 97 -> Test Accuracy: 88.96\n",
      "[98, 60] loss: 0.030\n",
      "[98, 120] loss: 0.028\n",
      "[98, 180] loss: 0.027\n",
      "[98, 240] loss: 0.029\n",
      "[98, 300] loss: 0.027\n",
      "[98, 360] loss: 0.028\n",
      "Epoch: 98 -> Loss: 0.0446627959609\n",
      "Epoch: 98 -> Test Accuracy: 88.77\n",
      "[99, 60] loss: 0.027\n",
      "[99, 120] loss: 0.027\n",
      "[99, 180] loss: 0.028\n",
      "[99, 240] loss: 0.028\n",
      "[99, 300] loss: 0.026\n",
      "[99, 360] loss: 0.027\n",
      "Epoch: 99 -> Loss: 0.0285762436688\n",
      "Epoch: 99 -> Test Accuracy: 88.91\n",
      "[100, 60] loss: 0.027\n",
      "[100, 120] loss: 0.027\n",
      "[100, 180] loss: 0.028\n",
      "[100, 240] loss: 0.026\n",
      "[100, 300] loss: 0.027\n",
      "[100, 360] loss: 0.025\n",
      "Epoch: 100 -> Loss: 0.0211671106517\n",
      "Epoch: 100 -> Test Accuracy: 88.85\n",
      "Finished Training\n",
      "[1, 60] loss: 1.864\n",
      "[1, 120] loss: 1.671\n",
      "[1, 180] loss: 1.617\n",
      "[1, 240] loss: 1.557\n",
      "[1, 300] loss: 1.503\n",
      "[1, 360] loss: 1.495\n",
      "Epoch: 1 -> Loss: 1.44402956963\n",
      "Epoch: 1 -> Test Accuracy: 41.77\n",
      "[2, 60] loss: 1.460\n",
      "[2, 120] loss: 1.441\n",
      "[2, 180] loss: 1.441\n",
      "[2, 240] loss: 1.405\n",
      "[2, 300] loss: 1.400\n",
      "[2, 360] loss: 1.397\n",
      "Epoch: 2 -> Loss: 1.38099598885\n",
      "Epoch: 2 -> Test Accuracy: 46.47\n",
      "[3, 60] loss: 1.362\n",
      "[3, 120] loss: 1.365\n",
      "[3, 180] loss: 1.377\n",
      "[3, 240] loss: 1.379\n",
      "[3, 300] loss: 1.372\n",
      "[3, 360] loss: 1.339\n",
      "Epoch: 3 -> Loss: 1.45053625107\n",
      "Epoch: 3 -> Test Accuracy: 46.79\n",
      "[4, 60] loss: 1.379\n",
      "[4, 120] loss: 1.351\n",
      "[4, 180] loss: 1.337\n",
      "[4, 240] loss: 1.336\n",
      "[4, 300] loss: 1.344\n",
      "[4, 360] loss: 1.328\n",
      "Epoch: 4 -> Loss: 1.41717123985\n",
      "Epoch: 4 -> Test Accuracy: 46.64\n",
      "[5, 60] loss: 1.328\n",
      "[5, 120] loss: 1.310\n",
      "[5, 180] loss: 1.340\n",
      "[5, 240] loss: 1.319\n",
      "[5, 300] loss: 1.337\n",
      "[5, 360] loss: 1.296\n",
      "Epoch: 5 -> Loss: 1.33960080147\n",
      "Epoch: 5 -> Test Accuracy: 47.92\n",
      "[6, 60] loss: 1.306\n",
      "[6, 120] loss: 1.314\n",
      "[6, 180] loss: 1.302\n",
      "[6, 240] loss: 1.304\n",
      "[6, 300] loss: 1.290\n",
      "[6, 360] loss: 1.302\n",
      "Epoch: 6 -> Loss: 1.32932209969\n",
      "Epoch: 6 -> Test Accuracy: 49.2\n",
      "[7, 60] loss: 1.294\n",
      "[7, 120] loss: 1.298\n",
      "[7, 180] loss: 1.289\n",
      "[7, 240] loss: 1.271\n",
      "[7, 300] loss: 1.317\n",
      "[7, 360] loss: 1.299\n",
      "Epoch: 7 -> Loss: 1.3274641037\n",
      "Epoch: 7 -> Test Accuracy: 48.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 60] loss: 1.297\n",
      "[8, 120] loss: 1.283\n",
      "[8, 180] loss: 1.292\n",
      "[8, 240] loss: 1.284\n",
      "[8, 300] loss: 1.272\n",
      "[8, 360] loss: 1.292\n",
      "Epoch: 8 -> Loss: 1.32960522175\n",
      "Epoch: 8 -> Test Accuracy: 49.94\n",
      "[9, 60] loss: 1.270\n",
      "[9, 120] loss: 1.276\n",
      "[9, 180] loss: 1.284\n",
      "[9, 240] loss: 1.274\n",
      "[9, 300] loss: 1.280\n",
      "[9, 360] loss: 1.279\n",
      "Epoch: 9 -> Loss: 1.27157330513\n",
      "Epoch: 9 -> Test Accuracy: 48.47\n",
      "[10, 60] loss: 1.273\n",
      "[10, 120] loss: 1.254\n",
      "[10, 180] loss: 1.284\n",
      "[10, 240] loss: 1.276\n",
      "[10, 300] loss: 1.265\n",
      "[10, 360] loss: 1.257\n",
      "Epoch: 10 -> Loss: 1.24339318275\n",
      "Epoch: 10 -> Test Accuracy: 50.51\n",
      "[11, 60] loss: 1.283\n",
      "[11, 120] loss: 1.267\n",
      "[11, 180] loss: 1.283\n",
      "[11, 240] loss: 1.245\n",
      "[11, 300] loss: 1.270\n",
      "[11, 360] loss: 1.270\n",
      "Epoch: 11 -> Loss: 1.20748829842\n",
      "Epoch: 11 -> Test Accuracy: 50.16\n",
      "[12, 60] loss: 1.271\n",
      "[12, 120] loss: 1.275\n",
      "[12, 180] loss: 1.266\n",
      "[12, 240] loss: 1.280\n",
      "[12, 300] loss: 1.268\n",
      "[12, 360] loss: 1.255\n",
      "Epoch: 12 -> Loss: 1.36186671257\n",
      "Epoch: 12 -> Test Accuracy: 50.7\n",
      "[13, 60] loss: 1.261\n",
      "[13, 120] loss: 1.268\n",
      "[13, 180] loss: 1.254\n",
      "[13, 240] loss: 1.261\n",
      "[13, 300] loss: 1.271\n",
      "[13, 360] loss: 1.261\n",
      "Epoch: 13 -> Loss: 1.32102811337\n",
      "Epoch: 13 -> Test Accuracy: 51.29\n",
      "[14, 60] loss: 1.259\n",
      "[14, 120] loss: 1.243\n",
      "[14, 180] loss: 1.250\n",
      "[14, 240] loss: 1.261\n",
      "[14, 300] loss: 1.252\n",
      "[14, 360] loss: 1.240\n",
      "Epoch: 14 -> Loss: 1.28719723225\n",
      "Epoch: 14 -> Test Accuracy: 50.45\n",
      "[15, 60] loss: 1.255\n",
      "[15, 120] loss: 1.253\n",
      "[15, 180] loss: 1.244\n",
      "[15, 240] loss: 1.250\n",
      "[15, 300] loss: 1.256\n",
      "[15, 360] loss: 1.267\n",
      "Epoch: 15 -> Loss: 1.30205976963\n",
      "Epoch: 15 -> Test Accuracy: 49.91\n",
      "[16, 60] loss: 1.258\n",
      "[16, 120] loss: 1.245\n",
      "[16, 180] loss: 1.248\n",
      "[16, 240] loss: 1.238\n",
      "[16, 300] loss: 1.243\n",
      "[16, 360] loss: 1.260\n",
      "Epoch: 16 -> Loss: 1.3010545969\n",
      "Epoch: 16 -> Test Accuracy: 51.02\n",
      "[17, 60] loss: 1.268\n",
      "[17, 120] loss: 1.262\n",
      "[17, 180] loss: 1.238\n",
      "[17, 240] loss: 1.266\n",
      "[17, 300] loss: 1.245\n",
      "[17, 360] loss: 1.242\n",
      "Epoch: 17 -> Loss: 1.30235147476\n",
      "Epoch: 17 -> Test Accuracy: 49.25\n",
      "[18, 60] loss: 1.267\n",
      "[18, 120] loss: 1.243\n",
      "[18, 180] loss: 1.254\n",
      "[18, 240] loss: 1.230\n",
      "[18, 300] loss: 1.237\n",
      "[18, 360] loss: 1.229\n",
      "Epoch: 18 -> Loss: 1.15867304802\n",
      "Epoch: 18 -> Test Accuracy: 49.81\n",
      "[19, 60] loss: 1.228\n",
      "[19, 120] loss: 1.263\n",
      "[19, 180] loss: 1.216\n",
      "[19, 240] loss: 1.262\n",
      "[19, 300] loss: 1.251\n",
      "[19, 360] loss: 1.244\n",
      "Epoch: 19 -> Loss: 1.38549339771\n",
      "Epoch: 19 -> Test Accuracy: 49.63\n",
      "[20, 60] loss: 1.226\n",
      "[20, 120] loss: 1.267\n",
      "[20, 180] loss: 1.252\n",
      "[20, 240] loss: 1.233\n",
      "[20, 300] loss: 1.237\n",
      "[20, 360] loss: 1.250\n",
      "Epoch: 20 -> Loss: 1.23976945877\n",
      "Epoch: 20 -> Test Accuracy: 51.37\n",
      "[21, 60] loss: 1.234\n",
      "[21, 120] loss: 1.238\n",
      "[21, 180] loss: 1.242\n",
      "[21, 240] loss: 1.244\n",
      "[21, 300] loss: 1.248\n",
      "[21, 360] loss: 1.237\n",
      "Epoch: 21 -> Loss: 1.28131520748\n",
      "Epoch: 21 -> Test Accuracy: 49.09\n",
      "[22, 60] loss: 1.248\n",
      "[22, 120] loss: 1.225\n",
      "[22, 180] loss: 1.240\n",
      "[22, 240] loss: 1.231\n",
      "[22, 300] loss: 1.231\n",
      "[22, 360] loss: 1.250\n",
      "Epoch: 22 -> Loss: 1.40720522404\n",
      "Epoch: 22 -> Test Accuracy: 50.51\n",
      "[23, 60] loss: 1.213\n",
      "[23, 120] loss: 1.245\n",
      "[23, 180] loss: 1.230\n",
      "[23, 240] loss: 1.258\n",
      "[23, 300] loss: 1.216\n",
      "[23, 360] loss: 1.245\n",
      "Epoch: 23 -> Loss: 1.28620302677\n",
      "Epoch: 23 -> Test Accuracy: 50.08\n",
      "[24, 60] loss: 1.230\n",
      "[24, 120] loss: 1.252\n",
      "[24, 180] loss: 1.232\n",
      "[24, 240] loss: 1.235\n",
      "[24, 300] loss: 1.258\n",
      "[24, 360] loss: 1.243\n",
      "Epoch: 24 -> Loss: 1.2525447607\n",
      "Epoch: 24 -> Test Accuracy: 51.07\n",
      "[25, 60] loss: 1.258\n",
      "[25, 120] loss: 1.241\n",
      "[25, 180] loss: 1.222\n",
      "[25, 240] loss: 1.251\n",
      "[25, 300] loss: 1.222\n",
      "[25, 360] loss: 1.236\n",
      "Epoch: 25 -> Loss: 1.24336826801\n",
      "Epoch: 25 -> Test Accuracy: 50.92\n",
      "[26, 60] loss: 1.228\n",
      "[26, 120] loss: 1.241\n",
      "[26, 180] loss: 1.256\n",
      "[26, 240] loss: 1.234\n",
      "[26, 300] loss: 1.231\n",
      "[26, 360] loss: 1.236\n",
      "Epoch: 26 -> Loss: 1.28107202053\n",
      "Epoch: 26 -> Test Accuracy: 49.91\n",
      "[27, 60] loss: 1.257\n",
      "[27, 120] loss: 1.231\n",
      "[27, 180] loss: 1.258\n",
      "[27, 240] loss: 1.243\n",
      "[27, 300] loss: 1.216\n",
      "[27, 360] loss: 1.229\n",
      "Epoch: 27 -> Loss: 1.49234557152\n",
      "Epoch: 27 -> Test Accuracy: 50.65\n",
      "[28, 60] loss: 1.218\n",
      "[28, 120] loss: 1.234\n",
      "[28, 180] loss: 1.223\n",
      "[28, 240] loss: 1.240\n",
      "[28, 300] loss: 1.230\n",
      "[28, 360] loss: 1.249\n",
      "Epoch: 28 -> Loss: 1.29160475731\n",
      "Epoch: 28 -> Test Accuracy: 50.92\n",
      "[29, 60] loss: 1.243\n",
      "[29, 120] loss: 1.207\n",
      "[29, 180] loss: 1.232\n",
      "[29, 240] loss: 1.230\n",
      "[29, 300] loss: 1.225\n",
      "[29, 360] loss: 1.239\n",
      "Epoch: 29 -> Loss: 1.32375359535\n",
      "Epoch: 29 -> Test Accuracy: 50.91\n",
      "[30, 60] loss: 1.232\n",
      "[30, 120] loss: 1.207\n",
      "[30, 180] loss: 1.254\n",
      "[30, 240] loss: 1.221\n",
      "[30, 300] loss: 1.261\n",
      "[30, 360] loss: 1.249\n",
      "Epoch: 30 -> Loss: 1.11683499813\n",
      "Epoch: 30 -> Test Accuracy: 50.95\n",
      "[31, 60] loss: 1.239\n",
      "[31, 120] loss: 1.233\n",
      "[31, 180] loss: 1.232\n",
      "[31, 240] loss: 1.241\n",
      "[31, 300] loss: 1.226\n",
      "[31, 360] loss: 1.232\n",
      "Epoch: 31 -> Loss: 1.21370029449\n",
      "Epoch: 31 -> Test Accuracy: 50.93\n",
      "[32, 60] loss: 1.243\n",
      "[32, 120] loss: 1.207\n",
      "[32, 180] loss: 1.249\n",
      "[32, 240] loss: 1.221\n",
      "[32, 300] loss: 1.247\n",
      "[32, 360] loss: 1.239\n",
      "Epoch: 32 -> Loss: 1.1960889101\n",
      "Epoch: 32 -> Test Accuracy: 51.69\n",
      "[33, 60] loss: 1.240\n",
      "[33, 120] loss: 1.202\n",
      "[33, 180] loss: 1.258\n",
      "[33, 240] loss: 1.244\n",
      "[33, 300] loss: 1.222\n",
      "[33, 360] loss: 1.240\n",
      "Epoch: 33 -> Loss: 1.21777820587\n",
      "Epoch: 33 -> Test Accuracy: 52.54\n",
      "[34, 60] loss: 1.224\n",
      "[34, 120] loss: 1.237\n",
      "[34, 180] loss: 1.221\n",
      "[34, 240] loss: 1.241\n",
      "[34, 300] loss: 1.231\n",
      "[34, 360] loss: 1.212\n",
      "Epoch: 34 -> Loss: 1.17303287983\n",
      "Epoch: 34 -> Test Accuracy: 51.68\n",
      "[35, 60] loss: 1.212\n",
      "[35, 120] loss: 1.238\n",
      "[35, 180] loss: 1.230\n",
      "[35, 240] loss: 1.232\n",
      "[35, 300] loss: 1.250\n",
      "[35, 360] loss: 1.215\n",
      "Epoch: 35 -> Loss: 1.48312735558\n",
      "Epoch: 35 -> Test Accuracy: 50.92\n",
      "[36, 60] loss: 1.166\n",
      "[36, 120] loss: 1.124\n",
      "[36, 180] loss: 1.119\n",
      "[36, 240] loss: 1.109\n",
      "[36, 300] loss: 1.114\n",
      "[36, 360] loss: 1.123\n",
      "Epoch: 36 -> Loss: 1.2248737812\n",
      "Epoch: 36 -> Test Accuracy: 56.05\n",
      "[37, 60] loss: 1.095\n",
      "[37, 120] loss: 1.095\n",
      "[37, 180] loss: 1.094\n",
      "[37, 240] loss: 1.111\n",
      "[37, 300] loss: 1.096\n",
      "[37, 360] loss: 1.112\n",
      "Epoch: 37 -> Loss: 1.09152638912\n",
      "Epoch: 37 -> Test Accuracy: 56.7\n",
      "[38, 60] loss: 1.073\n",
      "[38, 120] loss: 1.080\n",
      "[38, 180] loss: 1.112\n",
      "[38, 240] loss: 1.076\n",
      "[38, 300] loss: 1.084\n",
      "[38, 360] loss: 1.108\n",
      "Epoch: 38 -> Loss: 1.09655594826\n",
      "Epoch: 38 -> Test Accuracy: 56.34\n",
      "[39, 60] loss: 1.074\n",
      "[39, 120] loss: 1.091\n",
      "[39, 180] loss: 1.090\n",
      "[39, 240] loss: 1.090\n",
      "[39, 300] loss: 1.089\n",
      "[39, 360] loss: 1.091\n",
      "Epoch: 39 -> Loss: 0.956209361553\n",
      "Epoch: 39 -> Test Accuracy: 56.86\n",
      "[40, 60] loss: 1.054\n",
      "[40, 120] loss: 1.093\n",
      "[40, 180] loss: 1.092\n",
      "[40, 240] loss: 1.073\n",
      "[40, 300] loss: 1.091\n",
      "[40, 360] loss: 1.098\n",
      "Epoch: 40 -> Loss: 1.25034248829\n",
      "Epoch: 40 -> Test Accuracy: 56.63\n",
      "[41, 60] loss: 1.073\n",
      "[41, 120] loss: 1.085\n",
      "[41, 180] loss: 1.087\n",
      "[41, 240] loss: 1.085\n",
      "[41, 300] loss: 1.090\n",
      "[41, 360] loss: 1.080\n",
      "Epoch: 41 -> Loss: 1.07978630066\n",
      "Epoch: 41 -> Test Accuracy: 56.53\n",
      "[42, 60] loss: 1.078\n",
      "[42, 120] loss: 1.108\n",
      "[42, 180] loss: 1.061\n",
      "[42, 240] loss: 1.080\n",
      "[42, 300] loss: 1.091\n",
      "[42, 360] loss: 1.071\n",
      "Epoch: 42 -> Loss: 1.04367911816\n",
      "Epoch: 42 -> Test Accuracy: 56.45\n",
      "[43, 60] loss: 1.093\n",
      "[43, 120] loss: 1.091\n",
      "[43, 180] loss: 1.094\n",
      "[43, 240] loss: 1.059\n",
      "[43, 300] loss: 1.075\n",
      "[43, 360] loss: 1.064\n",
      "Epoch: 43 -> Loss: 1.15401351452\n",
      "Epoch: 43 -> Test Accuracy: 56.98\n",
      "[44, 60] loss: 1.060\n",
      "[44, 120] loss: 1.074\n",
      "[44, 180] loss: 1.075\n",
      "[44, 240] loss: 1.089\n",
      "[44, 300] loss: 1.093\n",
      "[44, 360] loss: 1.087\n",
      "Epoch: 44 -> Loss: 1.05450665951\n",
      "Epoch: 44 -> Test Accuracy: 57.01\n",
      "[45, 60] loss: 1.073\n",
      "[45, 120] loss: 1.068\n",
      "[45, 180] loss: 1.103\n",
      "[45, 240] loss: 1.085\n",
      "[45, 300] loss: 1.070\n",
      "[45, 360] loss: 1.067\n",
      "Epoch: 45 -> Loss: 1.11119806767\n",
      "Epoch: 45 -> Test Accuracy: 56.58\n",
      "[46, 60] loss: 1.065\n",
      "[46, 120] loss: 1.080\n",
      "[46, 180] loss: 1.083\n",
      "[46, 240] loss: 1.081\n",
      "[46, 300] loss: 1.077\n",
      "[46, 360] loss: 1.088\n",
      "Epoch: 46 -> Loss: 1.20605611801\n",
      "Epoch: 46 -> Test Accuracy: 56.67\n",
      "[47, 60] loss: 1.075\n",
      "[47, 120] loss: 1.072\n",
      "[47, 180] loss: 1.109\n",
      "[47, 240] loss: 1.055\n",
      "[47, 300] loss: 1.107\n",
      "[47, 360] loss: 1.060\n",
      "Epoch: 47 -> Loss: 0.890106320381\n",
      "Epoch: 47 -> Test Accuracy: 56.65\n",
      "[48, 60] loss: 1.083\n",
      "[48, 120] loss: 1.066\n",
      "[48, 180] loss: 1.085\n",
      "[48, 240] loss: 1.052\n",
      "[48, 300] loss: 1.101\n",
      "[48, 360] loss: 1.082\n",
      "Epoch: 48 -> Loss: 1.12150061131\n",
      "Epoch: 48 -> Test Accuracy: 56.74\n",
      "[49, 60] loss: 1.068\n",
      "[49, 120] loss: 1.075\n",
      "[49, 180] loss: 1.067\n",
      "[49, 240] loss: 1.076\n",
      "[49, 300] loss: 1.059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 360] loss: 1.079\n",
      "Epoch: 49 -> Loss: 0.977250099182\n",
      "Epoch: 49 -> Test Accuracy: 57.02\n",
      "[50, 60] loss: 1.074\n",
      "[50, 120] loss: 1.062\n",
      "[50, 180] loss: 1.093\n",
      "[50, 240] loss: 1.086\n",
      "[50, 300] loss: 1.077\n",
      "[50, 360] loss: 1.075\n",
      "Epoch: 50 -> Loss: 0.956322014332\n",
      "Epoch: 50 -> Test Accuracy: 56.73\n",
      "[51, 60] loss: 1.081\n",
      "[51, 120] loss: 1.065\n",
      "[51, 180] loss: 1.082\n",
      "[51, 240] loss: 1.092\n",
      "[51, 300] loss: 1.068\n",
      "[51, 360] loss: 1.077\n",
      "Epoch: 51 -> Loss: 0.871275305748\n",
      "Epoch: 51 -> Test Accuracy: 56.73\n",
      "[52, 60] loss: 1.098\n",
      "[52, 120] loss: 1.057\n",
      "[52, 180] loss: 1.085\n",
      "[52, 240] loss: 1.061\n",
      "[52, 300] loss: 1.059\n",
      "[52, 360] loss: 1.077\n",
      "Epoch: 52 -> Loss: 1.08031904697\n",
      "Epoch: 52 -> Test Accuracy: 57.28\n",
      "[53, 60] loss: 1.069\n",
      "[53, 120] loss: 1.075\n",
      "[53, 180] loss: 1.049\n",
      "[53, 240] loss: 1.060\n",
      "[53, 300] loss: 1.089\n",
      "[53, 360] loss: 1.065\n",
      "Epoch: 53 -> Loss: 1.02426958084\n",
      "Epoch: 53 -> Test Accuracy: 56.45\n",
      "[54, 60] loss: 1.049\n",
      "[54, 120] loss: 1.062\n",
      "[54, 180] loss: 1.075\n",
      "[54, 240] loss: 1.092\n",
      "[54, 300] loss: 1.067\n",
      "[54, 360] loss: 1.055\n",
      "Epoch: 54 -> Loss: 0.993823885918\n",
      "Epoch: 54 -> Test Accuracy: 56.99\n",
      "[55, 60] loss: 1.088\n",
      "[55, 120] loss: 1.091\n",
      "[55, 180] loss: 1.058\n",
      "[55, 240] loss: 1.084\n",
      "[55, 300] loss: 1.060\n",
      "[55, 360] loss: 1.076\n",
      "Epoch: 55 -> Loss: 1.09307777882\n",
      "Epoch: 55 -> Test Accuracy: 56.57\n",
      "[56, 60] loss: 1.099\n",
      "[56, 120] loss: 1.051\n",
      "[56, 180] loss: 1.083\n",
      "[56, 240] loss: 1.090\n",
      "[56, 300] loss: 1.063\n",
      "[56, 360] loss: 1.049\n",
      "Epoch: 56 -> Loss: 1.11584830284\n",
      "Epoch: 56 -> Test Accuracy: 57.59\n",
      "[57, 60] loss: 1.087\n",
      "[57, 120] loss: 1.086\n",
      "[57, 180] loss: 1.080\n",
      "[57, 240] loss: 1.062\n",
      "[57, 300] loss: 1.067\n",
      "[57, 360] loss: 1.080\n",
      "Epoch: 57 -> Loss: 1.02722227573\n",
      "Epoch: 57 -> Test Accuracy: 55.99\n",
      "[58, 60] loss: 1.055\n",
      "[58, 120] loss: 1.088\n",
      "[58, 180] loss: 1.058\n",
      "[58, 240] loss: 1.090\n",
      "[58, 300] loss: 1.066\n",
      "[58, 360] loss: 1.063\n",
      "Epoch: 58 -> Loss: 0.833899319172\n",
      "Epoch: 58 -> Test Accuracy: 56.69\n",
      "[59, 60] loss: 1.058\n",
      "[59, 120] loss: 1.058\n",
      "[59, 180] loss: 1.071\n",
      "[59, 240] loss: 1.066\n",
      "[59, 300] loss: 1.059\n",
      "[59, 360] loss: 1.081\n",
      "Epoch: 59 -> Loss: 1.12059116364\n",
      "Epoch: 59 -> Test Accuracy: 57.38\n",
      "[60, 60] loss: 1.090\n",
      "[60, 120] loss: 1.064\n",
      "[60, 180] loss: 1.077\n",
      "[60, 240] loss: 1.056\n",
      "[60, 300] loss: 1.073\n",
      "[60, 360] loss: 1.054\n",
      "Epoch: 60 -> Loss: 0.914999604225\n",
      "Epoch: 60 -> Test Accuracy: 57.44\n",
      "[61, 60] loss: 1.042\n",
      "[61, 120] loss: 1.077\n",
      "[61, 180] loss: 1.057\n",
      "[61, 240] loss: 1.080\n",
      "[61, 300] loss: 1.072\n",
      "[61, 360] loss: 1.087\n",
      "Epoch: 61 -> Loss: 1.22898113728\n",
      "Epoch: 61 -> Test Accuracy: 56.28\n",
      "[62, 60] loss: 1.067\n",
      "[62, 120] loss: 1.067\n",
      "[62, 180] loss: 1.074\n",
      "[62, 240] loss: 1.061\n",
      "[62, 300] loss: 1.058\n",
      "[62, 360] loss: 1.074\n",
      "Epoch: 62 -> Loss: 1.01636242867\n",
      "Epoch: 62 -> Test Accuracy: 57.47\n",
      "[63, 60] loss: 1.052\n",
      "[63, 120] loss: 1.094\n",
      "[63, 180] loss: 1.062\n",
      "[63, 240] loss: 1.052\n",
      "[63, 300] loss: 1.046\n",
      "[63, 360] loss: 1.073\n",
      "Epoch: 63 -> Loss: 1.17509865761\n",
      "Epoch: 63 -> Test Accuracy: 57.21\n",
      "[64, 60] loss: 1.050\n",
      "[64, 120] loss: 1.059\n",
      "[64, 180] loss: 1.078\n",
      "[64, 240] loss: 1.070\n",
      "[64, 300] loss: 1.056\n",
      "[64, 360] loss: 1.090\n",
      "Epoch: 64 -> Loss: 1.11205089092\n",
      "Epoch: 64 -> Test Accuracy: 57.0\n",
      "[65, 60] loss: 1.080\n",
      "[65, 120] loss: 1.077\n",
      "[65, 180] loss: 1.061\n",
      "[65, 240] loss: 1.055\n",
      "[65, 300] loss: 1.070\n",
      "[65, 360] loss: 1.052\n",
      "Epoch: 65 -> Loss: 1.16291832924\n",
      "Epoch: 65 -> Test Accuracy: 58.06\n",
      "[66, 60] loss: 1.069\n",
      "[66, 120] loss: 1.057\n",
      "[66, 180] loss: 1.056\n",
      "[66, 240] loss: 1.073\n",
      "[66, 300] loss: 1.079\n",
      "[66, 360] loss: 1.059\n",
      "Epoch: 66 -> Loss: 1.00119280815\n",
      "Epoch: 66 -> Test Accuracy: 57.5\n",
      "[67, 60] loss: 1.078\n",
      "[67, 120] loss: 1.058\n",
      "[67, 180] loss: 1.083\n",
      "[67, 240] loss: 1.051\n",
      "[67, 300] loss: 1.067\n",
      "[67, 360] loss: 1.054\n",
      "Epoch: 67 -> Loss: 1.20958316326\n",
      "Epoch: 67 -> Test Accuracy: 56.79\n",
      "[68, 60] loss: 1.039\n",
      "[68, 120] loss: 1.051\n",
      "[68, 180] loss: 1.091\n",
      "[68, 240] loss: 1.063\n",
      "[68, 300] loss: 1.072\n",
      "[68, 360] loss: 1.057\n",
      "Epoch: 68 -> Loss: 1.18608927727\n",
      "Epoch: 68 -> Test Accuracy: 55.76\n",
      "[69, 60] loss: 1.064\n",
      "[69, 120] loss: 1.063\n",
      "[69, 180] loss: 1.063\n",
      "[69, 240] loss: 1.077\n",
      "[69, 300] loss: 1.080\n",
      "[69, 360] loss: 1.060\n",
      "Epoch: 69 -> Loss: 0.930968105793\n",
      "Epoch: 69 -> Test Accuracy: 56.36\n",
      "[70, 60] loss: 1.067\n",
      "[70, 120] loss: 1.047\n",
      "[70, 180] loss: 1.075\n",
      "[70, 240] loss: 1.051\n",
      "[70, 300] loss: 1.066\n",
      "[70, 360] loss: 1.066\n",
      "Epoch: 70 -> Loss: 0.986559271812\n",
      "Epoch: 70 -> Test Accuracy: 57.08\n",
      "[71, 60] loss: 1.030\n",
      "[71, 120] loss: 1.000\n",
      "[71, 180] loss: 0.992\n",
      "[71, 240] loss: 0.967\n",
      "[71, 300] loss: 0.974\n",
      "[71, 360] loss: 0.985\n",
      "Epoch: 71 -> Loss: 0.939179062843\n",
      "Epoch: 71 -> Test Accuracy: 60.29\n",
      "[72, 60] loss: 0.982\n",
      "[72, 120] loss: 0.965\n",
      "[72, 180] loss: 0.960\n",
      "[72, 240] loss: 0.985\n",
      "[72, 300] loss: 0.988\n",
      "[72, 360] loss: 0.967\n",
      "Epoch: 72 -> Loss: 1.04515576363\n",
      "Epoch: 72 -> Test Accuracy: 60.65\n",
      "[73, 60] loss: 0.970\n",
      "[73, 120] loss: 0.954\n",
      "[73, 180] loss: 0.962\n",
      "[73, 240] loss: 0.986\n",
      "[73, 300] loss: 0.972\n",
      "[73, 360] loss: 0.954\n",
      "Epoch: 73 -> Loss: 1.22282624245\n",
      "Epoch: 73 -> Test Accuracy: 60.57\n",
      "[74, 60] loss: 0.951\n",
      "[74, 120] loss: 0.969\n",
      "[74, 180] loss: 0.965\n",
      "[74, 240] loss: 0.963\n",
      "[74, 300] loss: 0.963\n",
      "[74, 360] loss: 0.980\n",
      "Epoch: 74 -> Loss: 0.811575055122\n",
      "Epoch: 74 -> Test Accuracy: 60.64\n",
      "[75, 60] loss: 0.962\n",
      "[75, 120] loss: 0.957\n",
      "[75, 180] loss: 0.965\n",
      "[75, 240] loss: 0.971\n",
      "[75, 300] loss: 0.952\n",
      "[75, 360] loss: 0.973\n",
      "Epoch: 75 -> Loss: 0.982818961143\n",
      "Epoch: 75 -> Test Accuracy: 60.93\n",
      "[76, 60] loss: 0.968\n",
      "[76, 120] loss: 0.967\n",
      "[76, 180] loss: 0.950\n",
      "[76, 240] loss: 0.955\n",
      "[76, 300] loss: 0.945\n",
      "[76, 360] loss: 0.953\n",
      "Epoch: 76 -> Loss: 0.914991855621\n",
      "Epoch: 76 -> Test Accuracy: 61.07\n",
      "[77, 60] loss: 0.938\n",
      "[77, 120] loss: 0.966\n",
      "[77, 180] loss: 0.955\n",
      "[77, 240] loss: 0.957\n",
      "[77, 300] loss: 0.951\n",
      "[77, 360] loss: 0.962\n",
      "Epoch: 77 -> Loss: 0.887126147747\n",
      "Epoch: 77 -> Test Accuracy: 61.24\n",
      "[78, 60] loss: 0.944\n",
      "[78, 120] loss: 0.968\n",
      "[78, 180] loss: 0.950\n",
      "[78, 240] loss: 0.940\n",
      "[78, 300] loss: 0.953\n",
      "[78, 360] loss: 0.952\n",
      "Epoch: 78 -> Loss: 0.842532336712\n",
      "Epoch: 78 -> Test Accuracy: 60.68\n",
      "[79, 60] loss: 0.957\n",
      "[79, 120] loss: 0.939\n",
      "[79, 180] loss: 0.930\n",
      "[79, 240] loss: 0.973\n",
      "[79, 300] loss: 0.959\n",
      "[79, 360] loss: 0.947\n",
      "Epoch: 79 -> Loss: 0.939680457115\n",
      "Epoch: 79 -> Test Accuracy: 60.59\n",
      "[80, 60] loss: 0.926\n",
      "[80, 120] loss: 0.963\n",
      "[80, 180] loss: 0.960\n",
      "[80, 240] loss: 0.935\n",
      "[80, 300] loss: 0.975\n",
      "[80, 360] loss: 0.963\n",
      "Epoch: 80 -> Loss: 0.886693775654\n",
      "Epoch: 80 -> Test Accuracy: 61.14\n",
      "[81, 60] loss: 0.942\n",
      "[81, 120] loss: 0.934\n",
      "[81, 180] loss: 0.949\n",
      "[81, 240] loss: 0.952\n",
      "[81, 300] loss: 0.953\n",
      "[81, 360] loss: 0.975\n",
      "Epoch: 81 -> Loss: 1.00773954391\n",
      "Epoch: 81 -> Test Accuracy: 61.22\n",
      "[82, 60] loss: 0.961\n",
      "[82, 120] loss: 0.948\n",
      "[82, 180] loss: 0.962\n",
      "[82, 240] loss: 0.950\n",
      "[82, 300] loss: 0.950\n",
      "[82, 360] loss: 0.938\n",
      "Epoch: 82 -> Loss: 0.86182820797\n",
      "Epoch: 82 -> Test Accuracy: 61.14\n",
      "[83, 60] loss: 0.939\n",
      "[83, 120] loss: 0.954\n",
      "[83, 180] loss: 0.945\n",
      "[83, 240] loss: 0.929\n",
      "[83, 300] loss: 0.968\n",
      "[83, 360] loss: 0.976\n",
      "Epoch: 83 -> Loss: 0.856813073158\n",
      "Epoch: 83 -> Test Accuracy: 61.39\n",
      "[84, 60] loss: 0.939\n",
      "[84, 120] loss: 0.947\n",
      "[84, 180] loss: 0.947\n",
      "[84, 240] loss: 0.946\n",
      "[84, 300] loss: 0.944\n",
      "[84, 360] loss: 0.928\n",
      "Epoch: 84 -> Loss: 0.870489597321\n",
      "Epoch: 84 -> Test Accuracy: 61.09\n",
      "[85, 60] loss: 0.941\n",
      "[85, 120] loss: 0.934\n",
      "[85, 180] loss: 0.949\n",
      "[85, 240] loss: 0.956\n",
      "[85, 300] loss: 0.957\n",
      "[85, 360] loss: 0.951\n",
      "Epoch: 85 -> Loss: 0.97772949934\n",
      "Epoch: 85 -> Test Accuracy: 61.0\n",
      "[86, 60] loss: 0.923\n",
      "[86, 120] loss: 0.926\n",
      "[86, 180] loss: 0.922\n",
      "[86, 240] loss: 0.912\n",
      "[86, 300] loss: 0.914\n",
      "[86, 360] loss: 0.900\n",
      "Epoch: 86 -> Loss: 0.735722899437\n",
      "Epoch: 86 -> Test Accuracy: 62.33\n",
      "[87, 60] loss: 0.897\n",
      "[87, 120] loss: 0.910\n",
      "[87, 180] loss: 0.908\n",
      "[87, 240] loss: 0.914\n",
      "[87, 300] loss: 0.906\n",
      "[87, 360] loss: 0.889\n",
      "Epoch: 87 -> Loss: 0.859391033649\n",
      "Epoch: 87 -> Test Accuracy: 62.4\n",
      "[88, 60] loss: 0.911\n",
      "[88, 120] loss: 0.897\n",
      "[88, 180] loss: 0.912\n",
      "[88, 240] loss: 0.898\n",
      "[88, 300] loss: 0.899\n",
      "[88, 360] loss: 0.927\n",
      "Epoch: 88 -> Loss: 0.929223418236\n",
      "Epoch: 88 -> Test Accuracy: 62.79\n",
      "[89, 60] loss: 0.904\n",
      "[89, 120] loss: 0.900\n",
      "[89, 180] loss: 0.905\n",
      "[89, 240] loss: 0.897\n",
      "[89, 300] loss: 0.916\n",
      "[89, 360] loss: 0.906\n",
      "Epoch: 89 -> Loss: 0.872076869011\n",
      "Epoch: 89 -> Test Accuracy: 62.55\n",
      "[90, 60] loss: 0.903\n",
      "[90, 120] loss: 0.896\n",
      "[90, 180] loss: 0.916\n",
      "[90, 240] loss: 0.926\n",
      "[90, 300] loss: 0.897\n",
      "[90, 360] loss: 0.889\n",
      "Epoch: 90 -> Loss: 0.766025364399\n",
      "Epoch: 90 -> Test Accuracy: 62.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[91, 60] loss: 0.907\n",
      "[91, 120] loss: 0.900\n",
      "[91, 180] loss: 0.901\n",
      "[91, 240] loss: 0.909\n",
      "[91, 300] loss: 0.903\n",
      "[91, 360] loss: 0.910\n",
      "Epoch: 91 -> Loss: 0.828966319561\n",
      "Epoch: 91 -> Test Accuracy: 62.58\n",
      "[92, 60] loss: 0.910\n",
      "[92, 120] loss: 0.909\n",
      "[92, 180] loss: 0.909\n",
      "[92, 240] loss: 0.901\n",
      "[92, 300] loss: 0.905\n",
      "[92, 360] loss: 0.898\n",
      "Epoch: 92 -> Loss: 0.818657398224\n",
      "Epoch: 92 -> Test Accuracy: 62.69\n",
      "[93, 60] loss: 0.915\n",
      "[93, 120] loss: 0.887\n",
      "[93, 180] loss: 0.906\n",
      "[93, 240] loss: 0.895\n",
      "[93, 300] loss: 0.911\n",
      "[93, 360] loss: 0.905\n",
      "Epoch: 93 -> Loss: 0.830051124096\n",
      "Epoch: 93 -> Test Accuracy: 62.61\n",
      "[94, 60] loss: 0.908\n",
      "[94, 120] loss: 0.884\n",
      "[94, 180] loss: 0.894\n",
      "[94, 240] loss: 0.897\n",
      "[94, 300] loss: 0.907\n",
      "[94, 360] loss: 0.909\n",
      "Epoch: 94 -> Loss: 0.957485377789\n",
      "Epoch: 94 -> Test Accuracy: 62.52\n",
      "[95, 60] loss: 0.901\n",
      "[95, 120] loss: 0.904\n",
      "[95, 180] loss: 0.898\n",
      "[95, 240] loss: 0.909\n",
      "[95, 300] loss: 0.890\n",
      "[95, 360] loss: 0.887\n",
      "Epoch: 95 -> Loss: 0.985755622387\n",
      "Epoch: 95 -> Test Accuracy: 62.62\n",
      "[96, 60] loss: 0.888\n",
      "[96, 120] loss: 0.893\n",
      "[96, 180] loss: 0.907\n",
      "[96, 240] loss: 0.902\n",
      "[96, 300] loss: 0.908\n",
      "[96, 360] loss: 0.897\n",
      "Epoch: 96 -> Loss: 0.9027993083\n",
      "Epoch: 96 -> Test Accuracy: 62.5\n",
      "[97, 60] loss: 0.894\n",
      "[97, 120] loss: 0.907\n",
      "[97, 180] loss: 0.906\n",
      "[97, 240] loss: 0.888\n",
      "[97, 300] loss: 0.895\n",
      "[97, 360] loss: 0.901\n",
      "Epoch: 97 -> Loss: 0.991523385048\n",
      "Epoch: 97 -> Test Accuracy: 62.89\n",
      "[98, 60] loss: 0.910\n",
      "[98, 120] loss: 0.899\n",
      "[98, 180] loss: 0.906\n",
      "[98, 240] loss: 0.895\n",
      "[98, 300] loss: 0.892\n",
      "[98, 360] loss: 0.894\n",
      "Epoch: 98 -> Loss: 0.879671216011\n",
      "Epoch: 98 -> Test Accuracy: 62.51\n",
      "[99, 60] loss: 0.902\n",
      "[99, 120] loss: 0.900\n",
      "[99, 180] loss: 0.899\n",
      "[99, 240] loss: 0.907\n",
      "[99, 300] loss: 0.908\n",
      "[99, 360] loss: 0.898\n",
      "Epoch: 99 -> Loss: 0.87798756361\n",
      "Epoch: 99 -> Test Accuracy: 62.43\n",
      "[100, 60] loss: 0.884\n",
      "[100, 120] loss: 0.904\n",
      "[100, 180] loss: 0.897\n",
      "[100, 240] loss: 0.895\n",
      "[100, 300] loss: 0.892\n",
      "[100, 360] loss: 0.911\n",
      "Epoch: 100 -> Loss: 1.00998318195\n",
      "Epoch: 100 -> Test Accuracy: 62.72\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train ConvClassifiers on feature map of net_3block\n",
    "conv_block3_loss_log, conv_block3_valid_accuracy_log, conv_block3_test_accuracy_log, conv_block3_max_accuracy, \\\n",
    "conv_block3_best_epoch = tr.train_all_blocks(3, 10, [0.1, 0.02, 0.004, 0.0008], [35, 70, 85, 100], 0.9, 5e-4, net_block3, \n",
    "                                            criterion, trainloader, None, testloader, use_ConvClassifier=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename files\n",
    "fm.add_block_to_name(3, [100, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Block RotNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "net_block4 = RN.RotNet(num_classes=4, num_conv_block=4, add_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.137\n",
      "[1, 120] loss: 1.000\n",
      "[1, 180] loss: 0.926\n",
      "[1, 240] loss: 0.867\n",
      "[1, 300] loss: 0.812\n",
      "[1, 360] loss: 0.779\n",
      "Epoch: 1 -> Loss: 0.794867396355\n",
      "Epoch: 1 -> Test Accuracy: 69.4575\n",
      "[2, 60] loss: 0.737\n",
      "[2, 120] loss: 0.714\n",
      "[2, 180] loss: 0.691\n",
      "[2, 240] loss: 0.663\n",
      "[2, 300] loss: 0.653\n",
      "[2, 360] loss: 0.646\n",
      "Epoch: 2 -> Loss: 0.812446415424\n",
      "Epoch: 2 -> Test Accuracy: 74.955\n",
      "[3, 60] loss: 0.608\n",
      "[3, 120] loss: 0.610\n",
      "[3, 180] loss: 0.579\n",
      "[3, 240] loss: 0.591\n",
      "[3, 300] loss: 0.582\n",
      "[3, 360] loss: 0.574\n",
      "Epoch: 3 -> Loss: 0.612565040588\n",
      "Epoch: 3 -> Test Accuracy: 76.72\n",
      "[4, 60] loss: 0.533\n",
      "[4, 120] loss: 0.541\n",
      "[4, 180] loss: 0.538\n",
      "[4, 240] loss: 0.553\n",
      "[4, 300] loss: 0.527\n",
      "[4, 360] loss: 0.516\n",
      "Epoch: 4 -> Loss: 0.469202518463\n",
      "Epoch: 4 -> Test Accuracy: 78.8775\n",
      "[5, 60] loss: 0.504\n",
      "[5, 120] loss: 0.501\n",
      "[5, 180] loss: 0.498\n",
      "[5, 240] loss: 0.498\n",
      "[5, 300] loss: 0.497\n",
      "[5, 360] loss: 0.478\n",
      "Epoch: 5 -> Loss: 0.580173373222\n",
      "Epoch: 5 -> Test Accuracy: 80.325\n",
      "[6, 60] loss: 0.474\n",
      "[6, 120] loss: 0.460\n",
      "[6, 180] loss: 0.473\n",
      "[6, 240] loss: 0.476\n",
      "[6, 300] loss: 0.467\n",
      "[6, 360] loss: 0.472\n",
      "Epoch: 6 -> Loss: 0.366227656603\n",
      "Epoch: 6 -> Test Accuracy: 81.24\n",
      "[7, 60] loss: 0.441\n",
      "[7, 120] loss: 0.457\n",
      "[7, 180] loss: 0.460\n",
      "[7, 240] loss: 0.453\n",
      "[7, 300] loss: 0.442\n",
      "[7, 360] loss: 0.453\n",
      "Epoch: 7 -> Loss: 0.3851595819\n",
      "Epoch: 7 -> Test Accuracy: 81.7125\n",
      "[8, 60] loss: 0.441\n",
      "[8, 120] loss: 0.437\n",
      "[8, 180] loss: 0.426\n",
      "[8, 240] loss: 0.433\n",
      "[8, 300] loss: 0.432\n",
      "[8, 360] loss: 0.428\n",
      "Epoch: 8 -> Loss: 0.398950904608\n",
      "Epoch: 8 -> Test Accuracy: 83.31\n",
      "[9, 60] loss: 0.416\n",
      "[9, 120] loss: 0.410\n",
      "[9, 180] loss: 0.417\n",
      "[9, 240] loss: 0.437\n",
      "[9, 300] loss: 0.408\n",
      "[9, 360] loss: 0.431\n",
      "Epoch: 9 -> Loss: 0.503224730492\n",
      "Epoch: 9 -> Test Accuracy: 83.1125\n",
      "[10, 60] loss: 0.401\n",
      "[10, 120] loss: 0.403\n",
      "[10, 180] loss: 0.402\n",
      "[10, 240] loss: 0.411\n",
      "[10, 300] loss: 0.410\n",
      "[10, 360] loss: 0.415\n",
      "Epoch: 10 -> Loss: 0.499788463116\n",
      "Epoch: 10 -> Test Accuracy: 83.1725\n",
      "[11, 60] loss: 0.385\n",
      "[11, 120] loss: 0.395\n",
      "[11, 180] loss: 0.392\n",
      "[11, 240] loss: 0.406\n",
      "[11, 300] loss: 0.397\n",
      "[11, 360] loss: 0.385\n",
      "Epoch: 11 -> Loss: 0.531141400337\n",
      "Epoch: 11 -> Test Accuracy: 83.2175\n",
      "[12, 60] loss: 0.366\n",
      "[12, 120] loss: 0.391\n",
      "[12, 180] loss: 0.388\n",
      "[12, 240] loss: 0.399\n",
      "[12, 300] loss: 0.385\n",
      "[12, 360] loss: 0.378\n",
      "Epoch: 12 -> Loss: 0.328559964895\n",
      "Epoch: 12 -> Test Accuracy: 84.41\n",
      "[13, 60] loss: 0.367\n",
      "[13, 120] loss: 0.389\n",
      "[13, 180] loss: 0.371\n",
      "[13, 240] loss: 0.381\n",
      "[13, 300] loss: 0.389\n",
      "[13, 360] loss: 0.375\n",
      "Epoch: 13 -> Loss: 0.380201846361\n",
      "Epoch: 13 -> Test Accuracy: 84.83\n",
      "[14, 60] loss: 0.376\n",
      "[14, 120] loss: 0.368\n",
      "[14, 180] loss: 0.369\n",
      "[14, 240] loss: 0.368\n",
      "[14, 300] loss: 0.388\n",
      "[14, 360] loss: 0.378\n",
      "Epoch: 14 -> Loss: 0.372721731663\n",
      "Epoch: 14 -> Test Accuracy: 84.98\n",
      "[15, 60] loss: 0.371\n",
      "[15, 120] loss: 0.374\n",
      "[15, 180] loss: 0.366\n",
      "[15, 240] loss: 0.359\n",
      "[15, 300] loss: 0.365\n",
      "[15, 360] loss: 0.375\n",
      "Epoch: 15 -> Loss: 0.390071332455\n",
      "Epoch: 15 -> Test Accuracy: 84.12\n",
      "[16, 60] loss: 0.351\n",
      "[16, 120] loss: 0.359\n",
      "[16, 180] loss: 0.363\n",
      "[16, 240] loss: 0.370\n",
      "[16, 300] loss: 0.369\n",
      "[16, 360] loss: 0.353\n",
      "Epoch: 16 -> Loss: 0.413547039032\n",
      "Epoch: 16 -> Test Accuracy: 85.1875\n",
      "[17, 60] loss: 0.356\n",
      "[17, 120] loss: 0.357\n",
      "[17, 180] loss: 0.357\n",
      "[17, 240] loss: 0.368\n",
      "[17, 300] loss: 0.361\n",
      "[17, 360] loss: 0.351\n",
      "Epoch: 17 -> Loss: 0.299592465162\n",
      "Epoch: 17 -> Test Accuracy: 85.015\n",
      "[18, 60] loss: 0.344\n",
      "[18, 120] loss: 0.359\n",
      "[18, 180] loss: 0.366\n",
      "[18, 240] loss: 0.352\n",
      "[18, 300] loss: 0.359\n",
      "[18, 360] loss: 0.351\n",
      "Epoch: 18 -> Loss: 0.424548923969\n",
      "Epoch: 18 -> Test Accuracy: 85.995\n",
      "[19, 60] loss: 0.337\n",
      "[19, 120] loss: 0.349\n",
      "[19, 180] loss: 0.345\n",
      "[19, 240] loss: 0.339\n",
      "[19, 300] loss: 0.356\n",
      "[19, 360] loss: 0.356\n",
      "Epoch: 19 -> Loss: 0.357505440712\n",
      "Epoch: 19 -> Test Accuracy: 85.275\n",
      "[20, 60] loss: 0.343\n",
      "[20, 120] loss: 0.340\n",
      "[20, 180] loss: 0.348\n",
      "[20, 240] loss: 0.349\n",
      "[20, 300] loss: 0.339\n",
      "[20, 360] loss: 0.341\n",
      "Epoch: 20 -> Loss: 0.281944543123\n",
      "Epoch: 20 -> Test Accuracy: 85.41\n",
      "[21, 60] loss: 0.343\n",
      "[21, 120] loss: 0.337\n",
      "[21, 180] loss: 0.337\n",
      "[21, 240] loss: 0.344\n",
      "[21, 300] loss: 0.347\n",
      "[21, 360] loss: 0.340\n",
      "Epoch: 21 -> Loss: 0.336336195469\n",
      "Epoch: 21 -> Test Accuracy: 85.32\n",
      "[22, 60] loss: 0.326\n",
      "[22, 120] loss: 0.335\n",
      "[22, 180] loss: 0.335\n",
      "[22, 240] loss: 0.341\n",
      "[22, 300] loss: 0.352\n",
      "[22, 360] loss: 0.349\n",
      "Epoch: 22 -> Loss: 0.303259760141\n",
      "Epoch: 22 -> Test Accuracy: 86.4475\n",
      "[23, 60] loss: 0.323\n",
      "[23, 120] loss: 0.336\n",
      "[23, 180] loss: 0.335\n",
      "[23, 240] loss: 0.344\n",
      "[23, 300] loss: 0.340\n",
      "[23, 360] loss: 0.345\n",
      "Epoch: 23 -> Loss: 0.357082515955\n",
      "Epoch: 23 -> Test Accuracy: 86.265\n",
      "[24, 60] loss: 0.323\n",
      "[24, 120] loss: 0.326\n",
      "[24, 180] loss: 0.346\n",
      "[24, 240] loss: 0.347\n",
      "[24, 300] loss: 0.317\n",
      "[24, 360] loss: 0.347\n",
      "Epoch: 24 -> Loss: 0.23915246129\n",
      "Epoch: 24 -> Test Accuracy: 85.96\n",
      "[25, 60] loss: 0.326\n",
      "[25, 120] loss: 0.322\n",
      "[25, 180] loss: 0.337\n",
      "[25, 240] loss: 0.317\n",
      "[25, 300] loss: 0.341\n",
      "[25, 360] loss: 0.338\n",
      "Epoch: 25 -> Loss: 0.228496164083\n",
      "Epoch: 25 -> Test Accuracy: 86.855\n",
      "[26, 60] loss: 0.320\n",
      "[26, 120] loss: 0.325\n",
      "[26, 180] loss: 0.329\n",
      "[26, 240] loss: 0.333\n",
      "[26, 300] loss: 0.333\n",
      "[26, 360] loss: 0.346\n",
      "Epoch: 26 -> Loss: 0.216858237982\n",
      "Epoch: 26 -> Test Accuracy: 86.5675\n",
      "[27, 60] loss: 0.318\n",
      "[27, 120] loss: 0.318\n",
      "[27, 180] loss: 0.334\n",
      "[27, 240] loss: 0.321\n",
      "[27, 300] loss: 0.335\n",
      "[27, 360] loss: 0.331\n",
      "Epoch: 27 -> Loss: 0.391339421272\n",
      "Epoch: 27 -> Test Accuracy: 85.7675\n",
      "[28, 60] loss: 0.308\n",
      "[28, 120] loss: 0.314\n",
      "[28, 180] loss: 0.334\n",
      "[28, 240] loss: 0.320\n",
      "[28, 300] loss: 0.331\n",
      "[28, 360] loss: 0.349\n",
      "Epoch: 28 -> Loss: 0.35003438592\n",
      "Epoch: 28 -> Test Accuracy: 86.5675\n",
      "[29, 60] loss: 0.305\n",
      "[29, 120] loss: 0.320\n",
      "[29, 180] loss: 0.328\n",
      "[29, 240] loss: 0.331\n",
      "[29, 300] loss: 0.332\n",
      "[29, 360] loss: 0.328\n",
      "Epoch: 29 -> Loss: 0.2681453228\n",
      "Epoch: 29 -> Test Accuracy: 86.73\n",
      "[30, 60] loss: 0.302\n",
      "[30, 120] loss: 0.326\n",
      "[30, 180] loss: 0.338\n",
      "[30, 240] loss: 0.335\n",
      "[30, 300] loss: 0.316\n",
      "[30, 360] loss: 0.331\n",
      "Epoch: 30 -> Loss: 0.36447224021\n",
      "Epoch: 30 -> Test Accuracy: 86.855\n",
      "[31, 60] loss: 0.310\n",
      "[31, 120] loss: 0.319\n",
      "[31, 180] loss: 0.323\n",
      "[31, 240] loss: 0.321\n",
      "[31, 300] loss: 0.320\n",
      "[31, 360] loss: 0.327\n",
      "Epoch: 31 -> Loss: 0.360473960638\n",
      "Epoch: 31 -> Test Accuracy: 85.0075\n",
      "[32, 60] loss: 0.300\n",
      "[32, 120] loss: 0.333\n",
      "[32, 180] loss: 0.323\n",
      "[32, 240] loss: 0.321\n",
      "[32, 300] loss: 0.331\n",
      "[32, 360] loss: 0.317\n",
      "Epoch: 32 -> Loss: 0.217897102237\n",
      "Epoch: 32 -> Test Accuracy: 85.795\n",
      "[33, 60] loss: 0.310\n",
      "[33, 120] loss: 0.310\n",
      "[33, 180] loss: 0.326\n",
      "[33, 240] loss: 0.322\n",
      "[33, 300] loss: 0.316\n",
      "[33, 360] loss: 0.318\n",
      "Epoch: 33 -> Loss: 0.292844086885\n",
      "Epoch: 33 -> Test Accuracy: 85.625\n",
      "[34, 60] loss: 0.309\n",
      "[34, 120] loss: 0.306\n",
      "[34, 180] loss: 0.323\n",
      "[34, 240] loss: 0.317\n",
      "[34, 300] loss: 0.318\n",
      "[34, 360] loss: 0.322\n",
      "Epoch: 34 -> Loss: 0.343082368374\n",
      "Epoch: 34 -> Test Accuracy: 86.5425\n",
      "[35, 60] loss: 0.311\n",
      "[35, 120] loss: 0.301\n",
      "[35, 180] loss: 0.307\n",
      "[35, 240] loss: 0.317\n",
      "[35, 300] loss: 0.316\n",
      "[35, 360] loss: 0.322\n",
      "Epoch: 35 -> Loss: 0.370342642069\n",
      "Epoch: 35 -> Test Accuracy: 86.365\n",
      "[36, 60] loss: 0.305\n",
      "[36, 120] loss: 0.309\n",
      "[36, 180] loss: 0.322\n",
      "[36, 240] loss: 0.314\n",
      "[36, 300] loss: 0.336\n",
      "[36, 360] loss: 0.309\n",
      "Epoch: 36 -> Loss: 0.271720975637\n",
      "Epoch: 36 -> Test Accuracy: 87.1625\n",
      "[37, 60] loss: 0.304\n",
      "[37, 120] loss: 0.316\n",
      "[37, 180] loss: 0.308\n",
      "[37, 240] loss: 0.313\n",
      "[37, 300] loss: 0.309\n",
      "[37, 360] loss: 0.320\n",
      "Epoch: 37 -> Loss: 0.297063440084\n",
      "Epoch: 37 -> Test Accuracy: 86.58\n",
      "[38, 60] loss: 0.303\n",
      "[38, 120] loss: 0.321\n",
      "[38, 180] loss: 0.314\n",
      "[38, 240] loss: 0.309\n",
      "[38, 300] loss: 0.323\n",
      "[38, 360] loss: 0.311\n",
      "Epoch: 38 -> Loss: 0.181552857161\n",
      "Epoch: 38 -> Test Accuracy: 86.975\n",
      "[39, 60] loss: 0.300\n",
      "[39, 120] loss: 0.313\n",
      "[39, 180] loss: 0.312\n",
      "[39, 240] loss: 0.320\n",
      "[39, 300] loss: 0.316\n",
      "[39, 360] loss: 0.303\n",
      "Epoch: 39 -> Loss: 0.31209731102\n",
      "Epoch: 39 -> Test Accuracy: 86.03\n",
      "[40, 60] loss: 0.296\n",
      "[40, 120] loss: 0.321\n",
      "[40, 180] loss: 0.314\n",
      "[40, 240] loss: 0.302\n",
      "[40, 300] loss: 0.319\n",
      "[40, 360] loss: 0.326\n",
      "Epoch: 40 -> Loss: 0.280427634716\n",
      "Epoch: 40 -> Test Accuracy: 86.6225\n",
      "[41, 60] loss: 0.306\n",
      "[41, 120] loss: 0.293\n",
      "[41, 180] loss: 0.299\n",
      "[41, 240] loss: 0.319\n",
      "[41, 300] loss: 0.312\n",
      "[41, 360] loss: 0.308\n",
      "Epoch: 41 -> Loss: 0.456361353397\n",
      "Epoch: 41 -> Test Accuracy: 87.04\n",
      "[42, 60] loss: 0.294\n",
      "[42, 120] loss: 0.304\n",
      "[42, 180] loss: 0.308\n",
      "[42, 240] loss: 0.312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 300] loss: 0.313\n",
      "[42, 360] loss: 0.316\n",
      "Epoch: 42 -> Loss: 0.221511036158\n",
      "Epoch: 42 -> Test Accuracy: 87.05\n",
      "[43, 60] loss: 0.297\n",
      "[43, 120] loss: 0.310\n",
      "[43, 180] loss: 0.299\n",
      "[43, 240] loss: 0.314\n",
      "[43, 300] loss: 0.315\n",
      "[43, 360] loss: 0.305\n",
      "Epoch: 43 -> Loss: 0.267120063305\n",
      "Epoch: 43 -> Test Accuracy: 85.5825\n",
      "[44, 60] loss: 0.303\n",
      "[44, 120] loss: 0.295\n",
      "[44, 180] loss: 0.308\n",
      "[44, 240] loss: 0.300\n",
      "[44, 300] loss: 0.318\n",
      "[44, 360] loss: 0.318\n",
      "Epoch: 44 -> Loss: 0.265498161316\n",
      "Epoch: 44 -> Test Accuracy: 86.7125\n",
      "[45, 60] loss: 0.300\n",
      "[45, 120] loss: 0.305\n",
      "[45, 180] loss: 0.309\n",
      "[45, 240] loss: 0.316\n",
      "[45, 300] loss: 0.299\n",
      "[45, 360] loss: 0.294\n",
      "Epoch: 45 -> Loss: 0.447193145752\n",
      "Epoch: 45 -> Test Accuracy: 86.9225\n",
      "[46, 60] loss: 0.304\n",
      "[46, 120] loss: 0.310\n",
      "[46, 180] loss: 0.300\n",
      "[46, 240] loss: 0.306\n",
      "[46, 300] loss: 0.315\n",
      "[46, 360] loss: 0.309\n",
      "Epoch: 46 -> Loss: 0.284951984882\n",
      "Epoch: 46 -> Test Accuracy: 86.9175\n",
      "[47, 60] loss: 0.300\n",
      "[47, 120] loss: 0.301\n",
      "[47, 180] loss: 0.308\n",
      "[47, 240] loss: 0.309\n",
      "[47, 300] loss: 0.311\n",
      "[47, 360] loss: 0.302\n",
      "Epoch: 47 -> Loss: 0.338699758053\n",
      "Epoch: 47 -> Test Accuracy: 86.79\n",
      "[48, 60] loss: 0.297\n",
      "[48, 120] loss: 0.300\n",
      "[48, 180] loss: 0.292\n",
      "[48, 240] loss: 0.307\n",
      "[48, 300] loss: 0.308\n",
      "[48, 360] loss: 0.321\n",
      "Epoch: 48 -> Loss: 0.369885057211\n",
      "Epoch: 48 -> Test Accuracy: 87.625\n",
      "[49, 60] loss: 0.297\n",
      "[49, 120] loss: 0.304\n",
      "[49, 180] loss: 0.306\n",
      "[49, 240] loss: 0.289\n",
      "[49, 300] loss: 0.323\n",
      "[49, 360] loss: 0.312\n",
      "Epoch: 49 -> Loss: 0.206013768911\n",
      "Epoch: 49 -> Test Accuracy: 85.9825\n",
      "[50, 60] loss: 0.287\n",
      "[50, 120] loss: 0.298\n",
      "[50, 180] loss: 0.303\n",
      "[50, 240] loss: 0.310\n",
      "[50, 300] loss: 0.300\n",
      "[50, 360] loss: 0.312\n",
      "Epoch: 50 -> Loss: 0.308146715164\n",
      "Epoch: 50 -> Test Accuracy: 86.63\n",
      "[51, 60] loss: 0.307\n",
      "[51, 120] loss: 0.287\n",
      "[51, 180] loss: 0.301\n",
      "[51, 240] loss: 0.320\n",
      "[51, 300] loss: 0.304\n",
      "[51, 360] loss: 0.309\n",
      "Epoch: 51 -> Loss: 0.300403237343\n",
      "Epoch: 51 -> Test Accuracy: 87.365\n",
      "[52, 60] loss: 0.288\n",
      "[52, 120] loss: 0.280\n",
      "[52, 180] loss: 0.300\n",
      "[52, 240] loss: 0.315\n",
      "[52, 300] loss: 0.315\n",
      "[52, 360] loss: 0.318\n",
      "Epoch: 52 -> Loss: 0.342674553394\n",
      "Epoch: 52 -> Test Accuracy: 87.1525\n",
      "[53, 60] loss: 0.284\n",
      "[53, 120] loss: 0.310\n",
      "[53, 180] loss: 0.305\n",
      "[53, 240] loss: 0.310\n",
      "[53, 300] loss: 0.288\n",
      "[53, 360] loss: 0.310\n",
      "Epoch: 53 -> Loss: 0.375939935446\n",
      "Epoch: 53 -> Test Accuracy: 86.5625\n",
      "[54, 60] loss: 0.302\n",
      "[54, 120] loss: 0.296\n",
      "[54, 180] loss: 0.296\n",
      "[54, 240] loss: 0.308\n",
      "[54, 300] loss: 0.300\n",
      "[54, 360] loss: 0.301\n",
      "Epoch: 54 -> Loss: 0.229416161776\n",
      "Epoch: 54 -> Test Accuracy: 86.695\n",
      "[55, 60] loss: 0.283\n",
      "[55, 120] loss: 0.296\n",
      "[55, 180] loss: 0.308\n",
      "[55, 240] loss: 0.296\n",
      "[55, 300] loss: 0.314\n",
      "[55, 360] loss: 0.301\n",
      "Epoch: 55 -> Loss: 0.235499352217\n",
      "Epoch: 55 -> Test Accuracy: 87.3225\n",
      "[56, 60] loss: 0.287\n",
      "[56, 120] loss: 0.309\n",
      "[56, 180] loss: 0.307\n",
      "[56, 240] loss: 0.295\n",
      "[56, 300] loss: 0.295\n",
      "[56, 360] loss: 0.305\n",
      "Epoch: 56 -> Loss: 0.253729909658\n",
      "Epoch: 56 -> Test Accuracy: 87.4225\n",
      "[57, 60] loss: 0.284\n",
      "[57, 120] loss: 0.304\n",
      "[57, 180] loss: 0.301\n",
      "[57, 240] loss: 0.297\n",
      "[57, 300] loss: 0.294\n",
      "[57, 360] loss: 0.308\n",
      "Epoch: 57 -> Loss: 0.303264826536\n",
      "Epoch: 57 -> Test Accuracy: 86.205\n",
      "[58, 60] loss: 0.290\n",
      "[58, 120] loss: 0.301\n",
      "[58, 180] loss: 0.313\n",
      "[58, 240] loss: 0.296\n",
      "[58, 300] loss: 0.308\n",
      "[58, 360] loss: 0.296\n",
      "Epoch: 58 -> Loss: 0.420536756516\n",
      "Epoch: 58 -> Test Accuracy: 87.2525\n",
      "[59, 60] loss: 0.286\n",
      "[59, 120] loss: 0.275\n",
      "[59, 180] loss: 0.308\n",
      "[59, 240] loss: 0.295\n",
      "[59, 300] loss: 0.307\n",
      "[59, 360] loss: 0.303\n",
      "Epoch: 59 -> Loss: 0.208910435438\n",
      "Epoch: 59 -> Test Accuracy: 86.505\n",
      "[60, 60] loss: 0.274\n",
      "[60, 120] loss: 0.295\n",
      "[60, 180] loss: 0.307\n",
      "[60, 240] loss: 0.303\n",
      "[60, 300] loss: 0.294\n",
      "[60, 360] loss: 0.295\n",
      "Epoch: 60 -> Loss: 0.295198619366\n",
      "Epoch: 60 -> Test Accuracy: 87.195\n",
      "[61, 60] loss: 0.229\n",
      "[61, 120] loss: 0.197\n",
      "[61, 180] loss: 0.192\n",
      "[61, 240] loss: 0.182\n",
      "[61, 300] loss: 0.181\n",
      "[61, 360] loss: 0.172\n",
      "Epoch: 61 -> Loss: 0.163180410862\n",
      "Epoch: 61 -> Test Accuracy: 91.1\n",
      "[62, 60] loss: 0.160\n",
      "[62, 120] loss: 0.169\n",
      "[62, 180] loss: 0.163\n",
      "[62, 240] loss: 0.166\n",
      "[62, 300] loss: 0.172\n",
      "[62, 360] loss: 0.160\n",
      "Epoch: 62 -> Loss: 0.20783098042\n",
      "Epoch: 62 -> Test Accuracy: 90.9225\n",
      "[63, 60] loss: 0.156\n",
      "[63, 120] loss: 0.156\n",
      "[63, 180] loss: 0.151\n",
      "[63, 240] loss: 0.159\n",
      "[63, 300] loss: 0.155\n",
      "[63, 360] loss: 0.157\n",
      "Epoch: 63 -> Loss: 0.11354073137\n",
      "Epoch: 63 -> Test Accuracy: 90.845\n",
      "[64, 60] loss: 0.146\n",
      "[64, 120] loss: 0.150\n",
      "[64, 180] loss: 0.155\n",
      "[64, 240] loss: 0.154\n",
      "[64, 300] loss: 0.148\n",
      "[64, 360] loss: 0.149\n",
      "Epoch: 64 -> Loss: 0.135237962008\n",
      "Epoch: 64 -> Test Accuracy: 90.6325\n",
      "[65, 60] loss: 0.139\n",
      "[65, 120] loss: 0.149\n",
      "[65, 180] loss: 0.147\n",
      "[65, 240] loss: 0.142\n",
      "[65, 300] loss: 0.152\n",
      "[65, 360] loss: 0.153\n",
      "Epoch: 65 -> Loss: 0.104525461793\n",
      "Epoch: 65 -> Test Accuracy: 91.105\n",
      "[66, 60] loss: 0.135\n",
      "[66, 120] loss: 0.136\n",
      "[66, 180] loss: 0.146\n",
      "[66, 240] loss: 0.146\n",
      "[66, 300] loss: 0.155\n",
      "[66, 360] loss: 0.156\n",
      "Epoch: 66 -> Loss: 0.220670938492\n",
      "Epoch: 66 -> Test Accuracy: 90.91\n",
      "[67, 60] loss: 0.138\n",
      "[67, 120] loss: 0.134\n",
      "[67, 180] loss: 0.148\n",
      "[67, 240] loss: 0.145\n",
      "[67, 300] loss: 0.150\n",
      "[67, 360] loss: 0.152\n",
      "Epoch: 67 -> Loss: 0.169027552009\n",
      "Epoch: 67 -> Test Accuracy: 90.62\n",
      "[68, 60] loss: 0.132\n",
      "[68, 120] loss: 0.134\n",
      "[68, 180] loss: 0.146\n",
      "[68, 240] loss: 0.146\n",
      "[68, 300] loss: 0.148\n",
      "[68, 360] loss: 0.153\n",
      "Epoch: 68 -> Loss: 0.20659391582\n",
      "Epoch: 68 -> Test Accuracy: 90.9525\n",
      "[69, 60] loss: 0.138\n",
      "[69, 120] loss: 0.145\n",
      "[69, 180] loss: 0.145\n",
      "[69, 240] loss: 0.145\n",
      "[69, 300] loss: 0.141\n",
      "[69, 360] loss: 0.146\n",
      "Epoch: 69 -> Loss: 0.170845523477\n",
      "Epoch: 69 -> Test Accuracy: 90.125\n",
      "[70, 60] loss: 0.138\n",
      "[70, 120] loss: 0.142\n",
      "[70, 180] loss: 0.144\n",
      "[70, 240] loss: 0.148\n",
      "[70, 300] loss: 0.145\n",
      "[70, 360] loss: 0.157\n",
      "Epoch: 70 -> Loss: 0.105115845799\n",
      "Epoch: 70 -> Test Accuracy: 90.86\n",
      "[71, 60] loss: 0.132\n",
      "[71, 120] loss: 0.139\n",
      "[71, 180] loss: 0.143\n",
      "[71, 240] loss: 0.145\n",
      "[71, 300] loss: 0.156\n",
      "[71, 360] loss: 0.163\n",
      "Epoch: 71 -> Loss: 0.159091845155\n",
      "Epoch: 71 -> Test Accuracy: 90.6075\n",
      "[72, 60] loss: 0.136\n",
      "[72, 120] loss: 0.131\n",
      "[72, 180] loss: 0.142\n",
      "[72, 240] loss: 0.143\n",
      "[72, 300] loss: 0.154\n",
      "[72, 360] loss: 0.159\n",
      "Epoch: 72 -> Loss: 0.170966878533\n",
      "Epoch: 72 -> Test Accuracy: 90.805\n",
      "[73, 60] loss: 0.134\n",
      "[73, 120] loss: 0.137\n",
      "[73, 180] loss: 0.136\n",
      "[73, 240] loss: 0.144\n",
      "[73, 300] loss: 0.153\n",
      "[73, 360] loss: 0.154\n",
      "Epoch: 73 -> Loss: 0.24727961421\n",
      "Epoch: 73 -> Test Accuracy: 90.215\n",
      "[74, 60] loss: 0.140\n",
      "[74, 120] loss: 0.125\n",
      "[74, 180] loss: 0.145\n",
      "[74, 240] loss: 0.145\n",
      "[74, 300] loss: 0.151\n",
      "[74, 360] loss: 0.143\n",
      "Epoch: 74 -> Loss: 0.235743492842\n",
      "Epoch: 74 -> Test Accuracy: 90.3225\n",
      "[75, 60] loss: 0.134\n",
      "[75, 120] loss: 0.139\n",
      "[75, 180] loss: 0.139\n",
      "[75, 240] loss: 0.145\n",
      "[75, 300] loss: 0.148\n",
      "[75, 360] loss: 0.154\n",
      "Epoch: 75 -> Loss: 0.169205859303\n",
      "Epoch: 75 -> Test Accuracy: 89.925\n",
      "[76, 60] loss: 0.129\n",
      "[76, 120] loss: 0.141\n",
      "[76, 180] loss: 0.146\n",
      "[76, 240] loss: 0.146\n",
      "[76, 300] loss: 0.155\n",
      "[76, 360] loss: 0.157\n",
      "Epoch: 76 -> Loss: 0.168502181768\n",
      "Epoch: 76 -> Test Accuracy: 89.9525\n",
      "[77, 60] loss: 0.145\n",
      "[77, 120] loss: 0.142\n",
      "[77, 180] loss: 0.144\n",
      "[77, 240] loss: 0.146\n",
      "[77, 300] loss: 0.155\n",
      "[77, 360] loss: 0.145\n",
      "Epoch: 77 -> Loss: 0.121902562678\n",
      "Epoch: 77 -> Test Accuracy: 90.6125\n",
      "[78, 60] loss: 0.139\n",
      "[78, 120] loss: 0.137\n",
      "[78, 180] loss: 0.146\n",
      "[78, 240] loss: 0.146\n",
      "[78, 300] loss: 0.147\n",
      "[78, 360] loss: 0.149\n",
      "Epoch: 78 -> Loss: 0.117101036012\n",
      "Epoch: 78 -> Test Accuracy: 89.98\n",
      "[79, 60] loss: 0.126\n",
      "[79, 120] loss: 0.136\n",
      "[79, 180] loss: 0.150\n",
      "[79, 240] loss: 0.148\n",
      "[79, 300] loss: 0.155\n",
      "[79, 360] loss: 0.151\n",
      "Epoch: 79 -> Loss: 0.0923054665327\n",
      "Epoch: 79 -> Test Accuracy: 90.1925\n",
      "[80, 60] loss: 0.129\n",
      "[80, 120] loss: 0.140\n",
      "[80, 180] loss: 0.147\n",
      "[80, 240] loss: 0.148\n",
      "[80, 300] loss: 0.147\n",
      "[80, 360] loss: 0.155\n",
      "Epoch: 80 -> Loss: 0.133571043611\n",
      "Epoch: 80 -> Test Accuracy: 89.825\n",
      "[81, 60] loss: 0.137\n",
      "[81, 120] loss: 0.149\n",
      "[81, 180] loss: 0.142\n",
      "[81, 240] loss: 0.152\n",
      "[81, 300] loss: 0.147\n",
      "[81, 360] loss: 0.151\n",
      "Epoch: 81 -> Loss: 0.126559302211\n",
      "Epoch: 81 -> Test Accuracy: 90.37\n",
      "[82, 60] loss: 0.137\n",
      "[82, 120] loss: 0.148\n",
      "[82, 180] loss: 0.139\n",
      "[82, 240] loss: 0.144\n",
      "[82, 300] loss: 0.145\n",
      "[82, 360] loss: 0.143\n",
      "Epoch: 82 -> Loss: 0.124077871442\n",
      "Epoch: 82 -> Test Accuracy: 90.4975\n",
      "[83, 60] loss: 0.137\n",
      "[83, 120] loss: 0.139\n",
      "[83, 180] loss: 0.140\n",
      "[83, 240] loss: 0.153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83, 300] loss: 0.155\n",
      "[83, 360] loss: 0.140\n",
      "Epoch: 83 -> Loss: 0.160976886749\n",
      "Epoch: 83 -> Test Accuracy: 90.515\n",
      "[84, 60] loss: 0.149\n",
      "[84, 120] loss: 0.139\n",
      "[84, 180] loss: 0.143\n",
      "[84, 240] loss: 0.139\n",
      "[84, 300] loss: 0.144\n",
      "[84, 360] loss: 0.149\n",
      "Epoch: 84 -> Loss: 0.186266094446\n",
      "Epoch: 84 -> Test Accuracy: 90.5325\n",
      "[85, 60] loss: 0.132\n",
      "[85, 120] loss: 0.140\n",
      "[85, 180] loss: 0.134\n",
      "[85, 240] loss: 0.145\n",
      "[85, 300] loss: 0.147\n",
      "[85, 360] loss: 0.155\n",
      "Epoch: 85 -> Loss: 0.0835645273328\n",
      "Epoch: 85 -> Test Accuracy: 90.285\n",
      "[86, 60] loss: 0.137\n",
      "[86, 120] loss: 0.141\n",
      "[86, 180] loss: 0.141\n",
      "[86, 240] loss: 0.144\n",
      "[86, 300] loss: 0.145\n",
      "[86, 360] loss: 0.151\n",
      "Epoch: 86 -> Loss: 0.101553142071\n",
      "Epoch: 86 -> Test Accuracy: 90.3825\n",
      "[87, 60] loss: 0.137\n",
      "[87, 120] loss: 0.133\n",
      "[87, 180] loss: 0.130\n",
      "[87, 240] loss: 0.142\n",
      "[87, 300] loss: 0.142\n",
      "[87, 360] loss: 0.156\n",
      "Epoch: 87 -> Loss: 0.144443869591\n",
      "Epoch: 87 -> Test Accuracy: 90.5825\n",
      "[88, 60] loss: 0.129\n",
      "[88, 120] loss: 0.130\n",
      "[88, 180] loss: 0.143\n",
      "[88, 240] loss: 0.142\n",
      "[88, 300] loss: 0.151\n",
      "[88, 360] loss: 0.146\n",
      "Epoch: 88 -> Loss: 0.175868347287\n",
      "Epoch: 88 -> Test Accuracy: 90.5375\n",
      "[89, 60] loss: 0.126\n",
      "[89, 120] loss: 0.129\n",
      "[89, 180] loss: 0.141\n",
      "[89, 240] loss: 0.145\n",
      "[89, 300] loss: 0.144\n",
      "[89, 360] loss: 0.148\n",
      "Epoch: 89 -> Loss: 0.208842486143\n",
      "Epoch: 89 -> Test Accuracy: 90.205\n",
      "[90, 60] loss: 0.136\n",
      "[90, 120] loss: 0.139\n",
      "[90, 180] loss: 0.133\n",
      "[90, 240] loss: 0.143\n",
      "[90, 300] loss: 0.144\n",
      "[90, 360] loss: 0.154\n",
      "Epoch: 90 -> Loss: 0.19092489779\n",
      "Epoch: 90 -> Test Accuracy: 90.495\n",
      "[91, 60] loss: 0.125\n",
      "[91, 120] loss: 0.131\n",
      "[91, 180] loss: 0.148\n",
      "[91, 240] loss: 0.143\n",
      "[91, 300] loss: 0.143\n",
      "[91, 360] loss: 0.151\n",
      "Epoch: 91 -> Loss: 0.141488984227\n",
      "Epoch: 91 -> Test Accuracy: 90.1225\n",
      "[92, 60] loss: 0.130\n",
      "[92, 120] loss: 0.130\n",
      "[92, 180] loss: 0.141\n",
      "[92, 240] loss: 0.140\n",
      "[92, 300] loss: 0.146\n",
      "[92, 360] loss: 0.144\n",
      "Epoch: 92 -> Loss: 0.220425933599\n",
      "Epoch: 92 -> Test Accuracy: 90.195\n",
      "[93, 60] loss: 0.133\n",
      "[93, 120] loss: 0.133\n",
      "[93, 180] loss: 0.140\n",
      "[93, 240] loss: 0.148\n",
      "[93, 300] loss: 0.140\n",
      "[93, 360] loss: 0.145\n",
      "Epoch: 93 -> Loss: 0.132628396153\n",
      "Epoch: 93 -> Test Accuracy: 90.19\n",
      "[94, 60] loss: 0.123\n",
      "[94, 120] loss: 0.133\n",
      "[94, 180] loss: 0.140\n",
      "[94, 240] loss: 0.147\n",
      "[94, 300] loss: 0.141\n",
      "[94, 360] loss: 0.150\n",
      "Epoch: 94 -> Loss: 0.104115106165\n",
      "Epoch: 94 -> Test Accuracy: 90.475\n",
      "[95, 60] loss: 0.124\n",
      "[95, 120] loss: 0.133\n",
      "[95, 180] loss: 0.135\n",
      "[95, 240] loss: 0.139\n",
      "[95, 300] loss: 0.144\n",
      "[95, 360] loss: 0.148\n",
      "Epoch: 95 -> Loss: 0.226073861122\n",
      "Epoch: 95 -> Test Accuracy: 90.2525\n",
      "[96, 60] loss: 0.122\n",
      "[96, 120] loss: 0.145\n",
      "[96, 180] loss: 0.140\n",
      "[96, 240] loss: 0.127\n",
      "[96, 300] loss: 0.143\n",
      "[96, 360] loss: 0.135\n",
      "Epoch: 96 -> Loss: 0.174596995115\n",
      "Epoch: 96 -> Test Accuracy: 90.245\n",
      "[97, 60] loss: 0.128\n",
      "[97, 120] loss: 0.131\n",
      "[97, 180] loss: 0.142\n",
      "[97, 240] loss: 0.142\n",
      "[97, 300] loss: 0.140\n",
      "[97, 360] loss: 0.149\n",
      "Epoch: 97 -> Loss: 0.171282857656\n",
      "Epoch: 97 -> Test Accuracy: 90.0875\n",
      "[98, 60] loss: 0.130\n",
      "[98, 120] loss: 0.134\n",
      "[98, 180] loss: 0.131\n",
      "[98, 240] loss: 0.141\n",
      "[98, 300] loss: 0.146\n",
      "[98, 360] loss: 0.140\n",
      "Epoch: 98 -> Loss: 0.133102506399\n",
      "Epoch: 98 -> Test Accuracy: 90.195\n",
      "[99, 60] loss: 0.125\n",
      "[99, 120] loss: 0.132\n",
      "[99, 180] loss: 0.137\n",
      "[99, 240] loss: 0.140\n",
      "[99, 300] loss: 0.133\n",
      "[99, 360] loss: 0.149\n",
      "Epoch: 99 -> Loss: 0.156955257058\n",
      "Epoch: 99 -> Test Accuracy: 90.4825\n",
      "[100, 60] loss: 0.134\n",
      "[100, 120] loss: 0.133\n",
      "[100, 180] loss: 0.134\n",
      "[100, 240] loss: 0.136\n",
      "[100, 300] loss: 0.140\n",
      "[100, 360] loss: 0.143\n",
      "Epoch: 100 -> Loss: 0.196525841951\n",
      "Epoch: 100 -> Test Accuracy: 90.8425\n",
      "[101, 60] loss: 0.120\n",
      "[101, 120] loss: 0.127\n",
      "[101, 180] loss: 0.130\n",
      "[101, 240] loss: 0.137\n",
      "[101, 300] loss: 0.148\n",
      "[101, 360] loss: 0.142\n",
      "Epoch: 101 -> Loss: 0.18456146121\n",
      "Epoch: 101 -> Test Accuracy: 90.5575\n",
      "[102, 60] loss: 0.129\n",
      "[102, 120] loss: 0.129\n",
      "[102, 180] loss: 0.138\n",
      "[102, 240] loss: 0.137\n",
      "[102, 300] loss: 0.142\n",
      "[102, 360] loss: 0.142\n",
      "Epoch: 102 -> Loss: 0.154760733247\n",
      "Epoch: 102 -> Test Accuracy: 90.035\n",
      "[103, 60] loss: 0.130\n",
      "[103, 120] loss: 0.135\n",
      "[103, 180] loss: 0.135\n",
      "[103, 240] loss: 0.140\n",
      "[103, 300] loss: 0.134\n",
      "[103, 360] loss: 0.136\n",
      "Epoch: 103 -> Loss: 0.139910846949\n",
      "Epoch: 103 -> Test Accuracy: 90.185\n",
      "[104, 60] loss: 0.127\n",
      "[104, 120] loss: 0.132\n",
      "[104, 180] loss: 0.141\n",
      "[104, 240] loss: 0.133\n",
      "[104, 300] loss: 0.137\n",
      "[104, 360] loss: 0.138\n",
      "Epoch: 104 -> Loss: 0.214849710464\n",
      "Epoch: 104 -> Test Accuracy: 90.3625\n",
      "[105, 60] loss: 0.121\n",
      "[105, 120] loss: 0.122\n",
      "[105, 180] loss: 0.134\n",
      "[105, 240] loss: 0.144\n",
      "[105, 300] loss: 0.136\n",
      "[105, 360] loss: 0.139\n",
      "Epoch: 105 -> Loss: 0.222901269794\n",
      "Epoch: 105 -> Test Accuracy: 90.2525\n",
      "[106, 60] loss: 0.130\n",
      "[106, 120] loss: 0.135\n",
      "[106, 180] loss: 0.136\n",
      "[106, 240] loss: 0.133\n",
      "[106, 300] loss: 0.132\n",
      "[106, 360] loss: 0.139\n",
      "Epoch: 106 -> Loss: 0.109510205686\n",
      "Epoch: 106 -> Test Accuracy: 89.87\n",
      "[107, 60] loss: 0.121\n",
      "[107, 120] loss: 0.126\n",
      "[107, 180] loss: 0.126\n",
      "[107, 240] loss: 0.144\n",
      "[107, 300] loss: 0.148\n",
      "[107, 360] loss: 0.131\n",
      "Epoch: 107 -> Loss: 0.149783536792\n",
      "Epoch: 107 -> Test Accuracy: 90.1725\n",
      "[108, 60] loss: 0.128\n",
      "[108, 120] loss: 0.131\n",
      "[108, 180] loss: 0.129\n",
      "[108, 240] loss: 0.131\n",
      "[108, 300] loss: 0.131\n",
      "[108, 360] loss: 0.143\n",
      "Epoch: 108 -> Loss: 0.196491256356\n",
      "Epoch: 108 -> Test Accuracy: 90.68\n",
      "[109, 60] loss: 0.132\n",
      "[109, 120] loss: 0.128\n",
      "[109, 180] loss: 0.134\n",
      "[109, 240] loss: 0.128\n",
      "[109, 300] loss: 0.138\n",
      "[109, 360] loss: 0.139\n",
      "Epoch: 109 -> Loss: 0.161980122328\n",
      "Epoch: 109 -> Test Accuracy: 90.395\n",
      "[110, 60] loss: 0.123\n",
      "[110, 120] loss: 0.131\n",
      "[110, 180] loss: 0.131\n",
      "[110, 240] loss: 0.132\n",
      "[110, 300] loss: 0.141\n",
      "[110, 360] loss: 0.136\n",
      "Epoch: 110 -> Loss: 0.207882672548\n",
      "Epoch: 110 -> Test Accuracy: 90.47\n",
      "[111, 60] loss: 0.122\n",
      "[111, 120] loss: 0.129\n",
      "[111, 180] loss: 0.129\n",
      "[111, 240] loss: 0.135\n",
      "[111, 300] loss: 0.132\n",
      "[111, 360] loss: 0.144\n",
      "Epoch: 111 -> Loss: 0.236293151975\n",
      "Epoch: 111 -> Test Accuracy: 90.665\n",
      "[112, 60] loss: 0.122\n",
      "[112, 120] loss: 0.136\n",
      "[112, 180] loss: 0.132\n",
      "[112, 240] loss: 0.126\n",
      "[112, 300] loss: 0.135\n",
      "[112, 360] loss: 0.135\n",
      "Epoch: 112 -> Loss: 0.120939038694\n",
      "Epoch: 112 -> Test Accuracy: 90.03\n",
      "[113, 60] loss: 0.125\n",
      "[113, 120] loss: 0.128\n",
      "[113, 180] loss: 0.131\n",
      "[113, 240] loss: 0.139\n",
      "[113, 300] loss: 0.145\n",
      "[113, 360] loss: 0.137\n",
      "Epoch: 113 -> Loss: 0.19746054709\n",
      "Epoch: 113 -> Test Accuracy: 89.8175\n",
      "[114, 60] loss: 0.126\n",
      "[114, 120] loss: 0.123\n",
      "[114, 180] loss: 0.136\n",
      "[114, 240] loss: 0.132\n",
      "[114, 300] loss: 0.132\n",
      "[114, 360] loss: 0.131\n",
      "Epoch: 114 -> Loss: 0.161271959543\n",
      "Epoch: 114 -> Test Accuracy: 90.5275\n",
      "[115, 60] loss: 0.126\n",
      "[115, 120] loss: 0.123\n",
      "[115, 180] loss: 0.130\n",
      "[115, 240] loss: 0.132\n",
      "[115, 300] loss: 0.137\n",
      "[115, 360] loss: 0.142\n",
      "Epoch: 115 -> Loss: 0.1763882339\n",
      "Epoch: 115 -> Test Accuracy: 90.68\n",
      "[116, 60] loss: 0.125\n",
      "[116, 120] loss: 0.128\n",
      "[116, 180] loss: 0.134\n",
      "[116, 240] loss: 0.125\n",
      "[116, 300] loss: 0.132\n",
      "[116, 360] loss: 0.141\n",
      "Epoch: 116 -> Loss: 0.122055873275\n",
      "Epoch: 116 -> Test Accuracy: 90.83\n",
      "[117, 60] loss: 0.120\n",
      "[117, 120] loss: 0.123\n",
      "[117, 180] loss: 0.131\n",
      "[117, 240] loss: 0.129\n",
      "[117, 300] loss: 0.145\n",
      "[117, 360] loss: 0.136\n",
      "Epoch: 117 -> Loss: 0.091814443469\n",
      "Epoch: 117 -> Test Accuracy: 90.61\n",
      "[118, 60] loss: 0.118\n",
      "[118, 120] loss: 0.127\n",
      "[118, 180] loss: 0.138\n",
      "[118, 240] loss: 0.128\n",
      "[118, 300] loss: 0.131\n",
      "[118, 360] loss: 0.140\n",
      "Epoch: 118 -> Loss: 0.106722377241\n",
      "Epoch: 118 -> Test Accuracy: 90.7875\n",
      "[119, 60] loss: 0.116\n",
      "[119, 120] loss: 0.121\n",
      "[119, 180] loss: 0.133\n",
      "[119, 240] loss: 0.135\n",
      "[119, 300] loss: 0.140\n",
      "[119, 360] loss: 0.134\n",
      "Epoch: 119 -> Loss: 0.137277960777\n",
      "Epoch: 119 -> Test Accuracy: 90.5225\n",
      "[120, 60] loss: 0.127\n",
      "[120, 120] loss: 0.119\n",
      "[120, 180] loss: 0.130\n",
      "[120, 240] loss: 0.123\n",
      "[120, 300] loss: 0.129\n",
      "[120, 360] loss: 0.132\n",
      "Epoch: 120 -> Loss: 0.239175513387\n",
      "Epoch: 120 -> Test Accuracy: 90.3025\n",
      "[121, 60] loss: 0.092\n",
      "[121, 120] loss: 0.070\n",
      "[121, 180] loss: 0.075\n",
      "[121, 240] loss: 0.060\n",
      "[121, 300] loss: 0.069\n",
      "[121, 360] loss: 0.067\n",
      "Epoch: 121 -> Loss: 0.0414118692279\n",
      "Epoch: 121 -> Test Accuracy: 92.2125\n",
      "[122, 60] loss: 0.053\n",
      "[122, 120] loss: 0.053\n",
      "[122, 180] loss: 0.056\n",
      "[122, 240] loss: 0.052\n",
      "[122, 300] loss: 0.051\n",
      "[122, 360] loss: 0.051\n",
      "Epoch: 122 -> Loss: 0.0465137287974\n",
      "Epoch: 122 -> Test Accuracy: 92.355\n",
      "[123, 60] loss: 0.048\n",
      "[123, 120] loss: 0.047\n",
      "[123, 180] loss: 0.051\n",
      "[123, 240] loss: 0.044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123, 300] loss: 0.050\n",
      "[123, 360] loss: 0.045\n",
      "Epoch: 123 -> Loss: 0.0176722593606\n",
      "Epoch: 123 -> Test Accuracy: 92.405\n",
      "[124, 60] loss: 0.043\n",
      "[124, 120] loss: 0.041\n",
      "[124, 180] loss: 0.037\n",
      "[124, 240] loss: 0.043\n",
      "[124, 300] loss: 0.048\n",
      "[124, 360] loss: 0.046\n",
      "Epoch: 124 -> Loss: 0.0730856657028\n",
      "Epoch: 124 -> Test Accuracy: 92.19\n",
      "[125, 60] loss: 0.042\n",
      "[125, 120] loss: 0.041\n",
      "[125, 180] loss: 0.039\n",
      "[125, 240] loss: 0.040\n",
      "[125, 300] loss: 0.040\n",
      "[125, 360] loss: 0.038\n",
      "Epoch: 125 -> Loss: 0.0580299980938\n",
      "Epoch: 125 -> Test Accuracy: 92.285\n",
      "[126, 60] loss: 0.038\n",
      "[126, 120] loss: 0.037\n",
      "[126, 180] loss: 0.034\n",
      "[126, 240] loss: 0.036\n",
      "[126, 300] loss: 0.039\n",
      "[126, 360] loss: 0.036\n",
      "Epoch: 126 -> Loss: 0.0462010279298\n",
      "Epoch: 126 -> Test Accuracy: 92.1875\n",
      "[127, 60] loss: 0.034\n",
      "[127, 120] loss: 0.032\n",
      "[127, 180] loss: 0.035\n",
      "[127, 240] loss: 0.033\n",
      "[127, 300] loss: 0.037\n",
      "[127, 360] loss: 0.037\n",
      "Epoch: 127 -> Loss: 0.024158809334\n",
      "Epoch: 127 -> Test Accuracy: 91.94\n",
      "[128, 60] loss: 0.032\n",
      "[128, 120] loss: 0.034\n",
      "[128, 180] loss: 0.029\n",
      "[128, 240] loss: 0.035\n",
      "[128, 300] loss: 0.035\n",
      "[128, 360] loss: 0.032\n",
      "Epoch: 128 -> Loss: 0.0421493314207\n",
      "Epoch: 128 -> Test Accuracy: 92.0325\n",
      "[129, 60] loss: 0.031\n",
      "[129, 120] loss: 0.030\n",
      "[129, 180] loss: 0.031\n",
      "[129, 240] loss: 0.032\n",
      "[129, 300] loss: 0.030\n",
      "[129, 360] loss: 0.034\n",
      "Epoch: 129 -> Loss: 0.0303374230862\n",
      "Epoch: 129 -> Test Accuracy: 92.245\n",
      "[130, 60] loss: 0.027\n",
      "[130, 120] loss: 0.031\n",
      "[130, 180] loss: 0.032\n",
      "[130, 240] loss: 0.030\n",
      "[130, 300] loss: 0.032\n",
      "[130, 360] loss: 0.032\n",
      "Epoch: 130 -> Loss: 0.0399531796575\n",
      "Epoch: 130 -> Test Accuracy: 92.2975\n",
      "[131, 60] loss: 0.030\n",
      "[131, 120] loss: 0.028\n",
      "[131, 180] loss: 0.031\n",
      "[131, 240] loss: 0.030\n",
      "[131, 300] loss: 0.029\n",
      "[131, 360] loss: 0.031\n",
      "Epoch: 131 -> Loss: 0.0265237875283\n",
      "Epoch: 131 -> Test Accuracy: 92.135\n",
      "[132, 60] loss: 0.026\n",
      "[132, 120] loss: 0.026\n",
      "[132, 180] loss: 0.030\n",
      "[132, 240] loss: 0.029\n",
      "[132, 300] loss: 0.027\n",
      "[132, 360] loss: 0.031\n",
      "Epoch: 132 -> Loss: 0.0427924767137\n",
      "Epoch: 132 -> Test Accuracy: 92.225\n",
      "[133, 60] loss: 0.025\n",
      "[133, 120] loss: 0.025\n",
      "[133, 180] loss: 0.026\n",
      "[133, 240] loss: 0.026\n",
      "[133, 300] loss: 0.026\n",
      "[133, 360] loss: 0.028\n",
      "Epoch: 133 -> Loss: 0.02478871122\n",
      "Epoch: 133 -> Test Accuracy: 92.195\n",
      "[134, 60] loss: 0.025\n",
      "[134, 120] loss: 0.024\n",
      "[134, 180] loss: 0.028\n",
      "[134, 240] loss: 0.029\n",
      "[134, 300] loss: 0.029\n",
      "[134, 360] loss: 0.028\n",
      "Epoch: 134 -> Loss: 0.036567799747\n",
      "Epoch: 134 -> Test Accuracy: 92.285\n",
      "[135, 60] loss: 0.024\n",
      "[135, 120] loss: 0.026\n",
      "[135, 180] loss: 0.027\n",
      "[135, 240] loss: 0.025\n",
      "[135, 300] loss: 0.032\n",
      "[135, 360] loss: 0.031\n",
      "Epoch: 135 -> Loss: 0.039122056216\n",
      "Epoch: 135 -> Test Accuracy: 92.08\n",
      "[136, 60] loss: 0.027\n",
      "[136, 120] loss: 0.025\n",
      "[136, 180] loss: 0.027\n",
      "[136, 240] loss: 0.025\n",
      "[136, 300] loss: 0.030\n",
      "[136, 360] loss: 0.027\n",
      "Epoch: 136 -> Loss: 0.0136552285403\n",
      "Epoch: 136 -> Test Accuracy: 91.915\n",
      "[137, 60] loss: 0.023\n",
      "[137, 120] loss: 0.025\n",
      "[137, 180] loss: 0.027\n",
      "[137, 240] loss: 0.027\n",
      "[137, 300] loss: 0.026\n",
      "[137, 360] loss: 0.029\n",
      "Epoch: 137 -> Loss: 0.0468509532511\n",
      "Epoch: 137 -> Test Accuracy: 91.9725\n",
      "[138, 60] loss: 0.024\n",
      "[138, 120] loss: 0.024\n",
      "[138, 180] loss: 0.025\n",
      "[138, 240] loss: 0.025\n",
      "[138, 300] loss: 0.029\n",
      "[138, 360] loss: 0.027\n",
      "Epoch: 138 -> Loss: 0.0221829675138\n",
      "Epoch: 138 -> Test Accuracy: 92.1475\n",
      "[139, 60] loss: 0.024\n",
      "[139, 120] loss: 0.025\n",
      "[139, 180] loss: 0.024\n",
      "[139, 240] loss: 0.026\n",
      "[139, 300] loss: 0.026\n",
      "[139, 360] loss: 0.028\n",
      "Epoch: 139 -> Loss: 0.0304140113294\n",
      "Epoch: 139 -> Test Accuracy: 91.9225\n",
      "[140, 60] loss: 0.024\n",
      "[140, 120] loss: 0.024\n",
      "[140, 180] loss: 0.022\n",
      "[140, 240] loss: 0.028\n",
      "[140, 300] loss: 0.027\n",
      "[140, 360] loss: 0.025\n",
      "Epoch: 140 -> Loss: 0.0396079309285\n",
      "Epoch: 140 -> Test Accuracy: 91.935\n",
      "[141, 60] loss: 0.021\n",
      "[141, 120] loss: 0.025\n",
      "[141, 180] loss: 0.021\n",
      "[141, 240] loss: 0.026\n",
      "[141, 300] loss: 0.026\n",
      "[141, 360] loss: 0.025\n",
      "Epoch: 141 -> Loss: 0.0185330659151\n",
      "Epoch: 141 -> Test Accuracy: 92.0725\n",
      "[142, 60] loss: 0.024\n",
      "[142, 120] loss: 0.022\n",
      "[142, 180] loss: 0.025\n",
      "[142, 240] loss: 0.024\n",
      "[142, 300] loss: 0.025\n",
      "[142, 360] loss: 0.025\n",
      "Epoch: 142 -> Loss: 0.0451101586223\n",
      "Epoch: 142 -> Test Accuracy: 91.7775\n",
      "[143, 60] loss: 0.024\n",
      "[143, 120] loss: 0.024\n",
      "[143, 180] loss: 0.024\n",
      "[143, 240] loss: 0.023\n",
      "[143, 300] loss: 0.025\n",
      "[143, 360] loss: 0.023\n",
      "Epoch: 143 -> Loss: 0.0164500325918\n",
      "Epoch: 143 -> Test Accuracy: 91.88\n",
      "[144, 60] loss: 0.024\n",
      "[144, 120] loss: 0.025\n",
      "[144, 180] loss: 0.024\n",
      "[144, 240] loss: 0.025\n",
      "[144, 300] loss: 0.024\n",
      "[144, 360] loss: 0.024\n",
      "Epoch: 144 -> Loss: 0.0135100949556\n",
      "Epoch: 144 -> Test Accuracy: 91.7675\n",
      "[145, 60] loss: 0.024\n",
      "[145, 120] loss: 0.024\n",
      "[145, 180] loss: 0.024\n",
      "[145, 240] loss: 0.025\n",
      "[145, 300] loss: 0.024\n",
      "[145, 360] loss: 0.027\n",
      "Epoch: 145 -> Loss: 0.0363136902452\n",
      "Epoch: 145 -> Test Accuracy: 91.9625\n",
      "[146, 60] loss: 0.020\n",
      "[146, 120] loss: 0.023\n",
      "[146, 180] loss: 0.023\n",
      "[146, 240] loss: 0.022\n",
      "[146, 300] loss: 0.026\n",
      "[146, 360] loss: 0.029\n",
      "Epoch: 146 -> Loss: 0.0386595949531\n",
      "Epoch: 146 -> Test Accuracy: 91.91\n",
      "[147, 60] loss: 0.023\n",
      "[147, 120] loss: 0.024\n",
      "[147, 180] loss: 0.021\n",
      "[147, 240] loss: 0.023\n",
      "[147, 300] loss: 0.025\n",
      "[147, 360] loss: 0.025\n",
      "Epoch: 147 -> Loss: 0.0167467650026\n",
      "Epoch: 147 -> Test Accuracy: 92.04\n",
      "[148, 60] loss: 0.024\n",
      "[148, 120] loss: 0.022\n",
      "[148, 180] loss: 0.023\n",
      "[148, 240] loss: 0.024\n",
      "[148, 300] loss: 0.029\n",
      "[148, 360] loss: 0.025\n",
      "Epoch: 148 -> Loss: 0.0421693250537\n",
      "Epoch: 148 -> Test Accuracy: 91.8925\n",
      "[149, 60] loss: 0.021\n",
      "[149, 120] loss: 0.023\n",
      "[149, 180] loss: 0.023\n",
      "[149, 240] loss: 0.022\n",
      "[149, 300] loss: 0.026\n",
      "[149, 360] loss: 0.024\n",
      "Epoch: 149 -> Loss: 0.0438509173691\n",
      "Epoch: 149 -> Test Accuracy: 91.8975\n",
      "[150, 60] loss: 0.023\n",
      "[150, 120] loss: 0.024\n",
      "[150, 180] loss: 0.023\n",
      "[150, 240] loss: 0.024\n",
      "[150, 300] loss: 0.026\n",
      "[150, 360] loss: 0.026\n",
      "Epoch: 150 -> Loss: 0.0104505633935\n",
      "Epoch: 150 -> Test Accuracy: 91.965\n",
      "[151, 60] loss: 0.021\n",
      "[151, 120] loss: 0.023\n",
      "[151, 180] loss: 0.022\n",
      "[151, 240] loss: 0.023\n",
      "[151, 300] loss: 0.027\n",
      "[151, 360] loss: 0.024\n",
      "Epoch: 151 -> Loss: 0.0231580324471\n",
      "Epoch: 151 -> Test Accuracy: 91.7775\n",
      "[152, 60] loss: 0.024\n",
      "[152, 120] loss: 0.021\n",
      "[152, 180] loss: 0.021\n",
      "[152, 240] loss: 0.025\n",
      "[152, 300] loss: 0.024\n",
      "[152, 360] loss: 0.026\n",
      "Epoch: 152 -> Loss: 0.0205424427986\n",
      "Epoch: 152 -> Test Accuracy: 91.9025\n",
      "[153, 60] loss: 0.024\n",
      "[153, 120] loss: 0.024\n",
      "[153, 180] loss: 0.023\n",
      "[153, 240] loss: 0.022\n",
      "[153, 300] loss: 0.024\n",
      "[153, 360] loss: 0.025\n",
      "Epoch: 153 -> Loss: 0.0380544066429\n",
      "Epoch: 153 -> Test Accuracy: 91.83\n",
      "[154, 60] loss: 0.023\n",
      "[154, 120] loss: 0.023\n",
      "[154, 180] loss: 0.026\n",
      "[154, 240] loss: 0.024\n",
      "[154, 300] loss: 0.028\n",
      "[154, 360] loss: 0.024\n",
      "Epoch: 154 -> Loss: 0.0289457179606\n",
      "Epoch: 154 -> Test Accuracy: 91.7375\n",
      "[155, 60] loss: 0.022\n",
      "[155, 120] loss: 0.022\n",
      "[155, 180] loss: 0.026\n",
      "[155, 240] loss: 0.027\n",
      "[155, 300] loss: 0.026\n",
      "[155, 360] loss: 0.027\n",
      "Epoch: 155 -> Loss: 0.024421511218\n",
      "Epoch: 155 -> Test Accuracy: 91.7925\n",
      "[156, 60] loss: 0.024\n",
      "[156, 120] loss: 0.023\n",
      "[156, 180] loss: 0.024\n",
      "[156, 240] loss: 0.023\n",
      "[156, 300] loss: 0.026\n",
      "[156, 360] loss: 0.026\n",
      "Epoch: 156 -> Loss: 0.0266290605068\n",
      "Epoch: 156 -> Test Accuracy: 91.6575\n",
      "[157, 60] loss: 0.023\n",
      "[157, 120] loss: 0.024\n",
      "[157, 180] loss: 0.024\n",
      "[157, 240] loss: 0.024\n",
      "[157, 300] loss: 0.026\n",
      "[157, 360] loss: 0.024\n",
      "Epoch: 157 -> Loss: 0.0462897717953\n",
      "Epoch: 157 -> Test Accuracy: 91.8825\n",
      "[158, 60] loss: 0.023\n",
      "[158, 120] loss: 0.026\n",
      "[158, 180] loss: 0.025\n",
      "[158, 240] loss: 0.030\n",
      "[158, 300] loss: 0.028\n",
      "[158, 360] loss: 0.028\n",
      "Epoch: 158 -> Loss: 0.0148620530963\n",
      "Epoch: 158 -> Test Accuracy: 91.775\n",
      "[159, 60] loss: 0.022\n",
      "[159, 120] loss: 0.022\n",
      "[159, 180] loss: 0.025\n",
      "[159, 240] loss: 0.023\n",
      "[159, 300] loss: 0.025\n",
      "[159, 360] loss: 0.027\n",
      "Epoch: 159 -> Loss: 0.0128344995901\n",
      "Epoch: 159 -> Test Accuracy: 91.5875\n",
      "[160, 60] loss: 0.024\n",
      "[160, 120] loss: 0.024\n",
      "[160, 180] loss: 0.025\n",
      "[160, 240] loss: 0.024\n",
      "[160, 300] loss: 0.025\n",
      "[160, 360] loss: 0.029\n",
      "Epoch: 160 -> Loss: 0.0351010076702\n",
      "Epoch: 160 -> Test Accuracy: 91.72\n",
      "[161, 60] loss: 0.018\n",
      "[161, 120] loss: 0.019\n",
      "[161, 180] loss: 0.017\n",
      "[161, 240] loss: 0.016\n",
      "[161, 300] loss: 0.015\n",
      "[161, 360] loss: 0.015\n",
      "Epoch: 161 -> Loss: 0.00295136054046\n",
      "Epoch: 161 -> Test Accuracy: 92.2825\n",
      "[162, 60] loss: 0.011\n",
      "[162, 120] loss: 0.014\n",
      "[162, 180] loss: 0.011\n",
      "[162, 240] loss: 0.012\n",
      "[162, 300] loss: 0.011\n",
      "[162, 360] loss: 0.012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 162 -> Loss: 0.01083238516\n",
      "Epoch: 162 -> Test Accuracy: 92.365\n",
      "[163, 60] loss: 0.011\n",
      "[163, 120] loss: 0.011\n",
      "[163, 180] loss: 0.010\n",
      "[163, 240] loss: 0.011\n",
      "[163, 300] loss: 0.010\n",
      "[163, 360] loss: 0.011\n",
      "Epoch: 163 -> Loss: 0.00581384962425\n",
      "Epoch: 163 -> Test Accuracy: 92.3975\n",
      "[164, 60] loss: 0.010\n",
      "[164, 120] loss: 0.009\n",
      "[164, 180] loss: 0.010\n",
      "[164, 240] loss: 0.011\n",
      "[164, 300] loss: 0.011\n",
      "[164, 360] loss: 0.010\n",
      "Epoch: 164 -> Loss: 0.0135562168434\n",
      "Epoch: 164 -> Test Accuracy: 92.375\n",
      "[165, 60] loss: 0.010\n",
      "[165, 120] loss: 0.009\n",
      "[165, 180] loss: 0.010\n",
      "[165, 240] loss: 0.009\n",
      "[165, 300] loss: 0.009\n",
      "[165, 360] loss: 0.010\n",
      "Epoch: 165 -> Loss: 0.00747787486762\n",
      "Epoch: 165 -> Test Accuracy: 92.3925\n",
      "[166, 60] loss: 0.008\n",
      "[166, 120] loss: 0.010\n",
      "[166, 180] loss: 0.009\n",
      "[166, 240] loss: 0.008\n",
      "[166, 300] loss: 0.009\n",
      "[166, 360] loss: 0.008\n",
      "Epoch: 166 -> Loss: 0.0250803176314\n",
      "Epoch: 166 -> Test Accuracy: 92.3425\n",
      "[167, 60] loss: 0.008\n",
      "[167, 120] loss: 0.009\n",
      "[167, 180] loss: 0.009\n",
      "[167, 240] loss: 0.009\n",
      "[167, 300] loss: 0.008\n",
      "[167, 360] loss: 0.009\n",
      "Epoch: 167 -> Loss: 0.00682273413986\n",
      "Epoch: 167 -> Test Accuracy: 92.38\n",
      "[168, 60] loss: 0.009\n",
      "[168, 120] loss: 0.008\n",
      "[168, 180] loss: 0.009\n",
      "[168, 240] loss: 0.008\n",
      "[168, 300] loss: 0.008\n",
      "[168, 360] loss: 0.009\n",
      "Epoch: 168 -> Loss: 0.00138089875691\n",
      "Epoch: 168 -> Test Accuracy: 92.2725\n",
      "[169, 60] loss: 0.008\n",
      "[169, 120] loss: 0.007\n",
      "[169, 180] loss: 0.008\n",
      "[169, 240] loss: 0.007\n",
      "[169, 300] loss: 0.009\n",
      "[169, 360] loss: 0.008\n",
      "Epoch: 169 -> Loss: 0.00959970802069\n",
      "Epoch: 169 -> Test Accuracy: 92.3525\n",
      "[170, 60] loss: 0.007\n",
      "[170, 120] loss: 0.007\n",
      "[170, 180] loss: 0.007\n",
      "[170, 240] loss: 0.009\n",
      "[170, 300] loss: 0.008\n",
      "[170, 360] loss: 0.008\n",
      "Epoch: 170 -> Loss: 0.0142380241305\n",
      "Epoch: 170 -> Test Accuracy: 92.38\n",
      "[171, 60] loss: 0.007\n",
      "[171, 120] loss: 0.007\n",
      "[171, 180] loss: 0.008\n",
      "[171, 240] loss: 0.007\n",
      "[171, 300] loss: 0.008\n",
      "[171, 360] loss: 0.008\n",
      "Epoch: 171 -> Loss: 0.00682640541345\n",
      "Epoch: 171 -> Test Accuracy: 92.3675\n",
      "[172, 60] loss: 0.007\n",
      "[172, 120] loss: 0.007\n",
      "[172, 180] loss: 0.007\n",
      "[172, 240] loss: 0.007\n",
      "[172, 300] loss: 0.007\n",
      "[172, 360] loss: 0.007\n",
      "Epoch: 172 -> Loss: 0.00365952262655\n",
      "Epoch: 172 -> Test Accuracy: 92.37\n",
      "[173, 60] loss: 0.007\n",
      "[173, 120] loss: 0.007\n",
      "[173, 180] loss: 0.007\n",
      "[173, 240] loss: 0.007\n",
      "[173, 300] loss: 0.009\n",
      "[173, 360] loss: 0.007\n",
      "Epoch: 173 -> Loss: 0.0117625165731\n",
      "Epoch: 173 -> Test Accuracy: 92.2525\n",
      "[174, 60] loss: 0.007\n",
      "[174, 120] loss: 0.007\n",
      "[174, 180] loss: 0.006\n",
      "[174, 240] loss: 0.006\n",
      "[174, 300] loss: 0.007\n",
      "[174, 360] loss: 0.007\n",
      "Epoch: 174 -> Loss: 0.007074595429\n",
      "Epoch: 174 -> Test Accuracy: 92.4225\n",
      "[175, 60] loss: 0.007\n",
      "[175, 120] loss: 0.007\n",
      "[175, 180] loss: 0.007\n",
      "[175, 240] loss: 0.006\n",
      "[175, 300] loss: 0.008\n",
      "[175, 360] loss: 0.007\n",
      "Epoch: 175 -> Loss: 0.00487339589745\n",
      "Epoch: 175 -> Test Accuracy: 92.3275\n",
      "[176, 60] loss: 0.006\n",
      "[176, 120] loss: 0.007\n",
      "[176, 180] loss: 0.007\n",
      "[176, 240] loss: 0.007\n",
      "[176, 300] loss: 0.007\n",
      "[176, 360] loss: 0.007\n",
      "Epoch: 176 -> Loss: 0.00430308422074\n",
      "Epoch: 176 -> Test Accuracy: 92.265\n",
      "[177, 60] loss: 0.007\n",
      "[177, 120] loss: 0.006\n",
      "[177, 180] loss: 0.006\n",
      "[177, 240] loss: 0.006\n",
      "[177, 300] loss: 0.006\n",
      "[177, 360] loss: 0.007\n",
      "Epoch: 177 -> Loss: 0.00929529033601\n",
      "Epoch: 177 -> Test Accuracy: 92.2025\n",
      "[178, 60] loss: 0.006\n",
      "[178, 120] loss: 0.008\n",
      "[178, 180] loss: 0.006\n",
      "[178, 240] loss: 0.006\n",
      "[178, 300] loss: 0.006\n",
      "[178, 360] loss: 0.007\n",
      "Epoch: 178 -> Loss: 0.00234505464323\n",
      "Epoch: 178 -> Test Accuracy: 92.295\n",
      "[179, 60] loss: 0.006\n",
      "[179, 120] loss: 0.006\n",
      "[179, 180] loss: 0.006\n",
      "[179, 240] loss: 0.006\n",
      "[179, 300] loss: 0.006\n",
      "[179, 360] loss: 0.006\n",
      "Epoch: 179 -> Loss: 0.00509490817785\n",
      "Epoch: 179 -> Test Accuracy: 92.36\n",
      "[180, 60] loss: 0.006\n",
      "[180, 120] loss: 0.006\n",
      "[180, 180] loss: 0.006\n",
      "[180, 240] loss: 0.006\n",
      "[180, 300] loss: 0.006\n",
      "[180, 360] loss: 0.006\n",
      "Epoch: 180 -> Loss: 0.00487587368116\n",
      "Epoch: 180 -> Test Accuracy: 92.3675\n",
      "[181, 60] loss: 0.006\n",
      "[181, 120] loss: 0.006\n",
      "[181, 180] loss: 0.006\n",
      "[181, 240] loss: 0.006\n",
      "[181, 300] loss: 0.006\n",
      "[181, 360] loss: 0.006\n",
      "Epoch: 181 -> Loss: 0.00508175883442\n",
      "Epoch: 181 -> Test Accuracy: 92.34\n",
      "[182, 60] loss: 0.006\n",
      "[182, 120] loss: 0.005\n",
      "[182, 180] loss: 0.006\n",
      "[182, 240] loss: 0.006\n",
      "[182, 300] loss: 0.006\n",
      "[182, 360] loss: 0.007\n",
      "Epoch: 182 -> Loss: 0.0089147221297\n",
      "Epoch: 182 -> Test Accuracy: 92.4025\n",
      "[183, 60] loss: 0.006\n",
      "[183, 120] loss: 0.006\n",
      "[183, 180] loss: 0.006\n",
      "[183, 240] loss: 0.006\n",
      "[183, 300] loss: 0.006\n",
      "[183, 360] loss: 0.007\n",
      "Epoch: 183 -> Loss: 0.00553127285093\n",
      "Epoch: 183 -> Test Accuracy: 92.415\n",
      "[184, 60] loss: 0.005\n",
      "[184, 120] loss: 0.006\n",
      "[184, 180] loss: 0.005\n",
      "[184, 240] loss: 0.006\n",
      "[184, 300] loss: 0.006\n",
      "[184, 360] loss: 0.006\n",
      "Epoch: 184 -> Loss: 0.0177317056805\n",
      "Epoch: 184 -> Test Accuracy: 92.3525\n",
      "[185, 60] loss: 0.006\n",
      "[185, 120] loss: 0.006\n",
      "[185, 180] loss: 0.006\n",
      "[185, 240] loss: 0.006\n",
      "[185, 300] loss: 0.006\n",
      "[185, 360] loss: 0.005\n",
      "Epoch: 185 -> Loss: 0.00738380337134\n",
      "Epoch: 185 -> Test Accuracy: 92.3725\n",
      "[186, 60] loss: 0.006\n",
      "[186, 120] loss: 0.007\n",
      "[186, 180] loss: 0.006\n",
      "[186, 240] loss: 0.005\n",
      "[186, 300] loss: 0.006\n",
      "[186, 360] loss: 0.006\n",
      "Epoch: 186 -> Loss: 0.0105383563787\n",
      "Epoch: 186 -> Test Accuracy: 92.3575\n",
      "[187, 60] loss: 0.006\n",
      "[187, 120] loss: 0.005\n",
      "[187, 180] loss: 0.006\n",
      "[187, 240] loss: 0.006\n",
      "[187, 300] loss: 0.006\n",
      "[187, 360] loss: 0.006\n",
      "Epoch: 187 -> Loss: 0.0420073755085\n",
      "Epoch: 187 -> Test Accuracy: 92.3175\n",
      "[188, 60] loss: 0.006\n",
      "[188, 120] loss: 0.006\n",
      "[188, 180] loss: 0.006\n",
      "[188, 240] loss: 0.005\n",
      "[188, 300] loss: 0.005\n",
      "[188, 360] loss: 0.006\n",
      "Epoch: 188 -> Loss: 0.00325451348908\n",
      "Epoch: 188 -> Test Accuracy: 92.36\n",
      "[189, 60] loss: 0.005\n",
      "[189, 120] loss: 0.005\n",
      "[189, 180] loss: 0.006\n",
      "[189, 240] loss: 0.005\n",
      "[189, 300] loss: 0.005\n",
      "[189, 360] loss: 0.006\n",
      "Epoch: 189 -> Loss: 0.00539861805737\n",
      "Epoch: 189 -> Test Accuracy: 92.355\n",
      "[190, 60] loss: 0.005\n",
      "[190, 120] loss: 0.005\n",
      "[190, 180] loss: 0.005\n",
      "[190, 240] loss: 0.005\n",
      "[190, 300] loss: 0.005\n",
      "[190, 360] loss: 0.005\n",
      "Epoch: 190 -> Loss: 0.00122849119361\n",
      "Epoch: 190 -> Test Accuracy: 92.2725\n",
      "[191, 60] loss: 0.005\n",
      "[191, 120] loss: 0.005\n",
      "[191, 180] loss: 0.006\n",
      "[191, 240] loss: 0.006\n",
      "[191, 300] loss: 0.006\n",
      "[191, 360] loss: 0.005\n",
      "Epoch: 191 -> Loss: 0.00381630659103\n",
      "Epoch: 191 -> Test Accuracy: 92.3425\n",
      "[192, 60] loss: 0.005\n",
      "[192, 120] loss: 0.005\n",
      "[192, 180] loss: 0.005\n",
      "[192, 240] loss: 0.005\n",
      "[192, 300] loss: 0.006\n",
      "[192, 360] loss: 0.005\n",
      "Epoch: 192 -> Loss: 0.0104132499546\n",
      "Epoch: 192 -> Test Accuracy: 92.3175\n",
      "[193, 60] loss: 0.005\n",
      "[193, 120] loss: 0.006\n",
      "[193, 180] loss: 0.005\n",
      "[193, 240] loss: 0.005\n",
      "[193, 300] loss: 0.006\n",
      "[193, 360] loss: 0.005\n",
      "Epoch: 193 -> Loss: 0.00203834543936\n",
      "Epoch: 193 -> Test Accuracy: 92.38\n",
      "[194, 60] loss: 0.005\n",
      "[194, 120] loss: 0.005\n",
      "[194, 180] loss: 0.005\n",
      "[194, 240] loss: 0.005\n",
      "[194, 300] loss: 0.005\n",
      "[194, 360] loss: 0.006\n",
      "Epoch: 194 -> Loss: 0.0041365288198\n",
      "Epoch: 194 -> Test Accuracy: 92.3475\n",
      "[195, 60] loss: 0.006\n",
      "[195, 120] loss: 0.005\n",
      "[195, 180] loss: 0.005\n",
      "[195, 240] loss: 0.005\n",
      "[195, 300] loss: 0.005\n",
      "[195, 360] loss: 0.005\n",
      "Epoch: 195 -> Loss: 0.00238096271642\n",
      "Epoch: 195 -> Test Accuracy: 92.3225\n",
      "[196, 60] loss: 0.005\n",
      "[196, 120] loss: 0.005\n",
      "[196, 180] loss: 0.005\n",
      "[196, 240] loss: 0.006\n",
      "[196, 300] loss: 0.006\n",
      "[196, 360] loss: 0.005\n",
      "Epoch: 196 -> Loss: 0.00528842303902\n",
      "Epoch: 196 -> Test Accuracy: 92.2675\n",
      "[197, 60] loss: 0.005\n",
      "[197, 120] loss: 0.004\n",
      "[197, 180] loss: 0.004\n",
      "[197, 240] loss: 0.005\n",
      "[197, 300] loss: 0.005\n",
      "[197, 360] loss: 0.006\n",
      "Epoch: 197 -> Loss: 0.00239883293398\n",
      "Epoch: 197 -> Test Accuracy: 92.2725\n",
      "[198, 60] loss: 0.005\n",
      "[198, 120] loss: 0.005\n",
      "[198, 180] loss: 0.005\n",
      "[198, 240] loss: 0.005\n",
      "[198, 300] loss: 0.005\n",
      "[198, 360] loss: 0.004\n",
      "Epoch: 198 -> Loss: 0.00930885504931\n",
      "Epoch: 198 -> Test Accuracy: 92.31\n",
      "[199, 60] loss: 0.005\n",
      "[199, 120] loss: 0.005\n",
      "[199, 180] loss: 0.006\n",
      "[199, 240] loss: 0.005\n",
      "[199, 300] loss: 0.005\n",
      "[199, 360] loss: 0.005\n",
      "Epoch: 199 -> Loss: 0.00613606860861\n",
      "Epoch: 199 -> Test Accuracy: 92.2775\n",
      "[200, 60] loss: 0.005\n",
      "[200, 120] loss: 0.005\n",
      "[200, 180] loss: 0.005\n",
      "[200, 240] loss: 0.005\n",
      "[200, 300] loss: 0.005\n",
      "[200, 360] loss: 0.005\n",
      "Epoch: 200 -> Loss: 0.00464009866118\n",
      "Epoch: 200 -> Test Accuracy: 92.3025\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "rot_block4_loss_log, rot_block4_valid_accuracy_log, rot_block4_test_accuracy_log, rot_block4_max_accuracy, \\\n",
    "rot_block4_best_epoch = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], [60, 120, 160, 200], 0.9, 5e-4, net_block4, \n",
    "                                             criterion, trainloader, None, testloader, rot=['90', '180', '270'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 2.230\n",
      "[1, 120] loss: 1.243\n",
      "[1, 180] loss: 1.120\n",
      "[1, 240] loss: 1.094\n",
      "[1, 300] loss: 1.061\n",
      "[1, 360] loss: 0.994\n",
      "Epoch: 1 -> Loss: 1.02456128597\n",
      "Epoch: 1 -> Test Accuracy: 67.92\n",
      "[2, 60] loss: 0.951\n",
      "[2, 120] loss: 0.930\n",
      "[2, 180] loss: 0.918\n",
      "[2, 240] loss: 0.922\n",
      "[2, 300] loss: 0.895\n",
      "[2, 360] loss: 0.856\n",
      "Epoch: 2 -> Loss: 0.856550991535\n",
      "Epoch: 2 -> Test Accuracy: 71.33\n",
      "[3, 60] loss: 0.845\n",
      "[3, 120] loss: 0.804\n",
      "[3, 180] loss: 0.803\n",
      "[3, 240] loss: 0.813\n",
      "[3, 300] loss: 0.812\n",
      "[3, 360] loss: 0.798\n",
      "Epoch: 3 -> Loss: 0.928573012352\n",
      "Epoch: 3 -> Test Accuracy: 73.83\n",
      "[4, 60] loss: 0.761\n",
      "[4, 120] loss: 0.744\n",
      "[4, 180] loss: 0.777\n",
      "[4, 240] loss: 0.781\n",
      "[4, 300] loss: 0.759\n",
      "[4, 360] loss: 0.748\n",
      "Epoch: 4 -> Loss: 0.637997031212\n",
      "Epoch: 4 -> Test Accuracy: 74.91\n",
      "[5, 60] loss: 0.720\n",
      "[5, 120] loss: 0.742\n",
      "[5, 180] loss: 0.726\n",
      "[5, 240] loss: 0.705\n",
      "[5, 300] loss: 0.728\n",
      "[5, 360] loss: 0.717\n",
      "Epoch: 5 -> Loss: 0.620478510857\n",
      "Epoch: 5 -> Test Accuracy: 75.08\n",
      "[6, 60] loss: 0.686\n",
      "[6, 120] loss: 0.724\n",
      "[6, 180] loss: 0.718\n",
      "[6, 240] loss: 0.697\n",
      "[6, 300] loss: 0.692\n",
      "[6, 360] loss: 0.696\n",
      "Epoch: 6 -> Loss: 0.74586725235\n",
      "Epoch: 6 -> Test Accuracy: 75.89\n",
      "[7, 60] loss: 0.682\n",
      "[7, 120] loss: 0.656\n",
      "[7, 180] loss: 0.706\n",
      "[7, 240] loss: 0.686\n",
      "[7, 300] loss: 0.678\n",
      "[7, 360] loss: 0.687\n",
      "Epoch: 7 -> Loss: 0.943794071674\n",
      "Epoch: 7 -> Test Accuracy: 76.44\n",
      "[8, 60] loss: 0.659\n",
      "[8, 120] loss: 0.665\n",
      "[8, 180] loss: 0.661\n",
      "[8, 240] loss: 0.686\n",
      "[8, 300] loss: 0.672\n",
      "[8, 360] loss: 0.668\n",
      "Epoch: 8 -> Loss: 0.552208542824\n",
      "Epoch: 8 -> Test Accuracy: 77.02\n",
      "[9, 60] loss: 0.668\n",
      "[9, 120] loss: 0.641\n",
      "[9, 180] loss: 0.664\n",
      "[9, 240] loss: 0.656\n",
      "[9, 300] loss: 0.667\n",
      "[9, 360] loss: 0.653\n",
      "Epoch: 9 -> Loss: 0.613075315952\n",
      "Epoch: 9 -> Test Accuracy: 76.96\n",
      "[10, 60] loss: 0.665\n",
      "[10, 120] loss: 0.636\n",
      "[10, 180] loss: 0.663\n",
      "[10, 240] loss: 0.658\n",
      "[10, 300] loss: 0.647\n",
      "[10, 360] loss: 0.634\n",
      "Epoch: 10 -> Loss: 0.576074421406\n",
      "Epoch: 10 -> Test Accuracy: 77.3\n",
      "[11, 60] loss: 0.642\n",
      "[11, 120] loss: 0.649\n",
      "[11, 180] loss: 0.629\n",
      "[11, 240] loss: 0.634\n",
      "[11, 300] loss: 0.648\n",
      "[11, 360] loss: 0.640\n",
      "Epoch: 11 -> Loss: 0.752467095852\n",
      "Epoch: 11 -> Test Accuracy: 77.55\n",
      "[12, 60] loss: 0.624\n",
      "[12, 120] loss: 0.616\n",
      "[12, 180] loss: 0.623\n",
      "[12, 240] loss: 0.643\n",
      "[12, 300] loss: 0.637\n",
      "[12, 360] loss: 0.656\n",
      "Epoch: 12 -> Loss: 0.65791118145\n",
      "Epoch: 12 -> Test Accuracy: 76.78\n",
      "[13, 60] loss: 0.595\n",
      "[13, 120] loss: 0.637\n",
      "[13, 180] loss: 0.620\n",
      "[13, 240] loss: 0.609\n",
      "[13, 300] loss: 0.640\n",
      "[13, 360] loss: 0.642\n",
      "Epoch: 13 -> Loss: 0.574429869652\n",
      "Epoch: 13 -> Test Accuracy: 77.0\n",
      "[14, 60] loss: 0.600\n",
      "[14, 120] loss: 0.616\n",
      "[14, 180] loss: 0.594\n",
      "[14, 240] loss: 0.632\n",
      "[14, 300] loss: 0.627\n",
      "[14, 360] loss: 0.637\n",
      "Epoch: 14 -> Loss: 0.760913670063\n",
      "Epoch: 14 -> Test Accuracy: 78.03\n",
      "[15, 60] loss: 0.603\n",
      "[15, 120] loss: 0.615\n",
      "[15, 180] loss: 0.637\n",
      "[15, 240] loss: 0.600\n",
      "[15, 300] loss: 0.596\n",
      "[15, 360] loss: 0.625\n",
      "Epoch: 15 -> Loss: 0.549171328545\n",
      "Epoch: 15 -> Test Accuracy: 77.78\n",
      "[16, 60] loss: 0.606\n",
      "[16, 120] loss: 0.599\n",
      "[16, 180] loss: 0.612\n",
      "[16, 240] loss: 0.608\n",
      "[16, 300] loss: 0.612\n",
      "[16, 360] loss: 0.628\n",
      "Epoch: 16 -> Loss: 0.601016700268\n",
      "Epoch: 16 -> Test Accuracy: 77.98\n",
      "[17, 60] loss: 0.582\n",
      "[17, 120] loss: 0.628\n",
      "[17, 180] loss: 0.595\n",
      "[17, 240] loss: 0.616\n",
      "[17, 300] loss: 0.614\n",
      "[17, 360] loss: 0.626\n",
      "Epoch: 17 -> Loss: 0.641189277172\n",
      "Epoch: 17 -> Test Accuracy: 78.8\n",
      "[18, 60] loss: 0.593\n",
      "[18, 120] loss: 0.613\n",
      "[18, 180] loss: 0.585\n",
      "[18, 240] loss: 0.622\n",
      "[18, 300] loss: 0.614\n",
      "[18, 360] loss: 0.623\n",
      "Epoch: 18 -> Loss: 0.699341595173\n",
      "Epoch: 18 -> Test Accuracy: 78.61\n",
      "[19, 60] loss: 0.577\n",
      "[19, 120] loss: 0.598\n",
      "[19, 180] loss: 0.605\n",
      "[19, 240] loss: 0.613\n",
      "[19, 300] loss: 0.617\n",
      "[19, 360] loss: 0.604\n",
      "Epoch: 19 -> Loss: 0.32052180171\n",
      "Epoch: 19 -> Test Accuracy: 77.82\n",
      "[20, 60] loss: 0.588\n",
      "[20, 120] loss: 0.594\n",
      "[20, 180] loss: 0.599\n",
      "[20, 240] loss: 0.599\n",
      "[20, 300] loss: 0.637\n",
      "[20, 360] loss: 0.602\n",
      "Epoch: 20 -> Loss: 0.559190034866\n",
      "Epoch: 20 -> Test Accuracy: 78.28\n",
      "[21, 60] loss: 0.548\n",
      "[21, 120] loss: 0.523\n",
      "[21, 180] loss: 0.513\n",
      "[21, 240] loss: 0.511\n",
      "[21, 300] loss: 0.486\n",
      "[21, 360] loss: 0.490\n",
      "Epoch: 21 -> Loss: 0.432778656483\n",
      "Epoch: 21 -> Test Accuracy: 81.17\n",
      "[22, 60] loss: 0.473\n",
      "[22, 120] loss: 0.464\n",
      "[22, 180] loss: 0.472\n",
      "[22, 240] loss: 0.467\n",
      "[22, 300] loss: 0.467\n",
      "[22, 360] loss: 0.470\n",
      "Epoch: 22 -> Loss: 0.475130170584\n",
      "Epoch: 22 -> Test Accuracy: 81.26\n",
      "[23, 60] loss: 0.439\n",
      "[23, 120] loss: 0.435\n",
      "[23, 180] loss: 0.474\n",
      "[23, 240] loss: 0.440\n",
      "[23, 300] loss: 0.454\n",
      "[23, 360] loss: 0.452\n",
      "Epoch: 23 -> Loss: 0.418132156134\n",
      "Epoch: 23 -> Test Accuracy: 81.42\n",
      "[24, 60] loss: 0.446\n",
      "[24, 120] loss: 0.423\n",
      "[24, 180] loss: 0.447\n",
      "[24, 240] loss: 0.444\n",
      "[24, 300] loss: 0.439\n",
      "[24, 360] loss: 0.444\n",
      "Epoch: 24 -> Loss: 0.53231960535\n",
      "Epoch: 24 -> Test Accuracy: 81.81\n",
      "[25, 60] loss: 0.417\n",
      "[25, 120] loss: 0.438\n",
      "[25, 180] loss: 0.404\n",
      "[25, 240] loss: 0.442\n",
      "[25, 300] loss: 0.421\n",
      "[25, 360] loss: 0.445\n",
      "Epoch: 25 -> Loss: 0.326055705547\n",
      "Epoch: 25 -> Test Accuracy: 81.55\n",
      "[26, 60] loss: 0.401\n",
      "[26, 120] loss: 0.425\n",
      "[26, 180] loss: 0.412\n",
      "[26, 240] loss: 0.423\n",
      "[26, 300] loss: 0.418\n",
      "[26, 360] loss: 0.442\n",
      "Epoch: 26 -> Loss: 0.561061561108\n",
      "Epoch: 26 -> Test Accuracy: 81.69\n",
      "[27, 60] loss: 0.410\n",
      "[27, 120] loss: 0.420\n",
      "[27, 180] loss: 0.412\n",
      "[27, 240] loss: 0.415\n",
      "[27, 300] loss: 0.414\n",
      "[27, 360] loss: 0.430\n",
      "Epoch: 27 -> Loss: 0.54706299305\n",
      "Epoch: 27 -> Test Accuracy: 81.66\n",
      "[28, 60] loss: 0.392\n",
      "[28, 120] loss: 0.397\n",
      "[28, 180] loss: 0.405\n",
      "[28, 240] loss: 0.409\n",
      "[28, 300] loss: 0.426\n",
      "[28, 360] loss: 0.419\n",
      "Epoch: 28 -> Loss: 0.395202577114\n",
      "Epoch: 28 -> Test Accuracy: 81.51\n",
      "[29, 60] loss: 0.389\n",
      "[29, 120] loss: 0.407\n",
      "[29, 180] loss: 0.399\n",
      "[29, 240] loss: 0.404\n",
      "[29, 300] loss: 0.433\n",
      "[29, 360] loss: 0.428\n",
      "Epoch: 29 -> Loss: 0.46642190218\n",
      "Epoch: 29 -> Test Accuracy: 81.16\n",
      "[30, 60] loss: 0.387\n",
      "[30, 120] loss: 0.399\n",
      "[30, 180] loss: 0.396\n",
      "[30, 240] loss: 0.416\n",
      "[30, 300] loss: 0.402\n",
      "[30, 360] loss: 0.408\n",
      "Epoch: 30 -> Loss: 0.473554432392\n",
      "Epoch: 30 -> Test Accuracy: 81.69\n",
      "[31, 60] loss: 0.391\n",
      "[31, 120] loss: 0.404\n",
      "[31, 180] loss: 0.400\n",
      "[31, 240] loss: 0.398\n",
      "[31, 300] loss: 0.426\n",
      "[31, 360] loss: 0.405\n",
      "Epoch: 31 -> Loss: 0.469813108444\n",
      "Epoch: 31 -> Test Accuracy: 81.81\n",
      "[32, 60] loss: 0.392\n",
      "[32, 120] loss: 0.406\n",
      "[32, 180] loss: 0.412\n",
      "[32, 240] loss: 0.396\n",
      "[32, 300] loss: 0.403\n",
      "[32, 360] loss: 0.397\n",
      "Epoch: 32 -> Loss: 0.466124385595\n",
      "Epoch: 32 -> Test Accuracy: 81.49\n",
      "[33, 60] loss: 0.368\n",
      "[33, 120] loss: 0.403\n",
      "[33, 180] loss: 0.393\n",
      "[33, 240] loss: 0.404\n",
      "[33, 300] loss: 0.409\n",
      "[33, 360] loss: 0.411\n",
      "Epoch: 33 -> Loss: 0.490940630436\n",
      "Epoch: 33 -> Test Accuracy: 81.5\n",
      "[34, 60] loss: 0.381\n",
      "[34, 120] loss: 0.407\n",
      "[34, 180] loss: 0.398\n",
      "[34, 240] loss: 0.414\n",
      "[34, 300] loss: 0.391\n",
      "[34, 360] loss: 0.403\n",
      "Epoch: 34 -> Loss: 0.311519801617\n",
      "Epoch: 34 -> Test Accuracy: 81.79\n",
      "[35, 60] loss: 0.383\n",
      "[35, 120] loss: 0.381\n",
      "[35, 180] loss: 0.395\n",
      "[35, 240] loss: 0.403\n",
      "[35, 300] loss: 0.397\n",
      "[35, 360] loss: 0.390\n",
      "Epoch: 35 -> Loss: 0.36851477623\n",
      "Epoch: 35 -> Test Accuracy: 81.73\n",
      "[36, 60] loss: 0.392\n",
      "[36, 120] loss: 0.396\n",
      "[36, 180] loss: 0.394\n",
      "[36, 240] loss: 0.397\n",
      "[36, 300] loss: 0.406\n",
      "[36, 360] loss: 0.409\n",
      "Epoch: 36 -> Loss: 0.4400357306\n",
      "Epoch: 36 -> Test Accuracy: 81.52\n",
      "[37, 60] loss: 0.381\n",
      "[37, 120] loss: 0.394\n",
      "[37, 180] loss: 0.395\n",
      "[37, 240] loss: 0.393\n",
      "[37, 300] loss: 0.396\n",
      "[37, 360] loss: 0.394\n",
      "Epoch: 37 -> Loss: 0.660111069679\n",
      "Epoch: 37 -> Test Accuracy: 81.6\n",
      "[38, 60] loss: 0.393\n",
      "[38, 120] loss: 0.380\n",
      "[38, 180] loss: 0.407\n",
      "[38, 240] loss: 0.401\n",
      "[38, 300] loss: 0.382\n",
      "[38, 360] loss: 0.392\n",
      "Epoch: 38 -> Loss: 0.360459148884\n",
      "Epoch: 38 -> Test Accuracy: 81.92\n",
      "[39, 60] loss: 0.386\n",
      "[39, 120] loss: 0.394\n",
      "[39, 180] loss: 0.395\n",
      "[39, 240] loss: 0.389\n",
      "[39, 300] loss: 0.386\n",
      "[39, 360] loss: 0.390\n",
      "Epoch: 39 -> Loss: 0.431144952774\n",
      "Epoch: 39 -> Test Accuracy: 81.88\n",
      "[40, 60] loss: 0.374\n",
      "[40, 120] loss: 0.392\n",
      "[40, 180] loss: 0.388\n",
      "[40, 240] loss: 0.391\n",
      "[40, 300] loss: 0.392\n",
      "[40, 360] loss: 0.407\n",
      "Epoch: 40 -> Loss: 0.291284948587\n",
      "Epoch: 40 -> Test Accuracy: 81.67\n",
      "[41, 60] loss: 0.357\n",
      "[41, 120] loss: 0.340\n",
      "[41, 180] loss: 0.338\n",
      "[41, 240] loss: 0.344\n",
      "[41, 300] loss: 0.357\n",
      "[41, 360] loss: 0.348\n",
      "Epoch: 41 -> Loss: 0.251317769289\n",
      "Epoch: 41 -> Test Accuracy: 82.53\n",
      "[42, 60] loss: 0.331\n",
      "[42, 120] loss: 0.328\n",
      "[42, 180] loss: 0.338\n",
      "[42, 240] loss: 0.337\n",
      "[42, 300] loss: 0.319\n",
      "[42, 360] loss: 0.311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.324693381786\n",
      "Epoch: 42 -> Test Accuracy: 82.82\n",
      "[43, 60] loss: 0.320\n",
      "[43, 120] loss: 0.316\n",
      "[43, 180] loss: 0.310\n",
      "[43, 240] loss: 0.309\n",
      "[43, 300] loss: 0.302\n",
      "[43, 360] loss: 0.324\n",
      "Epoch: 43 -> Loss: 0.328915178776\n",
      "Epoch: 43 -> Test Accuracy: 83.16\n",
      "[44, 60] loss: 0.292\n",
      "[44, 120] loss: 0.294\n",
      "[44, 180] loss: 0.302\n",
      "[44, 240] loss: 0.320\n",
      "[44, 300] loss: 0.310\n",
      "[44, 360] loss: 0.312\n",
      "Epoch: 44 -> Loss: 0.402962446213\n",
      "Epoch: 44 -> Test Accuracy: 83.13\n",
      "[45, 60] loss: 0.305\n",
      "[45, 120] loss: 0.290\n",
      "[45, 180] loss: 0.289\n",
      "[45, 240] loss: 0.293\n",
      "[45, 300] loss: 0.311\n",
      "[45, 360] loss: 0.307\n",
      "Epoch: 45 -> Loss: 0.302144676447\n",
      "Epoch: 45 -> Test Accuracy: 82.93\n",
      "[46, 60] loss: 0.284\n",
      "[46, 120] loss: 0.290\n",
      "[46, 180] loss: 0.271\n",
      "[46, 240] loss: 0.287\n",
      "[46, 300] loss: 0.295\n",
      "[46, 360] loss: 0.293\n",
      "Epoch: 46 -> Loss: 0.377688199282\n",
      "Epoch: 46 -> Test Accuracy: 83.01\n",
      "[47, 60] loss: 0.284\n",
      "[47, 120] loss: 0.286\n",
      "[47, 180] loss: 0.284\n",
      "[47, 240] loss: 0.287\n",
      "[47, 300] loss: 0.274\n",
      "[47, 360] loss: 0.300\n",
      "Epoch: 47 -> Loss: 0.30963024497\n",
      "Epoch: 47 -> Test Accuracy: 83.03\n",
      "[48, 60] loss: 0.278\n",
      "[48, 120] loss: 0.275\n",
      "[48, 180] loss: 0.282\n",
      "[48, 240] loss: 0.281\n",
      "[48, 300] loss: 0.275\n",
      "[48, 360] loss: 0.290\n",
      "Epoch: 48 -> Loss: 0.275397837162\n",
      "Epoch: 48 -> Test Accuracy: 83.07\n",
      "[49, 60] loss: 0.275\n",
      "[49, 120] loss: 0.290\n",
      "[49, 180] loss: 0.285\n",
      "[49, 240] loss: 0.275\n",
      "[49, 300] loss: 0.279\n",
      "[49, 360] loss: 0.283\n",
      "Epoch: 49 -> Loss: 0.240924119949\n",
      "Epoch: 49 -> Test Accuracy: 83.19\n",
      "[50, 60] loss: 0.278\n",
      "[50, 120] loss: 0.262\n",
      "[50, 180] loss: 0.297\n",
      "[50, 240] loss: 0.280\n",
      "[50, 300] loss: 0.284\n",
      "[50, 360] loss: 0.273\n",
      "Epoch: 50 -> Loss: 0.349320113659\n",
      "Epoch: 50 -> Test Accuracy: 83.19\n",
      "[51, 60] loss: 0.283\n",
      "[51, 120] loss: 0.266\n",
      "[51, 180] loss: 0.281\n",
      "[51, 240] loss: 0.278\n",
      "[51, 300] loss: 0.268\n",
      "[51, 360] loss: 0.280\n",
      "Epoch: 51 -> Loss: 0.23971414566\n",
      "Epoch: 51 -> Test Accuracy: 83.22\n",
      "[52, 60] loss: 0.277\n",
      "[52, 120] loss: 0.271\n",
      "[52, 180] loss: 0.289\n",
      "[52, 240] loss: 0.270\n",
      "[52, 300] loss: 0.287\n",
      "[52, 360] loss: 0.272\n",
      "Epoch: 52 -> Loss: 0.367546737194\n",
      "Epoch: 52 -> Test Accuracy: 83.13\n",
      "[53, 60] loss: 0.268\n",
      "[53, 120] loss: 0.290\n",
      "[53, 180] loss: 0.277\n",
      "[53, 240] loss: 0.267\n",
      "[53, 300] loss: 0.275\n",
      "[53, 360] loss: 0.287\n",
      "Epoch: 53 -> Loss: 0.294652998447\n",
      "Epoch: 53 -> Test Accuracy: 83.24\n",
      "[54, 60] loss: 0.286\n",
      "[54, 120] loss: 0.269\n",
      "[54, 180] loss: 0.277\n",
      "[54, 240] loss: 0.278\n",
      "[54, 300] loss: 0.279\n",
      "[54, 360] loss: 0.270\n",
      "Epoch: 54 -> Loss: 0.426055431366\n",
      "Epoch: 54 -> Test Accuracy: 83.22\n",
      "[55, 60] loss: 0.270\n",
      "[55, 120] loss: 0.278\n",
      "[55, 180] loss: 0.278\n",
      "[55, 240] loss: 0.274\n",
      "[55, 300] loss: 0.275\n",
      "[55, 360] loss: 0.261\n",
      "Epoch: 55 -> Loss: 0.171196624637\n",
      "Epoch: 55 -> Test Accuracy: 83.16\n",
      "[56, 60] loss: 0.259\n",
      "[56, 120] loss: 0.267\n",
      "[56, 180] loss: 0.260\n",
      "[56, 240] loss: 0.273\n",
      "[56, 300] loss: 0.280\n",
      "[56, 360] loss: 0.261\n",
      "Epoch: 56 -> Loss: 0.269592046738\n",
      "Epoch: 56 -> Test Accuracy: 83.1\n",
      "[57, 60] loss: 0.263\n",
      "[57, 120] loss: 0.271\n",
      "[57, 180] loss: 0.268\n",
      "[57, 240] loss: 0.272\n",
      "[57, 300] loss: 0.264\n",
      "[57, 360] loss: 0.280\n",
      "Epoch: 57 -> Loss: 0.337279260159\n",
      "Epoch: 57 -> Test Accuracy: 83.19\n",
      "[58, 60] loss: 0.261\n",
      "[58, 120] loss: 0.270\n",
      "[58, 180] loss: 0.285\n",
      "[58, 240] loss: 0.267\n",
      "[58, 300] loss: 0.262\n",
      "[58, 360] loss: 0.270\n",
      "Epoch: 58 -> Loss: 0.174422353506\n",
      "Epoch: 58 -> Test Accuracy: 83.21\n",
      "[59, 60] loss: 0.271\n",
      "[59, 120] loss: 0.269\n",
      "[59, 180] loss: 0.269\n",
      "[59, 240] loss: 0.264\n",
      "[59, 300] loss: 0.271\n",
      "[59, 360] loss: 0.283\n",
      "Epoch: 59 -> Loss: 0.226357772946\n",
      "Epoch: 59 -> Test Accuracy: 83.18\n",
      "[60, 60] loss: 0.268\n",
      "[60, 120] loss: 0.265\n",
      "[60, 180] loss: 0.265\n",
      "[60, 240] loss: 0.272\n",
      "[60, 300] loss: 0.264\n",
      "[60, 360] loss: 0.275\n",
      "Epoch: 60 -> Loss: 0.313287436962\n",
      "Epoch: 60 -> Test Accuracy: 83.08\n",
      "[61, 60] loss: 0.265\n",
      "[61, 120] loss: 0.268\n",
      "[61, 180] loss: 0.260\n",
      "[61, 240] loss: 0.265\n",
      "[61, 300] loss: 0.265\n",
      "[61, 360] loss: 0.269\n",
      "Epoch: 61 -> Loss: 0.274167627096\n",
      "Epoch: 61 -> Test Accuracy: 83.2\n",
      "[62, 60] loss: 0.261\n",
      "[62, 120] loss: 0.254\n",
      "[62, 180] loss: 0.267\n",
      "[62, 240] loss: 0.280\n",
      "[62, 300] loss: 0.257\n",
      "[62, 360] loss: 0.256\n",
      "Epoch: 62 -> Loss: 0.329921722412\n",
      "Epoch: 62 -> Test Accuracy: 83.21\n",
      "[63, 60] loss: 0.269\n",
      "[63, 120] loss: 0.256\n",
      "[63, 180] loss: 0.256\n",
      "[63, 240] loss: 0.275\n",
      "[63, 300] loss: 0.273\n",
      "[63, 360] loss: 0.261\n",
      "Epoch: 63 -> Loss: 0.218802884221\n",
      "Epoch: 63 -> Test Accuracy: 83.22\n",
      "[64, 60] loss: 0.263\n",
      "[64, 120] loss: 0.267\n",
      "[64, 180] loss: 0.261\n",
      "[64, 240] loss: 0.260\n",
      "[64, 300] loss: 0.268\n",
      "[64, 360] loss: 0.243\n",
      "Epoch: 64 -> Loss: 0.265671014786\n",
      "Epoch: 64 -> Test Accuracy: 83.08\n",
      "[65, 60] loss: 0.265\n",
      "[65, 120] loss: 0.266\n",
      "[65, 180] loss: 0.265\n",
      "[65, 240] loss: 0.252\n",
      "[65, 300] loss: 0.262\n",
      "[65, 360] loss: 0.262\n",
      "Epoch: 65 -> Loss: 0.265791982412\n",
      "Epoch: 65 -> Test Accuracy: 83.19\n",
      "[66, 60] loss: 0.250\n",
      "[66, 120] loss: 0.256\n",
      "[66, 180] loss: 0.249\n",
      "[66, 240] loss: 0.255\n",
      "[66, 300] loss: 0.259\n",
      "[66, 360] loss: 0.262\n",
      "Epoch: 66 -> Loss: 0.237379238009\n",
      "Epoch: 66 -> Test Accuracy: 83.11\n",
      "[67, 60] loss: 0.269\n",
      "[67, 120] loss: 0.257\n",
      "[67, 180] loss: 0.256\n",
      "[67, 240] loss: 0.265\n",
      "[67, 300] loss: 0.262\n",
      "[67, 360] loss: 0.263\n",
      "Epoch: 67 -> Loss: 0.257568746805\n",
      "Epoch: 67 -> Test Accuracy: 83.11\n",
      "[68, 60] loss: 0.264\n",
      "[68, 120] loss: 0.255\n",
      "[68, 180] loss: 0.258\n",
      "[68, 240] loss: 0.253\n",
      "[68, 300] loss: 0.253\n",
      "[68, 360] loss: 0.256\n",
      "Epoch: 68 -> Loss: 0.129852861166\n",
      "Epoch: 68 -> Test Accuracy: 83.18\n",
      "[69, 60] loss: 0.249\n",
      "[69, 120] loss: 0.256\n",
      "[69, 180] loss: 0.255\n",
      "[69, 240] loss: 0.268\n",
      "[69, 300] loss: 0.259\n",
      "[69, 360] loss: 0.262\n",
      "Epoch: 69 -> Loss: 0.291700035334\n",
      "Epoch: 69 -> Test Accuracy: 83.25\n",
      "[70, 60] loss: 0.255\n",
      "[70, 120] loss: 0.248\n",
      "[70, 180] loss: 0.255\n",
      "[70, 240] loss: 0.249\n",
      "[70, 300] loss: 0.255\n",
      "[70, 360] loss: 0.257\n",
      "Epoch: 70 -> Loss: 0.233017995954\n",
      "Epoch: 70 -> Test Accuracy: 83.24\n",
      "[71, 60] loss: 0.266\n",
      "[71, 120] loss: 0.252\n",
      "[71, 180] loss: 0.262\n",
      "[71, 240] loss: 0.242\n",
      "[71, 300] loss: 0.271\n",
      "[71, 360] loss: 0.252\n",
      "Epoch: 71 -> Loss: 0.385525673628\n",
      "Epoch: 71 -> Test Accuracy: 83.11\n",
      "[72, 60] loss: 0.252\n",
      "[72, 120] loss: 0.264\n",
      "[72, 180] loss: 0.250\n",
      "[72, 240] loss: 0.256\n",
      "[72, 300] loss: 0.262\n",
      "[72, 360] loss: 0.258\n",
      "Epoch: 72 -> Loss: 0.353103339672\n",
      "Epoch: 72 -> Test Accuracy: 83.17\n",
      "[73, 60] loss: 0.250\n",
      "[73, 120] loss: 0.247\n",
      "[73, 180] loss: 0.253\n",
      "[73, 240] loss: 0.251\n",
      "[73, 300] loss: 0.262\n",
      "[73, 360] loss: 0.250\n",
      "Epoch: 73 -> Loss: 0.300883919001\n",
      "Epoch: 73 -> Test Accuracy: 83.12\n",
      "[74, 60] loss: 0.236\n",
      "[74, 120] loss: 0.267\n",
      "[74, 180] loss: 0.258\n",
      "[74, 240] loss: 0.253\n",
      "[74, 300] loss: 0.249\n",
      "[74, 360] loss: 0.243\n",
      "Epoch: 74 -> Loss: 0.264563918114\n",
      "Epoch: 74 -> Test Accuracy: 83.18\n",
      "[75, 60] loss: 0.245\n",
      "[75, 120] loss: 0.243\n",
      "[75, 180] loss: 0.239\n",
      "[75, 240] loss: 0.249\n",
      "[75, 300] loss: 0.250\n",
      "[75, 360] loss: 0.244\n",
      "Epoch: 75 -> Loss: 0.234849452972\n",
      "Epoch: 75 -> Test Accuracy: 83.22\n",
      "[76, 60] loss: 0.254\n",
      "[76, 120] loss: 0.255\n",
      "[76, 180] loss: 0.239\n",
      "[76, 240] loss: 0.248\n",
      "[76, 300] loss: 0.239\n",
      "[76, 360] loss: 0.259\n",
      "Epoch: 76 -> Loss: 0.241493031383\n",
      "Epoch: 76 -> Test Accuracy: 83.18\n",
      "[77, 60] loss: 0.249\n",
      "[77, 120] loss: 0.243\n",
      "[77, 180] loss: 0.263\n",
      "[77, 240] loss: 0.255\n",
      "[77, 300] loss: 0.240\n",
      "[77, 360] loss: 0.249\n",
      "Epoch: 77 -> Loss: 0.315884053707\n",
      "Epoch: 77 -> Test Accuracy: 83.27\n",
      "[78, 60] loss: 0.246\n",
      "[78, 120] loss: 0.244\n",
      "[78, 180] loss: 0.254\n",
      "[78, 240] loss: 0.247\n",
      "[78, 300] loss: 0.254\n",
      "[78, 360] loss: 0.249\n",
      "Epoch: 78 -> Loss: 0.208970949054\n",
      "Epoch: 78 -> Test Accuracy: 83.27\n",
      "[79, 60] loss: 0.237\n",
      "[79, 120] loss: 0.251\n",
      "[79, 180] loss: 0.245\n",
      "[79, 240] loss: 0.244\n",
      "[79, 300] loss: 0.246\n",
      "[79, 360] loss: 0.245\n",
      "Epoch: 79 -> Loss: 0.323103666306\n",
      "Epoch: 79 -> Test Accuracy: 83.17\n",
      "[80, 60] loss: 0.247\n",
      "[80, 120] loss: 0.241\n",
      "[80, 180] loss: 0.254\n",
      "[80, 240] loss: 0.249\n",
      "[80, 300] loss: 0.240\n",
      "[80, 360] loss: 0.259\n",
      "Epoch: 80 -> Loss: 0.199295803905\n",
      "Epoch: 80 -> Test Accuracy: 83.4\n",
      "[81, 60] loss: 0.237\n",
      "[81, 120] loss: 0.239\n",
      "[81, 180] loss: 0.249\n",
      "[81, 240] loss: 0.243\n",
      "[81, 300] loss: 0.255\n",
      "[81, 360] loss: 0.243\n",
      "Epoch: 81 -> Loss: 0.338535279036\n",
      "Epoch: 81 -> Test Accuracy: 83.18\n",
      "[82, 60] loss: 0.225\n",
      "[82, 120] loss: 0.248\n",
      "[82, 180] loss: 0.251\n",
      "[82, 240] loss: 0.249\n",
      "[82, 300] loss: 0.251\n",
      "[82, 360] loss: 0.243\n",
      "Epoch: 82 -> Loss: 0.154017060995\n",
      "Epoch: 82 -> Test Accuracy: 83.17\n",
      "[83, 60] loss: 0.244\n",
      "[83, 120] loss: 0.238\n",
      "[83, 180] loss: 0.238\n",
      "[83, 240] loss: 0.251\n",
      "[83, 300] loss: 0.256\n",
      "[83, 360] loss: 0.235\n",
      "Epoch: 83 -> Loss: 0.162914782763\n",
      "Epoch: 83 -> Test Accuracy: 83.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.236\n",
      "[84, 120] loss: 0.247\n",
      "[84, 180] loss: 0.243\n",
      "[84, 240] loss: 0.239\n",
      "[84, 300] loss: 0.238\n",
      "[84, 360] loss: 0.245\n",
      "Epoch: 84 -> Loss: 0.411727666855\n",
      "Epoch: 84 -> Test Accuracy: 83.28\n",
      "[85, 60] loss: 0.239\n",
      "[85, 120] loss: 0.241\n",
      "[85, 180] loss: 0.233\n",
      "[85, 240] loss: 0.249\n",
      "[85, 300] loss: 0.256\n",
      "[85, 360] loss: 0.240\n",
      "Epoch: 85 -> Loss: 0.313207805157\n",
      "Epoch: 85 -> Test Accuracy: 83.39\n",
      "[86, 60] loss: 0.235\n",
      "[86, 120] loss: 0.241\n",
      "[86, 180] loss: 0.244\n",
      "[86, 240] loss: 0.227\n",
      "[86, 300] loss: 0.246\n",
      "[86, 360] loss: 0.248\n",
      "Epoch: 86 -> Loss: 0.283459603786\n",
      "Epoch: 86 -> Test Accuracy: 83.34\n",
      "[87, 60] loss: 0.233\n",
      "[87, 120] loss: 0.248\n",
      "[87, 180] loss: 0.240\n",
      "[87, 240] loss: 0.242\n",
      "[87, 300] loss: 0.240\n",
      "[87, 360] loss: 0.251\n",
      "Epoch: 87 -> Loss: 0.385321199894\n",
      "Epoch: 87 -> Test Accuracy: 83.33\n",
      "[88, 60] loss: 0.232\n",
      "[88, 120] loss: 0.240\n",
      "[88, 180] loss: 0.236\n",
      "[88, 240] loss: 0.246\n",
      "[88, 300] loss: 0.246\n",
      "[88, 360] loss: 0.255\n",
      "Epoch: 88 -> Loss: 0.306116402149\n",
      "Epoch: 88 -> Test Accuracy: 83.31\n",
      "[89, 60] loss: 0.249\n",
      "[89, 120] loss: 0.237\n",
      "[89, 180] loss: 0.237\n",
      "[89, 240] loss: 0.241\n",
      "[89, 300] loss: 0.235\n",
      "[89, 360] loss: 0.233\n",
      "Epoch: 89 -> Loss: 0.23835735023\n",
      "Epoch: 89 -> Test Accuracy: 83.2\n",
      "[90, 60] loss: 0.241\n",
      "[90, 120] loss: 0.227\n",
      "[90, 180] loss: 0.240\n",
      "[90, 240] loss: 0.236\n",
      "[90, 300] loss: 0.238\n",
      "[90, 360] loss: 0.248\n",
      "Epoch: 90 -> Loss: 0.266027003527\n",
      "Epoch: 90 -> Test Accuracy: 83.19\n",
      "[91, 60] loss: 0.239\n",
      "[91, 120] loss: 0.241\n",
      "[91, 180] loss: 0.236\n",
      "[91, 240] loss: 0.235\n",
      "[91, 300] loss: 0.231\n",
      "[91, 360] loss: 0.243\n",
      "Epoch: 91 -> Loss: 0.228314995766\n",
      "Epoch: 91 -> Test Accuracy: 83.37\n",
      "[92, 60] loss: 0.229\n",
      "[92, 120] loss: 0.245\n",
      "[92, 180] loss: 0.233\n",
      "[92, 240] loss: 0.231\n",
      "[92, 300] loss: 0.241\n",
      "[92, 360] loss: 0.233\n",
      "Epoch: 92 -> Loss: 0.247621744871\n",
      "Epoch: 92 -> Test Accuracy: 83.28\n",
      "[93, 60] loss: 0.223\n",
      "[93, 120] loss: 0.223\n",
      "[93, 180] loss: 0.244\n",
      "[93, 240] loss: 0.236\n",
      "[93, 300] loss: 0.232\n",
      "[93, 360] loss: 0.246\n",
      "Epoch: 93 -> Loss: 0.309882640839\n",
      "Epoch: 93 -> Test Accuracy: 83.17\n",
      "[94, 60] loss: 0.240\n",
      "[94, 120] loss: 0.232\n",
      "[94, 180] loss: 0.233\n",
      "[94, 240] loss: 0.236\n",
      "[94, 300] loss: 0.237\n",
      "[94, 360] loss: 0.230\n",
      "Epoch: 94 -> Loss: 0.257661491632\n",
      "Epoch: 94 -> Test Accuracy: 83.22\n",
      "[95, 60] loss: 0.232\n",
      "[95, 120] loss: 0.228\n",
      "[95, 180] loss: 0.229\n",
      "[95, 240] loss: 0.232\n",
      "[95, 300] loss: 0.230\n",
      "[95, 360] loss: 0.238\n",
      "Epoch: 95 -> Loss: 0.148265600204\n",
      "Epoch: 95 -> Test Accuracy: 83.28\n",
      "[96, 60] loss: 0.219\n",
      "[96, 120] loss: 0.229\n",
      "[96, 180] loss: 0.240\n",
      "[96, 240] loss: 0.230\n",
      "[96, 300] loss: 0.230\n",
      "[96, 360] loss: 0.230\n",
      "Epoch: 96 -> Loss: 0.188380688429\n",
      "Epoch: 96 -> Test Accuracy: 83.3\n",
      "[97, 60] loss: 0.236\n",
      "[97, 120] loss: 0.232\n",
      "[97, 180] loss: 0.231\n",
      "[97, 240] loss: 0.242\n",
      "[97, 300] loss: 0.225\n",
      "[97, 360] loss: 0.215\n",
      "Epoch: 97 -> Loss: 0.263373583555\n",
      "Epoch: 97 -> Test Accuracy: 83.18\n",
      "[98, 60] loss: 0.230\n",
      "[98, 120] loss: 0.240\n",
      "[98, 180] loss: 0.221\n",
      "[98, 240] loss: 0.230\n",
      "[98, 300] loss: 0.226\n",
      "[98, 360] loss: 0.232\n",
      "Epoch: 98 -> Loss: 0.299914896488\n",
      "Epoch: 98 -> Test Accuracy: 83.31\n",
      "[99, 60] loss: 0.230\n",
      "[99, 120] loss: 0.237\n",
      "[99, 180] loss: 0.221\n",
      "[99, 240] loss: 0.228\n",
      "[99, 300] loss: 0.228\n",
      "[99, 360] loss: 0.229\n",
      "Epoch: 99 -> Loss: 0.356154024601\n",
      "Epoch: 99 -> Test Accuracy: 83.3\n",
      "[100, 60] loss: 0.223\n",
      "[100, 120] loss: 0.220\n",
      "[100, 180] loss: 0.223\n",
      "[100, 240] loss: 0.235\n",
      "[100, 300] loss: 0.244\n",
      "[100, 360] loss: 0.211\n",
      "Epoch: 100 -> Loss: 0.195377275348\n",
      "Epoch: 100 -> Test Accuracy: 83.36\n",
      "Finished Training\n",
      "[1, 60] loss: 1.686\n",
      "[1, 120] loss: 0.840\n",
      "[1, 180] loss: 0.756\n",
      "[1, 240] loss: 0.706\n",
      "[1, 300] loss: 0.673\n",
      "[1, 360] loss: 0.660\n",
      "Epoch: 1 -> Loss: 0.713796198368\n",
      "Epoch: 1 -> Test Accuracy: 77.76\n",
      "[2, 60] loss: 0.598\n",
      "[2, 120] loss: 0.587\n",
      "[2, 180] loss: 0.583\n",
      "[2, 240] loss: 0.578\n",
      "[2, 300] loss: 0.573\n",
      "[2, 360] loss: 0.557\n",
      "Epoch: 2 -> Loss: 0.595924735069\n",
      "Epoch: 2 -> Test Accuracy: 79.79\n",
      "[3, 60] loss: 0.532\n",
      "[3, 120] loss: 0.525\n",
      "[3, 180] loss: 0.517\n",
      "[3, 240] loss: 0.526\n",
      "[3, 300] loss: 0.490\n",
      "[3, 360] loss: 0.494\n",
      "Epoch: 3 -> Loss: 0.518764019012\n",
      "Epoch: 3 -> Test Accuracy: 81.36\n",
      "[4, 60] loss: 0.473\n",
      "[4, 120] loss: 0.490\n",
      "[4, 180] loss: 0.471\n",
      "[4, 240] loss: 0.483\n",
      "[4, 300] loss: 0.472\n",
      "[4, 360] loss: 0.495\n",
      "Epoch: 4 -> Loss: 0.465392649174\n",
      "Epoch: 4 -> Test Accuracy: 81.7\n",
      "[5, 60] loss: 0.450\n",
      "[5, 120] loss: 0.461\n",
      "[5, 180] loss: 0.470\n",
      "[5, 240] loss: 0.458\n",
      "[5, 300] loss: 0.456\n",
      "[5, 360] loss: 0.482\n",
      "Epoch: 5 -> Loss: 0.411147415638\n",
      "Epoch: 5 -> Test Accuracy: 82.79\n",
      "[6, 60] loss: 0.416\n",
      "[6, 120] loss: 0.449\n",
      "[6, 180] loss: 0.456\n",
      "[6, 240] loss: 0.440\n",
      "[6, 300] loss: 0.448\n",
      "[6, 360] loss: 0.449\n",
      "Epoch: 6 -> Loss: 0.165937781334\n",
      "Epoch: 6 -> Test Accuracy: 82.32\n",
      "[7, 60] loss: 0.417\n",
      "[7, 120] loss: 0.434\n",
      "[7, 180] loss: 0.422\n",
      "[7, 240] loss: 0.419\n",
      "[7, 300] loss: 0.434\n",
      "[7, 360] loss: 0.451\n",
      "Epoch: 7 -> Loss: 0.360976874828\n",
      "Epoch: 7 -> Test Accuracy: 82.69\n",
      "[8, 60] loss: 0.387\n",
      "[8, 120] loss: 0.378\n",
      "[8, 180] loss: 0.428\n",
      "[8, 240] loss: 0.421\n",
      "[8, 300] loss: 0.410\n",
      "[8, 360] loss: 0.434\n",
      "Epoch: 8 -> Loss: 0.630840659142\n",
      "Epoch: 8 -> Test Accuracy: 82.79\n",
      "[9, 60] loss: 0.403\n",
      "[9, 120] loss: 0.425\n",
      "[9, 180] loss: 0.404\n",
      "[9, 240] loss: 0.406\n",
      "[9, 300] loss: 0.433\n",
      "[9, 360] loss: 0.413\n",
      "Epoch: 9 -> Loss: 0.525284409523\n",
      "Epoch: 9 -> Test Accuracy: 82.96\n",
      "[10, 60] loss: 0.397\n",
      "[10, 120] loss: 0.403\n",
      "[10, 180] loss: 0.407\n",
      "[10, 240] loss: 0.397\n",
      "[10, 300] loss: 0.408\n",
      "[10, 360] loss: 0.404\n",
      "Epoch: 10 -> Loss: 0.405093044043\n",
      "Epoch: 10 -> Test Accuracy: 82.53\n",
      "[11, 60] loss: 0.383\n",
      "[11, 120] loss: 0.380\n",
      "[11, 180] loss: 0.406\n",
      "[11, 240] loss: 0.401\n",
      "[11, 300] loss: 0.397\n",
      "[11, 360] loss: 0.415\n",
      "Epoch: 11 -> Loss: 0.444411128759\n",
      "Epoch: 11 -> Test Accuracy: 83.14\n",
      "[12, 60] loss: 0.375\n",
      "[12, 120] loss: 0.383\n",
      "[12, 180] loss: 0.378\n",
      "[12, 240] loss: 0.400\n",
      "[12, 300] loss: 0.399\n",
      "[12, 360] loss: 0.411\n",
      "Epoch: 12 -> Loss: 0.423009961843\n",
      "Epoch: 12 -> Test Accuracy: 83.15\n",
      "[13, 60] loss: 0.372\n",
      "[13, 120] loss: 0.384\n",
      "[13, 180] loss: 0.374\n",
      "[13, 240] loss: 0.383\n",
      "[13, 300] loss: 0.395\n",
      "[13, 360] loss: 0.399\n",
      "Epoch: 13 -> Loss: 0.325323164463\n",
      "Epoch: 13 -> Test Accuracy: 83.02\n",
      "[14, 60] loss: 0.381\n",
      "[14, 120] loss: 0.382\n",
      "[14, 180] loss: 0.379\n",
      "[14, 240] loss: 0.380\n",
      "[14, 300] loss: 0.411\n",
      "[14, 360] loss: 0.387\n",
      "Epoch: 14 -> Loss: 0.312859266996\n",
      "Epoch: 14 -> Test Accuracy: 82.67\n",
      "[15, 60] loss: 0.376\n",
      "[15, 120] loss: 0.366\n",
      "[15, 180] loss: 0.387\n",
      "[15, 240] loss: 0.385\n",
      "[15, 300] loss: 0.380\n",
      "[15, 360] loss: 0.384\n",
      "Epoch: 15 -> Loss: 0.347870856524\n",
      "Epoch: 15 -> Test Accuracy: 83.19\n",
      "[16, 60] loss: 0.349\n",
      "[16, 120] loss: 0.386\n",
      "[16, 180] loss: 0.384\n",
      "[16, 240] loss: 0.370\n",
      "[16, 300] loss: 0.382\n",
      "[16, 360] loss: 0.387\n",
      "Epoch: 16 -> Loss: 0.615081489086\n",
      "Epoch: 16 -> Test Accuracy: 83.16\n",
      "[17, 60] loss: 0.358\n",
      "[17, 120] loss: 0.376\n",
      "[17, 180] loss: 0.359\n",
      "[17, 240] loss: 0.388\n",
      "[17, 300] loss: 0.394\n",
      "[17, 360] loss: 0.389\n",
      "Epoch: 17 -> Loss: 0.340720057487\n",
      "Epoch: 17 -> Test Accuracy: 84.04\n",
      "[18, 60] loss: 0.354\n",
      "[18, 120] loss: 0.358\n",
      "[18, 180] loss: 0.372\n",
      "[18, 240] loss: 0.372\n",
      "[18, 300] loss: 0.391\n",
      "[18, 360] loss: 0.379\n",
      "Epoch: 18 -> Loss: 0.281861931086\n",
      "Epoch: 18 -> Test Accuracy: 83.62\n",
      "[19, 60] loss: 0.361\n",
      "[19, 120] loss: 0.351\n",
      "[19, 180] loss: 0.383\n",
      "[19, 240] loss: 0.368\n",
      "[19, 300] loss: 0.392\n",
      "[19, 360] loss: 0.382\n",
      "Epoch: 19 -> Loss: 0.340991675854\n",
      "Epoch: 19 -> Test Accuracy: 83.62\n",
      "[20, 60] loss: 0.348\n",
      "[20, 120] loss: 0.356\n",
      "[20, 180] loss: 0.375\n",
      "[20, 240] loss: 0.376\n",
      "[20, 300] loss: 0.379\n",
      "[20, 360] loss: 0.377\n",
      "Epoch: 20 -> Loss: 0.524378657341\n",
      "Epoch: 20 -> Test Accuracy: 83.23\n",
      "[21, 60] loss: 0.319\n",
      "[21, 120] loss: 0.298\n",
      "[21, 180] loss: 0.297\n",
      "[21, 240] loss: 0.289\n",
      "[21, 300] loss: 0.306\n",
      "[21, 360] loss: 0.286\n",
      "Epoch: 21 -> Loss: 0.351801812649\n",
      "Epoch: 21 -> Test Accuracy: 85.3\n",
      "[22, 60] loss: 0.268\n",
      "[22, 120] loss: 0.261\n",
      "[22, 180] loss: 0.258\n",
      "[22, 240] loss: 0.257\n",
      "[22, 300] loss: 0.260\n",
      "[22, 360] loss: 0.268\n",
      "Epoch: 22 -> Loss: 0.209445759654\n",
      "Epoch: 22 -> Test Accuracy: 85.46\n",
      "[23, 60] loss: 0.245\n",
      "[23, 120] loss: 0.243\n",
      "[23, 180] loss: 0.248\n",
      "[23, 240] loss: 0.254\n",
      "[23, 300] loss: 0.251\n",
      "[23, 360] loss: 0.260\n",
      "Epoch: 23 -> Loss: 0.324668705463\n",
      "Epoch: 23 -> Test Accuracy: 85.58\n",
      "[24, 60] loss: 0.238\n",
      "[24, 120] loss: 0.237\n",
      "[24, 180] loss: 0.227\n",
      "[24, 240] loss: 0.233\n",
      "[24, 300] loss: 0.249\n",
      "[24, 360] loss: 0.236\n",
      "Epoch: 24 -> Loss: 0.232191890478\n",
      "Epoch: 24 -> Test Accuracy: 85.66\n",
      "[25, 60] loss: 0.229\n",
      "[25, 120] loss: 0.224\n",
      "[25, 180] loss: 0.228\n",
      "[25, 240] loss: 0.229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 300] loss: 0.239\n",
      "[25, 360] loss: 0.225\n",
      "Epoch: 25 -> Loss: 0.300569802523\n",
      "Epoch: 25 -> Test Accuracy: 85.45\n",
      "[26, 60] loss: 0.205\n",
      "[26, 120] loss: 0.211\n",
      "[26, 180] loss: 0.211\n",
      "[26, 240] loss: 0.227\n",
      "[26, 300] loss: 0.222\n",
      "[26, 360] loss: 0.241\n",
      "Epoch: 26 -> Loss: 0.433524310589\n",
      "Epoch: 26 -> Test Accuracy: 85.83\n",
      "[27, 60] loss: 0.212\n",
      "[27, 120] loss: 0.215\n",
      "[27, 180] loss: 0.205\n",
      "[27, 240] loss: 0.211\n",
      "[27, 300] loss: 0.216\n",
      "[27, 360] loss: 0.221\n",
      "Epoch: 27 -> Loss: 0.362206399441\n",
      "Epoch: 27 -> Test Accuracy: 85.71\n",
      "[28, 60] loss: 0.199\n",
      "[28, 120] loss: 0.220\n",
      "[28, 180] loss: 0.209\n",
      "[28, 240] loss: 0.212\n",
      "[28, 300] loss: 0.211\n",
      "[28, 360] loss: 0.220\n",
      "Epoch: 28 -> Loss: 0.257372438908\n",
      "Epoch: 28 -> Test Accuracy: 85.53\n",
      "[29, 60] loss: 0.196\n",
      "[29, 120] loss: 0.199\n",
      "[29, 180] loss: 0.212\n",
      "[29, 240] loss: 0.199\n",
      "[29, 300] loss: 0.205\n",
      "[29, 360] loss: 0.215\n",
      "Epoch: 29 -> Loss: 0.143148645759\n",
      "Epoch: 29 -> Test Accuracy: 85.44\n",
      "[30, 60] loss: 0.200\n",
      "[30, 120] loss: 0.200\n",
      "[30, 180] loss: 0.203\n",
      "[30, 240] loss: 0.204\n",
      "[30, 300] loss: 0.197\n",
      "[30, 360] loss: 0.222\n",
      "Epoch: 30 -> Loss: 0.274869740009\n",
      "Epoch: 30 -> Test Accuracy: 85.21\n",
      "[31, 60] loss: 0.203\n",
      "[31, 120] loss: 0.199\n",
      "[31, 180] loss: 0.192\n",
      "[31, 240] loss: 0.201\n",
      "[31, 300] loss: 0.197\n",
      "[31, 360] loss: 0.218\n",
      "Epoch: 31 -> Loss: 0.222203657031\n",
      "Epoch: 31 -> Test Accuracy: 85.59\n",
      "[32, 60] loss: 0.196\n",
      "[32, 120] loss: 0.192\n",
      "[32, 180] loss: 0.200\n",
      "[32, 240] loss: 0.197\n",
      "[32, 300] loss: 0.197\n",
      "[32, 360] loss: 0.210\n",
      "Epoch: 32 -> Loss: 0.371835768223\n",
      "Epoch: 32 -> Test Accuracy: 85.6\n",
      "[33, 60] loss: 0.198\n",
      "[33, 120] loss: 0.199\n",
      "[33, 180] loss: 0.196\n",
      "[33, 240] loss: 0.206\n",
      "[33, 300] loss: 0.197\n",
      "[33, 360] loss: 0.216\n",
      "Epoch: 33 -> Loss: 0.23426926136\n",
      "Epoch: 33 -> Test Accuracy: 85.41\n",
      "[34, 60] loss: 0.196\n",
      "[34, 120] loss: 0.199\n",
      "[34, 180] loss: 0.193\n",
      "[34, 240] loss: 0.192\n",
      "[34, 300] loss: 0.195\n",
      "[34, 360] loss: 0.209\n",
      "Epoch: 34 -> Loss: 0.187549471855\n",
      "Epoch: 34 -> Test Accuracy: 85.62\n",
      "[35, 60] loss: 0.192\n",
      "[35, 120] loss: 0.195\n",
      "[35, 180] loss: 0.195\n",
      "[35, 240] loss: 0.204\n",
      "[35, 300] loss: 0.201\n",
      "[35, 360] loss: 0.214\n",
      "Epoch: 35 -> Loss: 0.164348036051\n",
      "Epoch: 35 -> Test Accuracy: 85.47\n",
      "[36, 60] loss: 0.179\n",
      "[36, 120] loss: 0.192\n",
      "[36, 180] loss: 0.192\n",
      "[36, 240] loss: 0.210\n",
      "[36, 300] loss: 0.191\n",
      "[36, 360] loss: 0.201\n",
      "Epoch: 36 -> Loss: 0.246576979756\n",
      "Epoch: 36 -> Test Accuracy: 84.98\n",
      "[37, 60] loss: 0.191\n",
      "[37, 120] loss: 0.200\n",
      "[37, 180] loss: 0.186\n",
      "[37, 240] loss: 0.208\n",
      "[37, 300] loss: 0.217\n",
      "[37, 360] loss: 0.201\n",
      "Epoch: 37 -> Loss: 0.302735447884\n",
      "Epoch: 37 -> Test Accuracy: 85.46\n",
      "[38, 60] loss: 0.184\n",
      "[38, 120] loss: 0.183\n",
      "[38, 180] loss: 0.196\n",
      "[38, 240] loss: 0.201\n",
      "[38, 300] loss: 0.202\n",
      "[38, 360] loss: 0.213\n",
      "Epoch: 38 -> Loss: 0.264276355505\n",
      "Epoch: 38 -> Test Accuracy: 85.4\n",
      "[39, 60] loss: 0.192\n",
      "[39, 120] loss: 0.190\n",
      "[39, 180] loss: 0.203\n",
      "[39, 240] loss: 0.201\n",
      "[39, 300] loss: 0.195\n",
      "[39, 360] loss: 0.202\n",
      "Epoch: 39 -> Loss: 0.261293321848\n",
      "Epoch: 39 -> Test Accuracy: 85.6\n",
      "[40, 60] loss: 0.180\n",
      "[40, 120] loss: 0.191\n",
      "[40, 180] loss: 0.202\n",
      "[40, 240] loss: 0.207\n",
      "[40, 300] loss: 0.198\n",
      "[40, 360] loss: 0.197\n",
      "Epoch: 40 -> Loss: 0.253127634525\n",
      "Epoch: 40 -> Test Accuracy: 85.1\n",
      "[41, 60] loss: 0.170\n",
      "[41, 120] loss: 0.165\n",
      "[41, 180] loss: 0.159\n",
      "[41, 240] loss: 0.162\n",
      "[41, 300] loss: 0.149\n",
      "[41, 360] loss: 0.150\n",
      "Epoch: 41 -> Loss: 0.160399034619\n",
      "Epoch: 41 -> Test Accuracy: 86.11\n",
      "[42, 60] loss: 0.153\n",
      "[42, 120] loss: 0.144\n",
      "[42, 180] loss: 0.147\n",
      "[42, 240] loss: 0.146\n",
      "[42, 300] loss: 0.158\n",
      "[42, 360] loss: 0.149\n",
      "Epoch: 42 -> Loss: 0.144291177392\n",
      "Epoch: 42 -> Test Accuracy: 86.14\n",
      "[43, 60] loss: 0.132\n",
      "[43, 120] loss: 0.134\n",
      "[43, 180] loss: 0.135\n",
      "[43, 240] loss: 0.133\n",
      "[43, 300] loss: 0.149\n",
      "[43, 360] loss: 0.134\n",
      "Epoch: 43 -> Loss: 0.0491929352283\n",
      "Epoch: 43 -> Test Accuracy: 86.23\n",
      "[44, 60] loss: 0.131\n",
      "[44, 120] loss: 0.131\n",
      "[44, 180] loss: 0.133\n",
      "[44, 240] loss: 0.133\n",
      "[44, 300] loss: 0.124\n",
      "[44, 360] loss: 0.130\n",
      "Epoch: 44 -> Loss: 0.133320182562\n",
      "Epoch: 44 -> Test Accuracy: 86.01\n",
      "[45, 60] loss: 0.119\n",
      "[45, 120] loss: 0.125\n",
      "[45, 180] loss: 0.128\n",
      "[45, 240] loss: 0.121\n",
      "[45, 300] loss: 0.122\n",
      "[45, 360] loss: 0.121\n",
      "Epoch: 45 -> Loss: 0.129909679294\n",
      "Epoch: 45 -> Test Accuracy: 86.21\n",
      "[46, 60] loss: 0.117\n",
      "[46, 120] loss: 0.121\n",
      "[46, 180] loss: 0.117\n",
      "[46, 240] loss: 0.115\n",
      "[46, 300] loss: 0.127\n",
      "[46, 360] loss: 0.120\n",
      "Epoch: 46 -> Loss: 0.0729660987854\n",
      "Epoch: 46 -> Test Accuracy: 86.23\n",
      "[47, 60] loss: 0.118\n",
      "[47, 120] loss: 0.123\n",
      "[47, 180] loss: 0.115\n",
      "[47, 240] loss: 0.113\n",
      "[47, 300] loss: 0.121\n",
      "[47, 360] loss: 0.116\n",
      "Epoch: 47 -> Loss: 0.077927313745\n",
      "Epoch: 47 -> Test Accuracy: 86.19\n",
      "[48, 60] loss: 0.119\n",
      "[48, 120] loss: 0.112\n",
      "[48, 180] loss: 0.117\n",
      "[48, 240] loss: 0.110\n",
      "[48, 300] loss: 0.127\n",
      "[48, 360] loss: 0.119\n",
      "Epoch: 48 -> Loss: 0.179509848356\n",
      "Epoch: 48 -> Test Accuracy: 86.27\n",
      "[49, 60] loss: 0.109\n",
      "[49, 120] loss: 0.112\n",
      "[49, 180] loss: 0.108\n",
      "[49, 240] loss: 0.108\n",
      "[49, 300] loss: 0.109\n",
      "[49, 360] loss: 0.117\n",
      "Epoch: 49 -> Loss: 0.103594362736\n",
      "Epoch: 49 -> Test Accuracy: 86.31\n",
      "[50, 60] loss: 0.111\n",
      "[50, 120] loss: 0.102\n",
      "[50, 180] loss: 0.121\n",
      "[50, 240] loss: 0.115\n",
      "[50, 300] loss: 0.108\n",
      "[50, 360] loss: 0.105\n",
      "Epoch: 50 -> Loss: 0.0925953537226\n",
      "Epoch: 50 -> Test Accuracy: 86.31\n",
      "[51, 60] loss: 0.114\n",
      "[51, 120] loss: 0.106\n",
      "[51, 180] loss: 0.102\n",
      "[51, 240] loss: 0.117\n",
      "[51, 300] loss: 0.112\n",
      "[51, 360] loss: 0.102\n",
      "Epoch: 51 -> Loss: 0.161107063293\n",
      "Epoch: 51 -> Test Accuracy: 86.45\n",
      "[52, 60] loss: 0.106\n",
      "[52, 120] loss: 0.105\n",
      "[52, 180] loss: 0.111\n",
      "[52, 240] loss: 0.106\n",
      "[52, 300] loss: 0.108\n",
      "[52, 360] loss: 0.107\n",
      "Epoch: 52 -> Loss: 0.182375609875\n",
      "Epoch: 52 -> Test Accuracy: 86.42\n",
      "[53, 60] loss: 0.107\n",
      "[53, 120] loss: 0.111\n",
      "[53, 180] loss: 0.106\n",
      "[53, 240] loss: 0.105\n",
      "[53, 300] loss: 0.109\n",
      "[53, 360] loss: 0.103\n",
      "Epoch: 53 -> Loss: 0.0726860314608\n",
      "Epoch: 53 -> Test Accuracy: 86.48\n",
      "[54, 60] loss: 0.104\n",
      "[54, 120] loss: 0.102\n",
      "[54, 180] loss: 0.103\n",
      "[54, 240] loss: 0.101\n",
      "[54, 300] loss: 0.117\n",
      "[54, 360] loss: 0.101\n",
      "Epoch: 54 -> Loss: 0.128568321466\n",
      "Epoch: 54 -> Test Accuracy: 86.42\n",
      "[55, 60] loss: 0.104\n",
      "[55, 120] loss: 0.097\n",
      "[55, 180] loss: 0.099\n",
      "[55, 240] loss: 0.106\n",
      "[55, 300] loss: 0.105\n",
      "[55, 360] loss: 0.110\n",
      "Epoch: 55 -> Loss: 0.0842778533697\n",
      "Epoch: 55 -> Test Accuracy: 86.42\n",
      "[56, 60] loss: 0.103\n",
      "[56, 120] loss: 0.101\n",
      "[56, 180] loss: 0.106\n",
      "[56, 240] loss: 0.113\n",
      "[56, 300] loss: 0.103\n",
      "[56, 360] loss: 0.092\n",
      "Epoch: 56 -> Loss: 0.144144266844\n",
      "Epoch: 56 -> Test Accuracy: 86.44\n",
      "[57, 60] loss: 0.099\n",
      "[57, 120] loss: 0.099\n",
      "[57, 180] loss: 0.114\n",
      "[57, 240] loss: 0.102\n",
      "[57, 300] loss: 0.109\n",
      "[57, 360] loss: 0.106\n",
      "Epoch: 57 -> Loss: 0.178204581141\n",
      "Epoch: 57 -> Test Accuracy: 86.45\n",
      "[58, 60] loss: 0.098\n",
      "[58, 120] loss: 0.103\n",
      "[58, 180] loss: 0.105\n",
      "[58, 240] loss: 0.102\n",
      "[58, 300] loss: 0.103\n",
      "[58, 360] loss: 0.113\n",
      "Epoch: 58 -> Loss: 0.0632279366255\n",
      "Epoch: 58 -> Test Accuracy: 86.48\n",
      "[59, 60] loss: 0.097\n",
      "[59, 120] loss: 0.104\n",
      "[59, 180] loss: 0.105\n",
      "[59, 240] loss: 0.098\n",
      "[59, 300] loss: 0.105\n",
      "[59, 360] loss: 0.102\n",
      "Epoch: 59 -> Loss: 0.133172228932\n",
      "Epoch: 59 -> Test Accuracy: 86.4\n",
      "[60, 60] loss: 0.112\n",
      "[60, 120] loss: 0.101\n",
      "[60, 180] loss: 0.105\n",
      "[60, 240] loss: 0.097\n",
      "[60, 300] loss: 0.100\n",
      "[60, 360] loss: 0.101\n",
      "Epoch: 60 -> Loss: 0.0819771662354\n",
      "Epoch: 60 -> Test Accuracy: 86.48\n",
      "[61, 60] loss: 0.099\n",
      "[61, 120] loss: 0.101\n",
      "[61, 180] loss: 0.094\n",
      "[61, 240] loss: 0.096\n",
      "[61, 300] loss: 0.097\n",
      "[61, 360] loss: 0.103\n",
      "Epoch: 61 -> Loss: 0.0976850166917\n",
      "Epoch: 61 -> Test Accuracy: 86.44\n",
      "[62, 60] loss: 0.099\n",
      "[62, 120] loss: 0.103\n",
      "[62, 180] loss: 0.094\n",
      "[62, 240] loss: 0.100\n",
      "[62, 300] loss: 0.094\n",
      "[62, 360] loss: 0.101\n",
      "Epoch: 62 -> Loss: 0.0851505249739\n",
      "Epoch: 62 -> Test Accuracy: 86.44\n",
      "[63, 60] loss: 0.100\n",
      "[63, 120] loss: 0.092\n",
      "[63, 180] loss: 0.102\n",
      "[63, 240] loss: 0.098\n",
      "[63, 300] loss: 0.104\n",
      "[63, 360] loss: 0.094\n",
      "Epoch: 63 -> Loss: 0.0947118923068\n",
      "Epoch: 63 -> Test Accuracy: 86.43\n",
      "[64, 60] loss: 0.092\n",
      "[64, 120] loss: 0.097\n",
      "[64, 180] loss: 0.099\n",
      "[64, 240] loss: 0.096\n",
      "[64, 300] loss: 0.102\n",
      "[64, 360] loss: 0.098\n",
      "Epoch: 64 -> Loss: 0.123699858785\n",
      "Epoch: 64 -> Test Accuracy: 86.45\n",
      "[65, 60] loss: 0.106\n",
      "[65, 120] loss: 0.093\n",
      "[65, 180] loss: 0.092\n",
      "[65, 240] loss: 0.089\n",
      "[65, 300] loss: 0.095\n",
      "[65, 360] loss: 0.097\n",
      "Epoch: 65 -> Loss: 0.109273180366\n",
      "Epoch: 65 -> Test Accuracy: 86.39\n",
      "[66, 60] loss: 0.089\n",
      "[66, 120] loss: 0.100\n",
      "[66, 180] loss: 0.100\n",
      "[66, 240] loss: 0.096\n",
      "[66, 300] loss: 0.097\n",
      "[66, 360] loss: 0.093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Loss: 0.0894470512867\n",
      "Epoch: 66 -> Test Accuracy: 86.49\n",
      "[67, 60] loss: 0.100\n",
      "[67, 120] loss: 0.097\n",
      "[67, 180] loss: 0.094\n",
      "[67, 240] loss: 0.092\n",
      "[67, 300] loss: 0.103\n",
      "[67, 360] loss: 0.099\n",
      "Epoch: 67 -> Loss: 0.0494847781956\n",
      "Epoch: 67 -> Test Accuracy: 86.48\n",
      "[68, 60] loss: 0.092\n",
      "[68, 120] loss: 0.092\n",
      "[68, 180] loss: 0.102\n",
      "[68, 240] loss: 0.095\n",
      "[68, 300] loss: 0.088\n",
      "[68, 360] loss: 0.089\n",
      "Epoch: 68 -> Loss: 0.0702943652868\n",
      "Epoch: 68 -> Test Accuracy: 86.49\n",
      "[69, 60] loss: 0.092\n",
      "[69, 120] loss: 0.090\n",
      "[69, 180] loss: 0.098\n",
      "[69, 240] loss: 0.085\n",
      "[69, 300] loss: 0.098\n",
      "[69, 360] loss: 0.098\n",
      "Epoch: 69 -> Loss: 0.0853680148721\n",
      "Epoch: 69 -> Test Accuracy: 86.28\n",
      "[70, 60] loss: 0.091\n",
      "[70, 120] loss: 0.099\n",
      "[70, 180] loss: 0.092\n",
      "[70, 240] loss: 0.092\n",
      "[70, 300] loss: 0.094\n",
      "[70, 360] loss: 0.092\n",
      "Epoch: 70 -> Loss: 0.0688676387072\n",
      "Epoch: 70 -> Test Accuracy: 86.28\n",
      "[71, 60] loss: 0.090\n",
      "[71, 120] loss: 0.090\n",
      "[71, 180] loss: 0.090\n",
      "[71, 240] loss: 0.085\n",
      "[71, 300] loss: 0.097\n",
      "[71, 360] loss: 0.088\n",
      "Epoch: 71 -> Loss: 0.113015212119\n",
      "Epoch: 71 -> Test Accuracy: 86.31\n",
      "[72, 60] loss: 0.094\n",
      "[72, 120] loss: 0.085\n",
      "[72, 180] loss: 0.089\n",
      "[72, 240] loss: 0.092\n",
      "[72, 300] loss: 0.090\n",
      "[72, 360] loss: 0.091\n",
      "Epoch: 72 -> Loss: 0.0366297662258\n",
      "Epoch: 72 -> Test Accuracy: 86.27\n",
      "[73, 60] loss: 0.091\n",
      "[73, 120] loss: 0.095\n",
      "[73, 180] loss: 0.089\n",
      "[73, 240] loss: 0.095\n",
      "[73, 300] loss: 0.088\n",
      "[73, 360] loss: 0.089\n",
      "Epoch: 73 -> Loss: 0.0860002413392\n",
      "Epoch: 73 -> Test Accuracy: 86.3\n",
      "[74, 60] loss: 0.090\n",
      "[74, 120] loss: 0.089\n",
      "[74, 180] loss: 0.088\n",
      "[74, 240] loss: 0.089\n",
      "[74, 300] loss: 0.096\n",
      "[74, 360] loss: 0.087\n",
      "Epoch: 74 -> Loss: 0.12122604996\n",
      "Epoch: 74 -> Test Accuracy: 86.25\n",
      "[75, 60] loss: 0.100\n",
      "[75, 120] loss: 0.086\n",
      "[75, 180] loss: 0.092\n",
      "[75, 240] loss: 0.092\n",
      "[75, 300] loss: 0.087\n",
      "[75, 360] loss: 0.092\n",
      "Epoch: 75 -> Loss: 0.143907442689\n",
      "Epoch: 75 -> Test Accuracy: 86.3\n",
      "[76, 60] loss: 0.092\n",
      "[76, 120] loss: 0.088\n",
      "[76, 180] loss: 0.084\n",
      "[76, 240] loss: 0.092\n",
      "[76, 300] loss: 0.087\n",
      "[76, 360] loss: 0.086\n",
      "Epoch: 76 -> Loss: 0.132823690772\n",
      "Epoch: 76 -> Test Accuracy: 86.25\n",
      "[77, 60] loss: 0.093\n",
      "[77, 120] loss: 0.090\n",
      "[77, 180] loss: 0.084\n",
      "[77, 240] loss: 0.084\n",
      "[77, 300] loss: 0.094\n",
      "[77, 360] loss: 0.086\n",
      "Epoch: 77 -> Loss: 0.0807822346687\n",
      "Epoch: 77 -> Test Accuracy: 86.27\n",
      "[78, 60] loss: 0.093\n",
      "[78, 120] loss: 0.086\n",
      "[78, 180] loss: 0.086\n",
      "[78, 240] loss: 0.085\n",
      "[78, 300] loss: 0.088\n",
      "[78, 360] loss: 0.088\n",
      "Epoch: 78 -> Loss: 0.153176814318\n",
      "Epoch: 78 -> Test Accuracy: 86.33\n",
      "[79, 60] loss: 0.090\n",
      "[79, 120] loss: 0.083\n",
      "[79, 180] loss: 0.088\n",
      "[79, 240] loss: 0.086\n",
      "[79, 300] loss: 0.089\n",
      "[79, 360] loss: 0.092\n",
      "Epoch: 79 -> Loss: 0.069150172174\n",
      "Epoch: 79 -> Test Accuracy: 86.4\n",
      "[80, 60] loss: 0.089\n",
      "[80, 120] loss: 0.086\n",
      "[80, 180] loss: 0.080\n",
      "[80, 240] loss: 0.085\n",
      "[80, 300] loss: 0.086\n",
      "[80, 360] loss: 0.086\n",
      "Epoch: 80 -> Loss: 0.157168626785\n",
      "Epoch: 80 -> Test Accuracy: 86.39\n",
      "[81, 60] loss: 0.087\n",
      "[81, 120] loss: 0.089\n",
      "[81, 180] loss: 0.079\n",
      "[81, 240] loss: 0.087\n",
      "[81, 300] loss: 0.079\n",
      "[81, 360] loss: 0.084\n",
      "Epoch: 81 -> Loss: 0.0581612065434\n",
      "Epoch: 81 -> Test Accuracy: 86.32\n",
      "[82, 60] loss: 0.086\n",
      "[82, 120] loss: 0.084\n",
      "[82, 180] loss: 0.084\n",
      "[82, 240] loss: 0.089\n",
      "[82, 300] loss: 0.082\n",
      "[82, 360] loss: 0.085\n",
      "Epoch: 82 -> Loss: 0.0901796296239\n",
      "Epoch: 82 -> Test Accuracy: 86.45\n",
      "[83, 60] loss: 0.089\n",
      "[83, 120] loss: 0.087\n",
      "[83, 180] loss: 0.086\n",
      "[83, 240] loss: 0.092\n",
      "[83, 300] loss: 0.088\n",
      "[83, 360] loss: 0.087\n",
      "Epoch: 83 -> Loss: 0.0761756971478\n",
      "Epoch: 83 -> Test Accuracy: 86.35\n",
      "[84, 60] loss: 0.084\n",
      "[84, 120] loss: 0.088\n",
      "[84, 180] loss: 0.086\n",
      "[84, 240] loss: 0.085\n",
      "[84, 300] loss: 0.088\n",
      "[84, 360] loss: 0.080\n",
      "Epoch: 84 -> Loss: 0.0576263293624\n",
      "Epoch: 84 -> Test Accuracy: 86.41\n",
      "[85, 60] loss: 0.090\n",
      "[85, 120] loss: 0.079\n",
      "[85, 180] loss: 0.086\n",
      "[85, 240] loss: 0.088\n",
      "[85, 300] loss: 0.086\n",
      "[85, 360] loss: 0.088\n",
      "Epoch: 85 -> Loss: 0.0629512444139\n",
      "Epoch: 85 -> Test Accuracy: 86.43\n",
      "[86, 60] loss: 0.080\n",
      "[86, 120] loss: 0.084\n",
      "[86, 180] loss: 0.084\n",
      "[86, 240] loss: 0.080\n",
      "[86, 300] loss: 0.077\n",
      "[86, 360] loss: 0.087\n",
      "Epoch: 86 -> Loss: 0.153497621417\n",
      "Epoch: 86 -> Test Accuracy: 86.41\n",
      "[87, 60] loss: 0.086\n",
      "[87, 120] loss: 0.082\n",
      "[87, 180] loss: 0.077\n",
      "[87, 240] loss: 0.082\n",
      "[87, 300] loss: 0.084\n",
      "[87, 360] loss: 0.082\n",
      "Epoch: 87 -> Loss: 0.0447465181351\n",
      "Epoch: 87 -> Test Accuracy: 86.33\n",
      "[88, 60] loss: 0.081\n",
      "[88, 120] loss: 0.077\n",
      "[88, 180] loss: 0.080\n",
      "[88, 240] loss: 0.077\n",
      "[88, 300] loss: 0.085\n",
      "[88, 360] loss: 0.077\n",
      "Epoch: 88 -> Loss: 0.0640726983547\n",
      "Epoch: 88 -> Test Accuracy: 86.17\n",
      "[89, 60] loss: 0.085\n",
      "[89, 120] loss: 0.080\n",
      "[89, 180] loss: 0.081\n",
      "[89, 240] loss: 0.079\n",
      "[89, 300] loss: 0.079\n",
      "[89, 360] loss: 0.079\n",
      "Epoch: 89 -> Loss: 0.0466304011643\n",
      "Epoch: 89 -> Test Accuracy: 86.41\n",
      "[90, 60] loss: 0.084\n",
      "[90, 120] loss: 0.072\n",
      "[90, 180] loss: 0.083\n",
      "[90, 240] loss: 0.083\n",
      "[90, 300] loss: 0.079\n",
      "[90, 360] loss: 0.082\n",
      "Epoch: 90 -> Loss: 0.127213865519\n",
      "Epoch: 90 -> Test Accuracy: 86.44\n",
      "[91, 60] loss: 0.079\n",
      "[91, 120] loss: 0.081\n",
      "[91, 180] loss: 0.076\n",
      "[91, 240] loss: 0.083\n",
      "[91, 300] loss: 0.082\n",
      "[91, 360] loss: 0.079\n",
      "Epoch: 91 -> Loss: 0.134540230036\n",
      "Epoch: 91 -> Test Accuracy: 86.31\n",
      "[92, 60] loss: 0.081\n",
      "[92, 120] loss: 0.087\n",
      "[92, 180] loss: 0.075\n",
      "[92, 240] loss: 0.081\n",
      "[92, 300] loss: 0.079\n",
      "[92, 360] loss: 0.076\n",
      "Epoch: 92 -> Loss: 0.089403539896\n",
      "Epoch: 92 -> Test Accuracy: 86.26\n",
      "[93, 60] loss: 0.078\n",
      "[93, 120] loss: 0.078\n",
      "[93, 180] loss: 0.087\n",
      "[93, 240] loss: 0.079\n",
      "[93, 300] loss: 0.079\n",
      "[93, 360] loss: 0.074\n",
      "Epoch: 93 -> Loss: 0.10926129669\n",
      "Epoch: 93 -> Test Accuracy: 86.23\n",
      "[94, 60] loss: 0.076\n",
      "[94, 120] loss: 0.082\n",
      "[94, 180] loss: 0.082\n",
      "[94, 240] loss: 0.078\n",
      "[94, 300] loss: 0.079\n",
      "[94, 360] loss: 0.079\n",
      "Epoch: 94 -> Loss: 0.111430846155\n",
      "Epoch: 94 -> Test Accuracy: 86.42\n",
      "[95, 60] loss: 0.080\n",
      "[95, 120] loss: 0.081\n",
      "[95, 180] loss: 0.077\n",
      "[95, 240] loss: 0.078\n",
      "[95, 300] loss: 0.076\n",
      "[95, 360] loss: 0.080\n",
      "Epoch: 95 -> Loss: 0.156692311168\n",
      "Epoch: 95 -> Test Accuracy: 86.3\n",
      "[96, 60] loss: 0.076\n",
      "[96, 120] loss: 0.077\n",
      "[96, 180] loss: 0.079\n",
      "[96, 240] loss: 0.076\n",
      "[96, 300] loss: 0.079\n",
      "[96, 360] loss: 0.076\n",
      "Epoch: 96 -> Loss: 0.094629868865\n",
      "Epoch: 96 -> Test Accuracy: 86.29\n",
      "[97, 60] loss: 0.082\n",
      "[97, 120] loss: 0.073\n",
      "[97, 180] loss: 0.076\n",
      "[97, 240] loss: 0.076\n",
      "[97, 300] loss: 0.075\n",
      "[97, 360] loss: 0.081\n",
      "Epoch: 97 -> Loss: 0.104439616203\n",
      "Epoch: 97 -> Test Accuracy: 86.27\n",
      "[98, 60] loss: 0.070\n",
      "[98, 120] loss: 0.079\n",
      "[98, 180] loss: 0.076\n",
      "[98, 240] loss: 0.075\n",
      "[98, 300] loss: 0.080\n",
      "[98, 360] loss: 0.073\n",
      "Epoch: 98 -> Loss: 0.0386635959148\n",
      "Epoch: 98 -> Test Accuracy: 86.28\n",
      "[99, 60] loss: 0.074\n",
      "[99, 120] loss: 0.072\n",
      "[99, 180] loss: 0.071\n",
      "[99, 240] loss: 0.074\n",
      "[99, 300] loss: 0.078\n",
      "[99, 360] loss: 0.081\n",
      "Epoch: 99 -> Loss: 0.177420154214\n",
      "Epoch: 99 -> Test Accuracy: 86.28\n",
      "[100, 60] loss: 0.079\n",
      "[100, 120] loss: 0.073\n",
      "[100, 180] loss: 0.076\n",
      "[100, 240] loss: 0.071\n",
      "[100, 300] loss: 0.075\n",
      "[100, 360] loss: 0.071\n",
      "Epoch: 100 -> Loss: 0.0590741336346\n",
      "Epoch: 100 -> Test Accuracy: 86.33\n",
      "Finished Training\n",
      "[1, 60] loss: 1.694\n",
      "[1, 120] loss: 0.920\n",
      "[1, 180] loss: 0.862\n",
      "[1, 240] loss: 0.805\n",
      "[1, 300] loss: 0.770\n",
      "[1, 360] loss: 0.728\n",
      "Epoch: 1 -> Loss: 0.743055701256\n",
      "Epoch: 1 -> Test Accuracy: 71.81\n",
      "[2, 60] loss: 0.712\n",
      "[2, 120] loss: 0.694\n",
      "[2, 180] loss: 0.687\n",
      "[2, 240] loss: 0.671\n",
      "[2, 300] loss: 0.672\n",
      "[2, 360] loss: 0.665\n",
      "Epoch: 2 -> Loss: 0.871465981007\n",
      "Epoch: 2 -> Test Accuracy: 75.53\n",
      "[3, 60] loss: 0.640\n",
      "[3, 120] loss: 0.641\n",
      "[3, 180] loss: 0.617\n",
      "[3, 240] loss: 0.631\n",
      "[3, 300] loss: 0.615\n",
      "[3, 360] loss: 0.616\n",
      "Epoch: 3 -> Loss: 0.698072552681\n",
      "Epoch: 3 -> Test Accuracy: 75.06\n",
      "[4, 60] loss: 0.606\n",
      "[4, 120] loss: 0.617\n",
      "[4, 180] loss: 0.590\n",
      "[4, 240] loss: 0.613\n",
      "[4, 300] loss: 0.606\n",
      "[4, 360] loss: 0.586\n",
      "Epoch: 4 -> Loss: 0.576387405396\n",
      "Epoch: 4 -> Test Accuracy: 77.32\n",
      "[5, 60] loss: 0.565\n",
      "[5, 120] loss: 0.586\n",
      "[5, 180] loss: 0.590\n",
      "[5, 240] loss: 0.572\n",
      "[5, 300] loss: 0.573\n",
      "[5, 360] loss: 0.607\n",
      "Epoch: 5 -> Loss: 0.631888747215\n",
      "Epoch: 5 -> Test Accuracy: 76.83\n",
      "[6, 60] loss: 0.559\n",
      "[6, 120] loss: 0.574\n",
      "[6, 180] loss: 0.569\n",
      "[6, 240] loss: 0.581\n",
      "[6, 300] loss: 0.570\n",
      "[6, 360] loss: 0.565\n",
      "Epoch: 6 -> Loss: 0.525481045246\n",
      "Epoch: 6 -> Test Accuracy: 76.77\n",
      "[7, 60] loss: 0.553\n",
      "[7, 120] loss: 0.543\n",
      "[7, 180] loss: 0.555\n",
      "[7, 240] loss: 0.557\n",
      "[7, 300] loss: 0.554\n",
      "[7, 360] loss: 0.574\n",
      "Epoch: 7 -> Loss: 0.742649674416\n",
      "Epoch: 7 -> Test Accuracy: 78.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 60] loss: 0.552\n",
      "[8, 120] loss: 0.558\n",
      "[8, 180] loss: 0.564\n",
      "[8, 240] loss: 0.550\n",
      "[8, 300] loss: 0.560\n",
      "[8, 360] loss: 0.557\n",
      "Epoch: 8 -> Loss: 0.55362290144\n",
      "Epoch: 8 -> Test Accuracy: 78.19\n",
      "[9, 60] loss: 0.529\n",
      "[9, 120] loss: 0.548\n",
      "[9, 180] loss: 0.537\n",
      "[9, 240] loss: 0.538\n",
      "[9, 300] loss: 0.551\n",
      "[9, 360] loss: 0.548\n",
      "Epoch: 9 -> Loss: 0.710620522499\n",
      "Epoch: 9 -> Test Accuracy: 78.12\n",
      "[10, 60] loss: 0.521\n",
      "[10, 120] loss: 0.559\n",
      "[10, 180] loss: 0.547\n",
      "[10, 240] loss: 0.536\n",
      "[10, 300] loss: 0.536\n",
      "[10, 360] loss: 0.530\n",
      "Epoch: 10 -> Loss: 0.496505737305\n",
      "Epoch: 10 -> Test Accuracy: 78.08\n",
      "[11, 60] loss: 0.523\n",
      "[11, 120] loss: 0.532\n",
      "[11, 180] loss: 0.529\n",
      "[11, 240] loss: 0.536\n",
      "[11, 300] loss: 0.549\n",
      "[11, 360] loss: 0.545\n",
      "Epoch: 11 -> Loss: 0.558529138565\n",
      "Epoch: 11 -> Test Accuracy: 76.92\n",
      "[12, 60] loss: 0.542\n",
      "[12, 120] loss: 0.515\n",
      "[12, 180] loss: 0.531\n",
      "[12, 240] loss: 0.540\n",
      "[12, 300] loss: 0.545\n",
      "[12, 360] loss: 0.524\n",
      "Epoch: 12 -> Loss: 0.35805401206\n",
      "Epoch: 12 -> Test Accuracy: 78.24\n",
      "[13, 60] loss: 0.518\n",
      "[13, 120] loss: 0.519\n",
      "[13, 180] loss: 0.530\n",
      "[13, 240] loss: 0.542\n",
      "[13, 300] loss: 0.524\n",
      "[13, 360] loss: 0.531\n",
      "Epoch: 13 -> Loss: 0.75237673521\n",
      "Epoch: 13 -> Test Accuracy: 78.14\n",
      "[14, 60] loss: 0.534\n",
      "[14, 120] loss: 0.514\n",
      "[14, 180] loss: 0.532\n",
      "[14, 240] loss: 0.520\n",
      "[14, 300] loss: 0.539\n",
      "[14, 360] loss: 0.503\n",
      "Epoch: 14 -> Loss: 0.575156092644\n",
      "Epoch: 14 -> Test Accuracy: 78.78\n",
      "[15, 60] loss: 0.497\n",
      "[15, 120] loss: 0.525\n",
      "[15, 180] loss: 0.527\n",
      "[15, 240] loss: 0.511\n",
      "[15, 300] loss: 0.526\n",
      "[15, 360] loss: 0.516\n",
      "Epoch: 15 -> Loss: 0.491432487965\n",
      "Epoch: 15 -> Test Accuracy: 77.48\n",
      "[16, 60] loss: 0.516\n",
      "[16, 120] loss: 0.496\n",
      "[16, 180] loss: 0.520\n",
      "[16, 240] loss: 0.510\n",
      "[16, 300] loss: 0.519\n",
      "[16, 360] loss: 0.538\n",
      "Epoch: 16 -> Loss: 0.466390550137\n",
      "Epoch: 16 -> Test Accuracy: 78.23\n",
      "[17, 60] loss: 0.491\n",
      "[17, 120] loss: 0.486\n",
      "[17, 180] loss: 0.528\n",
      "[17, 240] loss: 0.509\n",
      "[17, 300] loss: 0.534\n",
      "[17, 360] loss: 0.525\n",
      "Epoch: 17 -> Loss: 0.72870272398\n",
      "Epoch: 17 -> Test Accuracy: 77.92\n",
      "[18, 60] loss: 0.489\n",
      "[18, 120] loss: 0.518\n",
      "[18, 180] loss: 0.513\n",
      "[18, 240] loss: 0.522\n",
      "[18, 300] loss: 0.526\n",
      "[18, 360] loss: 0.530\n",
      "Epoch: 18 -> Loss: 0.549607992172\n",
      "Epoch: 18 -> Test Accuracy: 78.06\n",
      "[19, 60] loss: 0.513\n",
      "[19, 120] loss: 0.522\n",
      "[19, 180] loss: 0.503\n",
      "[19, 240] loss: 0.523\n",
      "[19, 300] loss: 0.494\n",
      "[19, 360] loss: 0.519\n",
      "Epoch: 19 -> Loss: 0.405904442072\n",
      "Epoch: 19 -> Test Accuracy: 78.3\n",
      "[20, 60] loss: 0.484\n",
      "[20, 120] loss: 0.492\n",
      "[20, 180] loss: 0.528\n",
      "[20, 240] loss: 0.501\n",
      "[20, 300] loss: 0.514\n",
      "[20, 360] loss: 0.523\n",
      "Epoch: 20 -> Loss: 0.580073475838\n",
      "Epoch: 20 -> Test Accuracy: 78.18\n",
      "[21, 60] loss: 0.474\n",
      "[21, 120] loss: 0.440\n",
      "[21, 180] loss: 0.445\n",
      "[21, 240] loss: 0.458\n",
      "[21, 300] loss: 0.434\n",
      "[21, 360] loss: 0.426\n",
      "Epoch: 21 -> Loss: 0.416142135859\n",
      "Epoch: 21 -> Test Accuracy: 80.07\n",
      "[22, 60] loss: 0.422\n",
      "[22, 120] loss: 0.429\n",
      "[22, 180] loss: 0.408\n",
      "[22, 240] loss: 0.423\n",
      "[22, 300] loss: 0.419\n",
      "[22, 360] loss: 0.412\n",
      "Epoch: 22 -> Loss: 0.576765418053\n",
      "Epoch: 22 -> Test Accuracy: 80.79\n",
      "[23, 60] loss: 0.400\n",
      "[23, 120] loss: 0.388\n",
      "[23, 180] loss: 0.418\n",
      "[23, 240] loss: 0.394\n",
      "[23, 300] loss: 0.404\n",
      "[23, 360] loss: 0.383\n",
      "Epoch: 23 -> Loss: 0.502436280251\n",
      "Epoch: 23 -> Test Accuracy: 80.95\n",
      "[24, 60] loss: 0.395\n",
      "[24, 120] loss: 0.398\n",
      "[24, 180] loss: 0.394\n",
      "[24, 240] loss: 0.391\n",
      "[24, 300] loss: 0.393\n",
      "[24, 360] loss: 0.385\n",
      "Epoch: 24 -> Loss: 0.362904757261\n",
      "Epoch: 24 -> Test Accuracy: 81.2\n",
      "[25, 60] loss: 0.383\n",
      "[25, 120] loss: 0.381\n",
      "[25, 180] loss: 0.382\n",
      "[25, 240] loss: 0.380\n",
      "[25, 300] loss: 0.387\n",
      "[25, 360] loss: 0.394\n",
      "Epoch: 25 -> Loss: 0.409335702658\n",
      "Epoch: 25 -> Test Accuracy: 81.03\n",
      "[26, 60] loss: 0.377\n",
      "[26, 120] loss: 0.380\n",
      "[26, 180] loss: 0.373\n",
      "[26, 240] loss: 0.378\n",
      "[26, 300] loss: 0.372\n",
      "[26, 360] loss: 0.387\n",
      "Epoch: 26 -> Loss: 0.358269631863\n",
      "Epoch: 26 -> Test Accuracy: 81.18\n",
      "[27, 60] loss: 0.368\n",
      "[27, 120] loss: 0.373\n",
      "[27, 180] loss: 0.372\n",
      "[27, 240] loss: 0.371\n",
      "[27, 300] loss: 0.362\n",
      "[27, 360] loss: 0.394\n",
      "Epoch: 27 -> Loss: 0.334960639477\n",
      "Epoch: 27 -> Test Accuracy: 81.27\n",
      "[28, 60] loss: 0.364\n",
      "[28, 120] loss: 0.368\n",
      "[28, 180] loss: 0.368\n",
      "[28, 240] loss: 0.368\n",
      "[28, 300] loss: 0.360\n",
      "[28, 360] loss: 0.371\n",
      "Epoch: 28 -> Loss: 0.417045354843\n",
      "Epoch: 28 -> Test Accuracy: 81.02\n",
      "[29, 60] loss: 0.358\n",
      "[29, 120] loss: 0.375\n",
      "[29, 180] loss: 0.368\n",
      "[29, 240] loss: 0.357\n",
      "[29, 300] loss: 0.374\n",
      "[29, 360] loss: 0.381\n",
      "Epoch: 29 -> Loss: 0.411317199469\n",
      "Epoch: 29 -> Test Accuracy: 80.58\n",
      "[30, 60] loss: 0.365\n",
      "[30, 120] loss: 0.360\n",
      "[30, 180] loss: 0.348\n",
      "[30, 240] loss: 0.379\n",
      "[30, 300] loss: 0.385\n",
      "[30, 360] loss: 0.355\n",
      "Epoch: 30 -> Loss: 0.433897167444\n",
      "Epoch: 30 -> Test Accuracy: 80.94\n",
      "[31, 60] loss: 0.356\n",
      "[31, 120] loss: 0.356\n",
      "[31, 180] loss: 0.373\n",
      "[31, 240] loss: 0.361\n",
      "[31, 300] loss: 0.340\n",
      "[31, 360] loss: 0.373\n",
      "Epoch: 31 -> Loss: 0.35753172636\n",
      "Epoch: 31 -> Test Accuracy: 80.68\n",
      "[32, 60] loss: 0.351\n",
      "[32, 120] loss: 0.353\n",
      "[32, 180] loss: 0.364\n",
      "[32, 240] loss: 0.367\n",
      "[32, 300] loss: 0.356\n",
      "[32, 360] loss: 0.362\n",
      "Epoch: 32 -> Loss: 0.551405131817\n",
      "Epoch: 32 -> Test Accuracy: 80.93\n",
      "[33, 60] loss: 0.362\n",
      "[33, 120] loss: 0.357\n",
      "[33, 180] loss: 0.361\n",
      "[33, 240] loss: 0.362\n",
      "[33, 300] loss: 0.369\n",
      "[33, 360] loss: 0.371\n",
      "Epoch: 33 -> Loss: 0.497011035681\n",
      "Epoch: 33 -> Test Accuracy: 80.91\n",
      "[34, 60] loss: 0.346\n",
      "[34, 120] loss: 0.347\n",
      "[34, 180] loss: 0.345\n",
      "[34, 240] loss: 0.376\n",
      "[34, 300] loss: 0.370\n",
      "[34, 360] loss: 0.351\n",
      "Epoch: 34 -> Loss: 0.390002727509\n",
      "Epoch: 34 -> Test Accuracy: 80.68\n",
      "[35, 60] loss: 0.359\n",
      "[35, 120] loss: 0.350\n",
      "[35, 180] loss: 0.348\n",
      "[35, 240] loss: 0.369\n",
      "[35, 300] loss: 0.366\n",
      "[35, 360] loss: 0.365\n",
      "Epoch: 35 -> Loss: 0.320419311523\n",
      "Epoch: 35 -> Test Accuracy: 80.95\n",
      "[36, 60] loss: 0.346\n",
      "[36, 120] loss: 0.336\n",
      "[36, 180] loss: 0.353\n",
      "[36, 240] loss: 0.342\n",
      "[36, 300] loss: 0.376\n",
      "[36, 360] loss: 0.371\n",
      "Epoch: 36 -> Loss: 0.394420564175\n",
      "Epoch: 36 -> Test Accuracy: 80.92\n",
      "[37, 60] loss: 0.340\n",
      "[37, 120] loss: 0.346\n",
      "[37, 180] loss: 0.363\n",
      "[37, 240] loss: 0.352\n",
      "[37, 300] loss: 0.353\n",
      "[37, 360] loss: 0.370\n",
      "Epoch: 37 -> Loss: 0.313349068165\n",
      "Epoch: 37 -> Test Accuracy: 80.73\n",
      "[38, 60] loss: 0.352\n",
      "[38, 120] loss: 0.345\n",
      "[38, 180] loss: 0.341\n",
      "[38, 240] loss: 0.346\n",
      "[38, 300] loss: 0.365\n",
      "[38, 360] loss: 0.380\n",
      "Epoch: 38 -> Loss: 0.395396202803\n",
      "Epoch: 38 -> Test Accuracy: 80.67\n",
      "[39, 60] loss: 0.357\n",
      "[39, 120] loss: 0.346\n",
      "[39, 180] loss: 0.351\n",
      "[39, 240] loss: 0.357\n",
      "[39, 300] loss: 0.360\n",
      "[39, 360] loss: 0.358\n",
      "Epoch: 39 -> Loss: 0.545034348965\n",
      "Epoch: 39 -> Test Accuracy: 80.68\n",
      "[40, 60] loss: 0.339\n",
      "[40, 120] loss: 0.348\n",
      "[40, 180] loss: 0.350\n",
      "[40, 240] loss: 0.355\n",
      "[40, 300] loss: 0.360\n",
      "[40, 360] loss: 0.366\n",
      "Epoch: 40 -> Loss: 0.313844710588\n",
      "Epoch: 40 -> Test Accuracy: 80.8\n",
      "[41, 60] loss: 0.317\n",
      "[41, 120] loss: 0.309\n",
      "[41, 180] loss: 0.314\n",
      "[41, 240] loss: 0.329\n",
      "[41, 300] loss: 0.309\n",
      "[41, 360] loss: 0.294\n",
      "Epoch: 41 -> Loss: 0.325078189373\n",
      "Epoch: 41 -> Test Accuracy: 81.37\n",
      "[42, 60] loss: 0.309\n",
      "[42, 120] loss: 0.282\n",
      "[42, 180] loss: 0.305\n",
      "[42, 240] loss: 0.303\n",
      "[42, 300] loss: 0.302\n",
      "[42, 360] loss: 0.311\n",
      "Epoch: 42 -> Loss: 0.313443124294\n",
      "Epoch: 42 -> Test Accuracy: 81.86\n",
      "[43, 60] loss: 0.303\n",
      "[43, 120] loss: 0.287\n",
      "[43, 180] loss: 0.288\n",
      "[43, 240] loss: 0.282\n",
      "[43, 300] loss: 0.280\n",
      "[43, 360] loss: 0.292\n",
      "Epoch: 43 -> Loss: 0.311910748482\n",
      "Epoch: 43 -> Test Accuracy: 81.86\n",
      "[44, 60] loss: 0.273\n",
      "[44, 120] loss: 0.283\n",
      "[44, 180] loss: 0.289\n",
      "[44, 240] loss: 0.295\n",
      "[44, 300] loss: 0.281\n",
      "[44, 360] loss: 0.280\n",
      "Epoch: 44 -> Loss: 0.227935150266\n",
      "Epoch: 44 -> Test Accuracy: 81.8\n",
      "[45, 60] loss: 0.282\n",
      "[45, 120] loss: 0.268\n",
      "[45, 180] loss: 0.288\n",
      "[45, 240] loss: 0.269\n",
      "[45, 300] loss: 0.269\n",
      "[45, 360] loss: 0.286\n",
      "Epoch: 45 -> Loss: 0.3576387465\n",
      "Epoch: 45 -> Test Accuracy: 81.84\n",
      "[46, 60] loss: 0.265\n",
      "[46, 120] loss: 0.275\n",
      "[46, 180] loss: 0.277\n",
      "[46, 240] loss: 0.250\n",
      "[46, 300] loss: 0.267\n",
      "[46, 360] loss: 0.265\n",
      "Epoch: 46 -> Loss: 0.232256501913\n",
      "Epoch: 46 -> Test Accuracy: 82.02\n",
      "[47, 60] loss: 0.260\n",
      "[47, 120] loss: 0.266\n",
      "[47, 180] loss: 0.281\n",
      "[47, 240] loss: 0.252\n",
      "[47, 300] loss: 0.271\n",
      "[47, 360] loss: 0.266\n",
      "Epoch: 47 -> Loss: 0.26969397068\n",
      "Epoch: 47 -> Test Accuracy: 81.92\n",
      "[48, 60] loss: 0.277\n",
      "[48, 120] loss: 0.260\n",
      "[48, 180] loss: 0.266\n",
      "[48, 240] loss: 0.264\n",
      "[48, 300] loss: 0.255\n",
      "[48, 360] loss: 0.264\n",
      "Epoch: 48 -> Loss: 0.301000803709\n",
      "Epoch: 48 -> Test Accuracy: 82.02\n",
      "[49, 60] loss: 0.254\n",
      "[49, 120] loss: 0.262\n",
      "[49, 180] loss: 0.255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 240] loss: 0.273\n",
      "[49, 300] loss: 0.257\n",
      "[49, 360] loss: 0.263\n",
      "Epoch: 49 -> Loss: 0.319506466389\n",
      "Epoch: 49 -> Test Accuracy: 81.97\n",
      "[50, 60] loss: 0.259\n",
      "[50, 120] loss: 0.258\n",
      "[50, 180] loss: 0.254\n",
      "[50, 240] loss: 0.268\n",
      "[50, 300] loss: 0.274\n",
      "[50, 360] loss: 0.254\n",
      "Epoch: 50 -> Loss: 0.356002867222\n",
      "Epoch: 50 -> Test Accuracy: 81.97\n",
      "[51, 60] loss: 0.264\n",
      "[51, 120] loss: 0.236\n",
      "[51, 180] loss: 0.258\n",
      "[51, 240] loss: 0.251\n",
      "[51, 300] loss: 0.256\n",
      "[51, 360] loss: 0.266\n",
      "Epoch: 51 -> Loss: 0.309273183346\n",
      "Epoch: 51 -> Test Accuracy: 82.04\n",
      "[52, 60] loss: 0.260\n",
      "[52, 120] loss: 0.252\n",
      "[52, 180] loss: 0.259\n",
      "[52, 240] loss: 0.243\n",
      "[52, 300] loss: 0.254\n",
      "[52, 360] loss: 0.262\n",
      "Epoch: 52 -> Loss: 0.150607138872\n",
      "Epoch: 52 -> Test Accuracy: 82.08\n",
      "[53, 60] loss: 0.250\n",
      "[53, 120] loss: 0.254\n",
      "[53, 180] loss: 0.262\n",
      "[53, 240] loss: 0.274\n",
      "[53, 300] loss: 0.264\n",
      "[53, 360] loss: 0.247\n",
      "Epoch: 53 -> Loss: 0.204975634813\n",
      "Epoch: 53 -> Test Accuracy: 82.05\n",
      "[54, 60] loss: 0.238\n",
      "[54, 120] loss: 0.263\n",
      "[54, 180] loss: 0.247\n",
      "[54, 240] loss: 0.252\n",
      "[54, 300] loss: 0.253\n",
      "[54, 360] loss: 0.265\n",
      "Epoch: 54 -> Loss: 0.280548334122\n",
      "Epoch: 54 -> Test Accuracy: 82.05\n",
      "[55, 60] loss: 0.250\n",
      "[55, 120] loss: 0.245\n",
      "[55, 180] loss: 0.256\n",
      "[55, 240] loss: 0.278\n",
      "[55, 300] loss: 0.244\n",
      "[55, 360] loss: 0.254\n",
      "Epoch: 55 -> Loss: 0.304328233004\n",
      "Epoch: 55 -> Test Accuracy: 81.99\n",
      "[56, 60] loss: 0.253\n",
      "[56, 120] loss: 0.257\n",
      "[56, 180] loss: 0.253\n",
      "[56, 240] loss: 0.258\n",
      "[56, 300] loss: 0.247\n",
      "[56, 360] loss: 0.246\n",
      "Epoch: 56 -> Loss: 0.242158606648\n",
      "Epoch: 56 -> Test Accuracy: 81.96\n",
      "[57, 60] loss: 0.248\n",
      "[57, 120] loss: 0.255\n",
      "[57, 180] loss: 0.255\n",
      "[57, 240] loss: 0.254\n",
      "[57, 300] loss: 0.242\n",
      "[57, 360] loss: 0.261\n",
      "Epoch: 57 -> Loss: 0.278217554092\n",
      "Epoch: 57 -> Test Accuracy: 81.95\n",
      "[58, 60] loss: 0.244\n",
      "[58, 120] loss: 0.241\n",
      "[58, 180] loss: 0.245\n",
      "[58, 240] loss: 0.246\n",
      "[58, 300] loss: 0.256\n",
      "[58, 360] loss: 0.250\n",
      "Epoch: 58 -> Loss: 0.248314574361\n",
      "Epoch: 58 -> Test Accuracy: 82.08\n",
      "[59, 60] loss: 0.249\n",
      "[59, 120] loss: 0.252\n",
      "[59, 180] loss: 0.254\n",
      "[59, 240] loss: 0.238\n",
      "[59, 300] loss: 0.250\n",
      "[59, 360] loss: 0.253\n",
      "Epoch: 59 -> Loss: 0.188179284334\n",
      "Epoch: 59 -> Test Accuracy: 81.96\n",
      "[60, 60] loss: 0.233\n",
      "[60, 120] loss: 0.251\n",
      "[60, 180] loss: 0.237\n",
      "[60, 240] loss: 0.241\n",
      "[60, 300] loss: 0.250\n",
      "[60, 360] loss: 0.246\n",
      "Epoch: 60 -> Loss: 0.199340343475\n",
      "Epoch: 60 -> Test Accuracy: 82.1\n",
      "[61, 60] loss: 0.254\n",
      "[61, 120] loss: 0.237\n",
      "[61, 180] loss: 0.242\n",
      "[61, 240] loss: 0.259\n",
      "[61, 300] loss: 0.242\n",
      "[61, 360] loss: 0.241\n",
      "Epoch: 61 -> Loss: 0.155307322741\n",
      "Epoch: 61 -> Test Accuracy: 81.98\n",
      "[62, 60] loss: 0.237\n",
      "[62, 120] loss: 0.231\n",
      "[62, 180] loss: 0.256\n",
      "[62, 240] loss: 0.250\n",
      "[62, 300] loss: 0.239\n",
      "[62, 360] loss: 0.248\n",
      "Epoch: 62 -> Loss: 0.205468773842\n",
      "Epoch: 62 -> Test Accuracy: 81.96\n",
      "[63, 60] loss: 0.249\n",
      "[63, 120] loss: 0.247\n",
      "[63, 180] loss: 0.241\n",
      "[63, 240] loss: 0.258\n",
      "[63, 300] loss: 0.245\n",
      "[63, 360] loss: 0.247\n",
      "Epoch: 63 -> Loss: 0.28371232748\n",
      "Epoch: 63 -> Test Accuracy: 81.89\n",
      "[64, 60] loss: 0.238\n",
      "[64, 120] loss: 0.233\n",
      "[64, 180] loss: 0.247\n",
      "[64, 240] loss: 0.235\n",
      "[64, 300] loss: 0.238\n",
      "[64, 360] loss: 0.242\n",
      "Epoch: 64 -> Loss: 0.231269881129\n",
      "Epoch: 64 -> Test Accuracy: 81.86\n",
      "[65, 60] loss: 0.249\n",
      "[65, 120] loss: 0.248\n",
      "[65, 180] loss: 0.237\n",
      "[65, 240] loss: 0.238\n",
      "[65, 300] loss: 0.247\n",
      "[65, 360] loss: 0.241\n",
      "Epoch: 65 -> Loss: 0.323963522911\n",
      "Epoch: 65 -> Test Accuracy: 81.81\n",
      "[66, 60] loss: 0.238\n",
      "[66, 120] loss: 0.247\n",
      "[66, 180] loss: 0.250\n",
      "[66, 240] loss: 0.233\n",
      "[66, 300] loss: 0.235\n",
      "[66, 360] loss: 0.255\n",
      "Epoch: 66 -> Loss: 0.208741471171\n",
      "Epoch: 66 -> Test Accuracy: 81.85\n",
      "[67, 60] loss: 0.234\n",
      "[67, 120] loss: 0.247\n",
      "[67, 180] loss: 0.238\n",
      "[67, 240] loss: 0.226\n",
      "[67, 300] loss: 0.259\n",
      "[67, 360] loss: 0.230\n",
      "Epoch: 67 -> Loss: 0.211038544774\n",
      "Epoch: 67 -> Test Accuracy: 81.83\n",
      "[68, 60] loss: 0.237\n",
      "[68, 120] loss: 0.233\n",
      "[68, 180] loss: 0.237\n",
      "[68, 240] loss: 0.229\n",
      "[68, 300] loss: 0.230\n",
      "[68, 360] loss: 0.249\n",
      "Epoch: 68 -> Loss: 0.177535042167\n",
      "Epoch: 68 -> Test Accuracy: 81.93\n",
      "[69, 60] loss: 0.228\n",
      "[69, 120] loss: 0.235\n",
      "[69, 180] loss: 0.233\n",
      "[69, 240] loss: 0.252\n",
      "[69, 300] loss: 0.248\n",
      "[69, 360] loss: 0.235\n",
      "Epoch: 69 -> Loss: 0.278575390577\n",
      "Epoch: 69 -> Test Accuracy: 82.05\n",
      "[70, 60] loss: 0.227\n",
      "[70, 120] loss: 0.239\n",
      "[70, 180] loss: 0.243\n",
      "[70, 240] loss: 0.233\n",
      "[70, 300] loss: 0.241\n",
      "[70, 360] loss: 0.234\n",
      "Epoch: 70 -> Loss: 0.395994246006\n",
      "Epoch: 70 -> Test Accuracy: 82.09\n",
      "[71, 60] loss: 0.233\n",
      "[71, 120] loss: 0.219\n",
      "[71, 180] loss: 0.239\n",
      "[71, 240] loss: 0.227\n",
      "[71, 300] loss: 0.231\n",
      "[71, 360] loss: 0.235\n",
      "Epoch: 71 -> Loss: 0.247227042913\n",
      "Epoch: 71 -> Test Accuracy: 82.02\n",
      "[72, 60] loss: 0.233\n",
      "[72, 120] loss: 0.239\n",
      "[72, 180] loss: 0.243\n",
      "[72, 240] loss: 0.225\n",
      "[72, 300] loss: 0.234\n",
      "[72, 360] loss: 0.238\n",
      "Epoch: 72 -> Loss: 0.312953710556\n",
      "Epoch: 72 -> Test Accuracy: 81.99\n",
      "[73, 60] loss: 0.224\n",
      "[73, 120] loss: 0.214\n",
      "[73, 180] loss: 0.242\n",
      "[73, 240] loss: 0.234\n",
      "[73, 300] loss: 0.238\n",
      "[73, 360] loss: 0.235\n",
      "Epoch: 73 -> Loss: 0.345120817423\n",
      "Epoch: 73 -> Test Accuracy: 82.15\n",
      "[74, 60] loss: 0.222\n",
      "[74, 120] loss: 0.231\n",
      "[74, 180] loss: 0.237\n",
      "[74, 240] loss: 0.236\n",
      "[74, 300] loss: 0.229\n",
      "[74, 360] loss: 0.230\n",
      "Epoch: 74 -> Loss: 0.129827588797\n",
      "Epoch: 74 -> Test Accuracy: 82.12\n",
      "[75, 60] loss: 0.229\n",
      "[75, 120] loss: 0.233\n",
      "[75, 180] loss: 0.235\n",
      "[75, 240] loss: 0.238\n",
      "[75, 300] loss: 0.220\n",
      "[75, 360] loss: 0.233\n",
      "Epoch: 75 -> Loss: 0.179600089788\n",
      "Epoch: 75 -> Test Accuracy: 81.83\n",
      "[76, 60] loss: 0.229\n",
      "[76, 120] loss: 0.244\n",
      "[76, 180] loss: 0.227\n",
      "[76, 240] loss: 0.220\n",
      "[76, 300] loss: 0.232\n",
      "[76, 360] loss: 0.225\n",
      "Epoch: 76 -> Loss: 0.176581218839\n",
      "Epoch: 76 -> Test Accuracy: 81.9\n",
      "[77, 60] loss: 0.234\n",
      "[77, 120] loss: 0.229\n",
      "[77, 180] loss: 0.228\n",
      "[77, 240] loss: 0.240\n",
      "[77, 300] loss: 0.227\n",
      "[77, 360] loss: 0.236\n",
      "Epoch: 77 -> Loss: 0.238515287638\n",
      "Epoch: 77 -> Test Accuracy: 81.89\n",
      "[78, 60] loss: 0.237\n",
      "[78, 120] loss: 0.228\n",
      "[78, 180] loss: 0.216\n",
      "[78, 240] loss: 0.230\n",
      "[78, 300] loss: 0.235\n",
      "[78, 360] loss: 0.235\n",
      "Epoch: 78 -> Loss: 0.223357960582\n",
      "Epoch: 78 -> Test Accuracy: 81.88\n",
      "[79, 60] loss: 0.233\n",
      "[79, 120] loss: 0.230\n",
      "[79, 180] loss: 0.219\n",
      "[79, 240] loss: 0.221\n",
      "[79, 300] loss: 0.234\n",
      "[79, 360] loss: 0.221\n",
      "Epoch: 79 -> Loss: 0.313910156488\n",
      "Epoch: 79 -> Test Accuracy: 81.93\n",
      "[80, 60] loss: 0.235\n",
      "[80, 120] loss: 0.227\n",
      "[80, 180] loss: 0.231\n",
      "[80, 240] loss: 0.239\n",
      "[80, 300] loss: 0.220\n",
      "[80, 360] loss: 0.233\n",
      "Epoch: 80 -> Loss: 0.318058788776\n",
      "Epoch: 80 -> Test Accuracy: 81.91\n",
      "[81, 60] loss: 0.225\n",
      "[81, 120] loss: 0.221\n",
      "[81, 180] loss: 0.208\n",
      "[81, 240] loss: 0.227\n",
      "[81, 300] loss: 0.234\n",
      "[81, 360] loss: 0.216\n",
      "Epoch: 81 -> Loss: 0.183961391449\n",
      "Epoch: 81 -> Test Accuracy: 82.05\n",
      "[82, 60] loss: 0.238\n",
      "[82, 120] loss: 0.221\n",
      "[82, 180] loss: 0.228\n",
      "[82, 240] loss: 0.225\n",
      "[82, 300] loss: 0.224\n",
      "[82, 360] loss: 0.219\n",
      "Epoch: 82 -> Loss: 0.233062431216\n",
      "Epoch: 82 -> Test Accuracy: 81.8\n",
      "[83, 60] loss: 0.223\n",
      "[83, 120] loss: 0.222\n",
      "[83, 180] loss: 0.226\n",
      "[83, 240] loss: 0.228\n",
      "[83, 300] loss: 0.221\n",
      "[83, 360] loss: 0.232\n",
      "Epoch: 83 -> Loss: 0.140518277884\n",
      "Epoch: 83 -> Test Accuracy: 81.85\n",
      "[84, 60] loss: 0.216\n",
      "[84, 120] loss: 0.227\n",
      "[84, 180] loss: 0.224\n",
      "[84, 240] loss: 0.229\n",
      "[84, 300] loss: 0.216\n",
      "[84, 360] loss: 0.225\n",
      "Epoch: 84 -> Loss: 0.249069780111\n",
      "Epoch: 84 -> Test Accuracy: 81.87\n",
      "[85, 60] loss: 0.222\n",
      "[85, 120] loss: 0.234\n",
      "[85, 180] loss: 0.208\n",
      "[85, 240] loss: 0.224\n",
      "[85, 300] loss: 0.220\n",
      "[85, 360] loss: 0.220\n",
      "Epoch: 85 -> Loss: 0.250971436501\n",
      "Epoch: 85 -> Test Accuracy: 82.14\n",
      "[86, 60] loss: 0.224\n",
      "[86, 120] loss: 0.224\n",
      "[86, 180] loss: 0.227\n",
      "[86, 240] loss: 0.225\n",
      "[86, 300] loss: 0.217\n",
      "[86, 360] loss: 0.232\n",
      "Epoch: 86 -> Loss: 0.217952340841\n",
      "Epoch: 86 -> Test Accuracy: 81.99\n",
      "[87, 60] loss: 0.221\n",
      "[87, 120] loss: 0.220\n",
      "[87, 180] loss: 0.201\n",
      "[87, 240] loss: 0.216\n",
      "[87, 300] loss: 0.217\n",
      "[87, 360] loss: 0.223\n",
      "Epoch: 87 -> Loss: 0.267155408859\n",
      "Epoch: 87 -> Test Accuracy: 81.99\n",
      "[88, 60] loss: 0.225\n",
      "[88, 120] loss: 0.211\n",
      "[88, 180] loss: 0.211\n",
      "[88, 240] loss: 0.230\n",
      "[88, 300] loss: 0.223\n",
      "[88, 360] loss: 0.221\n",
      "Epoch: 88 -> Loss: 0.228883072734\n",
      "Epoch: 88 -> Test Accuracy: 82.06\n",
      "[89, 60] loss: 0.213\n",
      "[89, 120] loss: 0.198\n",
      "[89, 180] loss: 0.213\n",
      "[89, 240] loss: 0.230\n",
      "[89, 300] loss: 0.219\n",
      "[89, 360] loss: 0.223\n",
      "Epoch: 89 -> Loss: 0.339834690094\n",
      "Epoch: 89 -> Test Accuracy: 82.17\n",
      "[90, 60] loss: 0.224\n",
      "[90, 120] loss: 0.217\n",
      "[90, 180] loss: 0.211\n",
      "[90, 240] loss: 0.226\n",
      "[90, 300] loss: 0.211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90, 360] loss: 0.220\n",
      "Epoch: 90 -> Loss: 0.193515747786\n",
      "Epoch: 90 -> Test Accuracy: 81.99\n",
      "[91, 60] loss: 0.207\n",
      "[91, 120] loss: 0.212\n",
      "[91, 180] loss: 0.213\n",
      "[91, 240] loss: 0.224\n",
      "[91, 300] loss: 0.233\n",
      "[91, 360] loss: 0.229\n",
      "Epoch: 91 -> Loss: 0.282065957785\n",
      "Epoch: 91 -> Test Accuracy: 82.11\n",
      "[92, 60] loss: 0.223\n",
      "[92, 120] loss: 0.215\n",
      "[92, 180] loss: 0.222\n",
      "[92, 240] loss: 0.214\n",
      "[92, 300] loss: 0.210\n",
      "[92, 360] loss: 0.217\n",
      "Epoch: 92 -> Loss: 0.266321986914\n",
      "Epoch: 92 -> Test Accuracy: 82.19\n",
      "[93, 60] loss: 0.217\n",
      "[93, 120] loss: 0.208\n",
      "[93, 180] loss: 0.208\n",
      "[93, 240] loss: 0.221\n",
      "[93, 300] loss: 0.217\n",
      "[93, 360] loss: 0.222\n",
      "Epoch: 93 -> Loss: 0.40541562438\n",
      "Epoch: 93 -> Test Accuracy: 82.02\n",
      "[94, 60] loss: 0.214\n",
      "[94, 120] loss: 0.214\n",
      "[94, 180] loss: 0.210\n",
      "[94, 240] loss: 0.217\n",
      "[94, 300] loss: 0.207\n",
      "[94, 360] loss: 0.210\n",
      "Epoch: 94 -> Loss: 0.148151814938\n",
      "Epoch: 94 -> Test Accuracy: 81.91\n",
      "[95, 60] loss: 0.207\n",
      "[95, 120] loss: 0.211\n",
      "[95, 180] loss: 0.223\n",
      "[95, 240] loss: 0.216\n",
      "[95, 300] loss: 0.214\n",
      "[95, 360] loss: 0.217\n",
      "Epoch: 95 -> Loss: 0.228896856308\n",
      "Epoch: 95 -> Test Accuracy: 81.91\n",
      "[96, 60] loss: 0.220\n",
      "[96, 120] loss: 0.213\n",
      "[96, 180] loss: 0.214\n",
      "[96, 240] loss: 0.209\n",
      "[96, 300] loss: 0.205\n",
      "[96, 360] loss: 0.218\n",
      "Epoch: 96 -> Loss: 0.189814150333\n",
      "Epoch: 96 -> Test Accuracy: 82.08\n",
      "[97, 60] loss: 0.204\n",
      "[97, 120] loss: 0.210\n",
      "[97, 180] loss: 0.207\n",
      "[97, 240] loss: 0.215\n",
      "[97, 300] loss: 0.211\n",
      "[97, 360] loss: 0.210\n",
      "Epoch: 97 -> Loss: 0.205362319946\n",
      "Epoch: 97 -> Test Accuracy: 82.15\n",
      "[98, 60] loss: 0.207\n",
      "[98, 120] loss: 0.212\n",
      "[98, 180] loss: 0.212\n",
      "[98, 240] loss: 0.214\n",
      "[98, 300] loss: 0.205\n",
      "[98, 360] loss: 0.220\n",
      "Epoch: 98 -> Loss: 0.241427570581\n",
      "Epoch: 98 -> Test Accuracy: 82.12\n",
      "[99, 60] loss: 0.205\n",
      "[99, 120] loss: 0.215\n",
      "[99, 180] loss: 0.214\n",
      "[99, 240] loss: 0.208\n",
      "[99, 300] loss: 0.220\n",
      "[99, 360] loss: 0.209\n",
      "Epoch: 99 -> Loss: 0.207441568375\n",
      "Epoch: 99 -> Test Accuracy: 82.21\n",
      "[100, 60] loss: 0.207\n",
      "[100, 120] loss: 0.210\n",
      "[100, 180] loss: 0.205\n",
      "[100, 240] loss: 0.207\n",
      "[100, 300] loss: 0.211\n",
      "[100, 360] loss: 0.201\n",
      "Epoch: 100 -> Loss: 0.269614607096\n",
      "Epoch: 100 -> Test Accuracy: 82.03\n",
      "Finished Training\n",
      "[1, 60] loss: 2.780\n",
      "[1, 120] loss: 2.017\n",
      "[1, 180] loss: 1.943\n",
      "[1, 240] loss: 1.910\n",
      "[1, 300] loss: 1.888\n",
      "[1, 360] loss: 1.849\n",
      "Epoch: 1 -> Loss: 2.11684608459\n",
      "Epoch: 1 -> Test Accuracy: 32.05\n",
      "[2, 60] loss: 1.828\n",
      "[2, 120] loss: 1.795\n",
      "[2, 180] loss: 1.813\n",
      "[2, 240] loss: 1.802\n",
      "[2, 300] loss: 1.775\n",
      "[2, 360] loss: 1.770\n",
      "Epoch: 2 -> Loss: 1.6235730648\n",
      "Epoch: 2 -> Test Accuracy: 32.99\n",
      "[3, 60] loss: 1.757\n",
      "[3, 120] loss: 1.767\n",
      "[3, 180] loss: 1.746\n",
      "[3, 240] loss: 1.731\n",
      "[3, 300] loss: 1.736\n",
      "[3, 360] loss: 1.723\n",
      "Epoch: 3 -> Loss: 1.79555296898\n",
      "Epoch: 3 -> Test Accuracy: 35.47\n",
      "[4, 60] loss: 1.734\n",
      "[4, 120] loss: 1.728\n",
      "[4, 180] loss: 1.722\n",
      "[4, 240] loss: 1.702\n",
      "[4, 300] loss: 1.729\n",
      "[4, 360] loss: 1.698\n",
      "Epoch: 4 -> Loss: 1.67304289341\n",
      "Epoch: 4 -> Test Accuracy: 36.2\n",
      "[5, 60] loss: 1.710\n",
      "[5, 120] loss: 1.699\n",
      "[5, 180] loss: 1.716\n",
      "[5, 240] loss: 1.706\n",
      "[5, 300] loss: 1.671\n",
      "[5, 360] loss: 1.701\n",
      "Epoch: 5 -> Loss: 1.7464120388\n",
      "Epoch: 5 -> Test Accuracy: 35.84\n",
      "[6, 60] loss: 1.686\n",
      "[6, 120] loss: 1.703\n",
      "[6, 180] loss: 1.690\n",
      "[6, 240] loss: 1.694\n",
      "[6, 300] loss: 1.686\n",
      "[6, 360] loss: 1.693\n",
      "Epoch: 6 -> Loss: 1.80697655678\n",
      "Epoch: 6 -> Test Accuracy: 36.18\n",
      "[7, 60] loss: 1.669\n",
      "[7, 120] loss: 1.684\n",
      "[7, 180] loss: 1.673\n",
      "[7, 240] loss: 1.686\n",
      "[7, 300] loss: 1.689\n",
      "[7, 360] loss: 1.671\n",
      "Epoch: 7 -> Loss: 1.85465013981\n",
      "Epoch: 7 -> Test Accuracy: 36.74\n",
      "[8, 60] loss: 1.673\n",
      "[8, 120] loss: 1.668\n",
      "[8, 180] loss: 1.657\n",
      "[8, 240] loss: 1.670\n",
      "[8, 300] loss: 1.694\n",
      "[8, 360] loss: 1.663\n",
      "Epoch: 8 -> Loss: 1.73600804806\n",
      "Epoch: 8 -> Test Accuracy: 35.74\n",
      "[9, 60] loss: 1.655\n",
      "[9, 120] loss: 1.682\n",
      "[9, 180] loss: 1.654\n",
      "[9, 240] loss: 1.670\n",
      "[9, 300] loss: 1.670\n",
      "[9, 360] loss: 1.663\n",
      "Epoch: 9 -> Loss: 1.78963947296\n",
      "Epoch: 9 -> Test Accuracy: 37.83\n",
      "[10, 60] loss: 1.648\n",
      "[10, 120] loss: 1.662\n",
      "[10, 180] loss: 1.678\n",
      "[10, 240] loss: 1.663\n",
      "[10, 300] loss: 1.669\n",
      "[10, 360] loss: 1.677\n",
      "Epoch: 10 -> Loss: 1.74258291721\n",
      "Epoch: 10 -> Test Accuracy: 37.38\n",
      "[11, 60] loss: 1.670\n",
      "[11, 120] loss: 1.647\n",
      "[11, 180] loss: 1.649\n",
      "[11, 240] loss: 1.649\n",
      "[11, 300] loss: 1.657\n",
      "[11, 360] loss: 1.656\n",
      "Epoch: 11 -> Loss: 1.64230382442\n",
      "Epoch: 11 -> Test Accuracy: 36.95\n",
      "[12, 60] loss: 1.644\n",
      "[12, 120] loss: 1.659\n",
      "[12, 180] loss: 1.637\n",
      "[12, 240] loss: 1.654\n",
      "[12, 300] loss: 1.649\n",
      "[12, 360] loss: 1.659\n",
      "Epoch: 12 -> Loss: 1.66603112221\n",
      "Epoch: 12 -> Test Accuracy: 37.38\n",
      "[13, 60] loss: 1.656\n",
      "[13, 120] loss: 1.652\n",
      "[13, 180] loss: 1.677\n",
      "[13, 240] loss: 1.652\n",
      "[13, 300] loss: 1.647\n",
      "[13, 360] loss: 1.646\n",
      "Epoch: 13 -> Loss: 1.55933761597\n",
      "Epoch: 13 -> Test Accuracy: 37.29\n",
      "[14, 60] loss: 1.644\n",
      "[14, 120] loss: 1.657\n",
      "[14, 180] loss: 1.649\n",
      "[14, 240] loss: 1.648\n",
      "[14, 300] loss: 1.641\n",
      "[14, 360] loss: 1.665\n",
      "Epoch: 14 -> Loss: 1.6488969326\n",
      "Epoch: 14 -> Test Accuracy: 37.91\n",
      "[15, 60] loss: 1.655\n",
      "[15, 120] loss: 1.652\n",
      "[15, 180] loss: 1.663\n",
      "[15, 240] loss: 1.643\n",
      "[15, 300] loss: 1.633\n",
      "[15, 360] loss: 1.671\n",
      "Epoch: 15 -> Loss: 1.63132476807\n",
      "Epoch: 15 -> Test Accuracy: 37.94\n",
      "[16, 60] loss: 1.628\n",
      "[16, 120] loss: 1.650\n",
      "[16, 180] loss: 1.643\n",
      "[16, 240] loss: 1.667\n",
      "[16, 300] loss: 1.639\n",
      "[16, 360] loss: 1.634\n",
      "Epoch: 16 -> Loss: 1.6113216877\n",
      "Epoch: 16 -> Test Accuracy: 38.15\n",
      "[17, 60] loss: 1.646\n",
      "[17, 120] loss: 1.636\n",
      "[17, 180] loss: 1.644\n",
      "[17, 240] loss: 1.646\n",
      "[17, 300] loss: 1.653\n",
      "[17, 360] loss: 1.654\n",
      "Epoch: 17 -> Loss: 1.47934603691\n",
      "Epoch: 17 -> Test Accuracy: 38.26\n",
      "[18, 60] loss: 1.631\n",
      "[18, 120] loss: 1.650\n",
      "[18, 180] loss: 1.640\n",
      "[18, 240] loss: 1.645\n",
      "[18, 300] loss: 1.664\n",
      "[18, 360] loss: 1.639\n",
      "Epoch: 18 -> Loss: 1.67550218105\n",
      "Epoch: 18 -> Test Accuracy: 37.86\n",
      "[19, 60] loss: 1.618\n",
      "[19, 120] loss: 1.655\n",
      "[19, 180] loss: 1.659\n",
      "[19, 240] loss: 1.655\n",
      "[19, 300] loss: 1.661\n",
      "[19, 360] loss: 1.645\n",
      "Epoch: 19 -> Loss: 1.70519220829\n",
      "Epoch: 19 -> Test Accuracy: 36.88\n",
      "[20, 60] loss: 1.652\n",
      "[20, 120] loss: 1.642\n",
      "[20, 180] loss: 1.639\n",
      "[20, 240] loss: 1.637\n",
      "[20, 300] loss: 1.643\n",
      "[20, 360] loss: 1.652\n",
      "Epoch: 20 -> Loss: 1.55524027348\n",
      "Epoch: 20 -> Test Accuracy: 37.68\n",
      "[21, 60] loss: 1.607\n",
      "[21, 120] loss: 1.566\n",
      "[21, 180] loss: 1.558\n",
      "[21, 240] loss: 1.571\n",
      "[21, 300] loss: 1.550\n",
      "[21, 360] loss: 1.551\n",
      "Epoch: 21 -> Loss: 1.29302537441\n",
      "Epoch: 21 -> Test Accuracy: 39.98\n",
      "[22, 60] loss: 1.547\n",
      "[22, 120] loss: 1.537\n",
      "[22, 180] loss: 1.550\n",
      "[22, 240] loss: 1.551\n",
      "[22, 300] loss: 1.540\n",
      "[22, 360] loss: 1.532\n",
      "Epoch: 22 -> Loss: 1.61157298088\n",
      "Epoch: 22 -> Test Accuracy: 40.53\n",
      "[23, 60] loss: 1.508\n",
      "[23, 120] loss: 1.552\n",
      "[23, 180] loss: 1.544\n",
      "[23, 240] loss: 1.531\n",
      "[23, 300] loss: 1.508\n",
      "[23, 360] loss: 1.532\n",
      "Epoch: 23 -> Loss: 1.58555221558\n",
      "Epoch: 23 -> Test Accuracy: 41.26\n",
      "[24, 60] loss: 1.521\n",
      "[24, 120] loss: 1.530\n",
      "[24, 180] loss: 1.524\n",
      "[24, 240] loss: 1.527\n",
      "[24, 300] loss: 1.512\n",
      "[24, 360] loss: 1.504\n",
      "Epoch: 24 -> Loss: 1.71196591854\n",
      "Epoch: 24 -> Test Accuracy: 41.01\n",
      "[25, 60] loss: 1.518\n",
      "[25, 120] loss: 1.534\n",
      "[25, 180] loss: 1.524\n",
      "[25, 240] loss: 1.504\n",
      "[25, 300] loss: 1.517\n",
      "[25, 360] loss: 1.521\n",
      "Epoch: 25 -> Loss: 1.42711901665\n",
      "Epoch: 25 -> Test Accuracy: 41.09\n",
      "[26, 60] loss: 1.516\n",
      "[26, 120] loss: 1.504\n",
      "[26, 180] loss: 1.508\n",
      "[26, 240] loss: 1.515\n",
      "[26, 300] loss: 1.522\n",
      "[26, 360] loss: 1.525\n",
      "Epoch: 26 -> Loss: 1.23364794254\n",
      "Epoch: 26 -> Test Accuracy: 41.36\n",
      "[27, 60] loss: 1.521\n",
      "[27, 120] loss: 1.510\n",
      "[27, 180] loss: 1.494\n",
      "[27, 240] loss: 1.520\n",
      "[27, 300] loss: 1.512\n",
      "[27, 360] loss: 1.507\n",
      "Epoch: 27 -> Loss: 1.59367334843\n",
      "Epoch: 27 -> Test Accuracy: 41.08\n",
      "[28, 60] loss: 1.523\n",
      "[28, 120] loss: 1.500\n",
      "[28, 180] loss: 1.525\n",
      "[28, 240] loss: 1.509\n",
      "[28, 300] loss: 1.513\n",
      "[28, 360] loss: 1.505\n",
      "Epoch: 28 -> Loss: 1.61126577854\n",
      "Epoch: 28 -> Test Accuracy: 41.07\n",
      "[29, 60] loss: 1.509\n",
      "[29, 120] loss: 1.510\n",
      "[29, 180] loss: 1.492\n",
      "[29, 240] loss: 1.521\n",
      "[29, 300] loss: 1.521\n",
      "[29, 360] loss: 1.503\n",
      "Epoch: 29 -> Loss: 1.6448122263\n",
      "Epoch: 29 -> Test Accuracy: 40.65\n",
      "[30, 60] loss: 1.503\n",
      "[30, 120] loss: 1.512\n",
      "[30, 180] loss: 1.530\n",
      "[30, 240] loss: 1.510\n",
      "[30, 300] loss: 1.494\n",
      "[30, 360] loss: 1.515\n",
      "Epoch: 30 -> Loss: 1.47925448418\n",
      "Epoch: 30 -> Test Accuracy: 41.19\n",
      "[31, 60] loss: 1.496\n",
      "[31, 120] loss: 1.531\n",
      "[31, 180] loss: 1.522\n",
      "[31, 240] loss: 1.522\n",
      "[31, 300] loss: 1.487\n",
      "[31, 360] loss: 1.510\n",
      "Epoch: 31 -> Loss: 1.53049015999\n",
      "Epoch: 31 -> Test Accuracy: 41.13\n",
      "[32, 60] loss: 1.497\n",
      "[32, 120] loss: 1.495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 180] loss: 1.507\n",
      "[32, 240] loss: 1.505\n",
      "[32, 300] loss: 1.521\n",
      "[32, 360] loss: 1.517\n",
      "Epoch: 32 -> Loss: 1.58523619175\n",
      "Epoch: 32 -> Test Accuracy: 41.71\n",
      "[33, 60] loss: 1.498\n",
      "[33, 120] loss: 1.502\n",
      "[33, 180] loss: 1.496\n",
      "[33, 240] loss: 1.497\n",
      "[33, 300] loss: 1.506\n",
      "[33, 360] loss: 1.521\n",
      "Epoch: 33 -> Loss: 1.49433004856\n",
      "Epoch: 33 -> Test Accuracy: 41.7\n",
      "[34, 60] loss: 1.485\n",
      "[34, 120] loss: 1.509\n",
      "[34, 180] loss: 1.498\n",
      "[34, 240] loss: 1.513\n",
      "[34, 300] loss: 1.506\n",
      "[34, 360] loss: 1.512\n",
      "Epoch: 34 -> Loss: 1.43205678463\n",
      "Epoch: 34 -> Test Accuracy: 41.61\n",
      "[35, 60] loss: 1.493\n",
      "[35, 120] loss: 1.503\n",
      "[35, 180] loss: 1.501\n",
      "[35, 240] loss: 1.490\n",
      "[35, 300] loss: 1.520\n",
      "[35, 360] loss: 1.512\n",
      "Epoch: 35 -> Loss: 1.56469476223\n",
      "Epoch: 35 -> Test Accuracy: 41.38\n",
      "[36, 60] loss: 1.488\n",
      "[36, 120] loss: 1.485\n",
      "[36, 180] loss: 1.497\n",
      "[36, 240] loss: 1.526\n",
      "[36, 300] loss: 1.491\n",
      "[36, 360] loss: 1.520\n",
      "Epoch: 36 -> Loss: 1.60781121254\n",
      "Epoch: 36 -> Test Accuracy: 41.74\n",
      "[37, 60] loss: 1.494\n",
      "[37, 120] loss: 1.505\n",
      "[37, 180] loss: 1.511\n",
      "[37, 240] loss: 1.502\n",
      "[37, 300] loss: 1.509\n",
      "[37, 360] loss: 1.488\n",
      "Epoch: 37 -> Loss: 1.58845388889\n",
      "Epoch: 37 -> Test Accuracy: 41.61\n",
      "[38, 60] loss: 1.492\n",
      "[38, 120] loss: 1.496\n",
      "[38, 180] loss: 1.502\n",
      "[38, 240] loss: 1.493\n",
      "[38, 300] loss: 1.499\n",
      "[38, 360] loss: 1.507\n",
      "Epoch: 38 -> Loss: 1.47859203815\n",
      "Epoch: 38 -> Test Accuracy: 41.4\n",
      "[39, 60] loss: 1.506\n",
      "[39, 120] loss: 1.499\n",
      "[39, 180] loss: 1.496\n",
      "[39, 240] loss: 1.483\n",
      "[39, 300] loss: 1.514\n",
      "[39, 360] loss: 1.487\n",
      "Epoch: 39 -> Loss: 1.48128807545\n",
      "Epoch: 39 -> Test Accuracy: 41.16\n",
      "[40, 60] loss: 1.469\n",
      "[40, 120] loss: 1.519\n",
      "[40, 180] loss: 1.507\n",
      "[40, 240] loss: 1.510\n",
      "[40, 300] loss: 1.505\n",
      "[40, 360] loss: 1.527\n",
      "Epoch: 40 -> Loss: 1.47732055187\n",
      "Epoch: 40 -> Test Accuracy: 42.58\n",
      "[41, 60] loss: 1.471\n",
      "[41, 120] loss: 1.465\n",
      "[41, 180] loss: 1.448\n",
      "[41, 240] loss: 1.451\n",
      "[41, 300] loss: 1.458\n",
      "[41, 360] loss: 1.453\n",
      "Epoch: 41 -> Loss: 1.42059910297\n",
      "Epoch: 41 -> Test Accuracy: 42.99\n",
      "[42, 60] loss: 1.450\n",
      "[42, 120] loss: 1.434\n",
      "[42, 180] loss: 1.442\n",
      "[42, 240] loss: 1.444\n",
      "[42, 300] loss: 1.432\n",
      "[42, 360] loss: 1.436\n",
      "Epoch: 42 -> Loss: 1.51954257488\n",
      "Epoch: 42 -> Test Accuracy: 43.92\n",
      "[43, 60] loss: 1.427\n",
      "[43, 120] loss: 1.437\n",
      "[43, 180] loss: 1.424\n",
      "[43, 240] loss: 1.439\n",
      "[43, 300] loss: 1.439\n",
      "[43, 360] loss: 1.430\n",
      "Epoch: 43 -> Loss: 1.49740242958\n",
      "Epoch: 43 -> Test Accuracy: 43.83\n",
      "[44, 60] loss: 1.433\n",
      "[44, 120] loss: 1.416\n",
      "[44, 180] loss: 1.417\n",
      "[44, 240] loss: 1.412\n",
      "[44, 300] loss: 1.429\n",
      "[44, 360] loss: 1.447\n",
      "Epoch: 44 -> Loss: 1.56885778904\n",
      "Epoch: 44 -> Test Accuracy: 43.52\n",
      "[45, 60] loss: 1.425\n",
      "[45, 120] loss: 1.418\n",
      "[45, 180] loss: 1.416\n",
      "[45, 240] loss: 1.402\n",
      "[45, 300] loss: 1.420\n",
      "[45, 360] loss: 1.402\n",
      "Epoch: 45 -> Loss: 1.41420197487\n",
      "Epoch: 45 -> Test Accuracy: 43.7\n",
      "[46, 60] loss: 1.420\n",
      "[46, 120] loss: 1.411\n",
      "[46, 180] loss: 1.399\n",
      "[46, 240] loss: 1.401\n",
      "[46, 300] loss: 1.408\n",
      "[46, 360] loss: 1.397\n",
      "Epoch: 46 -> Loss: 1.64426076412\n",
      "Epoch: 46 -> Test Accuracy: 43.94\n",
      "[47, 60] loss: 1.427\n",
      "[47, 120] loss: 1.406\n",
      "[47, 180] loss: 1.396\n",
      "[47, 240] loss: 1.402\n",
      "[47, 300] loss: 1.398\n",
      "[47, 360] loss: 1.402\n",
      "Epoch: 47 -> Loss: 1.3566095829\n",
      "Epoch: 47 -> Test Accuracy: 44.22\n",
      "[48, 60] loss: 1.405\n",
      "[48, 120] loss: 1.406\n",
      "[48, 180] loss: 1.403\n",
      "[48, 240] loss: 1.407\n",
      "[48, 300] loss: 1.392\n",
      "[48, 360] loss: 1.405\n",
      "Epoch: 48 -> Loss: 1.4302418232\n",
      "Epoch: 48 -> Test Accuracy: 44.54\n",
      "[49, 60] loss: 1.404\n",
      "[49, 120] loss: 1.402\n",
      "[49, 180] loss: 1.389\n",
      "[49, 240] loss: 1.414\n",
      "[49, 300] loss: 1.385\n",
      "[49, 360] loss: 1.419\n",
      "Epoch: 49 -> Loss: 1.12989675999\n",
      "Epoch: 49 -> Test Accuracy: 44.17\n",
      "[50, 60] loss: 1.379\n",
      "[50, 120] loss: 1.405\n",
      "[50, 180] loss: 1.389\n",
      "[50, 240] loss: 1.400\n",
      "[50, 300] loss: 1.402\n",
      "[50, 360] loss: 1.406\n",
      "Epoch: 50 -> Loss: 1.38941919804\n",
      "Epoch: 50 -> Test Accuracy: 44.17\n",
      "[51, 60] loss: 1.408\n",
      "[51, 120] loss: 1.407\n",
      "[51, 180] loss: 1.389\n",
      "[51, 240] loss: 1.402\n",
      "[51, 300] loss: 1.389\n",
      "[51, 360] loss: 1.406\n",
      "Epoch: 51 -> Loss: 1.56563162804\n",
      "Epoch: 51 -> Test Accuracy: 44.35\n",
      "[52, 60] loss: 1.396\n",
      "[52, 120] loss: 1.391\n",
      "[52, 180] loss: 1.408\n",
      "[52, 240] loss: 1.405\n",
      "[52, 300] loss: 1.403\n",
      "[52, 360] loss: 1.402\n",
      "Epoch: 52 -> Loss: 1.4044907093\n",
      "Epoch: 52 -> Test Accuracy: 44.39\n",
      "[53, 60] loss: 1.393\n",
      "[53, 120] loss: 1.388\n",
      "[53, 180] loss: 1.412\n",
      "[53, 240] loss: 1.381\n",
      "[53, 300] loss: 1.376\n",
      "[53, 360] loss: 1.407\n",
      "Epoch: 53 -> Loss: 1.2614787817\n",
      "Epoch: 53 -> Test Accuracy: 44.55\n",
      "[54, 60] loss: 1.385\n",
      "[54, 120] loss: 1.397\n",
      "[54, 180] loss: 1.398\n",
      "[54, 240] loss: 1.399\n",
      "[54, 300] loss: 1.415\n",
      "[54, 360] loss: 1.406\n",
      "Epoch: 54 -> Loss: 1.50402617455\n",
      "Epoch: 54 -> Test Accuracy: 44.6\n",
      "[55, 60] loss: 1.411\n",
      "[55, 120] loss: 1.417\n",
      "[55, 180] loss: 1.386\n",
      "[55, 240] loss: 1.385\n",
      "[55, 300] loss: 1.380\n",
      "[55, 360] loss: 1.385\n",
      "Epoch: 55 -> Loss: 1.53083872795\n",
      "Epoch: 55 -> Test Accuracy: 44.48\n",
      "[56, 60] loss: 1.393\n",
      "[56, 120] loss: 1.400\n",
      "[56, 180] loss: 1.392\n",
      "[56, 240] loss: 1.378\n",
      "[56, 300] loss: 1.382\n",
      "[56, 360] loss: 1.390\n",
      "Epoch: 56 -> Loss: 1.34660482407\n",
      "Epoch: 56 -> Test Accuracy: 44.72\n",
      "[57, 60] loss: 1.400\n",
      "[57, 120] loss: 1.399\n",
      "[57, 180] loss: 1.396\n",
      "[57, 240] loss: 1.386\n",
      "[57, 300] loss: 1.391\n",
      "[57, 360] loss: 1.378\n",
      "Epoch: 57 -> Loss: 1.53670024872\n",
      "Epoch: 57 -> Test Accuracy: 44.75\n",
      "[58, 60] loss: 1.390\n",
      "[58, 120] loss: 1.395\n",
      "[58, 180] loss: 1.384\n",
      "[58, 240] loss: 1.396\n",
      "[58, 300] loss: 1.394\n",
      "[58, 360] loss: 1.380\n",
      "Epoch: 58 -> Loss: 1.3768055439\n",
      "Epoch: 58 -> Test Accuracy: 44.58\n",
      "[59, 60] loss: 1.381\n",
      "[59, 120] loss: 1.375\n",
      "[59, 180] loss: 1.382\n",
      "[59, 240] loss: 1.410\n",
      "[59, 300] loss: 1.399\n",
      "[59, 360] loss: 1.389\n",
      "Epoch: 59 -> Loss: 1.45823872089\n",
      "Epoch: 59 -> Test Accuracy: 44.71\n",
      "[60, 60] loss: 1.410\n",
      "[60, 120] loss: 1.392\n",
      "[60, 180] loss: 1.393\n",
      "[60, 240] loss: 1.386\n",
      "[60, 300] loss: 1.386\n",
      "[60, 360] loss: 1.392\n",
      "Epoch: 60 -> Loss: 1.58472537994\n",
      "Epoch: 60 -> Test Accuracy: 44.92\n",
      "[61, 60] loss: 1.375\n",
      "[61, 120] loss: 1.385\n",
      "[61, 180] loss: 1.384\n",
      "[61, 240] loss: 1.386\n",
      "[61, 300] loss: 1.385\n",
      "[61, 360] loss: 1.398\n",
      "Epoch: 61 -> Loss: 1.17956495285\n",
      "Epoch: 61 -> Test Accuracy: 44.91\n",
      "[62, 60] loss: 1.392\n",
      "[62, 120] loss: 1.386\n",
      "[62, 180] loss: 1.372\n",
      "[62, 240] loss: 1.379\n",
      "[62, 300] loss: 1.377\n",
      "[62, 360] loss: 1.393\n",
      "Epoch: 62 -> Loss: 1.49319601059\n",
      "Epoch: 62 -> Test Accuracy: 44.88\n",
      "[63, 60] loss: 1.377\n",
      "[63, 120] loss: 1.379\n",
      "[63, 180] loss: 1.408\n",
      "[63, 240] loss: 1.386\n",
      "[63, 300] loss: 1.383\n",
      "[63, 360] loss: 1.373\n",
      "Epoch: 63 -> Loss: 1.32970631123\n",
      "Epoch: 63 -> Test Accuracy: 44.92\n",
      "[64, 60] loss: 1.378\n",
      "[64, 120] loss: 1.395\n",
      "[64, 180] loss: 1.378\n",
      "[64, 240] loss: 1.387\n",
      "[64, 300] loss: 1.401\n",
      "[64, 360] loss: 1.375\n",
      "Epoch: 64 -> Loss: 1.42280781269\n",
      "Epoch: 64 -> Test Accuracy: 44.81\n",
      "[65, 60] loss: 1.393\n",
      "[65, 120] loss: 1.394\n",
      "[65, 180] loss: 1.408\n",
      "[65, 240] loss: 1.391\n",
      "[65, 300] loss: 1.384\n",
      "[65, 360] loss: 1.354\n",
      "Epoch: 65 -> Loss: 1.45208001137\n",
      "Epoch: 65 -> Test Accuracy: 44.87\n",
      "[66, 60] loss: 1.390\n",
      "[66, 120] loss: 1.385\n",
      "[66, 180] loss: 1.395\n",
      "[66, 240] loss: 1.369\n",
      "[66, 300] loss: 1.381\n",
      "[66, 360] loss: 1.391\n",
      "Epoch: 66 -> Loss: 1.48226940632\n",
      "Epoch: 66 -> Test Accuracy: 44.68\n",
      "[67, 60] loss: 1.387\n",
      "[67, 120] loss: 1.391\n",
      "[67, 180] loss: 1.388\n",
      "[67, 240] loss: 1.382\n",
      "[67, 300] loss: 1.384\n",
      "[67, 360] loss: 1.380\n",
      "Epoch: 67 -> Loss: 1.57635855675\n",
      "Epoch: 67 -> Test Accuracy: 44.97\n",
      "[68, 60] loss: 1.379\n",
      "[68, 120] loss: 1.371\n",
      "[68, 180] loss: 1.389\n",
      "[68, 240] loss: 1.367\n",
      "[68, 300] loss: 1.380\n",
      "[68, 360] loss: 1.411\n",
      "Epoch: 68 -> Loss: 1.50547111034\n",
      "Epoch: 68 -> Test Accuracy: 44.91\n",
      "[69, 60] loss: 1.388\n",
      "[69, 120] loss: 1.393\n",
      "[69, 180] loss: 1.391\n",
      "[69, 240] loss: 1.377\n",
      "[69, 300] loss: 1.369\n",
      "[69, 360] loss: 1.349\n",
      "Epoch: 69 -> Loss: 1.28048968315\n",
      "Epoch: 69 -> Test Accuracy: 44.88\n",
      "[70, 60] loss: 1.404\n",
      "[70, 120] loss: 1.364\n",
      "[70, 180] loss: 1.374\n",
      "[70, 240] loss: 1.385\n",
      "[70, 300] loss: 1.366\n",
      "[70, 360] loss: 1.403\n",
      "Epoch: 70 -> Loss: 1.4964350462\n",
      "Epoch: 70 -> Test Accuracy: 45.0\n",
      "[71, 60] loss: 1.373\n",
      "[71, 120] loss: 1.377\n",
      "[71, 180] loss: 1.387\n",
      "[71, 240] loss: 1.391\n",
      "[71, 300] loss: 1.368\n",
      "[71, 360] loss: 1.371\n",
      "Epoch: 71 -> Loss: 1.40300703049\n",
      "Epoch: 71 -> Test Accuracy: 44.9\n",
      "[72, 60] loss: 1.375\n",
      "[72, 120] loss: 1.378\n",
      "[72, 180] loss: 1.380\n",
      "[72, 240] loss: 1.350\n",
      "[72, 300] loss: 1.382\n",
      "[72, 360] loss: 1.384\n",
      "Epoch: 72 -> Loss: 1.49027097225\n",
      "Epoch: 72 -> Test Accuracy: 44.87\n",
      "[73, 60] loss: 1.381\n",
      "[73, 120] loss: 1.374\n",
      "[73, 180] loss: 1.372\n",
      "[73, 240] loss: 1.368\n",
      "[73, 300] loss: 1.376\n",
      "[73, 360] loss: 1.371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 -> Loss: 1.4244248867\n",
      "Epoch: 73 -> Test Accuracy: 44.77\n",
      "[74, 60] loss: 1.383\n",
      "[74, 120] loss: 1.371\n",
      "[74, 180] loss: 1.388\n",
      "[74, 240] loss: 1.386\n",
      "[74, 300] loss: 1.384\n",
      "[74, 360] loss: 1.383\n",
      "Epoch: 74 -> Loss: 1.35262942314\n",
      "Epoch: 74 -> Test Accuracy: 44.53\n",
      "[75, 60] loss: 1.381\n",
      "[75, 120] loss: 1.366\n",
      "[75, 180] loss: 1.373\n",
      "[75, 240] loss: 1.369\n",
      "[75, 300] loss: 1.363\n",
      "[75, 360] loss: 1.396\n",
      "Epoch: 75 -> Loss: 1.44752717018\n",
      "Epoch: 75 -> Test Accuracy: 44.99\n",
      "[76, 60] loss: 1.357\n",
      "[76, 120] loss: 1.399\n",
      "[76, 180] loss: 1.378\n",
      "[76, 240] loss: 1.369\n",
      "[76, 300] loss: 1.393\n",
      "[76, 360] loss: 1.379\n",
      "Epoch: 76 -> Loss: 1.41566932201\n",
      "Epoch: 76 -> Test Accuracy: 44.62\n",
      "[77, 60] loss: 1.358\n",
      "[77, 120] loss: 1.372\n",
      "[77, 180] loss: 1.373\n",
      "[77, 240] loss: 1.376\n",
      "[77, 300] loss: 1.372\n",
      "[77, 360] loss: 1.371\n",
      "Epoch: 77 -> Loss: 1.48313963413\n",
      "Epoch: 77 -> Test Accuracy: 44.91\n",
      "[78, 60] loss: 1.375\n",
      "[78, 120] loss: 1.375\n",
      "[78, 180] loss: 1.377\n",
      "[78, 240] loss: 1.377\n",
      "[78, 300] loss: 1.365\n",
      "[78, 360] loss: 1.383\n",
      "Epoch: 78 -> Loss: 1.26627409458\n",
      "Epoch: 78 -> Test Accuracy: 44.69\n",
      "[79, 60] loss: 1.402\n",
      "[79, 120] loss: 1.385\n",
      "[79, 180] loss: 1.368\n",
      "[79, 240] loss: 1.371\n",
      "[79, 300] loss: 1.371\n",
      "[79, 360] loss: 1.363\n",
      "Epoch: 79 -> Loss: 1.41633379459\n",
      "Epoch: 79 -> Test Accuracy: 44.69\n",
      "[80, 60] loss: 1.377\n",
      "[80, 120] loss: 1.402\n",
      "[80, 180] loss: 1.360\n",
      "[80, 240] loss: 1.347\n",
      "[80, 300] loss: 1.376\n",
      "[80, 360] loss: 1.353\n",
      "Epoch: 80 -> Loss: 1.38437247276\n",
      "Epoch: 80 -> Test Accuracy: 44.72\n",
      "[81, 60] loss: 1.392\n",
      "[81, 120] loss: 1.365\n",
      "[81, 180] loss: 1.377\n",
      "[81, 240] loss: 1.380\n",
      "[81, 300] loss: 1.358\n",
      "[81, 360] loss: 1.363\n",
      "Epoch: 81 -> Loss: 1.43992733955\n",
      "Epoch: 81 -> Test Accuracy: 44.89\n",
      "[82, 60] loss: 1.365\n",
      "[82, 120] loss: 1.377\n",
      "[82, 180] loss: 1.372\n",
      "[82, 240] loss: 1.363\n",
      "[82, 300] loss: 1.378\n",
      "[82, 360] loss: 1.366\n",
      "Epoch: 82 -> Loss: 1.4346010685\n",
      "Epoch: 82 -> Test Accuracy: 44.92\n",
      "[83, 60] loss: 1.382\n",
      "[83, 120] loss: 1.371\n",
      "[83, 180] loss: 1.369\n",
      "[83, 240] loss: 1.356\n",
      "[83, 300] loss: 1.364\n",
      "[83, 360] loss: 1.384\n",
      "Epoch: 83 -> Loss: 1.38349938393\n",
      "Epoch: 83 -> Test Accuracy: 44.74\n",
      "[84, 60] loss: 1.390\n",
      "[84, 120] loss: 1.372\n",
      "[84, 180] loss: 1.370\n",
      "[84, 240] loss: 1.361\n",
      "[84, 300] loss: 1.377\n",
      "[84, 360] loss: 1.374\n",
      "Epoch: 84 -> Loss: 1.35401344299\n",
      "Epoch: 84 -> Test Accuracy: 44.8\n",
      "[85, 60] loss: 1.375\n",
      "[85, 120] loss: 1.382\n",
      "[85, 180] loss: 1.353\n",
      "[85, 240] loss: 1.385\n",
      "[85, 300] loss: 1.374\n",
      "[85, 360] loss: 1.362\n",
      "Epoch: 85 -> Loss: 1.42785000801\n",
      "Epoch: 85 -> Test Accuracy: 44.96\n",
      "[86, 60] loss: 1.361\n",
      "[86, 120] loss: 1.371\n",
      "[86, 180] loss: 1.359\n",
      "[86, 240] loss: 1.371\n",
      "[86, 300] loss: 1.375\n",
      "[86, 360] loss: 1.379\n",
      "Epoch: 86 -> Loss: 1.2169406414\n",
      "Epoch: 86 -> Test Accuracy: 44.77\n",
      "[87, 60] loss: 1.362\n",
      "[87, 120] loss: 1.378\n",
      "[87, 180] loss: 1.355\n",
      "[87, 240] loss: 1.370\n",
      "[87, 300] loss: 1.361\n",
      "[87, 360] loss: 1.361\n",
      "Epoch: 87 -> Loss: 1.3394639492\n",
      "Epoch: 87 -> Test Accuracy: 44.99\n",
      "[88, 60] loss: 1.356\n",
      "[88, 120] loss: 1.374\n",
      "[88, 180] loss: 1.372\n",
      "[88, 240] loss: 1.375\n",
      "[88, 300] loss: 1.382\n",
      "[88, 360] loss: 1.339\n",
      "Epoch: 88 -> Loss: 1.58471822739\n",
      "Epoch: 88 -> Test Accuracy: 44.71\n",
      "[89, 60] loss: 1.368\n",
      "[89, 120] loss: 1.375\n",
      "[89, 180] loss: 1.365\n",
      "[89, 240] loss: 1.362\n",
      "[89, 300] loss: 1.368\n",
      "[89, 360] loss: 1.373\n",
      "Epoch: 89 -> Loss: 1.30124342442\n",
      "Epoch: 89 -> Test Accuracy: 45.03\n",
      "[90, 60] loss: 1.377\n",
      "[90, 120] loss: 1.347\n",
      "[90, 180] loss: 1.355\n",
      "[90, 240] loss: 1.382\n",
      "[90, 300] loss: 1.381\n",
      "[90, 360] loss: 1.378\n",
      "Epoch: 90 -> Loss: 1.3201675415\n",
      "Epoch: 90 -> Test Accuracy: 44.87\n",
      "[91, 60] loss: 1.361\n",
      "[91, 120] loss: 1.365\n",
      "[91, 180] loss: 1.357\n",
      "[91, 240] loss: 1.361\n",
      "[91, 300] loss: 1.367\n",
      "[91, 360] loss: 1.364\n",
      "Epoch: 91 -> Loss: 1.43757009506\n",
      "Epoch: 91 -> Test Accuracy: 44.93\n",
      "[92, 60] loss: 1.367\n",
      "[92, 120] loss: 1.368\n",
      "[92, 180] loss: 1.386\n",
      "[92, 240] loss: 1.356\n",
      "[92, 300] loss: 1.356\n",
      "[92, 360] loss: 1.372\n",
      "Epoch: 92 -> Loss: 1.41503834724\n",
      "Epoch: 92 -> Test Accuracy: 44.73\n",
      "[93, 60] loss: 1.368\n",
      "[93, 120] loss: 1.362\n",
      "[93, 180] loss: 1.368\n",
      "[93, 240] loss: 1.353\n",
      "[93, 300] loss: 1.373\n",
      "[93, 360] loss: 1.358\n",
      "Epoch: 93 -> Loss: 1.23785424232\n",
      "Epoch: 93 -> Test Accuracy: 44.84\n",
      "[94, 60] loss: 1.360\n",
      "[94, 120] loss: 1.374\n",
      "[94, 180] loss: 1.352\n",
      "[94, 240] loss: 1.347\n",
      "[94, 300] loss: 1.363\n",
      "[94, 360] loss: 1.371\n",
      "Epoch: 94 -> Loss: 1.20704317093\n",
      "Epoch: 94 -> Test Accuracy: 44.85\n",
      "[95, 60] loss: 1.364\n",
      "[95, 120] loss: 1.360\n",
      "[95, 180] loss: 1.375\n",
      "[95, 240] loss: 1.371\n",
      "[95, 300] loss: 1.356\n",
      "[95, 360] loss: 1.348\n",
      "Epoch: 95 -> Loss: 1.3346362114\n",
      "Epoch: 95 -> Test Accuracy: 44.99\n",
      "[96, 60] loss: 1.359\n",
      "[96, 120] loss: 1.350\n",
      "[96, 180] loss: 1.366\n",
      "[96, 240] loss: 1.356\n",
      "[96, 300] loss: 1.369\n",
      "[96, 360] loss: 1.351\n",
      "Epoch: 96 -> Loss: 1.27108216286\n",
      "Epoch: 96 -> Test Accuracy: 44.95\n",
      "[97, 60] loss: 1.350\n",
      "[97, 120] loss: 1.384\n",
      "[97, 180] loss: 1.370\n",
      "[97, 240] loss: 1.359\n",
      "[97, 300] loss: 1.355\n",
      "[97, 360] loss: 1.380\n",
      "Epoch: 97 -> Loss: 1.37658238411\n",
      "Epoch: 97 -> Test Accuracy: 45.39\n",
      "[98, 60] loss: 1.345\n",
      "[98, 120] loss: 1.377\n",
      "[98, 180] loss: 1.367\n",
      "[98, 240] loss: 1.348\n",
      "[98, 300] loss: 1.380\n",
      "[98, 360] loss: 1.371\n",
      "Epoch: 98 -> Loss: 1.39473462105\n",
      "Epoch: 98 -> Test Accuracy: 45.08\n",
      "[99, 60] loss: 1.382\n",
      "[99, 120] loss: 1.350\n",
      "[99, 180] loss: 1.389\n",
      "[99, 240] loss: 1.353\n",
      "[99, 300] loss: 1.362\n",
      "[99, 360] loss: 1.359\n",
      "Epoch: 99 -> Loss: 1.51599693298\n",
      "Epoch: 99 -> Test Accuracy: 45.19\n",
      "[100, 60] loss: 1.377\n",
      "[100, 120] loss: 1.351\n",
      "[100, 180] loss: 1.357\n",
      "[100, 240] loss: 1.372\n",
      "[100, 300] loss: 1.373\n",
      "[100, 360] loss: 1.347\n",
      "Epoch: 100 -> Loss: 1.36378133297\n",
      "Epoch: 100 -> Test Accuracy: 44.88\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train NonLinearClassifiers on feature map of net_3block\n",
    "block4_loss_log, block4_valid_accuracy_log, block4_test_accuracy_log, block4_max_accuracy, block4_best_epoch = \\\n",
    "tr.train_all_blocks(4, 10, [0.1, 0.02, 0.004, 0.0008], [20, 40, 45, 100], 0.9, 5e-4, net_block4, criterion, trainloader,\n",
    "                    None, testloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.317\n",
      "[1, 120] loss: 1.034\n",
      "[1, 180] loss: 0.942\n",
      "[1, 240] loss: 0.878\n",
      "[1, 300] loss: 0.822\n",
      "[1, 360] loss: 0.777\n",
      "Epoch: 1 -> Loss: 0.85375893116\n",
      "Epoch: 1 -> Test Accuracy: 69.91\n",
      "[2, 60] loss: 0.731\n",
      "[2, 120] loss: 0.704\n",
      "[2, 180] loss: 0.729\n",
      "[2, 240] loss: 0.700\n",
      "[2, 300] loss: 0.659\n",
      "[2, 360] loss: 0.675\n",
      "Epoch: 2 -> Loss: 0.733563542366\n",
      "Epoch: 2 -> Test Accuracy: 74.2\n",
      "[3, 60] loss: 0.634\n",
      "[3, 120] loss: 0.621\n",
      "[3, 180] loss: 0.623\n",
      "[3, 240] loss: 0.608\n",
      "[3, 300] loss: 0.599\n",
      "[3, 360] loss: 0.622\n",
      "Epoch: 3 -> Loss: 0.657238602638\n",
      "Epoch: 3 -> Test Accuracy: 75.29\n",
      "[4, 60] loss: 0.569\n",
      "[4, 120] loss: 0.579\n",
      "[4, 180] loss: 0.581\n",
      "[4, 240] loss: 0.577\n",
      "[4, 300] loss: 0.566\n",
      "[4, 360] loss: 0.570\n",
      "Epoch: 4 -> Loss: 0.562706947327\n",
      "Epoch: 4 -> Test Accuracy: 77.76\n",
      "[5, 60] loss: 0.527\n",
      "[5, 120] loss: 0.546\n",
      "[5, 180] loss: 0.549\n",
      "[5, 240] loss: 0.541\n",
      "[5, 300] loss: 0.543\n",
      "[5, 360] loss: 0.542\n",
      "Epoch: 5 -> Loss: 0.55960047245\n",
      "Epoch: 5 -> Test Accuracy: 79.33\n",
      "[6, 60] loss: 0.502\n",
      "[6, 120] loss: 0.523\n",
      "[6, 180] loss: 0.528\n",
      "[6, 240] loss: 0.524\n",
      "[6, 300] loss: 0.522\n",
      "[6, 360] loss: 0.522\n",
      "Epoch: 6 -> Loss: 0.461411237717\n",
      "Epoch: 6 -> Test Accuracy: 78.56\n",
      "[7, 60] loss: 0.481\n",
      "[7, 120] loss: 0.482\n",
      "[7, 180] loss: 0.502\n",
      "[7, 240] loss: 0.509\n",
      "[7, 300] loss: 0.502\n",
      "[7, 360] loss: 0.528\n",
      "Epoch: 7 -> Loss: 0.469476759434\n",
      "Epoch: 7 -> Test Accuracy: 78.43\n",
      "[8, 60] loss: 0.478\n",
      "[8, 120] loss: 0.486\n",
      "[8, 180] loss: 0.491\n",
      "[8, 240] loss: 0.485\n",
      "[8, 300] loss: 0.511\n",
      "[8, 360] loss: 0.491\n",
      "Epoch: 8 -> Loss: 0.554013252258\n",
      "Epoch: 8 -> Test Accuracy: 78.34\n",
      "[9, 60] loss: 0.472\n",
      "[9, 120] loss: 0.477\n",
      "[9, 180] loss: 0.480\n",
      "[9, 240] loss: 0.483\n",
      "[9, 300] loss: 0.476\n",
      "[9, 360] loss: 0.501\n",
      "Epoch: 9 -> Loss: 0.504217922688\n",
      "Epoch: 9 -> Test Accuracy: 79.39\n",
      "[10, 60] loss: 0.453\n",
      "[10, 120] loss: 0.462\n",
      "[10, 180] loss: 0.469\n",
      "[10, 240] loss: 0.472\n",
      "[10, 300] loss: 0.476\n",
      "[10, 360] loss: 0.497\n",
      "Epoch: 10 -> Loss: 0.388833403587\n",
      "Epoch: 10 -> Test Accuracy: 79.87\n",
      "[11, 60] loss: 0.453\n",
      "[11, 120] loss: 0.460\n",
      "[11, 180] loss: 0.480\n",
      "[11, 240] loss: 0.475\n",
      "[11, 300] loss: 0.463\n",
      "[11, 360] loss: 0.463\n",
      "Epoch: 11 -> Loss: 0.63988673687\n",
      "Epoch: 11 -> Test Accuracy: 79.02\n",
      "[12, 60] loss: 0.452\n",
      "[12, 120] loss: 0.458\n",
      "[12, 180] loss: 0.470\n",
      "[12, 240] loss: 0.458\n",
      "[12, 300] loss: 0.454\n",
      "[12, 360] loss: 0.470\n",
      "Epoch: 12 -> Loss: 0.373396754265\n",
      "Epoch: 12 -> Test Accuracy: 80.29\n",
      "[13, 60] loss: 0.432\n",
      "[13, 120] loss: 0.441\n",
      "[13, 180] loss: 0.437\n",
      "[13, 240] loss: 0.467\n",
      "[13, 300] loss: 0.460\n",
      "[13, 360] loss: 0.474\n",
      "Epoch: 13 -> Loss: 0.513366818428\n",
      "Epoch: 13 -> Test Accuracy: 80.27\n",
      "[14, 60] loss: 0.428\n",
      "[14, 120] loss: 0.421\n",
      "[14, 180] loss: 0.433\n",
      "[14, 240] loss: 0.455\n",
      "[14, 300] loss: 0.472\n",
      "[14, 360] loss: 0.459\n",
      "Epoch: 14 -> Loss: 0.390967190266\n",
      "Epoch: 14 -> Test Accuracy: 81.06\n",
      "[15, 60] loss: 0.432\n",
      "[15, 120] loss: 0.447\n",
      "[15, 180] loss: 0.432\n",
      "[15, 240] loss: 0.444\n",
      "[15, 300] loss: 0.459\n",
      "[15, 360] loss: 0.442\n",
      "Epoch: 15 -> Loss: 0.435603708029\n",
      "Epoch: 15 -> Test Accuracy: 79.75\n",
      "[16, 60] loss: 0.432\n",
      "[16, 120] loss: 0.417\n",
      "[16, 180] loss: 0.452\n",
      "[16, 240] loss: 0.439\n",
      "[16, 300] loss: 0.447\n",
      "[16, 360] loss: 0.448\n",
      "Epoch: 16 -> Loss: 0.441903918982\n",
      "Epoch: 16 -> Test Accuracy: 79.64\n",
      "[17, 60] loss: 0.411\n",
      "[17, 120] loss: 0.433\n",
      "[17, 180] loss: 0.433\n",
      "[17, 240] loss: 0.438\n",
      "[17, 300] loss: 0.450\n",
      "[17, 360] loss: 0.445\n",
      "Epoch: 17 -> Loss: 0.626737892628\n",
      "Epoch: 17 -> Test Accuracy: 79.97\n",
      "[18, 60] loss: 0.396\n",
      "[18, 120] loss: 0.430\n",
      "[18, 180] loss: 0.434\n",
      "[18, 240] loss: 0.435\n",
      "[18, 300] loss: 0.432\n",
      "[18, 360] loss: 0.449\n",
      "Epoch: 18 -> Loss: 0.517948031425\n",
      "Epoch: 18 -> Test Accuracy: 80.95\n",
      "[19, 60] loss: 0.399\n",
      "[19, 120] loss: 0.438\n",
      "[19, 180] loss: 0.452\n",
      "[19, 240] loss: 0.438\n",
      "[19, 300] loss: 0.430\n",
      "[19, 360] loss: 0.437\n",
      "Epoch: 19 -> Loss: 0.557867348194\n",
      "Epoch: 19 -> Test Accuracy: 80.61\n",
      "[20, 60] loss: 0.417\n",
      "[20, 120] loss: 0.416\n",
      "[20, 180] loss: 0.429\n",
      "[20, 240] loss: 0.445\n",
      "[20, 300] loss: 0.422\n",
      "[20, 360] loss: 0.424\n",
      "Epoch: 20 -> Loss: 0.506871461868\n",
      "Epoch: 20 -> Test Accuracy: 81.03\n",
      "[21, 60] loss: 0.419\n",
      "[21, 120] loss: 0.405\n",
      "[21, 180] loss: 0.420\n",
      "[21, 240] loss: 0.425\n",
      "[21, 300] loss: 0.429\n",
      "[21, 360] loss: 0.450\n",
      "Epoch: 21 -> Loss: 0.389891326427\n",
      "Epoch: 21 -> Test Accuracy: 81.23\n",
      "[22, 60] loss: 0.410\n",
      "[22, 120] loss: 0.428\n",
      "[22, 180] loss: 0.444\n",
      "[22, 240] loss: 0.399\n",
      "[22, 300] loss: 0.451\n",
      "[22, 360] loss: 0.439\n",
      "Epoch: 22 -> Loss: 0.449398756027\n",
      "Epoch: 22 -> Test Accuracy: 80.45\n",
      "[23, 60] loss: 0.389\n",
      "[23, 120] loss: 0.417\n",
      "[23, 180] loss: 0.443\n",
      "[23, 240] loss: 0.421\n",
      "[23, 300] loss: 0.427\n",
      "[23, 360] loss: 0.442\n",
      "Epoch: 23 -> Loss: 0.541883945465\n",
      "Epoch: 23 -> Test Accuracy: 80.32\n",
      "[24, 60] loss: 0.406\n",
      "[24, 120] loss: 0.412\n",
      "[24, 180] loss: 0.431\n",
      "[24, 240] loss: 0.424\n",
      "[24, 300] loss: 0.433\n",
      "[24, 360] loss: 0.420\n",
      "Epoch: 24 -> Loss: 0.37931266427\n",
      "Epoch: 24 -> Test Accuracy: 81.64\n",
      "[25, 60] loss: 0.376\n",
      "[25, 120] loss: 0.416\n",
      "[25, 180] loss: 0.429\n",
      "[25, 240] loss: 0.419\n",
      "[25, 300] loss: 0.448\n",
      "[25, 360] loss: 0.431\n",
      "Epoch: 25 -> Loss: 0.597392439842\n",
      "Epoch: 25 -> Test Accuracy: 81.31\n",
      "[26, 60] loss: 0.394\n",
      "[26, 120] loss: 0.429\n",
      "[26, 180] loss: 0.416\n",
      "[26, 240] loss: 0.410\n",
      "[26, 300] loss: 0.419\n",
      "[26, 360] loss: 0.455\n",
      "Epoch: 26 -> Loss: 0.511675238609\n",
      "Epoch: 26 -> Test Accuracy: 81.28\n",
      "[27, 60] loss: 0.395\n",
      "[27, 120] loss: 0.416\n",
      "[27, 180] loss: 0.420\n",
      "[27, 240] loss: 0.426\n",
      "[27, 300] loss: 0.421\n",
      "[27, 360] loss: 0.426\n",
      "Epoch: 27 -> Loss: 0.578441977501\n",
      "Epoch: 27 -> Test Accuracy: 79.8\n",
      "[28, 60] loss: 0.392\n",
      "[28, 120] loss: 0.408\n",
      "[28, 180] loss: 0.429\n",
      "[28, 240] loss: 0.429\n",
      "[28, 300] loss: 0.416\n",
      "[28, 360] loss: 0.440\n",
      "Epoch: 28 -> Loss: 0.333692938089\n",
      "Epoch: 28 -> Test Accuracy: 81.68\n",
      "[29, 60] loss: 0.404\n",
      "[29, 120] loss: 0.400\n",
      "[29, 180] loss: 0.411\n",
      "[29, 240] loss: 0.413\n",
      "[29, 300] loss: 0.423\n",
      "[29, 360] loss: 0.424\n",
      "Epoch: 29 -> Loss: 0.342605531216\n",
      "Epoch: 29 -> Test Accuracy: 79.7\n",
      "[30, 60] loss: 0.393\n",
      "[30, 120] loss: 0.416\n",
      "[30, 180] loss: 0.409\n",
      "[30, 240] loss: 0.430\n",
      "[30, 300] loss: 0.423\n",
      "[30, 360] loss: 0.431\n",
      "Epoch: 30 -> Loss: 0.394117236137\n",
      "Epoch: 30 -> Test Accuracy: 80.16\n",
      "[31, 60] loss: 0.414\n",
      "[31, 120] loss: 0.414\n",
      "[31, 180] loss: 0.413\n",
      "[31, 240] loss: 0.422\n",
      "[31, 300] loss: 0.417\n",
      "[31, 360] loss: 0.409\n",
      "Epoch: 31 -> Loss: 0.443602710962\n",
      "Epoch: 31 -> Test Accuracy: 80.6\n",
      "[32, 60] loss: 0.406\n",
      "[32, 120] loss: 0.412\n",
      "[32, 180] loss: 0.417\n",
      "[32, 240] loss: 0.404\n",
      "[32, 300] loss: 0.417\n",
      "[32, 360] loss: 0.441\n",
      "Epoch: 32 -> Loss: 0.419434785843\n",
      "Epoch: 32 -> Test Accuracy: 80.52\n",
      "[33, 60] loss: 0.409\n",
      "[33, 120] loss: 0.391\n",
      "[33, 180] loss: 0.416\n",
      "[33, 240] loss: 0.429\n",
      "[33, 300] loss: 0.421\n",
      "[33, 360] loss: 0.416\n",
      "Epoch: 33 -> Loss: 0.307298958302\n",
      "Epoch: 33 -> Test Accuracy: 80.33\n",
      "[34, 60] loss: 0.399\n",
      "[34, 120] loss: 0.415\n",
      "[34, 180] loss: 0.401\n",
      "[34, 240] loss: 0.426\n",
      "[34, 300] loss: 0.418\n",
      "[34, 360] loss: 0.428\n",
      "Epoch: 34 -> Loss: 0.300357103348\n",
      "Epoch: 34 -> Test Accuracy: 81.79\n",
      "[35, 60] loss: 0.398\n",
      "[35, 120] loss: 0.391\n",
      "[35, 180] loss: 0.431\n",
      "[35, 240] loss: 0.408\n",
      "[35, 300] loss: 0.433\n",
      "[35, 360] loss: 0.411\n",
      "Epoch: 35 -> Loss: 0.710281848907\n",
      "Epoch: 35 -> Test Accuracy: 80.85\n",
      "[36, 60] loss: 0.336\n",
      "[36, 120] loss: 0.293\n",
      "[36, 180] loss: 0.293\n",
      "[36, 240] loss: 0.281\n",
      "[36, 300] loss: 0.275\n",
      "[36, 360] loss: 0.273\n",
      "Epoch: 36 -> Loss: 0.209502652287\n",
      "Epoch: 36 -> Test Accuracy: 85.22\n",
      "[37, 60] loss: 0.252\n",
      "[37, 120] loss: 0.259\n",
      "[37, 180] loss: 0.256\n",
      "[37, 240] loss: 0.253\n",
      "[37, 300] loss: 0.267\n",
      "[37, 360] loss: 0.257\n",
      "Epoch: 37 -> Loss: 0.244319960475\n",
      "Epoch: 37 -> Test Accuracy: 85.26\n",
      "[38, 60] loss: 0.228\n",
      "[38, 120] loss: 0.236\n",
      "[38, 180] loss: 0.237\n",
      "[38, 240] loss: 0.246\n",
      "[38, 300] loss: 0.241\n",
      "[38, 360] loss: 0.254\n",
      "Epoch: 38 -> Loss: 0.291436851025\n",
      "Epoch: 38 -> Test Accuracy: 85.68\n",
      "[39, 60] loss: 0.219\n",
      "[39, 120] loss: 0.222\n",
      "[39, 180] loss: 0.246\n",
      "[39, 240] loss: 0.238\n",
      "[39, 300] loss: 0.251\n",
      "[39, 360] loss: 0.239\n",
      "Epoch: 39 -> Loss: 0.418965399265\n",
      "Epoch: 39 -> Test Accuracy: 85.31\n",
      "[40, 60] loss: 0.214\n",
      "[40, 120] loss: 0.225\n",
      "[40, 180] loss: 0.234\n",
      "[40, 240] loss: 0.228\n",
      "[40, 300] loss: 0.235\n",
      "[40, 360] loss: 0.228\n",
      "Epoch: 40 -> Loss: 0.271593302488\n",
      "Epoch: 40 -> Test Accuracy: 85.93\n",
      "[41, 60] loss: 0.215\n",
      "[41, 120] loss: 0.223\n",
      "[41, 180] loss: 0.225\n",
      "[41, 240] loss: 0.240\n",
      "[41, 300] loss: 0.231\n",
      "[41, 360] loss: 0.227\n",
      "Epoch: 41 -> Loss: 0.213749974966\n",
      "Epoch: 41 -> Test Accuracy: 85.35\n",
      "[42, 60] loss: 0.204\n",
      "[42, 120] loss: 0.213\n",
      "[42, 180] loss: 0.228\n",
      "[42, 240] loss: 0.237\n",
      "[42, 300] loss: 0.230\n",
      "[42, 360] loss: 0.221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.293609887362\n",
      "Epoch: 42 -> Test Accuracy: 84.74\n",
      "[43, 60] loss: 0.214\n",
      "[43, 120] loss: 0.216\n",
      "[43, 180] loss: 0.222\n",
      "[43, 240] loss: 0.228\n",
      "[43, 300] loss: 0.225\n",
      "[43, 360] loss: 0.238\n",
      "Epoch: 43 -> Loss: 0.207216143608\n",
      "Epoch: 43 -> Test Accuracy: 85.34\n",
      "[44, 60] loss: 0.210\n",
      "[44, 120] loss: 0.208\n",
      "[44, 180] loss: 0.224\n",
      "[44, 240] loss: 0.223\n",
      "[44, 300] loss: 0.232\n",
      "[44, 360] loss: 0.227\n",
      "Epoch: 44 -> Loss: 0.388124346733\n",
      "Epoch: 44 -> Test Accuracy: 84.88\n",
      "[45, 60] loss: 0.202\n",
      "[45, 120] loss: 0.227\n",
      "[45, 180] loss: 0.225\n",
      "[45, 240] loss: 0.219\n",
      "[45, 300] loss: 0.235\n",
      "[45, 360] loss: 0.241\n",
      "Epoch: 45 -> Loss: 0.259338051081\n",
      "Epoch: 45 -> Test Accuracy: 84.38\n",
      "[46, 60] loss: 0.206\n",
      "[46, 120] loss: 0.208\n",
      "[46, 180] loss: 0.216\n",
      "[46, 240] loss: 0.233\n",
      "[46, 300] loss: 0.230\n",
      "[46, 360] loss: 0.232\n",
      "Epoch: 46 -> Loss: 0.40508466959\n",
      "Epoch: 46 -> Test Accuracy: 84.92\n",
      "[47, 60] loss: 0.205\n",
      "[47, 120] loss: 0.213\n",
      "[47, 180] loss: 0.226\n",
      "[47, 240] loss: 0.225\n",
      "[47, 300] loss: 0.238\n",
      "[47, 360] loss: 0.225\n",
      "Epoch: 47 -> Loss: 0.371215879917\n",
      "Epoch: 47 -> Test Accuracy: 84.78\n",
      "[48, 60] loss: 0.219\n",
      "[48, 120] loss: 0.211\n",
      "[48, 180] loss: 0.228\n",
      "[48, 240] loss: 0.227\n",
      "[48, 300] loss: 0.225\n",
      "[48, 360] loss: 0.221\n",
      "Epoch: 48 -> Loss: 0.224132329226\n",
      "Epoch: 48 -> Test Accuracy: 85.14\n",
      "[49, 60] loss: 0.205\n",
      "[49, 120] loss: 0.211\n",
      "[49, 180] loss: 0.220\n",
      "[49, 240] loss: 0.220\n",
      "[49, 300] loss: 0.248\n",
      "[49, 360] loss: 0.231\n",
      "Epoch: 49 -> Loss: 0.252964317799\n",
      "Epoch: 49 -> Test Accuracy: 85.11\n",
      "[50, 60] loss: 0.200\n",
      "[50, 120] loss: 0.204\n",
      "[50, 180] loss: 0.216\n",
      "[50, 240] loss: 0.235\n",
      "[50, 300] loss: 0.231\n",
      "[50, 360] loss: 0.239\n",
      "Epoch: 50 -> Loss: 0.248744770885\n",
      "Epoch: 50 -> Test Accuracy: 84.45\n",
      "[51, 60] loss: 0.212\n",
      "[51, 120] loss: 0.210\n",
      "[51, 180] loss: 0.223\n",
      "[51, 240] loss: 0.222\n",
      "[51, 300] loss: 0.223\n",
      "[51, 360] loss: 0.243\n",
      "Epoch: 51 -> Loss: 0.272429913282\n",
      "Epoch: 51 -> Test Accuracy: 85.2\n",
      "[52, 60] loss: 0.215\n",
      "[52, 120] loss: 0.211\n",
      "[52, 180] loss: 0.218\n",
      "[52, 240] loss: 0.227\n",
      "[52, 300] loss: 0.221\n",
      "[52, 360] loss: 0.229\n",
      "Epoch: 52 -> Loss: 0.294247537851\n",
      "Epoch: 52 -> Test Accuracy: 85.04\n",
      "[53, 60] loss: 0.203\n",
      "[53, 120] loss: 0.220\n",
      "[53, 180] loss: 0.208\n",
      "[53, 240] loss: 0.228\n",
      "[53, 300] loss: 0.219\n",
      "[53, 360] loss: 0.237\n",
      "Epoch: 53 -> Loss: 0.313769996166\n",
      "Epoch: 53 -> Test Accuracy: 83.41\n",
      "[54, 60] loss: 0.213\n",
      "[54, 120] loss: 0.203\n",
      "[54, 180] loss: 0.221\n",
      "[54, 240] loss: 0.229\n",
      "[54, 300] loss: 0.235\n",
      "[54, 360] loss: 0.235\n",
      "Epoch: 54 -> Loss: 0.289877027273\n",
      "Epoch: 54 -> Test Accuracy: 84.81\n",
      "[55, 60] loss: 0.203\n",
      "[55, 120] loss: 0.204\n",
      "[55, 180] loss: 0.214\n",
      "[55, 240] loss: 0.228\n",
      "[55, 300] loss: 0.229\n",
      "[55, 360] loss: 0.237\n",
      "Epoch: 55 -> Loss: 0.222832590342\n",
      "Epoch: 55 -> Test Accuracy: 84.09\n",
      "[56, 60] loss: 0.214\n",
      "[56, 120] loss: 0.218\n",
      "[56, 180] loss: 0.214\n",
      "[56, 240] loss: 0.213\n",
      "[56, 300] loss: 0.226\n",
      "[56, 360] loss: 0.242\n",
      "Epoch: 56 -> Loss: 0.209725141525\n",
      "Epoch: 56 -> Test Accuracy: 85.16\n",
      "[57, 60] loss: 0.199\n",
      "[57, 120] loss: 0.211\n",
      "[57, 180] loss: 0.215\n",
      "[57, 240] loss: 0.226\n",
      "[57, 300] loss: 0.223\n",
      "[57, 360] loss: 0.224\n",
      "Epoch: 57 -> Loss: 0.312381833792\n",
      "Epoch: 57 -> Test Accuracy: 84.68\n",
      "[58, 60] loss: 0.205\n",
      "[58, 120] loss: 0.203\n",
      "[58, 180] loss: 0.214\n",
      "[58, 240] loss: 0.220\n",
      "[58, 300] loss: 0.227\n",
      "[58, 360] loss: 0.233\n",
      "Epoch: 58 -> Loss: 0.150704354048\n",
      "Epoch: 58 -> Test Accuracy: 83.98\n",
      "[59, 60] loss: 0.199\n",
      "[59, 120] loss: 0.200\n",
      "[59, 180] loss: 0.219\n",
      "[59, 240] loss: 0.224\n",
      "[59, 300] loss: 0.233\n",
      "[59, 360] loss: 0.235\n",
      "Epoch: 59 -> Loss: 0.225792959332\n",
      "Epoch: 59 -> Test Accuracy: 85.19\n",
      "[60, 60] loss: 0.199\n",
      "[60, 120] loss: 0.212\n",
      "[60, 180] loss: 0.226\n",
      "[60, 240] loss: 0.225\n",
      "[60, 300] loss: 0.232\n",
      "[60, 360] loss: 0.231\n",
      "Epoch: 60 -> Loss: 0.309464305639\n",
      "Epoch: 60 -> Test Accuracy: 84.62\n",
      "[61, 60] loss: 0.208\n",
      "[61, 120] loss: 0.211\n",
      "[61, 180] loss: 0.217\n",
      "[61, 240] loss: 0.219\n",
      "[61, 300] loss: 0.221\n",
      "[61, 360] loss: 0.223\n",
      "Epoch: 61 -> Loss: 0.281649410725\n",
      "Epoch: 61 -> Test Accuracy: 84.98\n",
      "[62, 60] loss: 0.207\n",
      "[62, 120] loss: 0.197\n",
      "[62, 180] loss: 0.210\n",
      "[62, 240] loss: 0.217\n",
      "[62, 300] loss: 0.231\n",
      "[62, 360] loss: 0.233\n",
      "Epoch: 62 -> Loss: 0.241186290979\n",
      "Epoch: 62 -> Test Accuracy: 84.4\n",
      "[63, 60] loss: 0.212\n",
      "[63, 120] loss: 0.213\n",
      "[63, 180] loss: 0.216\n",
      "[63, 240] loss: 0.215\n",
      "[63, 300] loss: 0.217\n",
      "[63, 360] loss: 0.212\n",
      "Epoch: 63 -> Loss: 0.190993517637\n",
      "Epoch: 63 -> Test Accuracy: 85.24\n",
      "[64, 60] loss: 0.194\n",
      "[64, 120] loss: 0.198\n",
      "[64, 180] loss: 0.204\n",
      "[64, 240] loss: 0.217\n",
      "[64, 300] loss: 0.228\n",
      "[64, 360] loss: 0.229\n",
      "Epoch: 64 -> Loss: 0.164922863245\n",
      "Epoch: 64 -> Test Accuracy: 83.97\n",
      "[65, 60] loss: 0.199\n",
      "[65, 120] loss: 0.202\n",
      "[65, 180] loss: 0.220\n",
      "[65, 240] loss: 0.208\n",
      "[65, 300] loss: 0.212\n",
      "[65, 360] loss: 0.224\n",
      "Epoch: 65 -> Loss: 0.259260714054\n",
      "Epoch: 65 -> Test Accuracy: 84.66\n",
      "[66, 60] loss: 0.198\n",
      "[66, 120] loss: 0.204\n",
      "[66, 180] loss: 0.213\n",
      "[66, 240] loss: 0.210\n",
      "[66, 300] loss: 0.210\n",
      "[66, 360] loss: 0.228\n",
      "Epoch: 66 -> Loss: 0.158710092306\n",
      "Epoch: 66 -> Test Accuracy: 84.6\n",
      "[67, 60] loss: 0.201\n",
      "[67, 120] loss: 0.202\n",
      "[67, 180] loss: 0.218\n",
      "[67, 240] loss: 0.230\n",
      "[67, 300] loss: 0.222\n",
      "[67, 360] loss: 0.220\n",
      "Epoch: 67 -> Loss: 0.216457799077\n",
      "Epoch: 67 -> Test Accuracy: 84.48\n",
      "[68, 60] loss: 0.201\n",
      "[68, 120] loss: 0.206\n",
      "[68, 180] loss: 0.208\n",
      "[68, 240] loss: 0.211\n",
      "[68, 300] loss: 0.219\n",
      "[68, 360] loss: 0.217\n",
      "Epoch: 68 -> Loss: 0.310901194811\n",
      "Epoch: 68 -> Test Accuracy: 84.29\n",
      "[69, 60] loss: 0.207\n",
      "[69, 120] loss: 0.187\n",
      "[69, 180] loss: 0.206\n",
      "[69, 240] loss: 0.220\n",
      "[69, 300] loss: 0.215\n",
      "[69, 360] loss: 0.220\n",
      "Epoch: 69 -> Loss: 0.265194237232\n",
      "Epoch: 69 -> Test Accuracy: 84.67\n",
      "[70, 60] loss: 0.190\n",
      "[70, 120] loss: 0.196\n",
      "[70, 180] loss: 0.213\n",
      "[70, 240] loss: 0.209\n",
      "[70, 300] loss: 0.229\n",
      "[70, 360] loss: 0.229\n",
      "Epoch: 70 -> Loss: 0.219814866781\n",
      "Epoch: 70 -> Test Accuracy: 84.54\n",
      "[71, 60] loss: 0.172\n",
      "[71, 120] loss: 0.155\n",
      "[71, 180] loss: 0.146\n",
      "[71, 240] loss: 0.147\n",
      "[71, 300] loss: 0.142\n",
      "[71, 360] loss: 0.135\n",
      "Epoch: 71 -> Loss: 0.154975146055\n",
      "Epoch: 71 -> Test Accuracy: 86.76\n",
      "[72, 60] loss: 0.130\n",
      "[72, 120] loss: 0.128\n",
      "[72, 180] loss: 0.133\n",
      "[72, 240] loss: 0.128\n",
      "[72, 300] loss: 0.125\n",
      "[72, 360] loss: 0.131\n",
      "Epoch: 72 -> Loss: 0.18896356225\n",
      "Epoch: 72 -> Test Accuracy: 86.92\n",
      "[73, 60] loss: 0.115\n",
      "[73, 120] loss: 0.125\n",
      "[73, 180] loss: 0.120\n",
      "[73, 240] loss: 0.122\n",
      "[73, 300] loss: 0.127\n",
      "[73, 360] loss: 0.122\n",
      "Epoch: 73 -> Loss: 0.136390626431\n",
      "Epoch: 73 -> Test Accuracy: 86.92\n",
      "[74, 60] loss: 0.112\n",
      "[74, 120] loss: 0.120\n",
      "[74, 180] loss: 0.122\n",
      "[74, 240] loss: 0.123\n",
      "[74, 300] loss: 0.115\n",
      "[74, 360] loss: 0.125\n",
      "Epoch: 74 -> Loss: 0.0847362950444\n",
      "Epoch: 74 -> Test Accuracy: 86.99\n",
      "[75, 60] loss: 0.112\n",
      "[75, 120] loss: 0.113\n",
      "[75, 180] loss: 0.114\n",
      "[75, 240] loss: 0.116\n",
      "[75, 300] loss: 0.118\n",
      "[75, 360] loss: 0.116\n",
      "Epoch: 75 -> Loss: 0.163486152887\n",
      "Epoch: 75 -> Test Accuracy: 86.97\n",
      "[76, 60] loss: 0.108\n",
      "[76, 120] loss: 0.111\n",
      "[76, 180] loss: 0.113\n",
      "[76, 240] loss: 0.119\n",
      "[76, 300] loss: 0.109\n",
      "[76, 360] loss: 0.115\n",
      "Epoch: 76 -> Loss: 0.122818872333\n",
      "Epoch: 76 -> Test Accuracy: 86.74\n",
      "[77, 60] loss: 0.103\n",
      "[77, 120] loss: 0.108\n",
      "[77, 180] loss: 0.110\n",
      "[77, 240] loss: 0.109\n",
      "[77, 300] loss: 0.112\n",
      "[77, 360] loss: 0.110\n",
      "Epoch: 77 -> Loss: 0.147726923227\n",
      "Epoch: 77 -> Test Accuracy: 86.81\n",
      "[78, 60] loss: 0.105\n",
      "[78, 120] loss: 0.103\n",
      "[78, 180] loss: 0.107\n",
      "[78, 240] loss: 0.106\n",
      "[78, 300] loss: 0.112\n",
      "[78, 360] loss: 0.109\n",
      "Epoch: 78 -> Loss: 0.0883704572916\n",
      "Epoch: 78 -> Test Accuracy: 86.63\n",
      "[79, 60] loss: 0.101\n",
      "[79, 120] loss: 0.103\n",
      "[79, 180] loss: 0.104\n",
      "[79, 240] loss: 0.105\n",
      "[79, 300] loss: 0.108\n",
      "[79, 360] loss: 0.104\n",
      "Epoch: 79 -> Loss: 0.117004476488\n",
      "Epoch: 79 -> Test Accuracy: 86.9\n",
      "[80, 60] loss: 0.099\n",
      "[80, 120] loss: 0.100\n",
      "[80, 180] loss: 0.104\n",
      "[80, 240] loss: 0.101\n",
      "[80, 300] loss: 0.101\n",
      "[80, 360] loss: 0.110\n",
      "Epoch: 80 -> Loss: 0.195863872766\n",
      "Epoch: 80 -> Test Accuracy: 86.78\n",
      "[81, 60] loss: 0.103\n",
      "[81, 120] loss: 0.100\n",
      "[81, 180] loss: 0.104\n",
      "[81, 240] loss: 0.109\n",
      "[81, 300] loss: 0.099\n",
      "[81, 360] loss: 0.105\n",
      "Epoch: 81 -> Loss: 0.0843843743205\n",
      "Epoch: 81 -> Test Accuracy: 86.53\n",
      "[82, 60] loss: 0.099\n",
      "[82, 120] loss: 0.095\n",
      "[82, 180] loss: 0.101\n",
      "[82, 240] loss: 0.101\n",
      "[82, 300] loss: 0.108\n",
      "[82, 360] loss: 0.103\n",
      "Epoch: 82 -> Loss: 0.124904334545\n",
      "Epoch: 82 -> Test Accuracy: 86.52\n",
      "[83, 60] loss: 0.100\n",
      "[83, 120] loss: 0.094\n",
      "[83, 180] loss: 0.094\n",
      "[83, 240] loss: 0.100\n",
      "[83, 300] loss: 0.104\n",
      "[83, 360] loss: 0.100\n",
      "Epoch: 83 -> Loss: 0.0962811857462\n",
      "Epoch: 83 -> Test Accuracy: 86.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.098\n",
      "[84, 120] loss: 0.098\n",
      "[84, 180] loss: 0.094\n",
      "[84, 240] loss: 0.097\n",
      "[84, 300] loss: 0.100\n",
      "[84, 360] loss: 0.099\n",
      "Epoch: 84 -> Loss: 0.112793006003\n",
      "Epoch: 84 -> Test Accuracy: 86.37\n",
      "[85, 60] loss: 0.091\n",
      "[85, 120] loss: 0.099\n",
      "[85, 180] loss: 0.100\n",
      "[85, 240] loss: 0.101\n",
      "[85, 300] loss: 0.100\n",
      "[85, 360] loss: 0.099\n",
      "Epoch: 85 -> Loss: 0.124794438481\n",
      "Epoch: 85 -> Test Accuracy: 86.34\n",
      "[86, 60] loss: 0.095\n",
      "[86, 120] loss: 0.087\n",
      "[86, 180] loss: 0.086\n",
      "[86, 240] loss: 0.086\n",
      "[86, 300] loss: 0.085\n",
      "[86, 360] loss: 0.085\n",
      "Epoch: 86 -> Loss: 0.0616463795304\n",
      "Epoch: 86 -> Test Accuracy: 86.63\n",
      "[87, 60] loss: 0.087\n",
      "[87, 120] loss: 0.083\n",
      "[87, 180] loss: 0.081\n",
      "[87, 240] loss: 0.087\n",
      "[87, 300] loss: 0.087\n",
      "[87, 360] loss: 0.083\n",
      "Epoch: 87 -> Loss: 0.0768335238099\n",
      "Epoch: 87 -> Test Accuracy: 86.81\n",
      "[88, 60] loss: 0.081\n",
      "[88, 120] loss: 0.079\n",
      "[88, 180] loss: 0.081\n",
      "[88, 240] loss: 0.080\n",
      "[88, 300] loss: 0.083\n",
      "[88, 360] loss: 0.083\n",
      "Epoch: 88 -> Loss: 0.101788140833\n",
      "Epoch: 88 -> Test Accuracy: 86.61\n",
      "[89, 60] loss: 0.083\n",
      "[89, 120] loss: 0.082\n",
      "[89, 180] loss: 0.085\n",
      "[89, 240] loss: 0.082\n",
      "[89, 300] loss: 0.080\n",
      "[89, 360] loss: 0.083\n",
      "Epoch: 89 -> Loss: 0.0952443405986\n",
      "Epoch: 89 -> Test Accuracy: 86.84\n",
      "[90, 60] loss: 0.084\n",
      "[90, 120] loss: 0.081\n",
      "[90, 180] loss: 0.080\n",
      "[90, 240] loss: 0.082\n",
      "[90, 300] loss: 0.083\n",
      "[90, 360] loss: 0.082\n",
      "Epoch: 90 -> Loss: 0.124131537974\n",
      "Epoch: 90 -> Test Accuracy: 86.78\n",
      "[91, 60] loss: 0.083\n",
      "[91, 120] loss: 0.080\n",
      "[91, 180] loss: 0.083\n",
      "[91, 240] loss: 0.082\n",
      "[91, 300] loss: 0.080\n",
      "[91, 360] loss: 0.081\n",
      "Epoch: 91 -> Loss: 0.105993390083\n",
      "Epoch: 91 -> Test Accuracy: 86.83\n",
      "[92, 60] loss: 0.082\n",
      "[92, 120] loss: 0.080\n",
      "[92, 180] loss: 0.079\n",
      "[92, 240] loss: 0.079\n",
      "[92, 300] loss: 0.081\n",
      "[92, 360] loss: 0.081\n",
      "Epoch: 92 -> Loss: 0.0783789530396\n",
      "Epoch: 92 -> Test Accuracy: 86.65\n",
      "[93, 60] loss: 0.084\n",
      "[93, 120] loss: 0.077\n",
      "[93, 180] loss: 0.081\n",
      "[93, 240] loss: 0.081\n",
      "[93, 300] loss: 0.083\n",
      "[93, 360] loss: 0.082\n",
      "Epoch: 93 -> Loss: 0.118588708341\n",
      "Epoch: 93 -> Test Accuracy: 86.72\n",
      "[94, 60] loss: 0.081\n",
      "[94, 120] loss: 0.081\n",
      "[94, 180] loss: 0.081\n",
      "[94, 240] loss: 0.079\n",
      "[94, 300] loss: 0.078\n",
      "[94, 360] loss: 0.084\n",
      "Epoch: 94 -> Loss: 0.0478985905647\n",
      "Epoch: 94 -> Test Accuracy: 86.62\n",
      "[95, 60] loss: 0.083\n",
      "[95, 120] loss: 0.077\n",
      "[95, 180] loss: 0.082\n",
      "[95, 240] loss: 0.081\n",
      "[95, 300] loss: 0.079\n",
      "[95, 360] loss: 0.076\n",
      "Epoch: 95 -> Loss: 0.135658308864\n",
      "Epoch: 95 -> Test Accuracy: 86.84\n",
      "[96, 60] loss: 0.076\n",
      "[96, 120] loss: 0.077\n",
      "[96, 180] loss: 0.080\n",
      "[96, 240] loss: 0.080\n",
      "[96, 300] loss: 0.081\n",
      "[96, 360] loss: 0.080\n",
      "Epoch: 96 -> Loss: 0.0865409225225\n",
      "Epoch: 96 -> Test Accuracy: 86.68\n",
      "[97, 60] loss: 0.083\n",
      "[97, 120] loss: 0.073\n",
      "[97, 180] loss: 0.079\n",
      "[97, 240] loss: 0.079\n",
      "[97, 300] loss: 0.083\n",
      "[97, 360] loss: 0.079\n",
      "Epoch: 97 -> Loss: 0.0713815540075\n",
      "Epoch: 97 -> Test Accuracy: 86.71\n",
      "[98, 60] loss: 0.076\n",
      "[98, 120] loss: 0.076\n",
      "[98, 180] loss: 0.076\n",
      "[98, 240] loss: 0.079\n",
      "[98, 300] loss: 0.082\n",
      "[98, 360] loss: 0.077\n",
      "Epoch: 98 -> Loss: 0.081008002162\n",
      "Epoch: 98 -> Test Accuracy: 86.53\n",
      "[99, 60] loss: 0.075\n",
      "[99, 120] loss: 0.076\n",
      "[99, 180] loss: 0.078\n",
      "[99, 240] loss: 0.082\n",
      "[99, 300] loss: 0.074\n",
      "[99, 360] loss: 0.082\n",
      "Epoch: 99 -> Loss: 0.131637752056\n",
      "Epoch: 99 -> Test Accuracy: 86.56\n",
      "[100, 60] loss: 0.074\n",
      "[100, 120] loss: 0.076\n",
      "[100, 180] loss: 0.080\n",
      "[100, 240] loss: 0.076\n",
      "[100, 300] loss: 0.079\n",
      "[100, 360] loss: 0.079\n",
      "Epoch: 100 -> Loss: 0.0959434136748\n",
      "Epoch: 100 -> Test Accuracy: 86.46\n",
      "Finished Training\n",
      "[1, 60] loss: 0.952\n",
      "[1, 120] loss: 0.618\n",
      "[1, 180] loss: 0.578\n",
      "[1, 240] loss: 0.556\n",
      "[1, 300] loss: 0.520\n",
      "[1, 360] loss: 0.507\n",
      "Epoch: 1 -> Loss: 0.414169877768\n",
      "Epoch: 1 -> Test Accuracy: 80.21\n",
      "[2, 60] loss: 0.449\n",
      "[2, 120] loss: 0.447\n",
      "[2, 180] loss: 0.433\n",
      "[2, 240] loss: 0.449\n",
      "[2, 300] loss: 0.440\n",
      "[2, 360] loss: 0.427\n",
      "Epoch: 2 -> Loss: 0.501649320126\n",
      "Epoch: 2 -> Test Accuracy: 82.71\n",
      "[3, 60] loss: 0.396\n",
      "[3, 120] loss: 0.416\n",
      "[3, 180] loss: 0.391\n",
      "[3, 240] loss: 0.385\n",
      "[3, 300] loss: 0.389\n",
      "[3, 360] loss: 0.382\n",
      "Epoch: 3 -> Loss: 0.223978951573\n",
      "Epoch: 3 -> Test Accuracy: 83.14\n",
      "[4, 60] loss: 0.347\n",
      "[4, 120] loss: 0.370\n",
      "[4, 180] loss: 0.368\n",
      "[4, 240] loss: 0.382\n",
      "[4, 300] loss: 0.363\n",
      "[4, 360] loss: 0.378\n",
      "Epoch: 4 -> Loss: 0.310819029808\n",
      "Epoch: 4 -> Test Accuracy: 84.75\n",
      "[5, 60] loss: 0.334\n",
      "[5, 120] loss: 0.344\n",
      "[5, 180] loss: 0.346\n",
      "[5, 240] loss: 0.362\n",
      "[5, 300] loss: 0.360\n",
      "[5, 360] loss: 0.358\n",
      "Epoch: 5 -> Loss: 0.487574100494\n",
      "Epoch: 5 -> Test Accuracy: 84.1\n",
      "[6, 60] loss: 0.328\n",
      "[6, 120] loss: 0.325\n",
      "[6, 180] loss: 0.340\n",
      "[6, 240] loss: 0.345\n",
      "[6, 300] loss: 0.339\n",
      "[6, 360] loss: 0.333\n",
      "Epoch: 6 -> Loss: 0.376892387867\n",
      "Epoch: 6 -> Test Accuracy: 84.47\n",
      "[7, 60] loss: 0.334\n",
      "[7, 120] loss: 0.323\n",
      "[7, 180] loss: 0.319\n",
      "[7, 240] loss: 0.311\n",
      "[7, 300] loss: 0.333\n",
      "[7, 360] loss: 0.339\n",
      "Epoch: 7 -> Loss: 0.340448081493\n",
      "Epoch: 7 -> Test Accuracy: 85.05\n",
      "[8, 60] loss: 0.298\n",
      "[8, 120] loss: 0.307\n",
      "[8, 180] loss: 0.303\n",
      "[8, 240] loss: 0.310\n",
      "[8, 300] loss: 0.323\n",
      "[8, 360] loss: 0.329\n",
      "Epoch: 8 -> Loss: 0.277217298746\n",
      "Epoch: 8 -> Test Accuracy: 84.33\n",
      "[9, 60] loss: 0.303\n",
      "[9, 120] loss: 0.295\n",
      "[9, 180] loss: 0.299\n",
      "[9, 240] loss: 0.300\n",
      "[9, 300] loss: 0.327\n",
      "[9, 360] loss: 0.322\n",
      "Epoch: 9 -> Loss: 0.44471129775\n",
      "Epoch: 9 -> Test Accuracy: 84.83\n",
      "[10, 60] loss: 0.279\n",
      "[10, 120] loss: 0.298\n",
      "[10, 180] loss: 0.288\n",
      "[10, 240] loss: 0.321\n",
      "[10, 300] loss: 0.294\n",
      "[10, 360] loss: 0.316\n",
      "Epoch: 10 -> Loss: 0.330905735493\n",
      "Epoch: 10 -> Test Accuracy: 84.27\n",
      "[11, 60] loss: 0.262\n",
      "[11, 120] loss: 0.293\n",
      "[11, 180] loss: 0.300\n",
      "[11, 240] loss: 0.308\n",
      "[11, 300] loss: 0.305\n",
      "[11, 360] loss: 0.330\n",
      "Epoch: 11 -> Loss: 0.310136109591\n",
      "Epoch: 11 -> Test Accuracy: 85.14\n",
      "[12, 60] loss: 0.263\n",
      "[12, 120] loss: 0.285\n",
      "[12, 180] loss: 0.271\n",
      "[12, 240] loss: 0.290\n",
      "[12, 300] loss: 0.302\n",
      "[12, 360] loss: 0.318\n",
      "Epoch: 12 -> Loss: 0.238249272108\n",
      "Epoch: 12 -> Test Accuracy: 84.05\n",
      "[13, 60] loss: 0.260\n",
      "[13, 120] loss: 0.275\n",
      "[13, 180] loss: 0.286\n",
      "[13, 240] loss: 0.300\n",
      "[13, 300] loss: 0.301\n",
      "[13, 360] loss: 0.312\n",
      "Epoch: 13 -> Loss: 0.432520806789\n",
      "Epoch: 13 -> Test Accuracy: 85.28\n",
      "[14, 60] loss: 0.262\n",
      "[14, 120] loss: 0.266\n",
      "[14, 180] loss: 0.291\n",
      "[14, 240] loss: 0.301\n",
      "[14, 300] loss: 0.288\n",
      "[14, 360] loss: 0.302\n",
      "Epoch: 14 -> Loss: 0.246303036809\n",
      "Epoch: 14 -> Test Accuracy: 84.92\n",
      "[15, 60] loss: 0.267\n",
      "[15, 120] loss: 0.261\n",
      "[15, 180] loss: 0.272\n",
      "[15, 240] loss: 0.287\n",
      "[15, 300] loss: 0.291\n",
      "[15, 360] loss: 0.292\n",
      "Epoch: 15 -> Loss: 0.344028949738\n",
      "Epoch: 15 -> Test Accuracy: 84.75\n",
      "[16, 60] loss: 0.259\n",
      "[16, 120] loss: 0.276\n",
      "[16, 180] loss: 0.285\n",
      "[16, 240] loss: 0.289\n",
      "[16, 300] loss: 0.285\n",
      "[16, 360] loss: 0.290\n",
      "Epoch: 16 -> Loss: 0.249055549502\n",
      "Epoch: 16 -> Test Accuracy: 85.02\n",
      "[17, 60] loss: 0.252\n",
      "[17, 120] loss: 0.273\n",
      "[17, 180] loss: 0.290\n",
      "[17, 240] loss: 0.289\n",
      "[17, 300] loss: 0.277\n",
      "[17, 360] loss: 0.293\n",
      "Epoch: 17 -> Loss: 0.198322817683\n",
      "Epoch: 17 -> Test Accuracy: 85.17\n",
      "[18, 60] loss: 0.259\n",
      "[18, 120] loss: 0.253\n",
      "[18, 180] loss: 0.273\n",
      "[18, 240] loss: 0.286\n",
      "[18, 300] loss: 0.280\n",
      "[18, 360] loss: 0.278\n",
      "Epoch: 18 -> Loss: 0.455472052097\n",
      "Epoch: 18 -> Test Accuracy: 84.96\n",
      "[19, 60] loss: 0.255\n",
      "[19, 120] loss: 0.261\n",
      "[19, 180] loss: 0.278\n",
      "[19, 240] loss: 0.279\n",
      "[19, 300] loss: 0.276\n",
      "[19, 360] loss: 0.273\n",
      "Epoch: 19 -> Loss: 0.265412330627\n",
      "Epoch: 19 -> Test Accuracy: 85.56\n",
      "[20, 60] loss: 0.244\n",
      "[20, 120] loss: 0.262\n",
      "[20, 180] loss: 0.272\n",
      "[20, 240] loss: 0.270\n",
      "[20, 300] loss: 0.272\n",
      "[20, 360] loss: 0.284\n",
      "Epoch: 20 -> Loss: 0.192430332303\n",
      "Epoch: 20 -> Test Accuracy: 85.6\n",
      "[21, 60] loss: 0.252\n",
      "[21, 120] loss: 0.254\n",
      "[21, 180] loss: 0.247\n",
      "[21, 240] loss: 0.285\n",
      "[21, 300] loss: 0.268\n",
      "[21, 360] loss: 0.288\n",
      "Epoch: 21 -> Loss: 0.273574054241\n",
      "Epoch: 21 -> Test Accuracy: 85.06\n",
      "[22, 60] loss: 0.235\n",
      "[22, 120] loss: 0.255\n",
      "[22, 180] loss: 0.277\n",
      "[22, 240] loss: 0.291\n",
      "[22, 300] loss: 0.268\n",
      "[22, 360] loss: 0.297\n",
      "Epoch: 22 -> Loss: 0.343318492174\n",
      "Epoch: 22 -> Test Accuracy: 85.44\n",
      "[23, 60] loss: 0.249\n",
      "[23, 120] loss: 0.260\n",
      "[23, 180] loss: 0.265\n",
      "[23, 240] loss: 0.263\n",
      "[23, 300] loss: 0.283\n",
      "[23, 360] loss: 0.272\n",
      "Epoch: 23 -> Loss: 0.218416303396\n",
      "Epoch: 23 -> Test Accuracy: 85.15\n",
      "[24, 60] loss: 0.242\n",
      "[24, 120] loss: 0.258\n",
      "[24, 180] loss: 0.251\n",
      "[24, 240] loss: 0.271\n",
      "[24, 300] loss: 0.275\n",
      "[24, 360] loss: 0.284\n",
      "Epoch: 24 -> Loss: 0.359894812107\n",
      "Epoch: 24 -> Test Accuracy: 84.84\n",
      "[25, 60] loss: 0.243\n",
      "[25, 120] loss: 0.257\n",
      "[25, 180] loss: 0.272\n",
      "[25, 240] loss: 0.280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 300] loss: 0.273\n",
      "[25, 360] loss: 0.282\n",
      "Epoch: 25 -> Loss: 0.263931572437\n",
      "Epoch: 25 -> Test Accuracy: 85.1\n",
      "[26, 60] loss: 0.248\n",
      "[26, 120] loss: 0.249\n",
      "[26, 180] loss: 0.266\n",
      "[26, 240] loss: 0.265\n",
      "[26, 300] loss: 0.270\n",
      "[26, 360] loss: 0.291\n",
      "Epoch: 26 -> Loss: 0.366226911545\n",
      "Epoch: 26 -> Test Accuracy: 85.97\n",
      "[27, 60] loss: 0.252\n",
      "[27, 120] loss: 0.244\n",
      "[27, 180] loss: 0.259\n",
      "[27, 240] loss: 0.266\n",
      "[27, 300] loss: 0.287\n",
      "[27, 360] loss: 0.281\n",
      "Epoch: 27 -> Loss: 0.187180116773\n",
      "Epoch: 27 -> Test Accuracy: 85.74\n",
      "[28, 60] loss: 0.235\n",
      "[28, 120] loss: 0.262\n",
      "[28, 180] loss: 0.268\n",
      "[28, 240] loss: 0.270\n",
      "[28, 300] loss: 0.270\n",
      "[28, 360] loss: 0.262\n",
      "Epoch: 28 -> Loss: 0.313909828663\n",
      "Epoch: 28 -> Test Accuracy: 85.53\n",
      "[29, 60] loss: 0.247\n",
      "[29, 120] loss: 0.248\n",
      "[29, 180] loss: 0.256\n",
      "[29, 240] loss: 0.261\n",
      "[29, 300] loss: 0.268\n",
      "[29, 360] loss: 0.272\n",
      "Epoch: 29 -> Loss: 0.273372739553\n",
      "Epoch: 29 -> Test Accuracy: 85.14\n",
      "[30, 60] loss: 0.243\n",
      "[30, 120] loss: 0.238\n",
      "[30, 180] loss: 0.258\n",
      "[30, 240] loss: 0.263\n",
      "[30, 300] loss: 0.272\n",
      "[30, 360] loss: 0.267\n",
      "Epoch: 30 -> Loss: 0.196704894304\n",
      "Epoch: 30 -> Test Accuracy: 85.03\n",
      "[31, 60] loss: 0.236\n",
      "[31, 120] loss: 0.240\n",
      "[31, 180] loss: 0.258\n",
      "[31, 240] loss: 0.256\n",
      "[31, 300] loss: 0.285\n",
      "[31, 360] loss: 0.277\n",
      "Epoch: 31 -> Loss: 0.268266499043\n",
      "Epoch: 31 -> Test Accuracy: 85.15\n",
      "[32, 60] loss: 0.254\n",
      "[32, 120] loss: 0.254\n",
      "[32, 180] loss: 0.268\n",
      "[32, 240] loss: 0.262\n",
      "[32, 300] loss: 0.279\n",
      "[32, 360] loss: 0.273\n",
      "Epoch: 32 -> Loss: 0.215573504567\n",
      "Epoch: 32 -> Test Accuracy: 84.62\n",
      "[33, 60] loss: 0.234\n",
      "[33, 120] loss: 0.237\n",
      "[33, 180] loss: 0.271\n",
      "[33, 240] loss: 0.268\n",
      "[33, 300] loss: 0.270\n",
      "[33, 360] loss: 0.273\n",
      "Epoch: 33 -> Loss: 0.571713209152\n",
      "Epoch: 33 -> Test Accuracy: 86.0\n",
      "[34, 60] loss: 0.238\n",
      "[34, 120] loss: 0.254\n",
      "[34, 180] loss: 0.253\n",
      "[34, 240] loss: 0.275\n",
      "[34, 300] loss: 0.263\n",
      "[34, 360] loss: 0.263\n",
      "Epoch: 34 -> Loss: 0.400410592556\n",
      "Epoch: 34 -> Test Accuracy: 84.63\n",
      "[35, 60] loss: 0.252\n",
      "[35, 120] loss: 0.226\n",
      "[35, 180] loss: 0.253\n",
      "[35, 240] loss: 0.268\n",
      "[35, 300] loss: 0.277\n",
      "[35, 360] loss: 0.267\n",
      "Epoch: 35 -> Loss: 0.415419578552\n",
      "Epoch: 35 -> Test Accuracy: 85.96\n",
      "[36, 60] loss: 0.193\n",
      "[36, 120] loss: 0.181\n",
      "[36, 180] loss: 0.164\n",
      "[36, 240] loss: 0.169\n",
      "[36, 300] loss: 0.169\n",
      "[36, 360] loss: 0.165\n",
      "Epoch: 36 -> Loss: 0.198602944613\n",
      "Epoch: 36 -> Test Accuracy: 88.2\n",
      "[37, 60] loss: 0.137\n",
      "[37, 120] loss: 0.145\n",
      "[37, 180] loss: 0.140\n",
      "[37, 240] loss: 0.145\n",
      "[37, 300] loss: 0.151\n",
      "[37, 360] loss: 0.137\n",
      "Epoch: 37 -> Loss: 0.145421355963\n",
      "Epoch: 37 -> Test Accuracy: 88.28\n",
      "[38, 60] loss: 0.122\n",
      "[38, 120] loss: 0.125\n",
      "[38, 180] loss: 0.129\n",
      "[38, 240] loss: 0.122\n",
      "[38, 300] loss: 0.122\n",
      "[38, 360] loss: 0.138\n",
      "Epoch: 38 -> Loss: 0.129230648279\n",
      "Epoch: 38 -> Test Accuracy: 88.22\n",
      "[39, 60] loss: 0.116\n",
      "[39, 120] loss: 0.118\n",
      "[39, 180] loss: 0.118\n",
      "[39, 240] loss: 0.119\n",
      "[39, 300] loss: 0.124\n",
      "[39, 360] loss: 0.125\n",
      "Epoch: 39 -> Loss: 0.137932151556\n",
      "Epoch: 39 -> Test Accuracy: 87.99\n",
      "[40, 60] loss: 0.110\n",
      "[40, 120] loss: 0.110\n",
      "[40, 180] loss: 0.110\n",
      "[40, 240] loss: 0.119\n",
      "[40, 300] loss: 0.119\n",
      "[40, 360] loss: 0.123\n",
      "Epoch: 40 -> Loss: 0.0638501867652\n",
      "Epoch: 40 -> Test Accuracy: 88.14\n",
      "[41, 60] loss: 0.100\n",
      "[41, 120] loss: 0.103\n",
      "[41, 180] loss: 0.115\n",
      "[41, 240] loss: 0.107\n",
      "[41, 300] loss: 0.115\n",
      "[41, 360] loss: 0.113\n",
      "Epoch: 41 -> Loss: 0.105708956718\n",
      "Epoch: 41 -> Test Accuracy: 87.63\n",
      "[42, 60] loss: 0.101\n",
      "[42, 120] loss: 0.108\n",
      "[42, 180] loss: 0.101\n",
      "[42, 240] loss: 0.116\n",
      "[42, 300] loss: 0.110\n",
      "[42, 360] loss: 0.115\n",
      "Epoch: 42 -> Loss: 0.0736425071955\n",
      "Epoch: 42 -> Test Accuracy: 87.42\n",
      "[43, 60] loss: 0.094\n",
      "[43, 120] loss: 0.099\n",
      "[43, 180] loss: 0.102\n",
      "[43, 240] loss: 0.112\n",
      "[43, 300] loss: 0.108\n",
      "[43, 360] loss: 0.116\n",
      "Epoch: 43 -> Loss: 0.120530486107\n",
      "Epoch: 43 -> Test Accuracy: 87.93\n",
      "[44, 60] loss: 0.094\n",
      "[44, 120] loss: 0.094\n",
      "[44, 180] loss: 0.100\n",
      "[44, 240] loss: 0.104\n",
      "[44, 300] loss: 0.113\n",
      "[44, 360] loss: 0.111\n",
      "Epoch: 44 -> Loss: 0.108045652509\n",
      "Epoch: 44 -> Test Accuracy: 87.8\n",
      "[45, 60] loss: 0.097\n",
      "[45, 120] loss: 0.100\n",
      "[45, 180] loss: 0.100\n",
      "[45, 240] loss: 0.111\n",
      "[45, 300] loss: 0.109\n",
      "[45, 360] loss: 0.116\n",
      "Epoch: 45 -> Loss: 0.151575952768\n",
      "Epoch: 45 -> Test Accuracy: 88.05\n",
      "[46, 60] loss: 0.096\n",
      "[46, 120] loss: 0.101\n",
      "[46, 180] loss: 0.098\n",
      "[46, 240] loss: 0.105\n",
      "[46, 300] loss: 0.112\n",
      "[46, 360] loss: 0.123\n",
      "Epoch: 46 -> Loss: 0.170598953962\n",
      "Epoch: 46 -> Test Accuracy: 87.38\n",
      "[47, 60] loss: 0.093\n",
      "[47, 120] loss: 0.101\n",
      "[47, 180] loss: 0.101\n",
      "[47, 240] loss: 0.106\n",
      "[47, 300] loss: 0.101\n",
      "[47, 360] loss: 0.113\n",
      "Epoch: 47 -> Loss: 0.163756608963\n",
      "Epoch: 47 -> Test Accuracy: 87.75\n",
      "[48, 60] loss: 0.097\n",
      "[48, 120] loss: 0.095\n",
      "[48, 180] loss: 0.100\n",
      "[48, 240] loss: 0.108\n",
      "[48, 300] loss: 0.110\n",
      "[48, 360] loss: 0.118\n",
      "Epoch: 48 -> Loss: 0.0852174311876\n",
      "Epoch: 48 -> Test Accuracy: 87.6\n",
      "[49, 60] loss: 0.094\n",
      "[49, 120] loss: 0.095\n",
      "[49, 180] loss: 0.100\n",
      "[49, 240] loss: 0.109\n",
      "[49, 300] loss: 0.105\n",
      "[49, 360] loss: 0.119\n",
      "Epoch: 49 -> Loss: 0.157170295715\n",
      "Epoch: 49 -> Test Accuracy: 87.57\n",
      "[50, 60] loss: 0.095\n",
      "[50, 120] loss: 0.100\n",
      "[50, 180] loss: 0.113\n",
      "[50, 240] loss: 0.112\n",
      "[50, 300] loss: 0.102\n",
      "[50, 360] loss: 0.106\n",
      "Epoch: 50 -> Loss: 0.123704351485\n",
      "Epoch: 50 -> Test Accuracy: 87.98\n",
      "[51, 60] loss: 0.092\n",
      "[51, 120] loss: 0.099\n",
      "[51, 180] loss: 0.102\n",
      "[51, 240] loss: 0.105\n",
      "[51, 300] loss: 0.109\n",
      "[51, 360] loss: 0.110\n",
      "Epoch: 51 -> Loss: 0.147049501538\n",
      "Epoch: 51 -> Test Accuracy: 87.25\n",
      "[52, 60] loss: 0.100\n",
      "[52, 120] loss: 0.100\n",
      "[52, 180] loss: 0.105\n",
      "[52, 240] loss: 0.111\n",
      "[52, 300] loss: 0.114\n",
      "[52, 360] loss: 0.111\n",
      "Epoch: 52 -> Loss: 0.0596989095211\n",
      "Epoch: 52 -> Test Accuracy: 87.18\n",
      "[53, 60] loss: 0.093\n",
      "[53, 120] loss: 0.093\n",
      "[53, 180] loss: 0.108\n",
      "[53, 240] loss: 0.110\n",
      "[53, 300] loss: 0.112\n",
      "[53, 360] loss: 0.111\n",
      "Epoch: 53 -> Loss: 0.0947528705001\n",
      "Epoch: 53 -> Test Accuracy: 86.92\n",
      "[54, 60] loss: 0.092\n",
      "[54, 120] loss: 0.099\n",
      "[54, 180] loss: 0.106\n",
      "[54, 240] loss: 0.107\n",
      "[54, 300] loss: 0.120\n",
      "[54, 360] loss: 0.120\n",
      "Epoch: 54 -> Loss: 0.0958858504891\n",
      "Epoch: 54 -> Test Accuracy: 86.99\n",
      "[55, 60] loss: 0.101\n",
      "[55, 120] loss: 0.097\n",
      "[55, 180] loss: 0.095\n",
      "[55, 240] loss: 0.108\n",
      "[55, 300] loss: 0.111\n",
      "[55, 360] loss: 0.114\n",
      "Epoch: 55 -> Loss: 0.106507226825\n",
      "Epoch: 55 -> Test Accuracy: 87.16\n",
      "[56, 60] loss: 0.095\n",
      "[56, 120] loss: 0.093\n",
      "[56, 180] loss: 0.112\n",
      "[56, 240] loss: 0.107\n",
      "[56, 300] loss: 0.112\n",
      "[56, 360] loss: 0.114\n",
      "Epoch: 56 -> Loss: 0.212266534567\n",
      "Epoch: 56 -> Test Accuracy: 87.17\n",
      "[57, 60] loss: 0.098\n",
      "[57, 120] loss: 0.103\n",
      "[57, 180] loss: 0.096\n",
      "[57, 240] loss: 0.099\n",
      "[57, 300] loss: 0.107\n",
      "[57, 360] loss: 0.107\n",
      "Epoch: 57 -> Loss: 0.121086105704\n",
      "Epoch: 57 -> Test Accuracy: 86.86\n",
      "[58, 60] loss: 0.098\n",
      "[58, 120] loss: 0.096\n",
      "[58, 180] loss: 0.106\n",
      "[58, 240] loss: 0.101\n",
      "[58, 300] loss: 0.110\n",
      "[58, 360] loss: 0.118\n",
      "Epoch: 58 -> Loss: 0.0587357357144\n",
      "Epoch: 58 -> Test Accuracy: 87.66\n",
      "[59, 60] loss: 0.092\n",
      "[59, 120] loss: 0.100\n",
      "[59, 180] loss: 0.101\n",
      "[59, 240] loss: 0.103\n",
      "[59, 300] loss: 0.116\n",
      "[59, 360] loss: 0.112\n",
      "Epoch: 59 -> Loss: 0.198756664991\n",
      "Epoch: 59 -> Test Accuracy: 87.2\n",
      "[60, 60] loss: 0.103\n",
      "[60, 120] loss: 0.098\n",
      "[60, 180] loss: 0.108\n",
      "[60, 240] loss: 0.110\n",
      "[60, 300] loss: 0.110\n",
      "[60, 360] loss: 0.112\n",
      "Epoch: 60 -> Loss: 0.0938141569495\n",
      "Epoch: 60 -> Test Accuracy: 87.34\n",
      "[61, 60] loss: 0.096\n",
      "[61, 120] loss: 0.097\n",
      "[61, 180] loss: 0.099\n",
      "[61, 240] loss: 0.098\n",
      "[61, 300] loss: 0.114\n",
      "[61, 360] loss: 0.111\n",
      "Epoch: 61 -> Loss: 0.1863887012\n",
      "Epoch: 61 -> Test Accuracy: 87.68\n",
      "[62, 60] loss: 0.101\n",
      "[62, 120] loss: 0.093\n",
      "[62, 180] loss: 0.109\n",
      "[62, 240] loss: 0.102\n",
      "[62, 300] loss: 0.105\n",
      "[62, 360] loss: 0.117\n",
      "Epoch: 62 -> Loss: 0.207286834717\n",
      "Epoch: 62 -> Test Accuracy: 86.84\n",
      "[63, 60] loss: 0.095\n",
      "[63, 120] loss: 0.095\n",
      "[63, 180] loss: 0.099\n",
      "[63, 240] loss: 0.101\n",
      "[63, 300] loss: 0.113\n",
      "[63, 360] loss: 0.110\n",
      "Epoch: 63 -> Loss: 0.158169820905\n",
      "Epoch: 63 -> Test Accuracy: 86.96\n",
      "[64, 60] loss: 0.094\n",
      "[64, 120] loss: 0.095\n",
      "[64, 180] loss: 0.098\n",
      "[64, 240] loss: 0.105\n",
      "[64, 300] loss: 0.115\n",
      "[64, 360] loss: 0.106\n",
      "Epoch: 64 -> Loss: 0.0998534411192\n",
      "Epoch: 64 -> Test Accuracy: 87.33\n",
      "[65, 60] loss: 0.098\n",
      "[65, 120] loss: 0.098\n",
      "[65, 180] loss: 0.097\n",
      "[65, 240] loss: 0.105\n",
      "[65, 300] loss: 0.101\n",
      "[65, 360] loss: 0.112\n",
      "Epoch: 65 -> Loss: 0.106932625175\n",
      "Epoch: 65 -> Test Accuracy: 87.32\n",
      "[66, 60] loss: 0.088\n",
      "[66, 120] loss: 0.099\n",
      "[66, 180] loss: 0.095\n",
      "[66, 240] loss: 0.105\n",
      "[66, 300] loss: 0.104\n",
      "[66, 360] loss: 0.116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Loss: 0.0699073076248\n",
      "Epoch: 66 -> Test Accuracy: 86.86\n",
      "[67, 60] loss: 0.097\n",
      "[67, 120] loss: 0.095\n",
      "[67, 180] loss: 0.098\n",
      "[67, 240] loss: 0.102\n",
      "[67, 300] loss: 0.106\n",
      "[67, 360] loss: 0.109\n",
      "Epoch: 67 -> Loss: 0.157968074083\n",
      "Epoch: 67 -> Test Accuracy: 87.37\n",
      "[68, 60] loss: 0.085\n",
      "[68, 120] loss: 0.095\n",
      "[68, 180] loss: 0.105\n",
      "[68, 240] loss: 0.109\n",
      "[68, 300] loss: 0.115\n",
      "[68, 360] loss: 0.106\n",
      "Epoch: 68 -> Loss: 0.213068723679\n",
      "Epoch: 68 -> Test Accuracy: 87.11\n",
      "[69, 60] loss: 0.090\n",
      "[69, 120] loss: 0.096\n",
      "[69, 180] loss: 0.097\n",
      "[69, 240] loss: 0.097\n",
      "[69, 300] loss: 0.111\n",
      "[69, 360] loss: 0.116\n",
      "Epoch: 69 -> Loss: 0.160988405347\n",
      "Epoch: 69 -> Test Accuracy: 87.02\n",
      "[70, 60] loss: 0.106\n",
      "[70, 120] loss: 0.093\n",
      "[70, 180] loss: 0.099\n",
      "[70, 240] loss: 0.110\n",
      "[70, 300] loss: 0.106\n",
      "[70, 360] loss: 0.107\n",
      "Epoch: 70 -> Loss: 0.0538219437003\n",
      "Epoch: 70 -> Test Accuracy: 87.59\n",
      "[71, 60] loss: 0.076\n",
      "[71, 120] loss: 0.070\n",
      "[71, 180] loss: 0.061\n",
      "[71, 240] loss: 0.060\n",
      "[71, 300] loss: 0.057\n",
      "[71, 360] loss: 0.059\n",
      "Epoch: 71 -> Loss: 0.0799103453755\n",
      "Epoch: 71 -> Test Accuracy: 88.89\n",
      "[72, 60] loss: 0.049\n",
      "[72, 120] loss: 0.053\n",
      "[72, 180] loss: 0.052\n",
      "[72, 240] loss: 0.049\n",
      "[72, 300] loss: 0.051\n",
      "[72, 360] loss: 0.053\n",
      "Epoch: 72 -> Loss: 0.0502574816346\n",
      "Epoch: 72 -> Test Accuracy: 88.74\n",
      "[73, 60] loss: 0.047\n",
      "[73, 120] loss: 0.046\n",
      "[73, 180] loss: 0.047\n",
      "[73, 240] loss: 0.048\n",
      "[73, 300] loss: 0.044\n",
      "[73, 360] loss: 0.046\n",
      "Epoch: 73 -> Loss: 0.0658984556794\n",
      "Epoch: 73 -> Test Accuracy: 88.6\n",
      "[74, 60] loss: 0.046\n",
      "[74, 120] loss: 0.043\n",
      "[74, 180] loss: 0.040\n",
      "[74, 240] loss: 0.043\n",
      "[74, 300] loss: 0.041\n",
      "[74, 360] loss: 0.044\n",
      "Epoch: 74 -> Loss: 0.0377081260085\n",
      "Epoch: 74 -> Test Accuracy: 88.59\n",
      "[75, 60] loss: 0.037\n",
      "[75, 120] loss: 0.044\n",
      "[75, 180] loss: 0.042\n",
      "[75, 240] loss: 0.041\n",
      "[75, 300] loss: 0.039\n",
      "[75, 360] loss: 0.041\n",
      "Epoch: 75 -> Loss: 0.029107671231\n",
      "Epoch: 75 -> Test Accuracy: 88.6\n",
      "[76, 60] loss: 0.038\n",
      "[76, 120] loss: 0.036\n",
      "[76, 180] loss: 0.039\n",
      "[76, 240] loss: 0.041\n",
      "[76, 300] loss: 0.039\n",
      "[76, 360] loss: 0.041\n",
      "Epoch: 76 -> Loss: 0.0521966218948\n",
      "Epoch: 76 -> Test Accuracy: 88.94\n",
      "[77, 60] loss: 0.038\n",
      "[77, 120] loss: 0.035\n",
      "[77, 180] loss: 0.037\n",
      "[77, 240] loss: 0.040\n",
      "[77, 300] loss: 0.035\n",
      "[77, 360] loss: 0.037\n",
      "Epoch: 77 -> Loss: 0.0934542566538\n",
      "Epoch: 77 -> Test Accuracy: 88.81\n",
      "[78, 60] loss: 0.037\n",
      "[78, 120] loss: 0.036\n",
      "[78, 180] loss: 0.036\n",
      "[78, 240] loss: 0.039\n",
      "[78, 300] loss: 0.036\n",
      "[78, 360] loss: 0.040\n",
      "Epoch: 78 -> Loss: 0.0826446935534\n",
      "Epoch: 78 -> Test Accuracy: 88.72\n",
      "[79, 60] loss: 0.034\n",
      "[79, 120] loss: 0.038\n",
      "[79, 180] loss: 0.035\n",
      "[79, 240] loss: 0.037\n",
      "[79, 300] loss: 0.036\n",
      "[79, 360] loss: 0.036\n",
      "Epoch: 79 -> Loss: 0.0416893064976\n",
      "Epoch: 79 -> Test Accuracy: 88.82\n",
      "[80, 60] loss: 0.035\n",
      "[80, 120] loss: 0.033\n",
      "[80, 180] loss: 0.034\n",
      "[80, 240] loss: 0.031\n",
      "[80, 300] loss: 0.032\n",
      "[80, 360] loss: 0.033\n",
      "Epoch: 80 -> Loss: 0.0288722570986\n",
      "Epoch: 80 -> Test Accuracy: 88.66\n",
      "[81, 60] loss: 0.033\n",
      "[81, 120] loss: 0.032\n",
      "[81, 180] loss: 0.036\n",
      "[81, 240] loss: 0.031\n",
      "[81, 300] loss: 0.035\n",
      "[81, 360] loss: 0.036\n",
      "Epoch: 81 -> Loss: 0.0369480773807\n",
      "Epoch: 81 -> Test Accuracy: 88.65\n",
      "[82, 60] loss: 0.031\n",
      "[82, 120] loss: 0.032\n",
      "[82, 180] loss: 0.033\n",
      "[82, 240] loss: 0.034\n",
      "[82, 300] loss: 0.035\n",
      "[82, 360] loss: 0.035\n",
      "Epoch: 82 -> Loss: 0.0687175914645\n",
      "Epoch: 82 -> Test Accuracy: 88.61\n",
      "[83, 60] loss: 0.030\n",
      "[83, 120] loss: 0.034\n",
      "[83, 180] loss: 0.031\n",
      "[83, 240] loss: 0.033\n",
      "[83, 300] loss: 0.033\n",
      "[83, 360] loss: 0.034\n",
      "Epoch: 83 -> Loss: 0.0150626059622\n",
      "Epoch: 83 -> Test Accuracy: 88.67\n",
      "[84, 60] loss: 0.029\n",
      "[84, 120] loss: 0.030\n",
      "[84, 180] loss: 0.033\n",
      "[84, 240] loss: 0.032\n",
      "[84, 300] loss: 0.031\n",
      "[84, 360] loss: 0.030\n",
      "Epoch: 84 -> Loss: 0.0690096765757\n",
      "Epoch: 84 -> Test Accuracy: 88.61\n",
      "[85, 60] loss: 0.029\n",
      "[85, 120] loss: 0.028\n",
      "[85, 180] loss: 0.031\n",
      "[85, 240] loss: 0.032\n",
      "[85, 300] loss: 0.034\n",
      "[85, 360] loss: 0.029\n",
      "Epoch: 85 -> Loss: 0.033593416214\n",
      "Epoch: 85 -> Test Accuracy: 88.62\n",
      "[86, 60] loss: 0.029\n",
      "[86, 120] loss: 0.027\n",
      "[86, 180] loss: 0.029\n",
      "[86, 240] loss: 0.027\n",
      "[86, 300] loss: 0.029\n",
      "[86, 360] loss: 0.028\n",
      "Epoch: 86 -> Loss: 0.0400550290942\n",
      "Epoch: 86 -> Test Accuracy: 88.69\n",
      "[87, 60] loss: 0.027\n",
      "[87, 120] loss: 0.027\n",
      "[87, 180] loss: 0.028\n",
      "[87, 240] loss: 0.029\n",
      "[87, 300] loss: 0.029\n",
      "[87, 360] loss: 0.028\n",
      "Epoch: 87 -> Loss: 0.0245758350939\n",
      "Epoch: 87 -> Test Accuracy: 88.72\n",
      "[88, 60] loss: 0.024\n",
      "[88, 120] loss: 0.027\n",
      "[88, 180] loss: 0.025\n",
      "[88, 240] loss: 0.028\n",
      "[88, 300] loss: 0.027\n",
      "[88, 360] loss: 0.028\n",
      "Epoch: 88 -> Loss: 0.0262403488159\n",
      "Epoch: 88 -> Test Accuracy: 88.65\n",
      "[89, 60] loss: 0.026\n",
      "[89, 120] loss: 0.028\n",
      "[89, 180] loss: 0.027\n",
      "[89, 240] loss: 0.028\n",
      "[89, 300] loss: 0.027\n",
      "[89, 360] loss: 0.028\n",
      "Epoch: 89 -> Loss: 0.0369921699166\n",
      "Epoch: 89 -> Test Accuracy: 88.66\n",
      "[90, 60] loss: 0.026\n",
      "[90, 120] loss: 0.024\n",
      "[90, 180] loss: 0.028\n",
      "[90, 240] loss: 0.026\n",
      "[90, 300] loss: 0.027\n",
      "[90, 360] loss: 0.026\n",
      "Epoch: 90 -> Loss: 0.0185502283275\n",
      "Epoch: 90 -> Test Accuracy: 88.64\n",
      "[91, 60] loss: 0.025\n",
      "[91, 120] loss: 0.025\n",
      "[91, 180] loss: 0.029\n",
      "[91, 240] loss: 0.026\n",
      "[91, 300] loss: 0.025\n",
      "[91, 360] loss: 0.025\n",
      "Epoch: 91 -> Loss: 0.0199996046722\n",
      "Epoch: 91 -> Test Accuracy: 88.61\n",
      "[92, 60] loss: 0.026\n",
      "[92, 120] loss: 0.025\n",
      "[92, 180] loss: 0.027\n",
      "[92, 240] loss: 0.025\n",
      "[92, 300] loss: 0.024\n",
      "[92, 360] loss: 0.026\n",
      "Epoch: 92 -> Loss: 0.0249551273882\n",
      "Epoch: 92 -> Test Accuracy: 88.77\n",
      "[93, 60] loss: 0.023\n",
      "[93, 120] loss: 0.024\n",
      "[93, 180] loss: 0.027\n",
      "[93, 240] loss: 0.025\n",
      "[93, 300] loss: 0.025\n",
      "[93, 360] loss: 0.025\n",
      "Epoch: 93 -> Loss: 0.014183094725\n",
      "Epoch: 93 -> Test Accuracy: 88.79\n",
      "[94, 60] loss: 0.027\n",
      "[94, 120] loss: 0.026\n",
      "[94, 180] loss: 0.026\n",
      "[94, 240] loss: 0.026\n",
      "[94, 300] loss: 0.025\n",
      "[94, 360] loss: 0.026\n",
      "Epoch: 94 -> Loss: 0.0361319817603\n",
      "Epoch: 94 -> Test Accuracy: 88.67\n",
      "[95, 60] loss: 0.023\n",
      "[95, 120] loss: 0.026\n",
      "[95, 180] loss: 0.024\n",
      "[95, 240] loss: 0.024\n",
      "[95, 300] loss: 0.026\n",
      "[95, 360] loss: 0.027\n",
      "Epoch: 95 -> Loss: 0.0252877231687\n",
      "Epoch: 95 -> Test Accuracy: 88.88\n",
      "[96, 60] loss: 0.023\n",
      "[96, 120] loss: 0.024\n",
      "[96, 180] loss: 0.027\n",
      "[96, 240] loss: 0.024\n",
      "[96, 300] loss: 0.024\n",
      "[96, 360] loss: 0.025\n",
      "Epoch: 96 -> Loss: 0.0154384318739\n",
      "Epoch: 96 -> Test Accuracy: 88.8\n",
      "[97, 60] loss: 0.028\n",
      "[97, 120] loss: 0.026\n",
      "[97, 180] loss: 0.025\n",
      "[97, 240] loss: 0.027\n",
      "[97, 300] loss: 0.025\n",
      "[97, 360] loss: 0.022\n",
      "Epoch: 97 -> Loss: 0.0261052660644\n",
      "Epoch: 97 -> Test Accuracy: 88.82\n",
      "[98, 60] loss: 0.026\n",
      "[98, 120] loss: 0.024\n",
      "[98, 180] loss: 0.027\n",
      "[98, 240] loss: 0.025\n",
      "[98, 300] loss: 0.023\n",
      "[98, 360] loss: 0.025\n",
      "Epoch: 98 -> Loss: 0.0463048517704\n",
      "Epoch: 98 -> Test Accuracy: 88.93\n",
      "[99, 60] loss: 0.023\n",
      "[99, 120] loss: 0.025\n",
      "[99, 180] loss: 0.025\n",
      "[99, 240] loss: 0.024\n",
      "[99, 300] loss: 0.026\n",
      "[99, 360] loss: 0.025\n",
      "Epoch: 99 -> Loss: 0.020349252969\n",
      "Epoch: 99 -> Test Accuracy: 88.78\n",
      "[100, 60] loss: 0.024\n",
      "[100, 120] loss: 0.026\n",
      "[100, 180] loss: 0.026\n",
      "[100, 240] loss: 0.024\n",
      "[100, 300] loss: 0.026\n",
      "[100, 360] loss: 0.025\n",
      "Epoch: 100 -> Loss: 0.0107081532478\n",
      "Epoch: 100 -> Test Accuracy: 88.82\n",
      "Finished Training\n",
      "[1, 60] loss: 0.987\n",
      "[1, 120] loss: 0.703\n",
      "[1, 180] loss: 0.673\n",
      "[1, 240] loss: 0.646\n",
      "[1, 300] loss: 0.612\n",
      "[1, 360] loss: 0.613\n",
      "Epoch: 1 -> Loss: 0.633817315102\n",
      "Epoch: 1 -> Test Accuracy: 75.57\n",
      "[2, 60] loss: 0.582\n",
      "[2, 120] loss: 0.570\n",
      "[2, 180] loss: 0.561\n",
      "[2, 240] loss: 0.550\n",
      "[2, 300] loss: 0.548\n",
      "[2, 360] loss: 0.531\n",
      "Epoch: 2 -> Loss: 0.46426025033\n",
      "Epoch: 2 -> Test Accuracy: 77.53\n",
      "[3, 60] loss: 0.534\n",
      "[3, 120] loss: 0.522\n",
      "[3, 180] loss: 0.501\n",
      "[3, 240] loss: 0.528\n",
      "[3, 300] loss: 0.521\n",
      "[3, 360] loss: 0.529\n",
      "Epoch: 3 -> Loss: 0.594623982906\n",
      "Epoch: 3 -> Test Accuracy: 78.61\n",
      "[4, 60] loss: 0.488\n",
      "[4, 120] loss: 0.494\n",
      "[4, 180] loss: 0.514\n",
      "[4, 240] loss: 0.501\n",
      "[4, 300] loss: 0.507\n",
      "[4, 360] loss: 0.497\n",
      "Epoch: 4 -> Loss: 0.772827744484\n",
      "Epoch: 4 -> Test Accuracy: 78.53\n",
      "[5, 60] loss: 0.488\n",
      "[5, 120] loss: 0.482\n",
      "[5, 180] loss: 0.489\n",
      "[5, 240] loss: 0.496\n",
      "[5, 300] loss: 0.492\n",
      "[5, 360] loss: 0.503\n",
      "Epoch: 5 -> Loss: 0.372553288937\n",
      "Epoch: 5 -> Test Accuracy: 79.32\n",
      "[6, 60] loss: 0.479\n",
      "[6, 120] loss: 0.470\n",
      "[6, 180] loss: 0.486\n",
      "[6, 240] loss: 0.495\n",
      "[6, 300] loss: 0.481\n",
      "[6, 360] loss: 0.499\n",
      "Epoch: 6 -> Loss: 0.633567869663\n",
      "Epoch: 6 -> Test Accuracy: 79.47\n",
      "[7, 60] loss: 0.471\n",
      "[7, 120] loss: 0.478\n",
      "[7, 180] loss: 0.471\n",
      "[7, 240] loss: 0.474\n",
      "[7, 300] loss: 0.490\n",
      "[7, 360] loss: 0.471\n",
      "Epoch: 7 -> Loss: 0.702497661114\n",
      "Epoch: 7 -> Test Accuracy: 78.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 60] loss: 0.478\n",
      "[8, 120] loss: 0.470\n",
      "[8, 180] loss: 0.463\n",
      "[8, 240] loss: 0.469\n",
      "[8, 300] loss: 0.477\n",
      "[8, 360] loss: 0.478\n",
      "Epoch: 8 -> Loss: 0.551252484322\n",
      "Epoch: 8 -> Test Accuracy: 79.9\n",
      "[9, 60] loss: 0.447\n",
      "[9, 120] loss: 0.461\n",
      "[9, 180] loss: 0.458\n",
      "[9, 240] loss: 0.482\n",
      "[9, 300] loss: 0.466\n",
      "[9, 360] loss: 0.468\n",
      "Epoch: 9 -> Loss: 0.530222952366\n",
      "Epoch: 9 -> Test Accuracy: 80.81\n",
      "[10, 60] loss: 0.430\n",
      "[10, 120] loss: 0.462\n",
      "[10, 180] loss: 0.478\n",
      "[10, 240] loss: 0.466\n",
      "[10, 300] loss: 0.468\n",
      "[10, 360] loss: 0.456\n",
      "Epoch: 10 -> Loss: 0.244303017855\n",
      "Epoch: 10 -> Test Accuracy: 79.86\n",
      "[11, 60] loss: 0.442\n",
      "[11, 120] loss: 0.463\n",
      "[11, 180] loss: 0.460\n",
      "[11, 240] loss: 0.452\n",
      "[11, 300] loss: 0.453\n",
      "[11, 360] loss: 0.456\n",
      "Epoch: 11 -> Loss: 0.46116065979\n",
      "Epoch: 11 -> Test Accuracy: 79.42\n",
      "[12, 60] loss: 0.455\n",
      "[12, 120] loss: 0.447\n",
      "[12, 180] loss: 0.456\n",
      "[12, 240] loss: 0.463\n",
      "[12, 300] loss: 0.450\n",
      "[12, 360] loss: 0.451\n",
      "Epoch: 12 -> Loss: 0.313399463892\n",
      "Epoch: 12 -> Test Accuracy: 80.0\n",
      "[13, 60] loss: 0.424\n",
      "[13, 120] loss: 0.430\n",
      "[13, 180] loss: 0.466\n",
      "[13, 240] loss: 0.449\n",
      "[13, 300] loss: 0.453\n",
      "[13, 360] loss: 0.454\n",
      "Epoch: 13 -> Loss: 0.516529560089\n",
      "Epoch: 13 -> Test Accuracy: 80.38\n",
      "[14, 60] loss: 0.424\n",
      "[14, 120] loss: 0.431\n",
      "[14, 180] loss: 0.430\n",
      "[14, 240] loss: 0.447\n",
      "[14, 300] loss: 0.453\n",
      "[14, 360] loss: 0.456\n",
      "Epoch: 14 -> Loss: 0.481050014496\n",
      "Epoch: 14 -> Test Accuracy: 79.62\n",
      "[15, 60] loss: 0.406\n",
      "[15, 120] loss: 0.431\n",
      "[15, 180] loss: 0.433\n",
      "[15, 240] loss: 0.441\n",
      "[15, 300] loss: 0.446\n",
      "[15, 360] loss: 0.445\n",
      "Epoch: 15 -> Loss: 0.648628652096\n",
      "Epoch: 15 -> Test Accuracy: 80.55\n",
      "[16, 60] loss: 0.425\n",
      "[16, 120] loss: 0.457\n",
      "[16, 180] loss: 0.445\n",
      "[16, 240] loss: 0.435\n",
      "[16, 300] loss: 0.427\n",
      "[16, 360] loss: 0.449\n",
      "Epoch: 16 -> Loss: 0.458556979895\n",
      "Epoch: 16 -> Test Accuracy: 79.49\n",
      "[17, 60] loss: 0.425\n",
      "[17, 120] loss: 0.449\n",
      "[17, 180] loss: 0.438\n",
      "[17, 240] loss: 0.454\n",
      "[17, 300] loss: 0.428\n",
      "[17, 360] loss: 0.441\n",
      "Epoch: 17 -> Loss: 0.598839402199\n",
      "Epoch: 17 -> Test Accuracy: 80.41\n",
      "[18, 60] loss: 0.429\n",
      "[18, 120] loss: 0.425\n",
      "[18, 180] loss: 0.423\n",
      "[18, 240] loss: 0.451\n",
      "[18, 300] loss: 0.433\n",
      "[18, 360] loss: 0.453\n",
      "Epoch: 18 -> Loss: 0.593737125397\n",
      "Epoch: 18 -> Test Accuracy: 79.28\n",
      "[19, 60] loss: 0.442\n",
      "[19, 120] loss: 0.445\n",
      "[19, 180] loss: 0.424\n",
      "[19, 240] loss: 0.437\n",
      "[19, 300] loss: 0.437\n",
      "[19, 360] loss: 0.445\n",
      "Epoch: 19 -> Loss: 0.397381365299\n",
      "Epoch: 19 -> Test Accuracy: 80.32\n",
      "[20, 60] loss: 0.402\n",
      "[20, 120] loss: 0.439\n",
      "[20, 180] loss: 0.420\n",
      "[20, 240] loss: 0.436\n",
      "[20, 300] loss: 0.454\n",
      "[20, 360] loss: 0.436\n",
      "Epoch: 20 -> Loss: 0.578511536121\n",
      "Epoch: 20 -> Test Accuracy: 79.46\n",
      "[21, 60] loss: 0.407\n",
      "[21, 120] loss: 0.435\n",
      "[21, 180] loss: 0.429\n",
      "[21, 240] loss: 0.439\n",
      "[21, 300] loss: 0.448\n",
      "[21, 360] loss: 0.433\n",
      "Epoch: 21 -> Loss: 0.358949750662\n",
      "Epoch: 21 -> Test Accuracy: 80.01\n",
      "[22, 60] loss: 0.421\n",
      "[22, 120] loss: 0.430\n",
      "[22, 180] loss: 0.435\n",
      "[22, 240] loss: 0.447\n",
      "[22, 300] loss: 0.434\n",
      "[22, 360] loss: 0.434\n",
      "Epoch: 22 -> Loss: 0.534760773182\n",
      "Epoch: 22 -> Test Accuracy: 80.42\n",
      "[23, 60] loss: 0.418\n",
      "[23, 120] loss: 0.416\n",
      "[23, 180] loss: 0.419\n",
      "[23, 240] loss: 0.420\n",
      "[23, 300] loss: 0.440\n",
      "[23, 360] loss: 0.449\n",
      "Epoch: 23 -> Loss: 0.41357511282\n",
      "Epoch: 23 -> Test Accuracy: 80.39\n",
      "[24, 60] loss: 0.408\n",
      "[24, 120] loss: 0.423\n",
      "[24, 180] loss: 0.444\n",
      "[24, 240] loss: 0.435\n",
      "[24, 300] loss: 0.415\n",
      "[24, 360] loss: 0.426\n",
      "Epoch: 24 -> Loss: 0.4816390872\n",
      "Epoch: 24 -> Test Accuracy: 80.66\n",
      "[25, 60] loss: 0.406\n",
      "[25, 120] loss: 0.418\n",
      "[25, 180] loss: 0.434\n",
      "[25, 240] loss: 0.437\n",
      "[25, 300] loss: 0.442\n",
      "[25, 360] loss: 0.440\n",
      "Epoch: 25 -> Loss: 0.652198672295\n",
      "Epoch: 25 -> Test Accuracy: 81.07\n",
      "[26, 60] loss: 0.420\n",
      "[26, 120] loss: 0.409\n",
      "[26, 180] loss: 0.433\n",
      "[26, 240] loss: 0.420\n",
      "[26, 300] loss: 0.441\n",
      "[26, 360] loss: 0.433\n",
      "Epoch: 26 -> Loss: 0.574666500092\n",
      "Epoch: 26 -> Test Accuracy: 80.46\n",
      "[27, 60] loss: 0.398\n",
      "[27, 120] loss: 0.434\n",
      "[27, 180] loss: 0.421\n",
      "[27, 240] loss: 0.440\n",
      "[27, 300] loss: 0.419\n",
      "[27, 360] loss: 0.436\n",
      "Epoch: 27 -> Loss: 0.317280769348\n",
      "Epoch: 27 -> Test Accuracy: 80.97\n",
      "[28, 60] loss: 0.409\n",
      "[28, 120] loss: 0.418\n",
      "[28, 180] loss: 0.418\n",
      "[28, 240] loss: 0.440\n",
      "[28, 300] loss: 0.435\n",
      "[28, 360] loss: 0.429\n",
      "Epoch: 28 -> Loss: 0.274955511093\n",
      "Epoch: 28 -> Test Accuracy: 79.81\n",
      "[29, 60] loss: 0.408\n",
      "[29, 120] loss: 0.414\n",
      "[29, 180] loss: 0.444\n",
      "[29, 240] loss: 0.427\n",
      "[29, 300] loss: 0.435\n",
      "[29, 360] loss: 0.429\n",
      "Epoch: 29 -> Loss: 0.274388819933\n",
      "Epoch: 29 -> Test Accuracy: 80.32\n",
      "[30, 60] loss: 0.385\n",
      "[30, 120] loss: 0.438\n",
      "[30, 180] loss: 0.410\n",
      "[30, 240] loss: 0.443\n",
      "[30, 300] loss: 0.438\n",
      "[30, 360] loss: 0.438\n",
      "Epoch: 30 -> Loss: 0.257281839848\n",
      "Epoch: 30 -> Test Accuracy: 80.16\n",
      "[31, 60] loss: 0.410\n",
      "[31, 120] loss: 0.420\n",
      "[31, 180] loss: 0.422\n",
      "[31, 240] loss: 0.415\n",
      "[31, 300] loss: 0.437\n",
      "[31, 360] loss: 0.424\n",
      "Epoch: 31 -> Loss: 0.471561342478\n",
      "Epoch: 31 -> Test Accuracy: 80.33\n",
      "[32, 60] loss: 0.414\n",
      "[32, 120] loss: 0.429\n",
      "[32, 180] loss: 0.426\n",
      "[32, 240] loss: 0.430\n",
      "[32, 300] loss: 0.430\n",
      "[32, 360] loss: 0.421\n",
      "Epoch: 32 -> Loss: 0.406518876553\n",
      "Epoch: 32 -> Test Accuracy: 80.92\n",
      "[33, 60] loss: 0.413\n",
      "[33, 120] loss: 0.421\n",
      "[33, 180] loss: 0.437\n",
      "[33, 240] loss: 0.419\n",
      "[33, 300] loss: 0.417\n",
      "[33, 360] loss: 0.420\n",
      "Epoch: 33 -> Loss: 0.305161654949\n",
      "Epoch: 33 -> Test Accuracy: 80.93\n",
      "[34, 60] loss: 0.418\n",
      "[34, 120] loss: 0.399\n",
      "[34, 180] loss: 0.413\n",
      "[34, 240] loss: 0.431\n",
      "[34, 300] loss: 0.436\n",
      "[34, 360] loss: 0.424\n",
      "Epoch: 34 -> Loss: 0.532312214375\n",
      "Epoch: 34 -> Test Accuracy: 80.42\n",
      "[35, 60] loss: 0.424\n",
      "[35, 120] loss: 0.416\n",
      "[35, 180] loss: 0.416\n",
      "[35, 240] loss: 0.436\n",
      "[35, 300] loss: 0.421\n",
      "[35, 360] loss: 0.406\n",
      "Epoch: 35 -> Loss: 0.748363554478\n",
      "Epoch: 35 -> Test Accuracy: 79.92\n",
      "[36, 60] loss: 0.370\n",
      "[36, 120] loss: 0.346\n",
      "[36, 180] loss: 0.349\n",
      "[36, 240] loss: 0.346\n",
      "[36, 300] loss: 0.327\n",
      "[36, 360] loss: 0.327\n",
      "Epoch: 36 -> Loss: 0.369983613491\n",
      "Epoch: 36 -> Test Accuracy: 83.03\n",
      "[37, 60] loss: 0.311\n",
      "[37, 120] loss: 0.330\n",
      "[37, 180] loss: 0.316\n",
      "[37, 240] loss: 0.315\n",
      "[37, 300] loss: 0.315\n",
      "[37, 360] loss: 0.309\n",
      "Epoch: 37 -> Loss: 0.33943015337\n",
      "Epoch: 37 -> Test Accuracy: 82.95\n",
      "[38, 60] loss: 0.298\n",
      "[38, 120] loss: 0.317\n",
      "[38, 180] loss: 0.305\n",
      "[38, 240] loss: 0.304\n",
      "[38, 300] loss: 0.303\n",
      "[38, 360] loss: 0.301\n",
      "Epoch: 38 -> Loss: 0.249521881342\n",
      "Epoch: 38 -> Test Accuracy: 82.88\n",
      "[39, 60] loss: 0.278\n",
      "[39, 120] loss: 0.303\n",
      "[39, 180] loss: 0.309\n",
      "[39, 240] loss: 0.301\n",
      "[39, 300] loss: 0.308\n",
      "[39, 360] loss: 0.318\n",
      "Epoch: 39 -> Loss: 0.329111665487\n",
      "Epoch: 39 -> Test Accuracy: 83.16\n",
      "[40, 60] loss: 0.296\n",
      "[40, 120] loss: 0.280\n",
      "[40, 180] loss: 0.299\n",
      "[40, 240] loss: 0.300\n",
      "[40, 300] loss: 0.293\n",
      "[40, 360] loss: 0.303\n",
      "Epoch: 40 -> Loss: 0.296360969543\n",
      "Epoch: 40 -> Test Accuracy: 83.21\n",
      "[41, 60] loss: 0.297\n",
      "[41, 120] loss: 0.278\n",
      "[41, 180] loss: 0.299\n",
      "[41, 240] loss: 0.288\n",
      "[41, 300] loss: 0.303\n",
      "[41, 360] loss: 0.298\n",
      "Epoch: 41 -> Loss: 0.211284086108\n",
      "Epoch: 41 -> Test Accuracy: 83.36\n",
      "[42, 60] loss: 0.281\n",
      "[42, 120] loss: 0.290\n",
      "[42, 180] loss: 0.282\n",
      "[42, 240] loss: 0.295\n",
      "[42, 300] loss: 0.304\n",
      "[42, 360] loss: 0.317\n",
      "Epoch: 42 -> Loss: 0.225504636765\n",
      "Epoch: 42 -> Test Accuracy: 82.66\n",
      "[43, 60] loss: 0.277\n",
      "[43, 120] loss: 0.277\n",
      "[43, 180] loss: 0.277\n",
      "[43, 240] loss: 0.289\n",
      "[43, 300] loss: 0.286\n",
      "[43, 360] loss: 0.305\n",
      "Epoch: 43 -> Loss: 0.272101044655\n",
      "Epoch: 43 -> Test Accuracy: 82.25\n",
      "[44, 60] loss: 0.276\n",
      "[44, 120] loss: 0.290\n",
      "[44, 180] loss: 0.286\n",
      "[44, 240] loss: 0.276\n",
      "[44, 300] loss: 0.296\n",
      "[44, 360] loss: 0.279\n",
      "Epoch: 44 -> Loss: 0.316694974899\n",
      "Epoch: 44 -> Test Accuracy: 82.81\n",
      "[45, 60] loss: 0.269\n",
      "[45, 120] loss: 0.273\n",
      "[45, 180] loss: 0.290\n",
      "[45, 240] loss: 0.285\n",
      "[45, 300] loss: 0.288\n",
      "[45, 360] loss: 0.291\n",
      "Epoch: 45 -> Loss: 0.294775515795\n",
      "Epoch: 45 -> Test Accuracy: 82.96\n",
      "[46, 60] loss: 0.282\n",
      "[46, 120] loss: 0.279\n",
      "[46, 180] loss: 0.282\n",
      "[46, 240] loss: 0.294\n",
      "[46, 300] loss: 0.267\n",
      "[46, 360] loss: 0.300\n",
      "Epoch: 46 -> Loss: 0.284305989742\n",
      "Epoch: 46 -> Test Accuracy: 82.56\n",
      "[47, 60] loss: 0.278\n",
      "[47, 120] loss: 0.280\n",
      "[47, 180] loss: 0.273\n",
      "[47, 240] loss: 0.285\n",
      "[47, 300] loss: 0.291\n",
      "[47, 360] loss: 0.289\n",
      "Epoch: 47 -> Loss: 0.393427908421\n",
      "Epoch: 47 -> Test Accuracy: 82.58\n",
      "[48, 60] loss: 0.287\n",
      "[48, 120] loss: 0.294\n",
      "[48, 180] loss: 0.282\n",
      "[48, 240] loss: 0.284\n",
      "[48, 300] loss: 0.287\n",
      "[48, 360] loss: 0.297\n",
      "Epoch: 48 -> Loss: 0.313535064459\n",
      "Epoch: 48 -> Test Accuracy: 82.47\n",
      "[49, 60] loss: 0.290\n",
      "[49, 120] loss: 0.279\n",
      "[49, 180] loss: 0.277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 240] loss: 0.273\n",
      "[49, 300] loss: 0.280\n",
      "[49, 360] loss: 0.309\n",
      "Epoch: 49 -> Loss: 0.366016864777\n",
      "Epoch: 49 -> Test Accuracy: 82.39\n",
      "[50, 60] loss: 0.259\n",
      "[50, 120] loss: 0.286\n",
      "[50, 180] loss: 0.282\n",
      "[50, 240] loss: 0.301\n",
      "[50, 300] loss: 0.282\n",
      "[50, 360] loss: 0.297\n",
      "Epoch: 50 -> Loss: 0.235420063138\n",
      "Epoch: 50 -> Test Accuracy: 82.74\n",
      "[51, 60] loss: 0.261\n",
      "[51, 120] loss: 0.275\n",
      "[51, 180] loss: 0.279\n",
      "[51, 240] loss: 0.278\n",
      "[51, 300] loss: 0.284\n",
      "[51, 360] loss: 0.292\n",
      "Epoch: 51 -> Loss: 0.37625837326\n",
      "Epoch: 51 -> Test Accuracy: 82.77\n",
      "[52, 60] loss: 0.256\n",
      "[52, 120] loss: 0.271\n",
      "[52, 180] loss: 0.275\n",
      "[52, 240] loss: 0.291\n",
      "[52, 300] loss: 0.285\n",
      "[52, 360] loss: 0.286\n",
      "Epoch: 52 -> Loss: 0.293025255203\n",
      "Epoch: 52 -> Test Accuracy: 82.65\n",
      "[53, 60] loss: 0.278\n",
      "[53, 120] loss: 0.277\n",
      "[53, 180] loss: 0.280\n",
      "[53, 240] loss: 0.267\n",
      "[53, 300] loss: 0.284\n",
      "[53, 360] loss: 0.277\n",
      "Epoch: 53 -> Loss: 0.383958637714\n",
      "Epoch: 53 -> Test Accuracy: 82.4\n",
      "[54, 60] loss: 0.263\n",
      "[54, 120] loss: 0.268\n",
      "[54, 180] loss: 0.272\n",
      "[54, 240] loss: 0.281\n",
      "[54, 300] loss: 0.289\n",
      "[54, 360] loss: 0.278\n",
      "Epoch: 54 -> Loss: 0.151452496648\n",
      "Epoch: 54 -> Test Accuracy: 82.71\n",
      "[55, 60] loss: 0.262\n",
      "[55, 120] loss: 0.268\n",
      "[55, 180] loss: 0.271\n",
      "[55, 240] loss: 0.273\n",
      "[55, 300] loss: 0.286\n",
      "[55, 360] loss: 0.280\n",
      "Epoch: 55 -> Loss: 0.257259398699\n",
      "Epoch: 55 -> Test Accuracy: 82.98\n",
      "[56, 60] loss: 0.256\n",
      "[56, 120] loss: 0.278\n",
      "[56, 180] loss: 0.284\n",
      "[56, 240] loss: 0.280\n",
      "[56, 300] loss: 0.289\n",
      "[56, 360] loss: 0.283\n",
      "Epoch: 56 -> Loss: 0.218032643199\n",
      "Epoch: 56 -> Test Accuracy: 83.12\n",
      "[57, 60] loss: 0.260\n",
      "[57, 120] loss: 0.273\n",
      "[57, 180] loss: 0.272\n",
      "[57, 240] loss: 0.277\n",
      "[57, 300] loss: 0.285\n",
      "[57, 360] loss: 0.291\n",
      "Epoch: 57 -> Loss: 0.253722965717\n",
      "Epoch: 57 -> Test Accuracy: 82.65\n",
      "[58, 60] loss: 0.266\n",
      "[58, 120] loss: 0.270\n",
      "[58, 180] loss: 0.290\n",
      "[58, 240] loss: 0.268\n",
      "[58, 300] loss: 0.281\n",
      "[58, 360] loss: 0.275\n",
      "Epoch: 58 -> Loss: 0.251605302095\n",
      "Epoch: 58 -> Test Accuracy: 83.1\n",
      "[59, 60] loss: 0.254\n",
      "[59, 120] loss: 0.276\n",
      "[59, 180] loss: 0.280\n",
      "[59, 240] loss: 0.272\n",
      "[59, 300] loss: 0.270\n",
      "[59, 360] loss: 0.279\n",
      "Epoch: 59 -> Loss: 0.306207507849\n",
      "Epoch: 59 -> Test Accuracy: 82.38\n",
      "[60, 60] loss: 0.264\n",
      "[60, 120] loss: 0.274\n",
      "[60, 180] loss: 0.264\n",
      "[60, 240] loss: 0.269\n",
      "[60, 300] loss: 0.275\n",
      "[60, 360] loss: 0.274\n",
      "Epoch: 60 -> Loss: 0.28145557642\n",
      "Epoch: 60 -> Test Accuracy: 82.42\n",
      "[61, 60] loss: 0.258\n",
      "[61, 120] loss: 0.283\n",
      "[61, 180] loss: 0.286\n",
      "[61, 240] loss: 0.284\n",
      "[61, 300] loss: 0.267\n",
      "[61, 360] loss: 0.279\n",
      "Epoch: 61 -> Loss: 0.27180275321\n",
      "Epoch: 61 -> Test Accuracy: 82.43\n",
      "[62, 60] loss: 0.262\n",
      "[62, 120] loss: 0.263\n",
      "[62, 180] loss: 0.275\n",
      "[62, 240] loss: 0.268\n",
      "[62, 300] loss: 0.275\n",
      "[62, 360] loss: 0.291\n",
      "Epoch: 62 -> Loss: 0.305367231369\n",
      "Epoch: 62 -> Test Accuracy: 82.12\n",
      "[63, 60] loss: 0.253\n",
      "[63, 120] loss: 0.253\n",
      "[63, 180] loss: 0.272\n",
      "[63, 240] loss: 0.272\n",
      "[63, 300] loss: 0.276\n",
      "[63, 360] loss: 0.298\n",
      "Epoch: 63 -> Loss: 0.346509218216\n",
      "Epoch: 63 -> Test Accuracy: 81.92\n",
      "[64, 60] loss: 0.272\n",
      "[64, 120] loss: 0.239\n",
      "[64, 180] loss: 0.264\n",
      "[64, 240] loss: 0.261\n",
      "[64, 300] loss: 0.271\n",
      "[64, 360] loss: 0.288\n",
      "Epoch: 64 -> Loss: 0.371111303568\n",
      "Epoch: 64 -> Test Accuracy: 82.18\n",
      "[65, 60] loss: 0.257\n",
      "[65, 120] loss: 0.252\n",
      "[65, 180] loss: 0.279\n",
      "[65, 240] loss: 0.275\n",
      "[65, 300] loss: 0.278\n",
      "[65, 360] loss: 0.270\n",
      "Epoch: 65 -> Loss: 0.480719178915\n",
      "Epoch: 65 -> Test Accuracy: 82.41\n",
      "[66, 60] loss: 0.264\n",
      "[66, 120] loss: 0.263\n",
      "[66, 180] loss: 0.271\n",
      "[66, 240] loss: 0.266\n",
      "[66, 300] loss: 0.269\n",
      "[66, 360] loss: 0.286\n",
      "Epoch: 66 -> Loss: 0.295153319836\n",
      "Epoch: 66 -> Test Accuracy: 82.16\n",
      "[67, 60] loss: 0.256\n",
      "[67, 120] loss: 0.275\n",
      "[67, 180] loss: 0.278\n",
      "[67, 240] loss: 0.265\n",
      "[67, 300] loss: 0.268\n",
      "[67, 360] loss: 0.272\n",
      "Epoch: 67 -> Loss: 0.251160293818\n",
      "Epoch: 67 -> Test Accuracy: 82.42\n",
      "[68, 60] loss: 0.254\n",
      "[68, 120] loss: 0.255\n",
      "[68, 180] loss: 0.261\n",
      "[68, 240] loss: 0.261\n",
      "[68, 300] loss: 0.280\n",
      "[68, 360] loss: 0.280\n",
      "Epoch: 68 -> Loss: 0.289622545242\n",
      "Epoch: 68 -> Test Accuracy: 82.57\n",
      "[69, 60] loss: 0.271\n",
      "[69, 120] loss: 0.257\n",
      "[69, 180] loss: 0.269\n",
      "[69, 240] loss: 0.277\n",
      "[69, 300] loss: 0.268\n",
      "[69, 360] loss: 0.277\n",
      "Epoch: 69 -> Loss: 0.269617021084\n",
      "Epoch: 69 -> Test Accuracy: 82.37\n",
      "[70, 60] loss: 0.242\n",
      "[70, 120] loss: 0.255\n",
      "[70, 180] loss: 0.264\n",
      "[70, 240] loss: 0.264\n",
      "[70, 300] loss: 0.268\n",
      "[70, 360] loss: 0.277\n",
      "Epoch: 70 -> Loss: 0.290511012077\n",
      "Epoch: 70 -> Test Accuracy: 82.92\n",
      "[71, 60] loss: 0.229\n",
      "[71, 120] loss: 0.209\n",
      "[71, 180] loss: 0.213\n",
      "[71, 240] loss: 0.203\n",
      "[71, 300] loss: 0.209\n",
      "[71, 360] loss: 0.206\n",
      "Epoch: 71 -> Loss: 0.357591629028\n",
      "Epoch: 71 -> Test Accuracy: 84.4\n",
      "[72, 60] loss: 0.201\n",
      "[72, 120] loss: 0.191\n",
      "[72, 180] loss: 0.197\n",
      "[72, 240] loss: 0.199\n",
      "[72, 300] loss: 0.177\n",
      "[72, 360] loss: 0.199\n",
      "Epoch: 72 -> Loss: 0.110013522208\n",
      "Epoch: 72 -> Test Accuracy: 84.19\n",
      "[73, 60] loss: 0.189\n",
      "[73, 120] loss: 0.180\n",
      "[73, 180] loss: 0.194\n",
      "[73, 240] loss: 0.202\n",
      "[73, 300] loss: 0.183\n",
      "[73, 360] loss: 0.190\n",
      "Epoch: 73 -> Loss: 0.162289425731\n",
      "Epoch: 73 -> Test Accuracy: 84.05\n",
      "[74, 60] loss: 0.176\n",
      "[74, 120] loss: 0.183\n",
      "[74, 180] loss: 0.178\n",
      "[74, 240] loss: 0.200\n",
      "[74, 300] loss: 0.193\n",
      "[74, 360] loss: 0.178\n",
      "Epoch: 74 -> Loss: 0.219318464398\n",
      "Epoch: 74 -> Test Accuracy: 84.09\n",
      "[75, 60] loss: 0.173\n",
      "[75, 120] loss: 0.179\n",
      "[75, 180] loss: 0.185\n",
      "[75, 240] loss: 0.181\n",
      "[75, 300] loss: 0.177\n",
      "[75, 360] loss: 0.188\n",
      "Epoch: 75 -> Loss: 0.227031901479\n",
      "Epoch: 75 -> Test Accuracy: 84.04\n",
      "[76, 60] loss: 0.168\n",
      "[76, 120] loss: 0.177\n",
      "[76, 180] loss: 0.172\n",
      "[76, 240] loss: 0.174\n",
      "[76, 300] loss: 0.182\n",
      "[76, 360] loss: 0.185\n",
      "Epoch: 76 -> Loss: 0.186178401113\n",
      "Epoch: 76 -> Test Accuracy: 84.05\n",
      "[77, 60] loss: 0.175\n",
      "[77, 120] loss: 0.178\n",
      "[77, 180] loss: 0.175\n",
      "[77, 240] loss: 0.172\n",
      "[77, 300] loss: 0.170\n",
      "[77, 360] loss: 0.177\n",
      "Epoch: 77 -> Loss: 0.132346317172\n",
      "Epoch: 77 -> Test Accuracy: 84.26\n",
      "[78, 60] loss: 0.175\n",
      "[78, 120] loss: 0.176\n",
      "[78, 180] loss: 0.170\n",
      "[78, 240] loss: 0.158\n",
      "[78, 300] loss: 0.170\n",
      "[78, 360] loss: 0.171\n",
      "Epoch: 78 -> Loss: 0.178392723203\n",
      "Epoch: 78 -> Test Accuracy: 84.01\n",
      "[79, 60] loss: 0.170\n",
      "[79, 120] loss: 0.156\n",
      "[79, 180] loss: 0.161\n",
      "[79, 240] loss: 0.174\n",
      "[79, 300] loss: 0.174\n",
      "[79, 360] loss: 0.176\n",
      "Epoch: 79 -> Loss: 0.175423651934\n",
      "Epoch: 79 -> Test Accuracy: 83.98\n",
      "[80, 60] loss: 0.163\n",
      "[80, 120] loss: 0.167\n",
      "[80, 180] loss: 0.166\n",
      "[80, 240] loss: 0.163\n",
      "[80, 300] loss: 0.160\n",
      "[80, 360] loss: 0.180\n",
      "Epoch: 80 -> Loss: 0.244992926717\n",
      "Epoch: 80 -> Test Accuracy: 83.87\n",
      "[81, 60] loss: 0.151\n",
      "[81, 120] loss: 0.162\n",
      "[81, 180] loss: 0.163\n",
      "[81, 240] loss: 0.172\n",
      "[81, 300] loss: 0.164\n",
      "[81, 360] loss: 0.164\n",
      "Epoch: 81 -> Loss: 0.185762181878\n",
      "Epoch: 81 -> Test Accuracy: 83.96\n",
      "[82, 60] loss: 0.160\n",
      "[82, 120] loss: 0.156\n",
      "[82, 180] loss: 0.163\n",
      "[82, 240] loss: 0.169\n",
      "[82, 300] loss: 0.166\n",
      "[82, 360] loss: 0.163\n",
      "Epoch: 82 -> Loss: 0.211119100451\n",
      "Epoch: 82 -> Test Accuracy: 83.85\n",
      "[83, 60] loss: 0.158\n",
      "[83, 120] loss: 0.162\n",
      "[83, 180] loss: 0.167\n",
      "[83, 240] loss: 0.167\n",
      "[83, 300] loss: 0.167\n",
      "[83, 360] loss: 0.156\n",
      "Epoch: 83 -> Loss: 0.193635687232\n",
      "Epoch: 83 -> Test Accuracy: 83.78\n",
      "[84, 60] loss: 0.157\n",
      "[84, 120] loss: 0.162\n",
      "[84, 180] loss: 0.153\n",
      "[84, 240] loss: 0.159\n",
      "[84, 300] loss: 0.164\n",
      "[84, 360] loss: 0.171\n",
      "Epoch: 84 -> Loss: 0.217514842749\n",
      "Epoch: 84 -> Test Accuracy: 83.58\n",
      "[85, 60] loss: 0.146\n",
      "[85, 120] loss: 0.151\n",
      "[85, 180] loss: 0.154\n",
      "[85, 240] loss: 0.162\n",
      "[85, 300] loss: 0.175\n",
      "[85, 360] loss: 0.162\n",
      "Epoch: 85 -> Loss: 0.116392895579\n",
      "Epoch: 85 -> Test Accuracy: 84.03\n",
      "[86, 60] loss: 0.146\n",
      "[86, 120] loss: 0.145\n",
      "[86, 180] loss: 0.152\n",
      "[86, 240] loss: 0.147\n",
      "[86, 300] loss: 0.140\n",
      "[86, 360] loss: 0.145\n",
      "Epoch: 86 -> Loss: 0.185937136412\n",
      "Epoch: 86 -> Test Accuracy: 84.08\n",
      "[87, 60] loss: 0.141\n",
      "[87, 120] loss: 0.135\n",
      "[87, 180] loss: 0.148\n",
      "[87, 240] loss: 0.139\n",
      "[87, 300] loss: 0.143\n",
      "[87, 360] loss: 0.139\n",
      "Epoch: 87 -> Loss: 0.215540960431\n",
      "Epoch: 87 -> Test Accuracy: 84.18\n",
      "[88, 60] loss: 0.137\n",
      "[88, 120] loss: 0.138\n",
      "[88, 180] loss: 0.135\n",
      "[88, 240] loss: 0.136\n",
      "[88, 300] loss: 0.135\n",
      "[88, 360] loss: 0.146\n",
      "Epoch: 88 -> Loss: 0.15281394124\n",
      "Epoch: 88 -> Test Accuracy: 84.08\n",
      "[89, 60] loss: 0.145\n",
      "[89, 120] loss: 0.142\n",
      "[89, 180] loss: 0.138\n",
      "[89, 240] loss: 0.135\n",
      "[89, 300] loss: 0.141\n",
      "[89, 360] loss: 0.138\n",
      "Epoch: 89 -> Loss: 0.106363192201\n",
      "Epoch: 89 -> Test Accuracy: 84.23\n",
      "[90, 60] loss: 0.139\n",
      "[90, 120] loss: 0.134\n",
      "[90, 180] loss: 0.134\n",
      "[90, 240] loss: 0.147\n",
      "[90, 300] loss: 0.140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90, 360] loss: 0.142\n",
      "Epoch: 90 -> Loss: 0.123370908201\n",
      "Epoch: 90 -> Test Accuracy: 84.32\n",
      "[91, 60] loss: 0.133\n",
      "[91, 120] loss: 0.127\n",
      "[91, 180] loss: 0.130\n",
      "[91, 240] loss: 0.140\n",
      "[91, 300] loss: 0.134\n",
      "[91, 360] loss: 0.141\n",
      "Epoch: 91 -> Loss: 0.221942216158\n",
      "Epoch: 91 -> Test Accuracy: 84.14\n",
      "[92, 60] loss: 0.132\n",
      "[92, 120] loss: 0.135\n",
      "[92, 180] loss: 0.131\n",
      "[92, 240] loss: 0.138\n",
      "[92, 300] loss: 0.135\n",
      "[92, 360] loss: 0.141\n",
      "Epoch: 92 -> Loss: 0.093013048172\n",
      "Epoch: 92 -> Test Accuracy: 84.2\n",
      "[93, 60] loss: 0.131\n",
      "[93, 120] loss: 0.133\n",
      "[93, 180] loss: 0.137\n",
      "[93, 240] loss: 0.135\n",
      "[93, 300] loss: 0.132\n",
      "[93, 360] loss: 0.132\n",
      "Epoch: 93 -> Loss: 0.294101417065\n",
      "Epoch: 93 -> Test Accuracy: 84.2\n",
      "[94, 60] loss: 0.126\n",
      "[94, 120] loss: 0.135\n",
      "[94, 180] loss: 0.134\n",
      "[94, 240] loss: 0.128\n",
      "[94, 300] loss: 0.138\n",
      "[94, 360] loss: 0.131\n",
      "Epoch: 94 -> Loss: 0.144086003304\n",
      "Epoch: 94 -> Test Accuracy: 84.12\n",
      "[95, 60] loss: 0.129\n",
      "[95, 120] loss: 0.133\n",
      "[95, 180] loss: 0.135\n",
      "[95, 240] loss: 0.131\n",
      "[95, 300] loss: 0.128\n",
      "[95, 360] loss: 0.132\n",
      "Epoch: 95 -> Loss: 0.0971439853311\n",
      "Epoch: 95 -> Test Accuracy: 84.18\n",
      "[96, 60] loss: 0.135\n",
      "[96, 120] loss: 0.131\n",
      "[96, 180] loss: 0.130\n",
      "[96, 240] loss: 0.136\n",
      "[96, 300] loss: 0.123\n",
      "[96, 360] loss: 0.140\n",
      "Epoch: 96 -> Loss: 0.0972165390849\n",
      "Epoch: 96 -> Test Accuracy: 84.42\n",
      "[97, 60] loss: 0.133\n",
      "[97, 120] loss: 0.130\n",
      "[97, 180] loss: 0.131\n",
      "[97, 240] loss: 0.138\n",
      "[97, 300] loss: 0.134\n",
      "[97, 360] loss: 0.128\n",
      "Epoch: 97 -> Loss: 0.162491112947\n",
      "Epoch: 97 -> Test Accuracy: 84.04\n",
      "[98, 60] loss: 0.124\n",
      "[98, 120] loss: 0.134\n",
      "[98, 180] loss: 0.132\n",
      "[98, 240] loss: 0.135\n",
      "[98, 300] loss: 0.137\n",
      "[98, 360] loss: 0.131\n",
      "Epoch: 98 -> Loss: 0.205570608377\n",
      "Epoch: 98 -> Test Accuracy: 84.06\n",
      "[99, 60] loss: 0.127\n",
      "[99, 120] loss: 0.129\n",
      "[99, 180] loss: 0.130\n",
      "[99, 240] loss: 0.130\n",
      "[99, 300] loss: 0.129\n",
      "[99, 360] loss: 0.126\n",
      "Epoch: 99 -> Loss: 0.222550436854\n",
      "Epoch: 99 -> Test Accuracy: 84.3\n",
      "[100, 60] loss: 0.137\n",
      "[100, 120] loss: 0.129\n",
      "[100, 180] loss: 0.130\n",
      "[100, 240] loss: 0.134\n",
      "[100, 300] loss: 0.121\n",
      "[100, 360] loss: 0.127\n",
      "Epoch: 100 -> Loss: 0.114342950284\n",
      "Epoch: 100 -> Test Accuracy: 84.01\n",
      "Finished Training\n",
      "[1, 60] loss: 2.080\n",
      "[1, 120] loss: 1.905\n",
      "[1, 180] loss: 1.849\n",
      "[1, 240] loss: 1.794\n",
      "[1, 300] loss: 1.802\n",
      "[1, 360] loss: 1.741\n",
      "Epoch: 1 -> Loss: 1.7553024292\n",
      "Epoch: 1 -> Test Accuracy: 33.95\n",
      "[2, 60] loss: 1.747\n",
      "[2, 120] loss: 1.725\n",
      "[2, 180] loss: 1.707\n",
      "[2, 240] loss: 1.703\n",
      "[2, 300] loss: 1.664\n",
      "[2, 360] loss: 1.665\n",
      "Epoch: 2 -> Loss: 1.70884299278\n",
      "Epoch: 2 -> Test Accuracy: 36.08\n",
      "[3, 60] loss: 1.641\n",
      "[3, 120] loss: 1.654\n",
      "[3, 180] loss: 1.631\n",
      "[3, 240] loss: 1.629\n",
      "[3, 300] loss: 1.614\n",
      "[3, 360] loss: 1.637\n",
      "Epoch: 3 -> Loss: 1.50546896458\n",
      "Epoch: 3 -> Test Accuracy: 37.27\n",
      "[4, 60] loss: 1.602\n",
      "[4, 120] loss: 1.600\n",
      "[4, 180] loss: 1.600\n",
      "[4, 240] loss: 1.598\n",
      "[4, 300] loss: 1.581\n",
      "[4, 360] loss: 1.613\n",
      "Epoch: 4 -> Loss: 1.69465231895\n",
      "Epoch: 4 -> Test Accuracy: 36.62\n",
      "[5, 60] loss: 1.577\n",
      "[5, 120] loss: 1.604\n",
      "[5, 180] loss: 1.553\n",
      "[5, 240] loss: 1.555\n",
      "[5, 300] loss: 1.565\n",
      "[5, 360] loss: 1.562\n",
      "Epoch: 5 -> Loss: 1.58563876152\n",
      "Epoch: 5 -> Test Accuracy: 38.45\n",
      "[6, 60] loss: 1.568\n",
      "[6, 120] loss: 1.551\n",
      "[6, 180] loss: 1.565\n",
      "[6, 240] loss: 1.553\n",
      "[6, 300] loss: 1.551\n",
      "[6, 360] loss: 1.540\n",
      "Epoch: 6 -> Loss: 1.67741835117\n",
      "Epoch: 6 -> Test Accuracy: 39.49\n",
      "[7, 60] loss: 1.545\n",
      "[7, 120] loss: 1.551\n",
      "[7, 180] loss: 1.549\n",
      "[7, 240] loss: 1.552\n",
      "[7, 300] loss: 1.524\n",
      "[7, 360] loss: 1.532\n",
      "Epoch: 7 -> Loss: 1.49990916252\n",
      "Epoch: 7 -> Test Accuracy: 41.37\n",
      "[8, 60] loss: 1.523\n",
      "[8, 120] loss: 1.538\n",
      "[8, 180] loss: 1.531\n",
      "[8, 240] loss: 1.548\n",
      "[8, 300] loss: 1.544\n",
      "[8, 360] loss: 1.523\n",
      "Epoch: 8 -> Loss: 1.83137392998\n",
      "Epoch: 8 -> Test Accuracy: 41.25\n",
      "[9, 60] loss: 1.528\n",
      "[9, 120] loss: 1.529\n",
      "[9, 180] loss: 1.527\n",
      "[9, 240] loss: 1.514\n",
      "[9, 300] loss: 1.521\n",
      "[9, 360] loss: 1.531\n",
      "Epoch: 9 -> Loss: 1.46106219292\n",
      "Epoch: 9 -> Test Accuracy: 39.85\n",
      "[10, 60] loss: 1.525\n",
      "[10, 120] loss: 1.504\n",
      "[10, 180] loss: 1.497\n",
      "[10, 240] loss: 1.520\n",
      "[10, 300] loss: 1.528\n",
      "[10, 360] loss: 1.527\n",
      "Epoch: 10 -> Loss: 1.51962482929\n",
      "Epoch: 10 -> Test Accuracy: 41.39\n",
      "[11, 60] loss: 1.502\n",
      "[11, 120] loss: 1.509\n",
      "[11, 180] loss: 1.505\n",
      "[11, 240] loss: 1.529\n",
      "[11, 300] loss: 1.518\n",
      "[11, 360] loss: 1.529\n",
      "Epoch: 11 -> Loss: 1.41178417206\n",
      "Epoch: 11 -> Test Accuracy: 40.01\n",
      "[12, 60] loss: 1.513\n",
      "[12, 120] loss: 1.504\n",
      "[12, 180] loss: 1.514\n",
      "[12, 240] loss: 1.520\n",
      "[12, 300] loss: 1.507\n",
      "[12, 360] loss: 1.485\n",
      "Epoch: 12 -> Loss: 1.53238582611\n",
      "Epoch: 12 -> Test Accuracy: 40.85\n",
      "[13, 60] loss: 1.500\n",
      "[13, 120] loss: 1.500\n",
      "[13, 180] loss: 1.516\n",
      "[13, 240] loss: 1.500\n",
      "[13, 300] loss: 1.479\n",
      "[13, 360] loss: 1.496\n",
      "Epoch: 13 -> Loss: 1.3504550457\n",
      "Epoch: 13 -> Test Accuracy: 41.34\n",
      "[14, 60] loss: 1.495\n",
      "[14, 120] loss: 1.492\n",
      "[14, 180] loss: 1.509\n",
      "[14, 240] loss: 1.500\n",
      "[14, 300] loss: 1.505\n",
      "[14, 360] loss: 1.490\n",
      "Epoch: 14 -> Loss: 1.56544852257\n",
      "Epoch: 14 -> Test Accuracy: 40.36\n",
      "[15, 60] loss: 1.475\n",
      "[15, 120] loss: 1.508\n",
      "[15, 180] loss: 1.508\n",
      "[15, 240] loss: 1.483\n",
      "[15, 300] loss: 1.519\n",
      "[15, 360] loss: 1.510\n",
      "Epoch: 15 -> Loss: 1.35666799545\n",
      "Epoch: 15 -> Test Accuracy: 42.02\n",
      "[16, 60] loss: 1.495\n",
      "[16, 120] loss: 1.508\n",
      "[16, 180] loss: 1.499\n",
      "[16, 240] loss: 1.483\n",
      "[16, 300] loss: 1.505\n",
      "[16, 360] loss: 1.489\n",
      "Epoch: 16 -> Loss: 1.39171421528\n",
      "Epoch: 16 -> Test Accuracy: 42.4\n",
      "[17, 60] loss: 1.484\n",
      "[17, 120] loss: 1.487\n",
      "[17, 180] loss: 1.476\n",
      "[17, 240] loss: 1.507\n",
      "[17, 300] loss: 1.504\n",
      "[17, 360] loss: 1.485\n",
      "Epoch: 17 -> Loss: 1.33801054955\n",
      "Epoch: 17 -> Test Accuracy: 41.92\n",
      "[18, 60] loss: 1.468\n",
      "[18, 120] loss: 1.488\n",
      "[18, 180] loss: 1.487\n",
      "[18, 240] loss: 1.483\n",
      "[18, 300] loss: 1.484\n",
      "[18, 360] loss: 1.499\n",
      "Epoch: 18 -> Loss: 1.47690463066\n",
      "Epoch: 18 -> Test Accuracy: 42.2\n",
      "[19, 60] loss: 1.478\n",
      "[19, 120] loss: 1.505\n",
      "[19, 180] loss: 1.503\n",
      "[19, 240] loss: 1.500\n",
      "[19, 300] loss: 1.478\n",
      "[19, 360] loss: 1.470\n",
      "Epoch: 19 -> Loss: 1.35110235214\n",
      "Epoch: 19 -> Test Accuracy: 42.46\n",
      "[20, 60] loss: 1.485\n",
      "[20, 120] loss: 1.501\n",
      "[20, 180] loss: 1.471\n",
      "[20, 240] loss: 1.494\n",
      "[20, 300] loss: 1.481\n",
      "[20, 360] loss: 1.484\n",
      "Epoch: 20 -> Loss: 1.38388347626\n",
      "Epoch: 20 -> Test Accuracy: 42.04\n",
      "[21, 60] loss: 1.468\n",
      "[21, 120] loss: 1.486\n",
      "[21, 180] loss: 1.518\n",
      "[21, 240] loss: 1.489\n",
      "[21, 300] loss: 1.469\n",
      "[21, 360] loss: 1.495\n",
      "Epoch: 21 -> Loss: 1.60085463524\n",
      "Epoch: 21 -> Test Accuracy: 42.32\n",
      "[22, 60] loss: 1.489\n",
      "[22, 120] loss: 1.475\n",
      "[22, 180] loss: 1.483\n",
      "[22, 240] loss: 1.500\n",
      "[22, 300] loss: 1.487\n",
      "[22, 360] loss: 1.486\n",
      "Epoch: 22 -> Loss: 1.40566277504\n",
      "Epoch: 22 -> Test Accuracy: 43.28\n",
      "[23, 60] loss: 1.471\n",
      "[23, 120] loss: 1.482\n",
      "[23, 180] loss: 1.477\n",
      "[23, 240] loss: 1.468\n",
      "[23, 300] loss: 1.488\n",
      "[23, 360] loss: 1.494\n",
      "Epoch: 23 -> Loss: 1.56549572945\n",
      "Epoch: 23 -> Test Accuracy: 41.99\n",
      "[24, 60] loss: 1.499\n",
      "[24, 120] loss: 1.462\n",
      "[24, 180] loss: 1.478\n",
      "[24, 240] loss: 1.484\n",
      "[24, 300] loss: 1.477\n",
      "[24, 360] loss: 1.494\n",
      "Epoch: 24 -> Loss: 1.5430907011\n",
      "Epoch: 24 -> Test Accuracy: 42.2\n",
      "[25, 60] loss: 1.478\n",
      "[25, 120] loss: 1.487\n",
      "[25, 180] loss: 1.488\n",
      "[25, 240] loss: 1.459\n",
      "[25, 300] loss: 1.482\n",
      "[25, 360] loss: 1.490\n",
      "Epoch: 25 -> Loss: 1.66279816628\n",
      "Epoch: 25 -> Test Accuracy: 42.36\n",
      "[26, 60] loss: 1.488\n",
      "[26, 120] loss: 1.478\n",
      "[26, 180] loss: 1.453\n",
      "[26, 240] loss: 1.486\n",
      "[26, 300] loss: 1.488\n",
      "[26, 360] loss: 1.494\n",
      "Epoch: 26 -> Loss: 1.56381630898\n",
      "Epoch: 26 -> Test Accuracy: 42.12\n",
      "[27, 60] loss: 1.477\n",
      "[27, 120] loss: 1.480\n",
      "[27, 180] loss: 1.487\n",
      "[27, 240] loss: 1.477\n",
      "[27, 300] loss: 1.481\n",
      "[27, 360] loss: 1.498\n",
      "Epoch: 27 -> Loss: 1.46698105335\n",
      "Epoch: 27 -> Test Accuracy: 43.05\n",
      "[28, 60] loss: 1.462\n",
      "[28, 120] loss: 1.491\n",
      "[28, 180] loss: 1.490\n",
      "[28, 240] loss: 1.463\n",
      "[28, 300] loss: 1.491\n",
      "[28, 360] loss: 1.464\n",
      "Epoch: 28 -> Loss: 1.41257596016\n",
      "Epoch: 28 -> Test Accuracy: 42.14\n",
      "[29, 60] loss: 1.481\n",
      "[29, 120] loss: 1.455\n",
      "[29, 180] loss: 1.485\n",
      "[29, 240] loss: 1.473\n",
      "[29, 300] loss: 1.474\n",
      "[29, 360] loss: 1.481\n",
      "Epoch: 29 -> Loss: 1.57031130791\n",
      "Epoch: 29 -> Test Accuracy: 41.08\n",
      "[30, 60] loss: 1.457\n",
      "[30, 120] loss: 1.481\n",
      "[30, 180] loss: 1.476\n",
      "[30, 240] loss: 1.481\n",
      "[30, 300] loss: 1.471\n",
      "[30, 360] loss: 1.485\n",
      "Epoch: 30 -> Loss: 1.37099862099\n",
      "Epoch: 30 -> Test Accuracy: 42.72\n",
      "[31, 60] loss: 1.471\n",
      "[31, 120] loss: 1.470\n",
      "[31, 180] loss: 1.453\n",
      "[31, 240] loss: 1.487\n",
      "[31, 300] loss: 1.485\n",
      "[31, 360] loss: 1.465\n",
      "Epoch: 31 -> Loss: 1.47513151169\n",
      "Epoch: 31 -> Test Accuracy: 39.76\n",
      "[32, 60] loss: 1.469\n",
      "[32, 120] loss: 1.469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 180] loss: 1.474\n",
      "[32, 240] loss: 1.490\n",
      "[32, 300] loss: 1.478\n",
      "[32, 360] loss: 1.476\n",
      "Epoch: 32 -> Loss: 1.24911093712\n",
      "Epoch: 32 -> Test Accuracy: 42.41\n",
      "[33, 60] loss: 1.478\n",
      "[33, 120] loss: 1.466\n",
      "[33, 180] loss: 1.465\n",
      "[33, 240] loss: 1.498\n",
      "[33, 300] loss: 1.459\n",
      "[33, 360] loss: 1.484\n",
      "Epoch: 33 -> Loss: 1.49904406071\n",
      "Epoch: 33 -> Test Accuracy: 41.9\n",
      "[34, 60] loss: 1.482\n",
      "[34, 120] loss: 1.452\n",
      "[34, 180] loss: 1.441\n",
      "[34, 240] loss: 1.480\n",
      "[34, 300] loss: 1.499\n",
      "[34, 360] loss: 1.476\n",
      "Epoch: 34 -> Loss: 1.74802398682\n",
      "Epoch: 34 -> Test Accuracy: 42.22\n",
      "[35, 60] loss: 1.471\n",
      "[35, 120] loss: 1.486\n",
      "[35, 180] loss: 1.460\n",
      "[35, 240] loss: 1.495\n",
      "[35, 300] loss: 1.478\n",
      "[35, 360] loss: 1.480\n",
      "Epoch: 35 -> Loss: 1.39175140858\n",
      "Epoch: 35 -> Test Accuracy: 44.02\n",
      "[36, 60] loss: 1.413\n",
      "[36, 120] loss: 1.383\n",
      "[36, 180] loss: 1.374\n",
      "[36, 240] loss: 1.373\n",
      "[36, 300] loss: 1.335\n",
      "[36, 360] loss: 1.360\n",
      "Epoch: 36 -> Loss: 1.31976079941\n",
      "Epoch: 36 -> Test Accuracy: 46.04\n",
      "[37, 60] loss: 1.344\n",
      "[37, 120] loss: 1.344\n",
      "[37, 180] loss: 1.338\n",
      "[37, 240] loss: 1.353\n",
      "[37, 300] loss: 1.356\n",
      "[37, 360] loss: 1.357\n",
      "Epoch: 37 -> Loss: 1.42699706554\n",
      "Epoch: 37 -> Test Accuracy: 46.67\n",
      "[38, 60] loss: 1.347\n",
      "[38, 120] loss: 1.336\n",
      "[38, 180] loss: 1.341\n",
      "[38, 240] loss: 1.344\n",
      "[38, 300] loss: 1.339\n",
      "[38, 360] loss: 1.357\n",
      "Epoch: 38 -> Loss: 1.34167742729\n",
      "Epoch: 38 -> Test Accuracy: 46.16\n",
      "[39, 60] loss: 1.347\n",
      "[39, 120] loss: 1.343\n",
      "[39, 180] loss: 1.342\n",
      "[39, 240] loss: 1.340\n",
      "[39, 300] loss: 1.338\n",
      "[39, 360] loss: 1.340\n",
      "Epoch: 39 -> Loss: 1.35274672508\n",
      "Epoch: 39 -> Test Accuracy: 46.64\n",
      "[40, 60] loss: 1.352\n",
      "[40, 120] loss: 1.348\n",
      "[40, 180] loss: 1.340\n",
      "[40, 240] loss: 1.329\n",
      "[40, 300] loss: 1.340\n",
      "[40, 360] loss: 1.329\n",
      "Epoch: 40 -> Loss: 1.21584248543\n",
      "Epoch: 40 -> Test Accuracy: 46.58\n",
      "[41, 60] loss: 1.324\n",
      "[41, 120] loss: 1.341\n",
      "[41, 180] loss: 1.335\n",
      "[41, 240] loss: 1.352\n",
      "[41, 300] loss: 1.360\n",
      "[41, 360] loss: 1.329\n",
      "Epoch: 41 -> Loss: 1.22676551342\n",
      "Epoch: 41 -> Test Accuracy: 46.91\n",
      "[42, 60] loss: 1.351\n",
      "[42, 120] loss: 1.327\n",
      "[42, 180] loss: 1.329\n",
      "[42, 240] loss: 1.316\n",
      "[42, 300] loss: 1.356\n",
      "[42, 360] loss: 1.354\n",
      "Epoch: 42 -> Loss: 1.4264652729\n",
      "Epoch: 42 -> Test Accuracy: 46.77\n",
      "[43, 60] loss: 1.324\n",
      "[43, 120] loss: 1.352\n",
      "[43, 180] loss: 1.348\n",
      "[43, 240] loss: 1.320\n",
      "[43, 300] loss: 1.336\n",
      "[43, 360] loss: 1.336\n",
      "Epoch: 43 -> Loss: 1.18330848217\n",
      "Epoch: 43 -> Test Accuracy: 46.79\n",
      "[44, 60] loss: 1.326\n",
      "[44, 120] loss: 1.333\n",
      "[44, 180] loss: 1.350\n",
      "[44, 240] loss: 1.341\n",
      "[44, 300] loss: 1.345\n",
      "[44, 360] loss: 1.329\n",
      "Epoch: 44 -> Loss: 1.38185465336\n",
      "Epoch: 44 -> Test Accuracy: 47.23\n",
      "[45, 60] loss: 1.340\n",
      "[45, 120] loss: 1.322\n",
      "[45, 180] loss: 1.350\n",
      "[45, 240] loss: 1.322\n",
      "[45, 300] loss: 1.335\n",
      "[45, 360] loss: 1.333\n",
      "Epoch: 45 -> Loss: 1.22677397728\n",
      "Epoch: 45 -> Test Accuracy: 46.62\n",
      "[46, 60] loss: 1.343\n",
      "[46, 120] loss: 1.337\n",
      "[46, 180] loss: 1.316\n",
      "[46, 240] loss: 1.315\n",
      "[46, 300] loss: 1.323\n",
      "[46, 360] loss: 1.359\n",
      "Epoch: 46 -> Loss: 1.50630879402\n",
      "Epoch: 46 -> Test Accuracy: 46.01\n",
      "[47, 60] loss: 1.342\n",
      "[47, 120] loss: 1.341\n",
      "[47, 180] loss: 1.352\n",
      "[47, 240] loss: 1.341\n",
      "[47, 300] loss: 1.323\n",
      "[47, 360] loss: 1.306\n",
      "Epoch: 47 -> Loss: 1.33651387691\n",
      "Epoch: 47 -> Test Accuracy: 46.2\n",
      "[48, 60] loss: 1.332\n",
      "[48, 120] loss: 1.318\n",
      "[48, 180] loss: 1.331\n",
      "[48, 240] loss: 1.351\n",
      "[48, 300] loss: 1.342\n",
      "[48, 360] loss: 1.328\n",
      "Epoch: 48 -> Loss: 1.20408606529\n",
      "Epoch: 48 -> Test Accuracy: 47.84\n",
      "[49, 60] loss: 1.335\n",
      "[49, 120] loss: 1.332\n",
      "[49, 180] loss: 1.334\n",
      "[49, 240] loss: 1.344\n",
      "[49, 300] loss: 1.321\n",
      "[49, 360] loss: 1.348\n",
      "Epoch: 49 -> Loss: 1.21405446529\n",
      "Epoch: 49 -> Test Accuracy: 46.72\n",
      "[50, 60] loss: 1.355\n",
      "[50, 120] loss: 1.332\n",
      "[50, 180] loss: 1.329\n",
      "[50, 240] loss: 1.343\n",
      "[50, 300] loss: 1.340\n",
      "[50, 360] loss: 1.335\n",
      "Epoch: 50 -> Loss: 1.20776414871\n",
      "Epoch: 50 -> Test Accuracy: 46.76\n",
      "[51, 60] loss: 1.347\n",
      "[51, 120] loss: 1.342\n",
      "[51, 180] loss: 1.315\n",
      "[51, 240] loss: 1.347\n",
      "[51, 300] loss: 1.309\n",
      "[51, 360] loss: 1.324\n",
      "Epoch: 51 -> Loss: 1.37042307854\n",
      "Epoch: 51 -> Test Accuracy: 46.59\n",
      "[52, 60] loss: 1.345\n",
      "[52, 120] loss: 1.342\n",
      "[52, 180] loss: 1.335\n",
      "[52, 240] loss: 1.342\n",
      "[52, 300] loss: 1.345\n",
      "[52, 360] loss: 1.333\n",
      "Epoch: 52 -> Loss: 1.45682871342\n",
      "Epoch: 52 -> Test Accuracy: 46.19\n",
      "[53, 60] loss: 1.313\n",
      "[53, 120] loss: 1.346\n",
      "[53, 180] loss: 1.350\n",
      "[53, 240] loss: 1.339\n",
      "[53, 300] loss: 1.341\n",
      "[53, 360] loss: 1.308\n",
      "Epoch: 53 -> Loss: 1.42852306366\n",
      "Epoch: 53 -> Test Accuracy: 47.55\n",
      "[54, 60] loss: 1.317\n",
      "[54, 120] loss: 1.350\n",
      "[54, 180] loss: 1.341\n",
      "[54, 240] loss: 1.328\n",
      "[54, 300] loss: 1.333\n",
      "[54, 360] loss: 1.321\n",
      "Epoch: 54 -> Loss: 1.6283352375\n",
      "Epoch: 54 -> Test Accuracy: 46.9\n",
      "[55, 60] loss: 1.332\n",
      "[55, 120] loss: 1.342\n",
      "[55, 180] loss: 1.353\n",
      "[55, 240] loss: 1.334\n",
      "[55, 300] loss: 1.356\n",
      "[55, 360] loss: 1.332\n",
      "Epoch: 55 -> Loss: 1.23243916035\n",
      "Epoch: 55 -> Test Accuracy: 45.35\n",
      "[56, 60] loss: 1.326\n",
      "[56, 120] loss: 1.329\n",
      "[56, 180] loss: 1.330\n",
      "[56, 240] loss: 1.323\n",
      "[56, 300] loss: 1.331\n",
      "[56, 360] loss: 1.322\n",
      "Epoch: 56 -> Loss: 1.49456393719\n",
      "Epoch: 56 -> Test Accuracy: 46.24\n",
      "[57, 60] loss: 1.309\n",
      "[57, 120] loss: 1.348\n",
      "[57, 180] loss: 1.329\n",
      "[57, 240] loss: 1.344\n",
      "[57, 300] loss: 1.339\n",
      "[57, 360] loss: 1.327\n",
      "Epoch: 57 -> Loss: 1.23918163776\n",
      "Epoch: 57 -> Test Accuracy: 46.93\n",
      "[58, 60] loss: 1.342\n",
      "[58, 120] loss: 1.314\n",
      "[58, 180] loss: 1.318\n",
      "[58, 240] loss: 1.332\n",
      "[58, 300] loss: 1.336\n",
      "[58, 360] loss: 1.330\n",
      "Epoch: 58 -> Loss: 1.23237967491\n",
      "Epoch: 58 -> Test Accuracy: 47.05\n",
      "[59, 60] loss: 1.328\n",
      "[59, 120] loss: 1.325\n",
      "[59, 180] loss: 1.326\n",
      "[59, 240] loss: 1.329\n",
      "[59, 300] loss: 1.346\n",
      "[59, 360] loss: 1.336\n",
      "Epoch: 59 -> Loss: 1.4707262516\n",
      "Epoch: 59 -> Test Accuracy: 47.39\n",
      "[60, 60] loss: 1.326\n",
      "[60, 120] loss: 1.328\n",
      "[60, 180] loss: 1.347\n",
      "[60, 240] loss: 1.340\n",
      "[60, 300] loss: 1.338\n",
      "[60, 360] loss: 1.329\n",
      "Epoch: 60 -> Loss: 1.22872769833\n",
      "Epoch: 60 -> Test Accuracy: 47.38\n",
      "[61, 60] loss: 1.332\n",
      "[61, 120] loss: 1.349\n",
      "[61, 180] loss: 1.317\n",
      "[61, 240] loss: 1.361\n",
      "[61, 300] loss: 1.322\n",
      "[61, 360] loss: 1.339\n",
      "Epoch: 61 -> Loss: 1.34468150139\n",
      "Epoch: 61 -> Test Accuracy: 46.82\n",
      "[62, 60] loss: 1.337\n",
      "[62, 120] loss: 1.323\n",
      "[62, 180] loss: 1.325\n",
      "[62, 240] loss: 1.353\n",
      "[62, 300] loss: 1.333\n",
      "[62, 360] loss: 1.329\n",
      "Epoch: 62 -> Loss: 1.23793375492\n",
      "Epoch: 62 -> Test Accuracy: 46.15\n",
      "[63, 60] loss: 1.315\n",
      "[63, 120] loss: 1.333\n",
      "[63, 180] loss: 1.331\n",
      "[63, 240] loss: 1.324\n",
      "[63, 300] loss: 1.314\n",
      "[63, 360] loss: 1.322\n",
      "Epoch: 63 -> Loss: 1.23091876507\n",
      "Epoch: 63 -> Test Accuracy: 46.45\n",
      "[64, 60] loss: 1.327\n",
      "[64, 120] loss: 1.336\n",
      "[64, 180] loss: 1.330\n",
      "[64, 240] loss: 1.311\n",
      "[64, 300] loss: 1.346\n",
      "[64, 360] loss: 1.332\n",
      "Epoch: 64 -> Loss: 1.13114273548\n",
      "Epoch: 64 -> Test Accuracy: 47.77\n",
      "[65, 60] loss: 1.352\n",
      "[65, 120] loss: 1.323\n",
      "[65, 180] loss: 1.355\n",
      "[65, 240] loss: 1.348\n",
      "[65, 300] loss: 1.319\n",
      "[65, 360] loss: 1.319\n",
      "Epoch: 65 -> Loss: 1.25970065594\n",
      "Epoch: 65 -> Test Accuracy: 47.21\n",
      "[66, 60] loss: 1.316\n",
      "[66, 120] loss: 1.326\n",
      "[66, 180] loss: 1.323\n",
      "[66, 240] loss: 1.343\n",
      "[66, 300] loss: 1.315\n",
      "[66, 360] loss: 1.344\n",
      "Epoch: 66 -> Loss: 1.30671179295\n",
      "Epoch: 66 -> Test Accuracy: 46.54\n",
      "[67, 60] loss: 1.343\n",
      "[67, 120] loss: 1.331\n",
      "[67, 180] loss: 1.303\n",
      "[67, 240] loss: 1.337\n",
      "[67, 300] loss: 1.344\n",
      "[67, 360] loss: 1.303\n",
      "Epoch: 67 -> Loss: 1.25397014618\n",
      "Epoch: 67 -> Test Accuracy: 46.52\n",
      "[68, 60] loss: 1.323\n",
      "[68, 120] loss: 1.339\n",
      "[68, 180] loss: 1.324\n",
      "[68, 240] loss: 1.316\n",
      "[68, 300] loss: 1.330\n",
      "[68, 360] loss: 1.318\n",
      "Epoch: 68 -> Loss: 1.50258708\n",
      "Epoch: 68 -> Test Accuracy: 47.25\n",
      "[69, 60] loss: 1.344\n",
      "[69, 120] loss: 1.344\n",
      "[69, 180] loss: 1.339\n",
      "[69, 240] loss: 1.312\n",
      "[69, 300] loss: 1.324\n",
      "[69, 360] loss: 1.346\n",
      "Epoch: 69 -> Loss: 1.42313313484\n",
      "Epoch: 69 -> Test Accuracy: 47.53\n",
      "[70, 60] loss: 1.322\n",
      "[70, 120] loss: 1.347\n",
      "[70, 180] loss: 1.340\n",
      "[70, 240] loss: 1.338\n",
      "[70, 300] loss: 1.320\n",
      "[70, 360] loss: 1.333\n",
      "Epoch: 70 -> Loss: 1.25750851631\n",
      "Epoch: 70 -> Test Accuracy: 46.87\n",
      "[71, 60] loss: 1.289\n",
      "[71, 120] loss: 1.265\n",
      "[71, 180] loss: 1.266\n",
      "[71, 240] loss: 1.236\n",
      "[71, 300] loss: 1.268\n",
      "[71, 360] loss: 1.241\n",
      "Epoch: 71 -> Loss: 1.24966061115\n",
      "Epoch: 71 -> Test Accuracy: 49.7\n",
      "[72, 60] loss: 1.260\n",
      "[72, 120] loss: 1.258\n",
      "[72, 180] loss: 1.232\n",
      "[72, 240] loss: 1.241\n",
      "[72, 300] loss: 1.261\n",
      "[72, 360] loss: 1.233\n",
      "Epoch: 72 -> Loss: 1.30978178978\n",
      "Epoch: 72 -> Test Accuracy: 49.3\n",
      "[73, 60] loss: 1.248\n",
      "[73, 120] loss: 1.240\n",
      "[73, 180] loss: 1.235\n",
      "[73, 240] loss: 1.230\n",
      "[73, 300] loss: 1.243\n",
      "[73, 360] loss: 1.231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 -> Loss: 1.25063586235\n",
      "Epoch: 73 -> Test Accuracy: 49.98\n",
      "[74, 60] loss: 1.218\n",
      "[74, 120] loss: 1.233\n",
      "[74, 180] loss: 1.229\n",
      "[74, 240] loss: 1.230\n",
      "[74, 300] loss: 1.248\n",
      "[74, 360] loss: 1.216\n",
      "Epoch: 74 -> Loss: 1.25857186317\n",
      "Epoch: 74 -> Test Accuracy: 49.84\n",
      "[75, 60] loss: 1.229\n",
      "[75, 120] loss: 1.231\n",
      "[75, 180] loss: 1.224\n",
      "[75, 240] loss: 1.227\n",
      "[75, 300] loss: 1.243\n",
      "[75, 360] loss: 1.239\n",
      "Epoch: 75 -> Loss: 1.43307590485\n",
      "Epoch: 75 -> Test Accuracy: 50.78\n",
      "[76, 60] loss: 1.230\n",
      "[76, 120] loss: 1.233\n",
      "[76, 180] loss: 1.243\n",
      "[76, 240] loss: 1.235\n",
      "[76, 300] loss: 1.225\n",
      "[76, 360] loss: 1.231\n",
      "Epoch: 76 -> Loss: 1.17694818974\n",
      "Epoch: 76 -> Test Accuracy: 50.06\n",
      "[77, 60] loss: 1.245\n",
      "[77, 120] loss: 1.230\n",
      "[77, 180] loss: 1.200\n",
      "[77, 240] loss: 1.241\n",
      "[77, 300] loss: 1.233\n",
      "[77, 360] loss: 1.221\n",
      "Epoch: 77 -> Loss: 1.06681239605\n",
      "Epoch: 77 -> Test Accuracy: 50.04\n",
      "[78, 60] loss: 1.220\n",
      "[78, 120] loss: 1.219\n",
      "[78, 180] loss: 1.237\n",
      "[78, 240] loss: 1.223\n",
      "[78, 300] loss: 1.222\n",
      "[78, 360] loss: 1.215\n",
      "Epoch: 78 -> Loss: 1.30192053318\n",
      "Epoch: 78 -> Test Accuracy: 49.88\n",
      "[79, 60] loss: 1.221\n",
      "[79, 120] loss: 1.224\n",
      "[79, 180] loss: 1.198\n",
      "[79, 240] loss: 1.213\n",
      "[79, 300] loss: 1.226\n",
      "[79, 360] loss: 1.251\n",
      "Epoch: 79 -> Loss: 1.05998766422\n",
      "Epoch: 79 -> Test Accuracy: 50.32\n",
      "[80, 60] loss: 1.217\n",
      "[80, 120] loss: 1.242\n",
      "[80, 180] loss: 1.226\n",
      "[80, 240] loss: 1.231\n",
      "[80, 300] loss: 1.216\n",
      "[80, 360] loss: 1.235\n",
      "Epoch: 80 -> Loss: 1.2868783474\n",
      "Epoch: 80 -> Test Accuracy: 49.97\n",
      "[81, 60] loss: 1.220\n",
      "[81, 120] loss: 1.230\n",
      "[81, 180] loss: 1.204\n",
      "[81, 240] loss: 1.213\n",
      "[81, 300] loss: 1.236\n",
      "[81, 360] loss: 1.231\n",
      "Epoch: 81 -> Loss: 1.09875941277\n",
      "Epoch: 81 -> Test Accuracy: 50.43\n",
      "[82, 60] loss: 1.219\n",
      "[82, 120] loss: 1.226\n",
      "[82, 180] loss: 1.227\n",
      "[82, 240] loss: 1.213\n",
      "[82, 300] loss: 1.230\n",
      "[82, 360] loss: 1.219\n",
      "Epoch: 82 -> Loss: 1.05632829666\n",
      "Epoch: 82 -> Test Accuracy: 50.31\n",
      "[83, 60] loss: 1.217\n",
      "[83, 120] loss: 1.211\n",
      "[83, 180] loss: 1.213\n",
      "[83, 240] loss: 1.228\n",
      "[83, 300] loss: 1.227\n",
      "[83, 360] loss: 1.232\n",
      "Epoch: 83 -> Loss: 1.20097947121\n",
      "Epoch: 83 -> Test Accuracy: 49.99\n",
      "[84, 60] loss: 1.225\n",
      "[84, 120] loss: 1.223\n",
      "[84, 180] loss: 1.224\n",
      "[84, 240] loss: 1.232\n",
      "[84, 300] loss: 1.232\n",
      "[84, 360] loss: 1.228\n",
      "Epoch: 84 -> Loss: 1.1697614193\n",
      "Epoch: 84 -> Test Accuracy: 50.36\n",
      "[85, 60] loss: 1.227\n",
      "[85, 120] loss: 1.218\n",
      "[85, 180] loss: 1.221\n",
      "[85, 240] loss: 1.207\n",
      "[85, 300] loss: 1.245\n",
      "[85, 360] loss: 1.248\n",
      "Epoch: 85 -> Loss: 0.971636652946\n",
      "Epoch: 85 -> Test Accuracy: 50.63\n",
      "[86, 60] loss: 1.211\n",
      "[86, 120] loss: 1.199\n",
      "[86, 180] loss: 1.197\n",
      "[86, 240] loss: 1.190\n",
      "[86, 300] loss: 1.184\n",
      "[86, 360] loss: 1.188\n",
      "Epoch: 86 -> Loss: 1.31397712231\n",
      "Epoch: 86 -> Test Accuracy: 51.55\n",
      "[87, 60] loss: 1.210\n",
      "[87, 120] loss: 1.204\n",
      "[87, 180] loss: 1.185\n",
      "[87, 240] loss: 1.188\n",
      "[87, 300] loss: 1.172\n",
      "[87, 360] loss: 1.189\n",
      "Epoch: 87 -> Loss: 1.29495596886\n",
      "Epoch: 87 -> Test Accuracy: 51.35\n",
      "[88, 60] loss: 1.192\n",
      "[88, 120] loss: 1.209\n",
      "[88, 180] loss: 1.182\n",
      "[88, 240] loss: 1.187\n",
      "[88, 300] loss: 1.184\n",
      "[88, 360] loss: 1.173\n",
      "Epoch: 88 -> Loss: 1.14376974106\n",
      "Epoch: 88 -> Test Accuracy: 51.76\n",
      "[89, 60] loss: 1.175\n",
      "[89, 120] loss: 1.163\n",
      "[89, 180] loss: 1.198\n",
      "[89, 240] loss: 1.187\n",
      "[89, 300] loss: 1.190\n",
      "[89, 360] loss: 1.193\n",
      "Epoch: 89 -> Loss: 1.01887774467\n",
      "Epoch: 89 -> Test Accuracy: 51.57\n",
      "[90, 60] loss: 1.182\n",
      "[90, 120] loss: 1.191\n",
      "[90, 180] loss: 1.174\n",
      "[90, 240] loss: 1.171\n",
      "[90, 300] loss: 1.194\n",
      "[90, 360] loss: 1.190\n",
      "Epoch: 90 -> Loss: 1.12466394901\n",
      "Epoch: 90 -> Test Accuracy: 51.74\n",
      "[91, 60] loss: 1.191\n",
      "[91, 120] loss: 1.154\n",
      "[91, 180] loss: 1.183\n",
      "[91, 240] loss: 1.182\n",
      "[91, 300] loss: 1.207\n",
      "[91, 360] loss: 1.171\n",
      "Epoch: 91 -> Loss: 1.2382324934\n",
      "Epoch: 91 -> Test Accuracy: 51.29\n",
      "[92, 60] loss: 1.186\n",
      "[92, 120] loss: 1.156\n",
      "[92, 180] loss: 1.188\n",
      "[92, 240] loss: 1.173\n",
      "[92, 300] loss: 1.190\n",
      "[92, 360] loss: 1.184\n",
      "Epoch: 92 -> Loss: 1.21876358986\n",
      "Epoch: 92 -> Test Accuracy: 51.11\n",
      "[93, 60] loss: 1.185\n",
      "[93, 120] loss: 1.172\n",
      "[93, 180] loss: 1.173\n",
      "[93, 240] loss: 1.184\n",
      "[93, 300] loss: 1.170\n",
      "[93, 360] loss: 1.181\n",
      "Epoch: 93 -> Loss: 1.11875629425\n",
      "Epoch: 93 -> Test Accuracy: 51.56\n",
      "[94, 60] loss: 1.177\n",
      "[94, 120] loss: 1.183\n",
      "[94, 180] loss: 1.166\n",
      "[94, 240] loss: 1.178\n",
      "[94, 300] loss: 1.182\n",
      "[94, 360] loss: 1.167\n",
      "Epoch: 94 -> Loss: 1.04624533653\n",
      "Epoch: 94 -> Test Accuracy: 51.81\n",
      "[95, 60] loss: 1.174\n",
      "[95, 120] loss: 1.180\n",
      "[95, 180] loss: 1.188\n",
      "[95, 240] loss: 1.167\n",
      "[95, 300] loss: 1.181\n",
      "[95, 360] loss: 1.181\n",
      "Epoch: 95 -> Loss: 1.15826714039\n",
      "Epoch: 95 -> Test Accuracy: 52.06\n",
      "[96, 60] loss: 1.180\n",
      "[96, 120] loss: 1.180\n",
      "[96, 180] loss: 1.179\n",
      "[96, 240] loss: 1.177\n",
      "[96, 300] loss: 1.203\n",
      "[96, 360] loss: 1.184\n",
      "Epoch: 96 -> Loss: 1.36237049103\n",
      "Epoch: 96 -> Test Accuracy: 51.5\n",
      "[97, 60] loss: 1.167\n",
      "[97, 120] loss: 1.178\n",
      "[97, 180] loss: 1.183\n",
      "[97, 240] loss: 1.164\n",
      "[97, 300] loss: 1.157\n",
      "[97, 360] loss: 1.165\n",
      "Epoch: 97 -> Loss: 1.19783329964\n",
      "Epoch: 97 -> Test Accuracy: 51.94\n",
      "[98, 60] loss: 1.156\n",
      "[98, 120] loss: 1.177\n",
      "[98, 180] loss: 1.174\n",
      "[98, 240] loss: 1.186\n",
      "[98, 300] loss: 1.168\n",
      "[98, 360] loss: 1.196\n",
      "Epoch: 98 -> Loss: 1.22145962715\n",
      "Epoch: 98 -> Test Accuracy: 52.29\n",
      "[99, 60] loss: 1.167\n",
      "[99, 120] loss: 1.168\n",
      "[99, 180] loss: 1.160\n",
      "[99, 240] loss: 1.159\n",
      "[99, 300] loss: 1.178\n",
      "[99, 360] loss: 1.182\n",
      "Epoch: 99 -> Loss: 1.09632265568\n",
      "Epoch: 99 -> Test Accuracy: 51.46\n",
      "[100, 60] loss: 1.171\n",
      "[100, 120] loss: 1.151\n",
      "[100, 180] loss: 1.162\n",
      "[100, 240] loss: 1.183\n",
      "[100, 300] loss: 1.181\n",
      "[100, 360] loss: 1.167\n",
      "Epoch: 100 -> Loss: 1.21928215027\n",
      "Epoch: 100 -> Test Accuracy: 51.7\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train ConvClassifiers on feature map of net_3block\n",
    "conv_block4_loss_log, conv_block4_valid_accuracy_log, conv_block4_test_accuracy_log, conv_block4_max_accuracy, \\\n",
    "conv_block4_best_epoch = tr.train_all_blocks(4, 10, [0.1, 0.02, 0.004, 0.0008], [35, 70, 85, 100], 0.9, 5e-4, net_block4, \n",
    "                                            criterion, trainloader, None, testloader, use_ConvClassifier=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename files\n",
    "fm.add_block_to_name(4, [100, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Block RotNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "net_block5 = RN.RotNet(num_classes=4, num_conv_block=5, add_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.142\n",
      "[1, 120] loss: 1.011\n",
      "[1, 180] loss: 0.954\n",
      "[1, 240] loss: 0.917\n",
      "[1, 300] loss: 0.865\n",
      "[1, 360] loss: 0.820\n",
      "Epoch: 1 -> Loss: 0.879907727242\n",
      "Epoch: 1 -> Test Accuracy: 67.0625\n",
      "[2, 60] loss: 0.780\n",
      "[2, 120] loss: 0.766\n",
      "[2, 180] loss: 0.746\n",
      "[2, 240] loss: 0.706\n",
      "[2, 300] loss: 0.698\n",
      "[2, 360] loss: 0.685\n",
      "Epoch: 2 -> Loss: 0.653258621693\n",
      "Epoch: 2 -> Test Accuracy: 73.2325\n",
      "[3, 60] loss: 0.660\n",
      "[3, 120] loss: 0.650\n",
      "[3, 180] loss: 0.637\n",
      "[3, 240] loss: 0.609\n",
      "[3, 300] loss: 0.600\n",
      "[3, 360] loss: 0.598\n",
      "Epoch: 3 -> Loss: 0.649241507053\n",
      "Epoch: 3 -> Test Accuracy: 75.89\n",
      "[4, 60] loss: 0.579\n",
      "[4, 120] loss: 0.575\n",
      "[4, 180] loss: 0.555\n",
      "[4, 240] loss: 0.563\n",
      "[4, 300] loss: 0.568\n",
      "[4, 360] loss: 0.547\n",
      "Epoch: 4 -> Loss: 0.479265928268\n",
      "Epoch: 4 -> Test Accuracy: 78.3525\n",
      "[5, 60] loss: 0.520\n",
      "[5, 120] loss: 0.527\n",
      "[5, 180] loss: 0.523\n",
      "[5, 240] loss: 0.527\n",
      "[5, 300] loss: 0.519\n",
      "[5, 360] loss: 0.514\n",
      "Epoch: 5 -> Loss: 0.413764715195\n",
      "Epoch: 5 -> Test Accuracy: 80.635\n",
      "[6, 60] loss: 0.498\n",
      "[6, 120] loss: 0.483\n",
      "[6, 180] loss: 0.485\n",
      "[6, 240] loss: 0.498\n",
      "[6, 300] loss: 0.492\n",
      "[6, 360] loss: 0.482\n",
      "Epoch: 6 -> Loss: 0.444755852222\n",
      "Epoch: 6 -> Test Accuracy: 80.1375\n",
      "[7, 60] loss: 0.479\n",
      "[7, 120] loss: 0.477\n",
      "[7, 180] loss: 0.469\n",
      "[7, 240] loss: 0.445\n",
      "[7, 300] loss: 0.462\n",
      "[7, 360] loss: 0.455\n",
      "Epoch: 7 -> Loss: 0.536284327507\n",
      "Epoch: 7 -> Test Accuracy: 81.055\n",
      "[8, 60] loss: 0.456\n",
      "[8, 120] loss: 0.445\n",
      "[8, 180] loss: 0.428\n",
      "[8, 240] loss: 0.452\n",
      "[8, 300] loss: 0.447\n",
      "[8, 360] loss: 0.435\n",
      "Epoch: 8 -> Loss: 0.421319097281\n",
      "Epoch: 8 -> Test Accuracy: 82.9725\n",
      "[9, 60] loss: 0.420\n",
      "[9, 120] loss: 0.421\n",
      "[9, 180] loss: 0.431\n",
      "[9, 240] loss: 0.428\n",
      "[9, 300] loss: 0.440\n",
      "[9, 360] loss: 0.425\n",
      "Epoch: 9 -> Loss: 0.40064483881\n",
      "Epoch: 9 -> Test Accuracy: 82.71\n",
      "[10, 60] loss: 0.402\n",
      "[10, 120] loss: 0.414\n",
      "[10, 180] loss: 0.414\n",
      "[10, 240] loss: 0.428\n",
      "[10, 300] loss: 0.429\n",
      "[10, 360] loss: 0.418\n",
      "Epoch: 10 -> Loss: 0.415181785822\n",
      "Epoch: 10 -> Test Accuracy: 82.805\n",
      "[11, 60] loss: 0.399\n",
      "[11, 120] loss: 0.412\n",
      "[11, 180] loss: 0.404\n",
      "[11, 240] loss: 0.418\n",
      "[11, 300] loss: 0.415\n",
      "[11, 360] loss: 0.399\n",
      "Epoch: 11 -> Loss: 0.51422303915\n",
      "Epoch: 11 -> Test Accuracy: 83.105\n",
      "[12, 60] loss: 0.404\n",
      "[12, 120] loss: 0.391\n",
      "[12, 180] loss: 0.426\n",
      "[12, 240] loss: 0.404\n",
      "[12, 300] loss: 0.394\n",
      "[12, 360] loss: 0.402\n",
      "Epoch: 12 -> Loss: 0.520103394985\n",
      "Epoch: 12 -> Test Accuracy: 82.9375\n",
      "[13, 60] loss: 0.390\n",
      "[13, 120] loss: 0.389\n",
      "[13, 180] loss: 0.390\n",
      "[13, 240] loss: 0.379\n",
      "[13, 300] loss: 0.386\n",
      "[13, 360] loss: 0.399\n",
      "Epoch: 13 -> Loss: 0.357770144939\n",
      "Epoch: 13 -> Test Accuracy: 83.9375\n",
      "[14, 60] loss: 0.390\n",
      "[14, 120] loss: 0.377\n",
      "[14, 180] loss: 0.368\n",
      "[14, 240] loss: 0.384\n",
      "[14, 300] loss: 0.388\n",
      "[14, 360] loss: 0.385\n",
      "Epoch: 14 -> Loss: 0.450511038303\n",
      "Epoch: 14 -> Test Accuracy: 84.5625\n",
      "[15, 60] loss: 0.367\n",
      "[15, 120] loss: 0.380\n",
      "[15, 180] loss: 0.377\n",
      "[15, 240] loss: 0.369\n",
      "[15, 300] loss: 0.387\n",
      "[15, 360] loss: 0.367\n",
      "Epoch: 15 -> Loss: 0.401414632797\n",
      "Epoch: 15 -> Test Accuracy: 83.8425\n",
      "[16, 60] loss: 0.375\n",
      "[16, 120] loss: 0.373\n",
      "[16, 180] loss: 0.365\n",
      "[16, 240] loss: 0.362\n",
      "[16, 300] loss: 0.383\n",
      "[16, 360] loss: 0.366\n",
      "Epoch: 16 -> Loss: 0.469763666391\n",
      "Epoch: 16 -> Test Accuracy: 84.8025\n",
      "[17, 60] loss: 0.350\n",
      "[17, 120] loss: 0.353\n",
      "[17, 180] loss: 0.369\n",
      "[17, 240] loss: 0.371\n",
      "[17, 300] loss: 0.381\n",
      "[17, 360] loss: 0.360\n",
      "Epoch: 17 -> Loss: 0.387192934752\n",
      "Epoch: 17 -> Test Accuracy: 85.18\n",
      "[18, 60] loss: 0.344\n",
      "[18, 120] loss: 0.358\n",
      "[18, 180] loss: 0.338\n",
      "[18, 240] loss: 0.366\n",
      "[18, 300] loss: 0.381\n",
      "[18, 360] loss: 0.365\n",
      "Epoch: 18 -> Loss: 0.296323984861\n",
      "Epoch: 18 -> Test Accuracy: 85.2375\n",
      "[19, 60] loss: 0.353\n",
      "[19, 120] loss: 0.353\n",
      "[19, 180] loss: 0.351\n",
      "[19, 240] loss: 0.349\n",
      "[19, 300] loss: 0.360\n",
      "[19, 360] loss: 0.362\n",
      "Epoch: 19 -> Loss: 0.38590914011\n",
      "Epoch: 19 -> Test Accuracy: 85.1175\n",
      "[20, 60] loss: 0.343\n",
      "[20, 120] loss: 0.345\n",
      "[20, 180] loss: 0.355\n",
      "[20, 240] loss: 0.360\n",
      "[20, 300] loss: 0.346\n",
      "[20, 360] loss: 0.350\n",
      "Epoch: 20 -> Loss: 0.248385116458\n",
      "Epoch: 20 -> Test Accuracy: 85.2025\n",
      "[21, 60] loss: 0.337\n",
      "[21, 120] loss: 0.343\n",
      "[21, 180] loss: 0.352\n",
      "[21, 240] loss: 0.335\n",
      "[21, 300] loss: 0.353\n",
      "[21, 360] loss: 0.350\n",
      "Epoch: 21 -> Loss: 0.263547241688\n",
      "Epoch: 21 -> Test Accuracy: 85.0425\n",
      "[22, 60] loss: 0.342\n",
      "[22, 120] loss: 0.336\n",
      "[22, 180] loss: 0.352\n",
      "[22, 240] loss: 0.340\n",
      "[22, 300] loss: 0.338\n",
      "[22, 360] loss: 0.364\n",
      "Epoch: 22 -> Loss: 0.286911606789\n",
      "Epoch: 22 -> Test Accuracy: 86.0575\n",
      "[23, 60] loss: 0.333\n",
      "[23, 120] loss: 0.341\n",
      "[23, 180] loss: 0.335\n",
      "[23, 240] loss: 0.338\n",
      "[23, 300] loss: 0.339\n",
      "[23, 360] loss: 0.344\n",
      "Epoch: 23 -> Loss: 0.464970827103\n",
      "Epoch: 23 -> Test Accuracy: 84.76\n",
      "[24, 60] loss: 0.349\n",
      "[24, 120] loss: 0.340\n",
      "[24, 180] loss: 0.334\n",
      "[24, 240] loss: 0.326\n",
      "[24, 300] loss: 0.331\n",
      "[24, 360] loss: 0.348\n",
      "Epoch: 24 -> Loss: 0.332907795906\n",
      "Epoch: 24 -> Test Accuracy: 85.9775\n",
      "[25, 60] loss: 0.344\n",
      "[25, 120] loss: 0.318\n",
      "[25, 180] loss: 0.342\n",
      "[25, 240] loss: 0.339\n",
      "[25, 300] loss: 0.340\n",
      "[25, 360] loss: 0.327\n",
      "Epoch: 25 -> Loss: 0.343102246523\n",
      "Epoch: 25 -> Test Accuracy: 85.095\n",
      "[26, 60] loss: 0.329\n",
      "[26, 120] loss: 0.325\n",
      "[26, 180] loss: 0.335\n",
      "[26, 240] loss: 0.338\n",
      "[26, 300] loss: 0.332\n",
      "[26, 360] loss: 0.347\n",
      "Epoch: 26 -> Loss: 0.594924092293\n",
      "Epoch: 26 -> Test Accuracy: 86.38\n",
      "[27, 60] loss: 0.328\n",
      "[27, 120] loss: 0.335\n",
      "[27, 180] loss: 0.329\n",
      "[27, 240] loss: 0.326\n",
      "[27, 300] loss: 0.342\n",
      "[27, 360] loss: 0.339\n",
      "Epoch: 27 -> Loss: 0.38805192709\n",
      "Epoch: 27 -> Test Accuracy: 86.13\n",
      "[28, 60] loss: 0.325\n",
      "[28, 120] loss: 0.332\n",
      "[28, 180] loss: 0.344\n",
      "[28, 240] loss: 0.327\n",
      "[28, 300] loss: 0.342\n",
      "[28, 360] loss: 0.334\n",
      "Epoch: 28 -> Loss: 0.422394037247\n",
      "Epoch: 28 -> Test Accuracy: 86.13\n",
      "[29, 60] loss: 0.324\n",
      "[29, 120] loss: 0.322\n",
      "[29, 180] loss: 0.338\n",
      "[29, 240] loss: 0.326\n",
      "[29, 300] loss: 0.323\n",
      "[29, 360] loss: 0.333\n",
      "Epoch: 29 -> Loss: 0.384451806545\n",
      "Epoch: 29 -> Test Accuracy: 85.215\n",
      "[30, 60] loss: 0.317\n",
      "[30, 120] loss: 0.329\n",
      "[30, 180] loss: 0.331\n",
      "[30, 240] loss: 0.325\n",
      "[30, 300] loss: 0.337\n",
      "[30, 360] loss: 0.325\n",
      "Epoch: 30 -> Loss: 0.426101267338\n",
      "Epoch: 30 -> Test Accuracy: 85.435\n",
      "[31, 60] loss: 0.311\n",
      "[31, 120] loss: 0.336\n",
      "[31, 180] loss: 0.320\n",
      "[31, 240] loss: 0.339\n",
      "[31, 300] loss: 0.327\n",
      "[31, 360] loss: 0.317\n",
      "Epoch: 31 -> Loss: 0.247449442744\n",
      "Epoch: 31 -> Test Accuracy: 84.955\n",
      "[32, 60] loss: 0.319\n",
      "[32, 120] loss: 0.322\n",
      "[32, 180] loss: 0.334\n",
      "[32, 240] loss: 0.319\n",
      "[32, 300] loss: 0.316\n",
      "[32, 360] loss: 0.332\n",
      "Epoch: 32 -> Loss: 0.346013247967\n",
      "Epoch: 32 -> Test Accuracy: 86.7325\n",
      "[33, 60] loss: 0.324\n",
      "[33, 120] loss: 0.320\n",
      "[33, 180] loss: 0.329\n",
      "[33, 240] loss: 0.323\n",
      "[33, 300] loss: 0.319\n",
      "[33, 360] loss: 0.331\n",
      "Epoch: 33 -> Loss: 0.440259516239\n",
      "Epoch: 33 -> Test Accuracy: 86.3725\n",
      "[34, 60] loss: 0.314\n",
      "[34, 120] loss: 0.321\n",
      "[34, 180] loss: 0.315\n",
      "[34, 240] loss: 0.323\n",
      "[34, 300] loss: 0.327\n",
      "[34, 360] loss: 0.330\n",
      "Epoch: 34 -> Loss: 0.273518353701\n",
      "Epoch: 34 -> Test Accuracy: 87.125\n",
      "[35, 60] loss: 0.312\n",
      "[35, 120] loss: 0.315\n",
      "[35, 180] loss: 0.332\n",
      "[35, 240] loss: 0.308\n",
      "[35, 300] loss: 0.319\n",
      "[35, 360] loss: 0.336\n",
      "Epoch: 35 -> Loss: 0.366416424513\n",
      "Epoch: 35 -> Test Accuracy: 85.9425\n",
      "[36, 60] loss: 0.312\n",
      "[36, 120] loss: 0.313\n",
      "[36, 180] loss: 0.317\n",
      "[36, 240] loss: 0.318\n",
      "[36, 300] loss: 0.322\n",
      "[36, 360] loss: 0.324\n",
      "Epoch: 36 -> Loss: 0.441331297159\n",
      "Epoch: 36 -> Test Accuracy: 85.815\n",
      "[37, 60] loss: 0.317\n",
      "[37, 120] loss: 0.325\n",
      "[37, 180] loss: 0.319\n",
      "[37, 240] loss: 0.317\n",
      "[37, 300] loss: 0.320\n",
      "[37, 360] loss: 0.319\n",
      "Epoch: 37 -> Loss: 0.295759141445\n",
      "Epoch: 37 -> Test Accuracy: 86.6625\n",
      "[38, 60] loss: 0.311\n",
      "[38, 120] loss: 0.320\n",
      "[38, 180] loss: 0.331\n",
      "[38, 240] loss: 0.298\n",
      "[38, 300] loss: 0.316\n",
      "[38, 360] loss: 0.332\n",
      "Epoch: 38 -> Loss: 0.432757198811\n",
      "Epoch: 38 -> Test Accuracy: 86.0325\n",
      "[39, 60] loss: 0.312\n",
      "[39, 120] loss: 0.319\n",
      "[39, 180] loss: 0.306\n",
      "[39, 240] loss: 0.313\n",
      "[39, 300] loss: 0.323\n",
      "[39, 360] loss: 0.326\n",
      "Epoch: 39 -> Loss: 0.283261060715\n",
      "Epoch: 39 -> Test Accuracy: 85.565\n",
      "[40, 60] loss: 0.318\n",
      "[40, 120] loss: 0.316\n",
      "[40, 180] loss: 0.310\n",
      "[40, 240] loss: 0.309\n",
      "[40, 300] loss: 0.327\n",
      "[40, 360] loss: 0.315\n",
      "Epoch: 40 -> Loss: 0.310457795858\n",
      "Epoch: 40 -> Test Accuracy: 86.15\n",
      "[41, 60] loss: 0.298\n",
      "[41, 120] loss: 0.319\n",
      "[41, 180] loss: 0.320\n",
      "[41, 240] loss: 0.309\n",
      "[41, 300] loss: 0.311\n",
      "[41, 360] loss: 0.310\n",
      "Epoch: 41 -> Loss: 0.243463426828\n",
      "Epoch: 41 -> Test Accuracy: 86.285\n",
      "[42, 60] loss: 0.306\n",
      "[42, 120] loss: 0.310\n",
      "[42, 180] loss: 0.330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 240] loss: 0.316\n",
      "[42, 300] loss: 0.315\n",
      "[42, 360] loss: 0.310\n",
      "Epoch: 42 -> Loss: 0.248992517591\n",
      "Epoch: 42 -> Test Accuracy: 87.4525\n",
      "[43, 60] loss: 0.311\n",
      "[43, 120] loss: 0.313\n",
      "[43, 180] loss: 0.320\n",
      "[43, 240] loss: 0.315\n",
      "[43, 300] loss: 0.306\n",
      "[43, 360] loss: 0.317\n",
      "Epoch: 43 -> Loss: 0.387246131897\n",
      "Epoch: 43 -> Test Accuracy: 85.94\n",
      "[44, 60] loss: 0.307\n",
      "[44, 120] loss: 0.308\n",
      "[44, 180] loss: 0.315\n",
      "[44, 240] loss: 0.322\n",
      "[44, 300] loss: 0.317\n",
      "[44, 360] loss: 0.319\n",
      "Epoch: 44 -> Loss: 0.265714913607\n",
      "Epoch: 44 -> Test Accuracy: 86.92\n",
      "[45, 60] loss: 0.301\n",
      "[45, 120] loss: 0.309\n",
      "[45, 180] loss: 0.310\n",
      "[45, 240] loss: 0.312\n",
      "[45, 300] loss: 0.315\n",
      "[45, 360] loss: 0.315\n",
      "Epoch: 45 -> Loss: 0.405098438263\n",
      "Epoch: 45 -> Test Accuracy: 86.6975\n",
      "[46, 60] loss: 0.301\n",
      "[46, 120] loss: 0.303\n",
      "[46, 180] loss: 0.302\n",
      "[46, 240] loss: 0.316\n",
      "[46, 300] loss: 0.322\n",
      "[46, 360] loss: 0.320\n",
      "Epoch: 46 -> Loss: 0.25601297617\n",
      "Epoch: 46 -> Test Accuracy: 87.5225\n",
      "[47, 60] loss: 0.296\n",
      "[47, 120] loss: 0.309\n",
      "[47, 180] loss: 0.311\n",
      "[47, 240] loss: 0.306\n",
      "[47, 300] loss: 0.316\n",
      "[47, 360] loss: 0.318\n",
      "Epoch: 47 -> Loss: 0.329749912024\n",
      "Epoch: 47 -> Test Accuracy: 85.9275\n",
      "[48, 60] loss: 0.311\n",
      "[48, 120] loss: 0.309\n",
      "[48, 180] loss: 0.302\n",
      "[48, 240] loss: 0.318\n",
      "[48, 300] loss: 0.308\n",
      "[48, 360] loss: 0.311\n",
      "Epoch: 48 -> Loss: 0.263875842094\n",
      "Epoch: 48 -> Test Accuracy: 87.1475\n",
      "[49, 60] loss: 0.306\n",
      "[49, 120] loss: 0.304\n",
      "[49, 180] loss: 0.304\n",
      "[49, 240] loss: 0.319\n",
      "[49, 300] loss: 0.308\n",
      "[49, 360] loss: 0.310\n",
      "Epoch: 49 -> Loss: 0.274224489927\n",
      "Epoch: 49 -> Test Accuracy: 85.915\n",
      "[50, 60] loss: 0.298\n",
      "[50, 120] loss: 0.313\n",
      "[50, 180] loss: 0.320\n",
      "[50, 240] loss: 0.307\n",
      "[50, 300] loss: 0.316\n",
      "[50, 360] loss: 0.302\n",
      "Epoch: 50 -> Loss: 0.35181003809\n",
      "Epoch: 50 -> Test Accuracy: 86.6375\n",
      "[51, 60] loss: 0.301\n",
      "[51, 120] loss: 0.301\n",
      "[51, 180] loss: 0.312\n",
      "[51, 240] loss: 0.303\n",
      "[51, 300] loss: 0.309\n",
      "[51, 360] loss: 0.317\n",
      "Epoch: 51 -> Loss: 0.366768479347\n",
      "Epoch: 51 -> Test Accuracy: 85.8425\n",
      "[52, 60] loss: 0.309\n",
      "[52, 120] loss: 0.293\n",
      "[52, 180] loss: 0.307\n",
      "[52, 240] loss: 0.300\n",
      "[52, 300] loss: 0.314\n",
      "[52, 360] loss: 0.321\n",
      "Epoch: 52 -> Loss: 0.337063014507\n",
      "Epoch: 52 -> Test Accuracy: 86.2775\n",
      "[53, 60] loss: 0.303\n",
      "[53, 120] loss: 0.304\n",
      "[53, 180] loss: 0.322\n",
      "[53, 240] loss: 0.300\n",
      "[53, 300] loss: 0.304\n",
      "[53, 360] loss: 0.305\n",
      "Epoch: 53 -> Loss: 0.319795370102\n",
      "Epoch: 53 -> Test Accuracy: 86.3325\n",
      "[54, 60] loss: 0.311\n",
      "[54, 120] loss: 0.308\n",
      "[54, 180] loss: 0.310\n",
      "[54, 240] loss: 0.310\n",
      "[54, 300] loss: 0.315\n",
      "[54, 360] loss: 0.312\n",
      "Epoch: 54 -> Loss: 0.4050809443\n",
      "Epoch: 54 -> Test Accuracy: 86.5875\n",
      "[55, 60] loss: 0.305\n",
      "[55, 120] loss: 0.313\n",
      "[55, 180] loss: 0.294\n",
      "[55, 240] loss: 0.310\n",
      "[55, 300] loss: 0.309\n",
      "[55, 360] loss: 0.316\n",
      "Epoch: 55 -> Loss: 0.272951424122\n",
      "Epoch: 55 -> Test Accuracy: 87.1375\n",
      "[56, 60] loss: 0.292\n",
      "[56, 120] loss: 0.309\n",
      "[56, 180] loss: 0.309\n",
      "[56, 240] loss: 0.301\n",
      "[56, 300] loss: 0.304\n",
      "[56, 360] loss: 0.309\n",
      "Epoch: 56 -> Loss: 0.300937861204\n",
      "Epoch: 56 -> Test Accuracy: 87.4\n",
      "[57, 60] loss: 0.286\n",
      "[57, 120] loss: 0.310\n",
      "[57, 180] loss: 0.301\n",
      "[57, 240] loss: 0.298\n",
      "[57, 300] loss: 0.320\n",
      "[57, 360] loss: 0.305\n",
      "Epoch: 57 -> Loss: 0.271987140179\n",
      "Epoch: 57 -> Test Accuracy: 87.8725\n",
      "[58, 60] loss: 0.287\n",
      "[58, 120] loss: 0.306\n",
      "[58, 180] loss: 0.307\n",
      "[58, 240] loss: 0.311\n",
      "[58, 300] loss: 0.302\n",
      "[58, 360] loss: 0.315\n",
      "Epoch: 58 -> Loss: 0.23361158371\n",
      "Epoch: 58 -> Test Accuracy: 86.2475\n",
      "[59, 60] loss: 0.308\n",
      "[59, 120] loss: 0.305\n",
      "[59, 180] loss: 0.291\n",
      "[59, 240] loss: 0.312\n",
      "[59, 300] loss: 0.297\n",
      "[59, 360] loss: 0.306\n",
      "Epoch: 59 -> Loss: 0.144916504622\n",
      "Epoch: 59 -> Test Accuracy: 86.2225\n",
      "[60, 60] loss: 0.305\n",
      "[60, 120] loss: 0.292\n",
      "[60, 180] loss: 0.294\n",
      "[60, 240] loss: 0.306\n",
      "[60, 300] loss: 0.301\n",
      "[60, 360] loss: 0.323\n",
      "Epoch: 60 -> Loss: 0.326564013958\n",
      "Epoch: 60 -> Test Accuracy: 87.045\n",
      "[61, 60] loss: 0.229\n",
      "[61, 120] loss: 0.202\n",
      "[61, 180] loss: 0.192\n",
      "[61, 240] loss: 0.192\n",
      "[61, 300] loss: 0.187\n",
      "[61, 360] loss: 0.179\n",
      "Epoch: 61 -> Loss: 0.230574369431\n",
      "Epoch: 61 -> Test Accuracy: 90.9175\n",
      "[62, 60] loss: 0.177\n",
      "[62, 120] loss: 0.165\n",
      "[62, 180] loss: 0.166\n",
      "[62, 240] loss: 0.165\n",
      "[62, 300] loss: 0.175\n",
      "[62, 360] loss: 0.173\n",
      "Epoch: 62 -> Loss: 0.331920176744\n",
      "Epoch: 62 -> Test Accuracy: 91.1525\n",
      "[63, 60] loss: 0.151\n",
      "[63, 120] loss: 0.151\n",
      "[63, 180] loss: 0.165\n",
      "[63, 240] loss: 0.160\n",
      "[63, 300] loss: 0.159\n",
      "[63, 360] loss: 0.168\n",
      "Epoch: 63 -> Loss: 0.138702332973\n",
      "Epoch: 63 -> Test Accuracy: 90.57\n",
      "[64, 60] loss: 0.145\n",
      "[64, 120] loss: 0.152\n",
      "[64, 180] loss: 0.166\n",
      "[64, 240] loss: 0.160\n",
      "[64, 300] loss: 0.153\n",
      "[64, 360] loss: 0.153\n",
      "Epoch: 64 -> Loss: 0.231413796544\n",
      "Epoch: 64 -> Test Accuracy: 90.715\n",
      "[65, 60] loss: 0.146\n",
      "[65, 120] loss: 0.144\n",
      "[65, 180] loss: 0.142\n",
      "[65, 240] loss: 0.161\n",
      "[65, 300] loss: 0.161\n",
      "[65, 360] loss: 0.151\n",
      "Epoch: 65 -> Loss: 0.17717076838\n",
      "Epoch: 65 -> Test Accuracy: 90.41\n",
      "[66, 60] loss: 0.140\n",
      "[66, 120] loss: 0.153\n",
      "[66, 180] loss: 0.134\n",
      "[66, 240] loss: 0.155\n",
      "[66, 300] loss: 0.149\n",
      "[66, 360] loss: 0.157\n",
      "Epoch: 66 -> Loss: 0.206969693303\n",
      "Epoch: 66 -> Test Accuracy: 90.9425\n",
      "[67, 60] loss: 0.140\n",
      "[67, 120] loss: 0.145\n",
      "[67, 180] loss: 0.156\n",
      "[67, 240] loss: 0.147\n",
      "[67, 300] loss: 0.143\n",
      "[67, 360] loss: 0.157\n",
      "Epoch: 67 -> Loss: 0.131964355707\n",
      "Epoch: 67 -> Test Accuracy: 90.615\n",
      "[68, 60] loss: 0.139\n",
      "[68, 120] loss: 0.151\n",
      "[68, 180] loss: 0.148\n",
      "[68, 240] loss: 0.151\n",
      "[68, 300] loss: 0.151\n",
      "[68, 360] loss: 0.154\n",
      "Epoch: 68 -> Loss: 0.159152001143\n",
      "Epoch: 68 -> Test Accuracy: 90.94\n",
      "[69, 60] loss: 0.127\n",
      "[69, 120] loss: 0.141\n",
      "[69, 180] loss: 0.153\n",
      "[69, 240] loss: 0.158\n",
      "[69, 300] loss: 0.155\n",
      "[69, 360] loss: 0.143\n",
      "Epoch: 69 -> Loss: 0.10637755692\n",
      "Epoch: 69 -> Test Accuracy: 90.75\n",
      "[70, 60] loss: 0.141\n",
      "[70, 120] loss: 0.144\n",
      "[70, 180] loss: 0.148\n",
      "[70, 240] loss: 0.148\n",
      "[70, 300] loss: 0.152\n",
      "[70, 360] loss: 0.147\n",
      "Epoch: 70 -> Loss: 0.176977485418\n",
      "Epoch: 70 -> Test Accuracy: 90.53\n",
      "[71, 60] loss: 0.145\n",
      "[71, 120] loss: 0.136\n",
      "[71, 180] loss: 0.154\n",
      "[71, 240] loss: 0.141\n",
      "[71, 300] loss: 0.151\n",
      "[71, 360] loss: 0.159\n",
      "Epoch: 71 -> Loss: 0.0825151652098\n",
      "Epoch: 71 -> Test Accuracy: 90.6075\n",
      "[72, 60] loss: 0.139\n",
      "[72, 120] loss: 0.143\n",
      "[72, 180] loss: 0.154\n",
      "[72, 240] loss: 0.147\n",
      "[72, 300] loss: 0.151\n",
      "[72, 360] loss: 0.153\n",
      "Epoch: 72 -> Loss: 0.154389351606\n",
      "Epoch: 72 -> Test Accuracy: 90.0375\n",
      "[73, 60] loss: 0.144\n",
      "[73, 120] loss: 0.139\n",
      "[73, 180] loss: 0.135\n",
      "[73, 240] loss: 0.157\n",
      "[73, 300] loss: 0.155\n",
      "[73, 360] loss: 0.159\n",
      "Epoch: 73 -> Loss: 0.245061397552\n",
      "Epoch: 73 -> Test Accuracy: 90.34\n",
      "[74, 60] loss: 0.137\n",
      "[74, 120] loss: 0.153\n",
      "[74, 180] loss: 0.141\n",
      "[74, 240] loss: 0.150\n",
      "[74, 300] loss: 0.154\n",
      "[74, 360] loss: 0.154\n",
      "Epoch: 74 -> Loss: 0.0731949210167\n",
      "Epoch: 74 -> Test Accuracy: 90.3275\n",
      "[75, 60] loss: 0.138\n",
      "[75, 120] loss: 0.144\n",
      "[75, 180] loss: 0.147\n",
      "[75, 240] loss: 0.150\n",
      "[75, 300] loss: 0.153\n",
      "[75, 360] loss: 0.159\n",
      "Epoch: 75 -> Loss: 0.153406336904\n",
      "Epoch: 75 -> Test Accuracy: 90.5275\n",
      "[76, 60] loss: 0.143\n",
      "[76, 120] loss: 0.146\n",
      "[76, 180] loss: 0.149\n",
      "[76, 240] loss: 0.149\n",
      "[76, 300] loss: 0.152\n",
      "[76, 360] loss: 0.154\n",
      "Epoch: 76 -> Loss: 0.17255230248\n",
      "Epoch: 76 -> Test Accuracy: 89.9025\n",
      "[77, 60] loss: 0.147\n",
      "[77, 120] loss: 0.152\n",
      "[77, 180] loss: 0.147\n",
      "[77, 240] loss: 0.163\n",
      "[77, 300] loss: 0.151\n",
      "[77, 360] loss: 0.147\n",
      "Epoch: 77 -> Loss: 0.193563193083\n",
      "Epoch: 77 -> Test Accuracy: 90.14\n",
      "[78, 60] loss: 0.138\n",
      "[78, 120] loss: 0.147\n",
      "[78, 180] loss: 0.149\n",
      "[78, 240] loss: 0.152\n",
      "[78, 300] loss: 0.150\n",
      "[78, 360] loss: 0.161\n",
      "Epoch: 78 -> Loss: 0.151032134891\n",
      "Epoch: 78 -> Test Accuracy: 90.345\n",
      "[79, 60] loss: 0.137\n",
      "[79, 120] loss: 0.140\n",
      "[79, 180] loss: 0.160\n",
      "[79, 240] loss: 0.147\n",
      "[79, 300] loss: 0.143\n",
      "[79, 360] loss: 0.160\n",
      "Epoch: 79 -> Loss: 0.172760114074\n",
      "Epoch: 79 -> Test Accuracy: 89.98\n",
      "[80, 60] loss: 0.148\n",
      "[80, 120] loss: 0.138\n",
      "[80, 180] loss: 0.143\n",
      "[80, 240] loss: 0.155\n",
      "[80, 300] loss: 0.155\n",
      "[80, 360] loss: 0.144\n",
      "Epoch: 80 -> Loss: 0.1439050138\n",
      "Epoch: 80 -> Test Accuracy: 89.9925\n",
      "[81, 60] loss: 0.139\n",
      "[81, 120] loss: 0.151\n",
      "[81, 180] loss: 0.147\n",
      "[81, 240] loss: 0.140\n",
      "[81, 300] loss: 0.150\n",
      "[81, 360] loss: 0.149\n",
      "Epoch: 81 -> Loss: 0.199298769236\n",
      "Epoch: 81 -> Test Accuracy: 90.185\n",
      "[82, 60] loss: 0.136\n",
      "[82, 120] loss: 0.143\n",
      "[82, 180] loss: 0.148\n",
      "[82, 240] loss: 0.149\n",
      "[82, 300] loss: 0.152\n",
      "[82, 360] loss: 0.157\n",
      "Epoch: 82 -> Loss: 0.202724501491\n",
      "Epoch: 82 -> Test Accuracy: 90.2525\n",
      "[83, 60] loss: 0.139\n",
      "[83, 120] loss: 0.145\n",
      "[83, 180] loss: 0.145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83, 240] loss: 0.151\n",
      "[83, 300] loss: 0.158\n",
      "[83, 360] loss: 0.157\n",
      "Epoch: 83 -> Loss: 0.0899760276079\n",
      "Epoch: 83 -> Test Accuracy: 90.6475\n",
      "[84, 60] loss: 0.134\n",
      "[84, 120] loss: 0.141\n",
      "[84, 180] loss: 0.156\n",
      "[84, 240] loss: 0.146\n",
      "[84, 300] loss: 0.162\n",
      "[84, 360] loss: 0.155\n",
      "Epoch: 84 -> Loss: 0.180371537805\n",
      "Epoch: 84 -> Test Accuracy: 90.2025\n",
      "[85, 60] loss: 0.139\n",
      "[85, 120] loss: 0.149\n",
      "[85, 180] loss: 0.155\n",
      "[85, 240] loss: 0.146\n",
      "[85, 300] loss: 0.146\n",
      "[85, 360] loss: 0.146\n",
      "Epoch: 85 -> Loss: 0.119351841509\n",
      "Epoch: 85 -> Test Accuracy: 90.3525\n",
      "[86, 60] loss: 0.138\n",
      "[86, 120] loss: 0.148\n",
      "[86, 180] loss: 0.144\n",
      "[86, 240] loss: 0.149\n",
      "[86, 300] loss: 0.144\n",
      "[86, 360] loss: 0.160\n",
      "Epoch: 86 -> Loss: 0.121209181845\n",
      "Epoch: 86 -> Test Accuracy: 89.91\n",
      "[87, 60] loss: 0.139\n",
      "[87, 120] loss: 0.143\n",
      "[87, 180] loss: 0.143\n",
      "[87, 240] loss: 0.146\n",
      "[87, 300] loss: 0.153\n",
      "[87, 360] loss: 0.152\n",
      "Epoch: 87 -> Loss: 0.330755650997\n",
      "Epoch: 87 -> Test Accuracy: 89.5725\n",
      "[88, 60] loss: 0.136\n",
      "[88, 120] loss: 0.148\n",
      "[88, 180] loss: 0.139\n",
      "[88, 240] loss: 0.155\n",
      "[88, 300] loss: 0.144\n",
      "[88, 360] loss: 0.158\n",
      "Epoch: 88 -> Loss: 0.162965506315\n",
      "Epoch: 88 -> Test Accuracy: 90.4\n",
      "[89, 60] loss: 0.126\n",
      "[89, 120] loss: 0.149\n",
      "[89, 180] loss: 0.153\n",
      "[89, 240] loss: 0.141\n",
      "[89, 300] loss: 0.151\n",
      "[89, 360] loss: 0.149\n",
      "Epoch: 89 -> Loss: 0.175088986754\n",
      "Epoch: 89 -> Test Accuracy: 90.315\n",
      "[90, 60] loss: 0.138\n",
      "[90, 120] loss: 0.135\n",
      "[90, 180] loss: 0.142\n",
      "[90, 240] loss: 0.145\n",
      "[90, 300] loss: 0.157\n",
      "[90, 360] loss: 0.146\n",
      "Epoch: 90 -> Loss: 0.0634703412652\n",
      "Epoch: 90 -> Test Accuracy: 90.155\n",
      "[91, 60] loss: 0.132\n",
      "[91, 120] loss: 0.141\n",
      "[91, 180] loss: 0.142\n",
      "[91, 240] loss: 0.143\n",
      "[91, 300] loss: 0.150\n",
      "[91, 360] loss: 0.152\n",
      "Epoch: 91 -> Loss: 0.138421192765\n",
      "Epoch: 91 -> Test Accuracy: 90.255\n",
      "[92, 60] loss: 0.132\n",
      "[92, 120] loss: 0.137\n",
      "[92, 180] loss: 0.133\n",
      "[92, 240] loss: 0.141\n",
      "[92, 300] loss: 0.158\n",
      "[92, 360] loss: 0.153\n",
      "Epoch: 92 -> Loss: 0.107471987605\n",
      "Epoch: 92 -> Test Accuracy: 90.2675\n",
      "[93, 60] loss: 0.128\n",
      "[93, 120] loss: 0.139\n",
      "[93, 180] loss: 0.144\n",
      "[93, 240] loss: 0.153\n",
      "[93, 300] loss: 0.143\n",
      "[93, 360] loss: 0.152\n",
      "Epoch: 93 -> Loss: 0.188422054052\n",
      "Epoch: 93 -> Test Accuracy: 90.2675\n",
      "[94, 60] loss: 0.139\n",
      "[94, 120] loss: 0.138\n",
      "[94, 180] loss: 0.140\n",
      "[94, 240] loss: 0.148\n",
      "[94, 300] loss: 0.145\n",
      "[94, 360] loss: 0.156\n",
      "Epoch: 94 -> Loss: 0.111334644258\n",
      "Epoch: 94 -> Test Accuracy: 90.27\n",
      "[95, 60] loss: 0.131\n",
      "[95, 120] loss: 0.139\n",
      "[95, 180] loss: 0.133\n",
      "[95, 240] loss: 0.142\n",
      "[95, 300] loss: 0.142\n",
      "[95, 360] loss: 0.147\n",
      "Epoch: 95 -> Loss: 0.122192241251\n",
      "Epoch: 95 -> Test Accuracy: 89.8875\n",
      "[96, 60] loss: 0.135\n",
      "[96, 120] loss: 0.138\n",
      "[96, 180] loss: 0.142\n",
      "[96, 240] loss: 0.146\n",
      "[96, 300] loss: 0.146\n",
      "[96, 360] loss: 0.145\n",
      "Epoch: 96 -> Loss: 0.136244103312\n",
      "Epoch: 96 -> Test Accuracy: 90.4175\n",
      "[97, 60] loss: 0.127\n",
      "[97, 120] loss: 0.138\n",
      "[97, 180] loss: 0.144\n",
      "[97, 240] loss: 0.143\n",
      "[97, 300] loss: 0.142\n",
      "[97, 360] loss: 0.143\n",
      "Epoch: 97 -> Loss: 0.0885021612048\n",
      "Epoch: 97 -> Test Accuracy: 89.34\n",
      "[98, 60] loss: 0.135\n",
      "[98, 120] loss: 0.141\n",
      "[98, 180] loss: 0.144\n",
      "[98, 240] loss: 0.141\n",
      "[98, 300] loss: 0.149\n",
      "[98, 360] loss: 0.140\n",
      "Epoch: 98 -> Loss: 0.144317850471\n",
      "Epoch: 98 -> Test Accuracy: 90.365\n",
      "[99, 60] loss: 0.136\n",
      "[99, 120] loss: 0.144\n",
      "[99, 180] loss: 0.142\n",
      "[99, 240] loss: 0.134\n",
      "[99, 300] loss: 0.151\n",
      "[99, 360] loss: 0.141\n",
      "Epoch: 99 -> Loss: 0.142362624407\n",
      "Epoch: 99 -> Test Accuracy: 90.2075\n",
      "[100, 60] loss: 0.126\n",
      "[100, 120] loss: 0.131\n",
      "[100, 180] loss: 0.144\n",
      "[100, 240] loss: 0.143\n",
      "[100, 300] loss: 0.143\n",
      "[100, 360] loss: 0.148\n",
      "Epoch: 100 -> Loss: 0.217404410243\n",
      "Epoch: 100 -> Test Accuracy: 90.595\n",
      "[101, 60] loss: 0.121\n",
      "[101, 120] loss: 0.133\n",
      "[101, 180] loss: 0.142\n",
      "[101, 240] loss: 0.139\n",
      "[101, 300] loss: 0.144\n",
      "[101, 360] loss: 0.149\n",
      "Epoch: 101 -> Loss: 0.112143948674\n",
      "Epoch: 101 -> Test Accuracy: 90.5375\n",
      "[102, 60] loss: 0.130\n",
      "[102, 120] loss: 0.138\n",
      "[102, 180] loss: 0.133\n",
      "[102, 240] loss: 0.135\n",
      "[102, 300] loss: 0.150\n",
      "[102, 360] loss: 0.146\n",
      "Epoch: 102 -> Loss: 0.219998091459\n",
      "Epoch: 102 -> Test Accuracy: 90.37\n",
      "[103, 60] loss: 0.133\n",
      "[103, 120] loss: 0.130\n",
      "[103, 180] loss: 0.140\n",
      "[103, 240] loss: 0.142\n",
      "[103, 300] loss: 0.148\n",
      "[103, 360] loss: 0.144\n",
      "Epoch: 103 -> Loss: 0.0865595936775\n",
      "Epoch: 103 -> Test Accuracy: 89.9725\n",
      "[104, 60] loss: 0.122\n",
      "[104, 120] loss: 0.140\n",
      "[104, 180] loss: 0.139\n",
      "[104, 240] loss: 0.131\n",
      "[104, 300] loss: 0.147\n",
      "[104, 360] loss: 0.146\n",
      "Epoch: 104 -> Loss: 0.186554774642\n",
      "Epoch: 104 -> Test Accuracy: 90.7075\n",
      "[105, 60] loss: 0.123\n",
      "[105, 120] loss: 0.138\n",
      "[105, 180] loss: 0.133\n",
      "[105, 240] loss: 0.145\n",
      "[105, 300] loss: 0.143\n",
      "[105, 360] loss: 0.146\n",
      "Epoch: 105 -> Loss: 0.137937352061\n",
      "Epoch: 105 -> Test Accuracy: 90.2525\n",
      "[106, 60] loss: 0.125\n",
      "[106, 120] loss: 0.138\n",
      "[106, 180] loss: 0.140\n",
      "[106, 240] loss: 0.146\n",
      "[106, 300] loss: 0.134\n",
      "[106, 360] loss: 0.137\n",
      "Epoch: 106 -> Loss: 0.128356069326\n",
      "Epoch: 106 -> Test Accuracy: 90.4925\n",
      "[107, 60] loss: 0.130\n",
      "[107, 120] loss: 0.132\n",
      "[107, 180] loss: 0.142\n",
      "[107, 240] loss: 0.132\n",
      "[107, 300] loss: 0.139\n",
      "[107, 360] loss: 0.144\n",
      "Epoch: 107 -> Loss: 0.173000097275\n",
      "Epoch: 107 -> Test Accuracy: 90.21\n",
      "[108, 60] loss: 0.126\n",
      "[108, 120] loss: 0.139\n",
      "[108, 180] loss: 0.145\n",
      "[108, 240] loss: 0.134\n",
      "[108, 300] loss: 0.138\n",
      "[108, 360] loss: 0.134\n",
      "Epoch: 108 -> Loss: 0.215180471539\n",
      "Epoch: 108 -> Test Accuracy: 90.2225\n",
      "[109, 60] loss: 0.128\n",
      "[109, 120] loss: 0.132\n",
      "[109, 180] loss: 0.136\n",
      "[109, 240] loss: 0.137\n",
      "[109, 300] loss: 0.134\n",
      "[109, 360] loss: 0.144\n",
      "Epoch: 109 -> Loss: 0.174933493137\n",
      "Epoch: 109 -> Test Accuracy: 90.56\n",
      "[110, 60] loss: 0.128\n",
      "[110, 120] loss: 0.128\n",
      "[110, 180] loss: 0.137\n",
      "[110, 240] loss: 0.140\n",
      "[110, 300] loss: 0.142\n",
      "[110, 360] loss: 0.146\n",
      "Epoch: 110 -> Loss: 0.112447999418\n",
      "Epoch: 110 -> Test Accuracy: 90.195\n",
      "[111, 60] loss: 0.121\n",
      "[111, 120] loss: 0.128\n",
      "[111, 180] loss: 0.140\n",
      "[111, 240] loss: 0.138\n",
      "[111, 300] loss: 0.132\n",
      "[111, 360] loss: 0.151\n",
      "Epoch: 111 -> Loss: 0.112225934863\n",
      "Epoch: 111 -> Test Accuracy: 90.5875\n",
      "[112, 60] loss: 0.118\n",
      "[112, 120] loss: 0.134\n",
      "[112, 180] loss: 0.143\n",
      "[112, 240] loss: 0.137\n",
      "[112, 300] loss: 0.149\n",
      "[112, 360] loss: 0.140\n",
      "Epoch: 112 -> Loss: 0.150579839945\n",
      "Epoch: 112 -> Test Accuracy: 90.7875\n",
      "[113, 60] loss: 0.122\n",
      "[113, 120] loss: 0.129\n",
      "[113, 180] loss: 0.133\n",
      "[113, 240] loss: 0.144\n",
      "[113, 300] loss: 0.137\n",
      "[113, 360] loss: 0.148\n",
      "Epoch: 113 -> Loss: 0.173209816217\n",
      "Epoch: 113 -> Test Accuracy: 90.59\n",
      "[114, 60] loss: 0.121\n",
      "[114, 120] loss: 0.136\n",
      "[114, 180] loss: 0.133\n",
      "[114, 240] loss: 0.131\n",
      "[114, 300] loss: 0.140\n",
      "[114, 360] loss: 0.141\n",
      "Epoch: 114 -> Loss: 0.126662015915\n",
      "Epoch: 114 -> Test Accuracy: 90.1375\n",
      "[115, 60] loss: 0.120\n",
      "[115, 120] loss: 0.134\n",
      "[115, 180] loss: 0.134\n",
      "[115, 240] loss: 0.137\n",
      "[115, 300] loss: 0.139\n",
      "[115, 360] loss: 0.135\n",
      "Epoch: 115 -> Loss: 0.167525678873\n",
      "Epoch: 115 -> Test Accuracy: 90.3575\n",
      "[116, 60] loss: 0.125\n",
      "[116, 120] loss: 0.124\n",
      "[116, 180] loss: 0.133\n",
      "[116, 240] loss: 0.136\n",
      "[116, 300] loss: 0.142\n",
      "[116, 360] loss: 0.143\n",
      "Epoch: 116 -> Loss: 0.145769029856\n",
      "Epoch: 116 -> Test Accuracy: 90.145\n",
      "[117, 60] loss: 0.124\n",
      "[117, 120] loss: 0.126\n",
      "[117, 180] loss: 0.134\n",
      "[117, 240] loss: 0.143\n",
      "[117, 300] loss: 0.139\n",
      "[117, 360] loss: 0.135\n",
      "Epoch: 117 -> Loss: 0.155775338411\n",
      "Epoch: 117 -> Test Accuracy: 90.3625\n",
      "[118, 60] loss: 0.122\n",
      "[118, 120] loss: 0.138\n",
      "[118, 180] loss: 0.125\n",
      "[118, 240] loss: 0.135\n",
      "[118, 300] loss: 0.133\n",
      "[118, 360] loss: 0.137\n",
      "Epoch: 118 -> Loss: 0.171157062054\n",
      "Epoch: 118 -> Test Accuracy: 89.8475\n",
      "[119, 60] loss: 0.117\n",
      "[119, 120] loss: 0.134\n",
      "[119, 180] loss: 0.133\n",
      "[119, 240] loss: 0.127\n",
      "[119, 300] loss: 0.142\n",
      "[119, 360] loss: 0.141\n",
      "Epoch: 119 -> Loss: 0.157969221473\n",
      "Epoch: 119 -> Test Accuracy: 90.605\n",
      "[120, 60] loss: 0.122\n",
      "[120, 120] loss: 0.123\n",
      "[120, 180] loss: 0.134\n",
      "[120, 240] loss: 0.134\n",
      "[120, 300] loss: 0.139\n",
      "[120, 360] loss: 0.141\n",
      "Epoch: 120 -> Loss: 0.0655948519707\n",
      "Epoch: 120 -> Test Accuracy: 90.1325\n",
      "[121, 60] loss: 0.103\n",
      "[121, 120] loss: 0.077\n",
      "[121, 180] loss: 0.065\n",
      "[121, 240] loss: 0.068\n",
      "[121, 300] loss: 0.066\n",
      "[121, 360] loss: 0.060\n",
      "Epoch: 121 -> Loss: 0.0533712394536\n",
      "Epoch: 121 -> Test Accuracy: 92.2275\n",
      "[122, 60] loss: 0.054\n",
      "[122, 120] loss: 0.057\n",
      "[122, 180] loss: 0.055\n",
      "[122, 240] loss: 0.055\n",
      "[122, 300] loss: 0.053\n",
      "[122, 360] loss: 0.057\n",
      "Epoch: 122 -> Loss: 0.0369960255921\n",
      "Epoch: 122 -> Test Accuracy: 92.325\n",
      "[123, 60] loss: 0.045\n",
      "[123, 120] loss: 0.049\n",
      "[123, 180] loss: 0.046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123, 240] loss: 0.048\n",
      "[123, 300] loss: 0.048\n",
      "[123, 360] loss: 0.048\n",
      "Epoch: 123 -> Loss: 0.0596450455487\n",
      "Epoch: 123 -> Test Accuracy: 92.3375\n",
      "[124, 60] loss: 0.043\n",
      "[124, 120] loss: 0.043\n",
      "[124, 180] loss: 0.047\n",
      "[124, 240] loss: 0.043\n",
      "[124, 300] loss: 0.047\n",
      "[124, 360] loss: 0.043\n",
      "Epoch: 124 -> Loss: 0.024054909125\n",
      "Epoch: 124 -> Test Accuracy: 92.2475\n",
      "[125, 60] loss: 0.037\n",
      "[125, 120] loss: 0.044\n",
      "[125, 180] loss: 0.042\n",
      "[125, 240] loss: 0.038\n",
      "[125, 300] loss: 0.040\n",
      "[125, 360] loss: 0.045\n",
      "Epoch: 125 -> Loss: 0.0246923975646\n",
      "Epoch: 125 -> Test Accuracy: 92.24\n",
      "[126, 60] loss: 0.036\n",
      "[126, 120] loss: 0.036\n",
      "[126, 180] loss: 0.036\n",
      "[126, 240] loss: 0.040\n",
      "[126, 300] loss: 0.042\n",
      "[126, 360] loss: 0.039\n",
      "Epoch: 126 -> Loss: 0.103281259537\n",
      "Epoch: 126 -> Test Accuracy: 92.1225\n",
      "[127, 60] loss: 0.038\n",
      "[127, 120] loss: 0.032\n",
      "[127, 180] loss: 0.036\n",
      "[127, 240] loss: 0.038\n",
      "[127, 300] loss: 0.039\n",
      "[127, 360] loss: 0.040\n",
      "Epoch: 127 -> Loss: 0.0224345587194\n",
      "Epoch: 127 -> Test Accuracy: 92.0875\n",
      "[128, 60] loss: 0.032\n",
      "[128, 120] loss: 0.032\n",
      "[128, 180] loss: 0.036\n",
      "[128, 240] loss: 0.032\n",
      "[128, 300] loss: 0.033\n",
      "[128, 360] loss: 0.036\n",
      "Epoch: 128 -> Loss: 0.0264527443796\n",
      "Epoch: 128 -> Test Accuracy: 92.095\n",
      "[129, 60] loss: 0.030\n",
      "[129, 120] loss: 0.031\n",
      "[129, 180] loss: 0.035\n",
      "[129, 240] loss: 0.036\n",
      "[129, 300] loss: 0.033\n",
      "[129, 360] loss: 0.037\n",
      "Epoch: 129 -> Loss: 0.0235800947994\n",
      "Epoch: 129 -> Test Accuracy: 91.9425\n",
      "[130, 60] loss: 0.032\n",
      "[130, 120] loss: 0.032\n",
      "[130, 180] loss: 0.030\n",
      "[130, 240] loss: 0.034\n",
      "[130, 300] loss: 0.034\n",
      "[130, 360] loss: 0.034\n",
      "Epoch: 130 -> Loss: 0.0120637947693\n",
      "Epoch: 130 -> Test Accuracy: 92.1075\n",
      "[131, 60] loss: 0.030\n",
      "[131, 120] loss: 0.032\n",
      "[131, 180] loss: 0.030\n",
      "[131, 240] loss: 0.033\n",
      "[131, 300] loss: 0.032\n",
      "[131, 360] loss: 0.030\n",
      "Epoch: 131 -> Loss: 0.0243150182068\n",
      "Epoch: 131 -> Test Accuracy: 92.005\n",
      "[132, 60] loss: 0.028\n",
      "[132, 120] loss: 0.031\n",
      "[132, 180] loss: 0.031\n",
      "[132, 240] loss: 0.033\n",
      "[132, 300] loss: 0.032\n",
      "[132, 360] loss: 0.032\n",
      "Epoch: 132 -> Loss: 0.0233574844897\n",
      "Epoch: 132 -> Test Accuracy: 91.6875\n",
      "[133, 60] loss: 0.029\n",
      "[133, 120] loss: 0.025\n",
      "[133, 180] loss: 0.030\n",
      "[133, 240] loss: 0.032\n",
      "[133, 300] loss: 0.030\n",
      "[133, 360] loss: 0.030\n",
      "Epoch: 133 -> Loss: 0.020484931767\n",
      "Epoch: 133 -> Test Accuracy: 91.8425\n",
      "[134, 60] loss: 0.029\n",
      "[134, 120] loss: 0.028\n",
      "[134, 180] loss: 0.032\n",
      "[134, 240] loss: 0.030\n",
      "[134, 300] loss: 0.032\n",
      "[134, 360] loss: 0.030\n",
      "Epoch: 134 -> Loss: 0.0285502430052\n",
      "Epoch: 134 -> Test Accuracy: 92.1475\n",
      "[135, 60] loss: 0.026\n",
      "[135, 120] loss: 0.028\n",
      "[135, 180] loss: 0.026\n",
      "[135, 240] loss: 0.032\n",
      "[135, 300] loss: 0.032\n",
      "[135, 360] loss: 0.030\n",
      "Epoch: 135 -> Loss: 0.0188366137445\n",
      "Epoch: 135 -> Test Accuracy: 91.95\n",
      "[136, 60] loss: 0.028\n",
      "[136, 120] loss: 0.027\n",
      "[136, 180] loss: 0.031\n",
      "[136, 240] loss: 0.027\n",
      "[136, 300] loss: 0.028\n",
      "[136, 360] loss: 0.030\n",
      "Epoch: 136 -> Loss: 0.0231858193874\n",
      "Epoch: 136 -> Test Accuracy: 91.91\n",
      "[137, 60] loss: 0.027\n",
      "[137, 120] loss: 0.030\n",
      "[137, 180] loss: 0.027\n",
      "[137, 240] loss: 0.033\n",
      "[137, 300] loss: 0.029\n",
      "[137, 360] loss: 0.029\n",
      "Epoch: 137 -> Loss: 0.0371332727373\n",
      "Epoch: 137 -> Test Accuracy: 91.8825\n",
      "[138, 60] loss: 0.028\n",
      "[138, 120] loss: 0.028\n",
      "[138, 180] loss: 0.024\n",
      "[138, 240] loss: 0.023\n",
      "[138, 300] loss: 0.028\n",
      "[138, 360] loss: 0.032\n",
      "Epoch: 138 -> Loss: 0.0230110865086\n",
      "Epoch: 138 -> Test Accuracy: 91.665\n",
      "[139, 60] loss: 0.027\n",
      "[139, 120] loss: 0.027\n",
      "[139, 180] loss: 0.028\n",
      "[139, 240] loss: 0.031\n",
      "[139, 300] loss: 0.031\n",
      "[139, 360] loss: 0.028\n",
      "Epoch: 139 -> Loss: 0.0255832076073\n",
      "Epoch: 139 -> Test Accuracy: 91.9775\n",
      "[140, 60] loss: 0.025\n",
      "[140, 120] loss: 0.026\n",
      "[140, 180] loss: 0.029\n",
      "[140, 240] loss: 0.027\n",
      "[140, 300] loss: 0.029\n",
      "[140, 360] loss: 0.029\n",
      "Epoch: 140 -> Loss: 0.0241238363087\n",
      "Epoch: 140 -> Test Accuracy: 91.7275\n",
      "[141, 60] loss: 0.028\n",
      "[141, 120] loss: 0.027\n",
      "[141, 180] loss: 0.026\n",
      "[141, 240] loss: 0.027\n",
      "[141, 300] loss: 0.029\n",
      "[141, 360] loss: 0.032\n",
      "Epoch: 141 -> Loss: 0.0543529763818\n",
      "Epoch: 141 -> Test Accuracy: 91.8825\n",
      "[142, 60] loss: 0.024\n",
      "[142, 120] loss: 0.028\n",
      "[142, 180] loss: 0.027\n",
      "[142, 240] loss: 0.027\n",
      "[142, 300] loss: 0.028\n",
      "[142, 360] loss: 0.032\n",
      "Epoch: 142 -> Loss: 0.0251797046512\n",
      "Epoch: 142 -> Test Accuracy: 91.885\n",
      "[143, 60] loss: 0.026\n",
      "[143, 120] loss: 0.028\n",
      "[143, 180] loss: 0.025\n",
      "[143, 240] loss: 0.027\n",
      "[143, 300] loss: 0.028\n",
      "[143, 360] loss: 0.029\n",
      "Epoch: 143 -> Loss: 0.0196725539863\n",
      "Epoch: 143 -> Test Accuracy: 91.87\n",
      "[144, 60] loss: 0.026\n",
      "[144, 120] loss: 0.025\n",
      "[144, 180] loss: 0.026\n",
      "[144, 240] loss: 0.025\n",
      "[144, 300] loss: 0.033\n",
      "[144, 360] loss: 0.028\n",
      "Epoch: 144 -> Loss: 0.0256709065288\n",
      "Epoch: 144 -> Test Accuracy: 91.8025\n",
      "[145, 60] loss: 0.027\n",
      "[145, 120] loss: 0.025\n",
      "[145, 180] loss: 0.029\n",
      "[145, 240] loss: 0.028\n",
      "[145, 300] loss: 0.028\n",
      "[145, 360] loss: 0.031\n",
      "Epoch: 145 -> Loss: 0.0314939245582\n",
      "Epoch: 145 -> Test Accuracy: 91.5625\n",
      "[146, 60] loss: 0.026\n",
      "[146, 120] loss: 0.028\n",
      "[146, 180] loss: 0.029\n",
      "[146, 240] loss: 0.030\n",
      "[146, 300] loss: 0.027\n",
      "[146, 360] loss: 0.030\n",
      "Epoch: 146 -> Loss: 0.0196925215423\n",
      "Epoch: 146 -> Test Accuracy: 91.7525\n",
      "[147, 60] loss: 0.027\n",
      "[147, 120] loss: 0.028\n",
      "[147, 180] loss: 0.028\n",
      "[147, 240] loss: 0.029\n",
      "[147, 300] loss: 0.031\n",
      "[147, 360] loss: 0.031\n",
      "Epoch: 147 -> Loss: 0.042223341763\n",
      "Epoch: 147 -> Test Accuracy: 91.3675\n",
      "[148, 60] loss: 0.023\n",
      "[148, 120] loss: 0.025\n",
      "[148, 180] loss: 0.029\n",
      "[148, 240] loss: 0.030\n",
      "[148, 300] loss: 0.033\n",
      "[148, 360] loss: 0.029\n",
      "Epoch: 148 -> Loss: 0.0144913922995\n",
      "Epoch: 148 -> Test Accuracy: 91.6925\n",
      "[149, 60] loss: 0.026\n",
      "[149, 120] loss: 0.026\n",
      "[149, 180] loss: 0.030\n",
      "[149, 240] loss: 0.029\n",
      "[149, 300] loss: 0.029\n",
      "[149, 360] loss: 0.030\n",
      "Epoch: 149 -> Loss: 0.022082393989\n",
      "Epoch: 149 -> Test Accuracy: 91.66\n",
      "[150, 60] loss: 0.026\n",
      "[150, 120] loss: 0.027\n",
      "[150, 180] loss: 0.031\n",
      "[150, 240] loss: 0.032\n",
      "[150, 300] loss: 0.031\n",
      "[150, 360] loss: 0.030\n",
      "Epoch: 150 -> Loss: 0.0222755819559\n",
      "Epoch: 150 -> Test Accuracy: 91.5325\n",
      "[151, 60] loss: 0.025\n",
      "[151, 120] loss: 0.029\n",
      "[151, 180] loss: 0.029\n",
      "[151, 240] loss: 0.029\n",
      "[151, 300] loss: 0.029\n",
      "[151, 360] loss: 0.030\n",
      "Epoch: 151 -> Loss: 0.065362110734\n",
      "Epoch: 151 -> Test Accuracy: 91.5075\n",
      "[152, 60] loss: 0.028\n",
      "[152, 120] loss: 0.026\n",
      "[152, 180] loss: 0.028\n",
      "[152, 240] loss: 0.029\n",
      "[152, 300] loss: 0.029\n",
      "[152, 360] loss: 0.029\n",
      "Epoch: 152 -> Loss: 0.054588355124\n",
      "Epoch: 152 -> Test Accuracy: 91.7825\n",
      "[153, 60] loss: 0.025\n",
      "[153, 120] loss: 0.025\n",
      "[153, 180] loss: 0.027\n",
      "[153, 240] loss: 0.029\n",
      "[153, 300] loss: 0.029\n",
      "[153, 360] loss: 0.032\n",
      "Epoch: 153 -> Loss: 0.029461633414\n",
      "Epoch: 153 -> Test Accuracy: 91.555\n",
      "[154, 60] loss: 0.026\n",
      "[154, 120] loss: 0.028\n",
      "[154, 180] loss: 0.026\n",
      "[154, 240] loss: 0.026\n",
      "[154, 300] loss: 0.029\n",
      "[154, 360] loss: 0.029\n",
      "Epoch: 154 -> Loss: 0.0207891091704\n",
      "Epoch: 154 -> Test Accuracy: 91.5425\n",
      "[155, 60] loss: 0.026\n",
      "[155, 120] loss: 0.028\n",
      "[155, 180] loss: 0.028\n",
      "[155, 240] loss: 0.029\n",
      "[155, 300] loss: 0.029\n",
      "[155, 360] loss: 0.029\n",
      "Epoch: 155 -> Loss: 0.015647739172\n",
      "Epoch: 155 -> Test Accuracy: 91.5575\n",
      "[156, 60] loss: 0.026\n",
      "[156, 120] loss: 0.028\n",
      "[156, 180] loss: 0.030\n",
      "[156, 240] loss: 0.029\n",
      "[156, 300] loss: 0.032\n",
      "[156, 360] loss: 0.031\n",
      "Epoch: 156 -> Loss: 0.0637053772807\n",
      "Epoch: 156 -> Test Accuracy: 91.9825\n",
      "[157, 60] loss: 0.025\n",
      "[157, 120] loss: 0.029\n",
      "[157, 180] loss: 0.030\n",
      "[157, 240] loss: 0.033\n",
      "[157, 300] loss: 0.030\n",
      "[157, 360] loss: 0.029\n",
      "Epoch: 157 -> Loss: 0.0295032598078\n",
      "Epoch: 157 -> Test Accuracy: 91.7025\n",
      "[158, 60] loss: 0.026\n",
      "[158, 120] loss: 0.028\n",
      "[158, 180] loss: 0.029\n",
      "[158, 240] loss: 0.035\n",
      "[158, 300] loss: 0.031\n",
      "[158, 360] loss: 0.029\n",
      "Epoch: 158 -> Loss: 0.0130021125078\n",
      "Epoch: 158 -> Test Accuracy: 91.555\n",
      "[159, 60] loss: 0.026\n",
      "[159, 120] loss: 0.030\n",
      "[159, 180] loss: 0.028\n",
      "[159, 240] loss: 0.030\n",
      "[159, 300] loss: 0.030\n",
      "[159, 360] loss: 0.034\n",
      "Epoch: 159 -> Loss: 0.0529192462564\n",
      "Epoch: 159 -> Test Accuracy: 91.56\n",
      "[160, 60] loss: 0.030\n",
      "[160, 120] loss: 0.026\n",
      "[160, 180] loss: 0.028\n",
      "[160, 240] loss: 0.028\n",
      "[160, 300] loss: 0.028\n",
      "[160, 360] loss: 0.034\n",
      "Epoch: 160 -> Loss: 0.0459890663624\n",
      "Epoch: 160 -> Test Accuracy: 91.475\n",
      "[161, 60] loss: 0.025\n",
      "[161, 120] loss: 0.017\n",
      "[161, 180] loss: 0.018\n",
      "[161, 240] loss: 0.015\n",
      "[161, 300] loss: 0.017\n",
      "[161, 360] loss: 0.013\n",
      "Epoch: 161 -> Loss: 0.0220302287489\n",
      "Epoch: 161 -> Test Accuracy: 92.0875\n",
      "[162, 60] loss: 0.013\n",
      "[162, 120] loss: 0.013\n",
      "[162, 180] loss: 0.011\n",
      "[162, 240] loss: 0.013\n",
      "[162, 300] loss: 0.012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[162, 360] loss: 0.013\n",
      "Epoch: 162 -> Loss: 0.0114667778835\n",
      "Epoch: 162 -> Test Accuracy: 91.9825\n",
      "[163, 60] loss: 0.011\n",
      "[163, 120] loss: 0.010\n",
      "[163, 180] loss: 0.011\n",
      "[163, 240] loss: 0.010\n",
      "[163, 300] loss: 0.010\n",
      "[163, 360] loss: 0.011\n",
      "Epoch: 163 -> Loss: 0.010524247773\n",
      "Epoch: 163 -> Test Accuracy: 92.12\n",
      "[164, 60] loss: 0.009\n",
      "[164, 120] loss: 0.011\n",
      "[164, 180] loss: 0.009\n",
      "[164, 240] loss: 0.009\n",
      "[164, 300] loss: 0.009\n",
      "[164, 360] loss: 0.010\n",
      "Epoch: 164 -> Loss: 0.00550093874335\n",
      "Epoch: 164 -> Test Accuracy: 92.115\n",
      "[165, 60] loss: 0.009\n",
      "[165, 120] loss: 0.009\n",
      "[165, 180] loss: 0.009\n",
      "[165, 240] loss: 0.008\n",
      "[165, 300] loss: 0.010\n",
      "[165, 360] loss: 0.010\n",
      "Epoch: 165 -> Loss: 0.00612861430272\n",
      "Epoch: 165 -> Test Accuracy: 92.1775\n",
      "[166, 60] loss: 0.008\n",
      "[166, 120] loss: 0.008\n",
      "[166, 180] loss: 0.008\n",
      "[166, 240] loss: 0.008\n",
      "[166, 300] loss: 0.009\n",
      "[166, 360] loss: 0.009\n",
      "Epoch: 166 -> Loss: 0.00707083428279\n",
      "Epoch: 166 -> Test Accuracy: 92.2175\n",
      "[167, 60] loss: 0.008\n",
      "[167, 120] loss: 0.008\n",
      "[167, 180] loss: 0.007\n",
      "[167, 240] loss: 0.008\n",
      "[167, 300] loss: 0.008\n",
      "[167, 360] loss: 0.008\n",
      "Epoch: 167 -> Loss: 0.00683377217501\n",
      "Epoch: 167 -> Test Accuracy: 92.085\n",
      "[168, 60] loss: 0.008\n",
      "[168, 120] loss: 0.008\n",
      "[168, 180] loss: 0.007\n",
      "[168, 240] loss: 0.008\n",
      "[168, 300] loss: 0.008\n",
      "[168, 360] loss: 0.007\n",
      "Epoch: 168 -> Loss: 0.00483309198171\n",
      "Epoch: 168 -> Test Accuracy: 92.2475\n",
      "[169, 60] loss: 0.007\n",
      "[169, 120] loss: 0.008\n",
      "[169, 180] loss: 0.007\n",
      "[169, 240] loss: 0.008\n",
      "[169, 300] loss: 0.008\n",
      "[169, 360] loss: 0.008\n",
      "Epoch: 169 -> Loss: 0.00548381824046\n",
      "Epoch: 169 -> Test Accuracy: 92.31\n",
      "[170, 60] loss: 0.007\n",
      "[170, 120] loss: 0.007\n",
      "[170, 180] loss: 0.007\n",
      "[170, 240] loss: 0.006\n",
      "[170, 300] loss: 0.008\n",
      "[170, 360] loss: 0.007\n",
      "Epoch: 170 -> Loss: 0.00372593407519\n",
      "Epoch: 170 -> Test Accuracy: 92.2425\n",
      "[171, 60] loss: 0.007\n",
      "[171, 120] loss: 0.007\n",
      "[171, 180] loss: 0.006\n",
      "[171, 240] loss: 0.007\n",
      "[171, 300] loss: 0.007\n",
      "[171, 360] loss: 0.007\n",
      "Epoch: 171 -> Loss: 0.00473756808788\n",
      "Epoch: 171 -> Test Accuracy: 92.3575\n",
      "[172, 60] loss: 0.005\n",
      "[172, 120] loss: 0.007\n",
      "[172, 180] loss: 0.006\n",
      "[172, 240] loss: 0.007\n",
      "[172, 300] loss: 0.007\n",
      "[172, 360] loss: 0.007\n",
      "Epoch: 172 -> Loss: 0.00564688351005\n",
      "Epoch: 172 -> Test Accuracy: 92.31\n",
      "[173, 60] loss: 0.006\n",
      "[173, 120] loss: 0.006\n",
      "[173, 180] loss: 0.007\n",
      "[173, 240] loss: 0.006\n",
      "[173, 300] loss: 0.005\n",
      "[173, 360] loss: 0.007\n",
      "Epoch: 173 -> Loss: 0.0036164522171\n",
      "Epoch: 173 -> Test Accuracy: 92.24\n",
      "[174, 60] loss: 0.006\n",
      "[174, 120] loss: 0.007\n",
      "[174, 180] loss: 0.005\n",
      "[174, 240] loss: 0.007\n",
      "[174, 300] loss: 0.006\n",
      "[174, 360] loss: 0.005\n",
      "Epoch: 174 -> Loss: 0.00585205340758\n",
      "Epoch: 174 -> Test Accuracy: 92.2925\n",
      "[175, 60] loss: 0.006\n",
      "[175, 120] loss: 0.006\n",
      "[175, 180] loss: 0.007\n",
      "[175, 240] loss: 0.006\n",
      "[175, 300] loss: 0.007\n",
      "[175, 360] loss: 0.006\n",
      "Epoch: 175 -> Loss: 0.00511104660109\n",
      "Epoch: 175 -> Test Accuracy: 92.31\n",
      "[176, 60] loss: 0.005\n",
      "[176, 120] loss: 0.007\n",
      "[176, 180] loss: 0.007\n",
      "[176, 240] loss: 0.005\n",
      "[176, 300] loss: 0.006\n",
      "[176, 360] loss: 0.007\n",
      "Epoch: 176 -> Loss: 0.00441678520292\n",
      "Epoch: 176 -> Test Accuracy: 92.2675\n",
      "[177, 60] loss: 0.006\n",
      "[177, 120] loss: 0.006\n",
      "[177, 180] loss: 0.006\n",
      "[177, 240] loss: 0.006\n",
      "[177, 300] loss: 0.006\n",
      "[177, 360] loss: 0.007\n",
      "Epoch: 177 -> Loss: 0.00191532517783\n",
      "Epoch: 177 -> Test Accuracy: 92.285\n",
      "[178, 60] loss: 0.006\n",
      "[178, 120] loss: 0.006\n",
      "[178, 180] loss: 0.006\n",
      "[178, 240] loss: 0.006\n",
      "[178, 300] loss: 0.007\n",
      "[178, 360] loss: 0.007\n",
      "Epoch: 178 -> Loss: 0.00457277148962\n",
      "Epoch: 178 -> Test Accuracy: 92.2625\n",
      "[179, 60] loss: 0.006\n",
      "[179, 120] loss: 0.006\n",
      "[179, 180] loss: 0.006\n",
      "[179, 240] loss: 0.006\n",
      "[179, 300] loss: 0.006\n",
      "[179, 360] loss: 0.005\n",
      "Epoch: 179 -> Loss: 0.00928752683103\n",
      "Epoch: 179 -> Test Accuracy: 92.3125\n",
      "[180, 60] loss: 0.006\n",
      "[180, 120] loss: 0.005\n",
      "[180, 180] loss: 0.005\n",
      "[180, 240] loss: 0.007\n",
      "[180, 300] loss: 0.006\n",
      "[180, 360] loss: 0.005\n",
      "Epoch: 180 -> Loss: 0.0101297572255\n",
      "Epoch: 180 -> Test Accuracy: 92.295\n",
      "[181, 60] loss: 0.005\n",
      "[181, 120] loss: 0.006\n",
      "[181, 180] loss: 0.006\n",
      "[181, 240] loss: 0.005\n",
      "[181, 300] loss: 0.005\n",
      "[181, 360] loss: 0.005\n",
      "Epoch: 181 -> Loss: 0.0114480080083\n",
      "Epoch: 181 -> Test Accuracy: 92.3\n",
      "[182, 60] loss: 0.006\n",
      "[182, 120] loss: 0.005\n",
      "[182, 180] loss: 0.005\n",
      "[182, 240] loss: 0.006\n",
      "[182, 300] loss: 0.005\n",
      "[182, 360] loss: 0.005\n",
      "Epoch: 182 -> Loss: 0.00377841666341\n",
      "Epoch: 182 -> Test Accuracy: 92.2975\n",
      "[183, 60] loss: 0.006\n",
      "[183, 120] loss: 0.005\n",
      "[183, 180] loss: 0.005\n",
      "[183, 240] loss: 0.006\n",
      "[183, 300] loss: 0.005\n",
      "[183, 360] loss: 0.005\n",
      "Epoch: 183 -> Loss: 0.00504678767174\n",
      "Epoch: 183 -> Test Accuracy: 92.2475\n",
      "[184, 60] loss: 0.005\n",
      "[184, 120] loss: 0.005\n",
      "[184, 180] loss: 0.005\n",
      "[184, 240] loss: 0.005\n",
      "[184, 300] loss: 0.005\n",
      "[184, 360] loss: 0.005\n",
      "Epoch: 184 -> Loss: 0.011169699952\n",
      "Epoch: 184 -> Test Accuracy: 92.2875\n",
      "[185, 60] loss: 0.005\n",
      "[185, 120] loss: 0.005\n",
      "[185, 180] loss: 0.005\n",
      "[185, 240] loss: 0.005\n",
      "[185, 300] loss: 0.005\n",
      "[185, 360] loss: 0.005\n",
      "Epoch: 185 -> Loss: 0.00336091220379\n",
      "Epoch: 185 -> Test Accuracy: 92.2075\n",
      "[186, 60] loss: 0.005\n",
      "[186, 120] loss: 0.005\n",
      "[186, 180] loss: 0.005\n",
      "[186, 240] loss: 0.005\n",
      "[186, 300] loss: 0.004\n",
      "[186, 360] loss: 0.005\n",
      "Epoch: 186 -> Loss: 0.00283480947837\n",
      "Epoch: 186 -> Test Accuracy: 92.1975\n",
      "[187, 60] loss: 0.005\n",
      "[187, 120] loss: 0.005\n",
      "[187, 180] loss: 0.005\n",
      "[187, 240] loss: 0.005\n",
      "[187, 300] loss: 0.004\n",
      "[187, 360] loss: 0.005\n",
      "Epoch: 187 -> Loss: 0.00175758148544\n",
      "Epoch: 187 -> Test Accuracy: 92.275\n",
      "[188, 60] loss: 0.006\n",
      "[188, 120] loss: 0.005\n",
      "[188, 180] loss: 0.005\n",
      "[188, 240] loss: 0.005\n",
      "[188, 300] loss: 0.005\n",
      "[188, 360] loss: 0.004\n",
      "Epoch: 188 -> Loss: 0.00531994085759\n",
      "Epoch: 188 -> Test Accuracy: 92.215\n",
      "[189, 60] loss: 0.005\n",
      "[189, 120] loss: 0.005\n",
      "[189, 180] loss: 0.005\n",
      "[189, 240] loss: 0.004\n",
      "[189, 300] loss: 0.005\n",
      "[189, 360] loss: 0.005\n",
      "Epoch: 189 -> Loss: 0.00448025157675\n",
      "Epoch: 189 -> Test Accuracy: 92.265\n",
      "[190, 60] loss: 0.004\n",
      "[190, 120] loss: 0.004\n",
      "[190, 180] loss: 0.004\n",
      "[190, 240] loss: 0.004\n",
      "[190, 300] loss: 0.005\n",
      "[190, 360] loss: 0.004\n",
      "Epoch: 190 -> Loss: 0.00946325622499\n",
      "Epoch: 190 -> Test Accuracy: 92.3175\n",
      "[191, 60] loss: 0.004\n",
      "[191, 120] loss: 0.005\n",
      "[191, 180] loss: 0.004\n",
      "[191, 240] loss: 0.005\n",
      "[191, 300] loss: 0.004\n",
      "[191, 360] loss: 0.004\n",
      "Epoch: 191 -> Loss: 0.0103990118951\n",
      "Epoch: 191 -> Test Accuracy: 92.28\n",
      "[192, 60] loss: 0.005\n",
      "[192, 120] loss: 0.005\n",
      "[192, 180] loss: 0.004\n",
      "[192, 240] loss: 0.004\n",
      "[192, 300] loss: 0.004\n",
      "[192, 360] loss: 0.005\n",
      "Epoch: 192 -> Loss: 0.00375246931799\n",
      "Epoch: 192 -> Test Accuracy: 92.24\n",
      "[193, 60] loss: 0.005\n",
      "[193, 120] loss: 0.004\n",
      "[193, 180] loss: 0.004\n",
      "[193, 240] loss: 0.004\n",
      "[193, 300] loss: 0.004\n",
      "[193, 360] loss: 0.004\n",
      "Epoch: 193 -> Loss: 0.001748457551\n",
      "Epoch: 193 -> Test Accuracy: 92.265\n",
      "[194, 60] loss: 0.005\n",
      "[194, 120] loss: 0.004\n",
      "[194, 180] loss: 0.005\n",
      "[194, 240] loss: 0.005\n",
      "[194, 300] loss: 0.005\n",
      "[194, 360] loss: 0.004\n",
      "Epoch: 194 -> Loss: 0.00145590899047\n",
      "Epoch: 194 -> Test Accuracy: 92.325\n",
      "[195, 60] loss: 0.005\n",
      "[195, 120] loss: 0.004\n",
      "[195, 180] loss: 0.005\n",
      "[195, 240] loss: 0.004\n",
      "[195, 300] loss: 0.004\n",
      "[195, 360] loss: 0.004\n",
      "Epoch: 195 -> Loss: 0.00710171228275\n",
      "Epoch: 195 -> Test Accuracy: 92.1925\n",
      "[196, 60] loss: 0.004\n",
      "[196, 120] loss: 0.005\n",
      "[196, 180] loss: 0.004\n",
      "[196, 240] loss: 0.005\n",
      "[196, 300] loss: 0.004\n",
      "[196, 360] loss: 0.005\n",
      "Epoch: 196 -> Loss: 0.00746373692527\n",
      "Epoch: 196 -> Test Accuracy: 92.2925\n",
      "[197, 60] loss: 0.004\n",
      "[197, 120] loss: 0.005\n",
      "[197, 180] loss: 0.004\n",
      "[197, 240] loss: 0.004\n",
      "[197, 300] loss: 0.004\n",
      "[197, 360] loss: 0.004\n",
      "Epoch: 197 -> Loss: 0.00212603062391\n",
      "Epoch: 197 -> Test Accuracy: 92.1875\n",
      "[198, 60] loss: 0.004\n",
      "[198, 120] loss: 0.004\n",
      "[198, 180] loss: 0.004\n",
      "[198, 240] loss: 0.005\n",
      "[198, 300] loss: 0.004\n",
      "[198, 360] loss: 0.004\n",
      "Epoch: 198 -> Loss: 0.00180586497299\n",
      "Epoch: 198 -> Test Accuracy: 92.1875\n",
      "[199, 60] loss: 0.004\n",
      "[199, 120] loss: 0.004\n",
      "[199, 180] loss: 0.004\n",
      "[199, 240] loss: 0.005\n",
      "[199, 300] loss: 0.004\n",
      "[199, 360] loss: 0.004\n",
      "Epoch: 199 -> Loss: 0.00208615278825\n",
      "Epoch: 199 -> Test Accuracy: 92.1525\n",
      "[200, 60] loss: 0.004\n",
      "[200, 120] loss: 0.003\n",
      "[200, 180] loss: 0.004\n",
      "[200, 240] loss: 0.005\n",
      "[200, 300] loss: 0.004\n",
      "[200, 360] loss: 0.004\n",
      "Epoch: 200 -> Loss: 0.00519321952015\n",
      "Epoch: 200 -> Test Accuracy: 92.27\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "rot_block5_loss_log, rot_block5_valid_accuracy_log, rot_block5_test_accuracy_log, rot_block5_max_accuracy, \\\n",
    "rot_block5_best_epoch = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], [60, 120, 160, 200], 0.9, 5e-4, net_block5, \n",
    "                                             criterion, trainloader, None, testloader, rot=['90', '180', '270'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 2.191\n",
      "[1, 120] loss: 1.233\n",
      "[1, 180] loss: 1.149\n",
      "[1, 240] loss: 1.066\n",
      "[1, 300] loss: 1.060\n",
      "[1, 360] loss: 1.004\n",
      "Epoch: 1 -> Loss: 1.0187497139\n",
      "Epoch: 1 -> Test Accuracy: 67.53\n",
      "[2, 60] loss: 0.953\n",
      "[2, 120] loss: 0.916\n",
      "[2, 180] loss: 0.904\n",
      "[2, 240] loss: 0.904\n",
      "[2, 300] loss: 0.890\n",
      "[2, 360] loss: 0.867\n",
      "Epoch: 2 -> Loss: 0.691092252731\n",
      "Epoch: 2 -> Test Accuracy: 71.58\n",
      "[3, 60] loss: 0.830\n",
      "[3, 120] loss: 0.824\n",
      "[3, 180] loss: 0.828\n",
      "[3, 240] loss: 0.833\n",
      "[3, 300] loss: 0.804\n",
      "[3, 360] loss: 0.804\n",
      "Epoch: 3 -> Loss: 0.830797672272\n",
      "Epoch: 3 -> Test Accuracy: 73.8\n",
      "[4, 60] loss: 0.782\n",
      "[4, 120] loss: 0.780\n",
      "[4, 180] loss: 0.762\n",
      "[4, 240] loss: 0.754\n",
      "[4, 300] loss: 0.743\n",
      "[4, 360] loss: 0.766\n",
      "Epoch: 4 -> Loss: 0.577464878559\n",
      "Epoch: 4 -> Test Accuracy: 74.51\n",
      "[5, 60] loss: 0.718\n",
      "[5, 120] loss: 0.731\n",
      "[5, 180] loss: 0.707\n",
      "[5, 240] loss: 0.734\n",
      "[5, 300] loss: 0.745\n",
      "[5, 360] loss: 0.744\n",
      "Epoch: 5 -> Loss: 0.719400107861\n",
      "Epoch: 5 -> Test Accuracy: 75.04\n",
      "[6, 60] loss: 0.709\n",
      "[6, 120] loss: 0.713\n",
      "[6, 180] loss: 0.721\n",
      "[6, 240] loss: 0.691\n",
      "[6, 300] loss: 0.688\n",
      "[6, 360] loss: 0.706\n",
      "Epoch: 6 -> Loss: 0.642412602901\n",
      "Epoch: 6 -> Test Accuracy: 76.28\n",
      "[7, 60] loss: 0.674\n",
      "[7, 120] loss: 0.677\n",
      "[7, 180] loss: 0.681\n",
      "[7, 240] loss: 0.690\n",
      "[7, 300] loss: 0.668\n",
      "[7, 360] loss: 0.721\n",
      "Epoch: 7 -> Loss: 0.675020098686\n",
      "Epoch: 7 -> Test Accuracy: 76.69\n",
      "[8, 60] loss: 0.654\n",
      "[8, 120] loss: 0.667\n",
      "[8, 180] loss: 0.662\n",
      "[8, 240] loss: 0.667\n",
      "[8, 300] loss: 0.662\n",
      "[8, 360] loss: 0.687\n",
      "Epoch: 8 -> Loss: 0.6832498312\n",
      "Epoch: 8 -> Test Accuracy: 77.53\n",
      "[9, 60] loss: 0.646\n",
      "[9, 120] loss: 0.641\n",
      "[9, 180] loss: 0.671\n",
      "[9, 240] loss: 0.668\n",
      "[9, 300] loss: 0.664\n",
      "[9, 360] loss: 0.681\n",
      "Epoch: 9 -> Loss: 0.662715733051\n",
      "Epoch: 9 -> Test Accuracy: 77.72\n",
      "[10, 60] loss: 0.607\n",
      "[10, 120] loss: 0.619\n",
      "[10, 180] loss: 0.654\n",
      "[10, 240] loss: 0.643\n",
      "[10, 300] loss: 0.667\n",
      "[10, 360] loss: 0.660\n",
      "Epoch: 10 -> Loss: 0.593425393105\n",
      "Epoch: 10 -> Test Accuracy: 77.79\n",
      "[11, 60] loss: 0.638\n",
      "[11, 120] loss: 0.629\n",
      "[11, 180] loss: 0.632\n",
      "[11, 240] loss: 0.635\n",
      "[11, 300] loss: 0.672\n",
      "[11, 360] loss: 0.649\n",
      "Epoch: 11 -> Loss: 0.595600962639\n",
      "Epoch: 11 -> Test Accuracy: 77.42\n",
      "[12, 60] loss: 0.614\n",
      "[12, 120] loss: 0.623\n",
      "[12, 180] loss: 0.638\n",
      "[12, 240] loss: 0.653\n",
      "[12, 300] loss: 0.631\n",
      "[12, 360] loss: 0.647\n",
      "Epoch: 12 -> Loss: 0.718051671982\n",
      "Epoch: 12 -> Test Accuracy: 77.56\n",
      "[13, 60] loss: 0.618\n",
      "[13, 120] loss: 0.609\n",
      "[13, 180] loss: 0.654\n",
      "[13, 240] loss: 0.631\n",
      "[13, 300] loss: 0.623\n",
      "[13, 360] loss: 0.641\n",
      "Epoch: 13 -> Loss: 0.669684290886\n",
      "Epoch: 13 -> Test Accuracy: 78.35\n",
      "[14, 60] loss: 0.606\n",
      "[14, 120] loss: 0.627\n",
      "[14, 180] loss: 0.608\n",
      "[14, 240] loss: 0.633\n",
      "[14, 300] loss: 0.622\n",
      "[14, 360] loss: 0.609\n",
      "Epoch: 14 -> Loss: 0.504918813705\n",
      "Epoch: 14 -> Test Accuracy: 77.78\n",
      "[15, 60] loss: 0.586\n",
      "[15, 120] loss: 0.612\n",
      "[15, 180] loss: 0.609\n",
      "[15, 240] loss: 0.621\n",
      "[15, 300] loss: 0.634\n",
      "[15, 360] loss: 0.639\n",
      "Epoch: 15 -> Loss: 0.626538038254\n",
      "Epoch: 15 -> Test Accuracy: 77.92\n",
      "[16, 60] loss: 0.611\n",
      "[16, 120] loss: 0.606\n",
      "[16, 180] loss: 0.614\n",
      "[16, 240] loss: 0.605\n",
      "[16, 300] loss: 0.607\n",
      "[16, 360] loss: 0.628\n",
      "Epoch: 16 -> Loss: 0.667554974556\n",
      "Epoch: 16 -> Test Accuracy: 78.3\n",
      "[17, 60] loss: 0.579\n",
      "[17, 120] loss: 0.581\n",
      "[17, 180] loss: 0.636\n",
      "[17, 240] loss: 0.621\n",
      "[17, 300] loss: 0.613\n",
      "[17, 360] loss: 0.639\n",
      "Epoch: 17 -> Loss: 0.733634769917\n",
      "Epoch: 17 -> Test Accuracy: 78.62\n",
      "[18, 60] loss: 0.579\n",
      "[18, 120] loss: 0.583\n",
      "[18, 180] loss: 0.612\n",
      "[18, 240] loss: 0.635\n",
      "[18, 300] loss: 0.615\n",
      "[18, 360] loss: 0.625\n",
      "Epoch: 18 -> Loss: 0.635933041573\n",
      "Epoch: 18 -> Test Accuracy: 78.62\n",
      "[19, 60] loss: 0.582\n",
      "[19, 120] loss: 0.613\n",
      "[19, 180] loss: 0.582\n",
      "[19, 240] loss: 0.633\n",
      "[19, 300] loss: 0.623\n",
      "[19, 360] loss: 0.611\n",
      "Epoch: 19 -> Loss: 0.566378474236\n",
      "Epoch: 19 -> Test Accuracy: 78.41\n",
      "[20, 60] loss: 0.600\n",
      "[20, 120] loss: 0.617\n",
      "[20, 180] loss: 0.594\n",
      "[20, 240] loss: 0.603\n",
      "[20, 300] loss: 0.619\n",
      "[20, 360] loss: 0.628\n",
      "Epoch: 20 -> Loss: 0.624588608742\n",
      "Epoch: 20 -> Test Accuracy: 78.89\n",
      "[21, 60] loss: 0.535\n",
      "[21, 120] loss: 0.527\n",
      "[21, 180] loss: 0.501\n",
      "[21, 240] loss: 0.506\n",
      "[21, 300] loss: 0.506\n",
      "[21, 360] loss: 0.499\n",
      "Epoch: 21 -> Loss: 0.542198717594\n",
      "Epoch: 21 -> Test Accuracy: 81.0\n",
      "[22, 60] loss: 0.477\n",
      "[22, 120] loss: 0.469\n",
      "[22, 180] loss: 0.479\n",
      "[22, 240] loss: 0.476\n",
      "[22, 300] loss: 0.469\n",
      "[22, 360] loss: 0.475\n",
      "Epoch: 22 -> Loss: 0.663014113903\n",
      "Epoch: 22 -> Test Accuracy: 81.3\n",
      "[23, 60] loss: 0.460\n",
      "[23, 120] loss: 0.456\n",
      "[23, 180] loss: 0.446\n",
      "[23, 240] loss: 0.446\n",
      "[23, 300] loss: 0.461\n",
      "[23, 360] loss: 0.454\n",
      "Epoch: 23 -> Loss: 0.505996108055\n",
      "Epoch: 23 -> Test Accuracy: 81.3\n",
      "[24, 60] loss: 0.418\n",
      "[24, 120] loss: 0.443\n",
      "[24, 180] loss: 0.457\n",
      "[24, 240] loss: 0.439\n",
      "[24, 300] loss: 0.428\n",
      "[24, 360] loss: 0.451\n",
      "Epoch: 24 -> Loss: 0.705869317055\n",
      "Epoch: 24 -> Test Accuracy: 81.75\n",
      "[25, 60] loss: 0.437\n",
      "[25, 120] loss: 0.439\n",
      "[25, 180] loss: 0.430\n",
      "[25, 240] loss: 0.442\n",
      "[25, 300] loss: 0.424\n",
      "[25, 360] loss: 0.422\n",
      "Epoch: 25 -> Loss: 0.422333717346\n",
      "Epoch: 25 -> Test Accuracy: 81.59\n",
      "[26, 60] loss: 0.411\n",
      "[26, 120] loss: 0.406\n",
      "[26, 180] loss: 0.406\n",
      "[26, 240] loss: 0.428\n",
      "[26, 300] loss: 0.429\n",
      "[26, 360] loss: 0.438\n",
      "Epoch: 26 -> Loss: 0.486231744289\n",
      "Epoch: 26 -> Test Accuracy: 81.33\n",
      "[27, 60] loss: 0.415\n",
      "[27, 120] loss: 0.410\n",
      "[27, 180] loss: 0.412\n",
      "[27, 240] loss: 0.426\n",
      "[27, 300] loss: 0.424\n",
      "[27, 360] loss: 0.431\n",
      "Epoch: 27 -> Loss: 0.762964248657\n",
      "Epoch: 27 -> Test Accuracy: 81.68\n",
      "[28, 60] loss: 0.408\n",
      "[28, 120] loss: 0.403\n",
      "[28, 180] loss: 0.406\n",
      "[28, 240] loss: 0.415\n",
      "[28, 300] loss: 0.416\n",
      "[28, 360] loss: 0.407\n",
      "Epoch: 28 -> Loss: 0.373728513718\n",
      "Epoch: 28 -> Test Accuracy: 82.09\n",
      "[29, 60] loss: 0.407\n",
      "[29, 120] loss: 0.408\n",
      "[29, 180] loss: 0.407\n",
      "[29, 240] loss: 0.413\n",
      "[29, 300] loss: 0.412\n",
      "[29, 360] loss: 0.418\n",
      "Epoch: 29 -> Loss: 0.400373518467\n",
      "Epoch: 29 -> Test Accuracy: 81.63\n",
      "[30, 60] loss: 0.399\n",
      "[30, 120] loss: 0.406\n",
      "[30, 180] loss: 0.403\n",
      "[30, 240] loss: 0.405\n",
      "[30, 300] loss: 0.412\n",
      "[30, 360] loss: 0.415\n",
      "Epoch: 30 -> Loss: 0.362346857786\n",
      "Epoch: 30 -> Test Accuracy: 81.19\n",
      "[31, 60] loss: 0.397\n",
      "[31, 120] loss: 0.418\n",
      "[31, 180] loss: 0.415\n",
      "[31, 240] loss: 0.401\n",
      "[31, 300] loss: 0.410\n",
      "[31, 360] loss: 0.416\n",
      "Epoch: 31 -> Loss: 0.594502806664\n",
      "Epoch: 31 -> Test Accuracy: 81.71\n",
      "[32, 60] loss: 0.387\n",
      "[32, 120] loss: 0.399\n",
      "[32, 180] loss: 0.408\n",
      "[32, 240] loss: 0.397\n",
      "[32, 300] loss: 0.399\n",
      "[32, 360] loss: 0.426\n",
      "Epoch: 32 -> Loss: 0.446017503738\n",
      "Epoch: 32 -> Test Accuracy: 81.98\n",
      "[33, 60] loss: 0.384\n",
      "[33, 120] loss: 0.410\n",
      "[33, 180] loss: 0.392\n",
      "[33, 240] loss: 0.394\n",
      "[33, 300] loss: 0.408\n",
      "[33, 360] loss: 0.413\n",
      "Epoch: 33 -> Loss: 0.329146325588\n",
      "Epoch: 33 -> Test Accuracy: 81.78\n",
      "[34, 60] loss: 0.390\n",
      "[34, 120] loss: 0.385\n",
      "[34, 180] loss: 0.398\n",
      "[34, 240] loss: 0.399\n",
      "[34, 300] loss: 0.401\n",
      "[34, 360] loss: 0.413\n",
      "Epoch: 34 -> Loss: 0.269251316786\n",
      "Epoch: 34 -> Test Accuracy: 81.82\n",
      "[35, 60] loss: 0.407\n",
      "[35, 120] loss: 0.379\n",
      "[35, 180] loss: 0.411\n",
      "[35, 240] loss: 0.388\n",
      "[35, 300] loss: 0.406\n",
      "[35, 360] loss: 0.412\n",
      "Epoch: 35 -> Loss: 0.453269541264\n",
      "Epoch: 35 -> Test Accuracy: 81.48\n",
      "[36, 60] loss: 0.393\n",
      "[36, 120] loss: 0.378\n",
      "[36, 180] loss: 0.387\n",
      "[36, 240] loss: 0.397\n",
      "[36, 300] loss: 0.408\n",
      "[36, 360] loss: 0.404\n",
      "Epoch: 36 -> Loss: 0.450781404972\n",
      "Epoch: 36 -> Test Accuracy: 81.37\n",
      "[37, 60] loss: 0.394\n",
      "[37, 120] loss: 0.393\n",
      "[37, 180] loss: 0.394\n",
      "[37, 240] loss: 0.409\n",
      "[37, 300] loss: 0.382\n",
      "[37, 360] loss: 0.404\n",
      "Epoch: 37 -> Loss: 0.668607056141\n",
      "Epoch: 37 -> Test Accuracy: 82.04\n",
      "[38, 60] loss: 0.400\n",
      "[38, 120] loss: 0.380\n",
      "[38, 180] loss: 0.383\n",
      "[38, 240] loss: 0.394\n",
      "[38, 300] loss: 0.403\n",
      "[38, 360] loss: 0.398\n",
      "Epoch: 38 -> Loss: 0.446645975113\n",
      "Epoch: 38 -> Test Accuracy: 81.38\n",
      "[39, 60] loss: 0.377\n",
      "[39, 120] loss: 0.398\n",
      "[39, 180] loss: 0.394\n",
      "[39, 240] loss: 0.406\n",
      "[39, 300] loss: 0.397\n",
      "[39, 360] loss: 0.398\n",
      "Epoch: 39 -> Loss: 0.271013170481\n",
      "Epoch: 39 -> Test Accuracy: 81.29\n",
      "[40, 60] loss: 0.380\n",
      "[40, 120] loss: 0.383\n",
      "[40, 180] loss: 0.376\n",
      "[40, 240] loss: 0.397\n",
      "[40, 300] loss: 0.393\n",
      "[40, 360] loss: 0.408\n",
      "Epoch: 40 -> Loss: 0.285903900862\n",
      "Epoch: 40 -> Test Accuracy: 81.75\n",
      "[41, 60] loss: 0.356\n",
      "[41, 120] loss: 0.360\n",
      "[41, 180] loss: 0.349\n",
      "[41, 240] loss: 0.346\n",
      "[41, 300] loss: 0.340\n",
      "[41, 360] loss: 0.348\n",
      "Epoch: 41 -> Loss: 0.441863834858\n",
      "Epoch: 41 -> Test Accuracy: 82.72\n",
      "[42, 60] loss: 0.329\n",
      "[42, 120] loss: 0.327\n",
      "[42, 180] loss: 0.337\n",
      "[42, 240] loss: 0.320\n",
      "[42, 300] loss: 0.324\n",
      "[42, 360] loss: 0.323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.386459052563\n",
      "Epoch: 42 -> Test Accuracy: 82.59\n",
      "[43, 60] loss: 0.317\n",
      "[43, 120] loss: 0.313\n",
      "[43, 180] loss: 0.320\n",
      "[43, 240] loss: 0.323\n",
      "[43, 300] loss: 0.325\n",
      "[43, 360] loss: 0.312\n",
      "Epoch: 43 -> Loss: 0.308984279633\n",
      "Epoch: 43 -> Test Accuracy: 82.93\n",
      "[44, 60] loss: 0.314\n",
      "[44, 120] loss: 0.315\n",
      "[44, 180] loss: 0.300\n",
      "[44, 240] loss: 0.311\n",
      "[44, 300] loss: 0.305\n",
      "[44, 360] loss: 0.315\n",
      "Epoch: 44 -> Loss: 0.330457448959\n",
      "Epoch: 44 -> Test Accuracy: 82.79\n",
      "[45, 60] loss: 0.292\n",
      "[45, 120] loss: 0.304\n",
      "[45, 180] loss: 0.309\n",
      "[45, 240] loss: 0.310\n",
      "[45, 300] loss: 0.305\n",
      "[45, 360] loss: 0.304\n",
      "Epoch: 45 -> Loss: 0.422406971455\n",
      "Epoch: 45 -> Test Accuracy: 83.04\n",
      "[46, 60] loss: 0.290\n",
      "[46, 120] loss: 0.291\n",
      "[46, 180] loss: 0.299\n",
      "[46, 240] loss: 0.293\n",
      "[46, 300] loss: 0.286\n",
      "[46, 360] loss: 0.305\n",
      "Epoch: 46 -> Loss: 0.363905400038\n",
      "Epoch: 46 -> Test Accuracy: 83.11\n",
      "[47, 60] loss: 0.298\n",
      "[47, 120] loss: 0.286\n",
      "[47, 180] loss: 0.285\n",
      "[47, 240] loss: 0.304\n",
      "[47, 300] loss: 0.282\n",
      "[47, 360] loss: 0.297\n",
      "Epoch: 47 -> Loss: 0.209653064609\n",
      "Epoch: 47 -> Test Accuracy: 83.09\n",
      "[48, 60] loss: 0.284\n",
      "[48, 120] loss: 0.287\n",
      "[48, 180] loss: 0.297\n",
      "[48, 240] loss: 0.304\n",
      "[48, 300] loss: 0.283\n",
      "[48, 360] loss: 0.292\n",
      "Epoch: 48 -> Loss: 0.317522734404\n",
      "Epoch: 48 -> Test Accuracy: 83.0\n",
      "[49, 60] loss: 0.280\n",
      "[49, 120] loss: 0.290\n",
      "[49, 180] loss: 0.286\n",
      "[49, 240] loss: 0.286\n",
      "[49, 300] loss: 0.269\n",
      "[49, 360] loss: 0.291\n",
      "Epoch: 49 -> Loss: 0.382529258728\n",
      "Epoch: 49 -> Test Accuracy: 83.07\n",
      "[50, 60] loss: 0.282\n",
      "[50, 120] loss: 0.301\n",
      "[50, 180] loss: 0.284\n",
      "[50, 240] loss: 0.287\n",
      "[50, 300] loss: 0.274\n",
      "[50, 360] loss: 0.283\n",
      "Epoch: 50 -> Loss: 0.30579406023\n",
      "Epoch: 50 -> Test Accuracy: 83.17\n",
      "[51, 60] loss: 0.284\n",
      "[51, 120] loss: 0.274\n",
      "[51, 180] loss: 0.270\n",
      "[51, 240] loss: 0.274\n",
      "[51, 300] loss: 0.298\n",
      "[51, 360] loss: 0.283\n",
      "Epoch: 51 -> Loss: 0.197437822819\n",
      "Epoch: 51 -> Test Accuracy: 83.25\n",
      "[52, 60] loss: 0.274\n",
      "[52, 120] loss: 0.277\n",
      "[52, 180] loss: 0.285\n",
      "[52, 240] loss: 0.274\n",
      "[52, 300] loss: 0.295\n",
      "[52, 360] loss: 0.298\n",
      "Epoch: 52 -> Loss: 0.19459874928\n",
      "Epoch: 52 -> Test Accuracy: 83.07\n",
      "[53, 60] loss: 0.284\n",
      "[53, 120] loss: 0.291\n",
      "[53, 180] loss: 0.275\n",
      "[53, 240] loss: 0.263\n",
      "[53, 300] loss: 0.273\n",
      "[53, 360] loss: 0.273\n",
      "Epoch: 53 -> Loss: 0.238254785538\n",
      "Epoch: 53 -> Test Accuracy: 83.0\n",
      "[54, 60] loss: 0.273\n",
      "[54, 120] loss: 0.283\n",
      "[54, 180] loss: 0.274\n",
      "[54, 240] loss: 0.279\n",
      "[54, 300] loss: 0.272\n",
      "[54, 360] loss: 0.265\n",
      "Epoch: 54 -> Loss: 0.29114484787\n",
      "Epoch: 54 -> Test Accuracy: 83.04\n",
      "[55, 60] loss: 0.277\n",
      "[55, 120] loss: 0.275\n",
      "[55, 180] loss: 0.267\n",
      "[55, 240] loss: 0.274\n",
      "[55, 300] loss: 0.275\n",
      "[55, 360] loss: 0.273\n",
      "Epoch: 55 -> Loss: 0.293521493673\n",
      "Epoch: 55 -> Test Accuracy: 83.12\n",
      "[56, 60] loss: 0.274\n",
      "[56, 120] loss: 0.272\n",
      "[56, 180] loss: 0.280\n",
      "[56, 240] loss: 0.285\n",
      "[56, 300] loss: 0.279\n",
      "[56, 360] loss: 0.277\n",
      "Epoch: 56 -> Loss: 0.254172801971\n",
      "Epoch: 56 -> Test Accuracy: 83.11\n",
      "[57, 60] loss: 0.271\n",
      "[57, 120] loss: 0.260\n",
      "[57, 180] loss: 0.268\n",
      "[57, 240] loss: 0.265\n",
      "[57, 300] loss: 0.277\n",
      "[57, 360] loss: 0.283\n",
      "Epoch: 57 -> Loss: 0.149351730943\n",
      "Epoch: 57 -> Test Accuracy: 83.16\n",
      "[58, 60] loss: 0.264\n",
      "[58, 120] loss: 0.278\n",
      "[58, 180] loss: 0.276\n",
      "[58, 240] loss: 0.273\n",
      "[58, 300] loss: 0.273\n",
      "[58, 360] loss: 0.282\n",
      "Epoch: 58 -> Loss: 0.342826217413\n",
      "Epoch: 58 -> Test Accuracy: 83.15\n",
      "[59, 60] loss: 0.283\n",
      "[59, 120] loss: 0.271\n",
      "[59, 180] loss: 0.279\n",
      "[59, 240] loss: 0.269\n",
      "[59, 300] loss: 0.277\n",
      "[59, 360] loss: 0.264\n",
      "Epoch: 59 -> Loss: 0.428512632847\n",
      "Epoch: 59 -> Test Accuracy: 83.12\n",
      "[60, 60] loss: 0.270\n",
      "[60, 120] loss: 0.276\n",
      "[60, 180] loss: 0.262\n",
      "[60, 240] loss: 0.278\n",
      "[60, 300] loss: 0.264\n",
      "[60, 360] loss: 0.270\n",
      "Epoch: 60 -> Loss: 0.234894424677\n",
      "Epoch: 60 -> Test Accuracy: 83.12\n",
      "[61, 60] loss: 0.274\n",
      "[61, 120] loss: 0.275\n",
      "[61, 180] loss: 0.266\n",
      "[61, 240] loss: 0.269\n",
      "[61, 300] loss: 0.267\n",
      "[61, 360] loss: 0.262\n",
      "Epoch: 61 -> Loss: 0.246370509267\n",
      "Epoch: 61 -> Test Accuracy: 83.24\n",
      "[62, 60] loss: 0.263\n",
      "[62, 120] loss: 0.273\n",
      "[62, 180] loss: 0.268\n",
      "[62, 240] loss: 0.275\n",
      "[62, 300] loss: 0.259\n",
      "[62, 360] loss: 0.267\n",
      "Epoch: 62 -> Loss: 0.25715816021\n",
      "Epoch: 62 -> Test Accuracy: 83.2\n",
      "[63, 60] loss: 0.262\n",
      "[63, 120] loss: 0.274\n",
      "[63, 180] loss: 0.269\n",
      "[63, 240] loss: 0.264\n",
      "[63, 300] loss: 0.266\n",
      "[63, 360] loss: 0.266\n",
      "Epoch: 63 -> Loss: 0.27557682991\n",
      "Epoch: 63 -> Test Accuracy: 83.14\n",
      "[64, 60] loss: 0.266\n",
      "[64, 120] loss: 0.264\n",
      "[64, 180] loss: 0.270\n",
      "[64, 240] loss: 0.255\n",
      "[64, 300] loss: 0.270\n",
      "[64, 360] loss: 0.269\n",
      "Epoch: 64 -> Loss: 0.254745543003\n",
      "Epoch: 64 -> Test Accuracy: 83.14\n",
      "[65, 60] loss: 0.270\n",
      "[65, 120] loss: 0.265\n",
      "[65, 180] loss: 0.270\n",
      "[65, 240] loss: 0.272\n",
      "[65, 300] loss: 0.254\n",
      "[65, 360] loss: 0.268\n",
      "Epoch: 65 -> Loss: 0.161807492375\n",
      "Epoch: 65 -> Test Accuracy: 83.21\n",
      "[66, 60] loss: 0.263\n",
      "[66, 120] loss: 0.268\n",
      "[66, 180] loss: 0.272\n",
      "[66, 240] loss: 0.270\n",
      "[66, 300] loss: 0.262\n",
      "[66, 360] loss: 0.263\n",
      "Epoch: 66 -> Loss: 0.369763582945\n",
      "Epoch: 66 -> Test Accuracy: 83.07\n",
      "[67, 60] loss: 0.262\n",
      "[67, 120] loss: 0.267\n",
      "[67, 180] loss: 0.260\n",
      "[67, 240] loss: 0.263\n",
      "[67, 300] loss: 0.263\n",
      "[67, 360] loss: 0.264\n",
      "Epoch: 67 -> Loss: 0.392437368631\n",
      "Epoch: 67 -> Test Accuracy: 83.14\n",
      "[68, 60] loss: 0.258\n",
      "[68, 120] loss: 0.256\n",
      "[68, 180] loss: 0.253\n",
      "[68, 240] loss: 0.258\n",
      "[68, 300] loss: 0.271\n",
      "[68, 360] loss: 0.255\n",
      "Epoch: 68 -> Loss: 0.232218980789\n",
      "Epoch: 68 -> Test Accuracy: 83.19\n",
      "[69, 60] loss: 0.278\n",
      "[69, 120] loss: 0.254\n",
      "[69, 180] loss: 0.265\n",
      "[69, 240] loss: 0.256\n",
      "[69, 300] loss: 0.256\n",
      "[69, 360] loss: 0.265\n",
      "Epoch: 69 -> Loss: 0.491817772388\n",
      "Epoch: 69 -> Test Accuracy: 83.24\n",
      "[70, 60] loss: 0.243\n",
      "[70, 120] loss: 0.268\n",
      "[70, 180] loss: 0.262\n",
      "[70, 240] loss: 0.251\n",
      "[70, 300] loss: 0.265\n",
      "[70, 360] loss: 0.265\n",
      "Epoch: 70 -> Loss: 0.381916821003\n",
      "Epoch: 70 -> Test Accuracy: 83.24\n",
      "[71, 60] loss: 0.252\n",
      "[71, 120] loss: 0.264\n",
      "[71, 180] loss: 0.266\n",
      "[71, 240] loss: 0.257\n",
      "[71, 300] loss: 0.267\n",
      "[71, 360] loss: 0.261\n",
      "Epoch: 71 -> Loss: 0.161095097661\n",
      "Epoch: 71 -> Test Accuracy: 83.27\n",
      "[72, 60] loss: 0.267\n",
      "[72, 120] loss: 0.262\n",
      "[72, 180] loss: 0.260\n",
      "[72, 240] loss: 0.256\n",
      "[72, 300] loss: 0.254\n",
      "[72, 360] loss: 0.256\n",
      "Epoch: 72 -> Loss: 0.323448717594\n",
      "Epoch: 72 -> Test Accuracy: 83.27\n",
      "[73, 60] loss: 0.241\n",
      "[73, 120] loss: 0.249\n",
      "[73, 180] loss: 0.252\n",
      "[73, 240] loss: 0.272\n",
      "[73, 300] loss: 0.258\n",
      "[73, 360] loss: 0.259\n",
      "Epoch: 73 -> Loss: 0.308931291103\n",
      "Epoch: 73 -> Test Accuracy: 83.39\n",
      "[74, 60] loss: 0.255\n",
      "[74, 120] loss: 0.250\n",
      "[74, 180] loss: 0.253\n",
      "[74, 240] loss: 0.261\n",
      "[74, 300] loss: 0.252\n",
      "[74, 360] loss: 0.244\n",
      "Epoch: 74 -> Loss: 0.222295761108\n",
      "Epoch: 74 -> Test Accuracy: 83.45\n",
      "[75, 60] loss: 0.251\n",
      "[75, 120] loss: 0.258\n",
      "[75, 180] loss: 0.252\n",
      "[75, 240] loss: 0.260\n",
      "[75, 300] loss: 0.255\n",
      "[75, 360] loss: 0.243\n",
      "Epoch: 75 -> Loss: 0.253968417645\n",
      "Epoch: 75 -> Test Accuracy: 83.37\n",
      "[76, 60] loss: 0.255\n",
      "[76, 120] loss: 0.256\n",
      "[76, 180] loss: 0.256\n",
      "[76, 240] loss: 0.255\n",
      "[76, 300] loss: 0.254\n",
      "[76, 360] loss: 0.249\n",
      "Epoch: 76 -> Loss: 0.250817447901\n",
      "Epoch: 76 -> Test Accuracy: 83.32\n",
      "[77, 60] loss: 0.247\n",
      "[77, 120] loss: 0.254\n",
      "[77, 180] loss: 0.262\n",
      "[77, 240] loss: 0.256\n",
      "[77, 300] loss: 0.262\n",
      "[77, 360] loss: 0.253\n",
      "Epoch: 77 -> Loss: 0.220827892423\n",
      "Epoch: 77 -> Test Accuracy: 83.3\n",
      "[78, 60] loss: 0.250\n",
      "[78, 120] loss: 0.241\n",
      "[78, 180] loss: 0.258\n",
      "[78, 240] loss: 0.244\n",
      "[78, 300] loss: 0.254\n",
      "[78, 360] loss: 0.255\n",
      "Epoch: 78 -> Loss: 0.230542570353\n",
      "Epoch: 78 -> Test Accuracy: 83.35\n",
      "[79, 60] loss: 0.238\n",
      "[79, 120] loss: 0.255\n",
      "[79, 180] loss: 0.256\n",
      "[79, 240] loss: 0.236\n",
      "[79, 300] loss: 0.248\n",
      "[79, 360] loss: 0.254\n",
      "Epoch: 79 -> Loss: 0.26578477025\n",
      "Epoch: 79 -> Test Accuracy: 83.41\n",
      "[80, 60] loss: 0.246\n",
      "[80, 120] loss: 0.253\n",
      "[80, 180] loss: 0.247\n",
      "[80, 240] loss: 0.247\n",
      "[80, 300] loss: 0.253\n",
      "[80, 360] loss: 0.244\n",
      "Epoch: 80 -> Loss: 0.317588686943\n",
      "Epoch: 80 -> Test Accuracy: 83.4\n",
      "[81, 60] loss: 0.245\n",
      "[81, 120] loss: 0.248\n",
      "[81, 180] loss: 0.238\n",
      "[81, 240] loss: 0.252\n",
      "[81, 300] loss: 0.254\n",
      "[81, 360] loss: 0.251\n",
      "Epoch: 81 -> Loss: 0.368969887495\n",
      "Epoch: 81 -> Test Accuracy: 83.41\n",
      "[82, 60] loss: 0.250\n",
      "[82, 120] loss: 0.251\n",
      "[82, 180] loss: 0.261\n",
      "[82, 240] loss: 0.243\n",
      "[82, 300] loss: 0.238\n",
      "[82, 360] loss: 0.231\n",
      "Epoch: 82 -> Loss: 0.26408046484\n",
      "Epoch: 82 -> Test Accuracy: 83.34\n",
      "[83, 60] loss: 0.242\n",
      "[83, 120] loss: 0.249\n",
      "[83, 180] loss: 0.242\n",
      "[83, 240] loss: 0.247\n",
      "[83, 300] loss: 0.252\n",
      "[83, 360] loss: 0.247\n",
      "Epoch: 83 -> Loss: 0.269054114819\n",
      "Epoch: 83 -> Test Accuracy: 83.25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.253\n",
      "[84, 120] loss: 0.243\n",
      "[84, 180] loss: 0.241\n",
      "[84, 240] loss: 0.250\n",
      "[84, 300] loss: 0.254\n",
      "[84, 360] loss: 0.233\n",
      "Epoch: 84 -> Loss: 0.285877496004\n",
      "Epoch: 84 -> Test Accuracy: 83.22\n",
      "[85, 60] loss: 0.249\n",
      "[85, 120] loss: 0.245\n",
      "[85, 180] loss: 0.232\n",
      "[85, 240] loss: 0.251\n",
      "[85, 300] loss: 0.257\n",
      "[85, 360] loss: 0.244\n",
      "Epoch: 85 -> Loss: 0.361768782139\n",
      "Epoch: 85 -> Test Accuracy: 83.36\n",
      "[86, 60] loss: 0.245\n",
      "[86, 120] loss: 0.247\n",
      "[86, 180] loss: 0.237\n",
      "[86, 240] loss: 0.245\n",
      "[86, 300] loss: 0.243\n",
      "[86, 360] loss: 0.232\n",
      "Epoch: 86 -> Loss: 0.292589753866\n",
      "Epoch: 86 -> Test Accuracy: 83.26\n",
      "[87, 60] loss: 0.251\n",
      "[87, 120] loss: 0.234\n",
      "[87, 180] loss: 0.243\n",
      "[87, 240] loss: 0.234\n",
      "[87, 300] loss: 0.239\n",
      "[87, 360] loss: 0.245\n",
      "Epoch: 87 -> Loss: 0.234339088202\n",
      "Epoch: 87 -> Test Accuracy: 83.31\n",
      "[88, 60] loss: 0.252\n",
      "[88, 120] loss: 0.232\n",
      "[88, 180] loss: 0.243\n",
      "[88, 240] loss: 0.249\n",
      "[88, 300] loss: 0.244\n",
      "[88, 360] loss: 0.255\n",
      "Epoch: 88 -> Loss: 0.264325469732\n",
      "Epoch: 88 -> Test Accuracy: 83.18\n",
      "[89, 60] loss: 0.248\n",
      "[89, 120] loss: 0.238\n",
      "[89, 180] loss: 0.242\n",
      "[89, 240] loss: 0.241\n",
      "[89, 300] loss: 0.240\n",
      "[89, 360] loss: 0.238\n",
      "Epoch: 89 -> Loss: 0.150319263339\n",
      "Epoch: 89 -> Test Accuracy: 83.25\n",
      "[90, 60] loss: 0.235\n",
      "[90, 120] loss: 0.237\n",
      "[90, 180] loss: 0.244\n",
      "[90, 240] loss: 0.256\n",
      "[90, 300] loss: 0.239\n",
      "[90, 360] loss: 0.245\n",
      "Epoch: 90 -> Loss: 0.232153579593\n",
      "Epoch: 90 -> Test Accuracy: 83.12\n",
      "[91, 60] loss: 0.234\n",
      "[91, 120] loss: 0.234\n",
      "[91, 180] loss: 0.229\n",
      "[91, 240] loss: 0.238\n",
      "[91, 300] loss: 0.249\n",
      "[91, 360] loss: 0.247\n",
      "Epoch: 91 -> Loss: 0.264952123165\n",
      "Epoch: 91 -> Test Accuracy: 83.17\n",
      "[92, 60] loss: 0.237\n",
      "[92, 120] loss: 0.234\n",
      "[92, 180] loss: 0.233\n",
      "[92, 240] loss: 0.237\n",
      "[92, 300] loss: 0.242\n",
      "[92, 360] loss: 0.245\n",
      "Epoch: 92 -> Loss: 0.194831311703\n",
      "Epoch: 92 -> Test Accuracy: 83.12\n",
      "[93, 60] loss: 0.237\n",
      "[93, 120] loss: 0.227\n",
      "[93, 180] loss: 0.232\n",
      "[93, 240] loss: 0.251\n",
      "[93, 300] loss: 0.244\n",
      "[93, 360] loss: 0.235\n",
      "Epoch: 93 -> Loss: 0.335960149765\n",
      "Epoch: 93 -> Test Accuracy: 83.41\n",
      "[94, 60] loss: 0.236\n",
      "[94, 120] loss: 0.243\n",
      "[94, 180] loss: 0.243\n",
      "[94, 240] loss: 0.244\n",
      "[94, 300] loss: 0.249\n",
      "[94, 360] loss: 0.228\n",
      "Epoch: 94 -> Loss: 0.184829905629\n",
      "Epoch: 94 -> Test Accuracy: 83.23\n",
      "[95, 60] loss: 0.235\n",
      "[95, 120] loss: 0.241\n",
      "[95, 180] loss: 0.242\n",
      "[95, 240] loss: 0.223\n",
      "[95, 300] loss: 0.230\n",
      "[95, 360] loss: 0.236\n",
      "Epoch: 95 -> Loss: 0.169149085879\n",
      "Epoch: 95 -> Test Accuracy: 83.16\n",
      "[96, 60] loss: 0.223\n",
      "[96, 120] loss: 0.233\n",
      "[96, 180] loss: 0.233\n",
      "[96, 240] loss: 0.230\n",
      "[96, 300] loss: 0.245\n",
      "[96, 360] loss: 0.243\n",
      "Epoch: 96 -> Loss: 0.324264466763\n",
      "Epoch: 96 -> Test Accuracy: 83.05\n",
      "[97, 60] loss: 0.217\n",
      "[97, 120] loss: 0.237\n",
      "[97, 180] loss: 0.245\n",
      "[97, 240] loss: 0.239\n",
      "[97, 300] loss: 0.234\n",
      "[97, 360] loss: 0.230\n",
      "Epoch: 97 -> Loss: 0.220908075571\n",
      "Epoch: 97 -> Test Accuracy: 83.19\n",
      "[98, 60] loss: 0.230\n",
      "[98, 120] loss: 0.223\n",
      "[98, 180] loss: 0.240\n",
      "[98, 240] loss: 0.234\n",
      "[98, 300] loss: 0.239\n",
      "[98, 360] loss: 0.229\n",
      "Epoch: 98 -> Loss: 0.292895853519\n",
      "Epoch: 98 -> Test Accuracy: 83.17\n",
      "[99, 60] loss: 0.234\n",
      "[99, 120] loss: 0.241\n",
      "[99, 180] loss: 0.232\n",
      "[99, 240] loss: 0.234\n",
      "[99, 300] loss: 0.233\n",
      "[99, 360] loss: 0.230\n",
      "Epoch: 99 -> Loss: 0.22486884892\n",
      "Epoch: 99 -> Test Accuracy: 83.21\n",
      "[100, 60] loss: 0.241\n",
      "[100, 120] loss: 0.231\n",
      "[100, 180] loss: 0.238\n",
      "[100, 240] loss: 0.222\n",
      "[100, 300] loss: 0.237\n",
      "[100, 360] loss: 0.226\n",
      "Epoch: 100 -> Loss: 0.291297256947\n",
      "Epoch: 100 -> Test Accuracy: 83.17\n",
      "Finished Training\n",
      "[1, 60] loss: 1.749\n",
      "[1, 120] loss: 0.854\n",
      "[1, 180] loss: 0.775\n",
      "[1, 240] loss: 0.717\n",
      "[1, 300] loss: 0.685\n",
      "[1, 360] loss: 0.676\n",
      "Epoch: 1 -> Loss: 0.782058358192\n",
      "Epoch: 1 -> Test Accuracy: 77.85\n",
      "[2, 60] loss: 0.633\n",
      "[2, 120] loss: 0.598\n",
      "[2, 180] loss: 0.573\n",
      "[2, 240] loss: 0.592\n",
      "[2, 300] loss: 0.568\n",
      "[2, 360] loss: 0.555\n",
      "Epoch: 2 -> Loss: 0.501369059086\n",
      "Epoch: 2 -> Test Accuracy: 79.55\n",
      "[3, 60] loss: 0.526\n",
      "[3, 120] loss: 0.529\n",
      "[3, 180] loss: 0.521\n",
      "[3, 240] loss: 0.512\n",
      "[3, 300] loss: 0.526\n",
      "[3, 360] loss: 0.532\n",
      "Epoch: 3 -> Loss: 0.506901562214\n",
      "Epoch: 3 -> Test Accuracy: 81.47\n",
      "[4, 60] loss: 0.506\n",
      "[4, 120] loss: 0.487\n",
      "[4, 180] loss: 0.487\n",
      "[4, 240] loss: 0.487\n",
      "[4, 300] loss: 0.454\n",
      "[4, 360] loss: 0.492\n",
      "Epoch: 4 -> Loss: 0.389085948467\n",
      "Epoch: 4 -> Test Accuracy: 82.69\n",
      "[5, 60] loss: 0.478\n",
      "[5, 120] loss: 0.453\n",
      "[5, 180] loss: 0.454\n",
      "[5, 240] loss: 0.449\n",
      "[5, 300] loss: 0.460\n",
      "[5, 360] loss: 0.461\n",
      "Epoch: 5 -> Loss: 0.52922385931\n",
      "Epoch: 5 -> Test Accuracy: 82.9\n",
      "[6, 60] loss: 0.418\n",
      "[6, 120] loss: 0.436\n",
      "[6, 180] loss: 0.446\n",
      "[6, 240] loss: 0.452\n",
      "[6, 300] loss: 0.444\n",
      "[6, 360] loss: 0.464\n",
      "Epoch: 6 -> Loss: 0.381972491741\n",
      "Epoch: 6 -> Test Accuracy: 82.87\n",
      "[7, 60] loss: 0.407\n",
      "[7, 120] loss: 0.409\n",
      "[7, 180] loss: 0.428\n",
      "[7, 240] loss: 0.440\n",
      "[7, 300] loss: 0.431\n",
      "[7, 360] loss: 0.446\n",
      "Epoch: 7 -> Loss: 0.342053741217\n",
      "Epoch: 7 -> Test Accuracy: 83.17\n",
      "[8, 60] loss: 0.409\n",
      "[8, 120] loss: 0.395\n",
      "[8, 180] loss: 0.439\n",
      "[8, 240] loss: 0.425\n",
      "[8, 300] loss: 0.430\n",
      "[8, 360] loss: 0.426\n",
      "Epoch: 8 -> Loss: 0.392809092999\n",
      "Epoch: 8 -> Test Accuracy: 83.19\n",
      "[9, 60] loss: 0.407\n",
      "[9, 120] loss: 0.413\n",
      "[9, 180] loss: 0.420\n",
      "[9, 240] loss: 0.409\n",
      "[9, 300] loss: 0.435\n",
      "[9, 360] loss: 0.415\n",
      "Epoch: 9 -> Loss: 0.321724116802\n",
      "Epoch: 9 -> Test Accuracy: 83.52\n",
      "[10, 60] loss: 0.392\n",
      "[10, 120] loss: 0.413\n",
      "[10, 180] loss: 0.412\n",
      "[10, 240] loss: 0.405\n",
      "[10, 300] loss: 0.408\n",
      "[10, 360] loss: 0.424\n",
      "Epoch: 10 -> Loss: 0.367678999901\n",
      "Epoch: 10 -> Test Accuracy: 83.77\n",
      "[11, 60] loss: 0.386\n",
      "[11, 120] loss: 0.404\n",
      "[11, 180] loss: 0.401\n",
      "[11, 240] loss: 0.392\n",
      "[11, 300] loss: 0.419\n",
      "[11, 360] loss: 0.409\n",
      "Epoch: 11 -> Loss: 0.212345600128\n",
      "Epoch: 11 -> Test Accuracy: 83.6\n",
      "[12, 60] loss: 0.370\n",
      "[12, 120] loss: 0.394\n",
      "[12, 180] loss: 0.390\n",
      "[12, 240] loss: 0.398\n",
      "[12, 300] loss: 0.398\n",
      "[12, 360] loss: 0.400\n",
      "Epoch: 12 -> Loss: 0.497515678406\n",
      "Epoch: 12 -> Test Accuracy: 83.29\n",
      "[13, 60] loss: 0.378\n",
      "[13, 120] loss: 0.386\n",
      "[13, 180] loss: 0.390\n",
      "[13, 240] loss: 0.417\n",
      "[13, 300] loss: 0.395\n",
      "[13, 360] loss: 0.401\n",
      "Epoch: 13 -> Loss: 0.446187019348\n",
      "Epoch: 13 -> Test Accuracy: 83.76\n",
      "[14, 60] loss: 0.365\n",
      "[14, 120] loss: 0.366\n",
      "[14, 180] loss: 0.387\n",
      "[14, 240] loss: 0.403\n",
      "[14, 300] loss: 0.386\n",
      "[14, 360] loss: 0.402\n",
      "Epoch: 14 -> Loss: 0.538952827454\n",
      "Epoch: 14 -> Test Accuracy: 84.37\n",
      "[15, 60] loss: 0.357\n",
      "[15, 120] loss: 0.382\n",
      "[15, 180] loss: 0.384\n",
      "[15, 240] loss: 0.386\n",
      "[15, 300] loss: 0.386\n",
      "[15, 360] loss: 0.386\n",
      "Epoch: 15 -> Loss: 0.190103888512\n",
      "Epoch: 15 -> Test Accuracy: 83.78\n",
      "[16, 60] loss: 0.362\n",
      "[16, 120] loss: 0.368\n",
      "[16, 180] loss: 0.383\n",
      "[16, 240] loss: 0.389\n",
      "[16, 300] loss: 0.403\n",
      "[16, 360] loss: 0.382\n",
      "Epoch: 16 -> Loss: 0.461983680725\n",
      "Epoch: 16 -> Test Accuracy: 83.9\n",
      "[17, 60] loss: 0.363\n",
      "[17, 120] loss: 0.361\n",
      "[17, 180] loss: 0.379\n",
      "[17, 240] loss: 0.391\n",
      "[17, 300] loss: 0.393\n",
      "[17, 360] loss: 0.393\n",
      "Epoch: 17 -> Loss: 0.46760314703\n",
      "Epoch: 17 -> Test Accuracy: 83.83\n",
      "[18, 60] loss: 0.365\n",
      "[18, 120] loss: 0.365\n",
      "[18, 180] loss: 0.397\n",
      "[18, 240] loss: 0.385\n",
      "[18, 300] loss: 0.376\n",
      "[18, 360] loss: 0.382\n",
      "Epoch: 18 -> Loss: 0.374777853489\n",
      "Epoch: 18 -> Test Accuracy: 83.9\n",
      "[19, 60] loss: 0.355\n",
      "[19, 120] loss: 0.370\n",
      "[19, 180] loss: 0.372\n",
      "[19, 240] loss: 0.382\n",
      "[19, 300] loss: 0.383\n",
      "[19, 360] loss: 0.380\n",
      "Epoch: 19 -> Loss: 0.49155536294\n",
      "Epoch: 19 -> Test Accuracy: 84.2\n",
      "[20, 60] loss: 0.353\n",
      "[20, 120] loss: 0.360\n",
      "[20, 180] loss: 0.384\n",
      "[20, 240] loss: 0.386\n",
      "[20, 300] loss: 0.400\n",
      "[20, 360] loss: 0.394\n",
      "Epoch: 20 -> Loss: 0.648967921734\n",
      "Epoch: 20 -> Test Accuracy: 84.16\n",
      "[21, 60] loss: 0.319\n",
      "[21, 120] loss: 0.313\n",
      "[21, 180] loss: 0.301\n",
      "[21, 240] loss: 0.287\n",
      "[21, 300] loss: 0.287\n",
      "[21, 360] loss: 0.266\n",
      "Epoch: 21 -> Loss: 0.270848423243\n",
      "Epoch: 21 -> Test Accuracy: 85.59\n",
      "[22, 60] loss: 0.273\n",
      "[22, 120] loss: 0.256\n",
      "[22, 180] loss: 0.272\n",
      "[22, 240] loss: 0.257\n",
      "[22, 300] loss: 0.270\n",
      "[22, 360] loss: 0.271\n",
      "Epoch: 22 -> Loss: 0.266317039728\n",
      "Epoch: 22 -> Test Accuracy: 85.61\n",
      "[23, 60] loss: 0.252\n",
      "[23, 120] loss: 0.247\n",
      "[23, 180] loss: 0.252\n",
      "[23, 240] loss: 0.250\n",
      "[23, 300] loss: 0.244\n",
      "[23, 360] loss: 0.238\n",
      "Epoch: 23 -> Loss: 0.3662994802\n",
      "Epoch: 23 -> Test Accuracy: 85.58\n",
      "[24, 60] loss: 0.241\n",
      "[24, 120] loss: 0.233\n",
      "[24, 180] loss: 0.226\n",
      "[24, 240] loss: 0.236\n",
      "[24, 300] loss: 0.249\n",
      "[24, 360] loss: 0.242\n",
      "Epoch: 24 -> Loss: 0.303165376186\n",
      "Epoch: 24 -> Test Accuracy: 86.12\n",
      "[25, 60] loss: 0.225\n",
      "[25, 120] loss: 0.224\n",
      "[25, 180] loss: 0.219\n",
      "[25, 240] loss: 0.234\n",
      "[25, 300] loss: 0.238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 360] loss: 0.240\n",
      "Epoch: 25 -> Loss: 0.109687641263\n",
      "Epoch: 25 -> Test Accuracy: 86.29\n",
      "[26, 60] loss: 0.221\n",
      "[26, 120] loss: 0.225\n",
      "[26, 180] loss: 0.219\n",
      "[26, 240] loss: 0.217\n",
      "[26, 300] loss: 0.237\n",
      "[26, 360] loss: 0.236\n",
      "Epoch: 26 -> Loss: 0.205183073878\n",
      "Epoch: 26 -> Test Accuracy: 85.93\n",
      "[27, 60] loss: 0.206\n",
      "[27, 120] loss: 0.209\n",
      "[27, 180] loss: 0.214\n",
      "[27, 240] loss: 0.220\n",
      "[27, 300] loss: 0.225\n",
      "[27, 360] loss: 0.226\n",
      "Epoch: 27 -> Loss: 0.18440118432\n",
      "Epoch: 27 -> Test Accuracy: 85.9\n",
      "[28, 60] loss: 0.209\n",
      "[28, 120] loss: 0.206\n",
      "[28, 180] loss: 0.207\n",
      "[28, 240] loss: 0.224\n",
      "[28, 300] loss: 0.221\n",
      "[28, 360] loss: 0.219\n",
      "Epoch: 28 -> Loss: 0.25542140007\n",
      "Epoch: 28 -> Test Accuracy: 85.99\n",
      "[29, 60] loss: 0.196\n",
      "[29, 120] loss: 0.209\n",
      "[29, 180] loss: 0.210\n",
      "[29, 240] loss: 0.208\n",
      "[29, 300] loss: 0.215\n",
      "[29, 360] loss: 0.224\n",
      "Epoch: 29 -> Loss: 0.261117190123\n",
      "Epoch: 29 -> Test Accuracy: 86.19\n",
      "[30, 60] loss: 0.200\n",
      "[30, 120] loss: 0.204\n",
      "[30, 180] loss: 0.205\n",
      "[30, 240] loss: 0.222\n",
      "[30, 300] loss: 0.201\n",
      "[30, 360] loss: 0.208\n",
      "Epoch: 30 -> Loss: 0.189640074968\n",
      "Epoch: 30 -> Test Accuracy: 85.7\n",
      "[31, 60] loss: 0.200\n",
      "[31, 120] loss: 0.200\n",
      "[31, 180] loss: 0.223\n",
      "[31, 240] loss: 0.216\n",
      "[31, 300] loss: 0.204\n",
      "[31, 360] loss: 0.211\n",
      "Epoch: 31 -> Loss: 0.190433308482\n",
      "Epoch: 31 -> Test Accuracy: 85.76\n",
      "[32, 60] loss: 0.198\n",
      "[32, 120] loss: 0.188\n",
      "[32, 180] loss: 0.203\n",
      "[32, 240] loss: 0.198\n",
      "[32, 300] loss: 0.197\n",
      "[32, 360] loss: 0.202\n",
      "Epoch: 32 -> Loss: 0.334373474121\n",
      "Epoch: 32 -> Test Accuracy: 85.59\n",
      "[33, 60] loss: 0.204\n",
      "[33, 120] loss: 0.196\n",
      "[33, 180] loss: 0.196\n",
      "[33, 240] loss: 0.208\n",
      "[33, 300] loss: 0.210\n",
      "[33, 360] loss: 0.205\n",
      "Epoch: 33 -> Loss: 0.234576627612\n",
      "Epoch: 33 -> Test Accuracy: 85.85\n",
      "[34, 60] loss: 0.200\n",
      "[34, 120] loss: 0.184\n",
      "[34, 180] loss: 0.195\n",
      "[34, 240] loss: 0.196\n",
      "[34, 300] loss: 0.214\n",
      "[34, 360] loss: 0.203\n",
      "Epoch: 34 -> Loss: 0.298561751842\n",
      "Epoch: 34 -> Test Accuracy: 85.09\n",
      "[35, 60] loss: 0.200\n",
      "[35, 120] loss: 0.198\n",
      "[35, 180] loss: 0.216\n",
      "[35, 240] loss: 0.196\n",
      "[35, 300] loss: 0.210\n",
      "[35, 360] loss: 0.214\n",
      "Epoch: 35 -> Loss: 0.210608810186\n",
      "Epoch: 35 -> Test Accuracy: 85.72\n",
      "[36, 60] loss: 0.196\n",
      "[36, 120] loss: 0.189\n",
      "[36, 180] loss: 0.206\n",
      "[36, 240] loss: 0.203\n",
      "[36, 300] loss: 0.211\n",
      "[36, 360] loss: 0.215\n",
      "Epoch: 36 -> Loss: 0.371167510748\n",
      "Epoch: 36 -> Test Accuracy: 85.54\n",
      "[37, 60] loss: 0.194\n",
      "[37, 120] loss: 0.192\n",
      "[37, 180] loss: 0.206\n",
      "[37, 240] loss: 0.195\n",
      "[37, 300] loss: 0.199\n",
      "[37, 360] loss: 0.206\n",
      "Epoch: 37 -> Loss: 0.263177335262\n",
      "Epoch: 37 -> Test Accuracy: 85.47\n",
      "[38, 60] loss: 0.194\n",
      "[38, 120] loss: 0.195\n",
      "[38, 180] loss: 0.188\n",
      "[38, 240] loss: 0.202\n",
      "[38, 300] loss: 0.209\n",
      "[38, 360] loss: 0.217\n",
      "Epoch: 38 -> Loss: 0.307290911674\n",
      "Epoch: 38 -> Test Accuracy: 85.38\n",
      "[39, 60] loss: 0.180\n",
      "[39, 120] loss: 0.198\n",
      "[39, 180] loss: 0.195\n",
      "[39, 240] loss: 0.199\n",
      "[39, 300] loss: 0.208\n",
      "[39, 360] loss: 0.194\n",
      "Epoch: 39 -> Loss: 0.224687665701\n",
      "Epoch: 39 -> Test Accuracy: 85.28\n",
      "[40, 60] loss: 0.198\n",
      "[40, 120] loss: 0.187\n",
      "[40, 180] loss: 0.197\n",
      "[40, 240] loss: 0.200\n",
      "[40, 300] loss: 0.202\n",
      "[40, 360] loss: 0.192\n",
      "Epoch: 40 -> Loss: 0.159667447209\n",
      "Epoch: 40 -> Test Accuracy: 85.56\n",
      "[41, 60] loss: 0.179\n",
      "[41, 120] loss: 0.167\n",
      "[41, 180] loss: 0.171\n",
      "[41, 240] loss: 0.153\n",
      "[41, 300] loss: 0.163\n",
      "[41, 360] loss: 0.163\n",
      "Epoch: 41 -> Loss: 0.23222117126\n",
      "Epoch: 41 -> Test Accuracy: 86.34\n",
      "[42, 60] loss: 0.150\n",
      "[42, 120] loss: 0.146\n",
      "[42, 180] loss: 0.143\n",
      "[42, 240] loss: 0.149\n",
      "[42, 300] loss: 0.152\n",
      "[42, 360] loss: 0.149\n",
      "Epoch: 42 -> Loss: 0.0830256268382\n",
      "Epoch: 42 -> Test Accuracy: 86.33\n",
      "[43, 60] loss: 0.139\n",
      "[43, 120] loss: 0.134\n",
      "[43, 180] loss: 0.138\n",
      "[43, 240] loss: 0.148\n",
      "[43, 300] loss: 0.144\n",
      "[43, 360] loss: 0.137\n",
      "Epoch: 43 -> Loss: 0.0753474235535\n",
      "Epoch: 43 -> Test Accuracy: 86.55\n",
      "[44, 60] loss: 0.133\n",
      "[44, 120] loss: 0.124\n",
      "[44, 180] loss: 0.130\n",
      "[44, 240] loss: 0.131\n",
      "[44, 300] loss: 0.135\n",
      "[44, 360] loss: 0.123\n",
      "Epoch: 44 -> Loss: 0.176255300641\n",
      "Epoch: 44 -> Test Accuracy: 86.74\n",
      "[45, 60] loss: 0.127\n",
      "[45, 120] loss: 0.133\n",
      "[45, 180] loss: 0.117\n",
      "[45, 240] loss: 0.125\n",
      "[45, 300] loss: 0.130\n",
      "[45, 360] loss: 0.140\n",
      "Epoch: 45 -> Loss: 0.202456757426\n",
      "Epoch: 45 -> Test Accuracy: 86.65\n",
      "[46, 60] loss: 0.127\n",
      "[46, 120] loss: 0.114\n",
      "[46, 180] loss: 0.118\n",
      "[46, 240] loss: 0.120\n",
      "[46, 300] loss: 0.123\n",
      "[46, 360] loss: 0.114\n",
      "Epoch: 46 -> Loss: 0.180775746703\n",
      "Epoch: 46 -> Test Accuracy: 86.66\n",
      "[47, 60] loss: 0.114\n",
      "[47, 120] loss: 0.117\n",
      "[47, 180] loss: 0.109\n",
      "[47, 240] loss: 0.124\n",
      "[47, 300] loss: 0.126\n",
      "[47, 360] loss: 0.111\n",
      "Epoch: 47 -> Loss: 0.101402208209\n",
      "Epoch: 47 -> Test Accuracy: 86.71\n",
      "[48, 60] loss: 0.119\n",
      "[48, 120] loss: 0.110\n",
      "[48, 180] loss: 0.106\n",
      "[48, 240] loss: 0.120\n",
      "[48, 300] loss: 0.110\n",
      "[48, 360] loss: 0.118\n",
      "Epoch: 48 -> Loss: 0.0640628188848\n",
      "Epoch: 48 -> Test Accuracy: 86.66\n",
      "[49, 60] loss: 0.116\n",
      "[49, 120] loss: 0.107\n",
      "[49, 180] loss: 0.115\n",
      "[49, 240] loss: 0.117\n",
      "[49, 300] loss: 0.114\n",
      "[49, 360] loss: 0.114\n",
      "Epoch: 49 -> Loss: 0.0750145241618\n",
      "Epoch: 49 -> Test Accuracy: 86.77\n",
      "[50, 60] loss: 0.116\n",
      "[50, 120] loss: 0.121\n",
      "[50, 180] loss: 0.118\n",
      "[50, 240] loss: 0.117\n",
      "[50, 300] loss: 0.105\n",
      "[50, 360] loss: 0.112\n",
      "Epoch: 50 -> Loss: 0.0838810130954\n",
      "Epoch: 50 -> Test Accuracy: 86.81\n",
      "[51, 60] loss: 0.112\n",
      "[51, 120] loss: 0.105\n",
      "[51, 180] loss: 0.112\n",
      "[51, 240] loss: 0.114\n",
      "[51, 300] loss: 0.114\n",
      "[51, 360] loss: 0.123\n",
      "Epoch: 51 -> Loss: 0.138732522726\n",
      "Epoch: 51 -> Test Accuracy: 86.85\n",
      "[52, 60] loss: 0.108\n",
      "[52, 120] loss: 0.115\n",
      "[52, 180] loss: 0.112\n",
      "[52, 240] loss: 0.104\n",
      "[52, 300] loss: 0.111\n",
      "[52, 360] loss: 0.115\n",
      "Epoch: 52 -> Loss: 0.0962293893099\n",
      "Epoch: 52 -> Test Accuracy: 86.75\n",
      "[53, 60] loss: 0.108\n",
      "[53, 120] loss: 0.112\n",
      "[53, 180] loss: 0.108\n",
      "[53, 240] loss: 0.105\n",
      "[53, 300] loss: 0.109\n",
      "[53, 360] loss: 0.109\n",
      "Epoch: 53 -> Loss: 0.106107614934\n",
      "Epoch: 53 -> Test Accuracy: 86.8\n",
      "[54, 60] loss: 0.108\n",
      "[54, 120] loss: 0.108\n",
      "[54, 180] loss: 0.111\n",
      "[54, 240] loss: 0.108\n",
      "[54, 300] loss: 0.107\n",
      "[54, 360] loss: 0.112\n",
      "Epoch: 54 -> Loss: 0.144389122725\n",
      "Epoch: 54 -> Test Accuracy: 86.81\n",
      "[55, 60] loss: 0.111\n",
      "[55, 120] loss: 0.104\n",
      "[55, 180] loss: 0.110\n",
      "[55, 240] loss: 0.106\n",
      "[55, 300] loss: 0.103\n",
      "[55, 360] loss: 0.106\n",
      "Epoch: 55 -> Loss: 0.0645121410489\n",
      "Epoch: 55 -> Test Accuracy: 86.83\n",
      "[56, 60] loss: 0.105\n",
      "[56, 120] loss: 0.108\n",
      "[56, 180] loss: 0.108\n",
      "[56, 240] loss: 0.101\n",
      "[56, 300] loss: 0.114\n",
      "[56, 360] loss: 0.105\n",
      "Epoch: 56 -> Loss: 0.0248605962843\n",
      "Epoch: 56 -> Test Accuracy: 86.85\n",
      "[57, 60] loss: 0.099\n",
      "[57, 120] loss: 0.101\n",
      "[57, 180] loss: 0.104\n",
      "[57, 240] loss: 0.108\n",
      "[57, 300] loss: 0.104\n",
      "[57, 360] loss: 0.105\n",
      "Epoch: 57 -> Loss: 0.0959103032947\n",
      "Epoch: 57 -> Test Accuracy: 86.94\n",
      "[58, 60] loss: 0.098\n",
      "[58, 120] loss: 0.107\n",
      "[58, 180] loss: 0.108\n",
      "[58, 240] loss: 0.116\n",
      "[58, 300] loss: 0.109\n",
      "[58, 360] loss: 0.111\n",
      "Epoch: 58 -> Loss: 0.127011954784\n",
      "Epoch: 58 -> Test Accuracy: 86.8\n",
      "[59, 60] loss: 0.105\n",
      "[59, 120] loss: 0.105\n",
      "[59, 180] loss: 0.095\n",
      "[59, 240] loss: 0.107\n",
      "[59, 300] loss: 0.098\n",
      "[59, 360] loss: 0.103\n",
      "Epoch: 59 -> Loss: 0.0823637545109\n",
      "Epoch: 59 -> Test Accuracy: 86.69\n",
      "[60, 60] loss: 0.112\n",
      "[60, 120] loss: 0.106\n",
      "[60, 180] loss: 0.101\n",
      "[60, 240] loss: 0.099\n",
      "[60, 300] loss: 0.098\n",
      "[60, 360] loss: 0.104\n",
      "Epoch: 60 -> Loss: 0.110426485538\n",
      "Epoch: 60 -> Test Accuracy: 86.71\n",
      "[61, 60] loss: 0.098\n",
      "[61, 120] loss: 0.102\n",
      "[61, 180] loss: 0.113\n",
      "[61, 240] loss: 0.102\n",
      "[61, 300] loss: 0.102\n",
      "[61, 360] loss: 0.107\n",
      "Epoch: 61 -> Loss: 0.138739585876\n",
      "Epoch: 61 -> Test Accuracy: 86.53\n",
      "[62, 60] loss: 0.094\n",
      "[62, 120] loss: 0.105\n",
      "[62, 180] loss: 0.104\n",
      "[62, 240] loss: 0.105\n",
      "[62, 300] loss: 0.092\n",
      "[62, 360] loss: 0.097\n",
      "Epoch: 62 -> Loss: 0.23392829299\n",
      "Epoch: 62 -> Test Accuracy: 86.64\n",
      "[63, 60] loss: 0.097\n",
      "[63, 120] loss: 0.094\n",
      "[63, 180] loss: 0.096\n",
      "[63, 240] loss: 0.099\n",
      "[63, 300] loss: 0.106\n",
      "[63, 360] loss: 0.100\n",
      "Epoch: 63 -> Loss: 0.107512846589\n",
      "Epoch: 63 -> Test Accuracy: 86.66\n",
      "[64, 60] loss: 0.098\n",
      "[64, 120] loss: 0.109\n",
      "[64, 180] loss: 0.100\n",
      "[64, 240] loss: 0.103\n",
      "[64, 300] loss: 0.100\n",
      "[64, 360] loss: 0.102\n",
      "Epoch: 64 -> Loss: 0.0828208550811\n",
      "Epoch: 64 -> Test Accuracy: 86.73\n",
      "[65, 60] loss: 0.098\n",
      "[65, 120] loss: 0.097\n",
      "[65, 180] loss: 0.102\n",
      "[65, 240] loss: 0.096\n",
      "[65, 300] loss: 0.098\n",
      "[65, 360] loss: 0.101\n",
      "Epoch: 65 -> Loss: 0.0965727418661\n",
      "Epoch: 65 -> Test Accuracy: 86.81\n",
      "[66, 60] loss: 0.095\n",
      "[66, 120] loss: 0.102\n",
      "[66, 180] loss: 0.102\n",
      "[66, 240] loss: 0.092\n",
      "[66, 300] loss: 0.100\n",
      "[66, 360] loss: 0.094\n",
      "Epoch: 66 -> Loss: 0.0906546264887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Test Accuracy: 86.83\n",
      "[67, 60] loss: 0.096\n",
      "[67, 120] loss: 0.093\n",
      "[67, 180] loss: 0.095\n",
      "[67, 240] loss: 0.097\n",
      "[67, 300] loss: 0.101\n",
      "[67, 360] loss: 0.092\n",
      "Epoch: 67 -> Loss: 0.230220392346\n",
      "Epoch: 67 -> Test Accuracy: 86.75\n",
      "[68, 60] loss: 0.095\n",
      "[68, 120] loss: 0.098\n",
      "[68, 180] loss: 0.100\n",
      "[68, 240] loss: 0.098\n",
      "[68, 300] loss: 0.094\n",
      "[68, 360] loss: 0.097\n",
      "Epoch: 68 -> Loss: 0.126962468028\n",
      "Epoch: 68 -> Test Accuracy: 86.8\n",
      "[69, 60] loss: 0.093\n",
      "[69, 120] loss: 0.100\n",
      "[69, 180] loss: 0.093\n",
      "[69, 240] loss: 0.093\n",
      "[69, 300] loss: 0.093\n",
      "[69, 360] loss: 0.094\n",
      "Epoch: 69 -> Loss: 0.112899698317\n",
      "Epoch: 69 -> Test Accuracy: 86.77\n",
      "[70, 60] loss: 0.093\n",
      "[70, 120] loss: 0.096\n",
      "[70, 180] loss: 0.098\n",
      "[70, 240] loss: 0.093\n",
      "[70, 300] loss: 0.102\n",
      "[70, 360] loss: 0.099\n",
      "Epoch: 70 -> Loss: 0.105285428464\n",
      "Epoch: 70 -> Test Accuracy: 86.8\n",
      "[71, 60] loss: 0.088\n",
      "[71, 120] loss: 0.091\n",
      "[71, 180] loss: 0.095\n",
      "[71, 240] loss: 0.092\n",
      "[71, 300] loss: 0.096\n",
      "[71, 360] loss: 0.095\n",
      "Epoch: 71 -> Loss: 0.0513737201691\n",
      "Epoch: 71 -> Test Accuracy: 86.74\n",
      "[72, 60] loss: 0.091\n",
      "[72, 120] loss: 0.086\n",
      "[72, 180] loss: 0.094\n",
      "[72, 240] loss: 0.094\n",
      "[72, 300] loss: 0.094\n",
      "[72, 360] loss: 0.095\n",
      "Epoch: 72 -> Loss: 0.0756416618824\n",
      "Epoch: 72 -> Test Accuracy: 86.74\n",
      "[73, 60] loss: 0.091\n",
      "[73, 120] loss: 0.093\n",
      "[73, 180] loss: 0.097\n",
      "[73, 240] loss: 0.090\n",
      "[73, 300] loss: 0.093\n",
      "[73, 360] loss: 0.090\n",
      "Epoch: 73 -> Loss: 0.143479973078\n",
      "Epoch: 73 -> Test Accuracy: 86.68\n",
      "[74, 60] loss: 0.094\n",
      "[74, 120] loss: 0.090\n",
      "[74, 180] loss: 0.093\n",
      "[74, 240] loss: 0.088\n",
      "[74, 300] loss: 0.093\n",
      "[74, 360] loss: 0.086\n",
      "Epoch: 74 -> Loss: 0.16214671731\n",
      "Epoch: 74 -> Test Accuracy: 86.66\n",
      "[75, 60] loss: 0.088\n",
      "[75, 120] loss: 0.090\n",
      "[75, 180] loss: 0.095\n",
      "[75, 240] loss: 0.089\n",
      "[75, 300] loss: 0.088\n",
      "[75, 360] loss: 0.093\n",
      "Epoch: 75 -> Loss: 0.171154215932\n",
      "Epoch: 75 -> Test Accuracy: 86.77\n",
      "[76, 60] loss: 0.093\n",
      "[76, 120] loss: 0.094\n",
      "[76, 180] loss: 0.091\n",
      "[76, 240] loss: 0.082\n",
      "[76, 300] loss: 0.086\n",
      "[76, 360] loss: 0.092\n",
      "Epoch: 76 -> Loss: 0.084661334753\n",
      "Epoch: 76 -> Test Accuracy: 86.78\n",
      "[77, 60] loss: 0.085\n",
      "[77, 120] loss: 0.087\n",
      "[77, 180] loss: 0.090\n",
      "[77, 240] loss: 0.094\n",
      "[77, 300] loss: 0.093\n",
      "[77, 360] loss: 0.094\n",
      "Epoch: 77 -> Loss: 0.15050201118\n",
      "Epoch: 77 -> Test Accuracy: 86.77\n",
      "[78, 60] loss: 0.089\n",
      "[78, 120] loss: 0.088\n",
      "[78, 180] loss: 0.091\n",
      "[78, 240] loss: 0.087\n",
      "[78, 300] loss: 0.088\n",
      "[78, 360] loss: 0.086\n",
      "Epoch: 78 -> Loss: 0.0578078553081\n",
      "Epoch: 78 -> Test Accuracy: 86.75\n",
      "[79, 60] loss: 0.089\n",
      "[79, 120] loss: 0.090\n",
      "[79, 180] loss: 0.088\n",
      "[79, 240] loss: 0.088\n",
      "[79, 300] loss: 0.096\n",
      "[79, 360] loss: 0.089\n",
      "Epoch: 79 -> Loss: 0.0875254422426\n",
      "Epoch: 79 -> Test Accuracy: 86.83\n",
      "[80, 60] loss: 0.080\n",
      "[80, 120] loss: 0.090\n",
      "[80, 180] loss: 0.085\n",
      "[80, 240] loss: 0.092\n",
      "[80, 300] loss: 0.082\n",
      "[80, 360] loss: 0.086\n",
      "Epoch: 80 -> Loss: 0.124927520752\n",
      "Epoch: 80 -> Test Accuracy: 86.72\n",
      "[81, 60] loss: 0.079\n",
      "[81, 120] loss: 0.081\n",
      "[81, 180] loss: 0.090\n",
      "[81, 240] loss: 0.091\n",
      "[81, 300] loss: 0.085\n",
      "[81, 360] loss: 0.092\n",
      "Epoch: 81 -> Loss: 0.105617366731\n",
      "Epoch: 81 -> Test Accuracy: 86.93\n",
      "[82, 60] loss: 0.084\n",
      "[82, 120] loss: 0.089\n",
      "[82, 180] loss: 0.089\n",
      "[82, 240] loss: 0.088\n",
      "[82, 300] loss: 0.087\n",
      "[82, 360] loss: 0.090\n",
      "Epoch: 82 -> Loss: 0.029067998752\n",
      "Epoch: 82 -> Test Accuracy: 86.71\n",
      "[83, 60] loss: 0.082\n",
      "[83, 120] loss: 0.087\n",
      "[83, 180] loss: 0.089\n",
      "[83, 240] loss: 0.083\n",
      "[83, 300] loss: 0.089\n",
      "[83, 360] loss: 0.081\n",
      "Epoch: 83 -> Loss: 0.0639834478498\n",
      "Epoch: 83 -> Test Accuracy: 86.75\n",
      "[84, 60] loss: 0.087\n",
      "[84, 120] loss: 0.090\n",
      "[84, 180] loss: 0.086\n",
      "[84, 240] loss: 0.084\n",
      "[84, 300] loss: 0.084\n",
      "[84, 360] loss: 0.077\n",
      "Epoch: 84 -> Loss: 0.214003324509\n",
      "Epoch: 84 -> Test Accuracy: 86.83\n",
      "[85, 60] loss: 0.087\n",
      "[85, 120] loss: 0.083\n",
      "[85, 180] loss: 0.077\n",
      "[85, 240] loss: 0.081\n",
      "[85, 300] loss: 0.086\n",
      "[85, 360] loss: 0.085\n",
      "Epoch: 85 -> Loss: 0.096241876483\n",
      "Epoch: 85 -> Test Accuracy: 86.76\n",
      "[86, 60] loss: 0.084\n",
      "[86, 120] loss: 0.086\n",
      "[86, 180] loss: 0.080\n",
      "[86, 240] loss: 0.087\n",
      "[86, 300] loss: 0.085\n",
      "[86, 360] loss: 0.078\n",
      "Epoch: 86 -> Loss: 0.0934243425727\n",
      "Epoch: 86 -> Test Accuracy: 86.85\n",
      "[87, 60] loss: 0.086\n",
      "[87, 120] loss: 0.081\n",
      "[87, 180] loss: 0.081\n",
      "[87, 240] loss: 0.089\n",
      "[87, 300] loss: 0.086\n",
      "[87, 360] loss: 0.086\n",
      "Epoch: 87 -> Loss: 0.114838458598\n",
      "Epoch: 87 -> Test Accuracy: 86.77\n",
      "[88, 60] loss: 0.089\n",
      "[88, 120] loss: 0.086\n",
      "[88, 180] loss: 0.084\n",
      "[88, 240] loss: 0.087\n",
      "[88, 300] loss: 0.084\n",
      "[88, 360] loss: 0.079\n",
      "Epoch: 88 -> Loss: 0.0664984509349\n",
      "Epoch: 88 -> Test Accuracy: 86.83\n",
      "[89, 60] loss: 0.087\n",
      "[89, 120] loss: 0.081\n",
      "[89, 180] loss: 0.085\n",
      "[89, 240] loss: 0.083\n",
      "[89, 300] loss: 0.082\n",
      "[89, 360] loss: 0.087\n",
      "Epoch: 89 -> Loss: 0.119344472885\n",
      "Epoch: 89 -> Test Accuracy: 86.96\n",
      "[90, 60] loss: 0.079\n",
      "[90, 120] loss: 0.078\n",
      "[90, 180] loss: 0.078\n",
      "[90, 240] loss: 0.084\n",
      "[90, 300] loss: 0.083\n",
      "[90, 360] loss: 0.080\n",
      "Epoch: 90 -> Loss: 0.133886605501\n",
      "Epoch: 90 -> Test Accuracy: 87.09\n",
      "[91, 60] loss: 0.081\n",
      "[91, 120] loss: 0.085\n",
      "[91, 180] loss: 0.078\n",
      "[91, 240] loss: 0.083\n",
      "[91, 300] loss: 0.082\n",
      "[91, 360] loss: 0.070\n",
      "Epoch: 91 -> Loss: 0.113796636462\n",
      "Epoch: 91 -> Test Accuracy: 86.91\n",
      "[92, 60] loss: 0.084\n",
      "[92, 120] loss: 0.078\n",
      "[92, 180] loss: 0.083\n",
      "[92, 240] loss: 0.077\n",
      "[92, 300] loss: 0.083\n",
      "[92, 360] loss: 0.081\n",
      "Epoch: 92 -> Loss: 0.195735186338\n",
      "Epoch: 92 -> Test Accuracy: 86.9\n",
      "[93, 60] loss: 0.080\n",
      "[93, 120] loss: 0.075\n",
      "[93, 180] loss: 0.081\n",
      "[93, 240] loss: 0.078\n",
      "[93, 300] loss: 0.085\n",
      "[93, 360] loss: 0.079\n",
      "Epoch: 93 -> Loss: 0.174853935838\n",
      "Epoch: 93 -> Test Accuracy: 86.87\n",
      "[94, 60] loss: 0.079\n",
      "[94, 120] loss: 0.080\n",
      "[94, 180] loss: 0.080\n",
      "[94, 240] loss: 0.076\n",
      "[94, 300] loss: 0.093\n",
      "[94, 360] loss: 0.083\n",
      "Epoch: 94 -> Loss: 0.0825445726514\n",
      "Epoch: 94 -> Test Accuracy: 86.86\n",
      "[95, 60] loss: 0.074\n",
      "[95, 120] loss: 0.076\n",
      "[95, 180] loss: 0.082\n",
      "[95, 240] loss: 0.078\n",
      "[95, 300] loss: 0.078\n",
      "[95, 360] loss: 0.078\n",
      "Epoch: 95 -> Loss: 0.0342990197241\n",
      "Epoch: 95 -> Test Accuracy: 86.76\n",
      "[96, 60] loss: 0.080\n",
      "[96, 120] loss: 0.076\n",
      "[96, 180] loss: 0.082\n",
      "[96, 240] loss: 0.080\n",
      "[96, 300] loss: 0.077\n",
      "[96, 360] loss: 0.081\n",
      "Epoch: 96 -> Loss: 0.0441205427051\n",
      "Epoch: 96 -> Test Accuracy: 86.85\n",
      "[97, 60] loss: 0.076\n",
      "[97, 120] loss: 0.081\n",
      "[97, 180] loss: 0.073\n",
      "[97, 240] loss: 0.079\n",
      "[97, 300] loss: 0.076\n",
      "[97, 360] loss: 0.080\n",
      "Epoch: 97 -> Loss: 0.142167195678\n",
      "Epoch: 97 -> Test Accuracy: 86.83\n",
      "[98, 60] loss: 0.076\n",
      "[98, 120] loss: 0.071\n",
      "[98, 180] loss: 0.075\n",
      "[98, 240] loss: 0.087\n",
      "[98, 300] loss: 0.083\n",
      "[98, 360] loss: 0.079\n",
      "Epoch: 98 -> Loss: 0.0865980088711\n",
      "Epoch: 98 -> Test Accuracy: 86.82\n",
      "[99, 60] loss: 0.073\n",
      "[99, 120] loss: 0.081\n",
      "[99, 180] loss: 0.081\n",
      "[99, 240] loss: 0.082\n",
      "[99, 300] loss: 0.083\n",
      "[99, 360] loss: 0.076\n",
      "Epoch: 99 -> Loss: 0.0401055291295\n",
      "Epoch: 99 -> Test Accuracy: 86.73\n",
      "[100, 60] loss: 0.083\n",
      "[100, 120] loss: 0.077\n",
      "[100, 180] loss: 0.081\n",
      "[100, 240] loss: 0.074\n",
      "[100, 300] loss: 0.073\n",
      "[100, 360] loss: 0.080\n",
      "Epoch: 100 -> Loss: 0.0495482906699\n",
      "Epoch: 100 -> Test Accuracy: 86.81\n",
      "Finished Training\n",
      "[1, 60] loss: 1.712\n",
      "[1, 120] loss: 0.882\n",
      "[1, 180] loss: 0.799\n",
      "[1, 240] loss: 0.799\n",
      "[1, 300] loss: 0.761\n",
      "[1, 360] loss: 0.733\n",
      "Epoch: 1 -> Loss: 0.725608706474\n",
      "Epoch: 1 -> Test Accuracy: 74.08\n",
      "[2, 60] loss: 0.689\n",
      "[2, 120] loss: 0.680\n",
      "[2, 180] loss: 0.672\n",
      "[2, 240] loss: 0.660\n",
      "[2, 300] loss: 0.635\n",
      "[2, 360] loss: 0.641\n",
      "Epoch: 2 -> Loss: 0.682466804981\n",
      "Epoch: 2 -> Test Accuracy: 76.6\n",
      "[3, 60] loss: 0.596\n",
      "[3, 120] loss: 0.615\n",
      "[3, 180] loss: 0.610\n",
      "[3, 240] loss: 0.609\n",
      "[3, 300] loss: 0.609\n",
      "[3, 360] loss: 0.600\n",
      "Epoch: 3 -> Loss: 0.884213447571\n",
      "Epoch: 3 -> Test Accuracy: 77.27\n",
      "[4, 60] loss: 0.571\n",
      "[4, 120] loss: 0.576\n",
      "[4, 180] loss: 0.594\n",
      "[4, 240] loss: 0.562\n",
      "[4, 300] loss: 0.578\n",
      "[4, 360] loss: 0.573\n",
      "Epoch: 4 -> Loss: 0.462479770184\n",
      "Epoch: 4 -> Test Accuracy: 78.3\n",
      "[5, 60] loss: 0.534\n",
      "[5, 120] loss: 0.565\n",
      "[5, 180] loss: 0.542\n",
      "[5, 240] loss: 0.561\n",
      "[5, 300] loss: 0.549\n",
      "[5, 360] loss: 0.572\n",
      "Epoch: 5 -> Loss: 0.54799580574\n",
      "Epoch: 5 -> Test Accuracy: 79.04\n",
      "[6, 60] loss: 0.550\n",
      "[6, 120] loss: 0.537\n",
      "[6, 180] loss: 0.536\n",
      "[6, 240] loss: 0.546\n",
      "[6, 300] loss: 0.545\n",
      "[6, 360] loss: 0.544\n",
      "Epoch: 6 -> Loss: 0.62681043148\n",
      "Epoch: 6 -> Test Accuracy: 78.85\n",
      "[7, 60] loss: 0.526\n",
      "[7, 120] loss: 0.509\n",
      "[7, 180] loss: 0.552\n",
      "[7, 240] loss: 0.530\n",
      "[7, 300] loss: 0.531\n",
      "[7, 360] loss: 0.534\n",
      "Epoch: 7 -> Loss: 0.540509104729\n",
      "Epoch: 7 -> Test Accuracy: 79.32\n",
      "[8, 60] loss: 0.502\n",
      "[8, 120] loss: 0.520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 180] loss: 0.533\n",
      "[8, 240] loss: 0.523\n",
      "[8, 300] loss: 0.532\n",
      "[8, 360] loss: 0.520\n",
      "Epoch: 8 -> Loss: 0.41220331192\n",
      "Epoch: 8 -> Test Accuracy: 79.43\n",
      "[9, 60] loss: 0.504\n",
      "[9, 120] loss: 0.518\n",
      "[9, 180] loss: 0.522\n",
      "[9, 240] loss: 0.513\n",
      "[9, 300] loss: 0.523\n",
      "[9, 360] loss: 0.516\n",
      "Epoch: 9 -> Loss: 0.491658776999\n",
      "Epoch: 9 -> Test Accuracy: 79.42\n",
      "[10, 60] loss: 0.494\n",
      "[10, 120] loss: 0.495\n",
      "[10, 180] loss: 0.506\n",
      "[10, 240] loss: 0.519\n",
      "[10, 300] loss: 0.520\n",
      "[10, 360] loss: 0.513\n",
      "Epoch: 10 -> Loss: 0.618852853775\n",
      "Epoch: 10 -> Test Accuracy: 79.01\n",
      "[11, 60] loss: 0.496\n",
      "[11, 120] loss: 0.484\n",
      "[11, 180] loss: 0.520\n",
      "[11, 240] loss: 0.516\n",
      "[11, 300] loss: 0.508\n",
      "[11, 360] loss: 0.503\n",
      "Epoch: 11 -> Loss: 0.436768859625\n",
      "Epoch: 11 -> Test Accuracy: 80.14\n",
      "[12, 60] loss: 0.488\n",
      "[12, 120] loss: 0.512\n",
      "[12, 180] loss: 0.499\n",
      "[12, 240] loss: 0.511\n",
      "[12, 300] loss: 0.502\n",
      "[12, 360] loss: 0.504\n",
      "Epoch: 12 -> Loss: 0.510075986385\n",
      "Epoch: 12 -> Test Accuracy: 79.88\n",
      "[13, 60] loss: 0.485\n",
      "[13, 120] loss: 0.473\n",
      "[13, 180] loss: 0.503\n",
      "[13, 240] loss: 0.493\n",
      "[13, 300] loss: 0.505\n",
      "[13, 360] loss: 0.488\n",
      "Epoch: 13 -> Loss: 0.611711680889\n",
      "Epoch: 13 -> Test Accuracy: 79.58\n",
      "[14, 60] loss: 0.482\n",
      "[14, 120] loss: 0.505\n",
      "[14, 180] loss: 0.483\n",
      "[14, 240] loss: 0.492\n",
      "[14, 300] loss: 0.505\n",
      "[14, 360] loss: 0.505\n",
      "Epoch: 14 -> Loss: 0.261534631252\n",
      "Epoch: 14 -> Test Accuracy: 79.99\n",
      "[15, 60] loss: 0.488\n",
      "[15, 120] loss: 0.503\n",
      "[15, 180] loss: 0.489\n",
      "[15, 240] loss: 0.485\n",
      "[15, 300] loss: 0.493\n",
      "[15, 360] loss: 0.506\n",
      "Epoch: 15 -> Loss: 0.45762437582\n",
      "Epoch: 15 -> Test Accuracy: 80.19\n",
      "[16, 60] loss: 0.473\n",
      "[16, 120] loss: 0.457\n",
      "[16, 180] loss: 0.486\n",
      "[16, 240] loss: 0.502\n",
      "[16, 300] loss: 0.495\n",
      "[16, 360] loss: 0.489\n",
      "Epoch: 16 -> Loss: 0.659011244774\n",
      "Epoch: 16 -> Test Accuracy: 79.44\n",
      "[17, 60] loss: 0.461\n",
      "[17, 120] loss: 0.461\n",
      "[17, 180] loss: 0.491\n",
      "[17, 240] loss: 0.486\n",
      "[17, 300] loss: 0.499\n",
      "[17, 360] loss: 0.511\n",
      "Epoch: 17 -> Loss: 0.354067713022\n",
      "Epoch: 17 -> Test Accuracy: 79.96\n",
      "[18, 60] loss: 0.466\n",
      "[18, 120] loss: 0.478\n",
      "[18, 180] loss: 0.481\n",
      "[18, 240] loss: 0.490\n",
      "[18, 300] loss: 0.499\n",
      "[18, 360] loss: 0.488\n",
      "Epoch: 18 -> Loss: 0.39367711544\n",
      "Epoch: 18 -> Test Accuracy: 80.4\n",
      "[19, 60] loss: 0.488\n",
      "[19, 120] loss: 0.471\n",
      "[19, 180] loss: 0.492\n",
      "[19, 240] loss: 0.490\n",
      "[19, 300] loss: 0.493\n",
      "[19, 360] loss: 0.492\n",
      "Epoch: 19 -> Loss: 0.437897980213\n",
      "Epoch: 19 -> Test Accuracy: 79.92\n",
      "[20, 60] loss: 0.449\n",
      "[20, 120] loss: 0.461\n",
      "[20, 180] loss: 0.501\n",
      "[20, 240] loss: 0.488\n",
      "[20, 300] loss: 0.499\n",
      "[20, 360] loss: 0.497\n",
      "Epoch: 20 -> Loss: 0.556707382202\n",
      "Epoch: 20 -> Test Accuracy: 80.51\n",
      "[21, 60] loss: 0.441\n",
      "[21, 120] loss: 0.428\n",
      "[21, 180] loss: 0.429\n",
      "[21, 240] loss: 0.400\n",
      "[21, 300] loss: 0.405\n",
      "[21, 360] loss: 0.399\n",
      "Epoch: 21 -> Loss: 0.40817913413\n",
      "Epoch: 21 -> Test Accuracy: 82.12\n",
      "[22, 60] loss: 0.378\n",
      "[22, 120] loss: 0.390\n",
      "[22, 180] loss: 0.392\n",
      "[22, 240] loss: 0.370\n",
      "[22, 300] loss: 0.404\n",
      "[22, 360] loss: 0.376\n",
      "Epoch: 22 -> Loss: 0.489045441151\n",
      "Epoch: 22 -> Test Accuracy: 82.05\n",
      "[23, 60] loss: 0.389\n",
      "[23, 120] loss: 0.357\n",
      "[23, 180] loss: 0.367\n",
      "[23, 240] loss: 0.368\n",
      "[23, 300] loss: 0.369\n",
      "[23, 360] loss: 0.371\n",
      "Epoch: 23 -> Loss: 0.382028520107\n",
      "Epoch: 23 -> Test Accuracy: 82.41\n",
      "[24, 60] loss: 0.371\n",
      "[24, 120] loss: 0.357\n",
      "[24, 180] loss: 0.342\n",
      "[24, 240] loss: 0.359\n",
      "[24, 300] loss: 0.364\n",
      "[24, 360] loss: 0.348\n",
      "Epoch: 24 -> Loss: 0.329211682081\n",
      "Epoch: 24 -> Test Accuracy: 82.42\n",
      "[25, 60] loss: 0.341\n",
      "[25, 120] loss: 0.361\n",
      "[25, 180] loss: 0.354\n",
      "[25, 240] loss: 0.342\n",
      "[25, 300] loss: 0.351\n",
      "[25, 360] loss: 0.360\n",
      "Epoch: 25 -> Loss: 0.281580328941\n",
      "Epoch: 25 -> Test Accuracy: 82.38\n",
      "[26, 60] loss: 0.345\n",
      "[26, 120] loss: 0.345\n",
      "[26, 180] loss: 0.343\n",
      "[26, 240] loss: 0.342\n",
      "[26, 300] loss: 0.347\n",
      "[26, 360] loss: 0.361\n",
      "Epoch: 26 -> Loss: 0.645790457726\n",
      "Epoch: 26 -> Test Accuracy: 82.41\n",
      "[27, 60] loss: 0.321\n",
      "[27, 120] loss: 0.331\n",
      "[27, 180] loss: 0.340\n",
      "[27, 240] loss: 0.347\n",
      "[27, 300] loss: 0.338\n",
      "[27, 360] loss: 0.358\n",
      "Epoch: 27 -> Loss: 0.500192224979\n",
      "Epoch: 27 -> Test Accuracy: 82.48\n",
      "[28, 60] loss: 0.338\n",
      "[28, 120] loss: 0.334\n",
      "[28, 180] loss: 0.339\n",
      "[28, 240] loss: 0.342\n",
      "[28, 300] loss: 0.336\n",
      "[28, 360] loss: 0.351\n",
      "Epoch: 28 -> Loss: 0.398776829243\n",
      "Epoch: 28 -> Test Accuracy: 82.43\n",
      "[29, 60] loss: 0.326\n",
      "[29, 120] loss: 0.338\n",
      "[29, 180] loss: 0.336\n",
      "[29, 240] loss: 0.325\n",
      "[29, 300] loss: 0.329\n",
      "[29, 360] loss: 0.351\n",
      "Epoch: 29 -> Loss: 0.352448642254\n",
      "Epoch: 29 -> Test Accuracy: 82.05\n",
      "[30, 60] loss: 0.317\n",
      "[30, 120] loss: 0.317\n",
      "[30, 180] loss: 0.342\n",
      "[30, 240] loss: 0.340\n",
      "[30, 300] loss: 0.323\n",
      "[30, 360] loss: 0.342\n",
      "Epoch: 30 -> Loss: 0.419357866049\n",
      "Epoch: 30 -> Test Accuracy: 82.16\n",
      "[31, 60] loss: 0.314\n",
      "[31, 120] loss: 0.349\n",
      "[31, 180] loss: 0.343\n",
      "[31, 240] loss: 0.324\n",
      "[31, 300] loss: 0.342\n",
      "[31, 360] loss: 0.341\n",
      "Epoch: 31 -> Loss: 0.44971293211\n",
      "Epoch: 31 -> Test Accuracy: 82.11\n",
      "[32, 60] loss: 0.312\n",
      "[32, 120] loss: 0.328\n",
      "[32, 180] loss: 0.342\n",
      "[32, 240] loss: 0.337\n",
      "[32, 300] loss: 0.334\n",
      "[32, 360] loss: 0.336\n",
      "Epoch: 32 -> Loss: 0.351040989161\n",
      "Epoch: 32 -> Test Accuracy: 82.2\n",
      "[33, 60] loss: 0.324\n",
      "[33, 120] loss: 0.312\n",
      "[33, 180] loss: 0.319\n",
      "[33, 240] loss: 0.342\n",
      "[33, 300] loss: 0.325\n",
      "[33, 360] loss: 0.338\n",
      "Epoch: 33 -> Loss: 0.481633335352\n",
      "Epoch: 33 -> Test Accuracy: 82.35\n",
      "[34, 60] loss: 0.326\n",
      "[34, 120] loss: 0.331\n",
      "[34, 180] loss: 0.321\n",
      "[34, 240] loss: 0.318\n",
      "[34, 300] loss: 0.325\n",
      "[34, 360] loss: 0.343\n",
      "Epoch: 34 -> Loss: 0.31899702549\n",
      "Epoch: 34 -> Test Accuracy: 82.35\n",
      "[35, 60] loss: 0.300\n",
      "[35, 120] loss: 0.322\n",
      "[35, 180] loss: 0.335\n",
      "[35, 240] loss: 0.315\n",
      "[35, 300] loss: 0.336\n",
      "[35, 360] loss: 0.334\n",
      "Epoch: 35 -> Loss: 0.378879010677\n",
      "Epoch: 35 -> Test Accuracy: 82.21\n",
      "[36, 60] loss: 0.319\n",
      "[36, 120] loss: 0.324\n",
      "[36, 180] loss: 0.304\n",
      "[36, 240] loss: 0.314\n",
      "[36, 300] loss: 0.319\n",
      "[36, 360] loss: 0.334\n",
      "Epoch: 36 -> Loss: 0.367710262537\n",
      "Epoch: 36 -> Test Accuracy: 81.97\n",
      "[37, 60] loss: 0.322\n",
      "[37, 120] loss: 0.323\n",
      "[37, 180] loss: 0.327\n",
      "[37, 240] loss: 0.325\n",
      "[37, 300] loss: 0.324\n",
      "[37, 360] loss: 0.331\n",
      "Epoch: 37 -> Loss: 0.331134974957\n",
      "Epoch: 37 -> Test Accuracy: 81.96\n",
      "[38, 60] loss: 0.313\n",
      "[38, 120] loss: 0.312\n",
      "[38, 180] loss: 0.324\n",
      "[38, 240] loss: 0.321\n",
      "[38, 300] loss: 0.336\n",
      "[38, 360] loss: 0.344\n",
      "Epoch: 38 -> Loss: 0.36177945137\n",
      "Epoch: 38 -> Test Accuracy: 81.53\n",
      "[39, 60] loss: 0.312\n",
      "[39, 120] loss: 0.311\n",
      "[39, 180] loss: 0.307\n",
      "[39, 240] loss: 0.329\n",
      "[39, 300] loss: 0.312\n",
      "[39, 360] loss: 0.338\n",
      "Epoch: 39 -> Loss: 0.279049754143\n",
      "Epoch: 39 -> Test Accuracy: 82.23\n",
      "[40, 60] loss: 0.318\n",
      "[40, 120] loss: 0.320\n",
      "[40, 180] loss: 0.314\n",
      "[40, 240] loss: 0.333\n",
      "[40, 300] loss: 0.321\n",
      "[40, 360] loss: 0.319\n",
      "Epoch: 40 -> Loss: 0.372402667999\n",
      "Epoch: 40 -> Test Accuracy: 81.65\n",
      "[41, 60] loss: 0.299\n",
      "[41, 120] loss: 0.296\n",
      "[41, 180] loss: 0.291\n",
      "[41, 240] loss: 0.279\n",
      "[41, 300] loss: 0.276\n",
      "[41, 360] loss: 0.298\n",
      "Epoch: 41 -> Loss: 0.271794259548\n",
      "Epoch: 41 -> Test Accuracy: 82.42\n",
      "[42, 60] loss: 0.260\n",
      "[42, 120] loss: 0.281\n",
      "[42, 180] loss: 0.257\n",
      "[42, 240] loss: 0.274\n",
      "[42, 300] loss: 0.284\n",
      "[42, 360] loss: 0.267\n",
      "Epoch: 42 -> Loss: 0.381589710712\n",
      "Epoch: 42 -> Test Accuracy: 82.68\n",
      "[43, 60] loss: 0.263\n",
      "[43, 120] loss: 0.269\n",
      "[43, 180] loss: 0.259\n",
      "[43, 240] loss: 0.250\n",
      "[43, 300] loss: 0.265\n",
      "[43, 360] loss: 0.254\n",
      "Epoch: 43 -> Loss: 0.350717246532\n",
      "Epoch: 43 -> Test Accuracy: 82.66\n",
      "[44, 60] loss: 0.253\n",
      "[44, 120] loss: 0.246\n",
      "[44, 180] loss: 0.261\n",
      "[44, 240] loss: 0.257\n",
      "[44, 300] loss: 0.242\n",
      "[44, 360] loss: 0.250\n",
      "Epoch: 44 -> Loss: 0.217512965202\n",
      "Epoch: 44 -> Test Accuracy: 82.59\n",
      "[45, 60] loss: 0.247\n",
      "[45, 120] loss: 0.242\n",
      "[45, 180] loss: 0.255\n",
      "[45, 240] loss: 0.240\n",
      "[45, 300] loss: 0.253\n",
      "[45, 360] loss: 0.250\n",
      "Epoch: 45 -> Loss: 0.335032522678\n",
      "Epoch: 45 -> Test Accuracy: 82.52\n",
      "[46, 60] loss: 0.244\n",
      "[46, 120] loss: 0.224\n",
      "[46, 180] loss: 0.235\n",
      "[46, 240] loss: 0.256\n",
      "[46, 300] loss: 0.229\n",
      "[46, 360] loss: 0.228\n",
      "Epoch: 46 -> Loss: 0.357813209295\n",
      "Epoch: 46 -> Test Accuracy: 82.62\n",
      "[47, 60] loss: 0.226\n",
      "[47, 120] loss: 0.231\n",
      "[47, 180] loss: 0.234\n",
      "[47, 240] loss: 0.241\n",
      "[47, 300] loss: 0.227\n",
      "[47, 360] loss: 0.247\n",
      "Epoch: 47 -> Loss: 0.202796503901\n",
      "Epoch: 47 -> Test Accuracy: 82.8\n",
      "[48, 60] loss: 0.234\n",
      "[48, 120] loss: 0.240\n",
      "[48, 180] loss: 0.245\n",
      "[48, 240] loss: 0.231\n",
      "[48, 300] loss: 0.232\n",
      "[48, 360] loss: 0.239\n",
      "Epoch: 48 -> Loss: 0.109588168561\n",
      "Epoch: 48 -> Test Accuracy: 82.78\n",
      "[49, 60] loss: 0.220\n",
      "[49, 120] loss: 0.232\n",
      "[49, 180] loss: 0.234\n",
      "[49, 240] loss: 0.229\n",
      "[49, 300] loss: 0.233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 360] loss: 0.227\n",
      "Epoch: 49 -> Loss: 0.266876459122\n",
      "Epoch: 49 -> Test Accuracy: 82.72\n",
      "[50, 60] loss: 0.231\n",
      "[50, 120] loss: 0.236\n",
      "[50, 180] loss: 0.230\n",
      "[50, 240] loss: 0.233\n",
      "[50, 300] loss: 0.234\n",
      "[50, 360] loss: 0.243\n",
      "Epoch: 50 -> Loss: 0.177063465118\n",
      "Epoch: 50 -> Test Accuracy: 82.67\n",
      "[51, 60] loss: 0.223\n",
      "[51, 120] loss: 0.224\n",
      "[51, 180] loss: 0.239\n",
      "[51, 240] loss: 0.235\n",
      "[51, 300] loss: 0.229\n",
      "[51, 360] loss: 0.221\n",
      "Epoch: 51 -> Loss: 0.218640118837\n",
      "Epoch: 51 -> Test Accuracy: 82.82\n",
      "[52, 60] loss: 0.230\n",
      "[52, 120] loss: 0.224\n",
      "[52, 180] loss: 0.224\n",
      "[52, 240] loss: 0.222\n",
      "[52, 300] loss: 0.227\n",
      "[52, 360] loss: 0.224\n",
      "Epoch: 52 -> Loss: 0.189923122525\n",
      "Epoch: 52 -> Test Accuracy: 82.8\n",
      "[53, 60] loss: 0.230\n",
      "[53, 120] loss: 0.217\n",
      "[53, 180] loss: 0.219\n",
      "[53, 240] loss: 0.223\n",
      "[53, 300] loss: 0.223\n",
      "[53, 360] loss: 0.221\n",
      "Epoch: 53 -> Loss: 0.257568657398\n",
      "Epoch: 53 -> Test Accuracy: 82.74\n",
      "[54, 60] loss: 0.221\n",
      "[54, 120] loss: 0.223\n",
      "[54, 180] loss: 0.212\n",
      "[54, 240] loss: 0.221\n",
      "[54, 300] loss: 0.222\n",
      "[54, 360] loss: 0.233\n",
      "Epoch: 54 -> Loss: 0.244090586901\n",
      "Epoch: 54 -> Test Accuracy: 82.72\n",
      "[55, 60] loss: 0.229\n",
      "[55, 120] loss: 0.219\n",
      "[55, 180] loss: 0.223\n",
      "[55, 240] loss: 0.228\n",
      "[55, 300] loss: 0.218\n",
      "[55, 360] loss: 0.213\n",
      "Epoch: 55 -> Loss: 0.269835144281\n",
      "Epoch: 55 -> Test Accuracy: 82.7\n",
      "[56, 60] loss: 0.223\n",
      "[56, 120] loss: 0.223\n",
      "[56, 180] loss: 0.233\n",
      "[56, 240] loss: 0.223\n",
      "[56, 300] loss: 0.219\n",
      "[56, 360] loss: 0.222\n",
      "Epoch: 56 -> Loss: 0.202019289136\n",
      "Epoch: 56 -> Test Accuracy: 82.77\n",
      "[57, 60] loss: 0.220\n",
      "[57, 120] loss: 0.223\n",
      "[57, 180] loss: 0.222\n",
      "[57, 240] loss: 0.218\n",
      "[57, 300] loss: 0.219\n",
      "[57, 360] loss: 0.222\n",
      "Epoch: 57 -> Loss: 0.203922942281\n",
      "Epoch: 57 -> Test Accuracy: 82.81\n",
      "[58, 60] loss: 0.222\n",
      "[58, 120] loss: 0.226\n",
      "[58, 180] loss: 0.211\n",
      "[58, 240] loss: 0.218\n",
      "[58, 300] loss: 0.225\n",
      "[58, 360] loss: 0.218\n",
      "Epoch: 58 -> Loss: 0.292508929968\n",
      "Epoch: 58 -> Test Accuracy: 82.77\n",
      "[59, 60] loss: 0.221\n",
      "[59, 120] loss: 0.219\n",
      "[59, 180] loss: 0.213\n",
      "[59, 240] loss: 0.223\n",
      "[59, 300] loss: 0.210\n",
      "[59, 360] loss: 0.225\n",
      "Epoch: 59 -> Loss: 0.151245430112\n",
      "Epoch: 59 -> Test Accuracy: 82.9\n",
      "[60, 60] loss: 0.219\n",
      "[60, 120] loss: 0.221\n",
      "[60, 180] loss: 0.209\n",
      "[60, 240] loss: 0.216\n",
      "[60, 300] loss: 0.216\n",
      "[60, 360] loss: 0.210\n",
      "Epoch: 60 -> Loss: 0.307315886021\n",
      "Epoch: 60 -> Test Accuracy: 82.94\n",
      "[61, 60] loss: 0.205\n",
      "[61, 120] loss: 0.221\n",
      "[61, 180] loss: 0.213\n",
      "[61, 240] loss: 0.214\n",
      "[61, 300] loss: 0.219\n",
      "[61, 360] loss: 0.220\n",
      "Epoch: 61 -> Loss: 0.149644941092\n",
      "Epoch: 61 -> Test Accuracy: 82.88\n",
      "[62, 60] loss: 0.216\n",
      "[62, 120] loss: 0.216\n",
      "[62, 180] loss: 0.210\n",
      "[62, 240] loss: 0.207\n",
      "[62, 300] loss: 0.232\n",
      "[62, 360] loss: 0.214\n",
      "Epoch: 62 -> Loss: 0.179108142853\n",
      "Epoch: 62 -> Test Accuracy: 82.9\n",
      "[63, 60] loss: 0.205\n",
      "[63, 120] loss: 0.216\n",
      "[63, 180] loss: 0.202\n",
      "[63, 240] loss: 0.221\n",
      "[63, 300] loss: 0.214\n",
      "[63, 360] loss: 0.222\n",
      "Epoch: 63 -> Loss: 0.292325556278\n",
      "Epoch: 63 -> Test Accuracy: 82.89\n",
      "[64, 60] loss: 0.209\n",
      "[64, 120] loss: 0.204\n",
      "[64, 180] loss: 0.206\n",
      "[64, 240] loss: 0.217\n",
      "[64, 300] loss: 0.222\n",
      "[64, 360] loss: 0.216\n",
      "Epoch: 64 -> Loss: 0.298978626728\n",
      "Epoch: 64 -> Test Accuracy: 82.87\n",
      "[65, 60] loss: 0.208\n",
      "[65, 120] loss: 0.210\n",
      "[65, 180] loss: 0.198\n",
      "[65, 240] loss: 0.212\n",
      "[65, 300] loss: 0.221\n",
      "[65, 360] loss: 0.222\n",
      "Epoch: 65 -> Loss: 0.273337900639\n",
      "Epoch: 65 -> Test Accuracy: 82.81\n",
      "[66, 60] loss: 0.204\n",
      "[66, 120] loss: 0.217\n",
      "[66, 180] loss: 0.207\n",
      "[66, 240] loss: 0.220\n",
      "[66, 300] loss: 0.200\n",
      "[66, 360] loss: 0.214\n",
      "Epoch: 66 -> Loss: 0.244506806135\n",
      "Epoch: 66 -> Test Accuracy: 82.81\n",
      "[67, 60] loss: 0.219\n",
      "[67, 120] loss: 0.201\n",
      "[67, 180] loss: 0.212\n",
      "[67, 240] loss: 0.204\n",
      "[67, 300] loss: 0.204\n",
      "[67, 360] loss: 0.209\n",
      "Epoch: 67 -> Loss: 0.259542226791\n",
      "Epoch: 67 -> Test Accuracy: 82.83\n",
      "[68, 60] loss: 0.205\n",
      "[68, 120] loss: 0.210\n",
      "[68, 180] loss: 0.204\n",
      "[68, 240] loss: 0.214\n",
      "[68, 300] loss: 0.199\n",
      "[68, 360] loss: 0.208\n",
      "Epoch: 68 -> Loss: 0.203338354826\n",
      "Epoch: 68 -> Test Accuracy: 83.0\n",
      "[69, 60] loss: 0.209\n",
      "[69, 120] loss: 0.200\n",
      "[69, 180] loss: 0.218\n",
      "[69, 240] loss: 0.209\n",
      "[69, 300] loss: 0.208\n",
      "[69, 360] loss: 0.198\n",
      "Epoch: 69 -> Loss: 0.299931555986\n",
      "Epoch: 69 -> Test Accuracy: 82.78\n",
      "[70, 60] loss: 0.200\n",
      "[70, 120] loss: 0.203\n",
      "[70, 180] loss: 0.212\n",
      "[70, 240] loss: 0.217\n",
      "[70, 300] loss: 0.199\n",
      "[70, 360] loss: 0.203\n",
      "Epoch: 70 -> Loss: 0.203955292702\n",
      "Epoch: 70 -> Test Accuracy: 82.7\n",
      "[71, 60] loss: 0.207\n",
      "[71, 120] loss: 0.206\n",
      "[71, 180] loss: 0.189\n",
      "[71, 240] loss: 0.208\n",
      "[71, 300] loss: 0.207\n",
      "[71, 360] loss: 0.201\n",
      "Epoch: 71 -> Loss: 0.171313792467\n",
      "Epoch: 71 -> Test Accuracy: 82.83\n",
      "[72, 60] loss: 0.202\n",
      "[72, 120] loss: 0.194\n",
      "[72, 180] loss: 0.210\n",
      "[72, 240] loss: 0.213\n",
      "[72, 300] loss: 0.196\n",
      "[72, 360] loss: 0.202\n",
      "Epoch: 72 -> Loss: 0.265488415956\n",
      "Epoch: 72 -> Test Accuracy: 82.76\n",
      "[73, 60] loss: 0.193\n",
      "[73, 120] loss: 0.203\n",
      "[73, 180] loss: 0.202\n",
      "[73, 240] loss: 0.195\n",
      "[73, 300] loss: 0.197\n",
      "[73, 360] loss: 0.196\n",
      "Epoch: 73 -> Loss: 0.28674659133\n",
      "Epoch: 73 -> Test Accuracy: 82.78\n",
      "[74, 60] loss: 0.194\n",
      "[74, 120] loss: 0.195\n",
      "[74, 180] loss: 0.204\n",
      "[74, 240] loss: 0.207\n",
      "[74, 300] loss: 0.208\n",
      "[74, 360] loss: 0.196\n",
      "Epoch: 74 -> Loss: 0.239073872566\n",
      "Epoch: 74 -> Test Accuracy: 82.79\n",
      "[75, 60] loss: 0.194\n",
      "[75, 120] loss: 0.211\n",
      "[75, 180] loss: 0.200\n",
      "[75, 240] loss: 0.196\n",
      "[75, 300] loss: 0.207\n",
      "[75, 360] loss: 0.199\n",
      "Epoch: 75 -> Loss: 0.168454840779\n",
      "Epoch: 75 -> Test Accuracy: 82.78\n",
      "[76, 60] loss: 0.199\n",
      "[76, 120] loss: 0.203\n",
      "[76, 180] loss: 0.203\n",
      "[76, 240] loss: 0.199\n",
      "[76, 300] loss: 0.205\n",
      "[76, 360] loss: 0.200\n",
      "Epoch: 76 -> Loss: 0.227793902159\n",
      "Epoch: 76 -> Test Accuracy: 82.79\n",
      "[77, 60] loss: 0.195\n",
      "[77, 120] loss: 0.203\n",
      "[77, 180] loss: 0.200\n",
      "[77, 240] loss: 0.204\n",
      "[77, 300] loss: 0.204\n",
      "[77, 360] loss: 0.206\n",
      "Epoch: 77 -> Loss: 0.20302310586\n",
      "Epoch: 77 -> Test Accuracy: 82.8\n",
      "[78, 60] loss: 0.197\n",
      "[78, 120] loss: 0.204\n",
      "[78, 180] loss: 0.194\n",
      "[78, 240] loss: 0.202\n",
      "[78, 300] loss: 0.210\n",
      "[78, 360] loss: 0.194\n",
      "Epoch: 78 -> Loss: 0.127615883946\n",
      "Epoch: 78 -> Test Accuracy: 82.74\n",
      "[79, 60] loss: 0.194\n",
      "[79, 120] loss: 0.192\n",
      "[79, 180] loss: 0.205\n",
      "[79, 240] loss: 0.200\n",
      "[79, 300] loss: 0.187\n",
      "[79, 360] loss: 0.187\n",
      "Epoch: 79 -> Loss: 0.162635758519\n",
      "Epoch: 79 -> Test Accuracy: 82.77\n",
      "[80, 60] loss: 0.201\n",
      "[80, 120] loss: 0.196\n",
      "[80, 180] loss: 0.189\n",
      "[80, 240] loss: 0.200\n",
      "[80, 300] loss: 0.194\n",
      "[80, 360] loss: 0.212\n",
      "Epoch: 80 -> Loss: 0.333744823933\n",
      "Epoch: 80 -> Test Accuracy: 82.83\n",
      "[81, 60] loss: 0.191\n",
      "[81, 120] loss: 0.200\n",
      "[81, 180] loss: 0.203\n",
      "[81, 240] loss: 0.202\n",
      "[81, 300] loss: 0.195\n",
      "[81, 360] loss: 0.195\n",
      "Epoch: 81 -> Loss: 0.185736805201\n",
      "Epoch: 81 -> Test Accuracy: 82.88\n",
      "[82, 60] loss: 0.192\n",
      "[82, 120] loss: 0.186\n",
      "[82, 180] loss: 0.201\n",
      "[82, 240] loss: 0.202\n",
      "[82, 300] loss: 0.195\n",
      "[82, 360] loss: 0.192\n",
      "Epoch: 82 -> Loss: 0.131227105856\n",
      "Epoch: 82 -> Test Accuracy: 82.7\n",
      "[83, 60] loss: 0.191\n",
      "[83, 120] loss: 0.194\n",
      "[83, 180] loss: 0.199\n",
      "[83, 240] loss: 0.192\n",
      "[83, 300] loss: 0.206\n",
      "[83, 360] loss: 0.192\n",
      "Epoch: 83 -> Loss: 0.149215370417\n",
      "Epoch: 83 -> Test Accuracy: 82.74\n",
      "[84, 60] loss: 0.181\n",
      "[84, 120] loss: 0.195\n",
      "[84, 180] loss: 0.185\n",
      "[84, 240] loss: 0.180\n",
      "[84, 300] loss: 0.190\n",
      "[84, 360] loss: 0.212\n",
      "Epoch: 84 -> Loss: 0.246774345636\n",
      "Epoch: 84 -> Test Accuracy: 82.77\n",
      "[85, 60] loss: 0.197\n",
      "[85, 120] loss: 0.184\n",
      "[85, 180] loss: 0.194\n",
      "[85, 240] loss: 0.195\n",
      "[85, 300] loss: 0.189\n",
      "[85, 360] loss: 0.192\n",
      "Epoch: 85 -> Loss: 0.205316931009\n",
      "Epoch: 85 -> Test Accuracy: 82.76\n",
      "[86, 60] loss: 0.192\n",
      "[86, 120] loss: 0.190\n",
      "[86, 180] loss: 0.194\n",
      "[86, 240] loss: 0.189\n",
      "[86, 300] loss: 0.195\n",
      "[86, 360] loss: 0.189\n",
      "Epoch: 86 -> Loss: 0.135312587023\n",
      "Epoch: 86 -> Test Accuracy: 82.81\n",
      "[87, 60] loss: 0.183\n",
      "[87, 120] loss: 0.184\n",
      "[87, 180] loss: 0.190\n",
      "[87, 240] loss: 0.181\n",
      "[87, 300] loss: 0.199\n",
      "[87, 360] loss: 0.179\n",
      "Epoch: 87 -> Loss: 0.226091340184\n",
      "Epoch: 87 -> Test Accuracy: 82.9\n",
      "[88, 60] loss: 0.190\n",
      "[88, 120] loss: 0.189\n",
      "[88, 180] loss: 0.181\n",
      "[88, 240] loss: 0.190\n",
      "[88, 300] loss: 0.190\n",
      "[88, 360] loss: 0.186\n",
      "Epoch: 88 -> Loss: 0.263732016087\n",
      "Epoch: 88 -> Test Accuracy: 82.88\n",
      "[89, 60] loss: 0.187\n",
      "[89, 120] loss: 0.193\n",
      "[89, 180] loss: 0.184\n",
      "[89, 240] loss: 0.187\n",
      "[89, 300] loss: 0.183\n",
      "[89, 360] loss: 0.193\n",
      "Epoch: 89 -> Loss: 0.201532512903\n",
      "Epoch: 89 -> Test Accuracy: 82.9\n",
      "[90, 60] loss: 0.172\n",
      "[90, 120] loss: 0.189\n",
      "[90, 180] loss: 0.183\n",
      "[90, 240] loss: 0.187\n",
      "[90, 300] loss: 0.201\n",
      "[90, 360] loss: 0.196\n",
      "Epoch: 90 -> Loss: 0.140012711287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 -> Test Accuracy: 82.76\n",
      "[91, 60] loss: 0.188\n",
      "[91, 120] loss: 0.173\n",
      "[91, 180] loss: 0.187\n",
      "[91, 240] loss: 0.187\n",
      "[91, 300] loss: 0.198\n",
      "[91, 360] loss: 0.180\n",
      "Epoch: 91 -> Loss: 0.176591917872\n",
      "Epoch: 91 -> Test Accuracy: 82.83\n",
      "[92, 60] loss: 0.182\n",
      "[92, 120] loss: 0.185\n",
      "[92, 180] loss: 0.192\n",
      "[92, 240] loss: 0.191\n",
      "[92, 300] loss: 0.190\n",
      "[92, 360] loss: 0.185\n",
      "Epoch: 92 -> Loss: 0.375464141369\n",
      "Epoch: 92 -> Test Accuracy: 82.79\n",
      "[93, 60] loss: 0.196\n",
      "[93, 120] loss: 0.182\n",
      "[93, 180] loss: 0.192\n",
      "[93, 240] loss: 0.183\n",
      "[93, 300] loss: 0.193\n",
      "[93, 360] loss: 0.192\n",
      "Epoch: 93 -> Loss: 0.115392968059\n",
      "Epoch: 93 -> Test Accuracy: 82.7\n",
      "[94, 60] loss: 0.180\n",
      "[94, 120] loss: 0.184\n",
      "[94, 180] loss: 0.175\n",
      "[94, 240] loss: 0.187\n",
      "[94, 300] loss: 0.180\n",
      "[94, 360] loss: 0.191\n",
      "Epoch: 94 -> Loss: 0.123291060328\n",
      "Epoch: 94 -> Test Accuracy: 82.7\n",
      "[95, 60] loss: 0.183\n",
      "[95, 120] loss: 0.192\n",
      "[95, 180] loss: 0.181\n",
      "[95, 240] loss: 0.189\n",
      "[95, 300] loss: 0.189\n",
      "[95, 360] loss: 0.187\n",
      "Epoch: 95 -> Loss: 0.179468899965\n",
      "Epoch: 95 -> Test Accuracy: 82.82\n",
      "[96, 60] loss: 0.184\n",
      "[96, 120] loss: 0.183\n",
      "[96, 180] loss: 0.188\n",
      "[96, 240] loss: 0.183\n",
      "[96, 300] loss: 0.180\n",
      "[96, 360] loss: 0.182\n",
      "Epoch: 96 -> Loss: 0.364301979542\n",
      "Epoch: 96 -> Test Accuracy: 82.83\n",
      "[97, 60] loss: 0.179\n",
      "[97, 120] loss: 0.186\n",
      "[97, 180] loss: 0.180\n",
      "[97, 240] loss: 0.181\n",
      "[97, 300] loss: 0.188\n",
      "[97, 360] loss: 0.192\n",
      "Epoch: 97 -> Loss: 0.230097383261\n",
      "Epoch: 97 -> Test Accuracy: 82.77\n",
      "[98, 60] loss: 0.179\n",
      "[98, 120] loss: 0.176\n",
      "[98, 180] loss: 0.186\n",
      "[98, 240] loss: 0.187\n",
      "[98, 300] loss: 0.184\n",
      "[98, 360] loss: 0.189\n",
      "Epoch: 98 -> Loss: 0.19270862639\n",
      "Epoch: 98 -> Test Accuracy: 82.81\n",
      "[99, 60] loss: 0.180\n",
      "[99, 120] loss: 0.178\n",
      "[99, 180] loss: 0.184\n",
      "[99, 240] loss: 0.182\n",
      "[99, 300] loss: 0.179\n",
      "[99, 360] loss: 0.183\n",
      "Epoch: 99 -> Loss: 0.228618234396\n",
      "Epoch: 99 -> Test Accuracy: 82.71\n",
      "[100, 60] loss: 0.170\n",
      "[100, 120] loss: 0.187\n",
      "[100, 180] loss: 0.177\n",
      "[100, 240] loss: 0.182\n",
      "[100, 300] loss: 0.183\n",
      "[100, 360] loss: 0.185\n",
      "Epoch: 100 -> Loss: 0.109822750092\n",
      "Epoch: 100 -> Test Accuracy: 82.74\n",
      "Finished Training\n",
      "[1, 60] loss: 2.372\n",
      "[1, 120] loss: 1.505\n",
      "[1, 180] loss: 1.394\n",
      "[1, 240] loss: 1.304\n",
      "[1, 300] loss: 1.296\n",
      "[1, 360] loss: 1.241\n",
      "Epoch: 1 -> Loss: 1.34962368011\n",
      "Epoch: 1 -> Test Accuracy: 53.16\n",
      "[2, 60] loss: 1.182\n",
      "[2, 120] loss: 1.175\n",
      "[2, 180] loss: 1.146\n",
      "[2, 240] loss: 1.155\n",
      "[2, 300] loss: 1.137\n",
      "[2, 360] loss: 1.122\n",
      "Epoch: 2 -> Loss: 1.09942436218\n",
      "Epoch: 2 -> Test Accuracy: 56.58\n",
      "[3, 60] loss: 1.108\n",
      "[3, 120] loss: 1.111\n",
      "[3, 180] loss: 1.098\n",
      "[3, 240] loss: 1.108\n",
      "[3, 300] loss: 1.094\n",
      "[3, 360] loss: 1.093\n",
      "Epoch: 3 -> Loss: 1.03554797173\n",
      "Epoch: 3 -> Test Accuracy: 57.16\n",
      "[4, 60] loss: 1.073\n",
      "[4, 120] loss: 1.075\n",
      "[4, 180] loss: 1.068\n",
      "[4, 240] loss: 1.074\n",
      "[4, 300] loss: 1.056\n",
      "[4, 360] loss: 1.051\n",
      "Epoch: 4 -> Loss: 1.16620135307\n",
      "Epoch: 4 -> Test Accuracy: 58.23\n",
      "[5, 60] loss: 1.053\n",
      "[5, 120] loss: 1.054\n",
      "[5, 180] loss: 1.038\n",
      "[5, 240] loss: 1.040\n",
      "[5, 300] loss: 1.062\n",
      "[5, 360] loss: 1.054\n",
      "Epoch: 5 -> Loss: 0.914865791798\n",
      "Epoch: 5 -> Test Accuracy: 58.88\n",
      "[6, 60] loss: 1.019\n",
      "[6, 120] loss: 1.041\n",
      "[6, 180] loss: 1.031\n",
      "[6, 240] loss: 1.019\n",
      "[6, 300] loss: 1.027\n",
      "[6, 360] loss: 1.064\n",
      "Epoch: 6 -> Loss: 0.925602555275\n",
      "Epoch: 6 -> Test Accuracy: 59.73\n",
      "[7, 60] loss: 1.036\n",
      "[7, 120] loss: 1.015\n",
      "[7, 180] loss: 1.046\n",
      "[7, 240] loss: 1.011\n",
      "[7, 300] loss: 1.031\n",
      "[7, 360] loss: 1.018\n",
      "Epoch: 7 -> Loss: 0.994306087494\n",
      "Epoch: 7 -> Test Accuracy: 59.7\n",
      "[8, 60] loss: 1.009\n",
      "[8, 120] loss: 1.040\n",
      "[8, 180] loss: 1.012\n",
      "[8, 240] loss: 1.016\n",
      "[8, 300] loss: 1.011\n",
      "[8, 360] loss: 1.015\n",
      "Epoch: 8 -> Loss: 0.960642933846\n",
      "Epoch: 8 -> Test Accuracy: 59.4\n",
      "[9, 60] loss: 1.016\n",
      "[9, 120] loss: 1.010\n",
      "[9, 180] loss: 1.003\n",
      "[9, 240] loss: 1.036\n",
      "[9, 300] loss: 1.008\n",
      "[9, 360] loss: 1.029\n",
      "Epoch: 9 -> Loss: 0.909088253975\n",
      "Epoch: 9 -> Test Accuracy: 60.56\n",
      "[10, 60] loss: 1.013\n",
      "[10, 120] loss: 1.004\n",
      "[10, 180] loss: 1.011\n",
      "[10, 240] loss: 1.014\n",
      "[10, 300] loss: 1.027\n",
      "[10, 360] loss: 0.997\n",
      "Epoch: 10 -> Loss: 1.16477251053\n",
      "Epoch: 10 -> Test Accuracy: 60.6\n",
      "[11, 60] loss: 0.982\n",
      "[11, 120] loss: 1.016\n",
      "[11, 180] loss: 1.016\n",
      "[11, 240] loss: 0.976\n",
      "[11, 300] loss: 1.022\n",
      "[11, 360] loss: 0.997\n",
      "Epoch: 11 -> Loss: 0.79717206955\n",
      "Epoch: 11 -> Test Accuracy: 59.12\n",
      "[12, 60] loss: 1.003\n",
      "[12, 120] loss: 0.999\n",
      "[12, 180] loss: 1.001\n",
      "[12, 240] loss: 1.008\n",
      "[12, 300] loss: 1.009\n",
      "[12, 360] loss: 0.995\n",
      "Epoch: 12 -> Loss: 1.01951897144\n",
      "Epoch: 12 -> Test Accuracy: 60.44\n",
      "[13, 60] loss: 1.017\n",
      "[13, 120] loss: 1.003\n",
      "[13, 180] loss: 1.001\n",
      "[13, 240] loss: 0.985\n",
      "[13, 300] loss: 0.998\n",
      "[13, 360] loss: 0.992\n",
      "Epoch: 13 -> Loss: 0.827505767345\n",
      "Epoch: 13 -> Test Accuracy: 59.26\n",
      "[14, 60] loss: 0.989\n",
      "[14, 120] loss: 1.001\n",
      "[14, 180] loss: 0.997\n",
      "[14, 240] loss: 0.994\n",
      "[14, 300] loss: 0.990\n",
      "[14, 360] loss: 1.008\n",
      "Epoch: 14 -> Loss: 0.877017378807\n",
      "Epoch: 14 -> Test Accuracy: 59.9\n",
      "[15, 60] loss: 1.018\n",
      "[15, 120] loss: 0.993\n",
      "[15, 180] loss: 0.996\n",
      "[15, 240] loss: 1.012\n",
      "[15, 300] loss: 0.991\n",
      "[15, 360] loss: 0.980\n",
      "Epoch: 15 -> Loss: 0.819955170155\n",
      "Epoch: 15 -> Test Accuracy: 60.98\n",
      "[16, 60] loss: 0.988\n",
      "[16, 120] loss: 0.998\n",
      "[16, 180] loss: 0.999\n",
      "[16, 240] loss: 0.993\n",
      "[16, 300] loss: 0.977\n",
      "[16, 360] loss: 0.997\n",
      "Epoch: 16 -> Loss: 1.1143437624\n",
      "Epoch: 16 -> Test Accuracy: 60.29\n",
      "[17, 60] loss: 0.985\n",
      "[17, 120] loss: 1.006\n",
      "[17, 180] loss: 0.988\n",
      "[17, 240] loss: 0.984\n",
      "[17, 300] loss: 1.008\n",
      "[17, 360] loss: 1.000\n",
      "Epoch: 17 -> Loss: 1.12090849876\n",
      "Epoch: 17 -> Test Accuracy: 61.2\n",
      "[18, 60] loss: 0.992\n",
      "[18, 120] loss: 1.000\n",
      "[18, 180] loss: 0.992\n",
      "[18, 240] loss: 0.993\n",
      "[18, 300] loss: 0.989\n",
      "[18, 360] loss: 1.001\n",
      "Epoch: 18 -> Loss: 0.938119411469\n",
      "Epoch: 18 -> Test Accuracy: 59.33\n",
      "[19, 60] loss: 0.986\n",
      "[19, 120] loss: 0.992\n",
      "[19, 180] loss: 0.981\n",
      "[19, 240] loss: 0.988\n",
      "[19, 300] loss: 1.012\n",
      "[19, 360] loss: 0.986\n",
      "Epoch: 19 -> Loss: 0.811034321785\n",
      "Epoch: 19 -> Test Accuracy: 60.18\n",
      "[20, 60] loss: 0.988\n",
      "[20, 120] loss: 0.995\n",
      "[20, 180] loss: 0.974\n",
      "[20, 240] loss: 0.988\n",
      "[20, 300] loss: 0.990\n",
      "[20, 360] loss: 0.987\n",
      "Epoch: 20 -> Loss: 0.946434855461\n",
      "Epoch: 20 -> Test Accuracy: 60.7\n",
      "[21, 60] loss: 0.939\n",
      "[21, 120] loss: 0.897\n",
      "[21, 180] loss: 0.915\n",
      "[21, 240] loss: 0.883\n",
      "[21, 300] loss: 0.901\n",
      "[21, 360] loss: 0.885\n",
      "Epoch: 21 -> Loss: 1.17736923695\n",
      "Epoch: 21 -> Test Accuracy: 63.35\n",
      "[22, 60] loss: 0.863\n",
      "[22, 120] loss: 0.872\n",
      "[22, 180] loss: 0.874\n",
      "[22, 240] loss: 0.849\n",
      "[22, 300] loss: 0.835\n",
      "[22, 360] loss: 0.861\n",
      "Epoch: 22 -> Loss: 0.820027709007\n",
      "Epoch: 22 -> Test Accuracy: 64.24\n",
      "[23, 60] loss: 0.854\n",
      "[23, 120] loss: 0.840\n",
      "[23, 180] loss: 0.869\n",
      "[23, 240] loss: 0.850\n",
      "[23, 300] loss: 0.857\n",
      "[23, 360] loss: 0.866\n",
      "Epoch: 23 -> Loss: 0.859305024147\n",
      "Epoch: 23 -> Test Accuracy: 64.87\n",
      "[24, 60] loss: 0.832\n",
      "[24, 120] loss: 0.826\n",
      "[24, 180] loss: 0.857\n",
      "[24, 240] loss: 0.833\n",
      "[24, 300] loss: 0.857\n",
      "[24, 360] loss: 0.849\n",
      "Epoch: 24 -> Loss: 0.771634340286\n",
      "Epoch: 24 -> Test Accuracy: 64.67\n",
      "[25, 60] loss: 0.839\n",
      "[25, 120] loss: 0.861\n",
      "[25, 180] loss: 0.839\n",
      "[25, 240] loss: 0.834\n",
      "[25, 300] loss: 0.836\n",
      "[25, 360] loss: 0.818\n",
      "Epoch: 25 -> Loss: 0.923593521118\n",
      "Epoch: 25 -> Test Accuracy: 64.72\n",
      "[26, 60] loss: 0.829\n",
      "[26, 120] loss: 0.844\n",
      "[26, 180] loss: 0.836\n",
      "[26, 240] loss: 0.823\n",
      "[26, 300] loss: 0.839\n",
      "[26, 360] loss: 0.825\n",
      "Epoch: 26 -> Loss: 0.885456204414\n",
      "Epoch: 26 -> Test Accuracy: 64.91\n",
      "[27, 60] loss: 0.812\n",
      "[27, 120] loss: 0.840\n",
      "[27, 180] loss: 0.852\n",
      "[27, 240] loss: 0.848\n",
      "[27, 300] loss: 0.841\n",
      "[27, 360] loss: 0.828\n",
      "Epoch: 27 -> Loss: 0.769920945168\n",
      "Epoch: 27 -> Test Accuracy: 64.75\n",
      "[28, 60] loss: 0.804\n",
      "[28, 120] loss: 0.842\n",
      "[28, 180] loss: 0.834\n",
      "[28, 240] loss: 0.803\n",
      "[28, 300] loss: 0.823\n",
      "[28, 360] loss: 0.836\n",
      "Epoch: 28 -> Loss: 0.705704391003\n",
      "Epoch: 28 -> Test Accuracy: 65.21\n",
      "[29, 60] loss: 0.823\n",
      "[29, 120] loss: 0.840\n",
      "[29, 180] loss: 0.818\n",
      "[29, 240] loss: 0.850\n",
      "[29, 300] loss: 0.811\n",
      "[29, 360] loss: 0.835\n",
      "Epoch: 29 -> Loss: 0.749869048595\n",
      "Epoch: 29 -> Test Accuracy: 64.92\n",
      "[30, 60] loss: 0.810\n",
      "[30, 120] loss: 0.829\n",
      "[30, 180] loss: 0.837\n",
      "[30, 240] loss: 0.834\n",
      "[30, 300] loss: 0.823\n",
      "[30, 360] loss: 0.857\n",
      "Epoch: 30 -> Loss: 0.728932917118\n",
      "Epoch: 30 -> Test Accuracy: 64.99\n",
      "[31, 60] loss: 0.802\n",
      "[31, 120] loss: 0.845\n",
      "[31, 180] loss: 0.818\n",
      "[31, 240] loss: 0.824\n",
      "[31, 300] loss: 0.835\n",
      "[31, 360] loss: 0.834\n",
      "Epoch: 31 -> Loss: 0.818415284157\n",
      "Epoch: 31 -> Test Accuracy: 65.25\n",
      "[32, 60] loss: 0.819\n",
      "[32, 120] loss: 0.807\n",
      "[32, 180] loss: 0.822\n",
      "[32, 240] loss: 0.809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 300] loss: 0.839\n",
      "[32, 360] loss: 0.842\n",
      "Epoch: 32 -> Loss: 0.931860089302\n",
      "Epoch: 32 -> Test Accuracy: 64.87\n",
      "[33, 60] loss: 0.789\n",
      "[33, 120] loss: 0.825\n",
      "[33, 180] loss: 0.830\n",
      "[33, 240] loss: 0.820\n",
      "[33, 300] loss: 0.835\n",
      "[33, 360] loss: 0.825\n",
      "Epoch: 33 -> Loss: 0.64410251379\n",
      "Epoch: 33 -> Test Accuracy: 65.27\n",
      "[34, 60] loss: 0.815\n",
      "[34, 120] loss: 0.826\n",
      "[34, 180] loss: 0.813\n",
      "[34, 240] loss: 0.825\n",
      "[34, 300] loss: 0.838\n",
      "[34, 360] loss: 0.825\n",
      "Epoch: 34 -> Loss: 0.574349761009\n",
      "Epoch: 34 -> Test Accuracy: 65.47\n",
      "[35, 60] loss: 0.812\n",
      "[35, 120] loss: 0.836\n",
      "[35, 180] loss: 0.814\n",
      "[35, 240] loss: 0.817\n",
      "[35, 300] loss: 0.813\n",
      "[35, 360] loss: 0.822\n",
      "Epoch: 35 -> Loss: 0.919684231281\n",
      "Epoch: 35 -> Test Accuracy: 64.38\n",
      "[36, 60] loss: 0.821\n",
      "[36, 120] loss: 0.837\n",
      "[36, 180] loss: 0.828\n",
      "[36, 240] loss: 0.812\n",
      "[36, 300] loss: 0.834\n",
      "[36, 360] loss: 0.827\n",
      "Epoch: 36 -> Loss: 0.81882172823\n",
      "Epoch: 36 -> Test Accuracy: 65.26\n",
      "[37, 60] loss: 0.796\n",
      "[37, 120] loss: 0.831\n",
      "[37, 180] loss: 0.824\n",
      "[37, 240] loss: 0.819\n",
      "[37, 300] loss: 0.821\n",
      "[37, 360] loss: 0.827\n",
      "Epoch: 37 -> Loss: 0.776624381542\n",
      "Epoch: 37 -> Test Accuracy: 65.2\n",
      "[38, 60] loss: 0.823\n",
      "[38, 120] loss: 0.810\n",
      "[38, 180] loss: 0.828\n",
      "[38, 240] loss: 0.833\n",
      "[38, 300] loss: 0.831\n",
      "[38, 360] loss: 0.812\n",
      "Epoch: 38 -> Loss: 0.756413280964\n",
      "Epoch: 38 -> Test Accuracy: 65.17\n",
      "[39, 60] loss: 0.829\n",
      "[39, 120] loss: 0.809\n",
      "[39, 180] loss: 0.814\n",
      "[39, 240] loss: 0.828\n",
      "[39, 300] loss: 0.829\n",
      "[39, 360] loss: 0.822\n",
      "Epoch: 39 -> Loss: 0.843352496624\n",
      "Epoch: 39 -> Test Accuracy: 65.29\n",
      "[40, 60] loss: 0.816\n",
      "[40, 120] loss: 0.798\n",
      "[40, 180] loss: 0.811\n",
      "[40, 240] loss: 0.842\n",
      "[40, 300] loss: 0.804\n",
      "[40, 360] loss: 0.851\n",
      "Epoch: 40 -> Loss: 0.748660326004\n",
      "Epoch: 40 -> Test Accuracy: 65.55\n",
      "[41, 60] loss: 0.793\n",
      "[41, 120] loss: 0.793\n",
      "[41, 180] loss: 0.762\n",
      "[41, 240] loss: 0.758\n",
      "[41, 300] loss: 0.786\n",
      "[41, 360] loss: 0.742\n",
      "Epoch: 41 -> Loss: 0.949951529503\n",
      "Epoch: 41 -> Test Accuracy: 66.61\n",
      "[42, 60] loss: 0.761\n",
      "[42, 120] loss: 0.750\n",
      "[42, 180] loss: 0.750\n",
      "[42, 240] loss: 0.768\n",
      "[42, 300] loss: 0.737\n",
      "[42, 360] loss: 0.748\n",
      "Epoch: 42 -> Loss: 0.818822979927\n",
      "Epoch: 42 -> Test Accuracy: 66.9\n",
      "[43, 60] loss: 0.741\n",
      "[43, 120] loss: 0.754\n",
      "[43, 180] loss: 0.718\n",
      "[43, 240] loss: 0.754\n",
      "[43, 300] loss: 0.733\n",
      "[43, 360] loss: 0.738\n",
      "Epoch: 43 -> Loss: 0.884896099567\n",
      "Epoch: 43 -> Test Accuracy: 67.53\n",
      "[44, 60] loss: 0.736\n",
      "[44, 120] loss: 0.733\n",
      "[44, 180] loss: 0.736\n",
      "[44, 240] loss: 0.751\n",
      "[44, 300] loss: 0.729\n",
      "[44, 360] loss: 0.720\n",
      "Epoch: 44 -> Loss: 0.686683535576\n",
      "Epoch: 44 -> Test Accuracy: 67.24\n",
      "[45, 60] loss: 0.731\n",
      "[45, 120] loss: 0.755\n",
      "[45, 180] loss: 0.746\n",
      "[45, 240] loss: 0.737\n",
      "[45, 300] loss: 0.729\n",
      "[45, 360] loss: 0.742\n",
      "Epoch: 45 -> Loss: 0.610719442368\n",
      "Epoch: 45 -> Test Accuracy: 67.63\n",
      "[46, 60] loss: 0.735\n",
      "[46, 120] loss: 0.728\n",
      "[46, 180] loss: 0.724\n",
      "[46, 240] loss: 0.731\n",
      "[46, 300] loss: 0.737\n",
      "[46, 360] loss: 0.709\n",
      "Epoch: 46 -> Loss: 0.667288541794\n",
      "Epoch: 46 -> Test Accuracy: 67.64\n",
      "[47, 60] loss: 0.722\n",
      "[47, 120] loss: 0.733\n",
      "[47, 180] loss: 0.710\n",
      "[47, 240] loss: 0.717\n",
      "[47, 300] loss: 0.724\n",
      "[47, 360] loss: 0.715\n",
      "Epoch: 47 -> Loss: 0.662789940834\n",
      "Epoch: 47 -> Test Accuracy: 67.75\n",
      "[48, 60] loss: 0.732\n",
      "[48, 120] loss: 0.707\n",
      "[48, 180] loss: 0.720\n",
      "[48, 240] loss: 0.719\n",
      "[48, 300] loss: 0.720\n",
      "[48, 360] loss: 0.703\n",
      "Epoch: 48 -> Loss: 0.763386487961\n",
      "Epoch: 48 -> Test Accuracy: 67.62\n",
      "[49, 60] loss: 0.715\n",
      "[49, 120] loss: 0.712\n",
      "[49, 180] loss: 0.699\n",
      "[49, 240] loss: 0.709\n",
      "[49, 300] loss: 0.706\n",
      "[49, 360] loss: 0.723\n",
      "Epoch: 49 -> Loss: 0.873286128044\n",
      "Epoch: 49 -> Test Accuracy: 67.88\n",
      "[50, 60] loss: 0.700\n",
      "[50, 120] loss: 0.720\n",
      "[50, 180] loss: 0.727\n",
      "[50, 240] loss: 0.717\n",
      "[50, 300] loss: 0.707\n",
      "[50, 360] loss: 0.721\n",
      "Epoch: 50 -> Loss: 0.814446568489\n",
      "Epoch: 50 -> Test Accuracy: 67.68\n",
      "[51, 60] loss: 0.718\n",
      "[51, 120] loss: 0.707\n",
      "[51, 180] loss: 0.709\n",
      "[51, 240] loss: 0.712\n",
      "[51, 300] loss: 0.722\n",
      "[51, 360] loss: 0.691\n",
      "Epoch: 51 -> Loss: 0.689360499382\n",
      "Epoch: 51 -> Test Accuracy: 68.03\n",
      "[52, 60] loss: 0.701\n",
      "[52, 120] loss: 0.714\n",
      "[52, 180] loss: 0.707\n",
      "[52, 240] loss: 0.702\n",
      "[52, 300] loss: 0.717\n",
      "[52, 360] loss: 0.714\n",
      "Epoch: 52 -> Loss: 0.732563614845\n",
      "Epoch: 52 -> Test Accuracy: 67.86\n",
      "[53, 60] loss: 0.704\n",
      "[53, 120] loss: 0.709\n",
      "[53, 180] loss: 0.698\n",
      "[53, 240] loss: 0.708\n",
      "[53, 300] loss: 0.706\n",
      "[53, 360] loss: 0.710\n",
      "Epoch: 53 -> Loss: 0.598559260368\n",
      "Epoch: 53 -> Test Accuracy: 67.83\n",
      "[54, 60] loss: 0.711\n",
      "[54, 120] loss: 0.712\n",
      "[54, 180] loss: 0.705\n",
      "[54, 240] loss: 0.709\n",
      "[54, 300] loss: 0.707\n",
      "[54, 360] loss: 0.705\n",
      "Epoch: 54 -> Loss: 0.762863993645\n",
      "Epoch: 54 -> Test Accuracy: 67.66\n",
      "[55, 60] loss: 0.691\n",
      "[55, 120] loss: 0.708\n",
      "[55, 180] loss: 0.709\n",
      "[55, 240] loss: 0.697\n",
      "[55, 300] loss: 0.710\n",
      "[55, 360] loss: 0.710\n",
      "Epoch: 55 -> Loss: 0.609529793262\n",
      "Epoch: 55 -> Test Accuracy: 67.78\n",
      "[56, 60] loss: 0.703\n",
      "[56, 120] loss: 0.706\n",
      "[56, 180] loss: 0.707\n",
      "[56, 240] loss: 0.717\n",
      "[56, 300] loss: 0.697\n",
      "[56, 360] loss: 0.717\n",
      "Epoch: 56 -> Loss: 0.768208682537\n",
      "Epoch: 56 -> Test Accuracy: 67.93\n",
      "[57, 60] loss: 0.708\n",
      "[57, 120] loss: 0.702\n",
      "[57, 180] loss: 0.698\n",
      "[57, 240] loss: 0.689\n",
      "[57, 300] loss: 0.717\n",
      "[57, 360] loss: 0.713\n",
      "Epoch: 57 -> Loss: 0.664506435394\n",
      "Epoch: 57 -> Test Accuracy: 68.06\n",
      "[58, 60] loss: 0.694\n",
      "[58, 120] loss: 0.700\n",
      "[58, 180] loss: 0.709\n",
      "[58, 240] loss: 0.712\n",
      "[58, 300] loss: 0.717\n",
      "[58, 360] loss: 0.704\n",
      "Epoch: 58 -> Loss: 0.828206241131\n",
      "Epoch: 58 -> Test Accuracy: 68.17\n",
      "[59, 60] loss: 0.701\n",
      "[59, 120] loss: 0.694\n",
      "[59, 180] loss: 0.701\n",
      "[59, 240] loss: 0.691\n",
      "[59, 300] loss: 0.702\n",
      "[59, 360] loss: 0.710\n",
      "Epoch: 59 -> Loss: 0.799270927906\n",
      "Epoch: 59 -> Test Accuracy: 68.09\n",
      "[60, 60] loss: 0.701\n",
      "[60, 120] loss: 0.698\n",
      "[60, 180] loss: 0.704\n",
      "[60, 240] loss: 0.693\n",
      "[60, 300] loss: 0.709\n",
      "[60, 360] loss: 0.690\n",
      "Epoch: 60 -> Loss: 0.598959028721\n",
      "Epoch: 60 -> Test Accuracy: 68.11\n",
      "[61, 60] loss: 0.699\n",
      "[61, 120] loss: 0.698\n",
      "[61, 180] loss: 0.724\n",
      "[61, 240] loss: 0.692\n",
      "[61, 300] loss: 0.704\n",
      "[61, 360] loss: 0.686\n",
      "Epoch: 61 -> Loss: 1.02019560337\n",
      "Epoch: 61 -> Test Accuracy: 68.09\n",
      "[62, 60] loss: 0.716\n",
      "[62, 120] loss: 0.691\n",
      "[62, 180] loss: 0.696\n",
      "[62, 240] loss: 0.694\n",
      "[62, 300] loss: 0.699\n",
      "[62, 360] loss: 0.702\n",
      "Epoch: 62 -> Loss: 0.659137964249\n",
      "Epoch: 62 -> Test Accuracy: 68.07\n",
      "[63, 60] loss: 0.682\n",
      "[63, 120] loss: 0.707\n",
      "[63, 180] loss: 0.706\n",
      "[63, 240] loss: 0.696\n",
      "[63, 300] loss: 0.705\n",
      "[63, 360] loss: 0.693\n",
      "Epoch: 63 -> Loss: 0.786054730415\n",
      "Epoch: 63 -> Test Accuracy: 68.31\n",
      "[64, 60] loss: 0.681\n",
      "[64, 120] loss: 0.719\n",
      "[64, 180] loss: 0.700\n",
      "[64, 240] loss: 0.697\n",
      "[64, 300] loss: 0.686\n",
      "[64, 360] loss: 0.703\n",
      "Epoch: 64 -> Loss: 0.618214726448\n",
      "Epoch: 64 -> Test Accuracy: 68.22\n",
      "[65, 60] loss: 0.675\n",
      "[65, 120] loss: 0.709\n",
      "[65, 180] loss: 0.693\n",
      "[65, 240] loss: 0.693\n",
      "[65, 300] loss: 0.708\n",
      "[65, 360] loss: 0.706\n",
      "Epoch: 65 -> Loss: 0.739111185074\n",
      "Epoch: 65 -> Test Accuracy: 68.43\n",
      "[66, 60] loss: 0.709\n",
      "[66, 120] loss: 0.685\n",
      "[66, 180] loss: 0.691\n",
      "[66, 240] loss: 0.689\n",
      "[66, 300] loss: 0.700\n",
      "[66, 360] loss: 0.700\n",
      "Epoch: 66 -> Loss: 0.80233669281\n",
      "Epoch: 66 -> Test Accuracy: 68.22\n",
      "[67, 60] loss: 0.695\n",
      "[67, 120] loss: 0.691\n",
      "[67, 180] loss: 0.697\n",
      "[67, 240] loss: 0.685\n",
      "[67, 300] loss: 0.689\n",
      "[67, 360] loss: 0.705\n",
      "Epoch: 67 -> Loss: 0.806155979633\n",
      "Epoch: 67 -> Test Accuracy: 68.46\n",
      "[68, 60] loss: 0.708\n",
      "[68, 120] loss: 0.664\n",
      "[68, 180] loss: 0.699\n",
      "[68, 240] loss: 0.676\n",
      "[68, 300] loss: 0.696\n",
      "[68, 360] loss: 0.719\n",
      "Epoch: 68 -> Loss: 0.70879894495\n",
      "Epoch: 68 -> Test Accuracy: 68.45\n",
      "[69, 60] loss: 0.685\n",
      "[69, 120] loss: 0.684\n",
      "[69, 180] loss: 0.687\n",
      "[69, 240] loss: 0.707\n",
      "[69, 300] loss: 0.690\n",
      "[69, 360] loss: 0.695\n",
      "Epoch: 69 -> Loss: 0.760807275772\n",
      "Epoch: 69 -> Test Accuracy: 68.41\n",
      "[70, 60] loss: 0.690\n",
      "[70, 120] loss: 0.672\n",
      "[70, 180] loss: 0.691\n",
      "[70, 240] loss: 0.696\n",
      "[70, 300] loss: 0.711\n",
      "[70, 360] loss: 0.690\n",
      "Epoch: 70 -> Loss: 0.605905115604\n",
      "Epoch: 70 -> Test Accuracy: 68.39\n",
      "[71, 60] loss: 0.674\n",
      "[71, 120] loss: 0.701\n",
      "[71, 180] loss: 0.687\n",
      "[71, 240] loss: 0.685\n",
      "[71, 300] loss: 0.687\n",
      "[71, 360] loss: 0.703\n",
      "Epoch: 71 -> Loss: 0.649821639061\n",
      "Epoch: 71 -> Test Accuracy: 68.36\n",
      "[72, 60] loss: 0.674\n",
      "[72, 120] loss: 0.701\n",
      "[72, 180] loss: 0.688\n",
      "[72, 240] loss: 0.689\n",
      "[72, 300] loss: 0.697\n",
      "[72, 360] loss: 0.699\n",
      "Epoch: 72 -> Loss: 0.876597881317\n",
      "Epoch: 72 -> Test Accuracy: 68.36\n",
      "[73, 60] loss: 0.687\n",
      "[73, 120] loss: 0.711\n",
      "[73, 180] loss: 0.697\n",
      "[73, 240] loss: 0.682\n",
      "[73, 300] loss: 0.685\n",
      "[73, 360] loss: 0.684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 -> Loss: 0.646624267101\n",
      "Epoch: 73 -> Test Accuracy: 68.53\n",
      "[74, 60] loss: 0.679\n",
      "[74, 120] loss: 0.700\n",
      "[74, 180] loss: 0.689\n",
      "[74, 240] loss: 0.676\n",
      "[74, 300] loss: 0.686\n",
      "[74, 360] loss: 0.701\n",
      "Epoch: 74 -> Loss: 1.03265500069\n",
      "Epoch: 74 -> Test Accuracy: 68.47\n",
      "[75, 60] loss: 0.691\n",
      "[75, 120] loss: 0.678\n",
      "[75, 180] loss: 0.679\n",
      "[75, 240] loss: 0.689\n",
      "[75, 300] loss: 0.695\n",
      "[75, 360] loss: 0.689\n",
      "Epoch: 75 -> Loss: 0.795816957951\n",
      "Epoch: 75 -> Test Accuracy: 68.5\n",
      "[76, 60] loss: 0.676\n",
      "[76, 120] loss: 0.682\n",
      "[76, 180] loss: 0.700\n",
      "[76, 240] loss: 0.684\n",
      "[76, 300] loss: 0.690\n",
      "[76, 360] loss: 0.700\n",
      "Epoch: 76 -> Loss: 0.663588225842\n",
      "Epoch: 76 -> Test Accuracy: 68.65\n",
      "[77, 60] loss: 0.685\n",
      "[77, 120] loss: 0.680\n",
      "[77, 180] loss: 0.692\n",
      "[77, 240] loss: 0.671\n",
      "[77, 300] loss: 0.688\n",
      "[77, 360] loss: 0.706\n",
      "Epoch: 77 -> Loss: 0.786404252052\n",
      "Epoch: 77 -> Test Accuracy: 68.52\n",
      "[78, 60] loss: 0.687\n",
      "[78, 120] loss: 0.661\n",
      "[78, 180] loss: 0.690\n",
      "[78, 240] loss: 0.672\n",
      "[78, 300] loss: 0.694\n",
      "[78, 360] loss: 0.702\n",
      "Epoch: 78 -> Loss: 0.622362375259\n",
      "Epoch: 78 -> Test Accuracy: 68.69\n",
      "[79, 60] loss: 0.700\n",
      "[79, 120] loss: 0.672\n",
      "[79, 180] loss: 0.690\n",
      "[79, 240] loss: 0.692\n",
      "[79, 300] loss: 0.691\n",
      "[79, 360] loss: 0.690\n",
      "Epoch: 79 -> Loss: 0.686405360699\n",
      "Epoch: 79 -> Test Accuracy: 68.52\n",
      "[80, 60] loss: 0.673\n",
      "[80, 120] loss: 0.699\n",
      "[80, 180] loss: 0.695\n",
      "[80, 240] loss: 0.693\n",
      "[80, 300] loss: 0.685\n",
      "[80, 360] loss: 0.671\n",
      "Epoch: 80 -> Loss: 0.650124192238\n",
      "Epoch: 80 -> Test Accuracy: 68.53\n",
      "[81, 60] loss: 0.678\n",
      "[81, 120] loss: 0.676\n",
      "[81, 180] loss: 0.670\n",
      "[81, 240] loss: 0.663\n",
      "[81, 300] loss: 0.678\n",
      "[81, 360] loss: 0.686\n",
      "Epoch: 81 -> Loss: 0.770892441273\n",
      "Epoch: 81 -> Test Accuracy: 68.4\n",
      "[82, 60] loss: 0.689\n",
      "[82, 120] loss: 0.680\n",
      "[82, 180] loss: 0.673\n",
      "[82, 240] loss: 0.688\n",
      "[82, 300] loss: 0.676\n",
      "[82, 360] loss: 0.677\n",
      "Epoch: 82 -> Loss: 0.564215064049\n",
      "Epoch: 82 -> Test Accuracy: 68.69\n",
      "[83, 60] loss: 0.674\n",
      "[83, 120] loss: 0.697\n",
      "[83, 180] loss: 0.688\n",
      "[83, 240] loss: 0.687\n",
      "[83, 300] loss: 0.684\n",
      "[83, 360] loss: 0.668\n",
      "Epoch: 83 -> Loss: 0.803149819374\n",
      "Epoch: 83 -> Test Accuracy: 68.62\n",
      "[84, 60] loss: 0.674\n",
      "[84, 120] loss: 0.691\n",
      "[84, 180] loss: 0.692\n",
      "[84, 240] loss: 0.693\n",
      "[84, 300] loss: 0.682\n",
      "[84, 360] loss: 0.664\n",
      "Epoch: 84 -> Loss: 0.732546925545\n",
      "Epoch: 84 -> Test Accuracy: 68.59\n",
      "[85, 60] loss: 0.669\n",
      "[85, 120] loss: 0.670\n",
      "[85, 180] loss: 0.683\n",
      "[85, 240] loss: 0.677\n",
      "[85, 300] loss: 0.685\n",
      "[85, 360] loss: 0.706\n",
      "Epoch: 85 -> Loss: 0.777378380299\n",
      "Epoch: 85 -> Test Accuracy: 68.63\n",
      "[86, 60] loss: 0.656\n",
      "[86, 120] loss: 0.689\n",
      "[86, 180] loss: 0.684\n",
      "[86, 240] loss: 0.694\n",
      "[86, 300] loss: 0.674\n",
      "[86, 360] loss: 0.682\n",
      "Epoch: 86 -> Loss: 0.569570720196\n",
      "Epoch: 86 -> Test Accuracy: 68.79\n",
      "[87, 60] loss: 0.680\n",
      "[87, 120] loss: 0.679\n",
      "[87, 180] loss: 0.684\n",
      "[87, 240] loss: 0.694\n",
      "[87, 300] loss: 0.682\n",
      "[87, 360] loss: 0.692\n",
      "Epoch: 87 -> Loss: 0.963040351868\n",
      "Epoch: 87 -> Test Accuracy: 68.61\n",
      "[88, 60] loss: 0.676\n",
      "[88, 120] loss: 0.667\n",
      "[88, 180] loss: 0.677\n",
      "[88, 240] loss: 0.678\n",
      "[88, 300] loss: 0.679\n",
      "[88, 360] loss: 0.675\n",
      "Epoch: 88 -> Loss: 0.560909330845\n",
      "Epoch: 88 -> Test Accuracy: 68.59\n",
      "[89, 60] loss: 0.668\n",
      "[89, 120] loss: 0.677\n",
      "[89, 180] loss: 0.677\n",
      "[89, 240] loss: 0.672\n",
      "[89, 300] loss: 0.686\n",
      "[89, 360] loss: 0.678\n",
      "Epoch: 89 -> Loss: 0.748982965946\n",
      "Epoch: 89 -> Test Accuracy: 68.83\n",
      "[90, 60] loss: 0.679\n",
      "[90, 120] loss: 0.675\n",
      "[90, 180] loss: 0.692\n",
      "[90, 240] loss: 0.677\n",
      "[90, 300] loss: 0.665\n",
      "[90, 360] loss: 0.672\n",
      "Epoch: 90 -> Loss: 0.795606613159\n",
      "Epoch: 90 -> Test Accuracy: 68.66\n",
      "[91, 60] loss: 0.682\n",
      "[91, 120] loss: 0.673\n",
      "[91, 180] loss: 0.681\n",
      "[91, 240] loss: 0.679\n",
      "[91, 300] loss: 0.679\n",
      "[91, 360] loss: 0.670\n",
      "Epoch: 91 -> Loss: 0.788378477097\n",
      "Epoch: 91 -> Test Accuracy: 68.95\n",
      "[92, 60] loss: 0.672\n",
      "[92, 120] loss: 0.673\n",
      "[92, 180] loss: 0.679\n",
      "[92, 240] loss: 0.661\n",
      "[92, 300] loss: 0.680\n",
      "[92, 360] loss: 0.682\n",
      "Epoch: 92 -> Loss: 0.700001597404\n",
      "Epoch: 92 -> Test Accuracy: 68.77\n",
      "[93, 60] loss: 0.664\n",
      "[93, 120] loss: 0.663\n",
      "[93, 180] loss: 0.689\n",
      "[93, 240] loss: 0.685\n",
      "[93, 300] loss: 0.699\n",
      "[93, 360] loss: 0.661\n",
      "Epoch: 93 -> Loss: 0.61819845438\n",
      "Epoch: 93 -> Test Accuracy: 68.69\n",
      "[94, 60] loss: 0.693\n",
      "[94, 120] loss: 0.661\n",
      "[94, 180] loss: 0.671\n",
      "[94, 240] loss: 0.664\n",
      "[94, 300] loss: 0.673\n",
      "[94, 360] loss: 0.691\n",
      "Epoch: 94 -> Loss: 0.63590246439\n",
      "Epoch: 94 -> Test Accuracy: 68.73\n",
      "[95, 60] loss: 0.687\n",
      "[95, 120] loss: 0.678\n",
      "[95, 180] loss: 0.662\n",
      "[95, 240] loss: 0.676\n",
      "[95, 300] loss: 0.679\n",
      "[95, 360] loss: 0.678\n",
      "Epoch: 95 -> Loss: 0.74157166481\n",
      "Epoch: 95 -> Test Accuracy: 68.76\n",
      "[96, 60] loss: 0.699\n",
      "[96, 120] loss: 0.677\n",
      "[96, 180] loss: 0.668\n",
      "[96, 240] loss: 0.661\n",
      "[96, 300] loss: 0.658\n",
      "[96, 360] loss: 0.674\n",
      "Epoch: 96 -> Loss: 0.784649431705\n",
      "Epoch: 96 -> Test Accuracy: 68.58\n",
      "[97, 60] loss: 0.651\n",
      "[97, 120] loss: 0.678\n",
      "[97, 180] loss: 0.666\n",
      "[97, 240] loss: 0.679\n",
      "[97, 300] loss: 0.688\n",
      "[97, 360] loss: 0.671\n",
      "Epoch: 97 -> Loss: 0.542047142982\n",
      "Epoch: 97 -> Test Accuracy: 68.76\n",
      "[98, 60] loss: 0.659\n",
      "[98, 120] loss: 0.672\n",
      "[98, 180] loss: 0.666\n",
      "[98, 240] loss: 0.672\n",
      "[98, 300] loss: 0.689\n",
      "[98, 360] loss: 0.675\n",
      "Epoch: 98 -> Loss: 0.835464775562\n",
      "Epoch: 98 -> Test Accuracy: 68.81\n",
      "[99, 60] loss: 0.677\n",
      "[99, 120] loss: 0.679\n",
      "[99, 180] loss: 0.695\n",
      "[99, 240] loss: 0.662\n",
      "[99, 300] loss: 0.666\n",
      "[99, 360] loss: 0.662\n",
      "Epoch: 99 -> Loss: 0.636039793491\n",
      "Epoch: 99 -> Test Accuracy: 68.64\n",
      "[100, 60] loss: 0.654\n",
      "[100, 120] loss: 0.680\n",
      "[100, 180] loss: 0.671\n",
      "[100, 240] loss: 0.653\n",
      "[100, 300] loss: 0.681\n",
      "[100, 360] loss: 0.667\n",
      "Epoch: 100 -> Loss: 0.673718214035\n",
      "Epoch: 100 -> Test Accuracy: 68.64\n",
      "Finished Training\n",
      "[1, 60] loss: 2.800\n",
      "[1, 120] loss: 2.140\n",
      "[1, 180] loss: 2.089\n",
      "[1, 240] loss: 2.069\n",
      "[1, 300] loss: 2.043\n",
      "[1, 360] loss: 2.035\n",
      "Epoch: 1 -> Loss: 1.92817020416\n",
      "Epoch: 1 -> Test Accuracy: 24.71\n",
      "[2, 60] loss: 2.008\n",
      "[2, 120] loss: 1.989\n",
      "[2, 180] loss: 1.992\n",
      "[2, 240] loss: 1.977\n",
      "[2, 300] loss: 1.973\n",
      "[2, 360] loss: 1.964\n",
      "Epoch: 2 -> Loss: 2.10142564774\n",
      "Epoch: 2 -> Test Accuracy: 27.47\n",
      "[3, 60] loss: 1.955\n",
      "[3, 120] loss: 1.947\n",
      "[3, 180] loss: 1.950\n",
      "[3, 240] loss: 1.917\n",
      "[3, 300] loss: 1.924\n",
      "[3, 360] loss: 1.940\n",
      "Epoch: 3 -> Loss: 1.94729840755\n",
      "Epoch: 3 -> Test Accuracy: 28.63\n",
      "[4, 60] loss: 1.927\n",
      "[4, 120] loss: 1.912\n",
      "[4, 180] loss: 1.921\n",
      "[4, 240] loss: 1.929\n",
      "[4, 300] loss: 1.913\n",
      "[4, 360] loss: 1.917\n",
      "Epoch: 4 -> Loss: 1.97549974918\n",
      "Epoch: 4 -> Test Accuracy: 28.88\n",
      "[5, 60] loss: 1.896\n",
      "[5, 120] loss: 1.903\n",
      "[5, 180] loss: 1.922\n",
      "[5, 240] loss: 1.900\n",
      "[5, 300] loss: 1.891\n",
      "[5, 360] loss: 1.892\n",
      "Epoch: 5 -> Loss: 1.95684874058\n",
      "Epoch: 5 -> Test Accuracy: 29.63\n",
      "[6, 60] loss: 1.895\n",
      "[6, 120] loss: 1.902\n",
      "[6, 180] loss: 1.889\n",
      "[6, 240] loss: 1.900\n",
      "[6, 300] loss: 1.881\n",
      "[6, 360] loss: 1.866\n",
      "Epoch: 6 -> Loss: 1.9390232563\n",
      "Epoch: 6 -> Test Accuracy: 30.02\n",
      "[7, 60] loss: 1.899\n",
      "[7, 120] loss: 1.889\n",
      "[7, 180] loss: 1.899\n",
      "[7, 240] loss: 1.879\n",
      "[7, 300] loss: 1.888\n",
      "[7, 360] loss: 1.892\n",
      "Epoch: 7 -> Loss: 1.95004343987\n",
      "Epoch: 7 -> Test Accuracy: 30.44\n",
      "[8, 60] loss: 1.869\n",
      "[8, 120] loss: 1.863\n",
      "[8, 180] loss: 1.877\n",
      "[8, 240] loss: 1.890\n",
      "[8, 300] loss: 1.892\n",
      "[8, 360] loss: 1.873\n",
      "Epoch: 8 -> Loss: 1.70396077633\n",
      "Epoch: 8 -> Test Accuracy: 29.84\n",
      "[9, 60] loss: 1.868\n",
      "[9, 120] loss: 1.856\n",
      "[9, 180] loss: 1.868\n",
      "[9, 240] loss: 1.867\n",
      "[9, 300] loss: 1.879\n",
      "[9, 360] loss: 1.887\n",
      "Epoch: 9 -> Loss: 1.9652671814\n",
      "Epoch: 9 -> Test Accuracy: 31.89\n",
      "[10, 60] loss: 1.857\n",
      "[10, 120] loss: 1.881\n",
      "[10, 180] loss: 1.867\n",
      "[10, 240] loss: 1.875\n",
      "[10, 300] loss: 1.876\n",
      "[10, 360] loss: 1.864\n",
      "Epoch: 10 -> Loss: 1.87818694115\n",
      "Epoch: 10 -> Test Accuracy: 30.67\n",
      "[11, 60] loss: 1.873\n",
      "[11, 120] loss: 1.873\n",
      "[11, 180] loss: 1.870\n",
      "[11, 240] loss: 1.860\n",
      "[11, 300] loss: 1.876\n",
      "[11, 360] loss: 1.883\n",
      "Epoch: 11 -> Loss: 1.98747324944\n",
      "Epoch: 11 -> Test Accuracy: 30.51\n",
      "[12, 60] loss: 1.877\n",
      "[12, 120] loss: 1.860\n",
      "[12, 180] loss: 1.863\n",
      "[12, 240] loss: 1.870\n",
      "[12, 300] loss: 1.870\n",
      "[12, 360] loss: 1.864\n",
      "Epoch: 12 -> Loss: 1.84878575802\n",
      "Epoch: 12 -> Test Accuracy: 30.09\n",
      "[13, 60] loss: 1.862\n",
      "[13, 120] loss: 1.852\n",
      "[13, 180] loss: 1.875\n",
      "[13, 240] loss: 1.871\n",
      "[13, 300] loss: 1.886\n",
      "[13, 360] loss: 1.875\n",
      "Epoch: 13 -> Loss: 1.90440535545\n",
      "Epoch: 13 -> Test Accuracy: 30.32\n",
      "[14, 60] loss: 1.877\n",
      "[14, 120] loss: 1.851\n",
      "[14, 180] loss: 1.865\n",
      "[14, 240] loss: 1.855\n",
      "[14, 300] loss: 1.860\n",
      "[14, 360] loss: 1.859\n",
      "Epoch: 14 -> Loss: 1.81933021545\n",
      "Epoch: 14 -> Test Accuracy: 30.74\n",
      "[15, 60] loss: 1.866\n",
      "[15, 120] loss: 1.866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 180] loss: 1.863\n",
      "[15, 240] loss: 1.849\n",
      "[15, 300] loss: 1.865\n",
      "[15, 360] loss: 1.861\n",
      "Epoch: 15 -> Loss: 1.82290387154\n",
      "Epoch: 15 -> Test Accuracy: 30.75\n",
      "[16, 60] loss: 1.844\n",
      "[16, 120] loss: 1.859\n",
      "[16, 180] loss: 1.864\n",
      "[16, 240] loss: 1.859\n",
      "[16, 300] loss: 1.841\n",
      "[16, 360] loss: 1.877\n",
      "Epoch: 16 -> Loss: 1.69116556644\n",
      "Epoch: 16 -> Test Accuracy: 29.65\n",
      "[17, 60] loss: 1.851\n",
      "[17, 120] loss: 1.855\n",
      "[17, 180] loss: 1.850\n",
      "[17, 240] loss: 1.858\n",
      "[17, 300] loss: 1.863\n",
      "[17, 360] loss: 1.861\n",
      "Epoch: 17 -> Loss: 1.8220924139\n",
      "Epoch: 17 -> Test Accuracy: 31.12\n",
      "[18, 60] loss: 1.851\n",
      "[18, 120] loss: 1.841\n",
      "[18, 180] loss: 1.853\n",
      "[18, 240] loss: 1.860\n",
      "[18, 300] loss: 1.849\n",
      "[18, 360] loss: 1.847\n",
      "Epoch: 18 -> Loss: 1.84232115746\n",
      "Epoch: 18 -> Test Accuracy: 30.8\n",
      "[19, 60] loss: 1.846\n",
      "[19, 120] loss: 1.853\n",
      "[19, 180] loss: 1.829\n",
      "[19, 240] loss: 1.867\n",
      "[19, 300] loss: 1.876\n",
      "[19, 360] loss: 1.859\n",
      "Epoch: 19 -> Loss: 1.89137077332\n",
      "Epoch: 19 -> Test Accuracy: 29.9\n",
      "[20, 60] loss: 1.859\n",
      "[20, 120] loss: 1.842\n",
      "[20, 180] loss: 1.849\n",
      "[20, 240] loss: 1.856\n",
      "[20, 300] loss: 1.849\n",
      "[20, 360] loss: 1.838\n",
      "Epoch: 20 -> Loss: 1.74403357506\n",
      "Epoch: 20 -> Test Accuracy: 31.07\n",
      "[21, 60] loss: 1.819\n",
      "[21, 120] loss: 1.790\n",
      "[21, 180] loss: 1.796\n",
      "[21, 240] loss: 1.794\n",
      "[21, 300] loss: 1.788\n",
      "[21, 360] loss: 1.760\n",
      "Epoch: 21 -> Loss: 1.7007175684\n",
      "Epoch: 21 -> Test Accuracy: 33.04\n",
      "[22, 60] loss: 1.755\n",
      "[22, 120] loss: 1.767\n",
      "[22, 180] loss: 1.767\n",
      "[22, 240] loss: 1.771\n",
      "[22, 300] loss: 1.778\n",
      "[22, 360] loss: 1.751\n",
      "Epoch: 22 -> Loss: 1.78580451012\n",
      "Epoch: 22 -> Test Accuracy: 33.38\n",
      "[23, 60] loss: 1.773\n",
      "[23, 120] loss: 1.746\n",
      "[23, 180] loss: 1.743\n",
      "[23, 240] loss: 1.743\n",
      "[23, 300] loss: 1.761\n",
      "[23, 360] loss: 1.767\n",
      "Epoch: 23 -> Loss: 1.86052191257\n",
      "Epoch: 23 -> Test Accuracy: 33.32\n",
      "[24, 60] loss: 1.742\n",
      "[24, 120] loss: 1.734\n",
      "[24, 180] loss: 1.760\n",
      "[24, 240] loss: 1.752\n",
      "[24, 300] loss: 1.743\n",
      "[24, 360] loss: 1.762\n",
      "Epoch: 24 -> Loss: 1.9423469305\n",
      "Epoch: 24 -> Test Accuracy: 33.22\n",
      "[25, 60] loss: 1.745\n",
      "[25, 120] loss: 1.743\n",
      "[25, 180] loss: 1.749\n",
      "[25, 240] loss: 1.747\n",
      "[25, 300] loss: 1.742\n",
      "[25, 360] loss: 1.749\n",
      "Epoch: 25 -> Loss: 1.93193244934\n",
      "Epoch: 25 -> Test Accuracy: 33.57\n",
      "[26, 60] loss: 1.768\n",
      "[26, 120] loss: 1.746\n",
      "[26, 180] loss: 1.746\n",
      "[26, 240] loss: 1.747\n",
      "[26, 300] loss: 1.762\n",
      "[26, 360] loss: 1.721\n",
      "Epoch: 26 -> Loss: 1.63496077061\n",
      "Epoch: 26 -> Test Accuracy: 33.66\n",
      "[27, 60] loss: 1.755\n",
      "[27, 120] loss: 1.735\n",
      "[27, 180] loss: 1.743\n",
      "[27, 240] loss: 1.744\n",
      "[27, 300] loss: 1.746\n",
      "[27, 360] loss: 1.744\n",
      "Epoch: 27 -> Loss: 1.92062973976\n",
      "Epoch: 27 -> Test Accuracy: 33.87\n",
      "[28, 60] loss: 1.736\n",
      "[28, 120] loss: 1.749\n",
      "[28, 180] loss: 1.746\n",
      "[28, 240] loss: 1.736\n",
      "[28, 300] loss: 1.742\n",
      "[28, 360] loss: 1.743\n",
      "Epoch: 28 -> Loss: 1.55879187584\n",
      "Epoch: 28 -> Test Accuracy: 33.79\n",
      "[29, 60] loss: 1.739\n",
      "[29, 120] loss: 1.759\n",
      "[29, 180] loss: 1.754\n",
      "[29, 240] loss: 1.727\n",
      "[29, 300] loss: 1.733\n",
      "[29, 360] loss: 1.733\n",
      "Epoch: 29 -> Loss: 1.81209504604\n",
      "Epoch: 29 -> Test Accuracy: 34.45\n",
      "[30, 60] loss: 1.749\n",
      "[30, 120] loss: 1.745\n",
      "[30, 180] loss: 1.743\n",
      "[30, 240] loss: 1.747\n",
      "[30, 300] loss: 1.740\n",
      "[30, 360] loss: 1.751\n",
      "Epoch: 30 -> Loss: 1.85501897335\n",
      "Epoch: 30 -> Test Accuracy: 34.41\n",
      "[31, 60] loss: 1.727\n",
      "[31, 120] loss: 1.742\n",
      "[31, 180] loss: 1.732\n",
      "[31, 240] loss: 1.745\n",
      "[31, 300] loss: 1.747\n",
      "[31, 360] loss: 1.743\n",
      "Epoch: 31 -> Loss: 1.79362797737\n",
      "Epoch: 31 -> Test Accuracy: 33.33\n",
      "[32, 60] loss: 1.752\n",
      "[32, 120] loss: 1.753\n",
      "[32, 180] loss: 1.749\n",
      "[32, 240] loss: 1.714\n",
      "[32, 300] loss: 1.742\n",
      "[32, 360] loss: 1.734\n",
      "Epoch: 32 -> Loss: 1.58487963676\n",
      "Epoch: 32 -> Test Accuracy: 34.08\n",
      "[33, 60] loss: 1.750\n",
      "[33, 120] loss: 1.750\n",
      "[33, 180] loss: 1.739\n",
      "[33, 240] loss: 1.739\n",
      "[33, 300] loss: 1.752\n",
      "[33, 360] loss: 1.732\n",
      "Epoch: 33 -> Loss: 2.03194999695\n",
      "Epoch: 33 -> Test Accuracy: 33.81\n",
      "[34, 60] loss: 1.757\n",
      "[34, 120] loss: 1.748\n",
      "[34, 180] loss: 1.744\n",
      "[34, 240] loss: 1.737\n",
      "[34, 300] loss: 1.725\n",
      "[34, 360] loss: 1.728\n",
      "Epoch: 34 -> Loss: 1.77967703342\n",
      "Epoch: 34 -> Test Accuracy: 33.51\n",
      "[35, 60] loss: 1.731\n",
      "[35, 120] loss: 1.742\n",
      "[35, 180] loss: 1.746\n",
      "[35, 240] loss: 1.740\n",
      "[35, 300] loss: 1.741\n",
      "[35, 360] loss: 1.744\n",
      "Epoch: 35 -> Loss: 1.69858205318\n",
      "Epoch: 35 -> Test Accuracy: 33.52\n",
      "[36, 60] loss: 1.745\n",
      "[36, 120] loss: 1.734\n",
      "[36, 180] loss: 1.721\n",
      "[36, 240] loss: 1.742\n",
      "[36, 300] loss: 1.732\n",
      "[36, 360] loss: 1.735\n",
      "Epoch: 36 -> Loss: 1.8284124136\n",
      "Epoch: 36 -> Test Accuracy: 34.05\n",
      "[37, 60] loss: 1.730\n",
      "[37, 120] loss: 1.740\n",
      "[37, 180] loss: 1.737\n",
      "[37, 240] loss: 1.749\n",
      "[37, 300] loss: 1.732\n",
      "[37, 360] loss: 1.745\n",
      "Epoch: 37 -> Loss: 1.54528903961\n",
      "Epoch: 37 -> Test Accuracy: 33.87\n",
      "[38, 60] loss: 1.745\n",
      "[38, 120] loss: 1.727\n",
      "[38, 180] loss: 1.757\n",
      "[38, 240] loss: 1.727\n",
      "[38, 300] loss: 1.723\n",
      "[38, 360] loss: 1.736\n",
      "Epoch: 38 -> Loss: 1.74225878716\n",
      "Epoch: 38 -> Test Accuracy: 33.85\n",
      "[39, 60] loss: 1.731\n",
      "[39, 120] loss: 1.743\n",
      "[39, 180] loss: 1.726\n",
      "[39, 240] loss: 1.728\n",
      "[39, 300] loss: 1.726\n",
      "[39, 360] loss: 1.750\n",
      "Epoch: 39 -> Loss: 1.72519528866\n",
      "Epoch: 39 -> Test Accuracy: 33.98\n",
      "[40, 60] loss: 1.740\n",
      "[40, 120] loss: 1.739\n",
      "[40, 180] loss: 1.747\n",
      "[40, 240] loss: 1.728\n",
      "[40, 300] loss: 1.726\n",
      "[40, 360] loss: 1.752\n",
      "Epoch: 40 -> Loss: 1.68703782558\n",
      "Epoch: 40 -> Test Accuracy: 34.02\n",
      "[41, 60] loss: 1.721\n",
      "[41, 120] loss: 1.683\n",
      "[41, 180] loss: 1.703\n",
      "[41, 240] loss: 1.709\n",
      "[41, 300] loss: 1.698\n",
      "[41, 360] loss: 1.702\n",
      "Epoch: 41 -> Loss: 1.68481981754\n",
      "Epoch: 41 -> Test Accuracy: 35.83\n",
      "[42, 60] loss: 1.674\n",
      "[42, 120] loss: 1.686\n",
      "[42, 180] loss: 1.693\n",
      "[42, 240] loss: 1.685\n",
      "[42, 300] loss: 1.699\n",
      "[42, 360] loss: 1.679\n",
      "Epoch: 42 -> Loss: 1.67172074318\n",
      "Epoch: 42 -> Test Accuracy: 35.73\n",
      "[43, 60] loss: 1.665\n",
      "[43, 120] loss: 1.682\n",
      "[43, 180] loss: 1.690\n",
      "[43, 240] loss: 1.693\n",
      "[43, 300] loss: 1.670\n",
      "[43, 360] loss: 1.676\n",
      "Epoch: 43 -> Loss: 1.71660399437\n",
      "Epoch: 43 -> Test Accuracy: 35.7\n",
      "[44, 60] loss: 1.689\n",
      "[44, 120] loss: 1.677\n",
      "[44, 180] loss: 1.656\n",
      "[44, 240] loss: 1.691\n",
      "[44, 300] loss: 1.669\n",
      "[44, 360] loss: 1.671\n",
      "Epoch: 44 -> Loss: 1.68848955631\n",
      "Epoch: 44 -> Test Accuracy: 35.83\n",
      "[45, 60] loss: 1.675\n",
      "[45, 120] loss: 1.663\n",
      "[45, 180] loss: 1.651\n",
      "[45, 240] loss: 1.678\n",
      "[45, 300] loss: 1.680\n",
      "[45, 360] loss: 1.666\n",
      "Epoch: 45 -> Loss: 1.63632297516\n",
      "Epoch: 45 -> Test Accuracy: 35.42\n",
      "[46, 60] loss: 1.672\n",
      "[46, 120] loss: 1.672\n",
      "[46, 180] loss: 1.653\n",
      "[46, 240] loss: 1.686\n",
      "[46, 300] loss: 1.647\n",
      "[46, 360] loss: 1.650\n",
      "Epoch: 46 -> Loss: 1.67822098732\n",
      "Epoch: 46 -> Test Accuracy: 36.28\n",
      "[47, 60] loss: 1.653\n",
      "[47, 120] loss: 1.666\n",
      "[47, 180] loss: 1.664\n",
      "[47, 240] loss: 1.658\n",
      "[47, 300] loss: 1.666\n",
      "[47, 360] loss: 1.667\n",
      "Epoch: 47 -> Loss: 1.72839260101\n",
      "Epoch: 47 -> Test Accuracy: 36.21\n",
      "[48, 60] loss: 1.673\n",
      "[48, 120] loss: 1.667\n",
      "[48, 180] loss: 1.648\n",
      "[48, 240] loss: 1.668\n",
      "[48, 300] loss: 1.661\n",
      "[48, 360] loss: 1.663\n",
      "Epoch: 48 -> Loss: 1.6988016367\n",
      "Epoch: 48 -> Test Accuracy: 36.25\n",
      "[49, 60] loss: 1.667\n",
      "[49, 120] loss: 1.656\n",
      "[49, 180] loss: 1.642\n",
      "[49, 240] loss: 1.652\n",
      "[49, 300] loss: 1.665\n",
      "[49, 360] loss: 1.663\n",
      "Epoch: 49 -> Loss: 1.82113933563\n",
      "Epoch: 49 -> Test Accuracy: 36.57\n",
      "[50, 60] loss: 1.667\n",
      "[50, 120] loss: 1.651\n",
      "[50, 180] loss: 1.650\n",
      "[50, 240] loss: 1.665\n",
      "[50, 300] loss: 1.674\n",
      "[50, 360] loss: 1.650\n",
      "Epoch: 50 -> Loss: 1.70216012001\n",
      "Epoch: 50 -> Test Accuracy: 36.55\n",
      "[51, 60] loss: 1.659\n",
      "[51, 120] loss: 1.648\n",
      "[51, 180] loss: 1.660\n",
      "[51, 240] loss: 1.638\n",
      "[51, 300] loss: 1.653\n",
      "[51, 360] loss: 1.658\n",
      "Epoch: 51 -> Loss: 1.57303094864\n",
      "Epoch: 51 -> Test Accuracy: 36.63\n",
      "[52, 60] loss: 1.681\n",
      "[52, 120] loss: 1.663\n",
      "[52, 180] loss: 1.666\n",
      "[52, 240] loss: 1.652\n",
      "[52, 300] loss: 1.638\n",
      "[52, 360] loss: 1.649\n",
      "Epoch: 52 -> Loss: 1.77626097202\n",
      "Epoch: 52 -> Test Accuracy: 36.74\n",
      "[53, 60] loss: 1.646\n",
      "[53, 120] loss: 1.643\n",
      "[53, 180] loss: 1.654\n",
      "[53, 240] loss: 1.662\n",
      "[53, 300] loss: 1.663\n",
      "[53, 360] loss: 1.642\n",
      "Epoch: 53 -> Loss: 1.67196941376\n",
      "Epoch: 53 -> Test Accuracy: 36.54\n",
      "[54, 60] loss: 1.644\n",
      "[54, 120] loss: 1.651\n",
      "[54, 180] loss: 1.646\n",
      "[54, 240] loss: 1.647\n",
      "[54, 300] loss: 1.646\n",
      "[54, 360] loss: 1.663\n",
      "Epoch: 54 -> Loss: 1.65347993374\n",
      "Epoch: 54 -> Test Accuracy: 36.64\n",
      "[55, 60] loss: 1.656\n",
      "[55, 120] loss: 1.658\n",
      "[55, 180] loss: 1.636\n",
      "[55, 240] loss: 1.644\n",
      "[55, 300] loss: 1.650\n",
      "[55, 360] loss: 1.653\n",
      "Epoch: 55 -> Loss: 1.63814067841\n",
      "Epoch: 55 -> Test Accuracy: 36.36\n",
      "[56, 60] loss: 1.642\n",
      "[56, 120] loss: 1.647\n",
      "[56, 180] loss: 1.643\n",
      "[56, 240] loss: 1.645\n",
      "[56, 300] loss: 1.644\n",
      "[56, 360] loss: 1.673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56 -> Loss: 1.62352335453\n",
      "Epoch: 56 -> Test Accuracy: 36.51\n",
      "[57, 60] loss: 1.653\n",
      "[57, 120] loss: 1.657\n",
      "[57, 180] loss: 1.629\n",
      "[57, 240] loss: 1.635\n",
      "[57, 300] loss: 1.656\n",
      "[57, 360] loss: 1.649\n",
      "Epoch: 57 -> Loss: 1.50538563728\n",
      "Epoch: 57 -> Test Accuracy: 36.59\n",
      "[58, 60] loss: 1.658\n",
      "[58, 120] loss: 1.638\n",
      "[58, 180] loss: 1.650\n",
      "[58, 240] loss: 1.663\n",
      "[58, 300] loss: 1.631\n",
      "[58, 360] loss: 1.643\n",
      "Epoch: 58 -> Loss: 1.66287612915\n",
      "Epoch: 58 -> Test Accuracy: 36.58\n",
      "[59, 60] loss: 1.665\n",
      "[59, 120] loss: 1.646\n",
      "[59, 180] loss: 1.664\n",
      "[59, 240] loss: 1.633\n",
      "[59, 300] loss: 1.666\n",
      "[59, 360] loss: 1.642\n",
      "Epoch: 59 -> Loss: 1.65239596367\n",
      "Epoch: 59 -> Test Accuracy: 36.72\n",
      "[60, 60] loss: 1.654\n",
      "[60, 120] loss: 1.655\n",
      "[60, 180] loss: 1.649\n",
      "[60, 240] loss: 1.653\n",
      "[60, 300] loss: 1.637\n",
      "[60, 360] loss: 1.626\n",
      "Epoch: 60 -> Loss: 1.70393717289\n",
      "Epoch: 60 -> Test Accuracy: 36.6\n",
      "[61, 60] loss: 1.634\n",
      "[61, 120] loss: 1.655\n",
      "[61, 180] loss: 1.644\n",
      "[61, 240] loss: 1.637\n",
      "[61, 300] loss: 1.640\n",
      "[61, 360] loss: 1.648\n",
      "Epoch: 61 -> Loss: 1.58803868294\n",
      "Epoch: 61 -> Test Accuracy: 36.61\n",
      "[62, 60] loss: 1.651\n",
      "[62, 120] loss: 1.646\n",
      "[62, 180] loss: 1.641\n",
      "[62, 240] loss: 1.658\n",
      "[62, 300] loss: 1.647\n",
      "[62, 360] loss: 1.643\n",
      "Epoch: 62 -> Loss: 1.82409060001\n",
      "Epoch: 62 -> Test Accuracy: 36.57\n",
      "[63, 60] loss: 1.653\n",
      "[63, 120] loss: 1.643\n",
      "[63, 180] loss: 1.638\n",
      "[63, 240] loss: 1.663\n",
      "[63, 300] loss: 1.644\n",
      "[63, 360] loss: 1.654\n",
      "Epoch: 63 -> Loss: 1.60529065132\n",
      "Epoch: 63 -> Test Accuracy: 36.54\n",
      "[64, 60] loss: 1.648\n",
      "[64, 120] loss: 1.642\n",
      "[64, 180] loss: 1.645\n",
      "[64, 240] loss: 1.648\n",
      "[64, 300] loss: 1.647\n",
      "[64, 360] loss: 1.641\n",
      "Epoch: 64 -> Loss: 1.67311632633\n",
      "Epoch: 64 -> Test Accuracy: 36.6\n",
      "[65, 60] loss: 1.646\n",
      "[65, 120] loss: 1.643\n",
      "[65, 180] loss: 1.645\n",
      "[65, 240] loss: 1.639\n",
      "[65, 300] loss: 1.641\n",
      "[65, 360] loss: 1.635\n",
      "Epoch: 65 -> Loss: 1.61642169952\n",
      "Epoch: 65 -> Test Accuracy: 36.49\n",
      "[66, 60] loss: 1.636\n",
      "[66, 120] loss: 1.630\n",
      "[66, 180] loss: 1.631\n",
      "[66, 240] loss: 1.658\n",
      "[66, 300] loss: 1.635\n",
      "[66, 360] loss: 1.636\n",
      "Epoch: 66 -> Loss: 1.79439008236\n",
      "Epoch: 66 -> Test Accuracy: 36.66\n",
      "[67, 60] loss: 1.647\n",
      "[67, 120] loss: 1.655\n",
      "[67, 180] loss: 1.653\n",
      "[67, 240] loss: 1.637\n",
      "[67, 300] loss: 1.636\n",
      "[67, 360] loss: 1.650\n",
      "Epoch: 67 -> Loss: 1.54494380951\n",
      "Epoch: 67 -> Test Accuracy: 36.75\n",
      "[68, 60] loss: 1.626\n",
      "[68, 120] loss: 1.636\n",
      "[68, 180] loss: 1.643\n",
      "[68, 240] loss: 1.646\n",
      "[68, 300] loss: 1.649\n",
      "[68, 360] loss: 1.632\n",
      "Epoch: 68 -> Loss: 1.6022670269\n",
      "Epoch: 68 -> Test Accuracy: 36.54\n",
      "[69, 60] loss: 1.630\n",
      "[69, 120] loss: 1.650\n",
      "[69, 180] loss: 1.640\n",
      "[69, 240] loss: 1.645\n",
      "[69, 300] loss: 1.628\n",
      "[69, 360] loss: 1.644\n",
      "Epoch: 69 -> Loss: 1.45776343346\n",
      "Epoch: 69 -> Test Accuracy: 36.79\n",
      "[70, 60] loss: 1.644\n",
      "[70, 120] loss: 1.641\n",
      "[70, 180] loss: 1.644\n",
      "[70, 240] loss: 1.654\n",
      "[70, 300] loss: 1.642\n",
      "[70, 360] loss: 1.624\n",
      "Epoch: 70 -> Loss: 1.67732739449\n",
      "Epoch: 70 -> Test Accuracy: 36.61\n",
      "[71, 60] loss: 1.657\n",
      "[71, 120] loss: 1.639\n",
      "[71, 180] loss: 1.659\n",
      "[71, 240] loss: 1.649\n",
      "[71, 300] loss: 1.638\n",
      "[71, 360] loss: 1.655\n",
      "Epoch: 71 -> Loss: 1.61282098293\n",
      "Epoch: 71 -> Test Accuracy: 36.69\n",
      "[72, 60] loss: 1.633\n",
      "[72, 120] loss: 1.617\n",
      "[72, 180] loss: 1.648\n",
      "[72, 240] loss: 1.650\n",
      "[72, 300] loss: 1.635\n",
      "[72, 360] loss: 1.621\n",
      "Epoch: 72 -> Loss: 1.65243649483\n",
      "Epoch: 72 -> Test Accuracy: 36.69\n",
      "[73, 60] loss: 1.644\n",
      "[73, 120] loss: 1.647\n",
      "[73, 180] loss: 1.640\n",
      "[73, 240] loss: 1.653\n",
      "[73, 300] loss: 1.663\n",
      "[73, 360] loss: 1.614\n",
      "Epoch: 73 -> Loss: 1.61603999138\n",
      "Epoch: 73 -> Test Accuracy: 36.88\n",
      "[74, 60] loss: 1.637\n",
      "[74, 120] loss: 1.643\n",
      "[74, 180] loss: 1.625\n",
      "[74, 240] loss: 1.644\n",
      "[74, 300] loss: 1.625\n",
      "[74, 360] loss: 1.644\n",
      "Epoch: 74 -> Loss: 1.63095319271\n",
      "Epoch: 74 -> Test Accuracy: 36.97\n",
      "[75, 60] loss: 1.641\n",
      "[75, 120] loss: 1.647\n",
      "[75, 180] loss: 1.649\n",
      "[75, 240] loss: 1.630\n",
      "[75, 300] loss: 1.639\n",
      "[75, 360] loss: 1.643\n",
      "Epoch: 75 -> Loss: 1.53273499012\n",
      "Epoch: 75 -> Test Accuracy: 36.84\n",
      "[76, 60] loss: 1.627\n",
      "[76, 120] loss: 1.624\n",
      "[76, 180] loss: 1.647\n",
      "[76, 240] loss: 1.644\n",
      "[76, 300] loss: 1.646\n",
      "[76, 360] loss: 1.629\n",
      "Epoch: 76 -> Loss: 1.7571618557\n",
      "Epoch: 76 -> Test Accuracy: 36.72\n",
      "[77, 60] loss: 1.646\n",
      "[77, 120] loss: 1.646\n",
      "[77, 180] loss: 1.631\n",
      "[77, 240] loss: 1.628\n",
      "[77, 300] loss: 1.649\n",
      "[77, 360] loss: 1.643\n",
      "Epoch: 77 -> Loss: 1.66895484924\n",
      "Epoch: 77 -> Test Accuracy: 36.67\n",
      "[78, 60] loss: 1.640\n",
      "[78, 120] loss: 1.635\n",
      "[78, 180] loss: 1.643\n",
      "[78, 240] loss: 1.641\n",
      "[78, 300] loss: 1.646\n",
      "[78, 360] loss: 1.644\n",
      "Epoch: 78 -> Loss: 1.72156202793\n",
      "Epoch: 78 -> Test Accuracy: 36.82\n",
      "[79, 60] loss: 1.634\n",
      "[79, 120] loss: 1.644\n",
      "[79, 180] loss: 1.627\n",
      "[79, 240] loss: 1.629\n",
      "[79, 300] loss: 1.637\n",
      "[79, 360] loss: 1.631\n",
      "Epoch: 79 -> Loss: 1.68813836575\n",
      "Epoch: 79 -> Test Accuracy: 36.52\n",
      "[80, 60] loss: 1.631\n",
      "[80, 120] loss: 1.641\n",
      "[80, 180] loss: 1.638\n",
      "[80, 240] loss: 1.635\n",
      "[80, 300] loss: 1.623\n",
      "[80, 360] loss: 1.627\n",
      "Epoch: 80 -> Loss: 1.76159322262\n",
      "Epoch: 80 -> Test Accuracy: 36.62\n",
      "[81, 60] loss: 1.620\n",
      "[81, 120] loss: 1.631\n",
      "[81, 180] loss: 1.648\n",
      "[81, 240] loss: 1.627\n",
      "[81, 300] loss: 1.626\n",
      "[81, 360] loss: 1.633\n",
      "Epoch: 81 -> Loss: 1.72262918949\n",
      "Epoch: 81 -> Test Accuracy: 36.86\n",
      "[82, 60] loss: 1.631\n",
      "[82, 120] loss: 1.639\n",
      "[82, 180] loss: 1.640\n",
      "[82, 240] loss: 1.637\n",
      "[82, 300] loss: 1.624\n",
      "[82, 360] loss: 1.634\n",
      "Epoch: 82 -> Loss: 1.55884814262\n",
      "Epoch: 82 -> Test Accuracy: 36.8\n",
      "[83, 60] loss: 1.642\n",
      "[83, 120] loss: 1.632\n",
      "[83, 180] loss: 1.634\n",
      "[83, 240] loss: 1.647\n",
      "[83, 300] loss: 1.620\n",
      "[83, 360] loss: 1.616\n",
      "Epoch: 83 -> Loss: 1.81178593636\n",
      "Epoch: 83 -> Test Accuracy: 37.06\n",
      "[84, 60] loss: 1.628\n",
      "[84, 120] loss: 1.654\n",
      "[84, 180] loss: 1.613\n",
      "[84, 240] loss: 1.635\n",
      "[84, 300] loss: 1.617\n",
      "[84, 360] loss: 1.635\n",
      "Epoch: 84 -> Loss: 1.47937834263\n",
      "Epoch: 84 -> Test Accuracy: 36.99\n",
      "[85, 60] loss: 1.621\n",
      "[85, 120] loss: 1.647\n",
      "[85, 180] loss: 1.630\n",
      "[85, 240] loss: 1.626\n",
      "[85, 300] loss: 1.641\n",
      "[85, 360] loss: 1.632\n",
      "Epoch: 85 -> Loss: 1.79377388954\n",
      "Epoch: 85 -> Test Accuracy: 36.88\n",
      "[86, 60] loss: 1.636\n",
      "[86, 120] loss: 1.642\n",
      "[86, 180] loss: 1.627\n",
      "[86, 240] loss: 1.620\n",
      "[86, 300] loss: 1.628\n",
      "[86, 360] loss: 1.629\n",
      "Epoch: 86 -> Loss: 1.67091298103\n",
      "Epoch: 86 -> Test Accuracy: 37.04\n",
      "[87, 60] loss: 1.643\n",
      "[87, 120] loss: 1.655\n",
      "[87, 180] loss: 1.619\n",
      "[87, 240] loss: 1.623\n",
      "[87, 300] loss: 1.634\n",
      "[87, 360] loss: 1.619\n",
      "Epoch: 87 -> Loss: 1.78414916992\n",
      "Epoch: 87 -> Test Accuracy: 37.1\n",
      "[88, 60] loss: 1.623\n",
      "[88, 120] loss: 1.623\n",
      "[88, 180] loss: 1.637\n",
      "[88, 240] loss: 1.628\n",
      "[88, 300] loss: 1.633\n",
      "[88, 360] loss: 1.633\n",
      "Epoch: 88 -> Loss: 1.57692408562\n",
      "Epoch: 88 -> Test Accuracy: 37.11\n",
      "[89, 60] loss: 1.632\n",
      "[89, 120] loss: 1.611\n",
      "[89, 180] loss: 1.626\n",
      "[89, 240] loss: 1.641\n",
      "[89, 300] loss: 1.626\n",
      "[89, 360] loss: 1.638\n",
      "Epoch: 89 -> Loss: 1.74365842342\n",
      "Epoch: 89 -> Test Accuracy: 36.86\n",
      "[90, 60] loss: 1.613\n",
      "[90, 120] loss: 1.624\n",
      "[90, 180] loss: 1.630\n",
      "[90, 240] loss: 1.640\n",
      "[90, 300] loss: 1.627\n",
      "[90, 360] loss: 1.644\n",
      "Epoch: 90 -> Loss: 1.60559618473\n",
      "Epoch: 90 -> Test Accuracy: 37.09\n",
      "[91, 60] loss: 1.633\n",
      "[91, 120] loss: 1.625\n",
      "[91, 180] loss: 1.631\n",
      "[91, 240] loss: 1.624\n",
      "[91, 300] loss: 1.617\n",
      "[91, 360] loss: 1.624\n",
      "Epoch: 91 -> Loss: 1.48891746998\n",
      "Epoch: 91 -> Test Accuracy: 36.95\n",
      "[92, 60] loss: 1.636\n",
      "[92, 120] loss: 1.612\n",
      "[92, 180] loss: 1.630\n",
      "[92, 240] loss: 1.637\n",
      "[92, 300] loss: 1.624\n",
      "[92, 360] loss: 1.638\n",
      "Epoch: 92 -> Loss: 1.72883474827\n",
      "Epoch: 92 -> Test Accuracy: 36.84\n",
      "[93, 60] loss: 1.620\n",
      "[93, 120] loss: 1.640\n",
      "[93, 180] loss: 1.639\n",
      "[93, 240] loss: 1.601\n",
      "[93, 300] loss: 1.633\n",
      "[93, 360] loss: 1.630\n",
      "Epoch: 93 -> Loss: 1.6387822628\n",
      "Epoch: 93 -> Test Accuracy: 37.09\n",
      "[94, 60] loss: 1.640\n",
      "[94, 120] loss: 1.630\n",
      "[94, 180] loss: 1.629\n",
      "[94, 240] loss: 1.640\n",
      "[94, 300] loss: 1.627\n",
      "[94, 360] loss: 1.618\n",
      "Epoch: 94 -> Loss: 1.63537764549\n",
      "Epoch: 94 -> Test Accuracy: 37.22\n",
      "[95, 60] loss: 1.608\n",
      "[95, 120] loss: 1.632\n",
      "[95, 180] loss: 1.598\n",
      "[95, 240] loss: 1.640\n",
      "[95, 300] loss: 1.609\n",
      "[95, 360] loss: 1.637\n",
      "Epoch: 95 -> Loss: 1.86297929287\n",
      "Epoch: 95 -> Test Accuracy: 37.34\n",
      "[96, 60] loss: 1.629\n",
      "[96, 120] loss: 1.637\n",
      "[96, 180] loss: 1.632\n",
      "[96, 240] loss: 1.622\n",
      "[96, 300] loss: 1.629\n",
      "[96, 360] loss: 1.635\n",
      "Epoch: 96 -> Loss: 1.6499363184\n",
      "Epoch: 96 -> Test Accuracy: 37.07\n",
      "[97, 60] loss: 1.616\n",
      "[97, 120] loss: 1.634\n",
      "[97, 180] loss: 1.614\n",
      "[97, 240] loss: 1.615\n",
      "[97, 300] loss: 1.615\n",
      "[97, 360] loss: 1.614\n",
      "Epoch: 97 -> Loss: 1.62461316586\n",
      "Epoch: 97 -> Test Accuracy: 37.2\n",
      "[98, 60] loss: 1.615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98, 120] loss: 1.619\n",
      "[98, 180] loss: 1.632\n",
      "[98, 240] loss: 1.636\n",
      "[98, 300] loss: 1.617\n",
      "[98, 360] loss: 1.638\n",
      "Epoch: 98 -> Loss: 1.62498402596\n",
      "Epoch: 98 -> Test Accuracy: 37.24\n",
      "[99, 60] loss: 1.599\n",
      "[99, 120] loss: 1.628\n",
      "[99, 180] loss: 1.634\n",
      "[99, 240] loss: 1.643\n",
      "[99, 300] loss: 1.633\n",
      "[99, 360] loss: 1.639\n",
      "Epoch: 99 -> Loss: 1.64017164707\n",
      "Epoch: 99 -> Test Accuracy: 37.18\n",
      "[100, 60] loss: 1.617\n",
      "[100, 120] loss: 1.650\n",
      "[100, 180] loss: 1.607\n",
      "[100, 240] loss: 1.627\n",
      "[100, 300] loss: 1.619\n",
      "[100, 360] loss: 1.621\n",
      "Epoch: 100 -> Loss: 1.56429064274\n",
      "Epoch: 100 -> Test Accuracy: 37.1\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train NonLinearClassifiers on feature map of net_3block\n",
    "block5_loss_log, block5_valid_accuracy_log, block5_test_accuracy_log, block5_max_accuracy, block5_best_epoch = \\\n",
    "tr.train_all_blocks(5, 10, [0.1, 0.02, 0.004, 0.0008], [20, 40, 45, 100], 0.9, 5e-4, net_block5, criterion, trainloader,\n",
    "                    None, testloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.333\n",
      "[1, 120] loss: 1.065\n",
      "[1, 180] loss: 0.953\n",
      "[1, 240] loss: 0.935\n",
      "[1, 300] loss: 0.847\n",
      "[1, 360] loss: 0.815\n",
      "Epoch: 1 -> Loss: 0.786949038506\n",
      "Epoch: 1 -> Test Accuracy: 70.53\n",
      "[2, 60] loss: 0.774\n",
      "[2, 120] loss: 0.726\n",
      "[2, 180] loss: 0.742\n",
      "[2, 240] loss: 0.737\n",
      "[2, 300] loss: 0.677\n",
      "[2, 360] loss: 0.675\n",
      "Epoch: 2 -> Loss: 0.569421470165\n",
      "Epoch: 2 -> Test Accuracy: 75.21\n",
      "[3, 60] loss: 0.641\n",
      "[3, 120] loss: 0.636\n",
      "[3, 180] loss: 0.650\n",
      "[3, 240] loss: 0.636\n",
      "[3, 300] loss: 0.635\n",
      "[3, 360] loss: 0.620\n",
      "Epoch: 3 -> Loss: 0.662040531635\n",
      "Epoch: 3 -> Test Accuracy: 76.35\n",
      "[4, 60] loss: 0.586\n",
      "[4, 120] loss: 0.595\n",
      "[4, 180] loss: 0.565\n",
      "[4, 240] loss: 0.598\n",
      "[4, 300] loss: 0.594\n",
      "[4, 360] loss: 0.580\n",
      "Epoch: 4 -> Loss: 0.491086632013\n",
      "Epoch: 4 -> Test Accuracy: 76.58\n",
      "[5, 60] loss: 0.541\n",
      "[5, 120] loss: 0.578\n",
      "[5, 180] loss: 0.551\n",
      "[5, 240] loss: 0.568\n",
      "[5, 300] loss: 0.564\n",
      "[5, 360] loss: 0.566\n",
      "Epoch: 5 -> Loss: 0.636288583279\n",
      "Epoch: 5 -> Test Accuracy: 78.31\n",
      "[6, 60] loss: 0.522\n",
      "[6, 120] loss: 0.543\n",
      "[6, 180] loss: 0.529\n",
      "[6, 240] loss: 0.544\n",
      "[6, 300] loss: 0.532\n",
      "[6, 360] loss: 0.529\n",
      "Epoch: 6 -> Loss: 0.657692492008\n",
      "Epoch: 6 -> Test Accuracy: 78.11\n",
      "[7, 60] loss: 0.488\n",
      "[7, 120] loss: 0.522\n",
      "[7, 180] loss: 0.520\n",
      "[7, 240] loss: 0.524\n",
      "[7, 300] loss: 0.508\n",
      "[7, 360] loss: 0.538\n",
      "Epoch: 7 -> Loss: 0.355096369982\n",
      "Epoch: 7 -> Test Accuracy: 78.87\n",
      "[8, 60] loss: 0.488\n",
      "[8, 120] loss: 0.507\n",
      "[8, 180] loss: 0.511\n",
      "[8, 240] loss: 0.523\n",
      "[8, 300] loss: 0.503\n",
      "[8, 360] loss: 0.503\n",
      "Epoch: 8 -> Loss: 0.36888307333\n",
      "Epoch: 8 -> Test Accuracy: 78.12\n",
      "[9, 60] loss: 0.471\n",
      "[9, 120] loss: 0.485\n",
      "[9, 180] loss: 0.510\n",
      "[9, 240] loss: 0.514\n",
      "[9, 300] loss: 0.493\n",
      "[9, 360] loss: 0.488\n",
      "Epoch: 9 -> Loss: 0.618241131306\n",
      "Epoch: 9 -> Test Accuracy: 78.85\n",
      "[10, 60] loss: 0.475\n",
      "[10, 120] loss: 0.491\n",
      "[10, 180] loss: 0.485\n",
      "[10, 240] loss: 0.484\n",
      "[10, 300] loss: 0.486\n",
      "[10, 360] loss: 0.503\n",
      "Epoch: 10 -> Loss: 0.548916816711\n",
      "Epoch: 10 -> Test Accuracy: 80.05\n",
      "[11, 60] loss: 0.462\n",
      "[11, 120] loss: 0.467\n",
      "[11, 180] loss: 0.479\n",
      "[11, 240] loss: 0.493\n",
      "[11, 300] loss: 0.475\n",
      "[11, 360] loss: 0.491\n",
      "Epoch: 11 -> Loss: 0.428336203098\n",
      "Epoch: 11 -> Test Accuracy: 78.76\n",
      "[12, 60] loss: 0.469\n",
      "[12, 120] loss: 0.474\n",
      "[12, 180] loss: 0.484\n",
      "[12, 240] loss: 0.468\n",
      "[12, 300] loss: 0.464\n",
      "[12, 360] loss: 0.486\n",
      "Epoch: 12 -> Loss: 0.616450190544\n",
      "Epoch: 12 -> Test Accuracy: 79.41\n",
      "[13, 60] loss: 0.464\n",
      "[13, 120] loss: 0.453\n",
      "[13, 180] loss: 0.468\n",
      "[13, 240] loss: 0.493\n",
      "[13, 300] loss: 0.453\n",
      "[13, 360] loss: 0.475\n",
      "Epoch: 13 -> Loss: 0.557088553905\n",
      "Epoch: 13 -> Test Accuracy: 79.73\n",
      "[14, 60] loss: 0.454\n",
      "[14, 120] loss: 0.451\n",
      "[14, 180] loss: 0.468\n",
      "[14, 240] loss: 0.463\n",
      "[14, 300] loss: 0.470\n",
      "[14, 360] loss: 0.492\n",
      "Epoch: 14 -> Loss: 0.44991594553\n",
      "Epoch: 14 -> Test Accuracy: 80.51\n",
      "[15, 60] loss: 0.435\n",
      "[15, 120] loss: 0.462\n",
      "[15, 180] loss: 0.452\n",
      "[15, 240] loss: 0.470\n",
      "[15, 300] loss: 0.479\n",
      "[15, 360] loss: 0.455\n",
      "Epoch: 15 -> Loss: 0.41972002387\n",
      "Epoch: 15 -> Test Accuracy: 81.05\n",
      "[16, 60] loss: 0.426\n",
      "[16, 120] loss: 0.446\n",
      "[16, 180] loss: 0.454\n",
      "[16, 240] loss: 0.445\n",
      "[16, 300] loss: 0.471\n",
      "[16, 360] loss: 0.465\n",
      "Epoch: 16 -> Loss: 0.647159159184\n",
      "Epoch: 16 -> Test Accuracy: 80.84\n",
      "[17, 60] loss: 0.442\n",
      "[17, 120] loss: 0.463\n",
      "[17, 180] loss: 0.454\n",
      "[17, 240] loss: 0.463\n",
      "[17, 300] loss: 0.453\n",
      "[17, 360] loss: 0.456\n",
      "Epoch: 17 -> Loss: 0.478126376867\n",
      "Epoch: 17 -> Test Accuracy: 81.36\n",
      "[18, 60] loss: 0.417\n",
      "[18, 120] loss: 0.434\n",
      "[18, 180] loss: 0.462\n",
      "[18, 240] loss: 0.457\n",
      "[18, 300] loss: 0.452\n",
      "[18, 360] loss: 0.464\n",
      "Epoch: 18 -> Loss: 0.456967294216\n",
      "Epoch: 18 -> Test Accuracy: 81.06\n",
      "[19, 60] loss: 0.436\n",
      "[19, 120] loss: 0.454\n",
      "[19, 180] loss: 0.446\n",
      "[19, 240] loss: 0.464\n",
      "[19, 300] loss: 0.462\n",
      "[19, 360] loss: 0.447\n",
      "Epoch: 19 -> Loss: 0.253569126129\n",
      "Epoch: 19 -> Test Accuracy: 80.6\n",
      "[20, 60] loss: 0.438\n",
      "[20, 120] loss: 0.422\n",
      "[20, 180] loss: 0.447\n",
      "[20, 240] loss: 0.455\n",
      "[20, 300] loss: 0.460\n",
      "[20, 360] loss: 0.438\n",
      "Epoch: 20 -> Loss: 0.368171274662\n",
      "Epoch: 20 -> Test Accuracy: 80.38\n",
      "[21, 60] loss: 0.427\n",
      "[21, 120] loss: 0.443\n",
      "[21, 180] loss: 0.440\n",
      "[21, 240] loss: 0.436\n",
      "[21, 300] loss: 0.457\n",
      "[21, 360] loss: 0.445\n",
      "Epoch: 21 -> Loss: 0.454250812531\n",
      "Epoch: 21 -> Test Accuracy: 80.65\n",
      "[22, 60] loss: 0.427\n",
      "[22, 120] loss: 0.414\n",
      "[22, 180] loss: 0.444\n",
      "[22, 240] loss: 0.453\n",
      "[22, 300] loss: 0.462\n",
      "[22, 360] loss: 0.459\n",
      "Epoch: 22 -> Loss: 0.438085258007\n",
      "Epoch: 22 -> Test Accuracy: 81.14\n",
      "[23, 60] loss: 0.420\n",
      "[23, 120] loss: 0.419\n",
      "[23, 180] loss: 0.427\n",
      "[23, 240] loss: 0.435\n",
      "[23, 300] loss: 0.440\n",
      "[23, 360] loss: 0.459\n",
      "Epoch: 23 -> Loss: 0.451319843531\n",
      "Epoch: 23 -> Test Accuracy: 80.76\n",
      "[24, 60] loss: 0.412\n",
      "[24, 120] loss: 0.429\n",
      "[24, 180] loss: 0.431\n",
      "[24, 240] loss: 0.439\n",
      "[24, 300] loss: 0.445\n",
      "[24, 360] loss: 0.448\n",
      "Epoch: 24 -> Loss: 0.50903737545\n",
      "Epoch: 24 -> Test Accuracy: 81.08\n",
      "[25, 60] loss: 0.403\n",
      "[25, 120] loss: 0.421\n",
      "[25, 180] loss: 0.444\n",
      "[25, 240] loss: 0.469\n",
      "[25, 300] loss: 0.442\n",
      "[25, 360] loss: 0.442\n",
      "Epoch: 25 -> Loss: 0.439836353064\n",
      "Epoch: 25 -> Test Accuracy: 81.4\n",
      "[26, 60] loss: 0.408\n",
      "[26, 120] loss: 0.436\n",
      "[26, 180] loss: 0.434\n",
      "[26, 240] loss: 0.437\n",
      "[26, 300] loss: 0.448\n",
      "[26, 360] loss: 0.448\n",
      "Epoch: 26 -> Loss: 0.499670177698\n",
      "Epoch: 26 -> Test Accuracy: 81.79\n",
      "[27, 60] loss: 0.406\n",
      "[27, 120] loss: 0.435\n",
      "[27, 180] loss: 0.422\n",
      "[27, 240] loss: 0.445\n",
      "[27, 300] loss: 0.424\n",
      "[27, 360] loss: 0.433\n",
      "Epoch: 27 -> Loss: 0.487015008926\n",
      "Epoch: 27 -> Test Accuracy: 81.19\n",
      "[28, 60] loss: 0.408\n",
      "[28, 120] loss: 0.430\n",
      "[28, 180] loss: 0.415\n",
      "[28, 240] loss: 0.436\n",
      "[28, 300] loss: 0.427\n",
      "[28, 360] loss: 0.426\n",
      "Epoch: 28 -> Loss: 0.363689720631\n",
      "Epoch: 28 -> Test Accuracy: 81.37\n",
      "[29, 60] loss: 0.410\n",
      "[29, 120] loss: 0.404\n",
      "[29, 180] loss: 0.445\n",
      "[29, 240] loss: 0.444\n",
      "[29, 300] loss: 0.429\n",
      "[29, 360] loss: 0.444\n",
      "Epoch: 29 -> Loss: 0.295611470938\n",
      "Epoch: 29 -> Test Accuracy: 81.11\n",
      "[30, 60] loss: 0.390\n",
      "[30, 120] loss: 0.406\n",
      "[30, 180] loss: 0.443\n",
      "[30, 240] loss: 0.452\n",
      "[30, 300] loss: 0.444\n",
      "[30, 360] loss: 0.440\n",
      "Epoch: 30 -> Loss: 0.507369935513\n",
      "Epoch: 30 -> Test Accuracy: 80.46\n",
      "[31, 60] loss: 0.411\n",
      "[31, 120] loss: 0.425\n",
      "[31, 180] loss: 0.417\n",
      "[31, 240] loss: 0.421\n",
      "[31, 300] loss: 0.420\n",
      "[31, 360] loss: 0.437\n",
      "Epoch: 31 -> Loss: 0.445518672466\n",
      "Epoch: 31 -> Test Accuracy: 79.96\n",
      "[32, 60] loss: 0.413\n",
      "[32, 120] loss: 0.411\n",
      "[32, 180] loss: 0.424\n",
      "[32, 240] loss: 0.432\n",
      "[32, 300] loss: 0.421\n",
      "[32, 360] loss: 0.419\n",
      "Epoch: 32 -> Loss: 0.47570425272\n",
      "Epoch: 32 -> Test Accuracy: 81.98\n",
      "[33, 60] loss: 0.401\n",
      "[33, 120] loss: 0.424\n",
      "[33, 180] loss: 0.429\n",
      "[33, 240] loss: 0.422\n",
      "[33, 300] loss: 0.430\n",
      "[33, 360] loss: 0.435\n",
      "Epoch: 33 -> Loss: 0.446942031384\n",
      "Epoch: 33 -> Test Accuracy: 82.28\n",
      "[34, 60] loss: 0.405\n",
      "[34, 120] loss: 0.426\n",
      "[34, 180] loss: 0.419\n",
      "[34, 240] loss: 0.432\n",
      "[34, 300] loss: 0.440\n",
      "[34, 360] loss: 0.426\n",
      "Epoch: 34 -> Loss: 0.255498349667\n",
      "Epoch: 34 -> Test Accuracy: 80.81\n",
      "[35, 60] loss: 0.406\n",
      "[35, 120] loss: 0.435\n",
      "[35, 180] loss: 0.416\n",
      "[35, 240] loss: 0.421\n",
      "[35, 300] loss: 0.443\n",
      "[35, 360] loss: 0.440\n",
      "Epoch: 35 -> Loss: 0.417250931263\n",
      "Epoch: 35 -> Test Accuracy: 82.24\n",
      "[36, 60] loss: 0.353\n",
      "[36, 120] loss: 0.311\n",
      "[36, 180] loss: 0.294\n",
      "[36, 240] loss: 0.285\n",
      "[36, 300] loss: 0.293\n",
      "[36, 360] loss: 0.294\n",
      "Epoch: 36 -> Loss: 0.183020979166\n",
      "Epoch: 36 -> Test Accuracy: 85.03\n",
      "[37, 60] loss: 0.260\n",
      "[37, 120] loss: 0.264\n",
      "[37, 180] loss: 0.275\n",
      "[37, 240] loss: 0.265\n",
      "[37, 300] loss: 0.270\n",
      "[37, 360] loss: 0.275\n",
      "Epoch: 37 -> Loss: 0.287083059549\n",
      "Epoch: 37 -> Test Accuracy: 85.2\n",
      "[38, 60] loss: 0.252\n",
      "[38, 120] loss: 0.249\n",
      "[38, 180] loss: 0.265\n",
      "[38, 240] loss: 0.253\n",
      "[38, 300] loss: 0.256\n",
      "[38, 360] loss: 0.254\n",
      "Epoch: 38 -> Loss: 0.223209902644\n",
      "Epoch: 38 -> Test Accuracy: 85.54\n",
      "[39, 60] loss: 0.234\n",
      "[39, 120] loss: 0.250\n",
      "[39, 180] loss: 0.238\n",
      "[39, 240] loss: 0.249\n",
      "[39, 300] loss: 0.255\n",
      "[39, 360] loss: 0.253\n",
      "Epoch: 39 -> Loss: 0.278548181057\n",
      "Epoch: 39 -> Test Accuracy: 85.57\n",
      "[40, 60] loss: 0.238\n",
      "[40, 120] loss: 0.229\n",
      "[40, 180] loss: 0.251\n",
      "[40, 240] loss: 0.235\n",
      "[40, 300] loss: 0.247\n",
      "[40, 360] loss: 0.252\n",
      "Epoch: 40 -> Loss: 0.244584515691\n",
      "Epoch: 40 -> Test Accuracy: 85.0\n",
      "[41, 60] loss: 0.218\n",
      "[41, 120] loss: 0.228\n",
      "[41, 180] loss: 0.243\n",
      "[41, 240] loss: 0.243\n",
      "[41, 300] loss: 0.262\n",
      "[41, 360] loss: 0.252\n",
      "Epoch: 41 -> Loss: 0.201477497816\n",
      "Epoch: 41 -> Test Accuracy: 85.05\n",
      "[42, 60] loss: 0.225\n",
      "[42, 120] loss: 0.240\n",
      "[42, 180] loss: 0.243\n",
      "[42, 240] loss: 0.235\n",
      "[42, 300] loss: 0.245\n",
      "[42, 360] loss: 0.236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.280175596476\n",
      "Epoch: 42 -> Test Accuracy: 85.23\n",
      "[43, 60] loss: 0.223\n",
      "[43, 120] loss: 0.225\n",
      "[43, 180] loss: 0.235\n",
      "[43, 240] loss: 0.242\n",
      "[43, 300] loss: 0.246\n",
      "[43, 360] loss: 0.252\n",
      "Epoch: 43 -> Loss: 0.35005235672\n",
      "Epoch: 43 -> Test Accuracy: 85.32\n",
      "[44, 60] loss: 0.215\n",
      "[44, 120] loss: 0.237\n",
      "[44, 180] loss: 0.226\n",
      "[44, 240] loss: 0.239\n",
      "[44, 300] loss: 0.241\n",
      "[44, 360] loss: 0.251\n",
      "Epoch: 44 -> Loss: 0.2853102386\n",
      "Epoch: 44 -> Test Accuracy: 84.71\n",
      "[45, 60] loss: 0.218\n",
      "[45, 120] loss: 0.226\n",
      "[45, 180] loss: 0.242\n",
      "[45, 240] loss: 0.243\n",
      "[45, 300] loss: 0.246\n",
      "[45, 360] loss: 0.252\n",
      "Epoch: 45 -> Loss: 0.248574644327\n",
      "Epoch: 45 -> Test Accuracy: 84.88\n",
      "[46, 60] loss: 0.226\n",
      "[46, 120] loss: 0.230\n",
      "[46, 180] loss: 0.227\n",
      "[46, 240] loss: 0.239\n",
      "[46, 300] loss: 0.233\n",
      "[46, 360] loss: 0.250\n",
      "Epoch: 46 -> Loss: 0.310829550028\n",
      "Epoch: 46 -> Test Accuracy: 84.88\n",
      "[47, 60] loss: 0.218\n",
      "[47, 120] loss: 0.222\n",
      "[47, 180] loss: 0.229\n",
      "[47, 240] loss: 0.240\n",
      "[47, 300] loss: 0.247\n",
      "[47, 360] loss: 0.245\n",
      "Epoch: 47 -> Loss: 0.211168333888\n",
      "Epoch: 47 -> Test Accuracy: 84.98\n",
      "[48, 60] loss: 0.224\n",
      "[48, 120] loss: 0.222\n",
      "[48, 180] loss: 0.241\n",
      "[48, 240] loss: 0.245\n",
      "[48, 300] loss: 0.244\n",
      "[48, 360] loss: 0.252\n",
      "Epoch: 48 -> Loss: 0.142855793238\n",
      "Epoch: 48 -> Test Accuracy: 84.86\n",
      "[49, 60] loss: 0.217\n",
      "[49, 120] loss: 0.223\n",
      "[49, 180] loss: 0.228\n",
      "[49, 240] loss: 0.245\n",
      "[49, 300] loss: 0.252\n",
      "[49, 360] loss: 0.242\n",
      "Epoch: 49 -> Loss: 0.225067064166\n",
      "Epoch: 49 -> Test Accuracy: 84.6\n",
      "[50, 60] loss: 0.219\n",
      "[50, 120] loss: 0.226\n",
      "[50, 180] loss: 0.232\n",
      "[50, 240] loss: 0.231\n",
      "[50, 300] loss: 0.245\n",
      "[50, 360] loss: 0.249\n",
      "Epoch: 50 -> Loss: 0.259711772203\n",
      "Epoch: 50 -> Test Accuracy: 84.31\n",
      "[51, 60] loss: 0.231\n",
      "[51, 120] loss: 0.223\n",
      "[51, 180] loss: 0.222\n",
      "[51, 240] loss: 0.249\n",
      "[51, 300] loss: 0.231\n",
      "[51, 360] loss: 0.250\n",
      "Epoch: 51 -> Loss: 0.310011714697\n",
      "Epoch: 51 -> Test Accuracy: 83.86\n",
      "[52, 60] loss: 0.218\n",
      "[52, 120] loss: 0.223\n",
      "[52, 180] loss: 0.230\n",
      "[52, 240] loss: 0.228\n",
      "[52, 300] loss: 0.234\n",
      "[52, 360] loss: 0.247\n",
      "Epoch: 52 -> Loss: 0.444591522217\n",
      "Epoch: 52 -> Test Accuracy: 84.93\n",
      "[53, 60] loss: 0.217\n",
      "[53, 120] loss: 0.230\n",
      "[53, 180] loss: 0.241\n",
      "[53, 240] loss: 0.239\n",
      "[53, 300] loss: 0.235\n",
      "[53, 360] loss: 0.247\n",
      "Epoch: 53 -> Loss: 0.273478269577\n",
      "Epoch: 53 -> Test Accuracy: 84.47\n",
      "[54, 60] loss: 0.228\n",
      "[54, 120] loss: 0.224\n",
      "[54, 180] loss: 0.234\n",
      "[54, 240] loss: 0.236\n",
      "[54, 300] loss: 0.235\n",
      "[54, 360] loss: 0.256\n",
      "Epoch: 54 -> Loss: 0.287811696529\n",
      "Epoch: 54 -> Test Accuracy: 84.49\n",
      "[55, 60] loss: 0.224\n",
      "[55, 120] loss: 0.219\n",
      "[55, 180] loss: 0.237\n",
      "[55, 240] loss: 0.239\n",
      "[55, 300] loss: 0.231\n",
      "[55, 360] loss: 0.251\n",
      "Epoch: 55 -> Loss: 0.301973521709\n",
      "Epoch: 55 -> Test Accuracy: 84.45\n",
      "[56, 60] loss: 0.222\n",
      "[56, 120] loss: 0.216\n",
      "[56, 180] loss: 0.229\n",
      "[56, 240] loss: 0.239\n",
      "[56, 300] loss: 0.255\n",
      "[56, 360] loss: 0.230\n",
      "Epoch: 56 -> Loss: 0.268222212791\n",
      "Epoch: 56 -> Test Accuracy: 84.38\n",
      "[57, 60] loss: 0.213\n",
      "[57, 120] loss: 0.218\n",
      "[57, 180] loss: 0.237\n",
      "[57, 240] loss: 0.229\n",
      "[57, 300] loss: 0.234\n",
      "[57, 360] loss: 0.249\n",
      "Epoch: 57 -> Loss: 0.2483484447\n",
      "Epoch: 57 -> Test Accuracy: 84.91\n",
      "[58, 60] loss: 0.215\n",
      "[58, 120] loss: 0.224\n",
      "[58, 180] loss: 0.237\n",
      "[58, 240] loss: 0.230\n",
      "[58, 300] loss: 0.241\n",
      "[58, 360] loss: 0.240\n",
      "Epoch: 58 -> Loss: 0.314450562\n",
      "Epoch: 58 -> Test Accuracy: 85.15\n",
      "[59, 60] loss: 0.224\n",
      "[59, 120] loss: 0.213\n",
      "[59, 180] loss: 0.218\n",
      "[59, 240] loss: 0.220\n",
      "[59, 300] loss: 0.243\n",
      "[59, 360] loss: 0.240\n",
      "Epoch: 59 -> Loss: 0.200652599335\n",
      "Epoch: 59 -> Test Accuracy: 84.2\n",
      "[60, 60] loss: 0.215\n",
      "[60, 120] loss: 0.224\n",
      "[60, 180] loss: 0.225\n",
      "[60, 240] loss: 0.239\n",
      "[60, 300] loss: 0.233\n",
      "[60, 360] loss: 0.235\n",
      "Epoch: 60 -> Loss: 0.229872345924\n",
      "Epoch: 60 -> Test Accuracy: 83.44\n",
      "[61, 60] loss: 0.217\n",
      "[61, 120] loss: 0.204\n",
      "[61, 180] loss: 0.233\n",
      "[61, 240] loss: 0.225\n",
      "[61, 300] loss: 0.242\n",
      "[61, 360] loss: 0.234\n",
      "Epoch: 61 -> Loss: 0.175081700087\n",
      "Epoch: 61 -> Test Accuracy: 84.08\n",
      "[62, 60] loss: 0.212\n",
      "[62, 120] loss: 0.225\n",
      "[62, 180] loss: 0.223\n",
      "[62, 240] loss: 0.232\n",
      "[62, 300] loss: 0.234\n",
      "[62, 360] loss: 0.248\n",
      "Epoch: 62 -> Loss: 0.225135922432\n",
      "Epoch: 62 -> Test Accuracy: 84.7\n",
      "[63, 60] loss: 0.211\n",
      "[63, 120] loss: 0.234\n",
      "[63, 180] loss: 0.222\n",
      "[63, 240] loss: 0.232\n",
      "[63, 300] loss: 0.228\n",
      "[63, 360] loss: 0.232\n",
      "Epoch: 63 -> Loss: 0.203235059977\n",
      "Epoch: 63 -> Test Accuracy: 83.65\n",
      "[64, 60] loss: 0.212\n",
      "[64, 120] loss: 0.225\n",
      "[64, 180] loss: 0.217\n",
      "[64, 240] loss: 0.223\n",
      "[64, 300] loss: 0.231\n",
      "[64, 360] loss: 0.242\n",
      "Epoch: 64 -> Loss: 0.252884924412\n",
      "Epoch: 64 -> Test Accuracy: 83.91\n",
      "[65, 60] loss: 0.216\n",
      "[65, 120] loss: 0.225\n",
      "[65, 180] loss: 0.222\n",
      "[65, 240] loss: 0.227\n",
      "[65, 300] loss: 0.236\n",
      "[65, 360] loss: 0.235\n",
      "Epoch: 65 -> Loss: 0.190664798021\n",
      "Epoch: 65 -> Test Accuracy: 84.3\n",
      "[66, 60] loss: 0.223\n",
      "[66, 120] loss: 0.220\n",
      "[66, 180] loss: 0.224\n",
      "[66, 240] loss: 0.226\n",
      "[66, 300] loss: 0.230\n",
      "[66, 360] loss: 0.230\n",
      "Epoch: 66 -> Loss: 0.193983033299\n",
      "Epoch: 66 -> Test Accuracy: 84.24\n",
      "[67, 60] loss: 0.202\n",
      "[67, 120] loss: 0.206\n",
      "[67, 180] loss: 0.227\n",
      "[67, 240] loss: 0.230\n",
      "[67, 300] loss: 0.226\n",
      "[67, 360] loss: 0.233\n",
      "Epoch: 67 -> Loss: 0.17890137434\n",
      "Epoch: 67 -> Test Accuracy: 84.0\n",
      "[68, 60] loss: 0.215\n",
      "[68, 120] loss: 0.223\n",
      "[68, 180] loss: 0.214\n",
      "[68, 240] loss: 0.213\n",
      "[68, 300] loss: 0.233\n",
      "[68, 360] loss: 0.233\n",
      "Epoch: 68 -> Loss: 0.377032458782\n",
      "Epoch: 68 -> Test Accuracy: 84.28\n",
      "[69, 60] loss: 0.210\n",
      "[69, 120] loss: 0.206\n",
      "[69, 180] loss: 0.228\n",
      "[69, 240] loss: 0.229\n",
      "[69, 300] loss: 0.230\n",
      "[69, 360] loss: 0.229\n",
      "Epoch: 69 -> Loss: 0.236047700047\n",
      "Epoch: 69 -> Test Accuracy: 83.91\n",
      "[70, 60] loss: 0.207\n",
      "[70, 120] loss: 0.226\n",
      "[70, 180] loss: 0.219\n",
      "[70, 240] loss: 0.232\n",
      "[70, 300] loss: 0.230\n",
      "[70, 360] loss: 0.231\n",
      "Epoch: 70 -> Loss: 0.165102601051\n",
      "Epoch: 70 -> Test Accuracy: 84.38\n",
      "[71, 60] loss: 0.180\n",
      "[71, 120] loss: 0.153\n",
      "[71, 180] loss: 0.145\n",
      "[71, 240] loss: 0.147\n",
      "[71, 300] loss: 0.153\n",
      "[71, 360] loss: 0.160\n",
      "Epoch: 71 -> Loss: 0.132235527039\n",
      "Epoch: 71 -> Test Accuracy: 86.26\n",
      "[72, 60] loss: 0.137\n",
      "[72, 120] loss: 0.139\n",
      "[72, 180] loss: 0.139\n",
      "[72, 240] loss: 0.132\n",
      "[72, 300] loss: 0.140\n",
      "[72, 360] loss: 0.136\n",
      "Epoch: 72 -> Loss: 0.138134047389\n",
      "Epoch: 72 -> Test Accuracy: 86.07\n",
      "[73, 60] loss: 0.129\n",
      "[73, 120] loss: 0.124\n",
      "[73, 180] loss: 0.141\n",
      "[73, 240] loss: 0.132\n",
      "[73, 300] loss: 0.126\n",
      "[73, 360] loss: 0.130\n",
      "Epoch: 73 -> Loss: 0.129165440798\n",
      "Epoch: 73 -> Test Accuracy: 86.01\n",
      "[74, 60] loss: 0.121\n",
      "[74, 120] loss: 0.125\n",
      "[74, 180] loss: 0.129\n",
      "[74, 240] loss: 0.127\n",
      "[74, 300] loss: 0.132\n",
      "[74, 360] loss: 0.132\n",
      "Epoch: 74 -> Loss: 0.145370796323\n",
      "Epoch: 74 -> Test Accuracy: 86.35\n",
      "[75, 60] loss: 0.116\n",
      "[75, 120] loss: 0.118\n",
      "[75, 180] loss: 0.120\n",
      "[75, 240] loss: 0.123\n",
      "[75, 300] loss: 0.130\n",
      "[75, 360] loss: 0.132\n",
      "Epoch: 75 -> Loss: 0.113258287311\n",
      "Epoch: 75 -> Test Accuracy: 86.46\n",
      "[76, 60] loss: 0.115\n",
      "[76, 120] loss: 0.117\n",
      "[76, 180] loss: 0.116\n",
      "[76, 240] loss: 0.126\n",
      "[76, 300] loss: 0.123\n",
      "[76, 360] loss: 0.122\n",
      "Epoch: 76 -> Loss: 0.0896287709475\n",
      "Epoch: 76 -> Test Accuracy: 86.26\n",
      "[77, 60] loss: 0.117\n",
      "[77, 120] loss: 0.117\n",
      "[77, 180] loss: 0.117\n",
      "[77, 240] loss: 0.119\n",
      "[77, 300] loss: 0.115\n",
      "[77, 360] loss: 0.126\n",
      "Epoch: 77 -> Loss: 0.104656539857\n",
      "Epoch: 77 -> Test Accuracy: 86.17\n",
      "[78, 60] loss: 0.113\n",
      "[78, 120] loss: 0.111\n",
      "[78, 180] loss: 0.114\n",
      "[78, 240] loss: 0.120\n",
      "[78, 300] loss: 0.121\n",
      "[78, 360] loss: 0.121\n",
      "Epoch: 78 -> Loss: 0.0998202711344\n",
      "Epoch: 78 -> Test Accuracy: 86.29\n",
      "[79, 60] loss: 0.110\n",
      "[79, 120] loss: 0.113\n",
      "[79, 180] loss: 0.112\n",
      "[79, 240] loss: 0.117\n",
      "[79, 300] loss: 0.113\n",
      "[79, 360] loss: 0.120\n",
      "Epoch: 79 -> Loss: 0.147906422615\n",
      "Epoch: 79 -> Test Accuracy: 86.21\n",
      "[80, 60] loss: 0.111\n",
      "[80, 120] loss: 0.107\n",
      "[80, 180] loss: 0.106\n",
      "[80, 240] loss: 0.106\n",
      "[80, 300] loss: 0.120\n",
      "[80, 360] loss: 0.113\n",
      "Epoch: 80 -> Loss: 0.0911607369781\n",
      "Epoch: 80 -> Test Accuracy: 86.17\n",
      "[81, 60] loss: 0.105\n",
      "[81, 120] loss: 0.105\n",
      "[81, 180] loss: 0.108\n",
      "[81, 240] loss: 0.108\n",
      "[81, 300] loss: 0.119\n",
      "[81, 360] loss: 0.116\n",
      "Epoch: 81 -> Loss: 0.0841901749372\n",
      "Epoch: 81 -> Test Accuracy: 85.95\n",
      "[82, 60] loss: 0.111\n",
      "[82, 120] loss: 0.108\n",
      "[82, 180] loss: 0.109\n",
      "[82, 240] loss: 0.105\n",
      "[82, 300] loss: 0.115\n",
      "[82, 360] loss: 0.110\n",
      "Epoch: 82 -> Loss: 0.110561177135\n",
      "Epoch: 82 -> Test Accuracy: 85.95\n",
      "[83, 60] loss: 0.104\n",
      "[83, 120] loss: 0.106\n",
      "[83, 180] loss: 0.106\n",
      "[83, 240] loss: 0.110\n",
      "[83, 300] loss: 0.112\n",
      "[83, 360] loss: 0.114\n",
      "Epoch: 83 -> Loss: 0.203587800264\n",
      "Epoch: 83 -> Test Accuracy: 85.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.101\n",
      "[84, 120] loss: 0.110\n",
      "[84, 180] loss: 0.105\n",
      "[84, 240] loss: 0.111\n",
      "[84, 300] loss: 0.113\n",
      "[84, 360] loss: 0.106\n",
      "Epoch: 84 -> Loss: 0.126119792461\n",
      "Epoch: 84 -> Test Accuracy: 86.14\n",
      "[85, 60] loss: 0.104\n",
      "[85, 120] loss: 0.100\n",
      "[85, 180] loss: 0.102\n",
      "[85, 240] loss: 0.105\n",
      "[85, 300] loss: 0.108\n",
      "[85, 360] loss: 0.115\n",
      "Epoch: 85 -> Loss: 0.0792875140905\n",
      "Epoch: 85 -> Test Accuracy: 86.21\n",
      "[86, 60] loss: 0.092\n",
      "[86, 120] loss: 0.096\n",
      "[86, 180] loss: 0.094\n",
      "[86, 240] loss: 0.091\n",
      "[86, 300] loss: 0.090\n",
      "[86, 360] loss: 0.098\n",
      "Epoch: 86 -> Loss: 0.0901971310377\n",
      "Epoch: 86 -> Test Accuracy: 86.37\n",
      "[87, 60] loss: 0.089\n",
      "[87, 120] loss: 0.089\n",
      "[87, 180] loss: 0.094\n",
      "[87, 240] loss: 0.089\n",
      "[87, 300] loss: 0.088\n",
      "[87, 360] loss: 0.091\n",
      "Epoch: 87 -> Loss: 0.0650262087584\n",
      "Epoch: 87 -> Test Accuracy: 86.29\n",
      "[88, 60] loss: 0.090\n",
      "[88, 120] loss: 0.084\n",
      "[88, 180] loss: 0.086\n",
      "[88, 240] loss: 0.092\n",
      "[88, 300] loss: 0.089\n",
      "[88, 360] loss: 0.093\n",
      "Epoch: 88 -> Loss: 0.103284418583\n",
      "Epoch: 88 -> Test Accuracy: 86.24\n",
      "[89, 60] loss: 0.085\n",
      "[89, 120] loss: 0.091\n",
      "[89, 180] loss: 0.085\n",
      "[89, 240] loss: 0.095\n",
      "[89, 300] loss: 0.095\n",
      "[89, 360] loss: 0.085\n",
      "Epoch: 89 -> Loss: 0.0971687883139\n",
      "Epoch: 89 -> Test Accuracy: 86.27\n",
      "[90, 60] loss: 0.089\n",
      "[90, 120] loss: 0.091\n",
      "[90, 180] loss: 0.092\n",
      "[90, 240] loss: 0.092\n",
      "[90, 300] loss: 0.088\n",
      "[90, 360] loss: 0.084\n",
      "Epoch: 90 -> Loss: 0.0642368644476\n",
      "Epoch: 90 -> Test Accuracy: 86.45\n",
      "[91, 60] loss: 0.087\n",
      "[91, 120] loss: 0.094\n",
      "[91, 180] loss: 0.091\n",
      "[91, 240] loss: 0.085\n",
      "[91, 300] loss: 0.090\n",
      "[91, 360] loss: 0.088\n",
      "Epoch: 91 -> Loss: 0.0973525494337\n",
      "Epoch: 91 -> Test Accuracy: 86.4\n",
      "[92, 60] loss: 0.083\n",
      "[92, 120] loss: 0.087\n",
      "[92, 180] loss: 0.086\n",
      "[92, 240] loss: 0.089\n",
      "[92, 300] loss: 0.086\n",
      "[92, 360] loss: 0.087\n",
      "Epoch: 92 -> Loss: 0.0609005689621\n",
      "Epoch: 92 -> Test Accuracy: 86.41\n",
      "[93, 60] loss: 0.084\n",
      "[93, 120] loss: 0.087\n",
      "[93, 180] loss: 0.085\n",
      "[93, 240] loss: 0.083\n",
      "[93, 300] loss: 0.089\n",
      "[93, 360] loss: 0.082\n",
      "Epoch: 93 -> Loss: 0.128231778741\n",
      "Epoch: 93 -> Test Accuracy: 86.35\n",
      "[94, 60] loss: 0.086\n",
      "[94, 120] loss: 0.083\n",
      "[94, 180] loss: 0.086\n",
      "[94, 240] loss: 0.085\n",
      "[94, 300] loss: 0.089\n",
      "[94, 360] loss: 0.087\n",
      "Epoch: 94 -> Loss: 0.121010996401\n",
      "Epoch: 94 -> Test Accuracy: 86.39\n",
      "[95, 60] loss: 0.083\n",
      "[95, 120] loss: 0.084\n",
      "[95, 180] loss: 0.084\n",
      "[95, 240] loss: 0.086\n",
      "[95, 300] loss: 0.084\n",
      "[95, 360] loss: 0.088\n",
      "Epoch: 95 -> Loss: 0.054477263242\n",
      "Epoch: 95 -> Test Accuracy: 86.37\n",
      "[96, 60] loss: 0.084\n",
      "[96, 120] loss: 0.085\n",
      "[96, 180] loss: 0.089\n",
      "[96, 240] loss: 0.082\n",
      "[96, 300] loss: 0.085\n",
      "[96, 360] loss: 0.089\n",
      "Epoch: 96 -> Loss: 0.0807441025972\n",
      "Epoch: 96 -> Test Accuracy: 86.19\n",
      "[97, 60] loss: 0.085\n",
      "[97, 120] loss: 0.089\n",
      "[97, 180] loss: 0.083\n",
      "[97, 240] loss: 0.084\n",
      "[97, 300] loss: 0.077\n",
      "[97, 360] loss: 0.090\n",
      "Epoch: 97 -> Loss: 0.0641637966037\n",
      "Epoch: 97 -> Test Accuracy: 86.3\n",
      "[98, 60] loss: 0.086\n",
      "[98, 120] loss: 0.082\n",
      "[98, 180] loss: 0.085\n",
      "[98, 240] loss: 0.089\n",
      "[98, 300] loss: 0.080\n",
      "[98, 360] loss: 0.087\n",
      "Epoch: 98 -> Loss: 0.0831135511398\n",
      "Epoch: 98 -> Test Accuracy: 86.27\n",
      "[99, 60] loss: 0.083\n",
      "[99, 120] loss: 0.089\n",
      "[99, 180] loss: 0.083\n",
      "[99, 240] loss: 0.084\n",
      "[99, 300] loss: 0.083\n",
      "[99, 360] loss: 0.087\n",
      "Epoch: 99 -> Loss: 0.0959678217769\n",
      "Epoch: 99 -> Test Accuracy: 86.17\n",
      "[100, 60] loss: 0.085\n",
      "[100, 120] loss: 0.087\n",
      "[100, 180] loss: 0.085\n",
      "[100, 240] loss: 0.086\n",
      "[100, 300] loss: 0.084\n",
      "[100, 360] loss: 0.085\n",
      "Epoch: 100 -> Loss: 0.0675167292356\n",
      "Epoch: 100 -> Test Accuracy: 86.1\n",
      "Finished Training\n",
      "[1, 60] loss: 0.950\n",
      "[1, 120] loss: 0.655\n",
      "[1, 180] loss: 0.593\n",
      "[1, 240] loss: 0.552\n",
      "[1, 300] loss: 0.531\n",
      "[1, 360] loss: 0.511\n",
      "Epoch: 1 -> Loss: 0.567516088486\n",
      "Epoch: 1 -> Test Accuracy: 79.41\n",
      "[2, 60] loss: 0.469\n",
      "[2, 120] loss: 0.468\n",
      "[2, 180] loss: 0.440\n",
      "[2, 240] loss: 0.448\n",
      "[2, 300] loss: 0.442\n",
      "[2, 360] loss: 0.406\n",
      "Epoch: 2 -> Loss: 0.409767687321\n",
      "Epoch: 2 -> Test Accuracy: 83.19\n",
      "[3, 60] loss: 0.390\n",
      "[3, 120] loss: 0.404\n",
      "[3, 180] loss: 0.381\n",
      "[3, 240] loss: 0.410\n",
      "[3, 300] loss: 0.409\n",
      "[3, 360] loss: 0.394\n",
      "Epoch: 3 -> Loss: 0.489633470774\n",
      "Epoch: 3 -> Test Accuracy: 83.78\n",
      "[4, 60] loss: 0.341\n",
      "[4, 120] loss: 0.355\n",
      "[4, 180] loss: 0.372\n",
      "[4, 240] loss: 0.395\n",
      "[4, 300] loss: 0.368\n",
      "[4, 360] loss: 0.370\n",
      "Epoch: 4 -> Loss: 0.441658437252\n",
      "Epoch: 4 -> Test Accuracy: 84.56\n",
      "[5, 60] loss: 0.343\n",
      "[5, 120] loss: 0.329\n",
      "[5, 180] loss: 0.350\n",
      "[5, 240] loss: 0.365\n",
      "[5, 300] loss: 0.359\n",
      "[5, 360] loss: 0.369\n",
      "Epoch: 5 -> Loss: 0.327306270599\n",
      "Epoch: 5 -> Test Accuracy: 84.23\n",
      "[6, 60] loss: 0.322\n",
      "[6, 120] loss: 0.319\n",
      "[6, 180] loss: 0.326\n",
      "[6, 240] loss: 0.337\n",
      "[6, 300] loss: 0.337\n",
      "[6, 360] loss: 0.360\n",
      "Epoch: 6 -> Loss: 0.334441393614\n",
      "Epoch: 6 -> Test Accuracy: 85.25\n",
      "[7, 60] loss: 0.307\n",
      "[7, 120] loss: 0.327\n",
      "[7, 180] loss: 0.324\n",
      "[7, 240] loss: 0.335\n",
      "[7, 300] loss: 0.335\n",
      "[7, 360] loss: 0.318\n",
      "Epoch: 7 -> Loss: 0.364732682705\n",
      "Epoch: 7 -> Test Accuracy: 85.02\n",
      "[8, 60] loss: 0.288\n",
      "[8, 120] loss: 0.315\n",
      "[8, 180] loss: 0.314\n",
      "[8, 240] loss: 0.324\n",
      "[8, 300] loss: 0.335\n",
      "[8, 360] loss: 0.318\n",
      "Epoch: 8 -> Loss: 0.43247756362\n",
      "Epoch: 8 -> Test Accuracy: 85.06\n",
      "[9, 60] loss: 0.289\n",
      "[9, 120] loss: 0.300\n",
      "[9, 180] loss: 0.315\n",
      "[9, 240] loss: 0.310\n",
      "[9, 300] loss: 0.322\n",
      "[9, 360] loss: 0.322\n",
      "Epoch: 9 -> Loss: 0.399453431368\n",
      "Epoch: 9 -> Test Accuracy: 84.95\n",
      "[10, 60] loss: 0.290\n",
      "[10, 120] loss: 0.290\n",
      "[10, 180] loss: 0.295\n",
      "[10, 240] loss: 0.322\n",
      "[10, 300] loss: 0.318\n",
      "[10, 360] loss: 0.328\n",
      "Epoch: 10 -> Loss: 0.285922348499\n",
      "Epoch: 10 -> Test Accuracy: 85.17\n",
      "[11, 60] loss: 0.285\n",
      "[11, 120] loss: 0.290\n",
      "[11, 180] loss: 0.294\n",
      "[11, 240] loss: 0.291\n",
      "[11, 300] loss: 0.304\n",
      "[11, 360] loss: 0.319\n",
      "Epoch: 11 -> Loss: 0.282105833292\n",
      "Epoch: 11 -> Test Accuracy: 85.8\n",
      "[12, 60] loss: 0.285\n",
      "[12, 120] loss: 0.282\n",
      "[12, 180] loss: 0.283\n",
      "[12, 240] loss: 0.294\n",
      "[12, 300] loss: 0.312\n",
      "[12, 360] loss: 0.317\n",
      "Epoch: 12 -> Loss: 0.376911878586\n",
      "Epoch: 12 -> Test Accuracy: 85.39\n",
      "[13, 60] loss: 0.271\n",
      "[13, 120] loss: 0.273\n",
      "[13, 180] loss: 0.293\n",
      "[13, 240] loss: 0.306\n",
      "[13, 300] loss: 0.296\n",
      "[13, 360] loss: 0.295\n",
      "Epoch: 13 -> Loss: 0.424772441387\n",
      "Epoch: 13 -> Test Accuracy: 85.46\n",
      "[14, 60] loss: 0.258\n",
      "[14, 120] loss: 0.286\n",
      "[14, 180] loss: 0.286\n",
      "[14, 240] loss: 0.293\n",
      "[14, 300] loss: 0.288\n",
      "[14, 360] loss: 0.303\n",
      "Epoch: 14 -> Loss: 0.346930891275\n",
      "Epoch: 14 -> Test Accuracy: 85.47\n",
      "[15, 60] loss: 0.267\n",
      "[15, 120] loss: 0.274\n",
      "[15, 180] loss: 0.281\n",
      "[15, 240] loss: 0.283\n",
      "[15, 300] loss: 0.306\n",
      "[15, 360] loss: 0.300\n",
      "Epoch: 15 -> Loss: 0.238441184163\n",
      "Epoch: 15 -> Test Accuracy: 85.16\n",
      "[16, 60] loss: 0.259\n",
      "[16, 120] loss: 0.271\n",
      "[16, 180] loss: 0.286\n",
      "[16, 240] loss: 0.277\n",
      "[16, 300] loss: 0.294\n",
      "[16, 360] loss: 0.303\n",
      "Epoch: 16 -> Loss: 0.245764061809\n",
      "Epoch: 16 -> Test Accuracy: 85.44\n",
      "[17, 60] loss: 0.267\n",
      "[17, 120] loss: 0.276\n",
      "[17, 180] loss: 0.278\n",
      "[17, 240] loss: 0.281\n",
      "[17, 300] loss: 0.280\n",
      "[17, 360] loss: 0.292\n",
      "Epoch: 17 -> Loss: 0.465405136347\n",
      "Epoch: 17 -> Test Accuracy: 86.18\n",
      "[18, 60] loss: 0.266\n",
      "[18, 120] loss: 0.271\n",
      "[18, 180] loss: 0.279\n",
      "[18, 240] loss: 0.289\n",
      "[18, 300] loss: 0.287\n",
      "[18, 360] loss: 0.287\n",
      "Epoch: 18 -> Loss: 0.288504749537\n",
      "Epoch: 18 -> Test Accuracy: 85.67\n",
      "[19, 60] loss: 0.257\n",
      "[19, 120] loss: 0.273\n",
      "[19, 180] loss: 0.274\n",
      "[19, 240] loss: 0.277\n",
      "[19, 300] loss: 0.282\n",
      "[19, 360] loss: 0.286\n",
      "Epoch: 19 -> Loss: 0.217609927058\n",
      "Epoch: 19 -> Test Accuracy: 85.83\n",
      "[20, 60] loss: 0.250\n",
      "[20, 120] loss: 0.256\n",
      "[20, 180] loss: 0.283\n",
      "[20, 240] loss: 0.290\n",
      "[20, 300] loss: 0.278\n",
      "[20, 360] loss: 0.296\n",
      "Epoch: 20 -> Loss: 0.238851994276\n",
      "Epoch: 20 -> Test Accuracy: 85.06\n",
      "[21, 60] loss: 0.258\n",
      "[21, 120] loss: 0.262\n",
      "[21, 180] loss: 0.260\n",
      "[21, 240] loss: 0.293\n",
      "[21, 300] loss: 0.280\n",
      "[21, 360] loss: 0.294\n",
      "Epoch: 21 -> Loss: 0.265640825033\n",
      "Epoch: 21 -> Test Accuracy: 85.78\n",
      "[22, 60] loss: 0.262\n",
      "[22, 120] loss: 0.258\n",
      "[22, 180] loss: 0.265\n",
      "[22, 240] loss: 0.277\n",
      "[22, 300] loss: 0.266\n",
      "[22, 360] loss: 0.302\n",
      "Epoch: 22 -> Loss: 0.363177239895\n",
      "Epoch: 22 -> Test Accuracy: 85.81\n",
      "[23, 60] loss: 0.252\n",
      "[23, 120] loss: 0.257\n",
      "[23, 180] loss: 0.267\n",
      "[23, 240] loss: 0.291\n",
      "[23, 300] loss: 0.283\n",
      "[23, 360] loss: 0.278\n",
      "Epoch: 23 -> Loss: 0.207975953817\n",
      "Epoch: 23 -> Test Accuracy: 85.31\n",
      "[24, 60] loss: 0.234\n",
      "[24, 120] loss: 0.253\n",
      "[24, 180] loss: 0.261\n",
      "[24, 240] loss: 0.280\n",
      "[24, 300] loss: 0.258\n",
      "[24, 360] loss: 0.294\n",
      "Epoch: 24 -> Loss: 0.312893211842\n",
      "Epoch: 24 -> Test Accuracy: 85.44\n",
      "[25, 60] loss: 0.265\n",
      "[25, 120] loss: 0.258\n",
      "[25, 180] loss: 0.276\n",
      "[25, 240] loss: 0.264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 300] loss: 0.271\n",
      "[25, 360] loss: 0.278\n",
      "Epoch: 25 -> Loss: 0.253926217556\n",
      "Epoch: 25 -> Test Accuracy: 86.13\n",
      "[26, 60] loss: 0.243\n",
      "[26, 120] loss: 0.273\n",
      "[26, 180] loss: 0.258\n",
      "[26, 240] loss: 0.270\n",
      "[26, 300] loss: 0.280\n",
      "[26, 360] loss: 0.285\n",
      "Epoch: 26 -> Loss: 0.362012416124\n",
      "Epoch: 26 -> Test Accuracy: 85.63\n",
      "[27, 60] loss: 0.247\n",
      "[27, 120] loss: 0.243\n",
      "[27, 180] loss: 0.272\n",
      "[27, 240] loss: 0.281\n",
      "[27, 300] loss: 0.277\n",
      "[27, 360] loss: 0.277\n",
      "Epoch: 27 -> Loss: 0.25884154439\n",
      "Epoch: 27 -> Test Accuracy: 85.86\n",
      "[28, 60] loss: 0.231\n",
      "[28, 120] loss: 0.257\n",
      "[28, 180] loss: 0.272\n",
      "[28, 240] loss: 0.285\n",
      "[28, 300] loss: 0.279\n",
      "[28, 360] loss: 0.286\n",
      "Epoch: 28 -> Loss: 0.261535018682\n",
      "Epoch: 28 -> Test Accuracy: 86.02\n",
      "[29, 60] loss: 0.233\n",
      "[29, 120] loss: 0.254\n",
      "[29, 180] loss: 0.273\n",
      "[29, 240] loss: 0.260\n",
      "[29, 300] loss: 0.282\n",
      "[29, 360] loss: 0.261\n",
      "Epoch: 29 -> Loss: 0.310969024897\n",
      "Epoch: 29 -> Test Accuracy: 85.84\n",
      "[30, 60] loss: 0.236\n",
      "[30, 120] loss: 0.267\n",
      "[30, 180] loss: 0.250\n",
      "[30, 240] loss: 0.276\n",
      "[30, 300] loss: 0.292\n",
      "[30, 360] loss: 0.296\n",
      "Epoch: 30 -> Loss: 0.236246064305\n",
      "Epoch: 30 -> Test Accuracy: 85.48\n",
      "[31, 60] loss: 0.239\n",
      "[31, 120] loss: 0.246\n",
      "[31, 180] loss: 0.264\n",
      "[31, 240] loss: 0.278\n",
      "[31, 300] loss: 0.273\n",
      "[31, 360] loss: 0.288\n",
      "Epoch: 31 -> Loss: 0.186521604657\n",
      "Epoch: 31 -> Test Accuracy: 86.0\n",
      "[32, 60] loss: 0.241\n",
      "[32, 120] loss: 0.259\n",
      "[32, 180] loss: 0.255\n",
      "[32, 240] loss: 0.266\n",
      "[32, 300] loss: 0.273\n",
      "[32, 360] loss: 0.292\n",
      "Epoch: 32 -> Loss: 0.372890084982\n",
      "Epoch: 32 -> Test Accuracy: 85.78\n",
      "[33, 60] loss: 0.244\n",
      "[33, 120] loss: 0.246\n",
      "[33, 180] loss: 0.260\n",
      "[33, 240] loss: 0.270\n",
      "[33, 300] loss: 0.283\n",
      "[33, 360] loss: 0.272\n",
      "Epoch: 33 -> Loss: 0.226140469313\n",
      "Epoch: 33 -> Test Accuracy: 85.85\n",
      "[34, 60] loss: 0.239\n",
      "[34, 120] loss: 0.256\n",
      "[34, 180] loss: 0.266\n",
      "[34, 240] loss: 0.266\n",
      "[34, 300] loss: 0.264\n",
      "[34, 360] loss: 0.283\n",
      "Epoch: 34 -> Loss: 0.321974217892\n",
      "Epoch: 34 -> Test Accuracy: 85.33\n",
      "[35, 60] loss: 0.239\n",
      "[35, 120] loss: 0.248\n",
      "[35, 180] loss: 0.254\n",
      "[35, 240] loss: 0.272\n",
      "[35, 300] loss: 0.280\n",
      "[35, 360] loss: 0.278\n",
      "Epoch: 35 -> Loss: 0.313983470201\n",
      "Epoch: 35 -> Test Accuracy: 85.75\n",
      "[36, 60] loss: 0.200\n",
      "[36, 120] loss: 0.195\n",
      "[36, 180] loss: 0.166\n",
      "[36, 240] loss: 0.167\n",
      "[36, 300] loss: 0.169\n",
      "[36, 360] loss: 0.173\n",
      "Epoch: 36 -> Loss: 0.119390532374\n",
      "Epoch: 36 -> Test Accuracy: 88.7\n",
      "[37, 60] loss: 0.140\n",
      "[37, 120] loss: 0.142\n",
      "[37, 180] loss: 0.149\n",
      "[37, 240] loss: 0.150\n",
      "[37, 300] loss: 0.146\n",
      "[37, 360] loss: 0.154\n",
      "Epoch: 37 -> Loss: 0.124185822904\n",
      "Epoch: 37 -> Test Accuracy: 88.89\n",
      "[38, 60] loss: 0.128\n",
      "[38, 120] loss: 0.130\n",
      "[38, 180] loss: 0.128\n",
      "[38, 240] loss: 0.139\n",
      "[38, 300] loss: 0.140\n",
      "[38, 360] loss: 0.140\n",
      "Epoch: 38 -> Loss: 0.104999914765\n",
      "Epoch: 38 -> Test Accuracy: 88.53\n",
      "[39, 60] loss: 0.109\n",
      "[39, 120] loss: 0.123\n",
      "[39, 180] loss: 0.126\n",
      "[39, 240] loss: 0.125\n",
      "[39, 300] loss: 0.120\n",
      "[39, 360] loss: 0.131\n",
      "Epoch: 39 -> Loss: 0.174828022718\n",
      "Epoch: 39 -> Test Accuracy: 88.27\n",
      "[40, 60] loss: 0.112\n",
      "[40, 120] loss: 0.112\n",
      "[40, 180] loss: 0.116\n",
      "[40, 240] loss: 0.118\n",
      "[40, 300] loss: 0.120\n",
      "[40, 360] loss: 0.118\n",
      "Epoch: 40 -> Loss: 0.0902897939086\n",
      "Epoch: 40 -> Test Accuracy: 88.44\n",
      "[41, 60] loss: 0.111\n",
      "[41, 120] loss: 0.103\n",
      "[41, 180] loss: 0.114\n",
      "[41, 240] loss: 0.111\n",
      "[41, 300] loss: 0.117\n",
      "[41, 360] loss: 0.123\n",
      "Epoch: 41 -> Loss: 0.105028510094\n",
      "Epoch: 41 -> Test Accuracy: 88.13\n",
      "[42, 60] loss: 0.097\n",
      "[42, 120] loss: 0.112\n",
      "[42, 180] loss: 0.107\n",
      "[42, 240] loss: 0.113\n",
      "[42, 300] loss: 0.117\n",
      "[42, 360] loss: 0.112\n",
      "Epoch: 42 -> Loss: 0.250066459179\n",
      "Epoch: 42 -> Test Accuracy: 88.27\n",
      "[43, 60] loss: 0.100\n",
      "[43, 120] loss: 0.108\n",
      "[43, 180] loss: 0.110\n",
      "[43, 240] loss: 0.107\n",
      "[43, 300] loss: 0.101\n",
      "[43, 360] loss: 0.116\n",
      "Epoch: 43 -> Loss: 0.0879633575678\n",
      "Epoch: 43 -> Test Accuracy: 88.03\n",
      "[44, 60] loss: 0.101\n",
      "[44, 120] loss: 0.099\n",
      "[44, 180] loss: 0.100\n",
      "[44, 240] loss: 0.107\n",
      "[44, 300] loss: 0.112\n",
      "[44, 360] loss: 0.113\n",
      "Epoch: 44 -> Loss: 0.0969996824861\n",
      "Epoch: 44 -> Test Accuracy: 87.58\n",
      "[45, 60] loss: 0.098\n",
      "[45, 120] loss: 0.097\n",
      "[45, 180] loss: 0.106\n",
      "[45, 240] loss: 0.112\n",
      "[45, 300] loss: 0.111\n",
      "[45, 360] loss: 0.110\n",
      "Epoch: 45 -> Loss: 0.108252003789\n",
      "Epoch: 45 -> Test Accuracy: 87.89\n",
      "[46, 60] loss: 0.103\n",
      "[46, 120] loss: 0.090\n",
      "[46, 180] loss: 0.110\n",
      "[46, 240] loss: 0.106\n",
      "[46, 300] loss: 0.107\n",
      "[46, 360] loss: 0.115\n",
      "Epoch: 46 -> Loss: 0.152457281947\n",
      "Epoch: 46 -> Test Accuracy: 87.99\n",
      "[47, 60] loss: 0.102\n",
      "[47, 120] loss: 0.098\n",
      "[47, 180] loss: 0.112\n",
      "[47, 240] loss: 0.110\n",
      "[47, 300] loss: 0.114\n",
      "[47, 360] loss: 0.114\n",
      "Epoch: 47 -> Loss: 0.0917657464743\n",
      "Epoch: 47 -> Test Accuracy: 87.74\n",
      "[48, 60] loss: 0.101\n",
      "[48, 120] loss: 0.102\n",
      "[48, 180] loss: 0.107\n",
      "[48, 240] loss: 0.114\n",
      "[48, 300] loss: 0.113\n",
      "[48, 360] loss: 0.112\n",
      "Epoch: 48 -> Loss: 0.063636764884\n",
      "Epoch: 48 -> Test Accuracy: 87.6\n",
      "[49, 60] loss: 0.096\n",
      "[49, 120] loss: 0.109\n",
      "[49, 180] loss: 0.104\n",
      "[49, 240] loss: 0.108\n",
      "[49, 300] loss: 0.109\n",
      "[49, 360] loss: 0.122\n",
      "Epoch: 49 -> Loss: 0.11520049721\n",
      "Epoch: 49 -> Test Accuracy: 87.86\n",
      "[50, 60] loss: 0.101\n",
      "[50, 120] loss: 0.105\n",
      "[50, 180] loss: 0.112\n",
      "[50, 240] loss: 0.114\n",
      "[50, 300] loss: 0.114\n",
      "[50, 360] loss: 0.124\n",
      "Epoch: 50 -> Loss: 0.137917950749\n",
      "Epoch: 50 -> Test Accuracy: 87.56\n",
      "[51, 60] loss: 0.097\n",
      "[51, 120] loss: 0.100\n",
      "[51, 180] loss: 0.111\n",
      "[51, 240] loss: 0.104\n",
      "[51, 300] loss: 0.115\n",
      "[51, 360] loss: 0.118\n",
      "Epoch: 51 -> Loss: 0.0573069266975\n",
      "Epoch: 51 -> Test Accuracy: 87.55\n",
      "[52, 60] loss: 0.100\n",
      "[52, 120] loss: 0.111\n",
      "[52, 180] loss: 0.116\n",
      "[52, 240] loss: 0.112\n",
      "[52, 300] loss: 0.120\n",
      "[52, 360] loss: 0.114\n",
      "Epoch: 52 -> Loss: 0.100233674049\n",
      "Epoch: 52 -> Test Accuracy: 87.35\n",
      "[53, 60] loss: 0.109\n",
      "[53, 120] loss: 0.102\n",
      "[53, 180] loss: 0.101\n",
      "[53, 240] loss: 0.119\n",
      "[53, 300] loss: 0.116\n",
      "[53, 360] loss: 0.109\n",
      "Epoch: 53 -> Loss: 0.137732282281\n",
      "Epoch: 53 -> Test Accuracy: 87.47\n",
      "[54, 60] loss: 0.092\n",
      "[54, 120] loss: 0.106\n",
      "[54, 180] loss: 0.100\n",
      "[54, 240] loss: 0.109\n",
      "[54, 300] loss: 0.112\n",
      "[54, 360] loss: 0.114\n",
      "Epoch: 54 -> Loss: 0.0868400335312\n",
      "Epoch: 54 -> Test Accuracy: 87.7\n",
      "[55, 60] loss: 0.107\n",
      "[55, 120] loss: 0.109\n",
      "[55, 180] loss: 0.105\n",
      "[55, 240] loss: 0.111\n",
      "[55, 300] loss: 0.116\n",
      "[55, 360] loss: 0.117\n",
      "Epoch: 55 -> Loss: 0.0781184509397\n",
      "Epoch: 55 -> Test Accuracy: 87.46\n",
      "[56, 60] loss: 0.097\n",
      "[56, 120] loss: 0.098\n",
      "[56, 180] loss: 0.104\n",
      "[56, 240] loss: 0.116\n",
      "[56, 300] loss: 0.117\n",
      "[56, 360] loss: 0.115\n",
      "Epoch: 56 -> Loss: 0.208792686462\n",
      "Epoch: 56 -> Test Accuracy: 87.88\n",
      "[57, 60] loss: 0.104\n",
      "[57, 120] loss: 0.101\n",
      "[57, 180] loss: 0.107\n",
      "[57, 240] loss: 0.110\n",
      "[57, 300] loss: 0.110\n",
      "[57, 360] loss: 0.120\n",
      "Epoch: 57 -> Loss: 0.0640537366271\n",
      "Epoch: 57 -> Test Accuracy: 87.72\n",
      "[58, 60] loss: 0.085\n",
      "[58, 120] loss: 0.100\n",
      "[58, 180] loss: 0.097\n",
      "[58, 240] loss: 0.117\n",
      "[58, 300] loss: 0.107\n",
      "[58, 360] loss: 0.116\n",
      "Epoch: 58 -> Loss: 0.0802043005824\n",
      "Epoch: 58 -> Test Accuracy: 87.64\n",
      "[59, 60] loss: 0.098\n",
      "[59, 120] loss: 0.099\n",
      "[59, 180] loss: 0.115\n",
      "[59, 240] loss: 0.104\n",
      "[59, 300] loss: 0.105\n",
      "[59, 360] loss: 0.117\n",
      "Epoch: 59 -> Loss: 0.136453658342\n",
      "Epoch: 59 -> Test Accuracy: 87.81\n",
      "[60, 60] loss: 0.102\n",
      "[60, 120] loss: 0.105\n",
      "[60, 180] loss: 0.098\n",
      "[60, 240] loss: 0.111\n",
      "[60, 300] loss: 0.117\n",
      "[60, 360] loss: 0.118\n",
      "Epoch: 60 -> Loss: 0.100392960012\n",
      "Epoch: 60 -> Test Accuracy: 87.25\n",
      "[61, 60] loss: 0.087\n",
      "[61, 120] loss: 0.100\n",
      "[61, 180] loss: 0.100\n",
      "[61, 240] loss: 0.111\n",
      "[61, 300] loss: 0.116\n",
      "[61, 360] loss: 0.110\n",
      "Epoch: 61 -> Loss: 0.179309219122\n",
      "Epoch: 61 -> Test Accuracy: 87.39\n",
      "[62, 60] loss: 0.090\n",
      "[62, 120] loss: 0.103\n",
      "[62, 180] loss: 0.114\n",
      "[62, 240] loss: 0.111\n",
      "[62, 300] loss: 0.100\n",
      "[62, 360] loss: 0.119\n",
      "Epoch: 62 -> Loss: 0.0796786695719\n",
      "Epoch: 62 -> Test Accuracy: 87.02\n",
      "[63, 60] loss: 0.098\n",
      "[63, 120] loss: 0.094\n",
      "[63, 180] loss: 0.102\n",
      "[63, 240] loss: 0.105\n",
      "[63, 300] loss: 0.111\n",
      "[63, 360] loss: 0.107\n",
      "Epoch: 63 -> Loss: 0.208764106035\n",
      "Epoch: 63 -> Test Accuracy: 87.53\n",
      "[64, 60] loss: 0.098\n",
      "[64, 120] loss: 0.093\n",
      "[64, 180] loss: 0.102\n",
      "[64, 240] loss: 0.103\n",
      "[64, 300] loss: 0.109\n",
      "[64, 360] loss: 0.128\n",
      "Epoch: 64 -> Loss: 0.116142176092\n",
      "Epoch: 64 -> Test Accuracy: 87.54\n",
      "[65, 60] loss: 0.094\n",
      "[65, 120] loss: 0.096\n",
      "[65, 180] loss: 0.108\n",
      "[65, 240] loss: 0.095\n",
      "[65, 300] loss: 0.107\n",
      "[65, 360] loss: 0.110\n",
      "Epoch: 65 -> Loss: 0.103625573218\n",
      "Epoch: 65 -> Test Accuracy: 87.24\n",
      "[66, 60] loss: 0.100\n",
      "[66, 120] loss: 0.097\n",
      "[66, 180] loss: 0.098\n",
      "[66, 240] loss: 0.115\n",
      "[66, 300] loss: 0.110\n",
      "[66, 360] loss: 0.107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Loss: 0.0833824425936\n",
      "Epoch: 66 -> Test Accuracy: 87.26\n",
      "[67, 60] loss: 0.096\n",
      "[67, 120] loss: 0.102\n",
      "[67, 180] loss: 0.097\n",
      "[67, 240] loss: 0.108\n",
      "[67, 300] loss: 0.107\n",
      "[67, 360] loss: 0.106\n",
      "Epoch: 67 -> Loss: 0.0990978777409\n",
      "Epoch: 67 -> Test Accuracy: 87.58\n",
      "[68, 60] loss: 0.099\n",
      "[68, 120] loss: 0.102\n",
      "[68, 180] loss: 0.100\n",
      "[68, 240] loss: 0.102\n",
      "[68, 300] loss: 0.105\n",
      "[68, 360] loss: 0.112\n",
      "Epoch: 68 -> Loss: 0.17935103178\n",
      "Epoch: 68 -> Test Accuracy: 87.51\n",
      "[69, 60] loss: 0.095\n",
      "[69, 120] loss: 0.102\n",
      "[69, 180] loss: 0.094\n",
      "[69, 240] loss: 0.103\n",
      "[69, 300] loss: 0.107\n",
      "[69, 360] loss: 0.107\n",
      "Epoch: 69 -> Loss: 0.137900769711\n",
      "Epoch: 69 -> Test Accuracy: 87.25\n",
      "[70, 60] loss: 0.102\n",
      "[70, 120] loss: 0.095\n",
      "[70, 180] loss: 0.100\n",
      "[70, 240] loss: 0.102\n",
      "[70, 300] loss: 0.111\n",
      "[70, 360] loss: 0.105\n",
      "Epoch: 70 -> Loss: 0.102032348514\n",
      "Epoch: 70 -> Test Accuracy: 87.47\n",
      "[71, 60] loss: 0.079\n",
      "[71, 120] loss: 0.068\n",
      "[71, 180] loss: 0.063\n",
      "[71, 240] loss: 0.065\n",
      "[71, 300] loss: 0.063\n",
      "[71, 360] loss: 0.057\n",
      "Epoch: 71 -> Loss: 0.081859588623\n",
      "Epoch: 71 -> Test Accuracy: 88.67\n",
      "[72, 60] loss: 0.061\n",
      "[72, 120] loss: 0.051\n",
      "[72, 180] loss: 0.057\n",
      "[72, 240] loss: 0.054\n",
      "[72, 300] loss: 0.052\n",
      "[72, 360] loss: 0.054\n",
      "Epoch: 72 -> Loss: 0.0608087293804\n",
      "Epoch: 72 -> Test Accuracy: 88.64\n",
      "[73, 60] loss: 0.043\n",
      "[73, 120] loss: 0.052\n",
      "[73, 180] loss: 0.045\n",
      "[73, 240] loss: 0.051\n",
      "[73, 300] loss: 0.049\n",
      "[73, 360] loss: 0.049\n",
      "Epoch: 73 -> Loss: 0.0568770170212\n",
      "Epoch: 73 -> Test Accuracy: 88.84\n",
      "[74, 60] loss: 0.045\n",
      "[74, 120] loss: 0.044\n",
      "[74, 180] loss: 0.042\n",
      "[74, 240] loss: 0.046\n",
      "[74, 300] loss: 0.044\n",
      "[74, 360] loss: 0.043\n",
      "Epoch: 74 -> Loss: 0.0394622161984\n",
      "Epoch: 74 -> Test Accuracy: 88.8\n",
      "[75, 60] loss: 0.044\n",
      "[75, 120] loss: 0.046\n",
      "[75, 180] loss: 0.047\n",
      "[75, 240] loss: 0.042\n",
      "[75, 300] loss: 0.043\n",
      "[75, 360] loss: 0.042\n",
      "Epoch: 75 -> Loss: 0.0484886132181\n",
      "Epoch: 75 -> Test Accuracy: 88.83\n",
      "[76, 60] loss: 0.041\n",
      "[76, 120] loss: 0.040\n",
      "[76, 180] loss: 0.043\n",
      "[76, 240] loss: 0.045\n",
      "[76, 300] loss: 0.042\n",
      "[76, 360] loss: 0.040\n",
      "Epoch: 76 -> Loss: 0.0638722628355\n",
      "Epoch: 76 -> Test Accuracy: 88.97\n",
      "[77, 60] loss: 0.040\n",
      "[77, 120] loss: 0.039\n",
      "[77, 180] loss: 0.043\n",
      "[77, 240] loss: 0.040\n",
      "[77, 300] loss: 0.037\n",
      "[77, 360] loss: 0.040\n",
      "Epoch: 77 -> Loss: 0.0669617950916\n",
      "Epoch: 77 -> Test Accuracy: 89.03\n",
      "[78, 60] loss: 0.037\n",
      "[78, 120] loss: 0.037\n",
      "[78, 180] loss: 0.034\n",
      "[78, 240] loss: 0.036\n",
      "[78, 300] loss: 0.033\n",
      "[78, 360] loss: 0.039\n",
      "Epoch: 78 -> Loss: 0.0251414775848\n",
      "Epoch: 78 -> Test Accuracy: 88.9\n",
      "[79, 60] loss: 0.034\n",
      "[79, 120] loss: 0.035\n",
      "[79, 180] loss: 0.035\n",
      "[79, 240] loss: 0.037\n",
      "[79, 300] loss: 0.039\n",
      "[79, 360] loss: 0.039\n",
      "Epoch: 79 -> Loss: 0.0317517668009\n",
      "Epoch: 79 -> Test Accuracy: 88.98\n",
      "[80, 60] loss: 0.032\n",
      "[80, 120] loss: 0.036\n",
      "[80, 180] loss: 0.037\n",
      "[80, 240] loss: 0.035\n",
      "[80, 300] loss: 0.037\n",
      "[80, 360] loss: 0.035\n",
      "Epoch: 80 -> Loss: 0.0272829048336\n",
      "Epoch: 80 -> Test Accuracy: 89.06\n",
      "[81, 60] loss: 0.031\n",
      "[81, 120] loss: 0.039\n",
      "[81, 180] loss: 0.037\n",
      "[81, 240] loss: 0.037\n",
      "[81, 300] loss: 0.031\n",
      "[81, 360] loss: 0.032\n",
      "Epoch: 81 -> Loss: 0.0354957543314\n",
      "Epoch: 81 -> Test Accuracy: 88.99\n",
      "[82, 60] loss: 0.037\n",
      "[82, 120] loss: 0.036\n",
      "[82, 180] loss: 0.033\n",
      "[82, 240] loss: 0.037\n",
      "[82, 300] loss: 0.032\n",
      "[82, 360] loss: 0.032\n",
      "Epoch: 82 -> Loss: 0.0204923991114\n",
      "Epoch: 82 -> Test Accuracy: 88.83\n",
      "[83, 60] loss: 0.031\n",
      "[83, 120] loss: 0.031\n",
      "[83, 180] loss: 0.032\n",
      "[83, 240] loss: 0.034\n",
      "[83, 300] loss: 0.036\n",
      "[83, 360] loss: 0.035\n",
      "Epoch: 83 -> Loss: 0.0334600880742\n",
      "Epoch: 83 -> Test Accuracy: 89.06\n",
      "[84, 60] loss: 0.034\n",
      "[84, 120] loss: 0.032\n",
      "[84, 180] loss: 0.033\n",
      "[84, 240] loss: 0.035\n",
      "[84, 300] loss: 0.032\n",
      "[84, 360] loss: 0.033\n",
      "Epoch: 84 -> Loss: 0.0230171438307\n",
      "Epoch: 84 -> Test Accuracy: 88.87\n",
      "[85, 60] loss: 0.031\n",
      "[85, 120] loss: 0.030\n",
      "[85, 180] loss: 0.029\n",
      "[85, 240] loss: 0.034\n",
      "[85, 300] loss: 0.033\n",
      "[85, 360] loss: 0.031\n",
      "Epoch: 85 -> Loss: 0.0265475027263\n",
      "Epoch: 85 -> Test Accuracy: 88.74\n",
      "[86, 60] loss: 0.030\n",
      "[86, 120] loss: 0.030\n",
      "[86, 180] loss: 0.029\n",
      "[86, 240] loss: 0.028\n",
      "[86, 300] loss: 0.028\n",
      "[86, 360] loss: 0.029\n",
      "Epoch: 86 -> Loss: 0.0267985705286\n",
      "Epoch: 86 -> Test Accuracy: 89.12\n",
      "[87, 60] loss: 0.029\n",
      "[87, 120] loss: 0.026\n",
      "[87, 180] loss: 0.029\n",
      "[87, 240] loss: 0.029\n",
      "[87, 300] loss: 0.029\n",
      "[87, 360] loss: 0.031\n",
      "Epoch: 87 -> Loss: 0.0311568919569\n",
      "Epoch: 87 -> Test Accuracy: 89.19\n",
      "[88, 60] loss: 0.027\n",
      "[88, 120] loss: 0.028\n",
      "[88, 180] loss: 0.028\n",
      "[88, 240] loss: 0.027\n",
      "[88, 300] loss: 0.027\n",
      "[88, 360] loss: 0.027\n",
      "Epoch: 88 -> Loss: 0.0179834477603\n",
      "Epoch: 88 -> Test Accuracy: 89.03\n",
      "[89, 60] loss: 0.028\n",
      "[89, 120] loss: 0.027\n",
      "[89, 180] loss: 0.026\n",
      "[89, 240] loss: 0.027\n",
      "[89, 300] loss: 0.027\n",
      "[89, 360] loss: 0.027\n",
      "Epoch: 89 -> Loss: 0.033421818167\n",
      "Epoch: 89 -> Test Accuracy: 89.16\n",
      "[90, 60] loss: 0.028\n",
      "[90, 120] loss: 0.027\n",
      "[90, 180] loss: 0.029\n",
      "[90, 240] loss: 0.027\n",
      "[90, 300] loss: 0.027\n",
      "[90, 360] loss: 0.028\n",
      "Epoch: 90 -> Loss: 0.0138774756342\n",
      "Epoch: 90 -> Test Accuracy: 89.17\n",
      "[91, 60] loss: 0.028\n",
      "[91, 120] loss: 0.024\n",
      "[91, 180] loss: 0.026\n",
      "[91, 240] loss: 0.027\n",
      "[91, 300] loss: 0.026\n",
      "[91, 360] loss: 0.030\n",
      "Epoch: 91 -> Loss: 0.0365059934556\n",
      "Epoch: 91 -> Test Accuracy: 89.22\n",
      "[92, 60] loss: 0.024\n",
      "[92, 120] loss: 0.025\n",
      "[92, 180] loss: 0.027\n",
      "[92, 240] loss: 0.024\n",
      "[92, 300] loss: 0.027\n",
      "[92, 360] loss: 0.029\n",
      "Epoch: 92 -> Loss: 0.0178997181356\n",
      "Epoch: 92 -> Test Accuracy: 89.2\n",
      "[93, 60] loss: 0.026\n",
      "[93, 120] loss: 0.026\n",
      "[93, 180] loss: 0.026\n",
      "[93, 240] loss: 0.025\n",
      "[93, 300] loss: 0.026\n",
      "[93, 360] loss: 0.025\n",
      "Epoch: 93 -> Loss: 0.034123878926\n",
      "Epoch: 93 -> Test Accuracy: 89.25\n",
      "[94, 60] loss: 0.026\n",
      "[94, 120] loss: 0.027\n",
      "[94, 180] loss: 0.025\n",
      "[94, 240] loss: 0.026\n",
      "[94, 300] loss: 0.028\n",
      "[94, 360] loss: 0.025\n",
      "Epoch: 94 -> Loss: 0.035915710032\n",
      "Epoch: 94 -> Test Accuracy: 89.24\n",
      "[95, 60] loss: 0.025\n",
      "[95, 120] loss: 0.027\n",
      "[95, 180] loss: 0.026\n",
      "[95, 240] loss: 0.027\n",
      "[95, 300] loss: 0.029\n",
      "[95, 360] loss: 0.026\n",
      "Epoch: 95 -> Loss: 0.0520519837737\n",
      "Epoch: 95 -> Test Accuracy: 89.19\n",
      "[96, 60] loss: 0.026\n",
      "[96, 120] loss: 0.025\n",
      "[96, 180] loss: 0.027\n",
      "[96, 240] loss: 0.025\n",
      "[96, 300] loss: 0.027\n",
      "[96, 360] loss: 0.026\n",
      "Epoch: 96 -> Loss: 0.013837153092\n",
      "Epoch: 96 -> Test Accuracy: 89.12\n",
      "[97, 60] loss: 0.025\n",
      "[97, 120] loss: 0.026\n",
      "[97, 180] loss: 0.027\n",
      "[97, 240] loss: 0.026\n",
      "[97, 300] loss: 0.025\n",
      "[97, 360] loss: 0.026\n",
      "Epoch: 97 -> Loss: 0.0172969549894\n",
      "Epoch: 97 -> Test Accuracy: 89.06\n",
      "[98, 60] loss: 0.025\n",
      "[98, 120] loss: 0.025\n",
      "[98, 180] loss: 0.024\n",
      "[98, 240] loss: 0.024\n",
      "[98, 300] loss: 0.026\n",
      "[98, 360] loss: 0.026\n",
      "Epoch: 98 -> Loss: 0.0431081987917\n",
      "Epoch: 98 -> Test Accuracy: 89.19\n",
      "[99, 60] loss: 0.026\n",
      "[99, 120] loss: 0.027\n",
      "[99, 180] loss: 0.024\n",
      "[99, 240] loss: 0.026\n",
      "[99, 300] loss: 0.026\n",
      "[99, 360] loss: 0.025\n",
      "Epoch: 99 -> Loss: 0.00700654368848\n",
      "Epoch: 99 -> Test Accuracy: 89.16\n",
      "[100, 60] loss: 0.025\n",
      "[100, 120] loss: 0.025\n",
      "[100, 180] loss: 0.024\n",
      "[100, 240] loss: 0.026\n",
      "[100, 300] loss: 0.026\n",
      "[100, 360] loss: 0.024\n",
      "Epoch: 100 -> Loss: 0.05342117697\n",
      "Epoch: 100 -> Test Accuracy: 89.14\n",
      "Finished Training\n",
      "[1, 60] loss: 0.938\n",
      "[1, 120] loss: 0.663\n",
      "[1, 180] loss: 0.629\n",
      "[1, 240] loss: 0.614\n",
      "[1, 300] loss: 0.595\n",
      "[1, 360] loss: 0.597\n",
      "Epoch: 1 -> Loss: 0.540397107601\n",
      "Epoch: 1 -> Test Accuracy: 77.56\n",
      "[2, 60] loss: 0.541\n",
      "[2, 120] loss: 0.538\n",
      "[2, 180] loss: 0.528\n",
      "[2, 240] loss: 0.536\n",
      "[2, 300] loss: 0.522\n",
      "[2, 360] loss: 0.521\n",
      "Epoch: 2 -> Loss: 0.522862792015\n",
      "Epoch: 2 -> Test Accuracy: 79.65\n",
      "[3, 60] loss: 0.480\n",
      "[3, 120] loss: 0.498\n",
      "[3, 180] loss: 0.506\n",
      "[3, 240] loss: 0.493\n",
      "[3, 300] loss: 0.487\n",
      "[3, 360] loss: 0.511\n",
      "Epoch: 3 -> Loss: 0.641894459724\n",
      "Epoch: 3 -> Test Accuracy: 79.74\n",
      "[4, 60] loss: 0.459\n",
      "[4, 120] loss: 0.481\n",
      "[4, 180] loss: 0.482\n",
      "[4, 240] loss: 0.465\n",
      "[4, 300] loss: 0.474\n",
      "[4, 360] loss: 0.483\n",
      "Epoch: 4 -> Loss: 0.420867681503\n",
      "Epoch: 4 -> Test Accuracy: 80.98\n",
      "[5, 60] loss: 0.455\n",
      "[5, 120] loss: 0.465\n",
      "[5, 180] loss: 0.458\n",
      "[5, 240] loss: 0.438\n",
      "[5, 300] loss: 0.465\n",
      "[5, 360] loss: 0.459\n",
      "Epoch: 5 -> Loss: 0.341810643673\n",
      "Epoch: 5 -> Test Accuracy: 80.22\n",
      "[6, 60] loss: 0.442\n",
      "[6, 120] loss: 0.442\n",
      "[6, 180] loss: 0.457\n",
      "[6, 240] loss: 0.465\n",
      "[6, 300] loss: 0.456\n",
      "[6, 360] loss: 0.445\n",
      "Epoch: 6 -> Loss: 0.340888381004\n",
      "Epoch: 6 -> Test Accuracy: 80.67\n",
      "[7, 60] loss: 0.436\n",
      "[7, 120] loss: 0.424\n",
      "[7, 180] loss: 0.443\n",
      "[7, 240] loss: 0.452\n",
      "[7, 300] loss: 0.444\n",
      "[7, 360] loss: 0.447\n",
      "Epoch: 7 -> Loss: 0.346537530422\n",
      "Epoch: 7 -> Test Accuracy: 81.26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 60] loss: 0.432\n",
      "[8, 120] loss: 0.440\n",
      "[8, 180] loss: 0.449\n",
      "[8, 240] loss: 0.447\n",
      "[8, 300] loss: 0.442\n",
      "[8, 360] loss: 0.425\n",
      "Epoch: 8 -> Loss: 0.520217359066\n",
      "Epoch: 8 -> Test Accuracy: 81.56\n",
      "[9, 60] loss: 0.412\n",
      "[9, 120] loss: 0.429\n",
      "[9, 180] loss: 0.408\n",
      "[9, 240] loss: 0.452\n",
      "[9, 300] loss: 0.428\n",
      "[9, 360] loss: 0.450\n",
      "Epoch: 9 -> Loss: 0.654241621494\n",
      "Epoch: 9 -> Test Accuracy: 80.21\n",
      "[10, 60] loss: 0.421\n",
      "[10, 120] loss: 0.435\n",
      "[10, 180] loss: 0.429\n",
      "[10, 240] loss: 0.413\n",
      "[10, 300] loss: 0.441\n",
      "[10, 360] loss: 0.436\n",
      "Epoch: 10 -> Loss: 0.34097841382\n",
      "Epoch: 10 -> Test Accuracy: 81.17\n",
      "[11, 60] loss: 0.415\n",
      "[11, 120] loss: 0.422\n",
      "[11, 180] loss: 0.421\n",
      "[11, 240] loss: 0.446\n",
      "[11, 300] loss: 0.422\n",
      "[11, 360] loss: 0.435\n",
      "Epoch: 11 -> Loss: 0.333814054728\n",
      "Epoch: 11 -> Test Accuracy: 82.17\n",
      "[12, 60] loss: 0.391\n",
      "[12, 120] loss: 0.415\n",
      "[12, 180] loss: 0.423\n",
      "[12, 240] loss: 0.427\n",
      "[12, 300] loss: 0.439\n",
      "[12, 360] loss: 0.432\n",
      "Epoch: 12 -> Loss: 0.419221788645\n",
      "Epoch: 12 -> Test Accuracy: 81.98\n",
      "[13, 60] loss: 0.403\n",
      "[13, 120] loss: 0.422\n",
      "[13, 180] loss: 0.403\n",
      "[13, 240] loss: 0.426\n",
      "[13, 300] loss: 0.433\n",
      "[13, 360] loss: 0.425\n",
      "Epoch: 13 -> Loss: 0.44030380249\n",
      "Epoch: 13 -> Test Accuracy: 81.29\n",
      "[14, 60] loss: 0.405\n",
      "[14, 120] loss: 0.410\n",
      "[14, 180] loss: 0.414\n",
      "[14, 240] loss: 0.437\n",
      "[14, 300] loss: 0.413\n",
      "[14, 360] loss: 0.423\n",
      "Epoch: 14 -> Loss: 0.352022230625\n",
      "Epoch: 14 -> Test Accuracy: 82.08\n",
      "[15, 60] loss: 0.392\n",
      "[15, 120] loss: 0.408\n",
      "[15, 180] loss: 0.425\n",
      "[15, 240] loss: 0.412\n",
      "[15, 300] loss: 0.436\n",
      "[15, 360] loss: 0.420\n",
      "Epoch: 15 -> Loss: 0.488187134266\n",
      "Epoch: 15 -> Test Accuracy: 81.8\n",
      "[16, 60] loss: 0.405\n",
      "[16, 120] loss: 0.392\n",
      "[16, 180] loss: 0.411\n",
      "[16, 240] loss: 0.419\n",
      "[16, 300] loss: 0.421\n",
      "[16, 360] loss: 0.415\n",
      "Epoch: 16 -> Loss: 0.362064629793\n",
      "Epoch: 16 -> Test Accuracy: 81.36\n",
      "[17, 60] loss: 0.392\n",
      "[17, 120] loss: 0.415\n",
      "[17, 180] loss: 0.403\n",
      "[17, 240] loss: 0.425\n",
      "[17, 300] loss: 0.413\n",
      "[17, 360] loss: 0.408\n",
      "Epoch: 17 -> Loss: 0.360011428595\n",
      "Epoch: 17 -> Test Accuracy: 82.12\n",
      "[18, 60] loss: 0.417\n",
      "[18, 120] loss: 0.400\n",
      "[18, 180] loss: 0.396\n",
      "[18, 240] loss: 0.402\n",
      "[18, 300] loss: 0.404\n",
      "[18, 360] loss: 0.405\n",
      "Epoch: 18 -> Loss: 0.369029462337\n",
      "Epoch: 18 -> Test Accuracy: 81.57\n",
      "[19, 60] loss: 0.398\n",
      "[19, 120] loss: 0.406\n",
      "[19, 180] loss: 0.408\n",
      "[19, 240] loss: 0.409\n",
      "[19, 300] loss: 0.429\n",
      "[19, 360] loss: 0.391\n",
      "Epoch: 19 -> Loss: 0.337388724089\n",
      "Epoch: 19 -> Test Accuracy: 81.26\n",
      "[20, 60] loss: 0.409\n",
      "[20, 120] loss: 0.407\n",
      "[20, 180] loss: 0.393\n",
      "[20, 240] loss: 0.412\n",
      "[20, 300] loss: 0.393\n",
      "[20, 360] loss: 0.417\n",
      "Epoch: 20 -> Loss: 0.389843225479\n",
      "Epoch: 20 -> Test Accuracy: 82.21\n",
      "[21, 60] loss: 0.383\n",
      "[21, 120] loss: 0.412\n",
      "[21, 180] loss: 0.410\n",
      "[21, 240] loss: 0.402\n",
      "[21, 300] loss: 0.398\n",
      "[21, 360] loss: 0.420\n",
      "Epoch: 21 -> Loss: 0.367174565792\n",
      "Epoch: 21 -> Test Accuracy: 82.26\n",
      "[22, 60] loss: 0.394\n",
      "[22, 120] loss: 0.406\n",
      "[22, 180] loss: 0.389\n",
      "[22, 240] loss: 0.394\n",
      "[22, 300] loss: 0.424\n",
      "[22, 360] loss: 0.420\n",
      "Epoch: 22 -> Loss: 0.28956207633\n",
      "Epoch: 22 -> Test Accuracy: 81.32\n",
      "[23, 60] loss: 0.377\n",
      "[23, 120] loss: 0.392\n",
      "[23, 180] loss: 0.409\n",
      "[23, 240] loss: 0.397\n",
      "[23, 300] loss: 0.409\n",
      "[23, 360] loss: 0.406\n",
      "Epoch: 23 -> Loss: 0.469201147556\n",
      "Epoch: 23 -> Test Accuracy: 82.0\n",
      "[24, 60] loss: 0.388\n",
      "[24, 120] loss: 0.372\n",
      "[24, 180] loss: 0.387\n",
      "[24, 240] loss: 0.410\n",
      "[24, 300] loss: 0.409\n",
      "[24, 360] loss: 0.419\n",
      "Epoch: 24 -> Loss: 0.463021278381\n",
      "Epoch: 24 -> Test Accuracy: 81.55\n",
      "[25, 60] loss: 0.382\n",
      "[25, 120] loss: 0.398\n",
      "[25, 180] loss: 0.396\n",
      "[25, 240] loss: 0.399\n",
      "[25, 300] loss: 0.413\n",
      "[25, 360] loss: 0.392\n",
      "Epoch: 25 -> Loss: 0.569637000561\n",
      "Epoch: 25 -> Test Accuracy: 82.03\n",
      "[26, 60] loss: 0.391\n",
      "[26, 120] loss: 0.405\n",
      "[26, 180] loss: 0.399\n",
      "[26, 240] loss: 0.397\n",
      "[26, 300] loss: 0.406\n",
      "[26, 360] loss: 0.409\n",
      "Epoch: 26 -> Loss: 0.525465130806\n",
      "Epoch: 26 -> Test Accuracy: 81.38\n",
      "[27, 60] loss: 0.370\n",
      "[27, 120] loss: 0.403\n",
      "[27, 180] loss: 0.397\n",
      "[27, 240] loss: 0.407\n",
      "[27, 300] loss: 0.401\n",
      "[27, 360] loss: 0.409\n",
      "Epoch: 27 -> Loss: 0.671908795834\n",
      "Epoch: 27 -> Test Accuracy: 82.04\n",
      "[28, 60] loss: 0.388\n",
      "[28, 120] loss: 0.406\n",
      "[28, 180] loss: 0.379\n",
      "[28, 240] loss: 0.393\n",
      "[28, 300] loss: 0.386\n",
      "[28, 360] loss: 0.411\n",
      "Epoch: 28 -> Loss: 0.361414551735\n",
      "Epoch: 28 -> Test Accuracy: 81.69\n",
      "[29, 60] loss: 0.382\n",
      "[29, 120] loss: 0.391\n",
      "[29, 180] loss: 0.403\n",
      "[29, 240] loss: 0.407\n",
      "[29, 300] loss: 0.401\n",
      "[29, 360] loss: 0.414\n",
      "Epoch: 29 -> Loss: 0.571306109428\n",
      "Epoch: 29 -> Test Accuracy: 82.01\n",
      "[30, 60] loss: 0.370\n",
      "[30, 120] loss: 0.393\n",
      "[30, 180] loss: 0.393\n",
      "[30, 240] loss: 0.403\n",
      "[30, 300] loss: 0.394\n",
      "[30, 360] loss: 0.412\n",
      "Epoch: 30 -> Loss: 0.616995990276\n",
      "Epoch: 30 -> Test Accuracy: 82.36\n",
      "[31, 60] loss: 0.370\n",
      "[31, 120] loss: 0.371\n",
      "[31, 180] loss: 0.386\n",
      "[31, 240] loss: 0.416\n",
      "[31, 300] loss: 0.421\n",
      "[31, 360] loss: 0.418\n",
      "Epoch: 31 -> Loss: 0.507322967052\n",
      "Epoch: 31 -> Test Accuracy: 82.38\n",
      "[32, 60] loss: 0.374\n",
      "[32, 120] loss: 0.400\n",
      "[32, 180] loss: 0.385\n",
      "[32, 240] loss: 0.384\n",
      "[32, 300] loss: 0.397\n",
      "[32, 360] loss: 0.414\n",
      "Epoch: 32 -> Loss: 0.497317880392\n",
      "Epoch: 32 -> Test Accuracy: 81.87\n",
      "[33, 60] loss: 0.366\n",
      "[33, 120] loss: 0.396\n",
      "[33, 180] loss: 0.385\n",
      "[33, 240] loss: 0.392\n",
      "[33, 300] loss: 0.390\n",
      "[33, 360] loss: 0.423\n",
      "Epoch: 33 -> Loss: 0.519937217236\n",
      "Epoch: 33 -> Test Accuracy: 81.39\n",
      "[34, 60] loss: 0.379\n",
      "[34, 120] loss: 0.393\n",
      "[34, 180] loss: 0.386\n",
      "[34, 240] loss: 0.400\n",
      "[34, 300] loss: 0.377\n",
      "[34, 360] loss: 0.412\n",
      "Epoch: 34 -> Loss: 0.449781030416\n",
      "Epoch: 34 -> Test Accuracy: 81.78\n",
      "[35, 60] loss: 0.370\n",
      "[35, 120] loss: 0.397\n",
      "[35, 180] loss: 0.394\n",
      "[35, 240] loss: 0.386\n",
      "[35, 300] loss: 0.400\n",
      "[35, 360] loss: 0.414\n",
      "Epoch: 35 -> Loss: 0.420093536377\n",
      "Epoch: 35 -> Test Accuracy: 82.77\n",
      "[36, 60] loss: 0.345\n",
      "[36, 120] loss: 0.330\n",
      "[36, 180] loss: 0.314\n",
      "[36, 240] loss: 0.311\n",
      "[36, 300] loss: 0.310\n",
      "[36, 360] loss: 0.309\n",
      "Epoch: 36 -> Loss: 0.436482340097\n",
      "Epoch: 36 -> Test Accuracy: 84.4\n",
      "[37, 60] loss: 0.290\n",
      "[37, 120] loss: 0.280\n",
      "[37, 180] loss: 0.299\n",
      "[37, 240] loss: 0.306\n",
      "[37, 300] loss: 0.283\n",
      "[37, 360] loss: 0.297\n",
      "Epoch: 37 -> Loss: 0.282569587231\n",
      "Epoch: 37 -> Test Accuracy: 84.28\n",
      "[38, 60] loss: 0.268\n",
      "[38, 120] loss: 0.278\n",
      "[38, 180] loss: 0.281\n",
      "[38, 240] loss: 0.282\n",
      "[38, 300] loss: 0.279\n",
      "[38, 360] loss: 0.276\n",
      "Epoch: 38 -> Loss: 0.325150221586\n",
      "Epoch: 38 -> Test Accuracy: 84.34\n",
      "[39, 60] loss: 0.259\n",
      "[39, 120] loss: 0.277\n",
      "[39, 180] loss: 0.283\n",
      "[39, 240] loss: 0.276\n",
      "[39, 300] loss: 0.266\n",
      "[39, 360] loss: 0.275\n",
      "Epoch: 39 -> Loss: 0.251514673233\n",
      "Epoch: 39 -> Test Accuracy: 84.39\n",
      "[40, 60] loss: 0.263\n",
      "[40, 120] loss: 0.251\n",
      "[40, 180] loss: 0.260\n",
      "[40, 240] loss: 0.276\n",
      "[40, 300] loss: 0.277\n",
      "[40, 360] loss: 0.268\n",
      "Epoch: 40 -> Loss: 0.17071852088\n",
      "Epoch: 40 -> Test Accuracy: 84.27\n",
      "[41, 60] loss: 0.254\n",
      "[41, 120] loss: 0.266\n",
      "[41, 180] loss: 0.262\n",
      "[41, 240] loss: 0.261\n",
      "[41, 300] loss: 0.265\n",
      "[41, 360] loss: 0.285\n",
      "Epoch: 41 -> Loss: 0.217326566577\n",
      "Epoch: 41 -> Test Accuracy: 84.16\n",
      "[42, 60] loss: 0.259\n",
      "[42, 120] loss: 0.263\n",
      "[42, 180] loss: 0.263\n",
      "[42, 240] loss: 0.255\n",
      "[42, 300] loss: 0.263\n",
      "[42, 360] loss: 0.267\n",
      "Epoch: 42 -> Loss: 0.199593856931\n",
      "Epoch: 42 -> Test Accuracy: 84.22\n",
      "[43, 60] loss: 0.252\n",
      "[43, 120] loss: 0.240\n",
      "[43, 180] loss: 0.253\n",
      "[43, 240] loss: 0.263\n",
      "[43, 300] loss: 0.258\n",
      "[43, 360] loss: 0.271\n",
      "Epoch: 43 -> Loss: 0.263486474752\n",
      "Epoch: 43 -> Test Accuracy: 83.91\n",
      "[44, 60] loss: 0.251\n",
      "[44, 120] loss: 0.249\n",
      "[44, 180] loss: 0.257\n",
      "[44, 240] loss: 0.253\n",
      "[44, 300] loss: 0.257\n",
      "[44, 360] loss: 0.266\n",
      "Epoch: 44 -> Loss: 0.226734489202\n",
      "Epoch: 44 -> Test Accuracy: 83.55\n",
      "[45, 60] loss: 0.240\n",
      "[45, 120] loss: 0.253\n",
      "[45, 180] loss: 0.257\n",
      "[45, 240] loss: 0.256\n",
      "[45, 300] loss: 0.259\n",
      "[45, 360] loss: 0.261\n",
      "Epoch: 45 -> Loss: 0.204331129789\n",
      "Epoch: 45 -> Test Accuracy: 83.77\n",
      "[46, 60] loss: 0.255\n",
      "[46, 120] loss: 0.239\n",
      "[46, 180] loss: 0.260\n",
      "[46, 240] loss: 0.268\n",
      "[46, 300] loss: 0.252\n",
      "[46, 360] loss: 0.273\n",
      "Epoch: 46 -> Loss: 0.184537768364\n",
      "Epoch: 46 -> Test Accuracy: 83.79\n",
      "[47, 60] loss: 0.244\n",
      "[47, 120] loss: 0.247\n",
      "[47, 180] loss: 0.256\n",
      "[47, 240] loss: 0.249\n",
      "[47, 300] loss: 0.259\n",
      "[47, 360] loss: 0.269\n",
      "Epoch: 47 -> Loss: 0.275578320026\n",
      "Epoch: 47 -> Test Accuracy: 83.89\n",
      "[48, 60] loss: 0.235\n",
      "[48, 120] loss: 0.251\n",
      "[48, 180] loss: 0.257\n",
      "[48, 240] loss: 0.248\n",
      "[48, 300] loss: 0.267\n",
      "[48, 360] loss: 0.265\n",
      "Epoch: 48 -> Loss: 0.193764194846\n",
      "Epoch: 48 -> Test Accuracy: 83.78\n",
      "[49, 60] loss: 0.239\n",
      "[49, 120] loss: 0.237\n",
      "[49, 180] loss: 0.253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 240] loss: 0.249\n",
      "[49, 300] loss: 0.267\n",
      "[49, 360] loss: 0.263\n",
      "Epoch: 49 -> Loss: 0.224213927984\n",
      "Epoch: 49 -> Test Accuracy: 83.74\n",
      "[50, 60] loss: 0.249\n",
      "[50, 120] loss: 0.237\n",
      "[50, 180] loss: 0.250\n",
      "[50, 240] loss: 0.248\n",
      "[50, 300] loss: 0.258\n",
      "[50, 360] loss: 0.254\n",
      "Epoch: 50 -> Loss: 0.286949723959\n",
      "Epoch: 50 -> Test Accuracy: 83.84\n",
      "[51, 60] loss: 0.248\n",
      "[51, 120] loss: 0.265\n",
      "[51, 180] loss: 0.243\n",
      "[51, 240] loss: 0.257\n",
      "[51, 300] loss: 0.260\n",
      "[51, 360] loss: 0.247\n",
      "Epoch: 51 -> Loss: 0.333163619041\n",
      "Epoch: 51 -> Test Accuracy: 83.75\n",
      "[52, 60] loss: 0.241\n",
      "[52, 120] loss: 0.252\n",
      "[52, 180] loss: 0.245\n",
      "[52, 240] loss: 0.257\n",
      "[52, 300] loss: 0.263\n",
      "[52, 360] loss: 0.248\n",
      "Epoch: 52 -> Loss: 0.318033605814\n",
      "Epoch: 52 -> Test Accuracy: 83.86\n",
      "[53, 60] loss: 0.227\n",
      "[53, 120] loss: 0.243\n",
      "[53, 180] loss: 0.255\n",
      "[53, 240] loss: 0.269\n",
      "[53, 300] loss: 0.261\n",
      "[53, 360] loss: 0.244\n",
      "Epoch: 53 -> Loss: 0.30602222681\n",
      "Epoch: 53 -> Test Accuracy: 83.56\n",
      "[54, 60] loss: 0.243\n",
      "[54, 120] loss: 0.237\n",
      "[54, 180] loss: 0.247\n",
      "[54, 240] loss: 0.252\n",
      "[54, 300] loss: 0.241\n",
      "[54, 360] loss: 0.260\n",
      "Epoch: 54 -> Loss: 0.236187174916\n",
      "Epoch: 54 -> Test Accuracy: 84.01\n",
      "[55, 60] loss: 0.228\n",
      "[55, 120] loss: 0.251\n",
      "[55, 180] loss: 0.244\n",
      "[55, 240] loss: 0.262\n",
      "[55, 300] loss: 0.252\n",
      "[55, 360] loss: 0.253\n",
      "Epoch: 55 -> Loss: 0.26162275672\n",
      "Epoch: 55 -> Test Accuracy: 83.89\n",
      "[56, 60] loss: 0.242\n",
      "[56, 120] loss: 0.238\n",
      "[56, 180] loss: 0.240\n",
      "[56, 240] loss: 0.270\n",
      "[56, 300] loss: 0.251\n",
      "[56, 360] loss: 0.256\n",
      "Epoch: 56 -> Loss: 0.304760992527\n",
      "Epoch: 56 -> Test Accuracy: 83.92\n",
      "[57, 60] loss: 0.255\n",
      "[57, 120] loss: 0.230\n",
      "[57, 180] loss: 0.234\n",
      "[57, 240] loss: 0.240\n",
      "[57, 300] loss: 0.264\n",
      "[57, 360] loss: 0.263\n",
      "Epoch: 57 -> Loss: 0.224745944142\n",
      "Epoch: 57 -> Test Accuracy: 83.62\n",
      "[58, 60] loss: 0.229\n",
      "[58, 120] loss: 0.238\n",
      "[58, 180] loss: 0.255\n",
      "[58, 240] loss: 0.251\n",
      "[58, 300] loss: 0.259\n",
      "[58, 360] loss: 0.252\n",
      "Epoch: 58 -> Loss: 0.114863157272\n",
      "Epoch: 58 -> Test Accuracy: 83.82\n",
      "[59, 60] loss: 0.224\n",
      "[59, 120] loss: 0.238\n",
      "[59, 180] loss: 0.243\n",
      "[59, 240] loss: 0.238\n",
      "[59, 300] loss: 0.254\n",
      "[59, 360] loss: 0.258\n",
      "Epoch: 59 -> Loss: 0.470723092556\n",
      "Epoch: 59 -> Test Accuracy: 83.32\n",
      "[60, 60] loss: 0.237\n",
      "[60, 120] loss: 0.222\n",
      "[60, 180] loss: 0.233\n",
      "[60, 240] loss: 0.250\n",
      "[60, 300] loss: 0.250\n",
      "[60, 360] loss: 0.255\n",
      "Epoch: 60 -> Loss: 0.208072856069\n",
      "Epoch: 60 -> Test Accuracy: 83.32\n",
      "[61, 60] loss: 0.229\n",
      "[61, 120] loss: 0.236\n",
      "[61, 180] loss: 0.244\n",
      "[61, 240] loss: 0.248\n",
      "[61, 300] loss: 0.244\n",
      "[61, 360] loss: 0.254\n",
      "Epoch: 61 -> Loss: 0.317508876324\n",
      "Epoch: 61 -> Test Accuracy: 83.61\n",
      "[62, 60] loss: 0.225\n",
      "[62, 120] loss: 0.241\n",
      "[62, 180] loss: 0.238\n",
      "[62, 240] loss: 0.242\n",
      "[62, 300] loss: 0.251\n",
      "[62, 360] loss: 0.243\n",
      "Epoch: 62 -> Loss: 0.239314004779\n",
      "Epoch: 62 -> Test Accuracy: 83.68\n",
      "[63, 60] loss: 0.238\n",
      "[63, 120] loss: 0.241\n",
      "[63, 180] loss: 0.237\n",
      "[63, 240] loss: 0.242\n",
      "[63, 300] loss: 0.255\n",
      "[63, 360] loss: 0.251\n",
      "Epoch: 63 -> Loss: 0.290678143501\n",
      "Epoch: 63 -> Test Accuracy: 83.2\n",
      "[64, 60] loss: 0.235\n",
      "[64, 120] loss: 0.232\n",
      "[64, 180] loss: 0.241\n",
      "[64, 240] loss: 0.254\n",
      "[64, 300] loss: 0.235\n",
      "[64, 360] loss: 0.249\n",
      "Epoch: 64 -> Loss: 0.339368104935\n",
      "Epoch: 64 -> Test Accuracy: 83.66\n",
      "[65, 60] loss: 0.227\n",
      "[65, 120] loss: 0.231\n",
      "[65, 180] loss: 0.240\n",
      "[65, 240] loss: 0.253\n",
      "[65, 300] loss: 0.239\n",
      "[65, 360] loss: 0.255\n",
      "Epoch: 65 -> Loss: 0.216001033783\n",
      "Epoch: 65 -> Test Accuracy: 83.66\n",
      "[66, 60] loss: 0.231\n",
      "[66, 120] loss: 0.227\n",
      "[66, 180] loss: 0.238\n",
      "[66, 240] loss: 0.240\n",
      "[66, 300] loss: 0.248\n",
      "[66, 360] loss: 0.236\n",
      "Epoch: 66 -> Loss: 0.155488461256\n",
      "Epoch: 66 -> Test Accuracy: 84.18\n",
      "[67, 60] loss: 0.229\n",
      "[67, 120] loss: 0.234\n",
      "[67, 180] loss: 0.234\n",
      "[67, 240] loss: 0.243\n",
      "[67, 300] loss: 0.255\n",
      "[67, 360] loss: 0.250\n",
      "Epoch: 67 -> Loss: 0.250218331814\n",
      "Epoch: 67 -> Test Accuracy: 84.13\n",
      "[68, 60] loss: 0.216\n",
      "[68, 120] loss: 0.236\n",
      "[68, 180] loss: 0.249\n",
      "[68, 240] loss: 0.247\n",
      "[68, 300] loss: 0.249\n",
      "[68, 360] loss: 0.238\n",
      "Epoch: 68 -> Loss: 0.28282302618\n",
      "Epoch: 68 -> Test Accuracy: 84.1\n",
      "[69, 60] loss: 0.230\n",
      "[69, 120] loss: 0.232\n",
      "[69, 180] loss: 0.242\n",
      "[69, 240] loss: 0.241\n",
      "[69, 300] loss: 0.243\n",
      "[69, 360] loss: 0.241\n",
      "Epoch: 69 -> Loss: 0.357885807753\n",
      "Epoch: 69 -> Test Accuracy: 83.44\n",
      "[70, 60] loss: 0.220\n",
      "[70, 120] loss: 0.233\n",
      "[70, 180] loss: 0.232\n",
      "[70, 240] loss: 0.239\n",
      "[70, 300] loss: 0.233\n",
      "[70, 360] loss: 0.261\n",
      "Epoch: 70 -> Loss: 0.23502202332\n",
      "Epoch: 70 -> Test Accuracy: 83.95\n",
      "[71, 60] loss: 0.204\n",
      "[71, 120] loss: 0.188\n",
      "[71, 180] loss: 0.188\n",
      "[71, 240] loss: 0.191\n",
      "[71, 300] loss: 0.183\n",
      "[71, 360] loss: 0.176\n",
      "Epoch: 71 -> Loss: 0.273092657328\n",
      "Epoch: 71 -> Test Accuracy: 85.09\n",
      "[72, 60] loss: 0.170\n",
      "[72, 120] loss: 0.168\n",
      "[72, 180] loss: 0.170\n",
      "[72, 240] loss: 0.174\n",
      "[72, 300] loss: 0.166\n",
      "[72, 360] loss: 0.165\n",
      "Epoch: 72 -> Loss: 0.165698498487\n",
      "Epoch: 72 -> Test Accuracy: 84.89\n",
      "[73, 60] loss: 0.160\n",
      "[73, 120] loss: 0.158\n",
      "[73, 180] loss: 0.170\n",
      "[73, 240] loss: 0.157\n",
      "[73, 300] loss: 0.161\n",
      "[73, 360] loss: 0.167\n",
      "Epoch: 73 -> Loss: 0.208750247955\n",
      "Epoch: 73 -> Test Accuracy: 85.27\n",
      "[74, 60] loss: 0.152\n",
      "[74, 120] loss: 0.156\n",
      "[74, 180] loss: 0.152\n",
      "[74, 240] loss: 0.165\n",
      "[74, 300] loss: 0.155\n",
      "[74, 360] loss: 0.171\n",
      "Epoch: 74 -> Loss: 0.232667163014\n",
      "Epoch: 74 -> Test Accuracy: 85.1\n",
      "[75, 60] loss: 0.159\n",
      "[75, 120] loss: 0.154\n",
      "[75, 180] loss: 0.159\n",
      "[75, 240] loss: 0.155\n",
      "[75, 300] loss: 0.160\n",
      "[75, 360] loss: 0.148\n",
      "Epoch: 75 -> Loss: 0.12503747642\n",
      "Epoch: 75 -> Test Accuracy: 85.31\n",
      "[76, 60] loss: 0.143\n",
      "[76, 120] loss: 0.141\n",
      "[76, 180] loss: 0.151\n",
      "[76, 240] loss: 0.147\n",
      "[76, 300] loss: 0.157\n",
      "[76, 360] loss: 0.151\n",
      "Epoch: 76 -> Loss: 0.229293018579\n",
      "Epoch: 76 -> Test Accuracy: 84.8\n",
      "[77, 60] loss: 0.149\n",
      "[77, 120] loss: 0.146\n",
      "[77, 180] loss: 0.149\n",
      "[77, 240] loss: 0.149\n",
      "[77, 300] loss: 0.144\n",
      "[77, 360] loss: 0.144\n",
      "Epoch: 77 -> Loss: 0.254591852427\n",
      "Epoch: 77 -> Test Accuracy: 85.11\n",
      "[78, 60] loss: 0.137\n",
      "[78, 120] loss: 0.151\n",
      "[78, 180] loss: 0.145\n",
      "[78, 240] loss: 0.140\n",
      "[78, 300] loss: 0.156\n",
      "[78, 360] loss: 0.155\n",
      "Epoch: 78 -> Loss: 0.197630897164\n",
      "Epoch: 78 -> Test Accuracy: 85.04\n",
      "[79, 60] loss: 0.132\n",
      "[79, 120] loss: 0.133\n",
      "[79, 180] loss: 0.151\n",
      "[79, 240] loss: 0.140\n",
      "[79, 300] loss: 0.152\n",
      "[79, 360] loss: 0.142\n",
      "Epoch: 79 -> Loss: 0.153967887163\n",
      "Epoch: 79 -> Test Accuracy: 85.0\n",
      "[80, 60] loss: 0.140\n",
      "[80, 120] loss: 0.144\n",
      "[80, 180] loss: 0.138\n",
      "[80, 240] loss: 0.136\n",
      "[80, 300] loss: 0.142\n",
      "[80, 360] loss: 0.139\n",
      "Epoch: 80 -> Loss: 0.116911053658\n",
      "Epoch: 80 -> Test Accuracy: 84.85\n",
      "[81, 60] loss: 0.138\n",
      "[81, 120] loss: 0.132\n",
      "[81, 180] loss: 0.137\n",
      "[81, 240] loss: 0.141\n",
      "[81, 300] loss: 0.137\n",
      "[81, 360] loss: 0.142\n",
      "Epoch: 81 -> Loss: 0.139522731304\n",
      "Epoch: 81 -> Test Accuracy: 84.94\n",
      "[82, 60] loss: 0.134\n",
      "[82, 120] loss: 0.130\n",
      "[82, 180] loss: 0.134\n",
      "[82, 240] loss: 0.137\n",
      "[82, 300] loss: 0.136\n",
      "[82, 360] loss: 0.147\n",
      "Epoch: 82 -> Loss: 0.0979183465242\n",
      "Epoch: 82 -> Test Accuracy: 84.77\n",
      "[83, 60] loss: 0.128\n",
      "[83, 120] loss: 0.132\n",
      "[83, 180] loss: 0.141\n",
      "[83, 240] loss: 0.142\n",
      "[83, 300] loss: 0.142\n",
      "[83, 360] loss: 0.142\n",
      "Epoch: 83 -> Loss: 0.0660660713911\n",
      "Epoch: 83 -> Test Accuracy: 84.94\n",
      "[84, 60] loss: 0.129\n",
      "[84, 120] loss: 0.132\n",
      "[84, 180] loss: 0.132\n",
      "[84, 240] loss: 0.132\n",
      "[84, 300] loss: 0.139\n",
      "[84, 360] loss: 0.130\n",
      "Epoch: 84 -> Loss: 0.151253610849\n",
      "Epoch: 84 -> Test Accuracy: 84.73\n",
      "[85, 60] loss: 0.135\n",
      "[85, 120] loss: 0.130\n",
      "[85, 180] loss: 0.141\n",
      "[85, 240] loss: 0.138\n",
      "[85, 300] loss: 0.129\n",
      "[85, 360] loss: 0.142\n",
      "Epoch: 85 -> Loss: 0.19433991611\n",
      "Epoch: 85 -> Test Accuracy: 84.86\n",
      "[86, 60] loss: 0.124\n",
      "[86, 120] loss: 0.121\n",
      "[86, 180] loss: 0.115\n",
      "[86, 240] loss: 0.126\n",
      "[86, 300] loss: 0.120\n",
      "[86, 360] loss: 0.120\n",
      "Epoch: 86 -> Loss: 0.109788499773\n",
      "Epoch: 86 -> Test Accuracy: 85.25\n",
      "[87, 60] loss: 0.112\n",
      "[87, 120] loss: 0.115\n",
      "[87, 180] loss: 0.121\n",
      "[87, 240] loss: 0.114\n",
      "[87, 300] loss: 0.118\n",
      "[87, 360] loss: 0.115\n",
      "Epoch: 87 -> Loss: 0.132476687431\n",
      "Epoch: 87 -> Test Accuracy: 85.14\n",
      "[88, 60] loss: 0.117\n",
      "[88, 120] loss: 0.115\n",
      "[88, 180] loss: 0.112\n",
      "[88, 240] loss: 0.110\n",
      "[88, 300] loss: 0.126\n",
      "[88, 360] loss: 0.115\n",
      "Epoch: 88 -> Loss: 0.0455316528678\n",
      "Epoch: 88 -> Test Accuracy: 85.18\n",
      "[89, 60] loss: 0.115\n",
      "[89, 120] loss: 0.120\n",
      "[89, 180] loss: 0.112\n",
      "[89, 240] loss: 0.115\n",
      "[89, 300] loss: 0.116\n",
      "[89, 360] loss: 0.114\n",
      "Epoch: 89 -> Loss: 0.15179681778\n",
      "Epoch: 89 -> Test Accuracy: 85.16\n",
      "[90, 60] loss: 0.112\n",
      "[90, 120] loss: 0.118\n",
      "[90, 180] loss: 0.117\n",
      "[90, 240] loss: 0.116\n",
      "[90, 300] loss: 0.117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90, 360] loss: 0.111\n",
      "Epoch: 90 -> Loss: 0.120844319463\n",
      "Epoch: 90 -> Test Accuracy: 85.26\n",
      "[91, 60] loss: 0.113\n",
      "[91, 120] loss: 0.112\n",
      "[91, 180] loss: 0.106\n",
      "[91, 240] loss: 0.112\n",
      "[91, 300] loss: 0.107\n",
      "[91, 360] loss: 0.114\n",
      "Epoch: 91 -> Loss: 0.0734865218401\n",
      "Epoch: 91 -> Test Accuracy: 85.34\n",
      "[92, 60] loss: 0.115\n",
      "[92, 120] loss: 0.114\n",
      "[92, 180] loss: 0.109\n",
      "[92, 240] loss: 0.113\n",
      "[92, 300] loss: 0.112\n",
      "[92, 360] loss: 0.107\n",
      "Epoch: 92 -> Loss: 0.0891503840685\n",
      "Epoch: 92 -> Test Accuracy: 85.31\n",
      "[93, 60] loss: 0.112\n",
      "[93, 120] loss: 0.115\n",
      "[93, 180] loss: 0.108\n",
      "[93, 240] loss: 0.113\n",
      "[93, 300] loss: 0.115\n",
      "[93, 360] loss: 0.106\n",
      "Epoch: 93 -> Loss: 0.0858323052526\n",
      "Epoch: 93 -> Test Accuracy: 85.25\n",
      "[94, 60] loss: 0.111\n",
      "[94, 120] loss: 0.110\n",
      "[94, 180] loss: 0.112\n",
      "[94, 240] loss: 0.109\n",
      "[94, 300] loss: 0.115\n",
      "[94, 360] loss: 0.111\n",
      "Epoch: 94 -> Loss: 0.158666104078\n",
      "Epoch: 94 -> Test Accuracy: 85.36\n",
      "[95, 60] loss: 0.104\n",
      "[95, 120] loss: 0.112\n",
      "[95, 180] loss: 0.107\n",
      "[95, 240] loss: 0.111\n",
      "[95, 300] loss: 0.108\n",
      "[95, 360] loss: 0.105\n",
      "Epoch: 95 -> Loss: 0.120916500688\n",
      "Epoch: 95 -> Test Accuracy: 85.09\n",
      "[96, 60] loss: 0.111\n",
      "[96, 120] loss: 0.113\n",
      "[96, 180] loss: 0.108\n",
      "[96, 240] loss: 0.112\n",
      "[96, 300] loss: 0.106\n",
      "[96, 360] loss: 0.107\n",
      "Epoch: 96 -> Loss: 0.153427556157\n",
      "Epoch: 96 -> Test Accuracy: 85.11\n",
      "[97, 60] loss: 0.109\n",
      "[97, 120] loss: 0.101\n",
      "[97, 180] loss: 0.107\n",
      "[97, 240] loss: 0.113\n",
      "[97, 300] loss: 0.110\n",
      "[97, 360] loss: 0.106\n",
      "Epoch: 97 -> Loss: 0.151247650385\n",
      "Epoch: 97 -> Test Accuracy: 85.08\n",
      "[98, 60] loss: 0.107\n",
      "[98, 120] loss: 0.108\n",
      "[98, 180] loss: 0.106\n",
      "[98, 240] loss: 0.101\n",
      "[98, 300] loss: 0.106\n",
      "[98, 360] loss: 0.115\n",
      "Epoch: 98 -> Loss: 0.122911930084\n",
      "Epoch: 98 -> Test Accuracy: 85.05\n",
      "[99, 60] loss: 0.108\n",
      "[99, 120] loss: 0.111\n",
      "[99, 180] loss: 0.106\n",
      "[99, 240] loss: 0.106\n",
      "[99, 300] loss: 0.107\n",
      "[99, 360] loss: 0.106\n",
      "Epoch: 99 -> Loss: 0.174003705382\n",
      "Epoch: 99 -> Test Accuracy: 85.2\n",
      "[100, 60] loss: 0.101\n",
      "[100, 120] loss: 0.104\n",
      "[100, 180] loss: 0.105\n",
      "[100, 240] loss: 0.106\n",
      "[100, 300] loss: 0.113\n",
      "[100, 360] loss: 0.117\n",
      "Epoch: 100 -> Loss: 0.13631670177\n",
      "Epoch: 100 -> Test Accuracy: 85.21\n",
      "Finished Training\n",
      "[1, 60] loss: 1.514\n",
      "[1, 120] loss: 1.223\n",
      "[1, 180] loss: 1.177\n",
      "[1, 240] loss: 1.131\n",
      "[1, 300] loss: 1.118\n",
      "[1, 360] loss: 1.054\n",
      "Epoch: 1 -> Loss: 1.19874501228\n",
      "Epoch: 1 -> Test Accuracy: 56.39\n",
      "[2, 60] loss: 1.030\n",
      "[2, 120] loss: 1.015\n",
      "[2, 180] loss: 1.018\n",
      "[2, 240] loss: 1.013\n",
      "[2, 300] loss: 1.010\n",
      "[2, 360] loss: 1.025\n",
      "Epoch: 2 -> Loss: 1.18249583244\n",
      "Epoch: 2 -> Test Accuracy: 58.83\n",
      "[3, 60] loss: 0.975\n",
      "[3, 120] loss: 0.978\n",
      "[3, 180] loss: 0.984\n",
      "[3, 240] loss: 0.973\n",
      "[3, 300] loss: 0.953\n",
      "[3, 360] loss: 0.959\n",
      "Epoch: 3 -> Loss: 0.995969116688\n",
      "Epoch: 3 -> Test Accuracy: 60.51\n",
      "[4, 60] loss: 0.952\n",
      "[4, 120] loss: 0.948\n",
      "[4, 180] loss: 0.924\n",
      "[4, 240] loss: 0.931\n",
      "[4, 300] loss: 0.949\n",
      "[4, 360] loss: 0.925\n",
      "Epoch: 4 -> Loss: 1.04860854149\n",
      "Epoch: 4 -> Test Accuracy: 60.94\n",
      "[5, 60] loss: 0.907\n",
      "[5, 120] loss: 0.930\n",
      "[5, 180] loss: 0.951\n",
      "[5, 240] loss: 0.915\n",
      "[5, 300] loss: 0.929\n",
      "[5, 360] loss: 0.915\n",
      "Epoch: 5 -> Loss: 0.845114052296\n",
      "Epoch: 5 -> Test Accuracy: 62.8\n",
      "[6, 60] loss: 0.914\n",
      "[6, 120] loss: 0.911\n",
      "[6, 180] loss: 0.916\n",
      "[6, 240] loss: 0.916\n",
      "[6, 300] loss: 0.921\n",
      "[6, 360] loss: 0.912\n",
      "Epoch: 6 -> Loss: 1.08579850197\n",
      "Epoch: 6 -> Test Accuracy: 62.36\n",
      "[7, 60] loss: 0.894\n",
      "[7, 120] loss: 0.905\n",
      "[7, 180] loss: 0.886\n",
      "[7, 240] loss: 0.900\n",
      "[7, 300] loss: 0.920\n",
      "[7, 360] loss: 0.896\n",
      "Epoch: 7 -> Loss: 0.765360236168\n",
      "Epoch: 7 -> Test Accuracy: 62.02\n",
      "[8, 60] loss: 0.900\n",
      "[8, 120] loss: 0.885\n",
      "[8, 180] loss: 0.890\n",
      "[8, 240] loss: 0.891\n",
      "[8, 300] loss: 0.893\n",
      "[8, 360] loss: 0.899\n",
      "Epoch: 8 -> Loss: 0.827205479145\n",
      "Epoch: 8 -> Test Accuracy: 63.65\n",
      "[9, 60] loss: 0.885\n",
      "[9, 120] loss: 0.870\n",
      "[9, 180] loss: 0.910\n",
      "[9, 240] loss: 0.898\n",
      "[9, 300] loss: 0.893\n",
      "[9, 360] loss: 0.886\n",
      "Epoch: 9 -> Loss: 0.740445256233\n",
      "Epoch: 9 -> Test Accuracy: 63.61\n",
      "[10, 60] loss: 0.895\n",
      "[10, 120] loss: 0.872\n",
      "[10, 180] loss: 0.895\n",
      "[10, 240] loss: 0.871\n",
      "[10, 300] loss: 0.872\n",
      "[10, 360] loss: 0.890\n",
      "Epoch: 10 -> Loss: 0.983616173267\n",
      "Epoch: 10 -> Test Accuracy: 62.35\n",
      "[11, 60] loss: 0.879\n",
      "[11, 120] loss: 0.870\n",
      "[11, 180] loss: 0.874\n",
      "[11, 240] loss: 0.873\n",
      "[11, 300] loss: 0.898\n",
      "[11, 360] loss: 0.882\n",
      "Epoch: 11 -> Loss: 0.943687736988\n",
      "Epoch: 11 -> Test Accuracy: 63.66\n",
      "[12, 60] loss: 0.878\n",
      "[12, 120] loss: 0.867\n",
      "[12, 180] loss: 0.887\n",
      "[12, 240] loss: 0.881\n",
      "[12, 300] loss: 0.890\n",
      "[12, 360] loss: 0.871\n",
      "Epoch: 12 -> Loss: 0.968141257763\n",
      "Epoch: 12 -> Test Accuracy: 64.05\n",
      "[13, 60] loss: 0.889\n",
      "[13, 120] loss: 0.860\n",
      "[13, 180] loss: 0.865\n",
      "[13, 240] loss: 0.884\n",
      "[13, 300] loss: 0.870\n",
      "[13, 360] loss: 0.859\n",
      "Epoch: 13 -> Loss: 0.897042274475\n",
      "Epoch: 13 -> Test Accuracy: 63.41\n",
      "[14, 60] loss: 0.859\n",
      "[14, 120] loss: 0.891\n",
      "[14, 180] loss: 0.852\n",
      "[14, 240] loss: 0.868\n",
      "[14, 300] loss: 0.881\n",
      "[14, 360] loss: 0.899\n",
      "Epoch: 14 -> Loss: 0.905533313751\n",
      "Epoch: 14 -> Test Accuracy: 63.32\n",
      "[15, 60] loss: 0.859\n",
      "[15, 120] loss: 0.868\n",
      "[15, 180] loss: 0.873\n",
      "[15, 240] loss: 0.875\n",
      "[15, 300] loss: 0.870\n",
      "[15, 360] loss: 0.884\n",
      "Epoch: 15 -> Loss: 0.909096240997\n",
      "Epoch: 15 -> Test Accuracy: 64.43\n",
      "[16, 60] loss: 0.857\n",
      "[16, 120] loss: 0.862\n",
      "[16, 180] loss: 0.863\n",
      "[16, 240] loss: 0.853\n",
      "[16, 300] loss: 0.862\n",
      "[16, 360] loss: 0.884\n",
      "Epoch: 16 -> Loss: 0.84402179718\n",
      "Epoch: 16 -> Test Accuracy: 64.37\n",
      "[17, 60] loss: 0.868\n",
      "[17, 120] loss: 0.873\n",
      "[17, 180] loss: 0.862\n",
      "[17, 240] loss: 0.866\n",
      "[17, 300] loss: 0.871\n",
      "[17, 360] loss: 0.864\n",
      "Epoch: 17 -> Loss: 0.966375052929\n",
      "Epoch: 17 -> Test Accuracy: 63.56\n",
      "[18, 60] loss: 0.870\n",
      "[18, 120] loss: 0.857\n",
      "[18, 180] loss: 0.858\n",
      "[18, 240] loss: 0.848\n",
      "[18, 300] loss: 0.866\n",
      "[18, 360] loss: 0.882\n",
      "Epoch: 18 -> Loss: 0.809091866016\n",
      "Epoch: 18 -> Test Accuracy: 63.57\n",
      "[19, 60] loss: 0.849\n",
      "[19, 120] loss: 0.858\n",
      "[19, 180] loss: 0.860\n",
      "[19, 240] loss: 0.860\n",
      "[19, 300] loss: 0.876\n",
      "[19, 360] loss: 0.859\n",
      "Epoch: 19 -> Loss: 0.859456181526\n",
      "Epoch: 19 -> Test Accuracy: 64.37\n",
      "[20, 60] loss: 0.835\n",
      "[20, 120] loss: 0.865\n",
      "[20, 180] loss: 0.863\n",
      "[20, 240] loss: 0.865\n",
      "[20, 300] loss: 0.851\n",
      "[20, 360] loss: 0.882\n",
      "Epoch: 20 -> Loss: 0.828038811684\n",
      "Epoch: 20 -> Test Accuracy: 64.19\n",
      "[21, 60] loss: 0.862\n",
      "[21, 120] loss: 0.864\n",
      "[21, 180] loss: 0.857\n",
      "[21, 240] loss: 0.866\n",
      "[21, 300] loss: 0.864\n",
      "[21, 360] loss: 0.844\n",
      "Epoch: 21 -> Loss: 0.853355050087\n",
      "Epoch: 21 -> Test Accuracy: 63.55\n",
      "[22, 60] loss: 0.862\n",
      "[22, 120] loss: 0.857\n",
      "[22, 180] loss: 0.832\n",
      "[22, 240] loss: 0.846\n",
      "[22, 300] loss: 0.850\n",
      "[22, 360] loss: 0.866\n",
      "Epoch: 22 -> Loss: 0.995328068733\n",
      "Epoch: 22 -> Test Accuracy: 64.25\n",
      "[23, 60] loss: 0.865\n",
      "[23, 120] loss: 0.841\n",
      "[23, 180] loss: 0.879\n",
      "[23, 240] loss: 0.855\n",
      "[23, 300] loss: 0.866\n",
      "[23, 360] loss: 0.860\n",
      "Epoch: 23 -> Loss: 0.895800709724\n",
      "Epoch: 23 -> Test Accuracy: 63.52\n",
      "[24, 60] loss: 0.864\n",
      "[24, 120] loss: 0.865\n",
      "[24, 180] loss: 0.854\n",
      "[24, 240] loss: 0.847\n",
      "[24, 300] loss: 0.882\n",
      "[24, 360] loss: 0.848\n",
      "Epoch: 24 -> Loss: 0.787972867489\n",
      "Epoch: 24 -> Test Accuracy: 62.24\n",
      "[25, 60] loss: 0.859\n",
      "[25, 120] loss: 0.861\n",
      "[25, 180] loss: 0.861\n",
      "[25, 240] loss: 0.866\n",
      "[25, 300] loss: 0.847\n",
      "[25, 360] loss: 0.851\n",
      "Epoch: 25 -> Loss: 0.907649517059\n",
      "Epoch: 25 -> Test Accuracy: 63.55\n",
      "[26, 60] loss: 0.833\n",
      "[26, 120] loss: 0.855\n",
      "[26, 180] loss: 0.871\n",
      "[26, 240] loss: 0.864\n",
      "[26, 300] loss: 0.865\n",
      "[26, 360] loss: 0.856\n",
      "Epoch: 26 -> Loss: 1.03827214241\n",
      "Epoch: 26 -> Test Accuracy: 64.48\n",
      "[27, 60] loss: 0.854\n",
      "[27, 120] loss: 0.871\n",
      "[27, 180] loss: 0.875\n",
      "[27, 240] loss: 0.867\n",
      "[27, 300] loss: 0.858\n",
      "[27, 360] loss: 0.839\n",
      "Epoch: 27 -> Loss: 0.860753715038\n",
      "Epoch: 27 -> Test Accuracy: 64.56\n",
      "[28, 60] loss: 0.841\n",
      "[28, 120] loss: 0.847\n",
      "[28, 180] loss: 0.859\n",
      "[28, 240] loss: 0.854\n",
      "[28, 300] loss: 0.847\n",
      "[28, 360] loss: 0.856\n",
      "Epoch: 28 -> Loss: 0.745554387569\n",
      "Epoch: 28 -> Test Accuracy: 64.37\n",
      "[29, 60] loss: 0.858\n",
      "[29, 120] loss: 0.855\n",
      "[29, 180] loss: 0.843\n",
      "[29, 240] loss: 0.857\n",
      "[29, 300] loss: 0.858\n",
      "[29, 360] loss: 0.851\n",
      "Epoch: 29 -> Loss: 0.785870432854\n",
      "Epoch: 29 -> Test Accuracy: 64.49\n",
      "[30, 60] loss: 0.842\n",
      "[30, 120] loss: 0.843\n",
      "[30, 180] loss: 0.861\n",
      "[30, 240] loss: 0.867\n",
      "[30, 300] loss: 0.845\n",
      "[30, 360] loss: 0.856\n",
      "Epoch: 30 -> Loss: 1.12057709694\n",
      "Epoch: 30 -> Test Accuracy: 64.87\n",
      "[31, 60] loss: 0.851\n",
      "[31, 120] loss: 0.864\n",
      "[31, 180] loss: 0.840\n",
      "[31, 240] loss: 0.860\n",
      "[31, 300] loss: 0.842\n",
      "[31, 360] loss: 0.855\n",
      "Epoch: 31 -> Loss: 0.791887998581\n",
      "Epoch: 31 -> Test Accuracy: 64.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 60] loss: 0.841\n",
      "[32, 120] loss: 0.849\n",
      "[32, 180] loss: 0.830\n",
      "[32, 240] loss: 0.830\n",
      "[32, 300] loss: 0.886\n",
      "[32, 360] loss: 0.869\n",
      "Epoch: 32 -> Loss: 0.739733934402\n",
      "Epoch: 32 -> Test Accuracy: 64.49\n",
      "[33, 60] loss: 0.846\n",
      "[33, 120] loss: 0.847\n",
      "[33, 180] loss: 0.843\n",
      "[33, 240] loss: 0.838\n",
      "[33, 300] loss: 0.843\n",
      "[33, 360] loss: 0.860\n",
      "Epoch: 33 -> Loss: 0.858152866364\n",
      "Epoch: 33 -> Test Accuracy: 63.92\n",
      "[34, 60] loss: 0.850\n",
      "[34, 120] loss: 0.841\n",
      "[34, 180] loss: 0.861\n",
      "[34, 240] loss: 0.849\n",
      "[34, 300] loss: 0.825\n",
      "[34, 360] loss: 0.859\n",
      "Epoch: 34 -> Loss: 0.870750308037\n",
      "Epoch: 34 -> Test Accuracy: 63.09\n",
      "[35, 60] loss: 0.832\n",
      "[35, 120] loss: 0.855\n",
      "[35, 180] loss: 0.866\n",
      "[35, 240] loss: 0.853\n",
      "[35, 300] loss: 0.852\n",
      "[35, 360] loss: 0.848\n",
      "Epoch: 35 -> Loss: 0.974261879921\n",
      "Epoch: 35 -> Test Accuracy: 63.38\n",
      "[36, 60] loss: 0.786\n",
      "[36, 120] loss: 0.754\n",
      "[36, 180] loss: 0.748\n",
      "[36, 240] loss: 0.760\n",
      "[36, 300] loss: 0.754\n",
      "[36, 360] loss: 0.730\n",
      "Epoch: 36 -> Loss: 0.744085490704\n",
      "Epoch: 36 -> Test Accuracy: 68.16\n",
      "[37, 60] loss: 0.716\n",
      "[37, 120] loss: 0.735\n",
      "[37, 180] loss: 0.729\n",
      "[37, 240] loss: 0.728\n",
      "[37, 300] loss: 0.732\n",
      "[37, 360] loss: 0.746\n",
      "Epoch: 37 -> Loss: 0.726249337196\n",
      "Epoch: 37 -> Test Accuracy: 67.92\n",
      "[38, 60] loss: 0.705\n",
      "[38, 120] loss: 0.706\n",
      "[38, 180] loss: 0.729\n",
      "[38, 240] loss: 0.757\n",
      "[38, 300] loss: 0.723\n",
      "[38, 360] loss: 0.705\n",
      "Epoch: 38 -> Loss: 0.754968702793\n",
      "Epoch: 38 -> Test Accuracy: 68.38\n",
      "[39, 60] loss: 0.726\n",
      "[39, 120] loss: 0.726\n",
      "[39, 180] loss: 0.708\n",
      "[39, 240] loss: 0.715\n",
      "[39, 300] loss: 0.722\n",
      "[39, 360] loss: 0.733\n",
      "Epoch: 39 -> Loss: 0.67219722271\n",
      "Epoch: 39 -> Test Accuracy: 67.89\n",
      "[40, 60] loss: 0.704\n",
      "[40, 120] loss: 0.706\n",
      "[40, 180] loss: 0.721\n",
      "[40, 240] loss: 0.713\n",
      "[40, 300] loss: 0.734\n",
      "[40, 360] loss: 0.714\n",
      "Epoch: 40 -> Loss: 0.777990162373\n",
      "Epoch: 40 -> Test Accuracy: 68.39\n",
      "[41, 60] loss: 0.703\n",
      "[41, 120] loss: 0.731\n",
      "[41, 180] loss: 0.730\n",
      "[41, 240] loss: 0.708\n",
      "[41, 300] loss: 0.718\n",
      "[41, 360] loss: 0.726\n",
      "Epoch: 41 -> Loss: 0.605883717537\n",
      "Epoch: 41 -> Test Accuracy: 68.96\n",
      "[42, 60] loss: 0.685\n",
      "[42, 120] loss: 0.722\n",
      "[42, 180] loss: 0.710\n",
      "[42, 240] loss: 0.727\n",
      "[42, 300] loss: 0.725\n",
      "[42, 360] loss: 0.726\n",
      "Epoch: 42 -> Loss: 0.827102839947\n",
      "Epoch: 42 -> Test Accuracy: 69.21\n",
      "[43, 60] loss: 0.691\n",
      "[43, 120] loss: 0.701\n",
      "[43, 180] loss: 0.721\n",
      "[43, 240] loss: 0.723\n",
      "[43, 300] loss: 0.730\n",
      "[43, 360] loss: 0.706\n",
      "Epoch: 43 -> Loss: 0.687110245228\n",
      "Epoch: 43 -> Test Accuracy: 67.89\n",
      "[44, 60] loss: 0.714\n",
      "[44, 120] loss: 0.724\n",
      "[44, 180] loss: 0.727\n",
      "[44, 240] loss: 0.704\n",
      "[44, 300] loss: 0.716\n",
      "[44, 360] loss: 0.707\n",
      "Epoch: 44 -> Loss: 0.63187277317\n",
      "Epoch: 44 -> Test Accuracy: 68.23\n",
      "[45, 60] loss: 0.700\n",
      "[45, 120] loss: 0.704\n",
      "[45, 180] loss: 0.716\n",
      "[45, 240] loss: 0.713\n",
      "[45, 300] loss: 0.710\n",
      "[45, 360] loss: 0.725\n",
      "Epoch: 45 -> Loss: 0.577881336212\n",
      "Epoch: 45 -> Test Accuracy: 68.52\n",
      "[46, 60] loss: 0.715\n",
      "[46, 120] loss: 0.698\n",
      "[46, 180] loss: 0.720\n",
      "[46, 240] loss: 0.727\n",
      "[46, 300] loss: 0.720\n",
      "[46, 360] loss: 0.709\n",
      "Epoch: 46 -> Loss: 0.953669726849\n",
      "Epoch: 46 -> Test Accuracy: 68.98\n",
      "[47, 60] loss: 0.713\n",
      "[47, 120] loss: 0.705\n",
      "[47, 180] loss: 0.721\n",
      "[47, 240] loss: 0.718\n",
      "[47, 300] loss: 0.690\n",
      "[47, 360] loss: 0.733\n",
      "Epoch: 47 -> Loss: 0.49425560236\n",
      "Epoch: 47 -> Test Accuracy: 68.56\n",
      "[48, 60] loss: 0.734\n",
      "[48, 120] loss: 0.716\n",
      "[48, 180] loss: 0.705\n",
      "[48, 240] loss: 0.714\n",
      "[48, 300] loss: 0.715\n",
      "[48, 360] loss: 0.712\n",
      "Epoch: 48 -> Loss: 0.803096592426\n",
      "Epoch: 48 -> Test Accuracy: 68.96\n",
      "[49, 60] loss: 0.678\n",
      "[49, 120] loss: 0.726\n",
      "[49, 180] loss: 0.710\n",
      "[49, 240] loss: 0.713\n",
      "[49, 300] loss: 0.696\n",
      "[49, 360] loss: 0.716\n",
      "Epoch: 49 -> Loss: 0.806043922901\n",
      "Epoch: 49 -> Test Accuracy: 67.81\n",
      "[50, 60] loss: 0.701\n",
      "[50, 120] loss: 0.702\n",
      "[50, 180] loss: 0.728\n",
      "[50, 240] loss: 0.726\n",
      "[50, 300] loss: 0.732\n",
      "[50, 360] loss: 0.725\n",
      "Epoch: 50 -> Loss: 0.694971442223\n",
      "Epoch: 50 -> Test Accuracy: 68.75\n",
      "[51, 60] loss: 0.705\n",
      "[51, 120] loss: 0.718\n",
      "[51, 180] loss: 0.702\n",
      "[51, 240] loss: 0.702\n",
      "[51, 300] loss: 0.709\n",
      "[51, 360] loss: 0.729\n",
      "Epoch: 51 -> Loss: 0.733152925968\n",
      "Epoch: 51 -> Test Accuracy: 68.46\n",
      "[52, 60] loss: 0.689\n",
      "[52, 120] loss: 0.711\n",
      "[52, 180] loss: 0.734\n",
      "[52, 240] loss: 0.723\n",
      "[52, 300] loss: 0.722\n",
      "[52, 360] loss: 0.702\n",
      "Epoch: 52 -> Loss: 0.76468527317\n",
      "Epoch: 52 -> Test Accuracy: 68.83\n",
      "[53, 60] loss: 0.680\n",
      "[53, 120] loss: 0.707\n",
      "[53, 180] loss: 0.713\n",
      "[53, 240] loss: 0.733\n",
      "[53, 300] loss: 0.715\n",
      "[53, 360] loss: 0.712\n",
      "Epoch: 53 -> Loss: 0.711628913879\n",
      "Epoch: 53 -> Test Accuracy: 68.2\n",
      "[54, 60] loss: 0.712\n",
      "[54, 120] loss: 0.724\n",
      "[54, 180] loss: 0.716\n",
      "[54, 240] loss: 0.704\n",
      "[54, 300] loss: 0.699\n",
      "[54, 360] loss: 0.721\n",
      "Epoch: 54 -> Loss: 0.745256364346\n",
      "Epoch: 54 -> Test Accuracy: 68.84\n",
      "[55, 60] loss: 0.702\n",
      "[55, 120] loss: 0.690\n",
      "[55, 180] loss: 0.724\n",
      "[55, 240] loss: 0.729\n",
      "[55, 300] loss: 0.717\n",
      "[55, 360] loss: 0.739\n",
      "Epoch: 55 -> Loss: 0.653406143188\n",
      "Epoch: 55 -> Test Accuracy: 67.95\n",
      "[56, 60] loss: 0.707\n",
      "[56, 120] loss: 0.711\n",
      "[56, 180] loss: 0.722\n",
      "[56, 240] loss: 0.715\n",
      "[56, 300] loss: 0.721\n",
      "[56, 360] loss: 0.717\n",
      "Epoch: 56 -> Loss: 0.779697060585\n",
      "Epoch: 56 -> Test Accuracy: 68.24\n",
      "[57, 60] loss: 0.708\n",
      "[57, 120] loss: 0.712\n",
      "[57, 180] loss: 0.713\n",
      "[57, 240] loss: 0.729\n",
      "[57, 300] loss: 0.706\n",
      "[57, 360] loss: 0.717\n",
      "Epoch: 57 -> Loss: 0.617446899414\n",
      "Epoch: 57 -> Test Accuracy: 68.11\n",
      "[58, 60] loss: 0.698\n",
      "[58, 120] loss: 0.706\n",
      "[58, 180] loss: 0.722\n",
      "[58, 240] loss: 0.721\n",
      "[58, 300] loss: 0.720\n",
      "[58, 360] loss: 0.702\n",
      "Epoch: 58 -> Loss: 0.611356675625\n",
      "Epoch: 58 -> Test Accuracy: 67.98\n",
      "[59, 60] loss: 0.699\n",
      "[59, 120] loss: 0.712\n",
      "[59, 180] loss: 0.712\n",
      "[59, 240] loss: 0.751\n",
      "[59, 300] loss: 0.699\n",
      "[59, 360] loss: 0.719\n",
      "Epoch: 59 -> Loss: 0.776597738266\n",
      "Epoch: 59 -> Test Accuracy: 67.1\n",
      "[60, 60] loss: 0.699\n",
      "[60, 120] loss: 0.721\n",
      "[60, 180] loss: 0.709\n",
      "[60, 240] loss: 0.707\n",
      "[60, 300] loss: 0.711\n",
      "[60, 360] loss: 0.727\n",
      "Epoch: 60 -> Loss: 0.692431807518\n",
      "Epoch: 60 -> Test Accuracy: 68.08\n",
      "[61, 60] loss: 0.711\n",
      "[61, 120] loss: 0.712\n",
      "[61, 180] loss: 0.702\n",
      "[61, 240] loss: 0.703\n",
      "[61, 300] loss: 0.714\n",
      "[61, 360] loss: 0.725\n",
      "Epoch: 61 -> Loss: 0.620374798775\n",
      "Epoch: 61 -> Test Accuracy: 68.79\n",
      "[62, 60] loss: 0.713\n",
      "[62, 120] loss: 0.719\n",
      "[62, 180] loss: 0.721\n",
      "[62, 240] loss: 0.703\n",
      "[62, 300] loss: 0.725\n",
      "[62, 360] loss: 0.698\n",
      "Epoch: 62 -> Loss: 0.678353428841\n",
      "Epoch: 62 -> Test Accuracy: 69.0\n",
      "[63, 60] loss: 0.692\n",
      "[63, 120] loss: 0.707\n",
      "[63, 180] loss: 0.702\n",
      "[63, 240] loss: 0.706\n",
      "[63, 300] loss: 0.701\n",
      "[63, 360] loss: 0.707\n",
      "Epoch: 63 -> Loss: 0.682418107986\n",
      "Epoch: 63 -> Test Accuracy: 68.33\n",
      "[64, 60] loss: 0.719\n",
      "[64, 120] loss: 0.721\n",
      "[64, 180] loss: 0.706\n",
      "[64, 240] loss: 0.702\n",
      "[64, 300] loss: 0.723\n",
      "[64, 360] loss: 0.719\n",
      "Epoch: 64 -> Loss: 0.87994146347\n",
      "Epoch: 64 -> Test Accuracy: 68.77\n",
      "[65, 60] loss: 0.691\n",
      "[65, 120] loss: 0.696\n",
      "[65, 180] loss: 0.702\n",
      "[65, 240] loss: 0.720\n",
      "[65, 300] loss: 0.721\n",
      "[65, 360] loss: 0.719\n",
      "Epoch: 65 -> Loss: 0.660311877728\n",
      "Epoch: 65 -> Test Accuracy: 68.76\n",
      "[66, 60] loss: 0.701\n",
      "[66, 120] loss: 0.708\n",
      "[66, 180] loss: 0.707\n",
      "[66, 240] loss: 0.710\n",
      "[66, 300] loss: 0.718\n",
      "[66, 360] loss: 0.721\n",
      "Epoch: 66 -> Loss: 0.770834386349\n",
      "Epoch: 66 -> Test Accuracy: 68.73\n",
      "[67, 60] loss: 0.697\n",
      "[67, 120] loss: 0.698\n",
      "[67, 180] loss: 0.710\n",
      "[67, 240] loss: 0.726\n",
      "[67, 300] loss: 0.700\n",
      "[67, 360] loss: 0.672\n",
      "Epoch: 67 -> Loss: 0.603191077709\n",
      "Epoch: 67 -> Test Accuracy: 67.74\n",
      "[68, 60] loss: 0.703\n",
      "[68, 120] loss: 0.675\n",
      "[68, 180] loss: 0.718\n",
      "[68, 240] loss: 0.703\n",
      "[68, 300] loss: 0.713\n",
      "[68, 360] loss: 0.715\n",
      "Epoch: 68 -> Loss: 0.793178021908\n",
      "Epoch: 68 -> Test Accuracy: 68.35\n",
      "[69, 60] loss: 0.702\n",
      "[69, 120] loss: 0.714\n",
      "[69, 180] loss: 0.727\n",
      "[69, 240] loss: 0.702\n",
      "[69, 300] loss: 0.699\n",
      "[69, 360] loss: 0.704\n",
      "Epoch: 69 -> Loss: 0.724453091621\n",
      "Epoch: 69 -> Test Accuracy: 68.35\n",
      "[70, 60] loss: 0.703\n",
      "[70, 120] loss: 0.691\n",
      "[70, 180] loss: 0.709\n",
      "[70, 240] loss: 0.692\n",
      "[70, 300] loss: 0.723\n",
      "[70, 360] loss: 0.695\n",
      "Epoch: 70 -> Loss: 0.820016205311\n",
      "Epoch: 70 -> Test Accuracy: 68.07\n",
      "[71, 60] loss: 0.668\n",
      "[71, 120] loss: 0.653\n",
      "[71, 180] loss: 0.659\n",
      "[71, 240] loss: 0.649\n",
      "[71, 300] loss: 0.633\n",
      "[71, 360] loss: 0.655\n",
      "Epoch: 71 -> Loss: 0.779743254185\n",
      "Epoch: 71 -> Test Accuracy: 70.97\n",
      "[72, 60] loss: 0.649\n",
      "[72, 120] loss: 0.615\n",
      "[72, 180] loss: 0.630\n",
      "[72, 240] loss: 0.626\n",
      "[72, 300] loss: 0.632\n",
      "[72, 360] loss: 0.636\n",
      "Epoch: 72 -> Loss: 0.709503173828\n",
      "Epoch: 72 -> Test Accuracy: 70.41\n",
      "[73, 60] loss: 0.637\n",
      "[73, 120] loss: 0.623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73, 180] loss: 0.630\n",
      "[73, 240] loss: 0.637\n",
      "[73, 300] loss: 0.623\n",
      "[73, 360] loss: 0.604\n",
      "Epoch: 73 -> Loss: 0.582615494728\n",
      "Epoch: 73 -> Test Accuracy: 71.53\n",
      "[74, 60] loss: 0.611\n",
      "[74, 120] loss: 0.625\n",
      "[74, 180] loss: 0.619\n",
      "[74, 240] loss: 0.617\n",
      "[74, 300] loss: 0.623\n",
      "[74, 360] loss: 0.629\n",
      "Epoch: 74 -> Loss: 0.716190457344\n",
      "Epoch: 74 -> Test Accuracy: 71.18\n",
      "[75, 60] loss: 0.626\n",
      "[75, 120] loss: 0.619\n",
      "[75, 180] loss: 0.633\n",
      "[75, 240] loss: 0.615\n",
      "[75, 300] loss: 0.604\n",
      "[75, 360] loss: 0.612\n",
      "Epoch: 75 -> Loss: 0.695552945137\n",
      "Epoch: 75 -> Test Accuracy: 71.23\n",
      "[76, 60] loss: 0.631\n",
      "[76, 120] loss: 0.625\n",
      "[76, 180] loss: 0.625\n",
      "[76, 240] loss: 0.630\n",
      "[76, 300] loss: 0.619\n",
      "[76, 360] loss: 0.620\n",
      "Epoch: 76 -> Loss: 0.539656877518\n",
      "Epoch: 76 -> Test Accuracy: 71.12\n",
      "[77, 60] loss: 0.613\n",
      "[77, 120] loss: 0.597\n",
      "[77, 180] loss: 0.610\n",
      "[77, 240] loss: 0.612\n",
      "[77, 300] loss: 0.617\n",
      "[77, 360] loss: 0.607\n",
      "Epoch: 77 -> Loss: 0.662396788597\n",
      "Epoch: 77 -> Test Accuracy: 71.37\n",
      "[78, 60] loss: 0.601\n",
      "[78, 120] loss: 0.622\n",
      "[78, 180] loss: 0.609\n",
      "[78, 240] loss: 0.605\n",
      "[78, 300] loss: 0.609\n",
      "[78, 360] loss: 0.619\n",
      "Epoch: 78 -> Loss: 0.539003491402\n",
      "Epoch: 78 -> Test Accuracy: 71.4\n",
      "[79, 60] loss: 0.598\n",
      "[79, 120] loss: 0.616\n",
      "[79, 180] loss: 0.610\n",
      "[79, 240] loss: 0.623\n",
      "[79, 300] loss: 0.610\n",
      "[79, 360] loss: 0.613\n",
      "Epoch: 79 -> Loss: 0.639579415321\n",
      "Epoch: 79 -> Test Accuracy: 70.9\n",
      "[80, 60] loss: 0.594\n",
      "[80, 120] loss: 0.609\n",
      "[80, 180] loss: 0.611\n",
      "[80, 240] loss: 0.630\n",
      "[80, 300] loss: 0.614\n",
      "[80, 360] loss: 0.607\n",
      "Epoch: 80 -> Loss: 0.544167280197\n",
      "Epoch: 80 -> Test Accuracy: 70.86\n",
      "[81, 60] loss: 0.590\n",
      "[81, 120] loss: 0.609\n",
      "[81, 180] loss: 0.601\n",
      "[81, 240] loss: 0.622\n",
      "[81, 300] loss: 0.619\n",
      "[81, 360] loss: 0.591\n",
      "Epoch: 81 -> Loss: 0.725351750851\n",
      "Epoch: 81 -> Test Accuracy: 71.2\n",
      "[82, 60] loss: 0.597\n",
      "[82, 120] loss: 0.610\n",
      "[82, 180] loss: 0.613\n",
      "[82, 240] loss: 0.614\n",
      "[82, 300] loss: 0.606\n",
      "[82, 360] loss: 0.612\n",
      "Epoch: 82 -> Loss: 0.542658209801\n",
      "Epoch: 82 -> Test Accuracy: 71.39\n",
      "[83, 60] loss: 0.598\n",
      "[83, 120] loss: 0.586\n",
      "[83, 180] loss: 0.624\n",
      "[83, 240] loss: 0.615\n",
      "[83, 300] loss: 0.623\n",
      "[83, 360] loss: 0.603\n",
      "Epoch: 83 -> Loss: 0.575292468071\n",
      "Epoch: 83 -> Test Accuracy: 71.3\n",
      "[84, 60] loss: 0.590\n",
      "[84, 120] loss: 0.611\n",
      "[84, 180] loss: 0.587\n",
      "[84, 240] loss: 0.598\n",
      "[84, 300] loss: 0.621\n",
      "[84, 360] loss: 0.615\n",
      "Epoch: 84 -> Loss: 0.701720178127\n",
      "Epoch: 84 -> Test Accuracy: 71.24\n",
      "[85, 60] loss: 0.604\n",
      "[85, 120] loss: 0.596\n",
      "[85, 180] loss: 0.626\n",
      "[85, 240] loss: 0.611\n",
      "[85, 300] loss: 0.604\n",
      "[85, 360] loss: 0.599\n",
      "Epoch: 85 -> Loss: 0.683473944664\n",
      "Epoch: 85 -> Test Accuracy: 71.62\n",
      "[86, 60] loss: 0.577\n",
      "[86, 120] loss: 0.594\n",
      "[86, 180] loss: 0.578\n",
      "[86, 240] loss: 0.609\n",
      "[86, 300] loss: 0.563\n",
      "[86, 360] loss: 0.584\n",
      "Epoch: 86 -> Loss: 0.565864562988\n",
      "Epoch: 86 -> Test Accuracy: 72.14\n",
      "[87, 60] loss: 0.581\n",
      "[87, 120] loss: 0.567\n",
      "[87, 180] loss: 0.591\n",
      "[87, 240] loss: 0.578\n",
      "[87, 300] loss: 0.577\n",
      "[87, 360] loss: 0.569\n",
      "Epoch: 87 -> Loss: 0.495789676905\n",
      "Epoch: 87 -> Test Accuracy: 71.86\n",
      "[88, 60] loss: 0.586\n",
      "[88, 120] loss: 0.566\n",
      "[88, 180] loss: 0.581\n",
      "[88, 240] loss: 0.577\n",
      "[88, 300] loss: 0.589\n",
      "[88, 360] loss: 0.577\n",
      "Epoch: 88 -> Loss: 0.603611111641\n",
      "Epoch: 88 -> Test Accuracy: 72.33\n",
      "[89, 60] loss: 0.563\n",
      "[89, 120] loss: 0.558\n",
      "[89, 180] loss: 0.566\n",
      "[89, 240] loss: 0.575\n",
      "[89, 300] loss: 0.580\n",
      "[89, 360] loss: 0.574\n",
      "Epoch: 89 -> Loss: 0.702374875546\n",
      "Epoch: 89 -> Test Accuracy: 72.04\n",
      "[90, 60] loss: 0.575\n",
      "[90, 120] loss: 0.572\n",
      "[90, 180] loss: 0.573\n",
      "[90, 240] loss: 0.562\n",
      "[90, 300] loss: 0.561\n",
      "[90, 360] loss: 0.584\n",
      "Epoch: 90 -> Loss: 0.65367859602\n",
      "Epoch: 90 -> Test Accuracy: 72.09\n",
      "[91, 60] loss: 0.583\n",
      "[91, 120] loss: 0.571\n",
      "[91, 180] loss: 0.563\n",
      "[91, 240] loss: 0.579\n",
      "[91, 300] loss: 0.572\n",
      "[91, 360] loss: 0.585\n",
      "Epoch: 91 -> Loss: 0.565649032593\n",
      "Epoch: 91 -> Test Accuracy: 72.3\n",
      "[92, 60] loss: 0.564\n",
      "[92, 120] loss: 0.573\n",
      "[92, 180] loss: 0.561\n",
      "[92, 240] loss: 0.551\n",
      "[92, 300] loss: 0.576\n",
      "[92, 360] loss: 0.581\n",
      "Epoch: 92 -> Loss: 0.66448611021\n",
      "Epoch: 92 -> Test Accuracy: 72.14\n",
      "[93, 60] loss: 0.559\n",
      "[93, 120] loss: 0.563\n",
      "[93, 180] loss: 0.569\n",
      "[93, 240] loss: 0.561\n",
      "[93, 300] loss: 0.573\n",
      "[93, 360] loss: 0.572\n",
      "Epoch: 93 -> Loss: 0.714541375637\n",
      "Epoch: 93 -> Test Accuracy: 72.18\n",
      "[94, 60] loss: 0.574\n",
      "[94, 120] loss: 0.588\n",
      "[94, 180] loss: 0.562\n",
      "[94, 240] loss: 0.562\n",
      "[94, 300] loss: 0.563\n",
      "[94, 360] loss: 0.563\n",
      "Epoch: 94 -> Loss: 0.680697798729\n",
      "Epoch: 94 -> Test Accuracy: 71.95\n",
      "[95, 60] loss: 0.571\n",
      "[95, 120] loss: 0.565\n",
      "[95, 180] loss: 0.567\n",
      "[95, 240] loss: 0.568\n",
      "[95, 300] loss: 0.564\n",
      "[95, 360] loss: 0.579\n",
      "Epoch: 95 -> Loss: 0.742103457451\n",
      "Epoch: 95 -> Test Accuracy: 72.02\n",
      "[96, 60] loss: 0.566\n",
      "[96, 120] loss: 0.555\n",
      "[96, 180] loss: 0.558\n",
      "[96, 240] loss: 0.565\n",
      "[96, 300] loss: 0.570\n",
      "[96, 360] loss: 0.567\n",
      "Epoch: 96 -> Loss: 0.514259278774\n",
      "Epoch: 96 -> Test Accuracy: 71.92\n",
      "[97, 60] loss: 0.555\n",
      "[97, 120] loss: 0.565\n",
      "[97, 180] loss: 0.563\n",
      "[97, 240] loss: 0.567\n",
      "[97, 300] loss: 0.570\n",
      "[97, 360] loss: 0.582\n",
      "Epoch: 97 -> Loss: 0.503473103046\n",
      "Epoch: 97 -> Test Accuracy: 72.12\n",
      "[98, 60] loss: 0.564\n",
      "[98, 120] loss: 0.553\n",
      "[98, 180] loss: 0.575\n",
      "[98, 240] loss: 0.584\n",
      "[98, 300] loss: 0.575\n",
      "[98, 360] loss: 0.574\n",
      "Epoch: 98 -> Loss: 0.411670833826\n",
      "Epoch: 98 -> Test Accuracy: 72.26\n",
      "[99, 60] loss: 0.580\n",
      "[99, 120] loss: 0.562\n",
      "[99, 180] loss: 0.572\n",
      "[99, 240] loss: 0.570\n",
      "[99, 300] loss: 0.554\n",
      "[99, 360] loss: 0.553\n",
      "Epoch: 99 -> Loss: 0.668234050274\n",
      "Epoch: 99 -> Test Accuracy: 72.36\n",
      "[100, 60] loss: 0.562\n",
      "[100, 120] loss: 0.551\n",
      "[100, 180] loss: 0.575\n",
      "[100, 240] loss: 0.590\n",
      "[100, 300] loss: 0.578\n",
      "[100, 360] loss: 0.550\n",
      "Epoch: 100 -> Loss: 0.527360320091\n",
      "Epoch: 100 -> Test Accuracy: 72.37\n",
      "Finished Training\n",
      "[1, 60] loss: 2.188\n",
      "[1, 120] loss: 2.054\n",
      "[1, 180] loss: 1.996\n",
      "[1, 240] loss: 1.966\n",
      "[1, 300] loss: 1.956\n",
      "[1, 360] loss: 1.937\n",
      "Epoch: 1 -> Loss: 2.11258411407\n",
      "Epoch: 1 -> Test Accuracy: 27.3\n",
      "[2, 60] loss: 1.936\n",
      "[2, 120] loss: 1.914\n",
      "[2, 180] loss: 1.924\n",
      "[2, 240] loss: 1.914\n",
      "[2, 300] loss: 1.921\n",
      "[2, 360] loss: 1.908\n",
      "Epoch: 2 -> Loss: 1.92323803902\n",
      "Epoch: 2 -> Test Accuracy: 28.22\n",
      "[3, 60] loss: 1.901\n",
      "[3, 120] loss: 1.895\n",
      "[3, 180] loss: 1.880\n",
      "[3, 240] loss: 1.888\n",
      "[3, 300] loss: 1.862\n",
      "[3, 360] loss: 1.889\n",
      "Epoch: 3 -> Loss: 1.77714920044\n",
      "Epoch: 3 -> Test Accuracy: 29.14\n",
      "[4, 60] loss: 1.856\n",
      "[4, 120] loss: 1.864\n",
      "[4, 180] loss: 1.868\n",
      "[4, 240] loss: 1.862\n",
      "[4, 300] loss: 1.870\n",
      "[4, 360] loss: 1.856\n",
      "Epoch: 4 -> Loss: 1.88342535496\n",
      "Epoch: 4 -> Test Accuracy: 30.07\n",
      "[5, 60] loss: 1.842\n",
      "[5, 120] loss: 1.850\n",
      "[5, 180] loss: 1.857\n",
      "[5, 240] loss: 1.849\n",
      "[5, 300] loss: 1.837\n",
      "[5, 360] loss: 1.841\n",
      "Epoch: 5 -> Loss: 1.81361961365\n",
      "Epoch: 5 -> Test Accuracy: 31.15\n",
      "[6, 60] loss: 1.831\n",
      "[6, 120] loss: 1.855\n",
      "[6, 180] loss: 1.844\n",
      "[6, 240] loss: 1.850\n",
      "[6, 300] loss: 1.833\n",
      "[6, 360] loss: 1.823\n",
      "Epoch: 6 -> Loss: 1.85598146915\n",
      "Epoch: 6 -> Test Accuracy: 31.32\n",
      "[7, 60] loss: 1.830\n",
      "[7, 120] loss: 1.831\n",
      "[7, 180] loss: 1.814\n",
      "[7, 240] loss: 1.844\n",
      "[7, 300] loss: 1.829\n",
      "[7, 360] loss: 1.826\n",
      "Epoch: 7 -> Loss: 1.75746154785\n",
      "Epoch: 7 -> Test Accuracy: 32.1\n",
      "[8, 60] loss: 1.837\n",
      "[8, 120] loss: 1.824\n",
      "[8, 180] loss: 1.814\n",
      "[8, 240] loss: 1.827\n",
      "[8, 300] loss: 1.824\n",
      "[8, 360] loss: 1.810\n",
      "Epoch: 8 -> Loss: 1.72553515434\n",
      "Epoch: 8 -> Test Accuracy: 30.69\n",
      "[9, 60] loss: 1.831\n",
      "[9, 120] loss: 1.811\n",
      "[9, 180] loss: 1.801\n",
      "[9, 240] loss: 1.816\n",
      "[9, 300] loss: 1.820\n",
      "[9, 360] loss: 1.807\n",
      "Epoch: 9 -> Loss: 1.81310534477\n",
      "Epoch: 9 -> Test Accuracy: 29.91\n",
      "[10, 60] loss: 1.801\n",
      "[10, 120] loss: 1.807\n",
      "[10, 180] loss: 1.807\n",
      "[10, 240] loss: 1.800\n",
      "[10, 300] loss: 1.808\n",
      "[10, 360] loss: 1.814\n",
      "Epoch: 10 -> Loss: 1.74140584469\n",
      "Epoch: 10 -> Test Accuracy: 31.4\n",
      "[11, 60] loss: 1.816\n",
      "[11, 120] loss: 1.792\n",
      "[11, 180] loss: 1.798\n",
      "[11, 240] loss: 1.801\n",
      "[11, 300] loss: 1.803\n",
      "[11, 360] loss: 1.807\n",
      "Epoch: 11 -> Loss: 1.82840323448\n",
      "Epoch: 11 -> Test Accuracy: 32.34\n",
      "[12, 60] loss: 1.814\n",
      "[12, 120] loss: 1.794\n",
      "[12, 180] loss: 1.795\n",
      "[12, 240] loss: 1.813\n",
      "[12, 300] loss: 1.785\n",
      "[12, 360] loss: 1.797\n",
      "Epoch: 12 -> Loss: 1.81161439419\n",
      "Epoch: 12 -> Test Accuracy: 30.49\n",
      "[13, 60] loss: 1.789\n",
      "[13, 120] loss: 1.778\n",
      "[13, 180] loss: 1.782\n",
      "[13, 240] loss: 1.816\n",
      "[13, 300] loss: 1.801\n",
      "[13, 360] loss: 1.798\n",
      "Epoch: 13 -> Loss: 1.99898469448\n",
      "Epoch: 13 -> Test Accuracy: 32.03\n",
      "[14, 60] loss: 1.792\n",
      "[14, 120] loss: 1.774\n",
      "[14, 180] loss: 1.797\n",
      "[14, 240] loss: 1.792\n",
      "[14, 300] loss: 1.793\n",
      "[14, 360] loss: 1.799\n",
      "Epoch: 14 -> Loss: 1.77131485939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 -> Test Accuracy: 31.09\n",
      "[15, 60] loss: 1.810\n",
      "[15, 120] loss: 1.802\n",
      "[15, 180] loss: 1.769\n",
      "[15, 240] loss: 1.768\n",
      "[15, 300] loss: 1.796\n",
      "[15, 360] loss: 1.781\n",
      "Epoch: 15 -> Loss: 1.87520051003\n",
      "Epoch: 15 -> Test Accuracy: 32.15\n",
      "[16, 60] loss: 1.799\n",
      "[16, 120] loss: 1.780\n",
      "[16, 180] loss: 1.795\n",
      "[16, 240] loss: 1.798\n",
      "[16, 300] loss: 1.773\n",
      "[16, 360] loss: 1.777\n",
      "Epoch: 16 -> Loss: 1.57727861404\n",
      "Epoch: 16 -> Test Accuracy: 32.46\n",
      "[17, 60] loss: 1.784\n",
      "[17, 120] loss: 1.768\n",
      "[17, 180] loss: 1.794\n",
      "[17, 240] loss: 1.780\n",
      "[17, 300] loss: 1.783\n",
      "[17, 360] loss: 1.763\n",
      "Epoch: 17 -> Loss: 1.89566206932\n",
      "Epoch: 17 -> Test Accuracy: 32.16\n",
      "[18, 60] loss: 1.781\n",
      "[18, 120] loss: 1.777\n",
      "[18, 180] loss: 1.786\n",
      "[18, 240] loss: 1.800\n",
      "[18, 300] loss: 1.794\n",
      "[18, 360] loss: 1.780\n",
      "Epoch: 18 -> Loss: 1.93311440945\n",
      "Epoch: 18 -> Test Accuracy: 32.69\n",
      "[19, 60] loss: 1.780\n",
      "[19, 120] loss: 1.800\n",
      "[19, 180] loss: 1.776\n",
      "[19, 240] loss: 1.783\n",
      "[19, 300] loss: 1.781\n",
      "[19, 360] loss: 1.786\n",
      "Epoch: 19 -> Loss: 1.75479316711\n",
      "Epoch: 19 -> Test Accuracy: 32.65\n",
      "[20, 60] loss: 1.786\n",
      "[20, 120] loss: 1.785\n",
      "[20, 180] loss: 1.766\n",
      "[20, 240] loss: 1.760\n",
      "[20, 300] loss: 1.796\n",
      "[20, 360] loss: 1.767\n",
      "Epoch: 20 -> Loss: 1.74201393127\n",
      "Epoch: 20 -> Test Accuracy: 31.92\n",
      "[21, 60] loss: 1.779\n",
      "[21, 120] loss: 1.770\n",
      "[21, 180] loss: 1.767\n",
      "[21, 240] loss: 1.777\n",
      "[21, 300] loss: 1.789\n",
      "[21, 360] loss: 1.782\n",
      "Epoch: 21 -> Loss: 1.69959187508\n",
      "Epoch: 21 -> Test Accuracy: 33.0\n",
      "[22, 60] loss: 1.770\n",
      "[22, 120] loss: 1.781\n",
      "[22, 180] loss: 1.790\n",
      "[22, 240] loss: 1.764\n",
      "[22, 300] loss: 1.778\n",
      "[22, 360] loss: 1.782\n",
      "Epoch: 22 -> Loss: 1.82969820499\n",
      "Epoch: 22 -> Test Accuracy: 33.65\n",
      "[23, 60] loss: 1.788\n",
      "[23, 120] loss: 1.755\n",
      "[23, 180] loss: 1.782\n",
      "[23, 240] loss: 1.758\n",
      "[23, 300] loss: 1.756\n",
      "[23, 360] loss: 1.779\n",
      "Epoch: 23 -> Loss: 1.81024456024\n",
      "Epoch: 23 -> Test Accuracy: 33.34\n",
      "[24, 60] loss: 1.763\n",
      "[24, 120] loss: 1.764\n",
      "[24, 180] loss: 1.763\n",
      "[24, 240] loss: 1.771\n",
      "[24, 300] loss: 1.784\n",
      "[24, 360] loss: 1.776\n",
      "Epoch: 24 -> Loss: 1.82504010201\n",
      "Epoch: 24 -> Test Accuracy: 32.22\n",
      "[25, 60] loss: 1.793\n",
      "[25, 120] loss: 1.783\n",
      "[25, 180] loss: 1.755\n",
      "[25, 240] loss: 1.768\n",
      "[25, 300] loss: 1.766\n",
      "[25, 360] loss: 1.766\n",
      "Epoch: 25 -> Loss: 1.72599256039\n",
      "Epoch: 25 -> Test Accuracy: 32.53\n",
      "[26, 60] loss: 1.792\n",
      "[26, 120] loss: 1.779\n",
      "[26, 180] loss: 1.767\n",
      "[26, 240] loss: 1.775\n",
      "[26, 300] loss: 1.755\n",
      "[26, 360] loss: 1.756\n",
      "Epoch: 26 -> Loss: 1.7113494873\n",
      "Epoch: 26 -> Test Accuracy: 33.29\n",
      "[27, 60] loss: 1.759\n",
      "[27, 120] loss: 1.763\n",
      "[27, 180] loss: 1.784\n",
      "[27, 240] loss: 1.777\n",
      "[27, 300] loss: 1.770\n",
      "[27, 360] loss: 1.770\n",
      "Epoch: 27 -> Loss: 1.63712656498\n",
      "Epoch: 27 -> Test Accuracy: 33.31\n",
      "[28, 60] loss: 1.789\n",
      "[28, 120] loss: 1.758\n",
      "[28, 180] loss: 1.779\n",
      "[28, 240] loss: 1.776\n",
      "[28, 300] loss: 1.759\n",
      "[28, 360] loss: 1.774\n",
      "Epoch: 28 -> Loss: 1.76605951786\n",
      "Epoch: 28 -> Test Accuracy: 33.4\n",
      "[29, 60] loss: 1.755\n",
      "[29, 120] loss: 1.769\n",
      "[29, 180] loss: 1.767\n",
      "[29, 240] loss: 1.772\n",
      "[29, 300] loss: 1.775\n",
      "[29, 360] loss: 1.768\n",
      "Epoch: 29 -> Loss: 1.78913366795\n",
      "Epoch: 29 -> Test Accuracy: 33.11\n",
      "[30, 60] loss: 1.762\n",
      "[30, 120] loss: 1.779\n",
      "[30, 180] loss: 1.785\n",
      "[30, 240] loss: 1.765\n",
      "[30, 300] loss: 1.766\n",
      "[30, 360] loss: 1.763\n",
      "Epoch: 30 -> Loss: 1.87430691719\n",
      "Epoch: 30 -> Test Accuracy: 32.32\n",
      "[31, 60] loss: 1.774\n",
      "[31, 120] loss: 1.781\n",
      "[31, 180] loss: 1.771\n",
      "[31, 240] loss: 1.770\n",
      "[31, 300] loss: 1.774\n",
      "[31, 360] loss: 1.768\n",
      "Epoch: 31 -> Loss: 1.84664511681\n",
      "Epoch: 31 -> Test Accuracy: 32.58\n",
      "[32, 60] loss: 1.762\n",
      "[32, 120] loss: 1.759\n",
      "[32, 180] loss: 1.760\n",
      "[32, 240] loss: 1.756\n",
      "[32, 300] loss: 1.783\n",
      "[32, 360] loss: 1.766\n",
      "Epoch: 32 -> Loss: 1.6602319479\n",
      "Epoch: 32 -> Test Accuracy: 32.76\n",
      "[33, 60] loss: 1.777\n",
      "[33, 120] loss: 1.777\n",
      "[33, 180] loss: 1.770\n",
      "[33, 240] loss: 1.759\n",
      "[33, 300] loss: 1.763\n",
      "[33, 360] loss: 1.767\n",
      "Epoch: 33 -> Loss: 1.80762553215\n",
      "Epoch: 33 -> Test Accuracy: 33.77\n",
      "[34, 60] loss: 1.763\n",
      "[34, 120] loss: 1.772\n",
      "[34, 180] loss: 1.764\n",
      "[34, 240] loss: 1.757\n",
      "[34, 300] loss: 1.773\n",
      "[34, 360] loss: 1.777\n",
      "Epoch: 34 -> Loss: 1.83848726749\n",
      "Epoch: 34 -> Test Accuracy: 33.22\n",
      "[35, 60] loss: 1.782\n",
      "[35, 120] loss: 1.759\n",
      "[35, 180] loss: 1.773\n",
      "[35, 240] loss: 1.784\n",
      "[35, 300] loss: 1.761\n",
      "[35, 360] loss: 1.774\n",
      "Epoch: 35 -> Loss: 1.74968755245\n",
      "Epoch: 35 -> Test Accuracy: 33.7\n",
      "[36, 60] loss: 1.718\n",
      "[36, 120] loss: 1.684\n",
      "[36, 180] loss: 1.692\n",
      "[36, 240] loss: 1.702\n",
      "[36, 300] loss: 1.683\n",
      "[36, 360] loss: 1.666\n",
      "Epoch: 36 -> Loss: 1.72911834717\n",
      "Epoch: 36 -> Test Accuracy: 35.97\n",
      "[37, 60] loss: 1.680\n",
      "[37, 120] loss: 1.683\n",
      "[37, 180] loss: 1.670\n",
      "[37, 240] loss: 1.685\n",
      "[37, 300] loss: 1.665\n",
      "[37, 360] loss: 1.675\n",
      "Epoch: 37 -> Loss: 1.59285736084\n",
      "Epoch: 37 -> Test Accuracy: 35.56\n",
      "[38, 60] loss: 1.665\n",
      "[38, 120] loss: 1.658\n",
      "[38, 180] loss: 1.685\n",
      "[38, 240] loss: 1.656\n",
      "[38, 300] loss: 1.665\n",
      "[38, 360] loss: 1.685\n",
      "Epoch: 38 -> Loss: 1.64157986641\n",
      "Epoch: 38 -> Test Accuracy: 36.12\n",
      "[39, 60] loss: 1.668\n",
      "[39, 120] loss: 1.679\n",
      "[39, 180] loss: 1.686\n",
      "[39, 240] loss: 1.641\n",
      "[39, 300] loss: 1.670\n",
      "[39, 360] loss: 1.673\n",
      "Epoch: 39 -> Loss: 1.68732106686\n",
      "Epoch: 39 -> Test Accuracy: 36.24\n",
      "[40, 60] loss: 1.668\n",
      "[40, 120] loss: 1.650\n",
      "[40, 180] loss: 1.644\n",
      "[40, 240] loss: 1.661\n",
      "[40, 300] loss: 1.682\n",
      "[40, 360] loss: 1.681\n",
      "Epoch: 40 -> Loss: 1.62086522579\n",
      "Epoch: 40 -> Test Accuracy: 36.69\n",
      "[41, 60] loss: 1.659\n",
      "[41, 120] loss: 1.669\n",
      "[41, 180] loss: 1.653\n",
      "[41, 240] loss: 1.675\n",
      "[41, 300] loss: 1.663\n",
      "[41, 360] loss: 1.650\n",
      "Epoch: 41 -> Loss: 1.7730499506\n",
      "Epoch: 41 -> Test Accuracy: 36.11\n",
      "[42, 60] loss: 1.651\n",
      "[42, 120] loss: 1.669\n",
      "[42, 180] loss: 1.665\n",
      "[42, 240] loss: 1.659\n",
      "[42, 300] loss: 1.648\n",
      "[42, 360] loss: 1.676\n",
      "Epoch: 42 -> Loss: 1.76718068123\n",
      "Epoch: 42 -> Test Accuracy: 35.3\n",
      "[43, 60] loss: 1.666\n",
      "[43, 120] loss: 1.671\n",
      "[43, 180] loss: 1.661\n",
      "[43, 240] loss: 1.666\n",
      "[43, 300] loss: 1.657\n",
      "[43, 360] loss: 1.655\n",
      "Epoch: 43 -> Loss: 1.58898413181\n",
      "Epoch: 43 -> Test Accuracy: 36.33\n",
      "[44, 60] loss: 1.662\n",
      "[44, 120] loss: 1.661\n",
      "[44, 180] loss: 1.661\n",
      "[44, 240] loss: 1.670\n",
      "[44, 300] loss: 1.663\n",
      "[44, 360] loss: 1.657\n",
      "Epoch: 44 -> Loss: 1.65532231331\n",
      "Epoch: 44 -> Test Accuracy: 36.22\n",
      "[45, 60] loss: 1.665\n",
      "[45, 120] loss: 1.659\n",
      "[45, 180] loss: 1.657\n",
      "[45, 240] loss: 1.664\n",
      "[45, 300] loss: 1.674\n",
      "[45, 360] loss: 1.661\n",
      "Epoch: 45 -> Loss: 1.71891474724\n",
      "Epoch: 45 -> Test Accuracy: 36.6\n",
      "[46, 60] loss: 1.671\n",
      "[46, 120] loss: 1.660\n",
      "[46, 180] loss: 1.673\n",
      "[46, 240] loss: 1.662\n",
      "[46, 300] loss: 1.668\n",
      "[46, 360] loss: 1.664\n",
      "Epoch: 46 -> Loss: 1.61859476566\n",
      "Epoch: 46 -> Test Accuracy: 36.05\n",
      "[47, 60] loss: 1.673\n",
      "[47, 120] loss: 1.637\n",
      "[47, 180] loss: 1.658\n",
      "[47, 240] loss: 1.650\n",
      "[47, 300] loss: 1.673\n",
      "[47, 360] loss: 1.649\n",
      "Epoch: 47 -> Loss: 1.5076649189\n",
      "Epoch: 47 -> Test Accuracy: 36.41\n",
      "[48, 60] loss: 1.652\n",
      "[48, 120] loss: 1.645\n",
      "[48, 180] loss: 1.650\n",
      "[48, 240] loss: 1.654\n",
      "[48, 300] loss: 1.673\n",
      "[48, 360] loss: 1.672\n",
      "Epoch: 48 -> Loss: 1.72200083733\n",
      "Epoch: 48 -> Test Accuracy: 36.88\n",
      "[49, 60] loss: 1.632\n",
      "[49, 120] loss: 1.651\n",
      "[49, 180] loss: 1.654\n",
      "[49, 240] loss: 1.661\n",
      "[49, 300] loss: 1.664\n",
      "[49, 360] loss: 1.675\n",
      "Epoch: 49 -> Loss: 1.75440061092\n",
      "Epoch: 49 -> Test Accuracy: 36.85\n",
      "[50, 60] loss: 1.670\n",
      "[50, 120] loss: 1.662\n",
      "[50, 180] loss: 1.669\n",
      "[50, 240] loss: 1.664\n",
      "[50, 300] loss: 1.666\n",
      "[50, 360] loss: 1.669\n",
      "Epoch: 50 -> Loss: 1.67321932316\n",
      "Epoch: 50 -> Test Accuracy: 36.32\n",
      "[51, 60] loss: 1.659\n",
      "[51, 120] loss: 1.643\n",
      "[51, 180] loss: 1.681\n",
      "[51, 240] loss: 1.640\n",
      "[51, 300] loss: 1.654\n",
      "[51, 360] loss: 1.654\n",
      "Epoch: 51 -> Loss: 1.60593950748\n",
      "Epoch: 51 -> Test Accuracy: 35.95\n",
      "[52, 60] loss: 1.641\n",
      "[52, 120] loss: 1.654\n",
      "[52, 180] loss: 1.667\n",
      "[52, 240] loss: 1.660\n",
      "[52, 300] loss: 1.658\n",
      "[52, 360] loss: 1.683\n",
      "Epoch: 52 -> Loss: 1.5842345953\n",
      "Epoch: 52 -> Test Accuracy: 36.24\n",
      "[53, 60] loss: 1.661\n",
      "[53, 120] loss: 1.648\n",
      "[53, 180] loss: 1.638\n",
      "[53, 240] loss: 1.656\n",
      "[53, 300] loss: 1.666\n",
      "[53, 360] loss: 1.659\n",
      "Epoch: 53 -> Loss: 1.77003884315\n",
      "Epoch: 53 -> Test Accuracy: 36.41\n",
      "[54, 60] loss: 1.653\n",
      "[54, 120] loss: 1.674\n",
      "[54, 180] loss: 1.633\n",
      "[54, 240] loss: 1.658\n",
      "[54, 300] loss: 1.651\n",
      "[54, 360] loss: 1.667\n",
      "Epoch: 54 -> Loss: 1.70054888725\n",
      "Epoch: 54 -> Test Accuracy: 36.65\n",
      "[55, 60] loss: 1.661\n",
      "[55, 120] loss: 1.643\n",
      "[55, 180] loss: 1.658\n",
      "[55, 240] loss: 1.658\n",
      "[55, 300] loss: 1.649\n",
      "[55, 360] loss: 1.657\n",
      "Epoch: 55 -> Loss: 1.60973453522\n",
      "Epoch: 55 -> Test Accuracy: 36.25\n",
      "[56, 60] loss: 1.654\n",
      "[56, 120] loss: 1.678\n",
      "[56, 180] loss: 1.648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56, 240] loss: 1.651\n",
      "[56, 300] loss: 1.655\n",
      "[56, 360] loss: 1.647\n",
      "Epoch: 56 -> Loss: 1.79181933403\n",
      "Epoch: 56 -> Test Accuracy: 36.88\n",
      "[57, 60] loss: 1.648\n",
      "[57, 120] loss: 1.655\n",
      "[57, 180] loss: 1.652\n",
      "[57, 240] loss: 1.658\n",
      "[57, 300] loss: 1.660\n",
      "[57, 360] loss: 1.667\n",
      "Epoch: 57 -> Loss: 1.72864556313\n",
      "Epoch: 57 -> Test Accuracy: 36.48\n",
      "[58, 60] loss: 1.643\n",
      "[58, 120] loss: 1.661\n",
      "[58, 180] loss: 1.652\n",
      "[58, 240] loss: 1.637\n",
      "[58, 300] loss: 1.653\n",
      "[58, 360] loss: 1.656\n",
      "Epoch: 58 -> Loss: 1.67901206017\n",
      "Epoch: 58 -> Test Accuracy: 36.83\n",
      "[59, 60] loss: 1.655\n",
      "[59, 120] loss: 1.666\n",
      "[59, 180] loss: 1.661\n",
      "[59, 240] loss: 1.650\n",
      "[59, 300] loss: 1.657\n",
      "[59, 360] loss: 1.651\n",
      "Epoch: 59 -> Loss: 1.73731040955\n",
      "Epoch: 59 -> Test Accuracy: 36.02\n",
      "[60, 60] loss: 1.657\n",
      "[60, 120] loss: 1.663\n",
      "[60, 180] loss: 1.654\n",
      "[60, 240] loss: 1.662\n",
      "[60, 300] loss: 1.651\n",
      "[60, 360] loss: 1.668\n",
      "Epoch: 60 -> Loss: 1.58225548267\n",
      "Epoch: 60 -> Test Accuracy: 36.59\n",
      "[61, 60] loss: 1.646\n",
      "[61, 120] loss: 1.656\n",
      "[61, 180] loss: 1.632\n",
      "[61, 240] loss: 1.661\n",
      "[61, 300] loss: 1.655\n",
      "[61, 360] loss: 1.644\n",
      "Epoch: 61 -> Loss: 1.83688473701\n",
      "Epoch: 61 -> Test Accuracy: 36.46\n",
      "[62, 60] loss: 1.659\n",
      "[62, 120] loss: 1.651\n",
      "[62, 180] loss: 1.651\n",
      "[62, 240] loss: 1.651\n",
      "[62, 300] loss: 1.651\n",
      "[62, 360] loss: 1.649\n",
      "Epoch: 62 -> Loss: 1.82855451107\n",
      "Epoch: 62 -> Test Accuracy: 36.98\n",
      "[63, 60] loss: 1.641\n",
      "[63, 120] loss: 1.658\n",
      "[63, 180] loss: 1.658\n",
      "[63, 240] loss: 1.662\n",
      "[63, 300] loss: 1.663\n",
      "[63, 360] loss: 1.654\n",
      "Epoch: 63 -> Loss: 1.91151428223\n",
      "Epoch: 63 -> Test Accuracy: 37.42\n",
      "[64, 60] loss: 1.658\n",
      "[64, 120] loss: 1.651\n",
      "[64, 180] loss: 1.646\n",
      "[64, 240] loss: 1.643\n",
      "[64, 300] loss: 1.665\n",
      "[64, 360] loss: 1.650\n",
      "Epoch: 64 -> Loss: 1.85328698158\n",
      "Epoch: 64 -> Test Accuracy: 36.95\n",
      "[65, 60] loss: 1.641\n",
      "[65, 120] loss: 1.657\n",
      "[65, 180] loss: 1.659\n",
      "[65, 240] loss: 1.643\n",
      "[65, 300] loss: 1.656\n",
      "[65, 360] loss: 1.680\n",
      "Epoch: 65 -> Loss: 1.52817463875\n",
      "Epoch: 65 -> Test Accuracy: 36.84\n",
      "[66, 60] loss: 1.646\n",
      "[66, 120] loss: 1.655\n",
      "[66, 180] loss: 1.645\n",
      "[66, 240] loss: 1.651\n",
      "[66, 300] loss: 1.654\n",
      "[66, 360] loss: 1.651\n",
      "Epoch: 66 -> Loss: 1.65356278419\n",
      "Epoch: 66 -> Test Accuracy: 36.84\n",
      "[67, 60] loss: 1.639\n",
      "[67, 120] loss: 1.645\n",
      "[67, 180] loss: 1.643\n",
      "[67, 240] loss: 1.647\n",
      "[67, 300] loss: 1.651\n",
      "[67, 360] loss: 1.661\n",
      "Epoch: 67 -> Loss: 1.79924809933\n",
      "Epoch: 67 -> Test Accuracy: 37.12\n",
      "[68, 60] loss: 1.656\n",
      "[68, 120] loss: 1.639\n",
      "[68, 180] loss: 1.645\n",
      "[68, 240] loss: 1.654\n",
      "[68, 300] loss: 1.646\n",
      "[68, 360] loss: 1.633\n",
      "Epoch: 68 -> Loss: 1.73234915733\n",
      "Epoch: 68 -> Test Accuracy: 36.01\n",
      "[69, 60] loss: 1.655\n",
      "[69, 120] loss: 1.628\n",
      "[69, 180] loss: 1.643\n",
      "[69, 240] loss: 1.654\n",
      "[69, 300] loss: 1.656\n",
      "[69, 360] loss: 1.653\n",
      "Epoch: 69 -> Loss: 1.76121973991\n",
      "Epoch: 69 -> Test Accuracy: 36.91\n",
      "[70, 60] loss: 1.654\n",
      "[70, 120] loss: 1.654\n",
      "[70, 180] loss: 1.641\n",
      "[70, 240] loss: 1.655\n",
      "[70, 300] loss: 1.648\n",
      "[70, 360] loss: 1.650\n",
      "Epoch: 70 -> Loss: 1.56188714504\n",
      "Epoch: 70 -> Test Accuracy: 36.51\n",
      "[71, 60] loss: 1.614\n",
      "[71, 120] loss: 1.596\n",
      "[71, 180] loss: 1.598\n",
      "[71, 240] loss: 1.592\n",
      "[71, 300] loss: 1.594\n",
      "[71, 360] loss: 1.588\n",
      "Epoch: 71 -> Loss: 1.55355679989\n",
      "Epoch: 71 -> Test Accuracy: 38.88\n",
      "[72, 60] loss: 1.591\n",
      "[72, 120] loss: 1.585\n",
      "[72, 180] loss: 1.577\n",
      "[72, 240] loss: 1.574\n",
      "[72, 300] loss: 1.596\n",
      "[72, 360] loss: 1.577\n",
      "Epoch: 72 -> Loss: 1.66962110996\n",
      "Epoch: 72 -> Test Accuracy: 39.02\n",
      "[73, 60] loss: 1.574\n",
      "[73, 120] loss: 1.592\n",
      "[73, 180] loss: 1.596\n",
      "[73, 240] loss: 1.577\n",
      "[73, 300] loss: 1.581\n",
      "[73, 360] loss: 1.588\n",
      "Epoch: 73 -> Loss: 1.5930262804\n",
      "Epoch: 73 -> Test Accuracy: 39.38\n",
      "[74, 60] loss: 1.560\n",
      "[74, 120] loss: 1.584\n",
      "[74, 180] loss: 1.586\n",
      "[74, 240] loss: 1.580\n",
      "[74, 300] loss: 1.575\n",
      "[74, 360] loss: 1.570\n",
      "Epoch: 74 -> Loss: 1.58979034424\n",
      "Epoch: 74 -> Test Accuracy: 38.94\n",
      "[75, 60] loss: 1.561\n",
      "[75, 120] loss: 1.572\n",
      "[75, 180] loss: 1.563\n",
      "[75, 240] loss: 1.586\n",
      "[75, 300] loss: 1.574\n",
      "[75, 360] loss: 1.567\n",
      "Epoch: 75 -> Loss: 1.40319633484\n",
      "Epoch: 75 -> Test Accuracy: 38.85\n",
      "[76, 60] loss: 1.571\n",
      "[76, 120] loss: 1.570\n",
      "[76, 180] loss: 1.570\n",
      "[76, 240] loss: 1.572\n",
      "[76, 300] loss: 1.579\n",
      "[76, 360] loss: 1.587\n",
      "Epoch: 76 -> Loss: 1.54051411152\n",
      "Epoch: 76 -> Test Accuracy: 39.1\n",
      "[77, 60] loss: 1.559\n",
      "[77, 120] loss: 1.564\n",
      "[77, 180] loss: 1.580\n",
      "[77, 240] loss: 1.577\n",
      "[77, 300] loss: 1.564\n",
      "[77, 360] loss: 1.579\n",
      "Epoch: 77 -> Loss: 1.55995154381\n",
      "Epoch: 77 -> Test Accuracy: 38.96\n",
      "[78, 60] loss: 1.574\n",
      "[78, 120] loss: 1.583\n",
      "[78, 180] loss: 1.566\n",
      "[78, 240] loss: 1.579\n",
      "[78, 300] loss: 1.579\n",
      "[78, 360] loss: 1.572\n",
      "Epoch: 78 -> Loss: 1.66184592247\n",
      "Epoch: 78 -> Test Accuracy: 39.15\n",
      "[79, 60] loss: 1.583\n",
      "[79, 120] loss: 1.553\n",
      "[79, 180] loss: 1.600\n",
      "[79, 240] loss: 1.559\n",
      "[79, 300] loss: 1.564\n",
      "[79, 360] loss: 1.561\n",
      "Epoch: 79 -> Loss: 1.58650422096\n",
      "Epoch: 79 -> Test Accuracy: 39.38\n",
      "[80, 60] loss: 1.560\n",
      "[80, 120] loss: 1.572\n",
      "[80, 180] loss: 1.565\n",
      "[80, 240] loss: 1.590\n",
      "[80, 300] loss: 1.568\n",
      "[80, 360] loss: 1.543\n",
      "Epoch: 80 -> Loss: 1.54278862476\n",
      "Epoch: 80 -> Test Accuracy: 39.63\n",
      "[81, 60] loss: 1.568\n",
      "[81, 120] loss: 1.567\n",
      "[81, 180] loss: 1.552\n",
      "[81, 240] loss: 1.569\n",
      "[81, 300] loss: 1.566\n",
      "[81, 360] loss: 1.565\n",
      "Epoch: 81 -> Loss: 1.72457146645\n",
      "Epoch: 81 -> Test Accuracy: 39.54\n",
      "[82, 60] loss: 1.561\n",
      "[82, 120] loss: 1.585\n",
      "[82, 180] loss: 1.581\n",
      "[82, 240] loss: 1.577\n",
      "[82, 300] loss: 1.569\n",
      "[82, 360] loss: 1.549\n",
      "Epoch: 82 -> Loss: 1.57050538063\n",
      "Epoch: 82 -> Test Accuracy: 39.8\n",
      "[83, 60] loss: 1.565\n",
      "[83, 120] loss: 1.545\n",
      "[83, 180] loss: 1.558\n",
      "[83, 240] loss: 1.553\n",
      "[83, 300] loss: 1.563\n",
      "[83, 360] loss: 1.568\n",
      "Epoch: 83 -> Loss: 1.61220419407\n",
      "Epoch: 83 -> Test Accuracy: 39.81\n",
      "[84, 60] loss: 1.579\n",
      "[84, 120] loss: 1.558\n",
      "[84, 180] loss: 1.572\n",
      "[84, 240] loss: 1.568\n",
      "[84, 300] loss: 1.557\n",
      "[84, 360] loss: 1.564\n",
      "Epoch: 84 -> Loss: 1.47156631947\n",
      "Epoch: 84 -> Test Accuracy: 39.27\n",
      "[85, 60] loss: 1.565\n",
      "[85, 120] loss: 1.562\n",
      "[85, 180] loss: 1.554\n",
      "[85, 240] loss: 1.569\n",
      "[85, 300] loss: 1.557\n",
      "[85, 360] loss: 1.559\n",
      "Epoch: 85 -> Loss: 1.64955067635\n",
      "Epoch: 85 -> Test Accuracy: 39.36\n",
      "[86, 60] loss: 1.558\n",
      "[86, 120] loss: 1.556\n",
      "[86, 180] loss: 1.535\n",
      "[86, 240] loss: 1.540\n",
      "[86, 300] loss: 1.534\n",
      "[86, 360] loss: 1.547\n",
      "Epoch: 86 -> Loss: 1.48388028145\n",
      "Epoch: 86 -> Test Accuracy: 40.16\n",
      "[87, 60] loss: 1.533\n",
      "[87, 120] loss: 1.536\n",
      "[87, 180] loss: 1.545\n",
      "[87, 240] loss: 1.535\n",
      "[87, 300] loss: 1.526\n",
      "[87, 360] loss: 1.521\n",
      "Epoch: 87 -> Loss: 1.63543701172\n",
      "Epoch: 87 -> Test Accuracy: 40.11\n",
      "[88, 60] loss: 1.537\n",
      "[88, 120] loss: 1.540\n",
      "[88, 180] loss: 1.527\n",
      "[88, 240] loss: 1.542\n",
      "[88, 300] loss: 1.536\n",
      "[88, 360] loss: 1.520\n",
      "Epoch: 88 -> Loss: 1.69780826569\n",
      "Epoch: 88 -> Test Accuracy: 40.49\n",
      "[89, 60] loss: 1.546\n",
      "[89, 120] loss: 1.542\n",
      "[89, 180] loss: 1.517\n",
      "[89, 240] loss: 1.525\n",
      "[89, 300] loss: 1.532\n",
      "[89, 360] loss: 1.527\n",
      "Epoch: 89 -> Loss: 1.55553030968\n",
      "Epoch: 89 -> Test Accuracy: 40.4\n",
      "[90, 60] loss: 1.525\n",
      "[90, 120] loss: 1.548\n",
      "[90, 180] loss: 1.534\n",
      "[90, 240] loss: 1.538\n",
      "[90, 300] loss: 1.522\n",
      "[90, 360] loss: 1.534\n",
      "Epoch: 90 -> Loss: 1.51833415031\n",
      "Epoch: 90 -> Test Accuracy: 40.3\n",
      "[91, 60] loss: 1.545\n",
      "[91, 120] loss: 1.531\n",
      "[91, 180] loss: 1.535\n",
      "[91, 240] loss: 1.526\n",
      "[91, 300] loss: 1.524\n",
      "[91, 360] loss: 1.516\n",
      "Epoch: 91 -> Loss: 1.6446698904\n",
      "Epoch: 91 -> Test Accuracy: 40.45\n",
      "[92, 60] loss: 1.523\n",
      "[92, 120] loss: 1.531\n",
      "[92, 180] loss: 1.536\n",
      "[92, 240] loss: 1.538\n",
      "[92, 300] loss: 1.519\n",
      "[92, 360] loss: 1.540\n",
      "Epoch: 92 -> Loss: 1.5694873333\n",
      "Epoch: 92 -> Test Accuracy: 40.15\n",
      "[93, 60] loss: 1.528\n",
      "[93, 120] loss: 1.543\n",
      "[93, 180] loss: 1.526\n",
      "[93, 240] loss: 1.537\n",
      "[93, 300] loss: 1.542\n",
      "[93, 360] loss: 1.524\n",
      "Epoch: 93 -> Loss: 1.41785228252\n",
      "Epoch: 93 -> Test Accuracy: 40.46\n",
      "[94, 60] loss: 1.521\n",
      "[94, 120] loss: 1.541\n",
      "[94, 180] loss: 1.519\n",
      "[94, 240] loss: 1.531\n",
      "[94, 300] loss: 1.523\n",
      "[94, 360] loss: 1.542\n",
      "Epoch: 94 -> Loss: 1.49153065681\n",
      "Epoch: 94 -> Test Accuracy: 40.57\n",
      "[95, 60] loss: 1.535\n",
      "[95, 120] loss: 1.551\n",
      "[95, 180] loss: 1.527\n",
      "[95, 240] loss: 1.528\n",
      "[95, 300] loss: 1.529\n",
      "[95, 360] loss: 1.519\n",
      "Epoch: 95 -> Loss: 1.69080924988\n",
      "Epoch: 95 -> Test Accuracy: 40.27\n",
      "[96, 60] loss: 1.527\n",
      "[96, 120] loss: 1.528\n",
      "[96, 180] loss: 1.548\n",
      "[96, 240] loss: 1.529\n",
      "[96, 300] loss: 1.529\n",
      "[96, 360] loss: 1.533\n",
      "Epoch: 96 -> Loss: 1.63573265076\n",
      "Epoch: 96 -> Test Accuracy: 40.19\n",
      "[97, 60] loss: 1.530\n",
      "[97, 120] loss: 1.529\n",
      "[97, 180] loss: 1.531\n",
      "[97, 240] loss: 1.526\n",
      "[97, 300] loss: 1.503\n",
      "[97, 360] loss: 1.512\n",
      "Epoch: 97 -> Loss: 1.44700396061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97 -> Test Accuracy: 40.34\n",
      "[98, 60] loss: 1.519\n",
      "[98, 120] loss: 1.536\n",
      "[98, 180] loss: 1.531\n",
      "[98, 240] loss: 1.541\n",
      "[98, 300] loss: 1.505\n",
      "[98, 360] loss: 1.508\n",
      "Epoch: 98 -> Loss: 1.44763350487\n",
      "Epoch: 98 -> Test Accuracy: 40.56\n",
      "[99, 60] loss: 1.511\n",
      "[99, 120] loss: 1.520\n",
      "[99, 180] loss: 1.532\n",
      "[99, 240] loss: 1.540\n",
      "[99, 300] loss: 1.520\n",
      "[99, 360] loss: 1.530\n",
      "Epoch: 99 -> Loss: 1.54947125912\n",
      "Epoch: 99 -> Test Accuracy: 40.38\n",
      "[100, 60] loss: 1.512\n",
      "[100, 120] loss: 1.547\n",
      "[100, 180] loss: 1.524\n",
      "[100, 240] loss: 1.527\n",
      "[100, 300] loss: 1.525\n",
      "[100, 360] loss: 1.516\n",
      "Epoch: 100 -> Loss: 1.33736300468\n",
      "Epoch: 100 -> Test Accuracy: 40.4\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train ConvClassifiers on feature map of net_3block\n",
    "conv_block5_loss_log, conv_block5_valid_accuracy_log, conv_block5_test_accuracy_log, conv_block5_max_accuracy, \\\n",
    "conv_block5_best_epoch = tr.train_all_blocks(5, 10, [0.1, 0.02, 0.004, 0.0008], [35, 70, 85, 100], 0.9, 5e-4, net_block5, \n",
    "                                            criterion, trainloader, None, testloader, use_ConvClassifier=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename files\n",
    "fm.add_block_to_name(5, [100, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Block RotNet with Average Pooling after ConvBlock 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "net_block5_avg = RN.RotNet(num_classes=4, num_conv_block=5, add_avg_pool=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.133\n",
      "[1, 120] loss: 0.995\n",
      "[1, 180] loss: 0.929\n",
      "[1, 240] loss: 0.893\n",
      "[1, 300] loss: 0.836\n",
      "[1, 360] loss: 0.791\n",
      "Epoch: 1 -> Loss: 0.734387993813\n",
      "Epoch: 1 -> Test Accuracy: 69.04\n",
      "[2, 60] loss: 0.755\n",
      "[2, 120] loss: 0.731\n",
      "[2, 180] loss: 0.683\n",
      "[2, 240] loss: 0.699\n",
      "[2, 300] loss: 0.671\n",
      "[2, 360] loss: 0.656\n",
      "Epoch: 2 -> Loss: 0.703846991062\n",
      "Epoch: 2 -> Test Accuracy: 73.9425\n",
      "[3, 60] loss: 0.635\n",
      "[3, 120] loss: 0.606\n",
      "[3, 180] loss: 0.599\n",
      "[3, 240] loss: 0.603\n",
      "[3, 300] loss: 0.587\n",
      "[3, 360] loss: 0.570\n",
      "Epoch: 3 -> Loss: 0.450614869595\n",
      "Epoch: 3 -> Test Accuracy: 77.5375\n",
      "[4, 60] loss: 0.557\n",
      "[4, 120] loss: 0.561\n",
      "[4, 180] loss: 0.557\n",
      "[4, 240] loss: 0.525\n",
      "[4, 300] loss: 0.530\n",
      "[4, 360] loss: 0.525\n",
      "Epoch: 4 -> Loss: 0.611191987991\n",
      "Epoch: 4 -> Test Accuracy: 79.31\n",
      "[5, 60] loss: 0.523\n",
      "[5, 120] loss: 0.507\n",
      "[5, 180] loss: 0.499\n",
      "[5, 240] loss: 0.506\n",
      "[5, 300] loss: 0.506\n",
      "[5, 360] loss: 0.495\n",
      "Epoch: 5 -> Loss: 0.548719704151\n",
      "Epoch: 5 -> Test Accuracy: 80.5375\n",
      "[6, 60] loss: 0.475\n",
      "[6, 120] loss: 0.477\n",
      "[6, 180] loss: 0.491\n",
      "[6, 240] loss: 0.481\n",
      "[6, 300] loss: 0.480\n",
      "[6, 360] loss: 0.465\n",
      "Epoch: 6 -> Loss: 0.444000422955\n",
      "Epoch: 6 -> Test Accuracy: 81.02\n",
      "[7, 60] loss: 0.462\n",
      "[7, 120] loss: 0.454\n",
      "[7, 180] loss: 0.465\n",
      "[7, 240] loss: 0.460\n",
      "[7, 300] loss: 0.460\n",
      "[7, 360] loss: 0.444\n",
      "Epoch: 7 -> Loss: 0.568881511688\n",
      "Epoch: 7 -> Test Accuracy: 82.3525\n",
      "[8, 60] loss: 0.435\n",
      "[8, 120] loss: 0.444\n",
      "[8, 180] loss: 0.451\n",
      "[8, 240] loss: 0.439\n",
      "[8, 300] loss: 0.432\n",
      "[8, 360] loss: 0.431\n",
      "Epoch: 8 -> Loss: 0.344248473644\n",
      "Epoch: 8 -> Test Accuracy: 83.3375\n",
      "[9, 60] loss: 0.426\n",
      "[9, 120] loss: 0.433\n",
      "[9, 180] loss: 0.432\n",
      "[9, 240] loss: 0.435\n",
      "[9, 300] loss: 0.423\n",
      "[9, 360] loss: 0.417\n",
      "Epoch: 9 -> Loss: 0.316713869572\n",
      "Epoch: 9 -> Test Accuracy: 83.1975\n",
      "[10, 60] loss: 0.408\n",
      "[10, 120] loss: 0.406\n",
      "[10, 180] loss: 0.403\n",
      "[10, 240] loss: 0.417\n",
      "[10, 300] loss: 0.422\n",
      "[10, 360] loss: 0.417\n",
      "Epoch: 10 -> Loss: 0.348001778126\n",
      "Epoch: 10 -> Test Accuracy: 83.57\n",
      "[11, 60] loss: 0.402\n",
      "[11, 120] loss: 0.390\n",
      "[11, 180] loss: 0.403\n",
      "[11, 240] loss: 0.410\n",
      "[11, 300] loss: 0.414\n",
      "[11, 360] loss: 0.404\n",
      "Epoch: 11 -> Loss: 0.350233018398\n",
      "Epoch: 11 -> Test Accuracy: 83.88\n",
      "[12, 60] loss: 0.401\n",
      "[12, 120] loss: 0.381\n",
      "[12, 180] loss: 0.386\n",
      "[12, 240] loss: 0.409\n",
      "[12, 300] loss: 0.395\n",
      "[12, 360] loss: 0.394\n",
      "Epoch: 12 -> Loss: 0.414737403393\n",
      "Epoch: 12 -> Test Accuracy: 83.845\n",
      "[13, 60] loss: 0.394\n",
      "[13, 120] loss: 0.377\n",
      "[13, 180] loss: 0.387\n",
      "[13, 240] loss: 0.387\n",
      "[13, 300] loss: 0.390\n",
      "[13, 360] loss: 0.381\n",
      "Epoch: 13 -> Loss: 0.331698209047\n",
      "Epoch: 13 -> Test Accuracy: 84.7575\n",
      "[14, 60] loss: 0.372\n",
      "[14, 120] loss: 0.385\n",
      "[14, 180] loss: 0.382\n",
      "[14, 240] loss: 0.373\n",
      "[14, 300] loss: 0.380\n",
      "[14, 360] loss: 0.371\n",
      "Epoch: 14 -> Loss: 0.346865266562\n",
      "Epoch: 14 -> Test Accuracy: 85.09\n",
      "[15, 60] loss: 0.366\n",
      "[15, 120] loss: 0.378\n",
      "[15, 180] loss: 0.379\n",
      "[15, 240] loss: 0.367\n",
      "[15, 300] loss: 0.372\n",
      "[15, 360] loss: 0.367\n",
      "Epoch: 15 -> Loss: 0.333948194981\n",
      "Epoch: 15 -> Test Accuracy: 83.255\n",
      "[16, 60] loss: 0.356\n",
      "[16, 120] loss: 0.364\n",
      "[16, 180] loss: 0.361\n",
      "[16, 240] loss: 0.376\n",
      "[16, 300] loss: 0.368\n",
      "[16, 360] loss: 0.366\n",
      "Epoch: 16 -> Loss: 0.446946293116\n",
      "Epoch: 16 -> Test Accuracy: 84.835\n",
      "[17, 60] loss: 0.353\n",
      "[17, 120] loss: 0.350\n",
      "[17, 180] loss: 0.358\n",
      "[17, 240] loss: 0.365\n",
      "[17, 300] loss: 0.361\n",
      "[17, 360] loss: 0.359\n",
      "Epoch: 17 -> Loss: 0.409370481968\n",
      "Epoch: 17 -> Test Accuracy: 84.605\n",
      "[18, 60] loss: 0.360\n",
      "[18, 120] loss: 0.348\n",
      "[18, 180] loss: 0.355\n",
      "[18, 240] loss: 0.354\n",
      "[18, 300] loss: 0.363\n",
      "[18, 360] loss: 0.350\n",
      "Epoch: 18 -> Loss: 0.35987663269\n",
      "Epoch: 18 -> Test Accuracy: 84.8975\n",
      "[19, 60] loss: 0.345\n",
      "[19, 120] loss: 0.335\n",
      "[19, 180] loss: 0.354\n",
      "[19, 240] loss: 0.352\n",
      "[19, 300] loss: 0.353\n",
      "[19, 360] loss: 0.369\n",
      "Epoch: 19 -> Loss: 0.318805009127\n",
      "Epoch: 19 -> Test Accuracy: 85.705\n",
      "[20, 60] loss: 0.348\n",
      "[20, 120] loss: 0.349\n",
      "[20, 180] loss: 0.351\n",
      "[20, 240] loss: 0.337\n",
      "[20, 300] loss: 0.357\n",
      "[20, 360] loss: 0.354\n",
      "Epoch: 20 -> Loss: 0.280278623104\n",
      "Epoch: 20 -> Test Accuracy: 85.3825\n",
      "[21, 60] loss: 0.343\n",
      "[21, 120] loss: 0.338\n",
      "[21, 180] loss: 0.343\n",
      "[21, 240] loss: 0.325\n",
      "[21, 300] loss: 0.343\n",
      "[21, 360] loss: 0.361\n",
      "Epoch: 21 -> Loss: 0.352840870619\n",
      "Epoch: 21 -> Test Accuracy: 86.315\n",
      "[22, 60] loss: 0.348\n",
      "[22, 120] loss: 0.336\n",
      "[22, 180] loss: 0.336\n",
      "[22, 240] loss: 0.349\n",
      "[22, 300] loss: 0.346\n",
      "[22, 360] loss: 0.337\n",
      "Epoch: 22 -> Loss: 0.300099760294\n",
      "Epoch: 22 -> Test Accuracy: 85.745\n",
      "[23, 60] loss: 0.334\n",
      "[23, 120] loss: 0.337\n",
      "[23, 180] loss: 0.327\n",
      "[23, 240] loss: 0.334\n",
      "[23, 300] loss: 0.333\n",
      "[23, 360] loss: 0.349\n",
      "Epoch: 23 -> Loss: 0.390959501266\n",
      "Epoch: 23 -> Test Accuracy: 85.23\n",
      "[24, 60] loss: 0.329\n",
      "[24, 120] loss: 0.336\n",
      "[24, 180] loss: 0.333\n",
      "[24, 240] loss: 0.330\n",
      "[24, 300] loss: 0.337\n",
      "[24, 360] loss: 0.351\n",
      "Epoch: 24 -> Loss: 0.290993452072\n",
      "Epoch: 24 -> Test Accuracy: 86.53\n",
      "[25, 60] loss: 0.323\n",
      "[25, 120] loss: 0.323\n",
      "[25, 180] loss: 0.345\n",
      "[25, 240] loss: 0.346\n",
      "[25, 300] loss: 0.331\n",
      "[25, 360] loss: 0.335\n",
      "Epoch: 25 -> Loss: 0.272879093885\n",
      "Epoch: 25 -> Test Accuracy: 86.5675\n",
      "[26, 60] loss: 0.320\n",
      "[26, 120] loss: 0.331\n",
      "[26, 180] loss: 0.326\n",
      "[26, 240] loss: 0.335\n",
      "[26, 300] loss: 0.327\n",
      "[26, 360] loss: 0.341\n",
      "Epoch: 26 -> Loss: 0.34915086627\n",
      "Epoch: 26 -> Test Accuracy: 85.62\n",
      "[27, 60] loss: 0.326\n",
      "[27, 120] loss: 0.337\n",
      "[27, 180] loss: 0.329\n",
      "[27, 240] loss: 0.332\n",
      "[27, 300] loss: 0.320\n",
      "[27, 360] loss: 0.331\n",
      "Epoch: 27 -> Loss: 0.321385204792\n",
      "Epoch: 27 -> Test Accuracy: 86.21\n",
      "[28, 60] loss: 0.317\n",
      "[28, 120] loss: 0.333\n",
      "[28, 180] loss: 0.332\n",
      "[28, 240] loss: 0.331\n",
      "[28, 300] loss: 0.329\n",
      "[28, 360] loss: 0.326\n",
      "Epoch: 28 -> Loss: 0.24275252223\n",
      "Epoch: 28 -> Test Accuracy: 87.0475\n",
      "[29, 60] loss: 0.309\n",
      "[29, 120] loss: 0.321\n",
      "[29, 180] loss: 0.334\n",
      "[29, 240] loss: 0.323\n",
      "[29, 300] loss: 0.327\n",
      "[29, 360] loss: 0.331\n",
      "Epoch: 29 -> Loss: 0.369251966476\n",
      "Epoch: 29 -> Test Accuracy: 85.875\n",
      "[30, 60] loss: 0.329\n",
      "[30, 120] loss: 0.319\n",
      "[30, 180] loss: 0.310\n",
      "[30, 240] loss: 0.319\n",
      "[30, 300] loss: 0.337\n",
      "[30, 360] loss: 0.318\n",
      "Epoch: 30 -> Loss: 0.33662301302\n",
      "Epoch: 30 -> Test Accuracy: 85.8525\n",
      "[31, 60] loss: 0.323\n",
      "[31, 120] loss: 0.320\n",
      "[31, 180] loss: 0.333\n",
      "[31, 240] loss: 0.320\n",
      "[31, 300] loss: 0.325\n",
      "[31, 360] loss: 0.322\n",
      "Epoch: 31 -> Loss: 0.317254155874\n",
      "Epoch: 31 -> Test Accuracy: 87.2075\n",
      "[32, 60] loss: 0.306\n",
      "[32, 120] loss: 0.318\n",
      "[32, 180] loss: 0.334\n",
      "[32, 240] loss: 0.315\n",
      "[32, 300] loss: 0.322\n",
      "[32, 360] loss: 0.316\n",
      "Epoch: 32 -> Loss: 0.376592308283\n",
      "Epoch: 32 -> Test Accuracy: 86.77\n",
      "[33, 60] loss: 0.305\n",
      "[33, 120] loss: 0.307\n",
      "[33, 180] loss: 0.316\n",
      "[33, 240] loss: 0.318\n",
      "[33, 300] loss: 0.315\n",
      "[33, 360] loss: 0.340\n",
      "Epoch: 33 -> Loss: 0.481035143137\n",
      "Epoch: 33 -> Test Accuracy: 86.345\n",
      "[34, 60] loss: 0.307\n",
      "[34, 120] loss: 0.319\n",
      "[34, 180] loss: 0.320\n",
      "[34, 240] loss: 0.328\n",
      "[34, 300] loss: 0.317\n",
      "[34, 360] loss: 0.325\n",
      "Epoch: 34 -> Loss: 0.242301702499\n",
      "Epoch: 34 -> Test Accuracy: 86.6775\n",
      "[35, 60] loss: 0.314\n",
      "[35, 120] loss: 0.308\n",
      "[35, 180] loss: 0.325\n",
      "[35, 240] loss: 0.321\n",
      "[35, 300] loss: 0.335\n",
      "[35, 360] loss: 0.309\n",
      "Epoch: 35 -> Loss: 0.402644693851\n",
      "Epoch: 35 -> Test Accuracy: 87.01\n",
      "[36, 60] loss: 0.312\n",
      "[36, 120] loss: 0.311\n",
      "[36, 180] loss: 0.318\n",
      "[36, 240] loss: 0.315\n",
      "[36, 300] loss: 0.324\n",
      "[36, 360] loss: 0.327\n",
      "Epoch: 36 -> Loss: 0.405948251486\n",
      "Epoch: 36 -> Test Accuracy: 87.075\n",
      "[37, 60] loss: 0.312\n",
      "[37, 120] loss: 0.323\n",
      "[37, 180] loss: 0.310\n",
      "[37, 240] loss: 0.312\n",
      "[37, 300] loss: 0.314\n",
      "[37, 360] loss: 0.314\n",
      "Epoch: 37 -> Loss: 0.377121597528\n",
      "Epoch: 37 -> Test Accuracy: 86.5975\n",
      "[38, 60] loss: 0.310\n",
      "[38, 120] loss: 0.307\n",
      "[38, 180] loss: 0.316\n",
      "[38, 240] loss: 0.308\n",
      "[38, 300] loss: 0.326\n",
      "[38, 360] loss: 0.318\n",
      "Epoch: 38 -> Loss: 0.381685197353\n",
      "Epoch: 38 -> Test Accuracy: 86.8425\n",
      "[39, 60] loss: 0.313\n",
      "[39, 120] loss: 0.313\n",
      "[39, 180] loss: 0.303\n",
      "[39, 240] loss: 0.316\n",
      "[39, 300] loss: 0.313\n",
      "[39, 360] loss: 0.326\n",
      "Epoch: 39 -> Loss: 0.370040208101\n",
      "Epoch: 39 -> Test Accuracy: 86.3925\n",
      "[40, 60] loss: 0.301\n",
      "[40, 120] loss: 0.306\n",
      "[40, 180] loss: 0.312\n",
      "[40, 240] loss: 0.308\n",
      "[40, 300] loss: 0.319\n",
      "[40, 360] loss: 0.318\n",
      "Epoch: 40 -> Loss: 0.434669882059\n",
      "Epoch: 40 -> Test Accuracy: 86.8575\n",
      "[41, 60] loss: 0.313\n",
      "[41, 120] loss: 0.301\n",
      "[41, 180] loss: 0.310\n",
      "[41, 240] loss: 0.307\n",
      "[41, 300] loss: 0.317\n",
      "[41, 360] loss: 0.322\n",
      "Epoch: 41 -> Loss: 0.350565582514\n",
      "Epoch: 41 -> Test Accuracy: 86.3175\n",
      "[42, 60] loss: 0.300\n",
      "[42, 120] loss: 0.295\n",
      "[42, 180] loss: 0.312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 240] loss: 0.315\n",
      "[42, 300] loss: 0.319\n",
      "[42, 360] loss: 0.314\n",
      "Epoch: 42 -> Loss: 0.327577084303\n",
      "Epoch: 42 -> Test Accuracy: 85.93\n",
      "[43, 60] loss: 0.304\n",
      "[43, 120] loss: 0.306\n",
      "[43, 180] loss: 0.308\n",
      "[43, 240] loss: 0.304\n",
      "[43, 300] loss: 0.311\n",
      "[43, 360] loss: 0.314\n",
      "Epoch: 43 -> Loss: 0.25012075901\n",
      "Epoch: 43 -> Test Accuracy: 86.8875\n",
      "[44, 60] loss: 0.292\n",
      "[44, 120] loss: 0.310\n",
      "[44, 180] loss: 0.324\n",
      "[44, 240] loss: 0.304\n",
      "[44, 300] loss: 0.298\n",
      "[44, 360] loss: 0.315\n",
      "Epoch: 44 -> Loss: 0.375960171223\n",
      "Epoch: 44 -> Test Accuracy: 86.715\n",
      "[45, 60] loss: 0.310\n",
      "[45, 120] loss: 0.313\n",
      "[45, 180] loss: 0.306\n",
      "[45, 240] loss: 0.325\n",
      "[45, 300] loss: 0.316\n",
      "[45, 360] loss: 0.312\n",
      "Epoch: 45 -> Loss: 0.236686378717\n",
      "Epoch: 45 -> Test Accuracy: 87.19\n",
      "[46, 60] loss: 0.300\n",
      "[46, 120] loss: 0.301\n",
      "[46, 180] loss: 0.311\n",
      "[46, 240] loss: 0.311\n",
      "[46, 300] loss: 0.310\n",
      "[46, 360] loss: 0.311\n",
      "Epoch: 46 -> Loss: 0.396911889315\n",
      "Epoch: 46 -> Test Accuracy: 87.475\n",
      "[47, 60] loss: 0.289\n",
      "[47, 120] loss: 0.308\n",
      "[47, 180] loss: 0.307\n",
      "[47, 240] loss: 0.314\n",
      "[47, 300] loss: 0.306\n",
      "[47, 360] loss: 0.318\n",
      "Epoch: 47 -> Loss: 0.135402008891\n",
      "Epoch: 47 -> Test Accuracy: 87.575\n",
      "[48, 60] loss: 0.292\n",
      "[48, 120] loss: 0.311\n",
      "[48, 180] loss: 0.310\n",
      "[48, 240] loss: 0.309\n",
      "[48, 300] loss: 0.307\n",
      "[48, 360] loss: 0.310\n",
      "Epoch: 48 -> Loss: 0.283059507608\n",
      "Epoch: 48 -> Test Accuracy: 86.48\n",
      "[49, 60] loss: 0.296\n",
      "[49, 120] loss: 0.301\n",
      "[49, 180] loss: 0.306\n",
      "[49, 240] loss: 0.313\n",
      "[49, 300] loss: 0.307\n",
      "[49, 360] loss: 0.307\n",
      "Epoch: 49 -> Loss: 0.338510423899\n",
      "Epoch: 49 -> Test Accuracy: 86.9825\n",
      "[50, 60] loss: 0.299\n",
      "[50, 120] loss: 0.306\n",
      "[50, 180] loss: 0.302\n",
      "[50, 240] loss: 0.297\n",
      "[50, 300] loss: 0.295\n",
      "[50, 360] loss: 0.308\n",
      "Epoch: 50 -> Loss: 0.294655561447\n",
      "Epoch: 50 -> Test Accuracy: 87.065\n",
      "[51, 60] loss: 0.299\n",
      "[51, 120] loss: 0.317\n",
      "[51, 180] loss: 0.299\n",
      "[51, 240] loss: 0.305\n",
      "[51, 300] loss: 0.298\n",
      "[51, 360] loss: 0.302\n",
      "Epoch: 51 -> Loss: 0.328475773335\n",
      "Epoch: 51 -> Test Accuracy: 86.81\n",
      "[52, 60] loss: 0.297\n",
      "[52, 120] loss: 0.307\n",
      "[52, 180] loss: 0.304\n",
      "[52, 240] loss: 0.302\n",
      "[52, 300] loss: 0.301\n",
      "[52, 360] loss: 0.303\n",
      "Epoch: 52 -> Loss: 0.276107043028\n",
      "Epoch: 52 -> Test Accuracy: 86.0775\n",
      "[53, 60] loss: 0.292\n",
      "[53, 120] loss: 0.305\n",
      "[53, 180] loss: 0.311\n",
      "[53, 240] loss: 0.310\n",
      "[53, 300] loss: 0.313\n",
      "[53, 360] loss: 0.303\n",
      "Epoch: 53 -> Loss: 0.286913126707\n",
      "Epoch: 53 -> Test Accuracy: 86.9775\n",
      "[54, 60] loss: 0.289\n",
      "[54, 120] loss: 0.301\n",
      "[54, 180] loss: 0.294\n",
      "[54, 240] loss: 0.306\n",
      "[54, 300] loss: 0.315\n",
      "[54, 360] loss: 0.304\n",
      "Epoch: 54 -> Loss: 0.270589530468\n",
      "Epoch: 54 -> Test Accuracy: 87.135\n",
      "[55, 60] loss: 0.299\n",
      "[55, 120] loss: 0.296\n",
      "[55, 180] loss: 0.319\n",
      "[55, 240] loss: 0.300\n",
      "[55, 300] loss: 0.306\n",
      "[55, 360] loss: 0.300\n",
      "Epoch: 55 -> Loss: 0.423596680164\n",
      "Epoch: 55 -> Test Accuracy: 86.79\n",
      "[56, 60] loss: 0.299\n",
      "[56, 120] loss: 0.310\n",
      "[56, 180] loss: 0.304\n",
      "[56, 240] loss: 0.308\n",
      "[56, 300] loss: 0.291\n",
      "[56, 360] loss: 0.304\n",
      "Epoch: 56 -> Loss: 0.466157197952\n",
      "Epoch: 56 -> Test Accuracy: 87.345\n",
      "[57, 60] loss: 0.297\n",
      "[57, 120] loss: 0.308\n",
      "[57, 180] loss: 0.295\n",
      "[57, 240] loss: 0.315\n",
      "[57, 300] loss: 0.315\n",
      "[57, 360] loss: 0.297\n",
      "Epoch: 57 -> Loss: 0.17191259563\n",
      "Epoch: 57 -> Test Accuracy: 87.2125\n",
      "[58, 60] loss: 0.293\n",
      "[58, 120] loss: 0.295\n",
      "[58, 180] loss: 0.290\n",
      "[58, 240] loss: 0.304\n",
      "[58, 300] loss: 0.306\n",
      "[58, 360] loss: 0.315\n",
      "Epoch: 58 -> Loss: 0.351678371429\n",
      "Epoch: 58 -> Test Accuracy: 86.855\n",
      "[59, 60] loss: 0.282\n",
      "[59, 120] loss: 0.301\n",
      "[59, 180] loss: 0.296\n",
      "[59, 240] loss: 0.303\n",
      "[59, 300] loss: 0.306\n",
      "[59, 360] loss: 0.313\n",
      "Epoch: 59 -> Loss: 0.360332012177\n",
      "Epoch: 59 -> Test Accuracy: 86.895\n",
      "[60, 60] loss: 0.284\n",
      "[60, 120] loss: 0.302\n",
      "[60, 180] loss: 0.295\n",
      "[60, 240] loss: 0.309\n",
      "[60, 300] loss: 0.292\n",
      "[60, 360] loss: 0.316\n",
      "Epoch: 60 -> Loss: 0.27473923564\n",
      "Epoch: 60 -> Test Accuracy: 87.56\n",
      "[61, 60] loss: 0.224\n",
      "[61, 120] loss: 0.206\n",
      "[61, 180] loss: 0.187\n",
      "[61, 240] loss: 0.182\n",
      "[61, 300] loss: 0.181\n",
      "[61, 360] loss: 0.175\n",
      "Epoch: 61 -> Loss: 0.179622292519\n",
      "Epoch: 61 -> Test Accuracy: 91.3725\n",
      "[62, 60] loss: 0.161\n",
      "[62, 120] loss: 0.172\n",
      "[62, 180] loss: 0.174\n",
      "[62, 240] loss: 0.164\n",
      "[62, 300] loss: 0.172\n",
      "[62, 360] loss: 0.164\n",
      "Epoch: 62 -> Loss: 0.205064579844\n",
      "Epoch: 62 -> Test Accuracy: 91.2525\n",
      "[63, 60] loss: 0.157\n",
      "[63, 120] loss: 0.150\n",
      "[63, 180] loss: 0.150\n",
      "[63, 240] loss: 0.150\n",
      "[63, 300] loss: 0.162\n",
      "[63, 360] loss: 0.161\n",
      "Epoch: 63 -> Loss: 0.151784986258\n",
      "Epoch: 63 -> Test Accuracy: 91.2325\n",
      "[64, 60] loss: 0.139\n",
      "[64, 120] loss: 0.153\n",
      "[64, 180] loss: 0.145\n",
      "[64, 240] loss: 0.141\n",
      "[64, 300] loss: 0.160\n",
      "[64, 360] loss: 0.155\n",
      "Epoch: 64 -> Loss: 0.199597761035\n",
      "Epoch: 64 -> Test Accuracy: 91.37\n",
      "[65, 60] loss: 0.140\n",
      "[65, 120] loss: 0.144\n",
      "[65, 180] loss: 0.146\n",
      "[65, 240] loss: 0.150\n",
      "[65, 300] loss: 0.149\n",
      "[65, 360] loss: 0.154\n",
      "Epoch: 65 -> Loss: 0.165205582976\n",
      "Epoch: 65 -> Test Accuracy: 91.2675\n",
      "[66, 60] loss: 0.133\n",
      "[66, 120] loss: 0.146\n",
      "[66, 180] loss: 0.139\n",
      "[66, 240] loss: 0.146\n",
      "[66, 300] loss: 0.145\n",
      "[66, 360] loss: 0.151\n",
      "Epoch: 66 -> Loss: 0.105967476964\n",
      "Epoch: 66 -> Test Accuracy: 91.365\n",
      "[67, 60] loss: 0.141\n",
      "[67, 120] loss: 0.143\n",
      "[67, 180] loss: 0.145\n",
      "[67, 240] loss: 0.145\n",
      "[67, 300] loss: 0.144\n",
      "[67, 360] loss: 0.158\n",
      "Epoch: 67 -> Loss: 0.190913632512\n",
      "Epoch: 67 -> Test Accuracy: 91.25\n",
      "[68, 60] loss: 0.133\n",
      "[68, 120] loss: 0.147\n",
      "[68, 180] loss: 0.142\n",
      "[68, 240] loss: 0.143\n",
      "[68, 300] loss: 0.152\n",
      "[68, 360] loss: 0.149\n",
      "Epoch: 68 -> Loss: 0.186832696199\n",
      "Epoch: 68 -> Test Accuracy: 91.4375\n",
      "[69, 60] loss: 0.130\n",
      "[69, 120] loss: 0.137\n",
      "[69, 180] loss: 0.143\n",
      "[69, 240] loss: 0.142\n",
      "[69, 300] loss: 0.151\n",
      "[69, 360] loss: 0.149\n",
      "Epoch: 69 -> Loss: 0.172724887729\n",
      "Epoch: 69 -> Test Accuracy: 90.7175\n",
      "[70, 60] loss: 0.135\n",
      "[70, 120] loss: 0.149\n",
      "[70, 180] loss: 0.144\n",
      "[70, 240] loss: 0.143\n",
      "[70, 300] loss: 0.147\n",
      "[70, 360] loss: 0.152\n",
      "Epoch: 70 -> Loss: 0.132741183043\n",
      "Epoch: 70 -> Test Accuracy: 91.22\n",
      "[71, 60] loss: 0.141\n",
      "[71, 120] loss: 0.143\n",
      "[71, 180] loss: 0.139\n",
      "[71, 240] loss: 0.151\n",
      "[71, 300] loss: 0.155\n",
      "[71, 360] loss: 0.141\n",
      "Epoch: 71 -> Loss: 0.150387123227\n",
      "Epoch: 71 -> Test Accuracy: 90.9325\n",
      "[72, 60] loss: 0.139\n",
      "[72, 120] loss: 0.137\n",
      "[72, 180] loss: 0.145\n",
      "[72, 240] loss: 0.152\n",
      "[72, 300] loss: 0.144\n",
      "[72, 360] loss: 0.148\n",
      "Epoch: 72 -> Loss: 0.0693176165223\n",
      "Epoch: 72 -> Test Accuracy: 91.1725\n",
      "[73, 60] loss: 0.140\n",
      "[73, 120] loss: 0.142\n",
      "[73, 180] loss: 0.139\n",
      "[73, 240] loss: 0.148\n",
      "[73, 300] loss: 0.144\n",
      "[73, 360] loss: 0.153\n",
      "Epoch: 73 -> Loss: 0.13521823287\n",
      "Epoch: 73 -> Test Accuracy: 91.0475\n",
      "[74, 60] loss: 0.135\n",
      "[74, 120] loss: 0.147\n",
      "[74, 180] loss: 0.142\n",
      "[74, 240] loss: 0.148\n",
      "[74, 300] loss: 0.149\n",
      "[74, 360] loss: 0.148\n",
      "Epoch: 74 -> Loss: 0.143914058805\n",
      "Epoch: 74 -> Test Accuracy: 91.1575\n",
      "[75, 60] loss: 0.131\n",
      "[75, 120] loss: 0.142\n",
      "[75, 180] loss: 0.145\n",
      "[75, 240] loss: 0.144\n",
      "[75, 300] loss: 0.152\n",
      "[75, 360] loss: 0.152\n",
      "Epoch: 75 -> Loss: 0.192818194628\n",
      "Epoch: 75 -> Test Accuracy: 90.91\n",
      "[76, 60] loss: 0.137\n",
      "[76, 120] loss: 0.144\n",
      "[76, 180] loss: 0.148\n",
      "[76, 240] loss: 0.152\n",
      "[76, 300] loss: 0.136\n",
      "[76, 360] loss: 0.157\n",
      "Epoch: 76 -> Loss: 0.153442636132\n",
      "Epoch: 76 -> Test Accuracy: 90.8975\n",
      "[77, 60] loss: 0.133\n",
      "[77, 120] loss: 0.134\n",
      "[77, 180] loss: 0.149\n",
      "[77, 240] loss: 0.147\n",
      "[77, 300] loss: 0.155\n",
      "[77, 360] loss: 0.145\n",
      "Epoch: 77 -> Loss: 0.132584944367\n",
      "Epoch: 77 -> Test Accuracy: 91.0875\n",
      "[78, 60] loss: 0.132\n",
      "[78, 120] loss: 0.140\n",
      "[78, 180] loss: 0.148\n",
      "[78, 240] loss: 0.150\n",
      "[78, 300] loss: 0.148\n",
      "[78, 360] loss: 0.142\n",
      "Epoch: 78 -> Loss: 0.185135513544\n",
      "Epoch: 78 -> Test Accuracy: 90.9825\n",
      "[79, 60] loss: 0.142\n",
      "[79, 120] loss: 0.141\n",
      "[79, 180] loss: 0.146\n",
      "[79, 240] loss: 0.148\n",
      "[79, 300] loss: 0.146\n",
      "[79, 360] loss: 0.153\n",
      "Epoch: 79 -> Loss: 0.0992786958814\n",
      "Epoch: 79 -> Test Accuracy: 91.075\n",
      "[80, 60] loss: 0.138\n",
      "[80, 120] loss: 0.140\n",
      "[80, 180] loss: 0.148\n",
      "[80, 240] loss: 0.142\n",
      "[80, 300] loss: 0.140\n",
      "[80, 360] loss: 0.153\n",
      "Epoch: 80 -> Loss: 0.153493851423\n",
      "Epoch: 80 -> Test Accuracy: 90.6475\n",
      "[81, 60] loss: 0.125\n",
      "[81, 120] loss: 0.140\n",
      "[81, 180] loss: 0.145\n",
      "[81, 240] loss: 0.152\n",
      "[81, 300] loss: 0.151\n",
      "[81, 360] loss: 0.143\n",
      "Epoch: 81 -> Loss: 0.251825928688\n",
      "Epoch: 81 -> Test Accuracy: 90.7675\n",
      "[82, 60] loss: 0.134\n",
      "[82, 120] loss: 0.143\n",
      "[82, 180] loss: 0.143\n",
      "[82, 240] loss: 0.151\n",
      "[82, 300] loss: 0.149\n",
      "[82, 360] loss: 0.147\n",
      "Epoch: 82 -> Loss: 0.155929639935\n",
      "Epoch: 82 -> Test Accuracy: 90.97\n",
      "[83, 60] loss: 0.133\n",
      "[83, 120] loss: 0.142\n",
      "[83, 180] loss: 0.148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83, 240] loss: 0.140\n",
      "[83, 300] loss: 0.150\n",
      "[83, 360] loss: 0.146\n",
      "Epoch: 83 -> Loss: 0.229354187846\n",
      "Epoch: 83 -> Test Accuracy: 90.54\n",
      "[84, 60] loss: 0.135\n",
      "[84, 120] loss: 0.143\n",
      "[84, 180] loss: 0.144\n",
      "[84, 240] loss: 0.154\n",
      "[84, 300] loss: 0.141\n",
      "[84, 360] loss: 0.147\n",
      "Epoch: 84 -> Loss: 0.12714394927\n",
      "Epoch: 84 -> Test Accuracy: 90.845\n",
      "[85, 60] loss: 0.127\n",
      "[85, 120] loss: 0.142\n",
      "[85, 180] loss: 0.144\n",
      "[85, 240] loss: 0.146\n",
      "[85, 300] loss: 0.153\n",
      "[85, 360] loss: 0.152\n",
      "Epoch: 85 -> Loss: 0.318979084492\n",
      "Epoch: 85 -> Test Accuracy: 90.69\n",
      "[86, 60] loss: 0.132\n",
      "[86, 120] loss: 0.147\n",
      "[86, 180] loss: 0.146\n",
      "[86, 240] loss: 0.139\n",
      "[86, 300] loss: 0.145\n",
      "[86, 360] loss: 0.148\n",
      "Epoch: 86 -> Loss: 0.191472277045\n",
      "Epoch: 86 -> Test Accuracy: 90.5825\n",
      "[87, 60] loss: 0.130\n",
      "[87, 120] loss: 0.145\n",
      "[87, 180] loss: 0.146\n",
      "[87, 240] loss: 0.146\n",
      "[87, 300] loss: 0.140\n",
      "[87, 360] loss: 0.148\n",
      "Epoch: 87 -> Loss: 0.118860125542\n",
      "Epoch: 87 -> Test Accuracy: 90.565\n",
      "[88, 60] loss: 0.131\n",
      "[88, 120] loss: 0.137\n",
      "[88, 180] loss: 0.142\n",
      "[88, 240] loss: 0.136\n",
      "[88, 300] loss: 0.148\n",
      "[88, 360] loss: 0.148\n",
      "Epoch: 88 -> Loss: 0.108965933323\n",
      "Epoch: 88 -> Test Accuracy: 90.6675\n",
      "[89, 60] loss: 0.134\n",
      "[89, 120] loss: 0.140\n",
      "[89, 180] loss: 0.144\n",
      "[89, 240] loss: 0.144\n",
      "[89, 300] loss: 0.148\n",
      "[89, 360] loss: 0.136\n",
      "Epoch: 89 -> Loss: 0.119066759944\n",
      "Epoch: 89 -> Test Accuracy: 90.3275\n",
      "[90, 60] loss: 0.138\n",
      "[90, 120] loss: 0.130\n",
      "[90, 180] loss: 0.146\n",
      "[90, 240] loss: 0.139\n",
      "[90, 300] loss: 0.150\n",
      "[90, 360] loss: 0.152\n",
      "Epoch: 90 -> Loss: 0.1684705019\n",
      "Epoch: 90 -> Test Accuracy: 90.8425\n",
      "[91, 60] loss: 0.129\n",
      "[91, 120] loss: 0.144\n",
      "[91, 180] loss: 0.134\n",
      "[91, 240] loss: 0.139\n",
      "[91, 300] loss: 0.145\n",
      "[91, 360] loss: 0.149\n",
      "Epoch: 91 -> Loss: 0.254869073629\n",
      "Epoch: 91 -> Test Accuracy: 91.0575\n",
      "[92, 60] loss: 0.132\n",
      "[92, 120] loss: 0.138\n",
      "[92, 180] loss: 0.139\n",
      "[92, 240] loss: 0.141\n",
      "[92, 300] loss: 0.143\n",
      "[92, 360] loss: 0.145\n",
      "Epoch: 92 -> Loss: 0.0642218962312\n",
      "Epoch: 92 -> Test Accuracy: 90.6125\n",
      "[93, 60] loss: 0.135\n",
      "[93, 120] loss: 0.129\n",
      "[93, 180] loss: 0.141\n",
      "[93, 240] loss: 0.139\n",
      "[93, 300] loss: 0.144\n",
      "[93, 360] loss: 0.147\n",
      "Epoch: 93 -> Loss: 0.0885292738676\n",
      "Epoch: 93 -> Test Accuracy: 90.5975\n",
      "[94, 60] loss: 0.123\n",
      "[94, 120] loss: 0.139\n",
      "[94, 180] loss: 0.136\n",
      "[94, 240] loss: 0.143\n",
      "[94, 300] loss: 0.137\n",
      "[94, 360] loss: 0.156\n",
      "Epoch: 94 -> Loss: 0.205532193184\n",
      "Epoch: 94 -> Test Accuracy: 90.5525\n",
      "[95, 60] loss: 0.135\n",
      "[95, 120] loss: 0.134\n",
      "[95, 180] loss: 0.134\n",
      "[95, 240] loss: 0.145\n",
      "[95, 300] loss: 0.143\n",
      "[95, 360] loss: 0.136\n",
      "Epoch: 95 -> Loss: 0.119009755552\n",
      "Epoch: 95 -> Test Accuracy: 90.415\n",
      "[96, 60] loss: 0.129\n",
      "[96, 120] loss: 0.127\n",
      "[96, 180] loss: 0.137\n",
      "[96, 240] loss: 0.144\n",
      "[96, 300] loss: 0.137\n",
      "[96, 360] loss: 0.148\n",
      "Epoch: 96 -> Loss: 0.186980634928\n",
      "Epoch: 96 -> Test Accuracy: 90.7575\n",
      "[97, 60] loss: 0.129\n",
      "[97, 120] loss: 0.130\n",
      "[97, 180] loss: 0.138\n",
      "[97, 240] loss: 0.139\n",
      "[97, 300] loss: 0.138\n",
      "[97, 360] loss: 0.145\n",
      "Epoch: 97 -> Loss: 0.161872446537\n",
      "Epoch: 97 -> Test Accuracy: 90.705\n",
      "[98, 60] loss: 0.132\n",
      "[98, 120] loss: 0.124\n",
      "[98, 180] loss: 0.144\n",
      "[98, 240] loss: 0.143\n",
      "[98, 300] loss: 0.131\n",
      "[98, 360] loss: 0.146\n",
      "Epoch: 98 -> Loss: 0.175838679075\n",
      "Epoch: 98 -> Test Accuracy: 90.9075\n",
      "[99, 60] loss: 0.133\n",
      "[99, 120] loss: 0.136\n",
      "[99, 180] loss: 0.132\n",
      "[99, 240] loss: 0.136\n",
      "[99, 300] loss: 0.144\n",
      "[99, 360] loss: 0.136\n",
      "Epoch: 99 -> Loss: 0.0949266478419\n",
      "Epoch: 99 -> Test Accuracy: 90.1725\n",
      "[100, 60] loss: 0.131\n",
      "[100, 120] loss: 0.131\n",
      "[100, 180] loss: 0.128\n",
      "[100, 240] loss: 0.141\n",
      "[100, 300] loss: 0.142\n",
      "[100, 360] loss: 0.141\n",
      "Epoch: 100 -> Loss: 0.10887812078\n",
      "Epoch: 100 -> Test Accuracy: 90.6075\n",
      "[101, 60] loss: 0.122\n",
      "[101, 120] loss: 0.134\n",
      "[101, 180] loss: 0.140\n",
      "[101, 240] loss: 0.141\n",
      "[101, 300] loss: 0.144\n",
      "[101, 360] loss: 0.139\n",
      "Epoch: 101 -> Loss: 0.114515647292\n",
      "Epoch: 101 -> Test Accuracy: 90.7075\n",
      "[102, 60] loss: 0.134\n",
      "[102, 120] loss: 0.132\n",
      "[102, 180] loss: 0.138\n",
      "[102, 240] loss: 0.135\n",
      "[102, 300] loss: 0.138\n",
      "[102, 360] loss: 0.131\n",
      "Epoch: 102 -> Loss: 0.170299351215\n",
      "Epoch: 102 -> Test Accuracy: 91.0175\n",
      "[103, 60] loss: 0.125\n",
      "[103, 120] loss: 0.132\n",
      "[103, 180] loss: 0.142\n",
      "[103, 240] loss: 0.139\n",
      "[103, 300] loss: 0.134\n",
      "[103, 360] loss: 0.140\n",
      "Epoch: 103 -> Loss: 0.210561752319\n",
      "Epoch: 103 -> Test Accuracy: 90.4225\n",
      "[104, 60] loss: 0.127\n",
      "[104, 120] loss: 0.131\n",
      "[104, 180] loss: 0.129\n",
      "[104, 240] loss: 0.132\n",
      "[104, 300] loss: 0.138\n",
      "[104, 360] loss: 0.142\n",
      "Epoch: 104 -> Loss: 0.160425677896\n",
      "Epoch: 104 -> Test Accuracy: 91.01\n",
      "[105, 60] loss: 0.124\n",
      "[105, 120] loss: 0.136\n",
      "[105, 180] loss: 0.129\n",
      "[105, 240] loss: 0.137\n",
      "[105, 300] loss: 0.135\n",
      "[105, 360] loss: 0.150\n",
      "Epoch: 105 -> Loss: 0.128519073129\n",
      "Epoch: 105 -> Test Accuracy: 90.865\n",
      "[106, 60] loss: 0.127\n",
      "[106, 120] loss: 0.125\n",
      "[106, 180] loss: 0.137\n",
      "[106, 240] loss: 0.132\n",
      "[106, 300] loss: 0.137\n",
      "[106, 360] loss: 0.141\n",
      "Epoch: 106 -> Loss: 0.135610595345\n",
      "Epoch: 106 -> Test Accuracy: 90.6275\n",
      "[107, 60] loss: 0.125\n",
      "[107, 120] loss: 0.139\n",
      "[107, 180] loss: 0.135\n",
      "[107, 240] loss: 0.134\n",
      "[107, 300] loss: 0.136\n",
      "[107, 360] loss: 0.145\n",
      "Epoch: 107 -> Loss: 0.0798975527287\n",
      "Epoch: 107 -> Test Accuracy: 91.055\n",
      "[108, 60] loss: 0.127\n",
      "[108, 120] loss: 0.136\n",
      "[108, 180] loss: 0.128\n",
      "[108, 240] loss: 0.136\n",
      "[108, 300] loss: 0.147\n",
      "[108, 360] loss: 0.141\n",
      "Epoch: 108 -> Loss: 0.139369383454\n",
      "Epoch: 108 -> Test Accuracy: 90.8625\n",
      "[109, 60] loss: 0.127\n",
      "[109, 120] loss: 0.127\n",
      "[109, 180] loss: 0.126\n",
      "[109, 240] loss: 0.142\n",
      "[109, 300] loss: 0.142\n",
      "[109, 360] loss: 0.143\n",
      "Epoch: 109 -> Loss: 0.164875671268\n",
      "Epoch: 109 -> Test Accuracy: 90.775\n",
      "[110, 60] loss: 0.120\n",
      "[110, 120] loss: 0.121\n",
      "[110, 180] loss: 0.136\n",
      "[110, 240] loss: 0.138\n",
      "[110, 300] loss: 0.142\n",
      "[110, 360] loss: 0.144\n",
      "Epoch: 110 -> Loss: 0.103205166757\n",
      "Epoch: 110 -> Test Accuracy: 90.935\n",
      "[111, 60] loss: 0.126\n",
      "[111, 120] loss: 0.127\n",
      "[111, 180] loss: 0.127\n",
      "[111, 240] loss: 0.139\n",
      "[111, 300] loss: 0.137\n",
      "[111, 360] loss: 0.134\n",
      "Epoch: 111 -> Loss: 0.0692005455494\n",
      "Epoch: 111 -> Test Accuracy: 91.13\n",
      "[112, 60] loss: 0.127\n",
      "[112, 120] loss: 0.126\n",
      "[112, 180] loss: 0.134\n",
      "[112, 240] loss: 0.136\n",
      "[112, 300] loss: 0.138\n",
      "[112, 360] loss: 0.134\n",
      "Epoch: 112 -> Loss: 0.16101680696\n",
      "Epoch: 112 -> Test Accuracy: 90.7875\n",
      "[113, 60] loss: 0.125\n",
      "[113, 120] loss: 0.125\n",
      "[113, 180] loss: 0.137\n",
      "[113, 240] loss: 0.129\n",
      "[113, 300] loss: 0.135\n",
      "[113, 360] loss: 0.141\n",
      "Epoch: 113 -> Loss: 0.092737480998\n",
      "Epoch: 113 -> Test Accuracy: 90.7075\n",
      "[114, 60] loss: 0.120\n",
      "[114, 120] loss: 0.127\n",
      "[114, 180] loss: 0.129\n",
      "[114, 240] loss: 0.140\n",
      "[114, 300] loss: 0.139\n",
      "[114, 360] loss: 0.131\n",
      "Epoch: 114 -> Loss: 0.122568629682\n",
      "Epoch: 114 -> Test Accuracy: 90.615\n",
      "[115, 60] loss: 0.120\n",
      "[115, 120] loss: 0.132\n",
      "[115, 180] loss: 0.132\n",
      "[115, 240] loss: 0.131\n",
      "[115, 300] loss: 0.131\n",
      "[115, 360] loss: 0.145\n",
      "Epoch: 115 -> Loss: 0.199221611023\n",
      "Epoch: 115 -> Test Accuracy: 90.9\n",
      "[116, 60] loss: 0.125\n",
      "[116, 120] loss: 0.132\n",
      "[116, 180] loss: 0.130\n",
      "[116, 240] loss: 0.128\n",
      "[116, 300] loss: 0.132\n",
      "[116, 360] loss: 0.138\n",
      "Epoch: 116 -> Loss: 0.141703039408\n",
      "Epoch: 116 -> Test Accuracy: 91.2975\n",
      "[117, 60] loss: 0.120\n",
      "[117, 120] loss: 0.137\n",
      "[117, 180] loss: 0.125\n",
      "[117, 240] loss: 0.138\n",
      "[117, 300] loss: 0.136\n",
      "[117, 360] loss: 0.135\n",
      "Epoch: 117 -> Loss: 0.0658210366964\n",
      "Epoch: 117 -> Test Accuracy: 90.6325\n",
      "[118, 60] loss: 0.122\n",
      "[118, 120] loss: 0.126\n",
      "[118, 180] loss: 0.129\n",
      "[118, 240] loss: 0.128\n",
      "[118, 300] loss: 0.133\n",
      "[118, 360] loss: 0.141\n",
      "Epoch: 118 -> Loss: 0.0907624289393\n",
      "Epoch: 118 -> Test Accuracy: 91.1825\n",
      "[119, 60] loss: 0.119\n",
      "[119, 120] loss: 0.123\n",
      "[119, 180] loss: 0.135\n",
      "[119, 240] loss: 0.134\n",
      "[119, 300] loss: 0.133\n",
      "[119, 360] loss: 0.129\n",
      "Epoch: 119 -> Loss: 0.10581485182\n",
      "Epoch: 119 -> Test Accuracy: 91.3175\n",
      "[120, 60] loss: 0.119\n",
      "[120, 120] loss: 0.127\n",
      "[120, 180] loss: 0.136\n",
      "[120, 240] loss: 0.130\n",
      "[120, 300] loss: 0.130\n",
      "[120, 360] loss: 0.130\n",
      "Epoch: 120 -> Loss: 0.238961130381\n",
      "Epoch: 120 -> Test Accuracy: 90.8125\n",
      "[121, 60] loss: 0.095\n",
      "[121, 120] loss: 0.075\n",
      "[121, 180] loss: 0.068\n",
      "[121, 240] loss: 0.074\n",
      "[121, 300] loss: 0.066\n",
      "[121, 360] loss: 0.061\n",
      "Epoch: 121 -> Loss: 0.0300402678549\n",
      "Epoch: 121 -> Test Accuracy: 92.515\n",
      "[122, 60] loss: 0.052\n",
      "[122, 120] loss: 0.053\n",
      "[122, 180] loss: 0.053\n",
      "[122, 240] loss: 0.053\n",
      "[122, 300] loss: 0.053\n",
      "[122, 360] loss: 0.056\n",
      "Epoch: 122 -> Loss: 0.0259395483881\n",
      "Epoch: 122 -> Test Accuracy: 92.64\n",
      "[123, 60] loss: 0.049\n",
      "[123, 120] loss: 0.048\n",
      "[123, 180] loss: 0.047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123, 240] loss: 0.051\n",
      "[123, 300] loss: 0.054\n",
      "[123, 360] loss: 0.046\n",
      "Epoch: 123 -> Loss: 0.0527698472142\n",
      "Epoch: 123 -> Test Accuracy: 92.7\n",
      "[124, 60] loss: 0.045\n",
      "[124, 120] loss: 0.044\n",
      "[124, 180] loss: 0.044\n",
      "[124, 240] loss: 0.041\n",
      "[124, 300] loss: 0.047\n",
      "[124, 360] loss: 0.049\n",
      "Epoch: 124 -> Loss: 0.0209973510355\n",
      "Epoch: 124 -> Test Accuracy: 92.7775\n",
      "[125, 60] loss: 0.044\n",
      "[125, 120] loss: 0.042\n",
      "[125, 180] loss: 0.042\n",
      "[125, 240] loss: 0.040\n",
      "[125, 300] loss: 0.043\n",
      "[125, 360] loss: 0.044\n",
      "Epoch: 125 -> Loss: 0.0214349012822\n",
      "Epoch: 125 -> Test Accuracy: 92.7225\n",
      "[126, 60] loss: 0.039\n",
      "[126, 120] loss: 0.038\n",
      "[126, 180] loss: 0.040\n",
      "[126, 240] loss: 0.039\n",
      "[126, 300] loss: 0.040\n",
      "[126, 360] loss: 0.041\n",
      "Epoch: 126 -> Loss: 0.0385562889278\n",
      "Epoch: 126 -> Test Accuracy: 92.325\n",
      "[127, 60] loss: 0.040\n",
      "[127, 120] loss: 0.039\n",
      "[127, 180] loss: 0.038\n",
      "[127, 240] loss: 0.039\n",
      "[127, 300] loss: 0.037\n",
      "[127, 360] loss: 0.039\n",
      "Epoch: 127 -> Loss: 0.0686577260494\n",
      "Epoch: 127 -> Test Accuracy: 92.385\n",
      "[128, 60] loss: 0.036\n",
      "[128, 120] loss: 0.032\n",
      "[128, 180] loss: 0.037\n",
      "[128, 240] loss: 0.040\n",
      "[128, 300] loss: 0.037\n",
      "[128, 360] loss: 0.036\n",
      "Epoch: 128 -> Loss: 0.0299630463123\n",
      "Epoch: 128 -> Test Accuracy: 92.6425\n",
      "[129, 60] loss: 0.033\n",
      "[129, 120] loss: 0.033\n",
      "[129, 180] loss: 0.034\n",
      "[129, 240] loss: 0.031\n",
      "[129, 300] loss: 0.038\n",
      "[129, 360] loss: 0.035\n",
      "Epoch: 129 -> Loss: 0.0308427158743\n",
      "Epoch: 129 -> Test Accuracy: 92.5925\n",
      "[130, 60] loss: 0.032\n",
      "[130, 120] loss: 0.031\n",
      "[130, 180] loss: 0.033\n",
      "[130, 240] loss: 0.035\n",
      "[130, 300] loss: 0.032\n",
      "[130, 360] loss: 0.035\n",
      "Epoch: 130 -> Loss: 0.00949907582253\n",
      "Epoch: 130 -> Test Accuracy: 92.535\n",
      "[131, 60] loss: 0.033\n",
      "[131, 120] loss: 0.031\n",
      "[131, 180] loss: 0.033\n",
      "[131, 240] loss: 0.032\n",
      "[131, 300] loss: 0.038\n",
      "[131, 360] loss: 0.036\n",
      "Epoch: 131 -> Loss: 0.0374791547656\n",
      "Epoch: 131 -> Test Accuracy: 92.4\n",
      "[132, 60] loss: 0.033\n",
      "[132, 120] loss: 0.030\n",
      "[132, 180] loss: 0.033\n",
      "[132, 240] loss: 0.030\n",
      "[132, 300] loss: 0.032\n",
      "[132, 360] loss: 0.032\n",
      "Epoch: 132 -> Loss: 0.0154404137284\n",
      "Epoch: 132 -> Test Accuracy: 92.425\n",
      "[133, 60] loss: 0.035\n",
      "[133, 120] loss: 0.030\n",
      "[133, 180] loss: 0.032\n",
      "[133, 240] loss: 0.029\n",
      "[133, 300] loss: 0.034\n",
      "[133, 360] loss: 0.034\n",
      "Epoch: 133 -> Loss: 0.023045161739\n",
      "Epoch: 133 -> Test Accuracy: 92.5525\n",
      "[134, 60] loss: 0.030\n",
      "[134, 120] loss: 0.031\n",
      "[134, 180] loss: 0.031\n",
      "[134, 240] loss: 0.029\n",
      "[134, 300] loss: 0.034\n",
      "[134, 360] loss: 0.033\n",
      "Epoch: 134 -> Loss: 0.0226583890617\n",
      "Epoch: 134 -> Test Accuracy: 92.2975\n",
      "[135, 60] loss: 0.035\n",
      "[135, 120] loss: 0.029\n",
      "[135, 180] loss: 0.028\n",
      "[135, 240] loss: 0.027\n",
      "[135, 300] loss: 0.033\n",
      "[135, 360] loss: 0.035\n",
      "Epoch: 135 -> Loss: 0.020358543843\n",
      "Epoch: 135 -> Test Accuracy: 92.355\n",
      "[136, 60] loss: 0.026\n",
      "[136, 120] loss: 0.031\n",
      "[136, 180] loss: 0.031\n",
      "[136, 240] loss: 0.031\n",
      "[136, 300] loss: 0.032\n",
      "[136, 360] loss: 0.036\n",
      "Epoch: 136 -> Loss: 0.061362631619\n",
      "Epoch: 136 -> Test Accuracy: 92.15\n",
      "[137, 60] loss: 0.029\n",
      "[137, 120] loss: 0.030\n",
      "[137, 180] loss: 0.035\n",
      "[137, 240] loss: 0.032\n",
      "[137, 300] loss: 0.030\n",
      "[137, 360] loss: 0.033\n",
      "Epoch: 137 -> Loss: 0.0410382337868\n",
      "Epoch: 137 -> Test Accuracy: 92.645\n",
      "[138, 60] loss: 0.027\n",
      "[138, 120] loss: 0.030\n",
      "[138, 180] loss: 0.032\n",
      "[138, 240] loss: 0.032\n",
      "[138, 300] loss: 0.031\n",
      "[138, 360] loss: 0.032\n",
      "Epoch: 138 -> Loss: 0.0309464540333\n",
      "Epoch: 138 -> Test Accuracy: 92.2425\n",
      "[139, 60] loss: 0.029\n",
      "[139, 120] loss: 0.030\n",
      "[139, 180] loss: 0.030\n",
      "[139, 240] loss: 0.030\n",
      "[139, 300] loss: 0.031\n",
      "[139, 360] loss: 0.032\n",
      "Epoch: 139 -> Loss: 0.0394255518913\n",
      "Epoch: 139 -> Test Accuracy: 92.3425\n",
      "[140, 60] loss: 0.025\n",
      "[140, 120] loss: 0.026\n",
      "[140, 180] loss: 0.030\n",
      "[140, 240] loss: 0.029\n",
      "[140, 300] loss: 0.029\n",
      "[140, 360] loss: 0.034\n",
      "Epoch: 140 -> Loss: 0.0308794472367\n",
      "Epoch: 140 -> Test Accuracy: 92.5\n",
      "[141, 60] loss: 0.025\n",
      "[141, 120] loss: 0.027\n",
      "[141, 180] loss: 0.029\n",
      "[141, 240] loss: 0.029\n",
      "[141, 300] loss: 0.030\n",
      "[141, 360] loss: 0.028\n",
      "Epoch: 141 -> Loss: 0.0604776255786\n",
      "Epoch: 141 -> Test Accuracy: 92.395\n",
      "[142, 60] loss: 0.029\n",
      "[142, 120] loss: 0.030\n",
      "[142, 180] loss: 0.033\n",
      "[142, 240] loss: 0.034\n",
      "[142, 300] loss: 0.031\n",
      "[142, 360] loss: 0.031\n",
      "Epoch: 142 -> Loss: 0.0340551249683\n",
      "Epoch: 142 -> Test Accuracy: 92.4275\n",
      "[143, 60] loss: 0.026\n",
      "[143, 120] loss: 0.028\n",
      "[143, 180] loss: 0.028\n",
      "[143, 240] loss: 0.030\n",
      "[143, 300] loss: 0.031\n",
      "[143, 360] loss: 0.035\n",
      "Epoch: 143 -> Loss: 0.0440046042204\n",
      "Epoch: 143 -> Test Accuracy: 92.28\n",
      "[144, 60] loss: 0.027\n",
      "[144, 120] loss: 0.025\n",
      "[144, 180] loss: 0.030\n",
      "[144, 240] loss: 0.030\n",
      "[144, 300] loss: 0.030\n",
      "[144, 360] loss: 0.031\n",
      "Epoch: 144 -> Loss: 0.0198750421405\n",
      "Epoch: 144 -> Test Accuracy: 92.5525\n",
      "[145, 60] loss: 0.024\n",
      "[145, 120] loss: 0.030\n",
      "[145, 180] loss: 0.029\n",
      "[145, 240] loss: 0.029\n",
      "[145, 300] loss: 0.031\n",
      "[145, 360] loss: 0.030\n",
      "Epoch: 145 -> Loss: 0.0194340758026\n",
      "Epoch: 145 -> Test Accuracy: 92.165\n",
      "[146, 60] loss: 0.029\n",
      "[146, 120] loss: 0.026\n",
      "[146, 180] loss: 0.029\n",
      "[146, 240] loss: 0.028\n",
      "[146, 300] loss: 0.032\n",
      "[146, 360] loss: 0.031\n",
      "Epoch: 146 -> Loss: 0.0197206251323\n",
      "Epoch: 146 -> Test Accuracy: 92.3475\n",
      "[147, 60] loss: 0.027\n",
      "[147, 120] loss: 0.025\n",
      "[147, 180] loss: 0.027\n",
      "[147, 240] loss: 0.031\n",
      "[147, 300] loss: 0.032\n",
      "[147, 360] loss: 0.031\n",
      "Epoch: 147 -> Loss: 0.0866356343031\n",
      "Epoch: 147 -> Test Accuracy: 92.4275\n",
      "[148, 60] loss: 0.029\n",
      "[148, 120] loss: 0.028\n",
      "[148, 180] loss: 0.032\n",
      "[148, 240] loss: 0.034\n",
      "[148, 300] loss: 0.029\n",
      "[148, 360] loss: 0.028\n",
      "Epoch: 148 -> Loss: 0.0319078341126\n",
      "Epoch: 148 -> Test Accuracy: 92.44\n",
      "[149, 60] loss: 0.026\n",
      "[149, 120] loss: 0.029\n",
      "[149, 180] loss: 0.026\n",
      "[149, 240] loss: 0.028\n",
      "[149, 300] loss: 0.029\n",
      "[149, 360] loss: 0.030\n",
      "Epoch: 149 -> Loss: 0.0358081944287\n",
      "Epoch: 149 -> Test Accuracy: 92.47\n",
      "[150, 60] loss: 0.027\n",
      "[150, 120] loss: 0.029\n",
      "[150, 180] loss: 0.031\n",
      "[150, 240] loss: 0.031\n",
      "[150, 300] loss: 0.028\n",
      "[150, 360] loss: 0.033\n",
      "Epoch: 150 -> Loss: 0.0283063240349\n",
      "Epoch: 150 -> Test Accuracy: 92.2825\n",
      "[151, 60] loss: 0.031\n",
      "[151, 120] loss: 0.027\n",
      "[151, 180] loss: 0.031\n",
      "[151, 240] loss: 0.032\n",
      "[151, 300] loss: 0.029\n",
      "[151, 360] loss: 0.030\n",
      "Epoch: 151 -> Loss: 0.0256258491427\n",
      "Epoch: 151 -> Test Accuracy: 92.065\n",
      "[152, 60] loss: 0.029\n",
      "[152, 120] loss: 0.026\n",
      "[152, 180] loss: 0.027\n",
      "[152, 240] loss: 0.028\n",
      "[152, 300] loss: 0.032\n",
      "[152, 360] loss: 0.032\n",
      "Epoch: 152 -> Loss: 0.021416598931\n",
      "Epoch: 152 -> Test Accuracy: 92.18\n",
      "[153, 60] loss: 0.026\n",
      "[153, 120] loss: 0.023\n",
      "[153, 180] loss: 0.033\n",
      "[153, 240] loss: 0.034\n",
      "[153, 300] loss: 0.031\n",
      "[153, 360] loss: 0.030\n",
      "Epoch: 153 -> Loss: 0.0278048813343\n",
      "Epoch: 153 -> Test Accuracy: 92.2725\n",
      "[154, 60] loss: 0.032\n",
      "[154, 120] loss: 0.026\n",
      "[154, 180] loss: 0.030\n",
      "[154, 240] loss: 0.027\n",
      "[154, 300] loss: 0.033\n",
      "[154, 360] loss: 0.033\n",
      "Epoch: 154 -> Loss: 0.0197122395039\n",
      "Epoch: 154 -> Test Accuracy: 92.5175\n",
      "[155, 60] loss: 0.026\n",
      "[155, 120] loss: 0.028\n",
      "[155, 180] loss: 0.029\n",
      "[155, 240] loss: 0.028\n",
      "[155, 300] loss: 0.031\n",
      "[155, 360] loss: 0.035\n",
      "Epoch: 155 -> Loss: 0.0445013940334\n",
      "Epoch: 155 -> Test Accuracy: 92.1975\n",
      "[156, 60] loss: 0.027\n",
      "[156, 120] loss: 0.030\n",
      "[156, 180] loss: 0.028\n",
      "[156, 240] loss: 0.033\n",
      "[156, 300] loss: 0.033\n",
      "[156, 360] loss: 0.029\n",
      "Epoch: 156 -> Loss: 0.0124058425426\n",
      "Epoch: 156 -> Test Accuracy: 92.15\n",
      "[157, 60] loss: 0.027\n",
      "[157, 120] loss: 0.029\n",
      "[157, 180] loss: 0.033\n",
      "[157, 240] loss: 0.032\n",
      "[157, 300] loss: 0.030\n",
      "[157, 360] loss: 0.033\n",
      "Epoch: 157 -> Loss: 0.0752840861678\n",
      "Epoch: 157 -> Test Accuracy: 92.0425\n",
      "[158, 60] loss: 0.029\n",
      "[158, 120] loss: 0.029\n",
      "[158, 180] loss: 0.029\n",
      "[158, 240] loss: 0.033\n",
      "[158, 300] loss: 0.034\n",
      "[158, 360] loss: 0.034\n",
      "Epoch: 158 -> Loss: 0.0160301905125\n",
      "Epoch: 158 -> Test Accuracy: 92.1275\n",
      "[159, 60] loss: 0.026\n",
      "[159, 120] loss: 0.028\n",
      "[159, 180] loss: 0.027\n",
      "[159, 240] loss: 0.030\n",
      "[159, 300] loss: 0.030\n",
      "[159, 360] loss: 0.033\n",
      "Epoch: 159 -> Loss: 0.0490647554398\n",
      "Epoch: 159 -> Test Accuracy: 92.005\n",
      "[160, 60] loss: 0.028\n",
      "[160, 120] loss: 0.035\n",
      "[160, 180] loss: 0.032\n",
      "[160, 240] loss: 0.032\n",
      "[160, 300] loss: 0.028\n",
      "[160, 360] loss: 0.034\n",
      "Epoch: 160 -> Loss: 0.0106905037537\n",
      "Epoch: 160 -> Test Accuracy: 92.15\n",
      "[161, 60] loss: 0.023\n",
      "[161, 120] loss: 0.020\n",
      "[161, 180] loss: 0.021\n",
      "[161, 240] loss: 0.019\n",
      "[161, 300] loss: 0.016\n",
      "[161, 360] loss: 0.016\n",
      "Epoch: 161 -> Loss: 0.0122965117916\n",
      "Epoch: 161 -> Test Accuracy: 92.6475\n",
      "[162, 60] loss: 0.012\n",
      "[162, 120] loss: 0.015\n",
      "[162, 180] loss: 0.012\n",
      "[162, 240] loss: 0.012\n",
      "[162, 300] loss: 0.011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[162, 360] loss: 0.015\n",
      "Epoch: 162 -> Loss: 0.00450548902154\n",
      "Epoch: 162 -> Test Accuracy: 92.6825\n",
      "[163, 60] loss: 0.010\n",
      "[163, 120] loss: 0.011\n",
      "[163, 180] loss: 0.012\n",
      "[163, 240] loss: 0.013\n",
      "[163, 300] loss: 0.013\n",
      "[163, 360] loss: 0.011\n",
      "Epoch: 163 -> Loss: 0.0176093392074\n",
      "Epoch: 163 -> Test Accuracy: 92.8325\n",
      "[164, 60] loss: 0.011\n",
      "[164, 120] loss: 0.008\n",
      "[164, 180] loss: 0.010\n",
      "[164, 240] loss: 0.013\n",
      "[164, 300] loss: 0.010\n",
      "[164, 360] loss: 0.012\n",
      "Epoch: 164 -> Loss: 0.003097954439\n",
      "Epoch: 164 -> Test Accuracy: 92.9225\n",
      "[165, 60] loss: 0.010\n",
      "[165, 120] loss: 0.009\n",
      "[165, 180] loss: 0.011\n",
      "[165, 240] loss: 0.009\n",
      "[165, 300] loss: 0.010\n",
      "[165, 360] loss: 0.009\n",
      "Epoch: 165 -> Loss: 0.0143561018631\n",
      "Epoch: 165 -> Test Accuracy: 92.845\n",
      "[166, 60] loss: 0.009\n",
      "[166, 120] loss: 0.009\n",
      "[166, 180] loss: 0.010\n",
      "[166, 240] loss: 0.009\n",
      "[166, 300] loss: 0.009\n",
      "[166, 360] loss: 0.008\n",
      "Epoch: 166 -> Loss: 0.00884181819856\n",
      "Epoch: 166 -> Test Accuracy: 92.8525\n",
      "[167, 60] loss: 0.009\n",
      "[167, 120] loss: 0.008\n",
      "[167, 180] loss: 0.009\n",
      "[167, 240] loss: 0.008\n",
      "[167, 300] loss: 0.008\n",
      "[167, 360] loss: 0.008\n",
      "Epoch: 167 -> Loss: 0.00783673767\n",
      "Epoch: 167 -> Test Accuracy: 92.8875\n",
      "[168, 60] loss: 0.008\n",
      "[168, 120] loss: 0.008\n",
      "[168, 180] loss: 0.007\n",
      "[168, 240] loss: 0.007\n",
      "[168, 300] loss: 0.009\n",
      "[168, 360] loss: 0.008\n",
      "Epoch: 168 -> Loss: 0.00417258497328\n",
      "Epoch: 168 -> Test Accuracy: 92.7225\n",
      "[169, 60] loss: 0.007\n",
      "[169, 120] loss: 0.008\n",
      "[169, 180] loss: 0.008\n",
      "[169, 240] loss: 0.007\n",
      "[169, 300] loss: 0.008\n",
      "[169, 360] loss: 0.008\n",
      "Epoch: 169 -> Loss: 0.00873354170471\n",
      "Epoch: 169 -> Test Accuracy: 92.8225\n",
      "[170, 60] loss: 0.007\n",
      "[170, 120] loss: 0.008\n",
      "[170, 180] loss: 0.007\n",
      "[170, 240] loss: 0.007\n",
      "[170, 300] loss: 0.006\n",
      "[170, 360] loss: 0.006\n",
      "Epoch: 170 -> Loss: 0.00229204003699\n",
      "Epoch: 170 -> Test Accuracy: 92.85\n",
      "[171, 60] loss: 0.007\n",
      "[171, 120] loss: 0.006\n",
      "[171, 180] loss: 0.008\n",
      "[171, 240] loss: 0.006\n",
      "[171, 300] loss: 0.008\n",
      "[171, 360] loss: 0.007\n",
      "Epoch: 171 -> Loss: 0.00241260230541\n",
      "Epoch: 171 -> Test Accuracy: 92.915\n",
      "[172, 60] loss: 0.007\n",
      "[172, 120] loss: 0.006\n",
      "[172, 180] loss: 0.006\n",
      "[172, 240] loss: 0.007\n",
      "[172, 300] loss: 0.006\n",
      "[172, 360] loss: 0.009\n",
      "Epoch: 172 -> Loss: 0.00679887551814\n",
      "Epoch: 172 -> Test Accuracy: 92.7675\n",
      "[173, 60] loss: 0.005\n",
      "[173, 120] loss: 0.006\n",
      "[173, 180] loss: 0.006\n",
      "[173, 240] loss: 0.008\n",
      "[173, 300] loss: 0.007\n",
      "[173, 360] loss: 0.008\n",
      "Epoch: 173 -> Loss: 0.00716267898679\n",
      "Epoch: 173 -> Test Accuracy: 92.87\n",
      "[174, 60] loss: 0.006\n",
      "[174, 120] loss: 0.008\n",
      "[174, 180] loss: 0.007\n",
      "[174, 240] loss: 0.008\n",
      "[174, 300] loss: 0.007\n",
      "[174, 360] loss: 0.007\n",
      "Epoch: 174 -> Loss: 0.0012970417738\n",
      "Epoch: 174 -> Test Accuracy: 92.8975\n",
      "[175, 60] loss: 0.006\n",
      "[175, 120] loss: 0.006\n",
      "[175, 180] loss: 0.006\n",
      "[175, 240] loss: 0.007\n",
      "[175, 300] loss: 0.006\n",
      "[175, 360] loss: 0.006\n",
      "Epoch: 175 -> Loss: 0.00364546990022\n",
      "Epoch: 175 -> Test Accuracy: 92.965\n",
      "[176, 60] loss: 0.006\n",
      "[176, 120] loss: 0.007\n",
      "[176, 180] loss: 0.006\n",
      "[176, 240] loss: 0.005\n",
      "[176, 300] loss: 0.006\n",
      "[176, 360] loss: 0.007\n",
      "Epoch: 176 -> Loss: 0.00232273410074\n",
      "Epoch: 176 -> Test Accuracy: 92.8775\n",
      "[177, 60] loss: 0.007\n",
      "[177, 120] loss: 0.006\n",
      "[177, 180] loss: 0.006\n",
      "[177, 240] loss: 0.007\n",
      "[177, 300] loss: 0.006\n",
      "[177, 360] loss: 0.006\n",
      "Epoch: 177 -> Loss: 0.0100824115798\n",
      "Epoch: 177 -> Test Accuracy: 92.8975\n",
      "[178, 60] loss: 0.006\n",
      "[178, 120] loss: 0.006\n",
      "[178, 180] loss: 0.005\n",
      "[178, 240] loss: 0.006\n",
      "[178, 300] loss: 0.005\n",
      "[178, 360] loss: 0.006\n",
      "Epoch: 178 -> Loss: 0.00211971998215\n",
      "Epoch: 178 -> Test Accuracy: 92.825\n",
      "[179, 60] loss: 0.007\n",
      "[179, 120] loss: 0.006\n",
      "[179, 180] loss: 0.007\n",
      "[179, 240] loss: 0.006\n",
      "[179, 300] loss: 0.006\n",
      "[179, 360] loss: 0.006\n",
      "Epoch: 179 -> Loss: 0.00143962202128\n",
      "Epoch: 179 -> Test Accuracy: 92.9475\n",
      "[180, 60] loss: 0.006\n",
      "[180, 120] loss: 0.006\n",
      "[180, 180] loss: 0.006\n",
      "[180, 240] loss: 0.005\n",
      "[180, 300] loss: 0.008\n",
      "[180, 360] loss: 0.005\n",
      "Epoch: 180 -> Loss: 0.0135680567473\n",
      "Epoch: 180 -> Test Accuracy: 92.93\n",
      "[181, 60] loss: 0.004\n",
      "[181, 120] loss: 0.006\n",
      "[181, 180] loss: 0.005\n",
      "[181, 240] loss: 0.005\n",
      "[181, 300] loss: 0.005\n",
      "[181, 360] loss: 0.007\n",
      "Epoch: 181 -> Loss: 0.00156322645489\n",
      "Epoch: 181 -> Test Accuracy: 92.8525\n",
      "[182, 60] loss: 0.005\n",
      "[182, 120] loss: 0.005\n",
      "[182, 180] loss: 0.006\n",
      "[182, 240] loss: 0.005\n",
      "[182, 300] loss: 0.007\n",
      "[182, 360] loss: 0.006\n",
      "Epoch: 182 -> Loss: 0.00645119976252\n",
      "Epoch: 182 -> Test Accuracy: 92.825\n",
      "[183, 60] loss: 0.005\n",
      "[183, 120] loss: 0.004\n",
      "[183, 180] loss: 0.006\n",
      "[183, 240] loss: 0.005\n",
      "[183, 300] loss: 0.005\n",
      "[183, 360] loss: 0.005\n",
      "Epoch: 183 -> Loss: 0.00355304102413\n",
      "Epoch: 183 -> Test Accuracy: 92.8725\n",
      "[184, 60] loss: 0.005\n",
      "[184, 120] loss: 0.006\n",
      "[184, 180] loss: 0.005\n",
      "[184, 240] loss: 0.008\n",
      "[184, 300] loss: 0.006\n",
      "[184, 360] loss: 0.005\n",
      "Epoch: 184 -> Loss: 0.00769839668646\n",
      "Epoch: 184 -> Test Accuracy: 92.85\n",
      "[185, 60] loss: 0.004\n",
      "[185, 120] loss: 0.006\n",
      "[185, 180] loss: 0.005\n",
      "[185, 240] loss: 0.004\n",
      "[185, 300] loss: 0.005\n",
      "[185, 360] loss: 0.005\n",
      "Epoch: 185 -> Loss: 0.00400306237862\n",
      "Epoch: 185 -> Test Accuracy: 92.795\n",
      "[186, 60] loss: 0.005\n",
      "[186, 120] loss: 0.005\n",
      "[186, 180] loss: 0.006\n",
      "[186, 240] loss: 0.005\n",
      "[186, 300] loss: 0.005\n",
      "[186, 360] loss: 0.006\n",
      "Epoch: 186 -> Loss: 0.00528923189268\n",
      "Epoch: 186 -> Test Accuracy: 92.835\n",
      "[187, 60] loss: 0.005\n",
      "[187, 120] loss: 0.005\n",
      "[187, 180] loss: 0.005\n",
      "[187, 240] loss: 0.005\n",
      "[187, 300] loss: 0.005\n",
      "[187, 360] loss: 0.005\n",
      "Epoch: 187 -> Loss: 0.00128426251467\n",
      "Epoch: 187 -> Test Accuracy: 92.9075\n",
      "[188, 60] loss: 0.005\n",
      "[188, 120] loss: 0.005\n",
      "[188, 180] loss: 0.005\n",
      "[188, 240] loss: 0.006\n",
      "[188, 300] loss: 0.006\n",
      "[188, 360] loss: 0.005\n",
      "Epoch: 188 -> Loss: 0.00146972236689\n",
      "Epoch: 188 -> Test Accuracy: 92.875\n",
      "[189, 60] loss: 0.005\n",
      "[189, 120] loss: 0.005\n",
      "[189, 180] loss: 0.005\n",
      "[189, 240] loss: 0.005\n",
      "[189, 300] loss: 0.004\n",
      "[189, 360] loss: 0.005\n",
      "Epoch: 189 -> Loss: 0.00285239890218\n",
      "Epoch: 189 -> Test Accuracy: 92.88\n",
      "[190, 60] loss: 0.005\n",
      "[190, 120] loss: 0.005\n",
      "[190, 180] loss: 0.005\n",
      "[190, 240] loss: 0.005\n",
      "[190, 300] loss: 0.005\n",
      "[190, 360] loss: 0.006\n",
      "Epoch: 190 -> Loss: 0.0287873260677\n",
      "Epoch: 190 -> Test Accuracy: 92.82\n",
      "[191, 60] loss: 0.005\n",
      "[191, 120] loss: 0.004\n",
      "[191, 180] loss: 0.005\n",
      "[191, 240] loss: 0.005\n",
      "[191, 300] loss: 0.005\n",
      "[191, 360] loss: 0.004\n",
      "Epoch: 191 -> Loss: 0.00185106915887\n",
      "Epoch: 191 -> Test Accuracy: 92.9125\n",
      "[192, 60] loss: 0.005\n",
      "[192, 120] loss: 0.005\n",
      "[192, 180] loss: 0.006\n",
      "[192, 240] loss: 0.005\n",
      "[192, 300] loss: 0.005\n",
      "[192, 360] loss: 0.004\n",
      "Epoch: 192 -> Loss: 0.00361132854596\n",
      "Epoch: 192 -> Test Accuracy: 92.82\n",
      "[193, 60] loss: 0.004\n",
      "[193, 120] loss: 0.005\n",
      "[193, 180] loss: 0.005\n",
      "[193, 240] loss: 0.005\n",
      "[193, 300] loss: 0.005\n",
      "[193, 360] loss: 0.005\n",
      "Epoch: 193 -> Loss: 0.00177018193062\n",
      "Epoch: 193 -> Test Accuracy: 92.7725\n",
      "[194, 60] loss: 0.005\n",
      "[194, 120] loss: 0.005\n",
      "[194, 180] loss: 0.004\n",
      "[194, 240] loss: 0.005\n",
      "[194, 300] loss: 0.005\n",
      "[194, 360] loss: 0.005\n",
      "Epoch: 194 -> Loss: 0.00225330586545\n",
      "Epoch: 194 -> Test Accuracy: 92.7375\n",
      "[195, 60] loss: 0.005\n",
      "[195, 120] loss: 0.005\n",
      "[195, 180] loss: 0.004\n",
      "[195, 240] loss: 0.005\n",
      "[195, 300] loss: 0.006\n",
      "[195, 360] loss: 0.005\n",
      "Epoch: 195 -> Loss: 0.000794994819444\n",
      "Epoch: 195 -> Test Accuracy: 92.85\n",
      "[196, 60] loss: 0.004\n",
      "[196, 120] loss: 0.004\n",
      "[196, 180] loss: 0.005\n",
      "[196, 240] loss: 0.005\n",
      "[196, 300] loss: 0.004\n",
      "[196, 360] loss: 0.005\n",
      "Epoch: 196 -> Loss: 0.00280061620288\n",
      "Epoch: 196 -> Test Accuracy: 92.795\n",
      "[197, 60] loss: 0.005\n",
      "[197, 120] loss: 0.006\n",
      "[197, 180] loss: 0.004\n",
      "[197, 240] loss: 0.005\n",
      "[197, 300] loss: 0.004\n",
      "[197, 360] loss: 0.005\n",
      "Epoch: 197 -> Loss: 0.0209960192442\n",
      "Epoch: 197 -> Test Accuracy: 92.8575\n",
      "[198, 60] loss: 0.005\n",
      "[198, 120] loss: 0.004\n",
      "[198, 180] loss: 0.005\n",
      "[198, 240] loss: 0.005\n",
      "[198, 300] loss: 0.005\n",
      "[198, 360] loss: 0.005\n",
      "Epoch: 198 -> Loss: 0.000845921051223\n",
      "Epoch: 198 -> Test Accuracy: 92.7475\n",
      "[199, 60] loss: 0.004\n",
      "[199, 120] loss: 0.006\n",
      "[199, 180] loss: 0.005\n",
      "[199, 240] loss: 0.005\n",
      "[199, 300] loss: 0.005\n",
      "[199, 360] loss: 0.004\n",
      "Epoch: 199 -> Loss: 0.00273622875102\n",
      "Epoch: 199 -> Test Accuracy: 92.8075\n",
      "[200, 60] loss: 0.005\n",
      "[200, 120] loss: 0.004\n",
      "[200, 180] loss: 0.004\n",
      "[200, 240] loss: 0.006\n",
      "[200, 300] loss: 0.004\n",
      "[200, 360] loss: 0.004\n",
      "Epoch: 200 -> Loss: 0.0029211237561\n",
      "Epoch: 200 -> Test Accuracy: 92.7525\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "rot_block5_avg_loss_log, rot_block5_avg_valid_accuracy_log, rot_block5_avg_test_accuracy_log, \\\n",
    "rot_block5_avg_max_accuracy, rot_block5_avg_best_epoch = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], \n",
    "    [60, 120, 160, 200], 0.9, 5e-4, net_block5_avg, criterion, trainloader, None, testloader, rot=['90', '180', '270'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 2.264\n",
      "[1, 120] loss: 1.241\n",
      "[1, 180] loss: 1.141\n",
      "[1, 240] loss: 1.071\n",
      "[1, 300] loss: 1.040\n",
      "[1, 360] loss: 1.011\n",
      "Epoch: 1 -> Loss: 0.947250187397\n",
      "Epoch: 1 -> Test Accuracy: 66.71\n",
      "[2, 60] loss: 0.952\n",
      "[2, 120] loss: 0.938\n",
      "[2, 180] loss: 0.928\n",
      "[2, 240] loss: 0.899\n",
      "[2, 300] loss: 0.897\n",
      "[2, 360] loss: 0.879\n",
      "Epoch: 2 -> Loss: 0.780076682568\n",
      "Epoch: 2 -> Test Accuracy: 71.74\n",
      "[3, 60] loss: 0.853\n",
      "[3, 120] loss: 0.831\n",
      "[3, 180] loss: 0.838\n",
      "[3, 240] loss: 0.812\n",
      "[3, 300] loss: 0.790\n",
      "[3, 360] loss: 0.811\n",
      "Epoch: 3 -> Loss: 0.728461623192\n",
      "Epoch: 3 -> Test Accuracy: 73.05\n",
      "[4, 60] loss: 0.785\n",
      "[4, 120] loss: 0.785\n",
      "[4, 180] loss: 0.761\n",
      "[4, 240] loss: 0.768\n",
      "[4, 300] loss: 0.757\n",
      "[4, 360] loss: 0.740\n",
      "Epoch: 4 -> Loss: 0.887087702751\n",
      "Epoch: 4 -> Test Accuracy: 74.92\n",
      "[5, 60] loss: 0.733\n",
      "[5, 120] loss: 0.740\n",
      "[5, 180] loss: 0.737\n",
      "[5, 240] loss: 0.762\n",
      "[5, 300] loss: 0.719\n",
      "[5, 360] loss: 0.705\n",
      "Epoch: 5 -> Loss: 0.714845299721\n",
      "Epoch: 5 -> Test Accuracy: 75.86\n",
      "[6, 60] loss: 0.698\n",
      "[6, 120] loss: 0.730\n",
      "[6, 180] loss: 0.700\n",
      "[6, 240] loss: 0.708\n",
      "[6, 300] loss: 0.709\n",
      "[6, 360] loss: 0.700\n",
      "Epoch: 6 -> Loss: 0.733296453953\n",
      "Epoch: 6 -> Test Accuracy: 76.63\n",
      "[7, 60] loss: 0.686\n",
      "[7, 120] loss: 0.674\n",
      "[7, 180] loss: 0.693\n",
      "[7, 240] loss: 0.681\n",
      "[7, 300] loss: 0.686\n",
      "[7, 360] loss: 0.702\n",
      "Epoch: 7 -> Loss: 0.545740842819\n",
      "Epoch: 7 -> Test Accuracy: 76.88\n",
      "[8, 60] loss: 0.651\n",
      "[8, 120] loss: 0.641\n",
      "[8, 180] loss: 0.676\n",
      "[8, 240] loss: 0.678\n",
      "[8, 300] loss: 0.687\n",
      "[8, 360] loss: 0.683\n",
      "Epoch: 8 -> Loss: 0.751765906811\n",
      "Epoch: 8 -> Test Accuracy: 77.53\n",
      "[9, 60] loss: 0.658\n",
      "[9, 120] loss: 0.659\n",
      "[9, 180] loss: 0.686\n",
      "[9, 240] loss: 0.648\n",
      "[9, 300] loss: 0.663\n",
      "[9, 360] loss: 0.670\n",
      "Epoch: 9 -> Loss: 0.578593850136\n",
      "Epoch: 9 -> Test Accuracy: 77.48\n",
      "[10, 60] loss: 0.637\n",
      "[10, 120] loss: 0.646\n",
      "[10, 180] loss: 0.636\n",
      "[10, 240] loss: 0.658\n",
      "[10, 300] loss: 0.642\n",
      "[10, 360] loss: 0.659\n",
      "Epoch: 10 -> Loss: 0.550889670849\n",
      "Epoch: 10 -> Test Accuracy: 77.09\n",
      "[11, 60] loss: 0.623\n",
      "[11, 120] loss: 0.658\n",
      "[11, 180] loss: 0.636\n",
      "[11, 240] loss: 0.661\n",
      "[11, 300] loss: 0.647\n",
      "[11, 360] loss: 0.629\n",
      "Epoch: 11 -> Loss: 0.764778852463\n",
      "Epoch: 11 -> Test Accuracy: 78.48\n",
      "[12, 60] loss: 0.626\n",
      "[12, 120] loss: 0.635\n",
      "[12, 180] loss: 0.654\n",
      "[12, 240] loss: 0.634\n",
      "[12, 300] loss: 0.633\n",
      "[12, 360] loss: 0.645\n",
      "Epoch: 12 -> Loss: 0.493833065033\n",
      "Epoch: 12 -> Test Accuracy: 76.89\n",
      "[13, 60] loss: 0.632\n",
      "[13, 120] loss: 0.613\n",
      "[13, 180] loss: 0.635\n",
      "[13, 240] loss: 0.650\n",
      "[13, 300] loss: 0.631\n",
      "[13, 360] loss: 0.626\n",
      "Epoch: 13 -> Loss: 0.695801973343\n",
      "Epoch: 13 -> Test Accuracy: 78.18\n",
      "[14, 60] loss: 0.615\n",
      "[14, 120] loss: 0.626\n",
      "[14, 180] loss: 0.605\n",
      "[14, 240] loss: 0.624\n",
      "[14, 300] loss: 0.640\n",
      "[14, 360] loss: 0.639\n",
      "Epoch: 14 -> Loss: 0.7085262537\n",
      "Epoch: 14 -> Test Accuracy: 77.48\n",
      "[15, 60] loss: 0.617\n",
      "[15, 120] loss: 0.628\n",
      "[15, 180] loss: 0.607\n",
      "[15, 240] loss: 0.613\n",
      "[15, 300] loss: 0.650\n",
      "[15, 360] loss: 0.622\n",
      "Epoch: 15 -> Loss: 0.514986395836\n",
      "Epoch: 15 -> Test Accuracy: 77.09\n",
      "[16, 60] loss: 0.604\n",
      "[16, 120] loss: 0.607\n",
      "[16, 180] loss: 0.622\n",
      "[16, 240] loss: 0.631\n",
      "[16, 300] loss: 0.634\n",
      "[16, 360] loss: 0.626\n",
      "Epoch: 16 -> Loss: 0.504911720753\n",
      "Epoch: 16 -> Test Accuracy: 79.0\n",
      "[17, 60] loss: 0.616\n",
      "[17, 120] loss: 0.609\n",
      "[17, 180] loss: 0.626\n",
      "[17, 240] loss: 0.635\n",
      "[17, 300] loss: 0.607\n",
      "[17, 360] loss: 0.616\n",
      "Epoch: 17 -> Loss: 0.776605129242\n",
      "Epoch: 17 -> Test Accuracy: 78.49\n",
      "[18, 60] loss: 0.594\n",
      "[18, 120] loss: 0.609\n",
      "[18, 180] loss: 0.619\n",
      "[18, 240] loss: 0.597\n",
      "[18, 300] loss: 0.639\n",
      "[18, 360] loss: 0.618\n",
      "Epoch: 18 -> Loss: 0.44218069315\n",
      "Epoch: 18 -> Test Accuracy: 78.77\n",
      "[19, 60] loss: 0.582\n",
      "[19, 120] loss: 0.613\n",
      "[19, 180] loss: 0.591\n",
      "[19, 240] loss: 0.625\n",
      "[19, 300] loss: 0.613\n",
      "[19, 360] loss: 0.630\n",
      "Epoch: 19 -> Loss: 0.568243980408\n",
      "Epoch: 19 -> Test Accuracy: 77.96\n",
      "[20, 60] loss: 0.597\n",
      "[20, 120] loss: 0.608\n",
      "[20, 180] loss: 0.608\n",
      "[20, 240] loss: 0.618\n",
      "[20, 300] loss: 0.603\n",
      "[20, 360] loss: 0.614\n",
      "Epoch: 20 -> Loss: 0.565756201744\n",
      "Epoch: 20 -> Test Accuracy: 78.08\n",
      "[21, 60] loss: 0.547\n",
      "[21, 120] loss: 0.516\n",
      "[21, 180] loss: 0.534\n",
      "[21, 240] loss: 0.513\n",
      "[21, 300] loss: 0.485\n",
      "[21, 360] loss: 0.496\n",
      "Epoch: 21 -> Loss: 0.429677665234\n",
      "Epoch: 21 -> Test Accuracy: 81.13\n",
      "[22, 60] loss: 0.499\n",
      "[22, 120] loss: 0.457\n",
      "[22, 180] loss: 0.485\n",
      "[22, 240] loss: 0.484\n",
      "[22, 300] loss: 0.468\n",
      "[22, 360] loss: 0.461\n",
      "Epoch: 22 -> Loss: 0.581822395325\n",
      "Epoch: 22 -> Test Accuracy: 81.71\n",
      "[23, 60] loss: 0.447\n",
      "[23, 120] loss: 0.461\n",
      "[23, 180] loss: 0.465\n",
      "[23, 240] loss: 0.453\n",
      "[23, 300] loss: 0.471\n",
      "[23, 360] loss: 0.469\n",
      "Epoch: 23 -> Loss: 0.44543632865\n",
      "Epoch: 23 -> Test Accuracy: 81.53\n",
      "[24, 60] loss: 0.440\n",
      "[24, 120] loss: 0.440\n",
      "[24, 180] loss: 0.443\n",
      "[24, 240] loss: 0.452\n",
      "[24, 300] loss: 0.435\n",
      "[24, 360] loss: 0.443\n",
      "Epoch: 24 -> Loss: 0.362554132938\n",
      "Epoch: 24 -> Test Accuracy: 81.85\n",
      "[25, 60] loss: 0.424\n",
      "[25, 120] loss: 0.436\n",
      "[25, 180] loss: 0.440\n",
      "[25, 240] loss: 0.437\n",
      "[25, 300] loss: 0.441\n",
      "[25, 360] loss: 0.438\n",
      "Epoch: 25 -> Loss: 0.376008927822\n",
      "Epoch: 25 -> Test Accuracy: 81.67\n",
      "[26, 60] loss: 0.415\n",
      "[26, 120] loss: 0.410\n",
      "[26, 180] loss: 0.420\n",
      "[26, 240] loss: 0.419\n",
      "[26, 300] loss: 0.434\n",
      "[26, 360] loss: 0.453\n",
      "Epoch: 26 -> Loss: 0.448520362377\n",
      "Epoch: 26 -> Test Accuracy: 82.16\n",
      "[27, 60] loss: 0.423\n",
      "[27, 120] loss: 0.433\n",
      "[27, 180] loss: 0.419\n",
      "[27, 240] loss: 0.422\n",
      "[27, 300] loss: 0.422\n",
      "[27, 360] loss: 0.437\n",
      "Epoch: 27 -> Loss: 0.331872880459\n",
      "Epoch: 27 -> Test Accuracy: 81.96\n",
      "[28, 60] loss: 0.411\n",
      "[28, 120] loss: 0.400\n",
      "[28, 180] loss: 0.428\n",
      "[28, 240] loss: 0.424\n",
      "[28, 300] loss: 0.427\n",
      "[28, 360] loss: 0.418\n",
      "Epoch: 28 -> Loss: 0.395055383444\n",
      "Epoch: 28 -> Test Accuracy: 81.9\n",
      "[29, 60] loss: 0.413\n",
      "[29, 120] loss: 0.398\n",
      "[29, 180] loss: 0.413\n",
      "[29, 240] loss: 0.415\n",
      "[29, 300] loss: 0.419\n",
      "[29, 360] loss: 0.418\n",
      "Epoch: 29 -> Loss: 0.299553990364\n",
      "Epoch: 29 -> Test Accuracy: 82.32\n",
      "[30, 60] loss: 0.401\n",
      "[30, 120] loss: 0.415\n",
      "[30, 180] loss: 0.408\n",
      "[30, 240] loss: 0.387\n",
      "[30, 300] loss: 0.398\n",
      "[30, 360] loss: 0.422\n",
      "Epoch: 30 -> Loss: 0.481783002615\n",
      "Epoch: 30 -> Test Accuracy: 81.7\n",
      "[31, 60] loss: 0.399\n",
      "[31, 120] loss: 0.416\n",
      "[31, 180] loss: 0.399\n",
      "[31, 240] loss: 0.407\n",
      "[31, 300] loss: 0.408\n",
      "[31, 360] loss: 0.408\n",
      "Epoch: 31 -> Loss: 0.344982713461\n",
      "Epoch: 31 -> Test Accuracy: 81.99\n",
      "[32, 60] loss: 0.398\n",
      "[32, 120] loss: 0.399\n",
      "[32, 180] loss: 0.415\n",
      "[32, 240] loss: 0.420\n",
      "[32, 300] loss: 0.404\n",
      "[32, 360] loss: 0.412\n",
      "Epoch: 32 -> Loss: 0.288294702768\n",
      "Epoch: 32 -> Test Accuracy: 81.88\n",
      "[33, 60] loss: 0.388\n",
      "[33, 120] loss: 0.412\n",
      "[33, 180] loss: 0.390\n",
      "[33, 240] loss: 0.409\n",
      "[33, 300] loss: 0.412\n",
      "[33, 360] loss: 0.408\n",
      "Epoch: 33 -> Loss: 0.49452033639\n",
      "Epoch: 33 -> Test Accuracy: 82.07\n",
      "[34, 60] loss: 0.381\n",
      "[34, 120] loss: 0.406\n",
      "[34, 180] loss: 0.395\n",
      "[34, 240] loss: 0.419\n",
      "[34, 300] loss: 0.411\n",
      "[34, 360] loss: 0.399\n",
      "Epoch: 34 -> Loss: 0.397643536329\n",
      "Epoch: 34 -> Test Accuracy: 81.75\n",
      "[35, 60] loss: 0.391\n",
      "[35, 120] loss: 0.398\n",
      "[35, 180] loss: 0.412\n",
      "[35, 240] loss: 0.419\n",
      "[35, 300] loss: 0.404\n",
      "[35, 360] loss: 0.410\n",
      "Epoch: 35 -> Loss: 0.360595881939\n",
      "Epoch: 35 -> Test Accuracy: 81.5\n",
      "[36, 60] loss: 0.389\n",
      "[36, 120] loss: 0.395\n",
      "[36, 180] loss: 0.410\n",
      "[36, 240] loss: 0.414\n",
      "[36, 300] loss: 0.408\n",
      "[36, 360] loss: 0.401\n",
      "Epoch: 36 -> Loss: 0.729253470898\n",
      "Epoch: 36 -> Test Accuracy: 81.83\n",
      "[37, 60] loss: 0.383\n",
      "[37, 120] loss: 0.405\n",
      "[37, 180] loss: 0.407\n",
      "[37, 240] loss: 0.392\n",
      "[37, 300] loss: 0.399\n",
      "[37, 360] loss: 0.422\n",
      "Epoch: 37 -> Loss: 0.426109790802\n",
      "Epoch: 37 -> Test Accuracy: 81.78\n",
      "[38, 60] loss: 0.393\n",
      "[38, 120] loss: 0.382\n",
      "[38, 180] loss: 0.404\n",
      "[38, 240] loss: 0.394\n",
      "[38, 300] loss: 0.399\n",
      "[38, 360] loss: 0.405\n",
      "Epoch: 38 -> Loss: 0.32703062892\n",
      "Epoch: 38 -> Test Accuracy: 81.77\n",
      "[39, 60] loss: 0.390\n",
      "[39, 120] loss: 0.378\n",
      "[39, 180] loss: 0.380\n",
      "[39, 240] loss: 0.393\n",
      "[39, 300] loss: 0.422\n",
      "[39, 360] loss: 0.414\n",
      "Epoch: 39 -> Loss: 0.390011519194\n",
      "Epoch: 39 -> Test Accuracy: 81.58\n",
      "[40, 60] loss: 0.389\n",
      "[40, 120] loss: 0.383\n",
      "[40, 180] loss: 0.378\n",
      "[40, 240] loss: 0.390\n",
      "[40, 300] loss: 0.395\n",
      "[40, 360] loss: 0.413\n",
      "Epoch: 40 -> Loss: 0.409378290176\n",
      "Epoch: 40 -> Test Accuracy: 81.98\n",
      "[41, 60] loss: 0.392\n",
      "[41, 120] loss: 0.353\n",
      "[41, 180] loss: 0.364\n",
      "[41, 240] loss: 0.334\n",
      "[41, 300] loss: 0.340\n",
      "[41, 360] loss: 0.330\n",
      "Epoch: 41 -> Loss: 0.468157291412\n",
      "Epoch: 41 -> Test Accuracy: 82.9\n",
      "[42, 60] loss: 0.332\n",
      "[42, 120] loss: 0.325\n",
      "[42, 180] loss: 0.346\n",
      "[42, 240] loss: 0.328\n",
      "[42, 300] loss: 0.328\n",
      "[42, 360] loss: 0.330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.288960307837\n",
      "Epoch: 42 -> Test Accuracy: 82.97\n",
      "[43, 60] loss: 0.314\n",
      "[43, 120] loss: 0.317\n",
      "[43, 180] loss: 0.334\n",
      "[43, 240] loss: 0.326\n",
      "[43, 300] loss: 0.327\n",
      "[43, 360] loss: 0.333\n",
      "Epoch: 43 -> Loss: 0.37066411972\n",
      "Epoch: 43 -> Test Accuracy: 83.04\n",
      "[44, 60] loss: 0.322\n",
      "[44, 120] loss: 0.316\n",
      "[44, 180] loss: 0.313\n",
      "[44, 240] loss: 0.322\n",
      "[44, 300] loss: 0.313\n",
      "[44, 360] loss: 0.330\n",
      "Epoch: 44 -> Loss: 0.276547819376\n",
      "Epoch: 44 -> Test Accuracy: 83.07\n",
      "[45, 60] loss: 0.300\n",
      "[45, 120] loss: 0.308\n",
      "[45, 180] loss: 0.313\n",
      "[45, 240] loss: 0.317\n",
      "[45, 300] loss: 0.309\n",
      "[45, 360] loss: 0.301\n",
      "Epoch: 45 -> Loss: 0.441224962473\n",
      "Epoch: 45 -> Test Accuracy: 82.83\n",
      "[46, 60] loss: 0.291\n",
      "[46, 120] loss: 0.289\n",
      "[46, 180] loss: 0.303\n",
      "[46, 240] loss: 0.299\n",
      "[46, 300] loss: 0.300\n",
      "[46, 360] loss: 0.291\n",
      "Epoch: 46 -> Loss: 0.358712673187\n",
      "Epoch: 46 -> Test Accuracy: 83.01\n",
      "[47, 60] loss: 0.303\n",
      "[47, 120] loss: 0.291\n",
      "[47, 180] loss: 0.295\n",
      "[47, 240] loss: 0.296\n",
      "[47, 300] loss: 0.290\n",
      "[47, 360] loss: 0.284\n",
      "Epoch: 47 -> Loss: 0.380125820637\n",
      "Epoch: 47 -> Test Accuracy: 83.07\n",
      "[48, 60] loss: 0.298\n",
      "[48, 120] loss: 0.288\n",
      "[48, 180] loss: 0.276\n",
      "[48, 240] loss: 0.293\n",
      "[48, 300] loss: 0.290\n",
      "[48, 360] loss: 0.287\n",
      "Epoch: 48 -> Loss: 0.304244577885\n",
      "Epoch: 48 -> Test Accuracy: 83.15\n",
      "[49, 60] loss: 0.284\n",
      "[49, 120] loss: 0.285\n",
      "[49, 180] loss: 0.292\n",
      "[49, 240] loss: 0.279\n",
      "[49, 300] loss: 0.287\n",
      "[49, 360] loss: 0.292\n",
      "Epoch: 49 -> Loss: 0.300312519073\n",
      "Epoch: 49 -> Test Accuracy: 83.2\n",
      "[50, 60] loss: 0.291\n",
      "[50, 120] loss: 0.278\n",
      "[50, 180] loss: 0.291\n",
      "[50, 240] loss: 0.297\n",
      "[50, 300] loss: 0.293\n",
      "[50, 360] loss: 0.281\n",
      "Epoch: 50 -> Loss: 0.213286370039\n",
      "Epoch: 50 -> Test Accuracy: 83.1\n",
      "[51, 60] loss: 0.293\n",
      "[51, 120] loss: 0.288\n",
      "[51, 180] loss: 0.286\n",
      "[51, 240] loss: 0.290\n",
      "[51, 300] loss: 0.285\n",
      "[51, 360] loss: 0.280\n",
      "Epoch: 51 -> Loss: 0.376870423555\n",
      "Epoch: 51 -> Test Accuracy: 83.24\n",
      "[52, 60] loss: 0.270\n",
      "[52, 120] loss: 0.284\n",
      "[52, 180] loss: 0.274\n",
      "[52, 240] loss: 0.291\n",
      "[52, 300] loss: 0.281\n",
      "[52, 360] loss: 0.289\n",
      "Epoch: 52 -> Loss: 0.355560034513\n",
      "Epoch: 52 -> Test Accuracy: 83.41\n",
      "[53, 60] loss: 0.283\n",
      "[53, 120] loss: 0.288\n",
      "[53, 180] loss: 0.294\n",
      "[53, 240] loss: 0.281\n",
      "[53, 300] loss: 0.293\n",
      "[53, 360] loss: 0.288\n",
      "Epoch: 53 -> Loss: 0.269876033068\n",
      "Epoch: 53 -> Test Accuracy: 83.29\n",
      "[54, 60] loss: 0.293\n",
      "[54, 120] loss: 0.274\n",
      "[54, 180] loss: 0.279\n",
      "[54, 240] loss: 0.293\n",
      "[54, 300] loss: 0.283\n",
      "[54, 360] loss: 0.279\n",
      "Epoch: 54 -> Loss: 0.264102876186\n",
      "Epoch: 54 -> Test Accuracy: 83.29\n",
      "[55, 60] loss: 0.276\n",
      "[55, 120] loss: 0.269\n",
      "[55, 180] loss: 0.280\n",
      "[55, 240] loss: 0.290\n",
      "[55, 300] loss: 0.284\n",
      "[55, 360] loss: 0.269\n",
      "Epoch: 55 -> Loss: 0.209694772959\n",
      "Epoch: 55 -> Test Accuracy: 83.28\n",
      "[56, 60] loss: 0.275\n",
      "[56, 120] loss: 0.280\n",
      "[56, 180] loss: 0.273\n",
      "[56, 240] loss: 0.276\n",
      "[56, 300] loss: 0.268\n",
      "[56, 360] loss: 0.296\n",
      "Epoch: 56 -> Loss: 0.395242065191\n",
      "Epoch: 56 -> Test Accuracy: 83.23\n",
      "[57, 60] loss: 0.296\n",
      "[57, 120] loss: 0.282\n",
      "[57, 180] loss: 0.268\n",
      "[57, 240] loss: 0.282\n",
      "[57, 300] loss: 0.274\n",
      "[57, 360] loss: 0.272\n",
      "Epoch: 57 -> Loss: 0.277080744505\n",
      "Epoch: 57 -> Test Accuracy: 83.33\n",
      "[58, 60] loss: 0.266\n",
      "[58, 120] loss: 0.281\n",
      "[58, 180] loss: 0.275\n",
      "[58, 240] loss: 0.274\n",
      "[58, 300] loss: 0.261\n",
      "[58, 360] loss: 0.276\n",
      "Epoch: 58 -> Loss: 0.488368034363\n",
      "Epoch: 58 -> Test Accuracy: 83.34\n",
      "[59, 60] loss: 0.280\n",
      "[59, 120] loss: 0.269\n",
      "[59, 180] loss: 0.270\n",
      "[59, 240] loss: 0.279\n",
      "[59, 300] loss: 0.281\n",
      "[59, 360] loss: 0.270\n",
      "Epoch: 59 -> Loss: 0.416568189859\n",
      "Epoch: 59 -> Test Accuracy: 83.37\n",
      "[60, 60] loss: 0.273\n",
      "[60, 120] loss: 0.276\n",
      "[60, 180] loss: 0.275\n",
      "[60, 240] loss: 0.275\n",
      "[60, 300] loss: 0.289\n",
      "[60, 360] loss: 0.275\n",
      "Epoch: 60 -> Loss: 0.240089580417\n",
      "Epoch: 60 -> Test Accuracy: 83.31\n",
      "[61, 60] loss: 0.266\n",
      "[61, 120] loss: 0.282\n",
      "[61, 180] loss: 0.279\n",
      "[61, 240] loss: 0.264\n",
      "[61, 300] loss: 0.271\n",
      "[61, 360] loss: 0.277\n",
      "Epoch: 61 -> Loss: 0.197897464037\n",
      "Epoch: 61 -> Test Accuracy: 83.34\n",
      "[62, 60] loss: 0.275\n",
      "[62, 120] loss: 0.268\n",
      "[62, 180] loss: 0.279\n",
      "[62, 240] loss: 0.275\n",
      "[62, 300] loss: 0.277\n",
      "[62, 360] loss: 0.272\n",
      "Epoch: 62 -> Loss: 0.182388901711\n",
      "Epoch: 62 -> Test Accuracy: 83.4\n",
      "[63, 60] loss: 0.261\n",
      "[63, 120] loss: 0.277\n",
      "[63, 180] loss: 0.273\n",
      "[63, 240] loss: 0.259\n",
      "[63, 300] loss: 0.276\n",
      "[63, 360] loss: 0.264\n",
      "Epoch: 63 -> Loss: 0.389243245125\n",
      "Epoch: 63 -> Test Accuracy: 83.4\n",
      "[64, 60] loss: 0.254\n",
      "[64, 120] loss: 0.283\n",
      "[64, 180] loss: 0.270\n",
      "[64, 240] loss: 0.276\n",
      "[64, 300] loss: 0.277\n",
      "[64, 360] loss: 0.268\n",
      "Epoch: 64 -> Loss: 0.328246951103\n",
      "Epoch: 64 -> Test Accuracy: 83.46\n",
      "[65, 60] loss: 0.256\n",
      "[65, 120] loss: 0.272\n",
      "[65, 180] loss: 0.268\n",
      "[65, 240] loss: 0.261\n",
      "[65, 300] loss: 0.270\n",
      "[65, 360] loss: 0.264\n",
      "Epoch: 65 -> Loss: 0.273667484522\n",
      "Epoch: 65 -> Test Accuracy: 83.41\n",
      "[66, 60] loss: 0.266\n",
      "[66, 120] loss: 0.269\n",
      "[66, 180] loss: 0.281\n",
      "[66, 240] loss: 0.277\n",
      "[66, 300] loss: 0.247\n",
      "[66, 360] loss: 0.266\n",
      "Epoch: 66 -> Loss: 0.299322456121\n",
      "Epoch: 66 -> Test Accuracy: 83.35\n",
      "[67, 60] loss: 0.263\n",
      "[67, 120] loss: 0.272\n",
      "[67, 180] loss: 0.254\n",
      "[67, 240] loss: 0.273\n",
      "[67, 300] loss: 0.270\n",
      "[67, 360] loss: 0.274\n",
      "Epoch: 67 -> Loss: 0.219202429056\n",
      "Epoch: 67 -> Test Accuracy: 83.53\n",
      "[68, 60] loss: 0.255\n",
      "[68, 120] loss: 0.262\n",
      "[68, 180] loss: 0.267\n",
      "[68, 240] loss: 0.269\n",
      "[68, 300] loss: 0.269\n",
      "[68, 360] loss: 0.264\n",
      "Epoch: 68 -> Loss: 0.331614226103\n",
      "Epoch: 68 -> Test Accuracy: 83.37\n",
      "[69, 60] loss: 0.259\n",
      "[69, 120] loss: 0.256\n",
      "[69, 180] loss: 0.280\n",
      "[69, 240] loss: 0.268\n",
      "[69, 300] loss: 0.264\n",
      "[69, 360] loss: 0.245\n",
      "Epoch: 69 -> Loss: 0.307165801525\n",
      "Epoch: 69 -> Test Accuracy: 83.51\n",
      "[70, 60] loss: 0.256\n",
      "[70, 120] loss: 0.266\n",
      "[70, 180] loss: 0.261\n",
      "[70, 240] loss: 0.269\n",
      "[70, 300] loss: 0.265\n",
      "[70, 360] loss: 0.258\n",
      "Epoch: 70 -> Loss: 0.359475910664\n",
      "Epoch: 70 -> Test Accuracy: 83.49\n",
      "[71, 60] loss: 0.255\n",
      "[71, 120] loss: 0.255\n",
      "[71, 180] loss: 0.267\n",
      "[71, 240] loss: 0.259\n",
      "[71, 300] loss: 0.266\n",
      "[71, 360] loss: 0.261\n",
      "Epoch: 71 -> Loss: 0.283290684223\n",
      "Epoch: 71 -> Test Accuracy: 83.63\n",
      "[72, 60] loss: 0.252\n",
      "[72, 120] loss: 0.262\n",
      "[72, 180] loss: 0.268\n",
      "[72, 240] loss: 0.266\n",
      "[72, 300] loss: 0.266\n",
      "[72, 360] loss: 0.263\n",
      "Epoch: 72 -> Loss: 0.2763671875\n",
      "Epoch: 72 -> Test Accuracy: 83.53\n",
      "[73, 60] loss: 0.268\n",
      "[73, 120] loss: 0.258\n",
      "[73, 180] loss: 0.266\n",
      "[73, 240] loss: 0.265\n",
      "[73, 300] loss: 0.258\n",
      "[73, 360] loss: 0.260\n",
      "Epoch: 73 -> Loss: 0.337265968323\n",
      "Epoch: 73 -> Test Accuracy: 83.57\n",
      "[74, 60] loss: 0.267\n",
      "[74, 120] loss: 0.261\n",
      "[74, 180] loss: 0.257\n",
      "[74, 240] loss: 0.254\n",
      "[74, 300] loss: 0.269\n",
      "[74, 360] loss: 0.255\n",
      "Epoch: 74 -> Loss: 0.185233920813\n",
      "Epoch: 74 -> Test Accuracy: 83.58\n",
      "[75, 60] loss: 0.254\n",
      "[75, 120] loss: 0.255\n",
      "[75, 180] loss: 0.249\n",
      "[75, 240] loss: 0.269\n",
      "[75, 300] loss: 0.251\n",
      "[75, 360] loss: 0.262\n",
      "Epoch: 75 -> Loss: 0.420707553625\n",
      "Epoch: 75 -> Test Accuracy: 83.67\n",
      "[76, 60] loss: 0.253\n",
      "[76, 120] loss: 0.255\n",
      "[76, 180] loss: 0.272\n",
      "[76, 240] loss: 0.263\n",
      "[76, 300] loss: 0.262\n",
      "[76, 360] loss: 0.253\n",
      "Epoch: 76 -> Loss: 0.130822077394\n",
      "Epoch: 76 -> Test Accuracy: 83.34\n",
      "[77, 60] loss: 0.256\n",
      "[77, 120] loss: 0.245\n",
      "[77, 180] loss: 0.260\n",
      "[77, 240] loss: 0.255\n",
      "[77, 300] loss: 0.245\n",
      "[77, 360] loss: 0.263\n",
      "Epoch: 77 -> Loss: 0.291424304247\n",
      "Epoch: 77 -> Test Accuracy: 83.56\n",
      "[78, 60] loss: 0.258\n",
      "[78, 120] loss: 0.256\n",
      "[78, 180] loss: 0.258\n",
      "[78, 240] loss: 0.252\n",
      "[78, 300] loss: 0.247\n",
      "[78, 360] loss: 0.268\n",
      "Epoch: 78 -> Loss: 0.190608337522\n",
      "Epoch: 78 -> Test Accuracy: 83.46\n",
      "[79, 60] loss: 0.252\n",
      "[79, 120] loss: 0.247\n",
      "[79, 180] loss: 0.253\n",
      "[79, 240] loss: 0.251\n",
      "[79, 300] loss: 0.240\n",
      "[79, 360] loss: 0.258\n",
      "Epoch: 79 -> Loss: 0.273918479681\n",
      "Epoch: 79 -> Test Accuracy: 83.49\n",
      "[80, 60] loss: 0.246\n",
      "[80, 120] loss: 0.262\n",
      "[80, 180] loss: 0.251\n",
      "[80, 240] loss: 0.241\n",
      "[80, 300] loss: 0.252\n",
      "[80, 360] loss: 0.256\n",
      "Epoch: 80 -> Loss: 0.322596520185\n",
      "Epoch: 80 -> Test Accuracy: 83.48\n",
      "[81, 60] loss: 0.248\n",
      "[81, 120] loss: 0.243\n",
      "[81, 180] loss: 0.254\n",
      "[81, 240] loss: 0.248\n",
      "[81, 300] loss: 0.237\n",
      "[81, 360] loss: 0.252\n",
      "Epoch: 81 -> Loss: 0.262036859989\n",
      "Epoch: 81 -> Test Accuracy: 83.39\n",
      "[82, 60] loss: 0.252\n",
      "[82, 120] loss: 0.241\n",
      "[82, 180] loss: 0.254\n",
      "[82, 240] loss: 0.245\n",
      "[82, 300] loss: 0.262\n",
      "[82, 360] loss: 0.243\n",
      "Epoch: 82 -> Loss: 0.25388020277\n",
      "Epoch: 82 -> Test Accuracy: 83.49\n",
      "[83, 60] loss: 0.255\n",
      "[83, 120] loss: 0.257\n",
      "[83, 180] loss: 0.245\n",
      "[83, 240] loss: 0.241\n",
      "[83, 300] loss: 0.249\n",
      "[83, 360] loss: 0.252\n",
      "Epoch: 83 -> Loss: 0.125445529819\n",
      "Epoch: 83 -> Test Accuracy: 83.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.254\n",
      "[84, 120] loss: 0.245\n",
      "[84, 180] loss: 0.252\n",
      "[84, 240] loss: 0.243\n",
      "[84, 300] loss: 0.245\n",
      "[84, 360] loss: 0.247\n",
      "Epoch: 84 -> Loss: 0.290449887514\n",
      "Epoch: 84 -> Test Accuracy: 83.42\n",
      "[85, 60] loss: 0.250\n",
      "[85, 120] loss: 0.250\n",
      "[85, 180] loss: 0.255\n",
      "[85, 240] loss: 0.237\n",
      "[85, 300] loss: 0.247\n",
      "[85, 360] loss: 0.240\n",
      "Epoch: 85 -> Loss: 0.256677687168\n",
      "Epoch: 85 -> Test Accuracy: 83.37\n",
      "[86, 60] loss: 0.254\n",
      "[86, 120] loss: 0.252\n",
      "[86, 180] loss: 0.248\n",
      "[86, 240] loss: 0.244\n",
      "[86, 300] loss: 0.244\n",
      "[86, 360] loss: 0.240\n",
      "Epoch: 86 -> Loss: 0.339571624994\n",
      "Epoch: 86 -> Test Accuracy: 83.45\n",
      "[87, 60] loss: 0.246\n",
      "[87, 120] loss: 0.258\n",
      "[87, 180] loss: 0.240\n",
      "[87, 240] loss: 0.249\n",
      "[87, 300] loss: 0.266\n",
      "[87, 360] loss: 0.229\n",
      "Epoch: 87 -> Loss: 0.417621672153\n",
      "Epoch: 87 -> Test Accuracy: 83.38\n",
      "[88, 60] loss: 0.249\n",
      "[88, 120] loss: 0.233\n",
      "[88, 180] loss: 0.253\n",
      "[88, 240] loss: 0.249\n",
      "[88, 300] loss: 0.241\n",
      "[88, 360] loss: 0.258\n",
      "Epoch: 88 -> Loss: 0.175293684006\n",
      "Epoch: 88 -> Test Accuracy: 83.38\n",
      "[89, 60] loss: 0.233\n",
      "[89, 120] loss: 0.254\n",
      "[89, 180] loss: 0.248\n",
      "[89, 240] loss: 0.248\n",
      "[89, 300] loss: 0.248\n",
      "[89, 360] loss: 0.252\n",
      "Epoch: 89 -> Loss: 0.242187306285\n",
      "Epoch: 89 -> Test Accuracy: 83.34\n",
      "[90, 60] loss: 0.263\n",
      "[90, 120] loss: 0.248\n",
      "[90, 180] loss: 0.254\n",
      "[90, 240] loss: 0.251\n",
      "[90, 300] loss: 0.243\n",
      "[90, 360] loss: 0.245\n",
      "Epoch: 90 -> Loss: 0.138871043921\n",
      "Epoch: 90 -> Test Accuracy: 83.46\n",
      "[91, 60] loss: 0.228\n",
      "[91, 120] loss: 0.249\n",
      "[91, 180] loss: 0.244\n",
      "[91, 240] loss: 0.249\n",
      "[91, 300] loss: 0.235\n",
      "[91, 360] loss: 0.261\n",
      "Epoch: 91 -> Loss: 0.298074096441\n",
      "Epoch: 91 -> Test Accuracy: 83.52\n",
      "[92, 60] loss: 0.248\n",
      "[92, 120] loss: 0.240\n",
      "[92, 180] loss: 0.245\n",
      "[92, 240] loss: 0.249\n",
      "[92, 300] loss: 0.255\n",
      "[92, 360] loss: 0.240\n",
      "Epoch: 92 -> Loss: 0.375261008739\n",
      "Epoch: 92 -> Test Accuracy: 83.51\n",
      "[93, 60] loss: 0.235\n",
      "[93, 120] loss: 0.241\n",
      "[93, 180] loss: 0.248\n",
      "[93, 240] loss: 0.251\n",
      "[93, 300] loss: 0.241\n",
      "[93, 360] loss: 0.238\n",
      "Epoch: 93 -> Loss: 0.170473784208\n",
      "Epoch: 93 -> Test Accuracy: 83.45\n",
      "[94, 60] loss: 0.235\n",
      "[94, 120] loss: 0.247\n",
      "[94, 180] loss: 0.233\n",
      "[94, 240] loss: 0.236\n",
      "[94, 300] loss: 0.246\n",
      "[94, 360] loss: 0.249\n",
      "Epoch: 94 -> Loss: 0.229346469045\n",
      "Epoch: 94 -> Test Accuracy: 83.4\n",
      "[95, 60] loss: 0.239\n",
      "[95, 120] loss: 0.234\n",
      "[95, 180] loss: 0.231\n",
      "[95, 240] loss: 0.250\n",
      "[95, 300] loss: 0.247\n",
      "[95, 360] loss: 0.241\n",
      "Epoch: 95 -> Loss: 0.402506738901\n",
      "Epoch: 95 -> Test Accuracy: 83.54\n",
      "[96, 60] loss: 0.234\n",
      "[96, 120] loss: 0.237\n",
      "[96, 180] loss: 0.236\n",
      "[96, 240] loss: 0.233\n",
      "[96, 300] loss: 0.247\n",
      "[96, 360] loss: 0.238\n",
      "Epoch: 96 -> Loss: 0.280490666628\n",
      "Epoch: 96 -> Test Accuracy: 83.57\n",
      "[97, 60] loss: 0.246\n",
      "[97, 120] loss: 0.237\n",
      "[97, 180] loss: 0.236\n",
      "[97, 240] loss: 0.245\n",
      "[97, 300] loss: 0.243\n",
      "[97, 360] loss: 0.238\n",
      "Epoch: 97 -> Loss: 0.160051196814\n",
      "Epoch: 97 -> Test Accuracy: 83.38\n",
      "[98, 60] loss: 0.246\n",
      "[98, 120] loss: 0.233\n",
      "[98, 180] loss: 0.246\n",
      "[98, 240] loss: 0.231\n",
      "[98, 300] loss: 0.242\n",
      "[98, 360] loss: 0.234\n",
      "Epoch: 98 -> Loss: 0.261619985104\n",
      "Epoch: 98 -> Test Accuracy: 83.41\n",
      "[99, 60] loss: 0.237\n",
      "[99, 120] loss: 0.239\n",
      "[99, 180] loss: 0.230\n",
      "[99, 240] loss: 0.233\n",
      "[99, 300] loss: 0.238\n",
      "[99, 360] loss: 0.232\n",
      "Epoch: 99 -> Loss: 0.299073845148\n",
      "Epoch: 99 -> Test Accuracy: 83.41\n",
      "[100, 60] loss: 0.236\n",
      "[100, 120] loss: 0.237\n",
      "[100, 180] loss: 0.246\n",
      "[100, 240] loss: 0.237\n",
      "[100, 300] loss: 0.226\n",
      "[100, 360] loss: 0.237\n",
      "Epoch: 100 -> Loss: 0.139979675412\n",
      "Epoch: 100 -> Test Accuracy: 83.39\n",
      "Finished Training\n",
      "[1, 60] loss: 1.766\n",
      "[1, 120] loss: 0.862\n",
      "[1, 180] loss: 0.763\n",
      "[1, 240] loss: 0.710\n",
      "[1, 300] loss: 0.696\n",
      "[1, 360] loss: 0.673\n",
      "Epoch: 1 -> Loss: 0.699618935585\n",
      "Epoch: 1 -> Test Accuracy: 78.54\n",
      "[2, 60] loss: 0.600\n",
      "[2, 120] loss: 0.585\n",
      "[2, 180] loss: 0.580\n",
      "[2, 240] loss: 0.581\n",
      "[2, 300] loss: 0.557\n",
      "[2, 360] loss: 0.571\n",
      "Epoch: 2 -> Loss: 0.665355205536\n",
      "Epoch: 2 -> Test Accuracy: 80.73\n",
      "[3, 60] loss: 0.516\n",
      "[3, 120] loss: 0.531\n",
      "[3, 180] loss: 0.508\n",
      "[3, 240] loss: 0.516\n",
      "[3, 300] loss: 0.518\n",
      "[3, 360] loss: 0.513\n",
      "Epoch: 3 -> Loss: 0.355344116688\n",
      "Epoch: 3 -> Test Accuracy: 81.85\n",
      "[4, 60] loss: 0.458\n",
      "[4, 120] loss: 0.481\n",
      "[4, 180] loss: 0.499\n",
      "[4, 240] loss: 0.470\n",
      "[4, 300] loss: 0.466\n",
      "[4, 360] loss: 0.490\n",
      "Epoch: 4 -> Loss: 0.419162988663\n",
      "Epoch: 4 -> Test Accuracy: 82.62\n",
      "[5, 60] loss: 0.454\n",
      "[5, 120] loss: 0.448\n",
      "[5, 180] loss: 0.461\n",
      "[5, 240] loss: 0.454\n",
      "[5, 300] loss: 0.443\n",
      "[5, 360] loss: 0.464\n",
      "Epoch: 5 -> Loss: 0.510218143463\n",
      "Epoch: 5 -> Test Accuracy: 82.76\n",
      "[6, 60] loss: 0.424\n",
      "[6, 120] loss: 0.420\n",
      "[6, 180] loss: 0.445\n",
      "[6, 240] loss: 0.449\n",
      "[6, 300] loss: 0.452\n",
      "[6, 360] loss: 0.446\n",
      "Epoch: 6 -> Loss: 0.403174817562\n",
      "Epoch: 6 -> Test Accuracy: 83.41\n",
      "[7, 60] loss: 0.406\n",
      "[7, 120] loss: 0.423\n",
      "[7, 180] loss: 0.420\n",
      "[7, 240] loss: 0.435\n",
      "[7, 300] loss: 0.420\n",
      "[7, 360] loss: 0.441\n",
      "Epoch: 7 -> Loss: 0.398490250111\n",
      "Epoch: 7 -> Test Accuracy: 83.76\n",
      "[8, 60] loss: 0.401\n",
      "[8, 120] loss: 0.403\n",
      "[8, 180] loss: 0.404\n",
      "[8, 240] loss: 0.430\n",
      "[8, 300] loss: 0.429\n",
      "[8, 360] loss: 0.426\n",
      "Epoch: 8 -> Loss: 0.623163461685\n",
      "Epoch: 8 -> Test Accuracy: 83.95\n",
      "[9, 60] loss: 0.387\n",
      "[9, 120] loss: 0.405\n",
      "[9, 180] loss: 0.389\n",
      "[9, 240] loss: 0.405\n",
      "[9, 300] loss: 0.428\n",
      "[9, 360] loss: 0.414\n",
      "Epoch: 9 -> Loss: 0.299457907677\n",
      "Epoch: 9 -> Test Accuracy: 83.94\n",
      "[10, 60] loss: 0.390\n",
      "[10, 120] loss: 0.399\n",
      "[10, 180] loss: 0.410\n",
      "[10, 240] loss: 0.406\n",
      "[10, 300] loss: 0.401\n",
      "[10, 360] loss: 0.402\n",
      "Epoch: 10 -> Loss: 0.455329567194\n",
      "Epoch: 10 -> Test Accuracy: 84.33\n",
      "[11, 60] loss: 0.382\n",
      "[11, 120] loss: 0.380\n",
      "[11, 180] loss: 0.386\n",
      "[11, 240] loss: 0.404\n",
      "[11, 300] loss: 0.414\n",
      "[11, 360] loss: 0.402\n",
      "Epoch: 11 -> Loss: 0.395554035902\n",
      "Epoch: 11 -> Test Accuracy: 83.88\n",
      "[12, 60] loss: 0.384\n",
      "[12, 120] loss: 0.376\n",
      "[12, 180] loss: 0.390\n",
      "[12, 240] loss: 0.395\n",
      "[12, 300] loss: 0.394\n",
      "[12, 360] loss: 0.421\n",
      "Epoch: 12 -> Loss: 0.492409050465\n",
      "Epoch: 12 -> Test Accuracy: 83.88\n",
      "[13, 60] loss: 0.375\n",
      "[13, 120] loss: 0.378\n",
      "[13, 180] loss: 0.383\n",
      "[13, 240] loss: 0.399\n",
      "[13, 300] loss: 0.397\n",
      "[13, 360] loss: 0.400\n",
      "Epoch: 13 -> Loss: 0.761789798737\n",
      "Epoch: 13 -> Test Accuracy: 83.79\n",
      "[14, 60] loss: 0.355\n",
      "[14, 120] loss: 0.377\n",
      "[14, 180] loss: 0.385\n",
      "[14, 240] loss: 0.387\n",
      "[14, 300] loss: 0.420\n",
      "[14, 360] loss: 0.408\n",
      "Epoch: 14 -> Loss: 0.290653288364\n",
      "Epoch: 14 -> Test Accuracy: 84.47\n",
      "[15, 60] loss: 0.365\n",
      "[15, 120] loss: 0.363\n",
      "[15, 180] loss: 0.382\n",
      "[15, 240] loss: 0.387\n",
      "[15, 300] loss: 0.393\n",
      "[15, 360] loss: 0.371\n",
      "Epoch: 15 -> Loss: 0.291873306036\n",
      "Epoch: 15 -> Test Accuracy: 84.63\n",
      "[16, 60] loss: 0.356\n",
      "[16, 120] loss: 0.368\n",
      "[16, 180] loss: 0.371\n",
      "[16, 240] loss: 0.378\n",
      "[16, 300] loss: 0.400\n",
      "[16, 360] loss: 0.387\n",
      "Epoch: 16 -> Loss: 0.41303524375\n",
      "Epoch: 16 -> Test Accuracy: 84.54\n",
      "[17, 60] loss: 0.357\n",
      "[17, 120] loss: 0.362\n",
      "[17, 180] loss: 0.384\n",
      "[17, 240] loss: 0.383\n",
      "[17, 300] loss: 0.386\n",
      "[17, 360] loss: 0.382\n",
      "Epoch: 17 -> Loss: 0.656370520592\n",
      "Epoch: 17 -> Test Accuracy: 84.64\n",
      "[18, 60] loss: 0.350\n",
      "[18, 120] loss: 0.360\n",
      "[18, 180] loss: 0.365\n",
      "[18, 240] loss: 0.378\n",
      "[18, 300] loss: 0.397\n",
      "[18, 360] loss: 0.376\n",
      "Epoch: 18 -> Loss: 0.576655805111\n",
      "Epoch: 18 -> Test Accuracy: 84.63\n",
      "[19, 60] loss: 0.353\n",
      "[19, 120] loss: 0.368\n",
      "[19, 180] loss: 0.363\n",
      "[19, 240] loss: 0.371\n",
      "[19, 300] loss: 0.374\n",
      "[19, 360] loss: 0.383\n",
      "Epoch: 19 -> Loss: 0.576562523842\n",
      "Epoch: 19 -> Test Accuracy: 84.71\n",
      "[20, 60] loss: 0.360\n",
      "[20, 120] loss: 0.361\n",
      "[20, 180] loss: 0.363\n",
      "[20, 240] loss: 0.374\n",
      "[20, 300] loss: 0.366\n",
      "[20, 360] loss: 0.391\n",
      "Epoch: 20 -> Loss: 0.332089275122\n",
      "Epoch: 20 -> Test Accuracy: 84.41\n",
      "[21, 60] loss: 0.315\n",
      "[21, 120] loss: 0.309\n",
      "[21, 180] loss: 0.299\n",
      "[21, 240] loss: 0.291\n",
      "[21, 300] loss: 0.290\n",
      "[21, 360] loss: 0.289\n",
      "Epoch: 21 -> Loss: 0.277859002352\n",
      "Epoch: 21 -> Test Accuracy: 86.75\n",
      "[22, 60] loss: 0.260\n",
      "[22, 120] loss: 0.263\n",
      "[22, 180] loss: 0.261\n",
      "[22, 240] loss: 0.256\n",
      "[22, 300] loss: 0.266\n",
      "[22, 360] loss: 0.259\n",
      "Epoch: 22 -> Loss: 0.172056719661\n",
      "Epoch: 22 -> Test Accuracy: 86.79\n",
      "[23, 60] loss: 0.242\n",
      "[23, 120] loss: 0.244\n",
      "[23, 180] loss: 0.253\n",
      "[23, 240] loss: 0.256\n",
      "[23, 300] loss: 0.245\n",
      "[23, 360] loss: 0.257\n",
      "Epoch: 23 -> Loss: 0.155487775803\n",
      "Epoch: 23 -> Test Accuracy: 86.92\n",
      "[24, 60] loss: 0.231\n",
      "[24, 120] loss: 0.244\n",
      "[24, 180] loss: 0.240\n",
      "[24, 240] loss: 0.233\n",
      "[24, 300] loss: 0.229\n",
      "[24, 360] loss: 0.236\n",
      "Epoch: 24 -> Loss: 0.303609281778\n",
      "Epoch: 24 -> Test Accuracy: 86.73\n",
      "[25, 60] loss: 0.211\n",
      "[25, 120] loss: 0.223\n",
      "[25, 180] loss: 0.228\n",
      "[25, 240] loss: 0.226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 300] loss: 0.224\n",
      "[25, 360] loss: 0.230\n",
      "Epoch: 25 -> Loss: 0.245379209518\n",
      "Epoch: 25 -> Test Accuracy: 86.67\n",
      "[26, 60] loss: 0.197\n",
      "[26, 120] loss: 0.214\n",
      "[26, 180] loss: 0.230\n",
      "[26, 240] loss: 0.223\n",
      "[26, 300] loss: 0.221\n",
      "[26, 360] loss: 0.225\n",
      "Epoch: 26 -> Loss: 0.319973796606\n",
      "Epoch: 26 -> Test Accuracy: 86.9\n",
      "[27, 60] loss: 0.205\n",
      "[27, 120] loss: 0.205\n",
      "[27, 180] loss: 0.201\n",
      "[27, 240] loss: 0.222\n",
      "[27, 300] loss: 0.217\n",
      "[27, 360] loss: 0.219\n",
      "Epoch: 27 -> Loss: 0.254327714443\n",
      "Epoch: 27 -> Test Accuracy: 86.64\n",
      "[28, 60] loss: 0.205\n",
      "[28, 120] loss: 0.203\n",
      "[28, 180] loss: 0.197\n",
      "[28, 240] loss: 0.222\n",
      "[28, 300] loss: 0.224\n",
      "[28, 360] loss: 0.214\n",
      "Epoch: 28 -> Loss: 0.217792361975\n",
      "Epoch: 28 -> Test Accuracy: 86.92\n",
      "[29, 60] loss: 0.202\n",
      "[29, 120] loss: 0.199\n",
      "[29, 180] loss: 0.203\n",
      "[29, 240] loss: 0.209\n",
      "[29, 300] loss: 0.194\n",
      "[29, 360] loss: 0.220\n",
      "Epoch: 29 -> Loss: 0.14414075017\n",
      "Epoch: 29 -> Test Accuracy: 86.72\n",
      "[30, 60] loss: 0.177\n",
      "[30, 120] loss: 0.205\n",
      "[30, 180] loss: 0.205\n",
      "[30, 240] loss: 0.193\n",
      "[30, 300] loss: 0.224\n",
      "[30, 360] loss: 0.194\n",
      "Epoch: 30 -> Loss: 0.229222148657\n",
      "Epoch: 30 -> Test Accuracy: 86.64\n",
      "[31, 60] loss: 0.181\n",
      "[31, 120] loss: 0.196\n",
      "[31, 180] loss: 0.194\n",
      "[31, 240] loss: 0.208\n",
      "[31, 300] loss: 0.217\n",
      "[31, 360] loss: 0.219\n",
      "Epoch: 31 -> Loss: 0.136704564095\n",
      "Epoch: 31 -> Test Accuracy: 86.79\n",
      "[32, 60] loss: 0.178\n",
      "[32, 120] loss: 0.200\n",
      "[32, 180] loss: 0.204\n",
      "[32, 240] loss: 0.205\n",
      "[32, 300] loss: 0.216\n",
      "[32, 360] loss: 0.204\n",
      "Epoch: 32 -> Loss: 0.127716064453\n",
      "Epoch: 32 -> Test Accuracy: 86.2\n",
      "[33, 60] loss: 0.181\n",
      "[33, 120] loss: 0.185\n",
      "[33, 180] loss: 0.202\n",
      "[33, 240] loss: 0.207\n",
      "[33, 300] loss: 0.193\n",
      "[33, 360] loss: 0.220\n",
      "Epoch: 33 -> Loss: 0.19144937396\n",
      "Epoch: 33 -> Test Accuracy: 86.66\n",
      "[34, 60] loss: 0.186\n",
      "[34, 120] loss: 0.201\n",
      "[34, 180] loss: 0.201\n",
      "[34, 240] loss: 0.203\n",
      "[34, 300] loss: 0.206\n",
      "[34, 360] loss: 0.196\n",
      "Epoch: 34 -> Loss: 0.18144698441\n",
      "Epoch: 34 -> Test Accuracy: 86.08\n",
      "[35, 60] loss: 0.182\n",
      "[35, 120] loss: 0.196\n",
      "[35, 180] loss: 0.189\n",
      "[35, 240] loss: 0.201\n",
      "[35, 300] loss: 0.198\n",
      "[35, 360] loss: 0.204\n",
      "Epoch: 35 -> Loss: 0.155216068029\n",
      "Epoch: 35 -> Test Accuracy: 86.32\n",
      "[36, 60] loss: 0.193\n",
      "[36, 120] loss: 0.189\n",
      "[36, 180] loss: 0.194\n",
      "[36, 240] loss: 0.189\n",
      "[36, 300] loss: 0.203\n",
      "[36, 360] loss: 0.198\n",
      "Epoch: 36 -> Loss: 0.151616245508\n",
      "Epoch: 36 -> Test Accuracy: 86.31\n",
      "[37, 60] loss: 0.190\n",
      "[37, 120] loss: 0.185\n",
      "[37, 180] loss: 0.199\n",
      "[37, 240] loss: 0.196\n",
      "[37, 300] loss: 0.202\n",
      "[37, 360] loss: 0.197\n",
      "Epoch: 37 -> Loss: 0.209808751941\n",
      "Epoch: 37 -> Test Accuracy: 86.07\n",
      "[38, 60] loss: 0.192\n",
      "[38, 120] loss: 0.198\n",
      "[38, 180] loss: 0.192\n",
      "[38, 240] loss: 0.186\n",
      "[38, 300] loss: 0.191\n",
      "[38, 360] loss: 0.206\n",
      "Epoch: 38 -> Loss: 0.174093723297\n",
      "Epoch: 38 -> Test Accuracy: 86.17\n",
      "[39, 60] loss: 0.189\n",
      "[39, 120] loss: 0.189\n",
      "[39, 180] loss: 0.198\n",
      "[39, 240] loss: 0.193\n",
      "[39, 300] loss: 0.185\n",
      "[39, 360] loss: 0.211\n",
      "Epoch: 39 -> Loss: 0.125268101692\n",
      "Epoch: 39 -> Test Accuracy: 86.09\n",
      "[40, 60] loss: 0.181\n",
      "[40, 120] loss: 0.202\n",
      "[40, 180] loss: 0.191\n",
      "[40, 240] loss: 0.204\n",
      "[40, 300] loss: 0.190\n",
      "[40, 360] loss: 0.198\n",
      "Epoch: 40 -> Loss: 0.21692070365\n",
      "Epoch: 40 -> Test Accuracy: 86.19\n",
      "[41, 60] loss: 0.178\n",
      "[41, 120] loss: 0.167\n",
      "[41, 180] loss: 0.163\n",
      "[41, 240] loss: 0.157\n",
      "[41, 300] loss: 0.152\n",
      "[41, 360] loss: 0.144\n",
      "Epoch: 41 -> Loss: 0.225368738174\n",
      "Epoch: 41 -> Test Accuracy: 86.55\n",
      "[42, 60] loss: 0.138\n",
      "[42, 120] loss: 0.135\n",
      "[42, 180] loss: 0.138\n",
      "[42, 240] loss: 0.148\n",
      "[42, 300] loss: 0.141\n",
      "[42, 360] loss: 0.152\n",
      "Epoch: 42 -> Loss: 0.149103716016\n",
      "Epoch: 42 -> Test Accuracy: 87.26\n",
      "[43, 60] loss: 0.136\n",
      "[43, 120] loss: 0.143\n",
      "[43, 180] loss: 0.136\n",
      "[43, 240] loss: 0.135\n",
      "[43, 300] loss: 0.136\n",
      "[43, 360] loss: 0.145\n",
      "Epoch: 43 -> Loss: 0.0620906054974\n",
      "Epoch: 43 -> Test Accuracy: 87.09\n",
      "[44, 60] loss: 0.135\n",
      "[44, 120] loss: 0.138\n",
      "[44, 180] loss: 0.133\n",
      "[44, 240] loss: 0.124\n",
      "[44, 300] loss: 0.119\n",
      "[44, 360] loss: 0.126\n",
      "Epoch: 44 -> Loss: 0.123044706881\n",
      "Epoch: 44 -> Test Accuracy: 87.09\n",
      "[45, 60] loss: 0.124\n",
      "[45, 120] loss: 0.127\n",
      "[45, 180] loss: 0.126\n",
      "[45, 240] loss: 0.133\n",
      "[45, 300] loss: 0.128\n",
      "[45, 360] loss: 0.132\n",
      "Epoch: 45 -> Loss: 0.141208052635\n",
      "Epoch: 45 -> Test Accuracy: 87.28\n",
      "[46, 60] loss: 0.121\n",
      "[46, 120] loss: 0.125\n",
      "[46, 180] loss: 0.117\n",
      "[46, 240] loss: 0.107\n",
      "[46, 300] loss: 0.114\n",
      "[46, 360] loss: 0.119\n",
      "Epoch: 46 -> Loss: 0.116904355586\n",
      "Epoch: 46 -> Test Accuracy: 87.44\n",
      "[47, 60] loss: 0.112\n",
      "[47, 120] loss: 0.111\n",
      "[47, 180] loss: 0.122\n",
      "[47, 240] loss: 0.110\n",
      "[47, 300] loss: 0.113\n",
      "[47, 360] loss: 0.127\n",
      "Epoch: 47 -> Loss: 0.0988012328744\n",
      "Epoch: 47 -> Test Accuracy: 87.5\n",
      "[48, 60] loss: 0.113\n",
      "[48, 120] loss: 0.108\n",
      "[48, 180] loss: 0.118\n",
      "[48, 240] loss: 0.125\n",
      "[48, 300] loss: 0.111\n",
      "[48, 360] loss: 0.112\n",
      "Epoch: 48 -> Loss: 0.0872803628445\n",
      "Epoch: 48 -> Test Accuracy: 87.57\n",
      "[49, 60] loss: 0.108\n",
      "[49, 120] loss: 0.114\n",
      "[49, 180] loss: 0.117\n",
      "[49, 240] loss: 0.105\n",
      "[49, 300] loss: 0.112\n",
      "[49, 360] loss: 0.108\n",
      "Epoch: 49 -> Loss: 0.150241240859\n",
      "Epoch: 49 -> Test Accuracy: 87.62\n",
      "[50, 60] loss: 0.109\n",
      "[50, 120] loss: 0.111\n",
      "[50, 180] loss: 0.114\n",
      "[50, 240] loss: 0.114\n",
      "[50, 300] loss: 0.111\n",
      "[50, 360] loss: 0.117\n",
      "Epoch: 50 -> Loss: 0.163899093866\n",
      "Epoch: 50 -> Test Accuracy: 87.56\n",
      "[51, 60] loss: 0.110\n",
      "[51, 120] loss: 0.107\n",
      "[51, 180] loss: 0.110\n",
      "[51, 240] loss: 0.110\n",
      "[51, 300] loss: 0.103\n",
      "[51, 360] loss: 0.110\n",
      "Epoch: 51 -> Loss: 0.350514829159\n",
      "Epoch: 51 -> Test Accuracy: 87.64\n",
      "[52, 60] loss: 0.103\n",
      "[52, 120] loss: 0.112\n",
      "[52, 180] loss: 0.107\n",
      "[52, 240] loss: 0.114\n",
      "[52, 300] loss: 0.104\n",
      "[52, 360] loss: 0.109\n",
      "Epoch: 52 -> Loss: 0.134163230658\n",
      "Epoch: 52 -> Test Accuracy: 87.65\n",
      "[53, 60] loss: 0.110\n",
      "[53, 120] loss: 0.100\n",
      "[53, 180] loss: 0.108\n",
      "[53, 240] loss: 0.105\n",
      "[53, 300] loss: 0.109\n",
      "[53, 360] loss: 0.111\n",
      "Epoch: 53 -> Loss: 0.0690125450492\n",
      "Epoch: 53 -> Test Accuracy: 87.64\n",
      "[54, 60] loss: 0.106\n",
      "[54, 120] loss: 0.103\n",
      "[54, 180] loss: 0.112\n",
      "[54, 240] loss: 0.113\n",
      "[54, 300] loss: 0.109\n",
      "[54, 360] loss: 0.108\n",
      "Epoch: 54 -> Loss: 0.10334558785\n",
      "Epoch: 54 -> Test Accuracy: 87.62\n",
      "[55, 60] loss: 0.099\n",
      "[55, 120] loss: 0.110\n",
      "[55, 180] loss: 0.099\n",
      "[55, 240] loss: 0.107\n",
      "[55, 300] loss: 0.107\n",
      "[55, 360] loss: 0.109\n",
      "Epoch: 55 -> Loss: 0.128227949142\n",
      "Epoch: 55 -> Test Accuracy: 87.6\n",
      "[56, 60] loss: 0.107\n",
      "[56, 120] loss: 0.106\n",
      "[56, 180] loss: 0.111\n",
      "[56, 240] loss: 0.095\n",
      "[56, 300] loss: 0.106\n",
      "[56, 360] loss: 0.101\n",
      "Epoch: 56 -> Loss: 0.15927273035\n",
      "Epoch: 56 -> Test Accuracy: 87.62\n",
      "[57, 60] loss: 0.107\n",
      "[57, 120] loss: 0.096\n",
      "[57, 180] loss: 0.107\n",
      "[57, 240] loss: 0.106\n",
      "[57, 300] loss: 0.104\n",
      "[57, 360] loss: 0.109\n",
      "Epoch: 57 -> Loss: 0.0682558864355\n",
      "Epoch: 57 -> Test Accuracy: 87.53\n",
      "[58, 60] loss: 0.104\n",
      "[58, 120] loss: 0.096\n",
      "[58, 180] loss: 0.101\n",
      "[58, 240] loss: 0.102\n",
      "[58, 300] loss: 0.101\n",
      "[58, 360] loss: 0.103\n",
      "Epoch: 58 -> Loss: 0.0607363171875\n",
      "Epoch: 58 -> Test Accuracy: 87.57\n",
      "[59, 60] loss: 0.113\n",
      "[59, 120] loss: 0.100\n",
      "[59, 180] loss: 0.110\n",
      "[59, 240] loss: 0.105\n",
      "[59, 300] loss: 0.099\n",
      "[59, 360] loss: 0.103\n",
      "Epoch: 59 -> Loss: 0.0597909465432\n",
      "Epoch: 59 -> Test Accuracy: 87.56\n",
      "[60, 60] loss: 0.111\n",
      "[60, 120] loss: 0.105\n",
      "[60, 180] loss: 0.098\n",
      "[60, 240] loss: 0.101\n",
      "[60, 300] loss: 0.101\n",
      "[60, 360] loss: 0.102\n",
      "Epoch: 60 -> Loss: 0.0754465982318\n",
      "Epoch: 60 -> Test Accuracy: 87.65\n",
      "[61, 60] loss: 0.101\n",
      "[61, 120] loss: 0.102\n",
      "[61, 180] loss: 0.099\n",
      "[61, 240] loss: 0.102\n",
      "[61, 300] loss: 0.103\n",
      "[61, 360] loss: 0.091\n",
      "Epoch: 61 -> Loss: 0.0987722501159\n",
      "Epoch: 61 -> Test Accuracy: 87.52\n",
      "[62, 60] loss: 0.107\n",
      "[62, 120] loss: 0.103\n",
      "[62, 180] loss: 0.097\n",
      "[62, 240] loss: 0.095\n",
      "[62, 300] loss: 0.091\n",
      "[62, 360] loss: 0.096\n",
      "Epoch: 62 -> Loss: 0.102488897741\n",
      "Epoch: 62 -> Test Accuracy: 87.59\n",
      "[63, 60] loss: 0.106\n",
      "[63, 120] loss: 0.095\n",
      "[63, 180] loss: 0.098\n",
      "[63, 240] loss: 0.101\n",
      "[63, 300] loss: 0.097\n",
      "[63, 360] loss: 0.100\n",
      "Epoch: 63 -> Loss: 0.130622044206\n",
      "Epoch: 63 -> Test Accuracy: 87.41\n",
      "[64, 60] loss: 0.103\n",
      "[64, 120] loss: 0.094\n",
      "[64, 180] loss: 0.094\n",
      "[64, 240] loss: 0.100\n",
      "[64, 300] loss: 0.097\n",
      "[64, 360] loss: 0.099\n",
      "Epoch: 64 -> Loss: 0.0695501118898\n",
      "Epoch: 64 -> Test Accuracy: 87.49\n",
      "[65, 60] loss: 0.092\n",
      "[65, 120] loss: 0.092\n",
      "[65, 180] loss: 0.095\n",
      "[65, 240] loss: 0.097\n",
      "[65, 300] loss: 0.100\n",
      "[65, 360] loss: 0.092\n",
      "Epoch: 65 -> Loss: 0.036482591182\n",
      "Epoch: 65 -> Test Accuracy: 87.57\n",
      "[66, 60] loss: 0.087\n",
      "[66, 120] loss: 0.093\n",
      "[66, 180] loss: 0.103\n",
      "[66, 240] loss: 0.105\n",
      "[66, 300] loss: 0.094\n",
      "[66, 360] loss: 0.099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Loss: 0.0848872512579\n",
      "Epoch: 66 -> Test Accuracy: 87.56\n",
      "[67, 60] loss: 0.094\n",
      "[67, 120] loss: 0.086\n",
      "[67, 180] loss: 0.095\n",
      "[67, 240] loss: 0.096\n",
      "[67, 300] loss: 0.097\n",
      "[67, 360] loss: 0.086\n",
      "Epoch: 67 -> Loss: 0.0743397846818\n",
      "Epoch: 67 -> Test Accuracy: 87.41\n",
      "[68, 60] loss: 0.096\n",
      "[68, 120] loss: 0.089\n",
      "[68, 180] loss: 0.096\n",
      "[68, 240] loss: 0.088\n",
      "[68, 300] loss: 0.099\n",
      "[68, 360] loss: 0.091\n",
      "Epoch: 68 -> Loss: 0.0396004766226\n",
      "Epoch: 68 -> Test Accuracy: 87.5\n",
      "[69, 60] loss: 0.090\n",
      "[69, 120] loss: 0.088\n",
      "[69, 180] loss: 0.095\n",
      "[69, 240] loss: 0.101\n",
      "[69, 300] loss: 0.095\n",
      "[69, 360] loss: 0.097\n",
      "Epoch: 69 -> Loss: 0.0822754353285\n",
      "Epoch: 69 -> Test Accuracy: 87.48\n",
      "[70, 60] loss: 0.093\n",
      "[70, 120] loss: 0.088\n",
      "[70, 180] loss: 0.086\n",
      "[70, 240] loss: 0.092\n",
      "[70, 300] loss: 0.092\n",
      "[70, 360] loss: 0.101\n",
      "Epoch: 70 -> Loss: 0.0378089174628\n",
      "Epoch: 70 -> Test Accuracy: 87.49\n",
      "[71, 60] loss: 0.089\n",
      "[71, 120] loss: 0.094\n",
      "[71, 180] loss: 0.094\n",
      "[71, 240] loss: 0.092\n",
      "[71, 300] loss: 0.095\n",
      "[71, 360] loss: 0.092\n",
      "Epoch: 71 -> Loss: 0.0390153750777\n",
      "Epoch: 71 -> Test Accuracy: 87.58\n",
      "[72, 60] loss: 0.095\n",
      "[72, 120] loss: 0.084\n",
      "[72, 180] loss: 0.089\n",
      "[72, 240] loss: 0.086\n",
      "[72, 300] loss: 0.093\n",
      "[72, 360] loss: 0.092\n",
      "Epoch: 72 -> Loss: 0.157563358545\n",
      "Epoch: 72 -> Test Accuracy: 87.48\n",
      "[73, 60] loss: 0.098\n",
      "[73, 120] loss: 0.086\n",
      "[73, 180] loss: 0.089\n",
      "[73, 240] loss: 0.092\n",
      "[73, 300] loss: 0.089\n",
      "[73, 360] loss: 0.098\n",
      "Epoch: 73 -> Loss: 0.1063657552\n",
      "Epoch: 73 -> Test Accuracy: 87.41\n",
      "[74, 60] loss: 0.088\n",
      "[74, 120] loss: 0.090\n",
      "[74, 180] loss: 0.096\n",
      "[74, 240] loss: 0.089\n",
      "[74, 300] loss: 0.094\n",
      "[74, 360] loss: 0.085\n",
      "Epoch: 74 -> Loss: 0.074556030333\n",
      "Epoch: 74 -> Test Accuracy: 87.38\n",
      "[75, 60] loss: 0.096\n",
      "[75, 120] loss: 0.084\n",
      "[75, 180] loss: 0.094\n",
      "[75, 240] loss: 0.086\n",
      "[75, 300] loss: 0.095\n",
      "[75, 360] loss: 0.094\n",
      "Epoch: 75 -> Loss: 0.0970042943954\n",
      "Epoch: 75 -> Test Accuracy: 87.45\n",
      "[76, 60] loss: 0.085\n",
      "[76, 120] loss: 0.091\n",
      "[76, 180] loss: 0.089\n",
      "[76, 240] loss: 0.089\n",
      "[76, 300] loss: 0.094\n",
      "[76, 360] loss: 0.088\n",
      "Epoch: 76 -> Loss: 0.060628592968\n",
      "Epoch: 76 -> Test Accuracy: 87.38\n",
      "[77, 60] loss: 0.090\n",
      "[77, 120] loss: 0.091\n",
      "[77, 180] loss: 0.088\n",
      "[77, 240] loss: 0.090\n",
      "[77, 300] loss: 0.085\n",
      "[77, 360] loss: 0.085\n",
      "Epoch: 77 -> Loss: 0.0850139707327\n",
      "Epoch: 77 -> Test Accuracy: 87.4\n",
      "[78, 60] loss: 0.090\n",
      "[78, 120] loss: 0.091\n",
      "[78, 180] loss: 0.085\n",
      "[78, 240] loss: 0.084\n",
      "[78, 300] loss: 0.087\n",
      "[78, 360] loss: 0.082\n",
      "Epoch: 78 -> Loss: 0.0912916883826\n",
      "Epoch: 78 -> Test Accuracy: 87.37\n",
      "[79, 60] loss: 0.086\n",
      "[79, 120] loss: 0.080\n",
      "[79, 180] loss: 0.099\n",
      "[79, 240] loss: 0.084\n",
      "[79, 300] loss: 0.090\n",
      "[79, 360] loss: 0.085\n",
      "Epoch: 79 -> Loss: 0.0399698093534\n",
      "Epoch: 79 -> Test Accuracy: 87.47\n",
      "[80, 60] loss: 0.078\n",
      "[80, 120] loss: 0.091\n",
      "[80, 180] loss: 0.078\n",
      "[80, 240] loss: 0.082\n",
      "[80, 300] loss: 0.088\n",
      "[80, 360] loss: 0.090\n",
      "Epoch: 80 -> Loss: 0.221188545227\n",
      "Epoch: 80 -> Test Accuracy: 87.39\n",
      "[81, 60] loss: 0.080\n",
      "[81, 120] loss: 0.083\n",
      "[81, 180] loss: 0.094\n",
      "[81, 240] loss: 0.086\n",
      "[81, 300] loss: 0.087\n",
      "[81, 360] loss: 0.086\n",
      "Epoch: 81 -> Loss: 0.0999411121011\n",
      "Epoch: 81 -> Test Accuracy: 87.25\n",
      "[82, 60] loss: 0.081\n",
      "[82, 120] loss: 0.083\n",
      "[82, 180] loss: 0.084\n",
      "[82, 240] loss: 0.091\n",
      "[82, 300] loss: 0.087\n",
      "[82, 360] loss: 0.086\n",
      "Epoch: 82 -> Loss: 0.0594945773482\n",
      "Epoch: 82 -> Test Accuracy: 87.4\n",
      "[83, 60] loss: 0.085\n",
      "[83, 120] loss: 0.087\n",
      "[83, 180] loss: 0.089\n",
      "[83, 240] loss: 0.086\n",
      "[83, 300] loss: 0.078\n",
      "[83, 360] loss: 0.085\n",
      "Epoch: 83 -> Loss: 0.0747034028172\n",
      "Epoch: 83 -> Test Accuracy: 87.29\n",
      "[84, 60] loss: 0.078\n",
      "[84, 120] loss: 0.086\n",
      "[84, 180] loss: 0.085\n",
      "[84, 240] loss: 0.085\n",
      "[84, 300] loss: 0.082\n",
      "[84, 360] loss: 0.087\n",
      "Epoch: 84 -> Loss: 0.0988084152341\n",
      "Epoch: 84 -> Test Accuracy: 87.3\n",
      "[85, 60] loss: 0.082\n",
      "[85, 120] loss: 0.087\n",
      "[85, 180] loss: 0.085\n",
      "[85, 240] loss: 0.082\n",
      "[85, 300] loss: 0.083\n",
      "[85, 360] loss: 0.082\n",
      "Epoch: 85 -> Loss: 0.0846343711019\n",
      "Epoch: 85 -> Test Accuracy: 87.27\n",
      "[86, 60] loss: 0.082\n",
      "[86, 120] loss: 0.078\n",
      "[86, 180] loss: 0.080\n",
      "[86, 240] loss: 0.083\n",
      "[86, 300] loss: 0.085\n",
      "[86, 360] loss: 0.084\n",
      "Epoch: 86 -> Loss: 0.1024389714\n",
      "Epoch: 86 -> Test Accuracy: 87.33\n",
      "[87, 60] loss: 0.069\n",
      "[87, 120] loss: 0.084\n",
      "[87, 180] loss: 0.077\n",
      "[87, 240] loss: 0.081\n",
      "[87, 300] loss: 0.079\n",
      "[87, 360] loss: 0.086\n",
      "Epoch: 87 -> Loss: 0.102925218642\n",
      "Epoch: 87 -> Test Accuracy: 87.37\n",
      "[88, 60] loss: 0.077\n",
      "[88, 120] loss: 0.079\n",
      "[88, 180] loss: 0.082\n",
      "[88, 240] loss: 0.080\n",
      "[88, 300] loss: 0.081\n",
      "[88, 360] loss: 0.087\n",
      "Epoch: 88 -> Loss: 0.0587773621082\n",
      "Epoch: 88 -> Test Accuracy: 87.27\n",
      "[89, 60] loss: 0.083\n",
      "[89, 120] loss: 0.083\n",
      "[89, 180] loss: 0.080\n",
      "[89, 240] loss: 0.084\n",
      "[89, 300] loss: 0.083\n",
      "[89, 360] loss: 0.085\n",
      "Epoch: 89 -> Loss: 0.0700077265501\n",
      "Epoch: 89 -> Test Accuracy: 87.35\n",
      "[90, 60] loss: 0.073\n",
      "[90, 120] loss: 0.085\n",
      "[90, 180] loss: 0.076\n",
      "[90, 240] loss: 0.080\n",
      "[90, 300] loss: 0.081\n",
      "[90, 360] loss: 0.084\n",
      "Epoch: 90 -> Loss: 0.144710034132\n",
      "Epoch: 90 -> Test Accuracy: 87.27\n",
      "[91, 60] loss: 0.076\n",
      "[91, 120] loss: 0.072\n",
      "[91, 180] loss: 0.078\n",
      "[91, 240] loss: 0.085\n",
      "[91, 300] loss: 0.087\n",
      "[91, 360] loss: 0.078\n",
      "Epoch: 91 -> Loss: 0.0391719564795\n",
      "Epoch: 91 -> Test Accuracy: 87.25\n",
      "[92, 60] loss: 0.078\n",
      "[92, 120] loss: 0.081\n",
      "[92, 180] loss: 0.077\n",
      "[92, 240] loss: 0.081\n",
      "[92, 300] loss: 0.079\n",
      "[92, 360] loss: 0.077\n",
      "Epoch: 92 -> Loss: 0.0433510020375\n",
      "Epoch: 92 -> Test Accuracy: 87.34\n",
      "[93, 60] loss: 0.078\n",
      "[93, 120] loss: 0.077\n",
      "[93, 180] loss: 0.083\n",
      "[93, 240] loss: 0.078\n",
      "[93, 300] loss: 0.072\n",
      "[93, 360] loss: 0.087\n",
      "Epoch: 93 -> Loss: 0.0474859848619\n",
      "Epoch: 93 -> Test Accuracy: 87.48\n",
      "[94, 60] loss: 0.078\n",
      "[94, 120] loss: 0.081\n",
      "[94, 180] loss: 0.080\n",
      "[94, 240] loss: 0.087\n",
      "[94, 300] loss: 0.077\n",
      "[94, 360] loss: 0.087\n",
      "Epoch: 94 -> Loss: 0.0395618267357\n",
      "Epoch: 94 -> Test Accuracy: 87.48\n",
      "[95, 60] loss: 0.074\n",
      "[95, 120] loss: 0.079\n",
      "[95, 180] loss: 0.085\n",
      "[95, 240] loss: 0.078\n",
      "[95, 300] loss: 0.074\n",
      "[95, 360] loss: 0.077\n",
      "Epoch: 95 -> Loss: 0.074554271996\n",
      "Epoch: 95 -> Test Accuracy: 87.46\n",
      "[96, 60] loss: 0.076\n",
      "[96, 120] loss: 0.077\n",
      "[96, 180] loss: 0.077\n",
      "[96, 240] loss: 0.079\n",
      "[96, 300] loss: 0.083\n",
      "[96, 360] loss: 0.080\n",
      "Epoch: 96 -> Loss: 0.110460281372\n",
      "Epoch: 96 -> Test Accuracy: 87.5\n",
      "[97, 60] loss: 0.075\n",
      "[97, 120] loss: 0.079\n",
      "[97, 180] loss: 0.076\n",
      "[97, 240] loss: 0.076\n",
      "[97, 300] loss: 0.078\n",
      "[97, 360] loss: 0.079\n",
      "Epoch: 97 -> Loss: 0.0524679943919\n",
      "Epoch: 97 -> Test Accuracy: 87.5\n",
      "[98, 60] loss: 0.079\n",
      "[98, 120] loss: 0.081\n",
      "[98, 180] loss: 0.075\n",
      "[98, 240] loss: 0.075\n",
      "[98, 300] loss: 0.079\n",
      "[98, 360] loss: 0.077\n",
      "Epoch: 98 -> Loss: 0.0430227890611\n",
      "Epoch: 98 -> Test Accuracy: 87.43\n",
      "[99, 60] loss: 0.068\n",
      "[99, 120] loss: 0.073\n",
      "[99, 180] loss: 0.071\n",
      "[99, 240] loss: 0.078\n",
      "[99, 300] loss: 0.077\n",
      "[99, 360] loss: 0.080\n",
      "Epoch: 99 -> Loss: 0.0874961540103\n",
      "Epoch: 99 -> Test Accuracy: 87.27\n",
      "[100, 60] loss: 0.073\n",
      "[100, 120] loss: 0.078\n",
      "[100, 180] loss: 0.076\n",
      "[100, 240] loss: 0.071\n",
      "[100, 300] loss: 0.077\n",
      "[100, 360] loss: 0.079\n",
      "Epoch: 100 -> Loss: 0.0354603752494\n",
      "Epoch: 100 -> Test Accuracy: 87.36\n",
      "Finished Training\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [128 x 3072], m2: [12288 x 200] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-74487ea16ff2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train NonLinearClassifiers on feature map of net_3block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m block5_avg_loss_log, block5_avg_valid_accuracy_log, block5_avg_test_accuracy_log, block5_avg_max_accuracy, block5_best_epoch = tr.train_all_blocks(5, 10, [0.1, 0.02, 0.004, 0.0008], [20, 40, 45, 100], 0.9, 5e-4, net_block5_avg, \n\u001b[0;32m----> 3\u001b[0;31m                                         criterion, trainloader, None, testloader) \n\u001b[0m",
      "\u001b[0;32m/home/leo/Dropbox/Bachelorarbeit/Peer Review FeatureLearningRotNet/functionalities/trainer.pyc\u001b[0m in \u001b[0;36mtrain_all_blocks\u001b[0;34m(conv_block_num, num_classes, lr_list, epoch_change, momentum, weight_decay, net, criterion, trainloader, validloader, testloader, use_paper_metric, use_ConvClassifier)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mtmp_loss_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_valid_accuracy_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_test_accuracy_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_max_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_best_epoch\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             adaptive_learning(lr_list, epoch_change, momentum, weight_decay, net, criterion, trainloader, validloader,\n\u001b[0;32m--> 332\u001b[0;31m                               testloader, clf, i+1, None, use_paper_metric, use_ConvClassifier)\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mloss_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_loss_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/Dropbox/Bachelorarbeit/Peer Review FeatureLearningRotNet/functionalities/trainer.pyc\u001b[0m in \u001b[0;36madaptive_learning\u001b[0;34m(lr_list, epoch_change, momentum, weight_decay, net, criterion, trainloader, validloader, testloader, classifier, conv_block_num, rot, use_paper_metric, use_ConvClassifier)\u001b[0m\n\u001b[1;32m    274\u001b[0m             train(num_epoch, net, criterion, optimizer, trainloader, validloader, testloader, classifier,\n\u001b[1;32m    275\u001b[0m                   \u001b[0mconv_block_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprinting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_paper_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                   use_ConvClassifier)\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mloss_log\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtmp_loss_log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/Dropbox/Bachelorarbeit/Peer Review FeatureLearningRotNet/functionalities/trainer.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_epoch, net, criterion, optimizer, trainloader, validloader, testloader, classifier, conv_block_num, epoch_offset, rot, printing, max_accuracy, best_epoch, use_paper_metric, use_ConvClassifier)\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_feat_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_feat_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconv_block_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/Dropbox/Bachelorarbeit/Peer Review FeatureLearningRotNet/architecture/NonLinearClassifier.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, feat)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \"\"\"\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/torch/nn/modules/container.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/torch/nn/modules/linear.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [128 x 3072], m2: [12288 x 200] at /opt/conda/conda-bld/pytorch_1525909934016/work/aten/src/THC/generic/THCTensorMathBlas.cu:249"
     ]
    }
   ],
   "source": [
    "# train NonLinearClassifiers on feature map of net_3block\n",
    "block5_avg_loss_log, block5_avg_valid_accuracy_log, block5_avg_test_accuracy_log, block5_avg_max_accuracy, \\\n",
    "block5_best_epoch = tr.train_all_blocks(5, 10, [0.1, 0.02, 0.004, 0.0008], [20, 40, 45, 100], 0.9, 5e-4, net_block5_avg, \n",
    "                                        criterion, trainloader, None, testloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train ConvClassifiers on feature map of net_3block\n",
    "conv_block5_avg_loss_log, conv_block5_avg_valid_accuracy_log, conv_block5_avg_test_accuracy_log, \\\n",
    "conv_block5_avg_max_accuracy, conv_block5_avg_best_epoch = tr.train_all_blocks(5, 10, [0.1, 0.02, 0.004, 0.0008], \\\n",
    "    [35, 70, 85, 100], 0.9, 5e-4, net_block5_avg, criterion, trainloader, None, testloader, use_ConvClassifier=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename files\n",
    "fm.add_block_to_name(5, [100, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised NIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In the code of the paper a 3 convolutional block RotNet was used for the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize networks\n",
    "net_class = RN.RotNet(num_classes=10, num_conv_block=3, add_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.794\n",
      "[1, 120] loss: 1.453\n",
      "[1, 180] loss: 1.334\n",
      "[1, 240] loss: 1.226\n",
      "[1, 300] loss: 1.148\n",
      "[1, 360] loss: 1.098\n",
      "Epoch: 1 -> Loss: 0.989088892937\n",
      "Epoch: 1 -> Test Accuracy: 60.22\n",
      "[2, 60] loss: 1.020\n",
      "[2, 120] loss: 1.000\n",
      "[2, 180] loss: 0.975\n",
      "[2, 240] loss: 0.921\n",
      "[2, 300] loss: 0.931\n",
      "[2, 360] loss: 0.870\n",
      "Epoch: 2 -> Loss: 0.792598664761\n",
      "Epoch: 2 -> Test Accuracy: 68.92\n",
      "[3, 60] loss: 0.849\n",
      "[3, 120] loss: 0.823\n",
      "[3, 180] loss: 0.795\n",
      "[3, 240] loss: 0.764\n",
      "[3, 300] loss: 0.785\n",
      "[3, 360] loss: 0.769\n",
      "Epoch: 3 -> Loss: 0.676234722137\n",
      "Epoch: 3 -> Test Accuracy: 72.56\n",
      "[4, 60] loss: 0.740\n",
      "[4, 120] loss: 0.716\n",
      "[4, 180] loss: 0.709\n",
      "[4, 240] loss: 0.706\n",
      "[4, 300] loss: 0.695\n",
      "[4, 360] loss: 0.700\n",
      "Epoch: 4 -> Loss: 0.625342488289\n",
      "Epoch: 4 -> Test Accuracy: 74.46\n",
      "[5, 60] loss: 0.668\n",
      "[5, 120] loss: 0.656\n",
      "[5, 180] loss: 0.656\n",
      "[5, 240] loss: 0.651\n",
      "[5, 300] loss: 0.664\n",
      "[5, 360] loss: 0.661\n",
      "Epoch: 5 -> Loss: 0.504440784454\n",
      "Epoch: 5 -> Test Accuracy: 75.3\n",
      "[6, 60] loss: 0.629\n",
      "[6, 120] loss: 0.618\n",
      "[6, 180] loss: 0.629\n",
      "[6, 240] loss: 0.628\n",
      "[6, 300] loss: 0.602\n",
      "[6, 360] loss: 0.634\n",
      "Epoch: 6 -> Loss: 0.620152413845\n",
      "Epoch: 6 -> Test Accuracy: 75.91\n",
      "[7, 60] loss: 0.584\n",
      "[7, 120] loss: 0.583\n",
      "[7, 180] loss: 0.603\n",
      "[7, 240] loss: 0.593\n",
      "[7, 300] loss: 0.585\n",
      "[7, 360] loss: 0.593\n",
      "Epoch: 7 -> Loss: 0.640753090382\n",
      "Epoch: 7 -> Test Accuracy: 78.39\n",
      "[8, 60] loss: 0.569\n",
      "[8, 120] loss: 0.564\n",
      "[8, 180] loss: 0.559\n",
      "[8, 240] loss: 0.564\n",
      "[8, 300] loss: 0.592\n",
      "[8, 360] loss: 0.575\n",
      "Epoch: 8 -> Loss: 0.802178680897\n",
      "Epoch: 8 -> Test Accuracy: 77.16\n",
      "[9, 60] loss: 0.552\n",
      "[9, 120] loss: 0.550\n",
      "[9, 180] loss: 0.534\n",
      "[9, 240] loss: 0.546\n",
      "[9, 300] loss: 0.558\n",
      "[9, 360] loss: 0.534\n",
      "Epoch: 9 -> Loss: 0.793254971504\n",
      "Epoch: 9 -> Test Accuracy: 78.88\n",
      "[10, 60] loss: 0.517\n",
      "[10, 120] loss: 0.534\n",
      "[10, 180] loss: 0.543\n",
      "[10, 240] loss: 0.521\n",
      "[10, 300] loss: 0.534\n",
      "[10, 360] loss: 0.545\n",
      "Epoch: 10 -> Loss: 0.384285777807\n",
      "Epoch: 10 -> Test Accuracy: 79.33\n",
      "[11, 60] loss: 0.500\n",
      "[11, 120] loss: 0.522\n",
      "[11, 180] loss: 0.508\n",
      "[11, 240] loss: 0.522\n",
      "[11, 300] loss: 0.536\n",
      "[11, 360] loss: 0.504\n",
      "Epoch: 11 -> Loss: 0.577188074589\n",
      "Epoch: 11 -> Test Accuracy: 79.07\n",
      "[12, 60] loss: 0.501\n",
      "[12, 120] loss: 0.494\n",
      "[12, 180] loss: 0.503\n",
      "[12, 240] loss: 0.528\n",
      "[12, 300] loss: 0.514\n",
      "[12, 360] loss: 0.514\n",
      "Epoch: 12 -> Loss: 0.561318576336\n",
      "Epoch: 12 -> Test Accuracy: 80.7\n",
      "[13, 60] loss: 0.487\n",
      "[13, 120] loss: 0.518\n",
      "[13, 180] loss: 0.500\n",
      "[13, 240] loss: 0.490\n",
      "[13, 300] loss: 0.502\n",
      "[13, 360] loss: 0.487\n",
      "Epoch: 13 -> Loss: 0.579890489578\n",
      "Epoch: 13 -> Test Accuracy: 80.58\n",
      "[14, 60] loss: 0.492\n",
      "[14, 120] loss: 0.473\n",
      "[14, 180] loss: 0.484\n",
      "[14, 240] loss: 0.475\n",
      "[14, 300] loss: 0.507\n",
      "[14, 360] loss: 0.490\n",
      "Epoch: 14 -> Loss: 0.641694128513\n",
      "Epoch: 14 -> Test Accuracy: 80.56\n",
      "[15, 60] loss: 0.470\n",
      "[15, 120] loss: 0.459\n",
      "[15, 180] loss: 0.502\n",
      "[15, 240] loss: 0.486\n",
      "[15, 300] loss: 0.479\n",
      "[15, 360] loss: 0.482\n",
      "Epoch: 15 -> Loss: 0.55553150177\n",
      "Epoch: 15 -> Test Accuracy: 79.93\n",
      "[16, 60] loss: 0.443\n",
      "[16, 120] loss: 0.457\n",
      "[16, 180] loss: 0.486\n",
      "[16, 240] loss: 0.480\n",
      "[16, 300] loss: 0.504\n",
      "[16, 360] loss: 0.477\n",
      "Epoch: 16 -> Loss: 0.673222005367\n",
      "Epoch: 16 -> Test Accuracy: 81.29\n",
      "[17, 60] loss: 0.454\n",
      "[17, 120] loss: 0.491\n",
      "[17, 180] loss: 0.458\n",
      "[17, 240] loss: 0.457\n",
      "[17, 300] loss: 0.486\n",
      "[17, 360] loss: 0.464\n",
      "Epoch: 17 -> Loss: 0.517729103565\n",
      "Epoch: 17 -> Test Accuracy: 81.51\n",
      "[18, 60] loss: 0.455\n",
      "[18, 120] loss: 0.456\n",
      "[18, 180] loss: 0.452\n",
      "[18, 240] loss: 0.494\n",
      "[18, 300] loss: 0.462\n",
      "[18, 360] loss: 0.443\n",
      "Epoch: 18 -> Loss: 0.497783750296\n",
      "Epoch: 18 -> Test Accuracy: 81.62\n",
      "[19, 60] loss: 0.443\n",
      "[19, 120] loss: 0.465\n",
      "[19, 180] loss: 0.441\n",
      "[19, 240] loss: 0.459\n",
      "[19, 300] loss: 0.473\n",
      "[19, 360] loss: 0.457\n",
      "Epoch: 19 -> Loss: 0.445433288813\n",
      "Epoch: 19 -> Test Accuracy: 81.64\n",
      "[20, 60] loss: 0.455\n",
      "[20, 120] loss: 0.422\n",
      "[20, 180] loss: 0.454\n",
      "[20, 240] loss: 0.440\n",
      "[20, 300] loss: 0.467\n",
      "[20, 360] loss: 0.463\n",
      "Epoch: 20 -> Loss: 0.599771082401\n",
      "Epoch: 20 -> Test Accuracy: 81.75\n",
      "[21, 60] loss: 0.428\n",
      "[21, 120] loss: 0.448\n",
      "[21, 180] loss: 0.433\n",
      "[21, 240] loss: 0.460\n",
      "[21, 300] loss: 0.464\n",
      "[21, 360] loss: 0.456\n",
      "Epoch: 21 -> Loss: 0.415910393\n",
      "Epoch: 21 -> Test Accuracy: 81.77\n",
      "[22, 60] loss: 0.441\n",
      "[22, 120] loss: 0.449\n",
      "[22, 180] loss: 0.431\n",
      "[22, 240] loss: 0.432\n",
      "[22, 300] loss: 0.439\n",
      "[22, 360] loss: 0.435\n",
      "Epoch: 22 -> Loss: 0.205844804645\n",
      "Epoch: 22 -> Test Accuracy: 81.33\n",
      "[23, 60] loss: 0.428\n",
      "[23, 120] loss: 0.417\n",
      "[23, 180] loss: 0.434\n",
      "[23, 240] loss: 0.432\n",
      "[23, 300] loss: 0.441\n",
      "[23, 360] loss: 0.465\n",
      "Epoch: 23 -> Loss: 0.48451513052\n",
      "Epoch: 23 -> Test Accuracy: 80.55\n",
      "[24, 60] loss: 0.406\n",
      "[24, 120] loss: 0.428\n",
      "[24, 180] loss: 0.450\n",
      "[24, 240] loss: 0.451\n",
      "[24, 300] loss: 0.430\n",
      "[24, 360] loss: 0.451\n",
      "Epoch: 24 -> Loss: 0.43328088522\n",
      "Epoch: 24 -> Test Accuracy: 82.17\n",
      "[25, 60] loss: 0.417\n",
      "[25, 120] loss: 0.440\n",
      "[25, 180] loss: 0.422\n",
      "[25, 240] loss: 0.437\n",
      "[25, 300] loss: 0.449\n",
      "[25, 360] loss: 0.450\n",
      "Epoch: 25 -> Loss: 0.226140528917\n",
      "Epoch: 25 -> Test Accuracy: 80.97\n",
      "[26, 60] loss: 0.412\n",
      "[26, 120] loss: 0.419\n",
      "[26, 180] loss: 0.433\n",
      "[26, 240] loss: 0.421\n",
      "[26, 300] loss: 0.447\n",
      "[26, 360] loss: 0.441\n",
      "Epoch: 26 -> Loss: 0.505807638168\n",
      "Epoch: 26 -> Test Accuracy: 82.8\n",
      "[27, 60] loss: 0.408\n",
      "[27, 120] loss: 0.418\n",
      "[27, 180] loss: 0.416\n",
      "[27, 240] loss: 0.434\n",
      "[27, 300] loss: 0.433\n",
      "[27, 360] loss: 0.422\n",
      "Epoch: 27 -> Loss: 0.539763748646\n",
      "Epoch: 27 -> Test Accuracy: 83.15\n",
      "[28, 60] loss: 0.399\n",
      "[28, 120] loss: 0.407\n",
      "[28, 180] loss: 0.448\n",
      "[28, 240] loss: 0.406\n",
      "[28, 300] loss: 0.418\n",
      "[28, 360] loss: 0.449\n",
      "Epoch: 28 -> Loss: 0.402915149927\n",
      "Epoch: 28 -> Test Accuracy: 82.85\n",
      "[29, 60] loss: 0.394\n",
      "[29, 120] loss: 0.402\n",
      "[29, 180] loss: 0.411\n",
      "[29, 240] loss: 0.430\n",
      "[29, 300] loss: 0.433\n",
      "[29, 360] loss: 0.416\n",
      "Epoch: 29 -> Loss: 0.382785618305\n",
      "Epoch: 29 -> Test Accuracy: 81.72\n",
      "[30, 60] loss: 0.423\n",
      "[30, 120] loss: 0.403\n",
      "[30, 180] loss: 0.393\n",
      "[30, 240] loss: 0.420\n",
      "[30, 300] loss: 0.449\n",
      "[30, 360] loss: 0.430\n",
      "Epoch: 30 -> Loss: 0.528232634068\n",
      "Epoch: 30 -> Test Accuracy: 82.87\n",
      "[31, 60] loss: 0.403\n",
      "[31, 120] loss: 0.387\n",
      "[31, 180] loss: 0.404\n",
      "[31, 240] loss: 0.423\n",
      "[31, 300] loss: 0.420\n",
      "[31, 360] loss: 0.429\n",
      "Epoch: 31 -> Loss: 0.445465147495\n",
      "Epoch: 31 -> Test Accuracy: 82.0\n",
      "[32, 60] loss: 0.382\n",
      "[32, 120] loss: 0.402\n",
      "[32, 180] loss: 0.403\n",
      "[32, 240] loss: 0.435\n",
      "[32, 300] loss: 0.420\n",
      "[32, 360] loss: 0.419\n",
      "Epoch: 32 -> Loss: 0.393837422132\n",
      "Epoch: 32 -> Test Accuracy: 83.07\n",
      "[33, 60] loss: 0.394\n",
      "[33, 120] loss: 0.389\n",
      "[33, 180] loss: 0.414\n",
      "[33, 240] loss: 0.423\n",
      "[33, 300] loss: 0.400\n",
      "[33, 360] loss: 0.421\n",
      "Epoch: 33 -> Loss: 0.501782536507\n",
      "Epoch: 33 -> Test Accuracy: 81.18\n",
      "[34, 60] loss: 0.394\n",
      "[34, 120] loss: 0.415\n",
      "[34, 180] loss: 0.414\n",
      "[34, 240] loss: 0.428\n",
      "[34, 300] loss: 0.402\n",
      "[34, 360] loss: 0.426\n",
      "Epoch: 34 -> Loss: 0.531346440315\n",
      "Epoch: 34 -> Test Accuracy: 82.19\n",
      "[35, 60] loss: 0.380\n",
      "[35, 120] loss: 0.398\n",
      "[35, 180] loss: 0.414\n",
      "[35, 240] loss: 0.435\n",
      "[35, 300] loss: 0.408\n",
      "[35, 360] loss: 0.416\n",
      "Epoch: 35 -> Loss: 0.330902278423\n",
      "Epoch: 35 -> Test Accuracy: 83.77\n",
      "[36, 60] loss: 0.388\n",
      "[36, 120] loss: 0.414\n",
      "[36, 180] loss: 0.404\n",
      "[36, 240] loss: 0.402\n",
      "[36, 300] loss: 0.408\n",
      "[36, 360] loss: 0.414\n",
      "Epoch: 36 -> Loss: 0.44836807251\n",
      "Epoch: 36 -> Test Accuracy: 83.2\n",
      "[37, 60] loss: 0.399\n",
      "[37, 120] loss: 0.410\n",
      "[37, 180] loss: 0.411\n",
      "[37, 240] loss: 0.419\n",
      "[37, 300] loss: 0.413\n",
      "[37, 360] loss: 0.404\n",
      "Epoch: 37 -> Loss: 0.530152797699\n",
      "Epoch: 37 -> Test Accuracy: 82.51\n",
      "[38, 60] loss: 0.401\n",
      "[38, 120] loss: 0.377\n",
      "[38, 180] loss: 0.393\n",
      "[38, 240] loss: 0.411\n",
      "[38, 300] loss: 0.413\n",
      "[38, 360] loss: 0.401\n",
      "Epoch: 38 -> Loss: 0.288441091776\n",
      "Epoch: 38 -> Test Accuracy: 82.86\n",
      "[39, 60] loss: 0.402\n",
      "[39, 120] loss: 0.394\n",
      "[39, 180] loss: 0.398\n",
      "[39, 240] loss: 0.402\n",
      "[39, 300] loss: 0.406\n",
      "[39, 360] loss: 0.435\n",
      "Epoch: 39 -> Loss: 0.561746239662\n",
      "Epoch: 39 -> Test Accuracy: 84.04\n",
      "[40, 60] loss: 0.373\n",
      "[40, 120] loss: 0.382\n",
      "[40, 180] loss: 0.410\n",
      "[40, 240] loss: 0.420\n",
      "[40, 300] loss: 0.390\n",
      "[40, 360] loss: 0.396\n",
      "Epoch: 40 -> Loss: 0.34759286046\n",
      "Epoch: 40 -> Test Accuracy: 83.12\n",
      "[41, 60] loss: 0.383\n",
      "[41, 120] loss: 0.390\n",
      "[41, 180] loss: 0.397\n",
      "[41, 240] loss: 0.416\n",
      "[41, 300] loss: 0.414\n",
      "[41, 360] loss: 0.415\n",
      "Epoch: 41 -> Loss: 0.417120069265\n",
      "Epoch: 41 -> Test Accuracy: 83.1\n",
      "[42, 60] loss: 0.371\n",
      "[42, 120] loss: 0.375\n",
      "[42, 180] loss: 0.408\n",
      "[42, 240] loss: 0.415\n",
      "[42, 300] loss: 0.421\n",
      "[42, 360] loss: 0.412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.324781596661\n",
      "Epoch: 42 -> Test Accuracy: 83.55\n",
      "[43, 60] loss: 0.372\n",
      "[43, 120] loss: 0.379\n",
      "[43, 180] loss: 0.407\n",
      "[43, 240] loss: 0.411\n",
      "[43, 300] loss: 0.412\n",
      "[43, 360] loss: 0.419\n",
      "Epoch: 43 -> Loss: 0.386346638203\n",
      "Epoch: 43 -> Test Accuracy: 81.11\n",
      "[44, 60] loss: 0.386\n",
      "[44, 120] loss: 0.376\n",
      "[44, 180] loss: 0.389\n",
      "[44, 240] loss: 0.392\n",
      "[44, 300] loss: 0.404\n",
      "[44, 360] loss: 0.400\n",
      "Epoch: 44 -> Loss: 0.373041033745\n",
      "Epoch: 44 -> Test Accuracy: 83.11\n",
      "[45, 60] loss: 0.370\n",
      "[45, 120] loss: 0.371\n",
      "[45, 180] loss: 0.393\n",
      "[45, 240] loss: 0.400\n",
      "[45, 300] loss: 0.395\n",
      "[45, 360] loss: 0.422\n",
      "Epoch: 45 -> Loss: 0.541353464127\n",
      "Epoch: 45 -> Test Accuracy: 82.71\n",
      "[46, 60] loss: 0.379\n",
      "[46, 120] loss: 0.372\n",
      "[46, 180] loss: 0.397\n",
      "[46, 240] loss: 0.412\n",
      "[46, 300] loss: 0.394\n",
      "[46, 360] loss: 0.413\n",
      "Epoch: 46 -> Loss: 0.397569149733\n",
      "Epoch: 46 -> Test Accuracy: 83.12\n",
      "[47, 60] loss: 0.363\n",
      "[47, 120] loss: 0.409\n",
      "[47, 180] loss: 0.402\n",
      "[47, 240] loss: 0.380\n",
      "[47, 300] loss: 0.394\n",
      "[47, 360] loss: 0.415\n",
      "Epoch: 47 -> Loss: 0.331615746021\n",
      "Epoch: 47 -> Test Accuracy: 82.31\n",
      "[48, 60] loss: 0.379\n",
      "[48, 120] loss: 0.370\n",
      "[48, 180] loss: 0.387\n",
      "[48, 240] loss: 0.399\n",
      "[48, 300] loss: 0.387\n",
      "[48, 360] loss: 0.399\n",
      "Epoch: 48 -> Loss: 0.42289981246\n",
      "Epoch: 48 -> Test Accuracy: 83.83\n",
      "[49, 60] loss: 0.370\n",
      "[49, 120] loss: 0.376\n",
      "[49, 180] loss: 0.379\n",
      "[49, 240] loss: 0.397\n",
      "[49, 300] loss: 0.418\n",
      "[49, 360] loss: 0.386\n",
      "Epoch: 49 -> Loss: 0.470990568399\n",
      "Epoch: 49 -> Test Accuracy: 82.75\n",
      "[50, 60] loss: 0.370\n",
      "[50, 120] loss: 0.410\n",
      "[50, 180] loss: 0.364\n",
      "[50, 240] loss: 0.396\n",
      "[50, 300] loss: 0.410\n",
      "[50, 360] loss: 0.402\n",
      "Epoch: 50 -> Loss: 0.246995657682\n",
      "Epoch: 50 -> Test Accuracy: 83.25\n",
      "[51, 60] loss: 0.382\n",
      "[51, 120] loss: 0.399\n",
      "[51, 180] loss: 0.375\n",
      "[51, 240] loss: 0.374\n",
      "[51, 300] loss: 0.403\n",
      "[51, 360] loss: 0.387\n",
      "Epoch: 51 -> Loss: 0.45343080163\n",
      "Epoch: 51 -> Test Accuracy: 82.63\n",
      "[52, 60] loss: 0.365\n",
      "[52, 120] loss: 0.377\n",
      "[52, 180] loss: 0.379\n",
      "[52, 240] loss: 0.402\n",
      "[52, 300] loss: 0.401\n",
      "[52, 360] loss: 0.396\n",
      "Epoch: 52 -> Loss: 0.358422338963\n",
      "Epoch: 52 -> Test Accuracy: 84.48\n",
      "[53, 60] loss: 0.362\n",
      "[53, 120] loss: 0.385\n",
      "[53, 180] loss: 0.405\n",
      "[53, 240] loss: 0.399\n",
      "[53, 300] loss: 0.393\n",
      "[53, 360] loss: 0.419\n",
      "Epoch: 53 -> Loss: 0.625765562057\n",
      "Epoch: 53 -> Test Accuracy: 83.89\n",
      "[54, 60] loss: 0.345\n",
      "[54, 120] loss: 0.383\n",
      "[54, 180] loss: 0.376\n",
      "[54, 240] loss: 0.373\n",
      "[54, 300] loss: 0.411\n",
      "[54, 360] loss: 0.417\n",
      "Epoch: 54 -> Loss: 0.538621306419\n",
      "Epoch: 54 -> Test Accuracy: 82.97\n",
      "[55, 60] loss: 0.361\n",
      "[55, 120] loss: 0.364\n",
      "[55, 180] loss: 0.394\n",
      "[55, 240] loss: 0.391\n",
      "[55, 300] loss: 0.396\n",
      "[55, 360] loss: 0.380\n",
      "Epoch: 55 -> Loss: 0.473729521036\n",
      "Epoch: 55 -> Test Accuracy: 84.12\n",
      "[56, 60] loss: 0.361\n",
      "[56, 120] loss: 0.383\n",
      "[56, 180] loss: 0.387\n",
      "[56, 240] loss: 0.395\n",
      "[56, 300] loss: 0.411\n",
      "[56, 360] loss: 0.390\n",
      "Epoch: 56 -> Loss: 0.514081537724\n",
      "Epoch: 56 -> Test Accuracy: 83.6\n",
      "[57, 60] loss: 0.369\n",
      "[57, 120] loss: 0.383\n",
      "[57, 180] loss: 0.379\n",
      "[57, 240] loss: 0.384\n",
      "[57, 300] loss: 0.406\n",
      "[57, 360] loss: 0.380\n",
      "Epoch: 57 -> Loss: 0.378554314375\n",
      "Epoch: 57 -> Test Accuracy: 83.53\n",
      "[58, 60] loss: 0.358\n",
      "[58, 120] loss: 0.377\n",
      "[58, 180] loss: 0.394\n",
      "[58, 240] loss: 0.404\n",
      "[58, 300] loss: 0.382\n",
      "[58, 360] loss: 0.385\n",
      "Epoch: 58 -> Loss: 0.273430883884\n",
      "Epoch: 58 -> Test Accuracy: 83.73\n",
      "[59, 60] loss: 0.356\n",
      "[59, 120] loss: 0.416\n",
      "[59, 180] loss: 0.374\n",
      "[59, 240] loss: 0.394\n",
      "[59, 300] loss: 0.382\n",
      "[59, 360] loss: 0.417\n",
      "Epoch: 59 -> Loss: 0.561969876289\n",
      "Epoch: 59 -> Test Accuracy: 83.73\n",
      "[60, 60] loss: 0.370\n",
      "[60, 120] loss: 0.377\n",
      "[60, 180] loss: 0.373\n",
      "[60, 240] loss: 0.389\n",
      "[60, 300] loss: 0.396\n",
      "[60, 360] loss: 0.401\n",
      "Epoch: 60 -> Loss: 0.352978587151\n",
      "Epoch: 60 -> Test Accuracy: 83.45\n",
      "[61, 60] loss: 0.283\n",
      "[61, 120] loss: 0.221\n",
      "[61, 180] loss: 0.222\n",
      "[61, 240] loss: 0.217\n",
      "[61, 300] loss: 0.185\n",
      "[61, 360] loss: 0.206\n",
      "Epoch: 61 -> Loss: 0.150876551867\n",
      "Epoch: 61 -> Test Accuracy: 89.13\n",
      "[62, 60] loss: 0.173\n",
      "[62, 120] loss: 0.173\n",
      "[62, 180] loss: 0.174\n",
      "[62, 240] loss: 0.169\n",
      "[62, 300] loss: 0.174\n",
      "[62, 360] loss: 0.185\n",
      "Epoch: 62 -> Loss: 0.173810645938\n",
      "Epoch: 62 -> Test Accuracy: 89.75\n",
      "[63, 60] loss: 0.143\n",
      "[63, 120] loss: 0.150\n",
      "[63, 180] loss: 0.165\n",
      "[63, 240] loss: 0.167\n",
      "[63, 300] loss: 0.161\n",
      "[63, 360] loss: 0.167\n",
      "Epoch: 63 -> Loss: 0.216121867299\n",
      "Epoch: 63 -> Test Accuracy: 89.62\n",
      "[64, 60] loss: 0.141\n",
      "[64, 120] loss: 0.142\n",
      "[64, 180] loss: 0.142\n",
      "[64, 240] loss: 0.158\n",
      "[64, 300] loss: 0.159\n",
      "[64, 360] loss: 0.143\n",
      "Epoch: 64 -> Loss: 0.192062705755\n",
      "Epoch: 64 -> Test Accuracy: 89.76\n",
      "[65, 60] loss: 0.132\n",
      "[65, 120] loss: 0.125\n",
      "[65, 180] loss: 0.131\n",
      "[65, 240] loss: 0.142\n",
      "[65, 300] loss: 0.152\n",
      "[65, 360] loss: 0.146\n",
      "Epoch: 65 -> Loss: 0.0942428261042\n",
      "Epoch: 65 -> Test Accuracy: 89.37\n",
      "[66, 60] loss: 0.122\n",
      "[66, 120] loss: 0.126\n",
      "[66, 180] loss: 0.121\n",
      "[66, 240] loss: 0.127\n",
      "[66, 300] loss: 0.134\n",
      "[66, 360] loss: 0.138\n",
      "Epoch: 66 -> Loss: 0.14484423399\n",
      "Epoch: 66 -> Test Accuracy: 89.04\n",
      "[67, 60] loss: 0.122\n",
      "[67, 120] loss: 0.126\n",
      "[67, 180] loss: 0.128\n",
      "[67, 240] loss: 0.129\n",
      "[67, 300] loss: 0.128\n",
      "[67, 360] loss: 0.146\n",
      "Epoch: 67 -> Loss: 0.101023696363\n",
      "Epoch: 67 -> Test Accuracy: 89.13\n",
      "[68, 60] loss: 0.116\n",
      "[68, 120] loss: 0.112\n",
      "[68, 180] loss: 0.124\n",
      "[68, 240] loss: 0.141\n",
      "[68, 300] loss: 0.136\n",
      "[68, 360] loss: 0.130\n",
      "Epoch: 68 -> Loss: 0.138984620571\n",
      "Epoch: 68 -> Test Accuracy: 89.25\n",
      "[69, 60] loss: 0.112\n",
      "[69, 120] loss: 0.124\n",
      "[69, 180] loss: 0.120\n",
      "[69, 240] loss: 0.130\n",
      "[69, 300] loss: 0.137\n",
      "[69, 360] loss: 0.143\n",
      "Epoch: 69 -> Loss: 0.120225608349\n",
      "Epoch: 69 -> Test Accuracy: 88.41\n",
      "[70, 60] loss: 0.114\n",
      "[70, 120] loss: 0.121\n",
      "[70, 180] loss: 0.150\n",
      "[70, 240] loss: 0.135\n",
      "[70, 300] loss: 0.150\n",
      "[70, 360] loss: 0.142\n",
      "Epoch: 70 -> Loss: 0.0975787416101\n",
      "Epoch: 70 -> Test Accuracy: 89.0\n",
      "[71, 60] loss: 0.115\n",
      "[71, 120] loss: 0.125\n",
      "[71, 180] loss: 0.121\n",
      "[71, 240] loss: 0.136\n",
      "[71, 300] loss: 0.140\n",
      "[71, 360] loss: 0.141\n",
      "Epoch: 71 -> Loss: 0.266739428043\n",
      "Epoch: 71 -> Test Accuracy: 88.97\n",
      "[72, 60] loss: 0.127\n",
      "[72, 120] loss: 0.136\n",
      "[72, 180] loss: 0.147\n",
      "[72, 240] loss: 0.147\n",
      "[72, 300] loss: 0.128\n",
      "[72, 360] loss: 0.127\n",
      "Epoch: 72 -> Loss: 0.192725881934\n",
      "Epoch: 72 -> Test Accuracy: 88.83\n",
      "[73, 60] loss: 0.125\n",
      "[73, 120] loss: 0.121\n",
      "[73, 180] loss: 0.124\n",
      "[73, 240] loss: 0.134\n",
      "[73, 300] loss: 0.149\n",
      "[73, 360] loss: 0.164\n",
      "Epoch: 73 -> Loss: 0.166150122881\n",
      "Epoch: 73 -> Test Accuracy: 88.43\n",
      "[74, 60] loss: 0.121\n",
      "[74, 120] loss: 0.123\n",
      "[74, 180] loss: 0.114\n",
      "[74, 240] loss: 0.125\n",
      "[74, 300] loss: 0.144\n",
      "[74, 360] loss: 0.152\n",
      "Epoch: 74 -> Loss: 0.105919376016\n",
      "Epoch: 74 -> Test Accuracy: 88.18\n",
      "[75, 60] loss: 0.123\n",
      "[75, 120] loss: 0.125\n",
      "[75, 180] loss: 0.132\n",
      "[75, 240] loss: 0.137\n",
      "[75, 300] loss: 0.151\n",
      "[75, 360] loss: 0.149\n",
      "Epoch: 75 -> Loss: 0.184201315045\n",
      "Epoch: 75 -> Test Accuracy: 88.44\n",
      "[76, 60] loss: 0.129\n",
      "[76, 120] loss: 0.114\n",
      "[76, 180] loss: 0.142\n",
      "[76, 240] loss: 0.144\n",
      "[76, 300] loss: 0.145\n",
      "[76, 360] loss: 0.154\n",
      "Epoch: 76 -> Loss: 0.0975792780519\n",
      "Epoch: 76 -> Test Accuracy: 88.3\n",
      "[77, 60] loss: 0.127\n",
      "[77, 120] loss: 0.131\n",
      "[77, 180] loss: 0.135\n",
      "[77, 240] loss: 0.142\n",
      "[77, 300] loss: 0.139\n",
      "[77, 360] loss: 0.144\n",
      "Epoch: 77 -> Loss: 0.121199890971\n",
      "Epoch: 77 -> Test Accuracy: 88.31\n",
      "[78, 60] loss: 0.120\n",
      "[78, 120] loss: 0.128\n",
      "[78, 180] loss: 0.144\n",
      "[78, 240] loss: 0.143\n",
      "[78, 300] loss: 0.144\n",
      "[78, 360] loss: 0.146\n",
      "Epoch: 78 -> Loss: 0.194299593568\n",
      "Epoch: 78 -> Test Accuracy: 88.02\n",
      "[79, 60] loss: 0.141\n",
      "[79, 120] loss: 0.125\n",
      "[79, 180] loss: 0.129\n",
      "[79, 240] loss: 0.137\n",
      "[79, 300] loss: 0.148\n",
      "[79, 360] loss: 0.132\n",
      "Epoch: 79 -> Loss: 0.107095241547\n",
      "Epoch: 79 -> Test Accuracy: 88.47\n",
      "[80, 60] loss: 0.114\n",
      "[80, 120] loss: 0.120\n",
      "[80, 180] loss: 0.131\n",
      "[80, 240] loss: 0.130\n",
      "[80, 300] loss: 0.152\n",
      "[80, 360] loss: 0.141\n",
      "Epoch: 80 -> Loss: 0.244767993689\n",
      "Epoch: 80 -> Test Accuracy: 88.45\n",
      "[81, 60] loss: 0.125\n",
      "[81, 120] loss: 0.125\n",
      "[81, 180] loss: 0.120\n",
      "[81, 240] loss: 0.151\n",
      "[81, 300] loss: 0.155\n",
      "[81, 360] loss: 0.133\n",
      "Epoch: 81 -> Loss: 0.113862551749\n",
      "Epoch: 81 -> Test Accuracy: 88.41\n",
      "[82, 60] loss: 0.128\n",
      "[82, 120] loss: 0.132\n",
      "[82, 180] loss: 0.140\n",
      "[82, 240] loss: 0.141\n",
      "[82, 300] loss: 0.134\n",
      "[82, 360] loss: 0.160\n",
      "Epoch: 82 -> Loss: 0.13775447011\n",
      "Epoch: 82 -> Test Accuracy: 87.97\n",
      "[83, 60] loss: 0.125\n",
      "[83, 120] loss: 0.128\n",
      "[83, 180] loss: 0.133\n",
      "[83, 240] loss: 0.141\n",
      "[83, 300] loss: 0.138\n",
      "[83, 360] loss: 0.138\n",
      "Epoch: 83 -> Loss: 0.0760831236839\n",
      "Epoch: 83 -> Test Accuracy: 87.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.112\n",
      "[84, 120] loss: 0.122\n",
      "[84, 180] loss: 0.123\n",
      "[84, 240] loss: 0.126\n",
      "[84, 300] loss: 0.133\n",
      "[84, 360] loss: 0.151\n",
      "Epoch: 84 -> Loss: 0.127449959517\n",
      "Epoch: 84 -> Test Accuracy: 88.31\n",
      "[85, 60] loss: 0.120\n",
      "[85, 120] loss: 0.125\n",
      "[85, 180] loss: 0.129\n",
      "[85, 240] loss: 0.138\n",
      "[85, 300] loss: 0.130\n",
      "[85, 360] loss: 0.150\n",
      "Epoch: 85 -> Loss: 0.136907219887\n",
      "Epoch: 85 -> Test Accuracy: 88.29\n",
      "[86, 60] loss: 0.119\n",
      "[86, 120] loss: 0.129\n",
      "[86, 180] loss: 0.129\n",
      "[86, 240] loss: 0.136\n",
      "[86, 300] loss: 0.124\n",
      "[86, 360] loss: 0.136\n",
      "Epoch: 86 -> Loss: 0.203608512878\n",
      "Epoch: 86 -> Test Accuracy: 88.7\n",
      "[87, 60] loss: 0.132\n",
      "[87, 120] loss: 0.133\n",
      "[87, 180] loss: 0.119\n",
      "[87, 240] loss: 0.141\n",
      "[87, 300] loss: 0.141\n",
      "[87, 360] loss: 0.143\n",
      "Epoch: 87 -> Loss: 0.186554715037\n",
      "Epoch: 87 -> Test Accuracy: 88.05\n",
      "[88, 60] loss: 0.121\n",
      "[88, 120] loss: 0.128\n",
      "[88, 180] loss: 0.122\n",
      "[88, 240] loss: 0.132\n",
      "[88, 300] loss: 0.135\n",
      "[88, 360] loss: 0.139\n",
      "Epoch: 88 -> Loss: 0.16848936677\n",
      "Epoch: 88 -> Test Accuracy: 88.09\n",
      "[89, 60] loss: 0.128\n",
      "[89, 120] loss: 0.123\n",
      "[89, 180] loss: 0.120\n",
      "[89, 240] loss: 0.133\n",
      "[89, 300] loss: 0.128\n",
      "[89, 360] loss: 0.141\n",
      "Epoch: 89 -> Loss: 0.171915084124\n",
      "Epoch: 89 -> Test Accuracy: 88.06\n",
      "[90, 60] loss: 0.123\n",
      "[90, 120] loss: 0.121\n",
      "[90, 180] loss: 0.121\n",
      "[90, 240] loss: 0.146\n",
      "[90, 300] loss: 0.148\n",
      "[90, 360] loss: 0.147\n",
      "Epoch: 90 -> Loss: 0.140754237771\n",
      "Epoch: 90 -> Test Accuracy: 88.52\n",
      "[91, 60] loss: 0.122\n",
      "[91, 120] loss: 0.132\n",
      "[91, 180] loss: 0.123\n",
      "[91, 240] loss: 0.118\n",
      "[91, 300] loss: 0.135\n",
      "[91, 360] loss: 0.137\n",
      "Epoch: 91 -> Loss: 0.0354556366801\n",
      "Epoch: 91 -> Test Accuracy: 87.85\n",
      "[92, 60] loss: 0.111\n",
      "[92, 120] loss: 0.118\n",
      "[92, 180] loss: 0.120\n",
      "[92, 240] loss: 0.128\n",
      "[92, 300] loss: 0.131\n",
      "[92, 360] loss: 0.142\n",
      "Epoch: 92 -> Loss: 0.154803663492\n",
      "Epoch: 92 -> Test Accuracy: 88.46\n",
      "[93, 60] loss: 0.117\n",
      "[93, 120] loss: 0.121\n",
      "[93, 180] loss: 0.112\n",
      "[93, 240] loss: 0.138\n",
      "[93, 300] loss: 0.140\n",
      "[93, 360] loss: 0.147\n",
      "Epoch: 93 -> Loss: 0.124383784831\n",
      "Epoch: 93 -> Test Accuracy: 88.71\n",
      "[94, 60] loss: 0.124\n",
      "[94, 120] loss: 0.120\n",
      "[94, 180] loss: 0.122\n",
      "[94, 240] loss: 0.137\n",
      "[94, 300] loss: 0.140\n",
      "[94, 360] loss: 0.130\n",
      "Epoch: 94 -> Loss: 0.139553830028\n",
      "Epoch: 94 -> Test Accuracy: 88.72\n",
      "[95, 60] loss: 0.115\n",
      "[95, 120] loss: 0.112\n",
      "[95, 180] loss: 0.124\n",
      "[95, 240] loss: 0.121\n",
      "[95, 300] loss: 0.128\n",
      "[95, 360] loss: 0.134\n",
      "Epoch: 95 -> Loss: 0.114479422569\n",
      "Epoch: 95 -> Test Accuracy: 88.83\n",
      "[96, 60] loss: 0.113\n",
      "[96, 120] loss: 0.121\n",
      "[96, 180] loss: 0.129\n",
      "[96, 240] loss: 0.124\n",
      "[96, 300] loss: 0.124\n",
      "[96, 360] loss: 0.136\n",
      "Epoch: 96 -> Loss: 0.117480203509\n",
      "Epoch: 96 -> Test Accuracy: 88.41\n",
      "[97, 60] loss: 0.121\n",
      "[97, 120] loss: 0.117\n",
      "[97, 180] loss: 0.115\n",
      "[97, 240] loss: 0.121\n",
      "[97, 300] loss: 0.131\n",
      "[97, 360] loss: 0.139\n",
      "Epoch: 97 -> Loss: 0.165293186903\n",
      "Epoch: 97 -> Test Accuracy: 88.6\n",
      "[98, 60] loss: 0.104\n",
      "[98, 120] loss: 0.114\n",
      "[98, 180] loss: 0.113\n",
      "[98, 240] loss: 0.121\n",
      "[98, 300] loss: 0.138\n",
      "[98, 360] loss: 0.134\n",
      "Epoch: 98 -> Loss: 0.0770029500127\n",
      "Epoch: 98 -> Test Accuracy: 88.53\n",
      "[99, 60] loss: 0.106\n",
      "[99, 120] loss: 0.114\n",
      "[99, 180] loss: 0.115\n",
      "[99, 240] loss: 0.126\n",
      "[99, 300] loss: 0.120\n",
      "[99, 360] loss: 0.129\n",
      "Epoch: 99 -> Loss: 0.206289798021\n",
      "Epoch: 99 -> Test Accuracy: 87.94\n",
      "[100, 60] loss: 0.106\n",
      "[100, 120] loss: 0.098\n",
      "[100, 180] loss: 0.116\n",
      "[100, 240] loss: 0.114\n",
      "[100, 300] loss: 0.128\n",
      "[100, 360] loss: 0.141\n",
      "Epoch: 100 -> Loss: 0.164075702429\n",
      "Epoch: 100 -> Test Accuracy: 87.85\n",
      "[101, 60] loss: 0.121\n",
      "[101, 120] loss: 0.121\n",
      "[101, 180] loss: 0.113\n",
      "[101, 240] loss: 0.114\n",
      "[101, 300] loss: 0.123\n",
      "[101, 360] loss: 0.130\n",
      "Epoch: 101 -> Loss: 0.177345186472\n",
      "Epoch: 101 -> Test Accuracy: 88.27\n",
      "[102, 60] loss: 0.116\n",
      "[102, 120] loss: 0.111\n",
      "[102, 180] loss: 0.114\n",
      "[102, 240] loss: 0.134\n",
      "[102, 300] loss: 0.122\n",
      "[102, 360] loss: 0.139\n",
      "Epoch: 102 -> Loss: 0.392570436001\n",
      "Epoch: 102 -> Test Accuracy: 87.64\n",
      "[103, 60] loss: 0.123\n",
      "[103, 120] loss: 0.111\n",
      "[103, 180] loss: 0.110\n",
      "[103, 240] loss: 0.129\n",
      "[103, 300] loss: 0.128\n",
      "[103, 360] loss: 0.150\n",
      "Epoch: 103 -> Loss: 0.242449074984\n",
      "Epoch: 103 -> Test Accuracy: 88.51\n",
      "[104, 60] loss: 0.111\n",
      "[104, 120] loss: 0.121\n",
      "[104, 180] loss: 0.113\n",
      "[104, 240] loss: 0.115\n",
      "[104, 300] loss: 0.125\n",
      "[104, 360] loss: 0.143\n",
      "Epoch: 104 -> Loss: 0.0710851401091\n",
      "Epoch: 104 -> Test Accuracy: 88.1\n",
      "[105, 60] loss: 0.104\n",
      "[105, 120] loss: 0.098\n",
      "[105, 180] loss: 0.118\n",
      "[105, 240] loss: 0.115\n",
      "[105, 300] loss: 0.138\n",
      "[105, 360] loss: 0.146\n",
      "Epoch: 105 -> Loss: 0.192751646042\n",
      "Epoch: 105 -> Test Accuracy: 88.25\n",
      "[106, 60] loss: 0.107\n",
      "[106, 120] loss: 0.120\n",
      "[106, 180] loss: 0.121\n",
      "[106, 240] loss: 0.126\n",
      "[106, 300] loss: 0.118\n",
      "[106, 360] loss: 0.122\n",
      "Epoch: 106 -> Loss: 0.173643916845\n",
      "Epoch: 106 -> Test Accuracy: 86.81\n",
      "[107, 60] loss: 0.105\n",
      "[107, 120] loss: 0.107\n",
      "[107, 180] loss: 0.108\n",
      "[107, 240] loss: 0.124\n",
      "[107, 300] loss: 0.121\n",
      "[107, 360] loss: 0.122\n",
      "Epoch: 107 -> Loss: 0.153318792582\n",
      "Epoch: 107 -> Test Accuracy: 88.16\n",
      "[108, 60] loss: 0.109\n",
      "[108, 120] loss: 0.112\n",
      "[108, 180] loss: 0.121\n",
      "[108, 240] loss: 0.117\n",
      "[108, 300] loss: 0.128\n",
      "[108, 360] loss: 0.136\n",
      "Epoch: 108 -> Loss: 0.133110269904\n",
      "Epoch: 108 -> Test Accuracy: 88.12\n",
      "[109, 60] loss: 0.115\n",
      "[109, 120] loss: 0.120\n",
      "[109, 180] loss: 0.110\n",
      "[109, 240] loss: 0.118\n",
      "[109, 300] loss: 0.122\n",
      "[109, 360] loss: 0.124\n",
      "Epoch: 109 -> Loss: 0.22077088058\n",
      "Epoch: 109 -> Test Accuracy: 87.62\n",
      "[110, 60] loss: 0.116\n",
      "[110, 120] loss: 0.112\n",
      "[110, 180] loss: 0.108\n",
      "[110, 240] loss: 0.132\n",
      "[110, 300] loss: 0.127\n",
      "[110, 360] loss: 0.128\n",
      "Epoch: 110 -> Loss: 0.148302406073\n",
      "Epoch: 110 -> Test Accuracy: 88.28\n",
      "[111, 60] loss: 0.106\n",
      "[111, 120] loss: 0.114\n",
      "[111, 180] loss: 0.127\n",
      "[111, 240] loss: 0.116\n",
      "[111, 300] loss: 0.122\n",
      "[111, 360] loss: 0.116\n",
      "Epoch: 111 -> Loss: 0.101910591125\n",
      "Epoch: 111 -> Test Accuracy: 88.74\n",
      "[112, 60] loss: 0.102\n",
      "[112, 120] loss: 0.103\n",
      "[112, 180] loss: 0.110\n",
      "[112, 240] loss: 0.114\n",
      "[112, 300] loss: 0.136\n",
      "[112, 360] loss: 0.134\n",
      "Epoch: 112 -> Loss: 0.139820635319\n",
      "Epoch: 112 -> Test Accuracy: 88.33\n",
      "[113, 60] loss: 0.106\n",
      "[113, 120] loss: 0.104\n",
      "[113, 180] loss: 0.106\n",
      "[113, 240] loss: 0.115\n",
      "[113, 300] loss: 0.119\n",
      "[113, 360] loss: 0.127\n",
      "Epoch: 113 -> Loss: 0.0812459290028\n",
      "Epoch: 113 -> Test Accuracy: 88.11\n",
      "[114, 60] loss: 0.114\n",
      "[114, 120] loss: 0.103\n",
      "[114, 180] loss: 0.110\n",
      "[114, 240] loss: 0.127\n",
      "[114, 300] loss: 0.120\n",
      "[114, 360] loss: 0.131\n",
      "Epoch: 114 -> Loss: 0.241338014603\n",
      "Epoch: 114 -> Test Accuracy: 88.53\n",
      "[115, 60] loss: 0.106\n",
      "[115, 120] loss: 0.107\n",
      "[115, 180] loss: 0.108\n",
      "[115, 240] loss: 0.117\n",
      "[115, 300] loss: 0.115\n",
      "[115, 360] loss: 0.118\n",
      "Epoch: 115 -> Loss: 0.159904807806\n",
      "Epoch: 115 -> Test Accuracy: 88.51\n",
      "[116, 60] loss: 0.113\n",
      "[116, 120] loss: 0.113\n",
      "[116, 180] loss: 0.125\n",
      "[116, 240] loss: 0.135\n",
      "[116, 300] loss: 0.123\n",
      "[116, 360] loss: 0.125\n",
      "Epoch: 116 -> Loss: 0.11884085834\n",
      "Epoch: 116 -> Test Accuracy: 88.47\n",
      "[117, 60] loss: 0.099\n",
      "[117, 120] loss: 0.107\n",
      "[117, 180] loss: 0.122\n",
      "[117, 240] loss: 0.128\n",
      "[117, 300] loss: 0.121\n",
      "[117, 360] loss: 0.126\n",
      "Epoch: 117 -> Loss: 0.0420174226165\n",
      "Epoch: 117 -> Test Accuracy: 88.24\n",
      "[118, 60] loss: 0.098\n",
      "[118, 120] loss: 0.094\n",
      "[118, 180] loss: 0.103\n",
      "[118, 240] loss: 0.119\n",
      "[118, 300] loss: 0.120\n",
      "[118, 360] loss: 0.122\n",
      "Epoch: 118 -> Loss: 0.116893291473\n",
      "Epoch: 118 -> Test Accuracy: 87.91\n",
      "[119, 60] loss: 0.114\n",
      "[119, 120] loss: 0.108\n",
      "[119, 180] loss: 0.105\n",
      "[119, 240] loss: 0.098\n",
      "[119, 300] loss: 0.109\n",
      "[119, 360] loss: 0.119\n",
      "Epoch: 119 -> Loss: 0.0944111347198\n",
      "Epoch: 119 -> Test Accuracy: 88.47\n",
      "[120, 60] loss: 0.100\n",
      "[120, 120] loss: 0.101\n",
      "[120, 180] loss: 0.108\n",
      "[120, 240] loss: 0.107\n",
      "[120, 300] loss: 0.115\n",
      "[120, 360] loss: 0.122\n",
      "Epoch: 120 -> Loss: 0.0781654268503\n",
      "Epoch: 120 -> Test Accuracy: 88.68\n",
      "[121, 60] loss: 0.076\n",
      "[121, 120] loss: 0.053\n",
      "[121, 180] loss: 0.046\n",
      "[121, 240] loss: 0.044\n",
      "[121, 300] loss: 0.039\n",
      "[121, 360] loss: 0.038\n",
      "Epoch: 121 -> Loss: 0.0565217845142\n",
      "Epoch: 121 -> Test Accuracy: 91.0\n",
      "[122, 60] loss: 0.030\n",
      "[122, 120] loss: 0.030\n",
      "[122, 180] loss: 0.028\n",
      "[122, 240] loss: 0.026\n",
      "[122, 300] loss: 0.033\n",
      "[122, 360] loss: 0.033\n",
      "Epoch: 122 -> Loss: 0.040603466332\n",
      "Epoch: 122 -> Test Accuracy: 91.14\n",
      "[123, 60] loss: 0.025\n",
      "[123, 120] loss: 0.024\n",
      "[123, 180] loss: 0.023\n",
      "[123, 240] loss: 0.021\n",
      "[123, 300] loss: 0.024\n",
      "[123, 360] loss: 0.023\n",
      "Epoch: 123 -> Loss: 0.0392349287868\n",
      "Epoch: 123 -> Test Accuracy: 91.23\n",
      "[124, 60] loss: 0.022\n",
      "[124, 120] loss: 0.021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[124, 180] loss: 0.019\n",
      "[124, 240] loss: 0.019\n",
      "[124, 300] loss: 0.023\n",
      "[124, 360] loss: 0.020\n",
      "Epoch: 124 -> Loss: 0.014781457372\n",
      "Epoch: 124 -> Test Accuracy: 91.12\n",
      "[125, 60] loss: 0.018\n",
      "[125, 120] loss: 0.018\n",
      "[125, 180] loss: 0.021\n",
      "[125, 240] loss: 0.019\n",
      "[125, 300] loss: 0.019\n",
      "[125, 360] loss: 0.018\n",
      "Epoch: 125 -> Loss: 0.0167721323669\n",
      "Epoch: 125 -> Test Accuracy: 91.34\n",
      "[126, 60] loss: 0.017\n",
      "[126, 120] loss: 0.016\n",
      "[126, 180] loss: 0.017\n",
      "[126, 240] loss: 0.017\n",
      "[126, 300] loss: 0.019\n",
      "[126, 360] loss: 0.017\n",
      "Epoch: 126 -> Loss: 0.0848335027695\n",
      "Epoch: 126 -> Test Accuracy: 91.11\n",
      "[127, 60] loss: 0.015\n",
      "[127, 120] loss: 0.016\n",
      "[127, 180] loss: 0.016\n",
      "[127, 240] loss: 0.017\n",
      "[127, 300] loss: 0.017\n",
      "[127, 360] loss: 0.017\n",
      "Epoch: 127 -> Loss: 0.0125324781984\n",
      "Epoch: 127 -> Test Accuracy: 91.08\n",
      "[128, 60] loss: 0.015\n",
      "[128, 120] loss: 0.012\n",
      "[128, 180] loss: 0.014\n",
      "[128, 240] loss: 0.015\n",
      "[128, 300] loss: 0.015\n",
      "[128, 360] loss: 0.016\n",
      "Epoch: 128 -> Loss: 0.0312589555979\n",
      "Epoch: 128 -> Test Accuracy: 91.4\n",
      "[129, 60] loss: 0.015\n",
      "[129, 120] loss: 0.014\n",
      "[129, 180] loss: 0.015\n",
      "[129, 240] loss: 0.014\n",
      "[129, 300] loss: 0.013\n",
      "[129, 360] loss: 0.015\n",
      "Epoch: 129 -> Loss: 0.0130217969418\n",
      "Epoch: 129 -> Test Accuracy: 91.35\n",
      "[130, 60] loss: 0.013\n",
      "[130, 120] loss: 0.013\n",
      "[130, 180] loss: 0.014\n",
      "[130, 240] loss: 0.013\n",
      "[130, 300] loss: 0.014\n",
      "[130, 360] loss: 0.015\n",
      "Epoch: 130 -> Loss: 0.0347522571683\n",
      "Epoch: 130 -> Test Accuracy: 91.44\n",
      "[131, 60] loss: 0.013\n",
      "[131, 120] loss: 0.012\n",
      "[131, 180] loss: 0.013\n",
      "[131, 240] loss: 0.013\n",
      "[131, 300] loss: 0.012\n",
      "[131, 360] loss: 0.013\n",
      "Epoch: 131 -> Loss: 0.0206875987351\n",
      "Epoch: 131 -> Test Accuracy: 91.39\n",
      "[132, 60] loss: 0.012\n",
      "[132, 120] loss: 0.013\n",
      "[132, 180] loss: 0.012\n",
      "[132, 240] loss: 0.011\n",
      "[132, 300] loss: 0.015\n",
      "[132, 360] loss: 0.013\n",
      "Epoch: 132 -> Loss: 0.0230661574751\n",
      "Epoch: 132 -> Test Accuracy: 91.58\n",
      "[133, 60] loss: 0.012\n",
      "[133, 120] loss: 0.011\n",
      "[133, 180] loss: 0.012\n",
      "[133, 240] loss: 0.013\n",
      "[133, 300] loss: 0.012\n",
      "[133, 360] loss: 0.012\n",
      "Epoch: 133 -> Loss: 0.0413665995002\n",
      "Epoch: 133 -> Test Accuracy: 91.43\n",
      "[134, 60] loss: 0.010\n",
      "[134, 120] loss: 0.011\n",
      "[134, 180] loss: 0.012\n",
      "[134, 240] loss: 0.010\n",
      "[134, 300] loss: 0.011\n",
      "[134, 360] loss: 0.011\n",
      "Epoch: 134 -> Loss: 0.0186693780124\n",
      "Epoch: 134 -> Test Accuracy: 91.19\n",
      "[135, 60] loss: 0.010\n",
      "[135, 120] loss: 0.011\n",
      "[135, 180] loss: 0.011\n",
      "[135, 240] loss: 0.011\n",
      "[135, 300] loss: 0.011\n",
      "[135, 360] loss: 0.011\n",
      "Epoch: 135 -> Loss: 0.0119986953214\n",
      "Epoch: 135 -> Test Accuracy: 91.6\n",
      "[136, 60] loss: 0.011\n",
      "[136, 120] loss: 0.011\n",
      "[136, 180] loss: 0.011\n",
      "[136, 240] loss: 0.010\n",
      "[136, 300] loss: 0.012\n",
      "[136, 360] loss: 0.010\n",
      "Epoch: 136 -> Loss: 0.00918613933027\n",
      "Epoch: 136 -> Test Accuracy: 91.38\n",
      "[137, 60] loss: 0.009\n",
      "[137, 120] loss: 0.011\n",
      "[137, 180] loss: 0.011\n",
      "[137, 240] loss: 0.011\n",
      "[137, 300] loss: 0.010\n",
      "[137, 360] loss: 0.013\n",
      "Epoch: 137 -> Loss: 0.00561661738902\n",
      "Epoch: 137 -> Test Accuracy: 91.41\n",
      "[138, 60] loss: 0.011\n",
      "[138, 120] loss: 0.009\n",
      "[138, 180] loss: 0.009\n",
      "[138, 240] loss: 0.011\n",
      "[138, 300] loss: 0.011\n",
      "[138, 360] loss: 0.010\n",
      "Epoch: 138 -> Loss: 0.0108347414061\n",
      "Epoch: 138 -> Test Accuracy: 91.08\n",
      "[139, 60] loss: 0.010\n",
      "[139, 120] loss: 0.010\n",
      "[139, 180] loss: 0.011\n",
      "[139, 240] loss: 0.011\n",
      "[139, 300] loss: 0.010\n",
      "[139, 360] loss: 0.011\n",
      "Epoch: 139 -> Loss: 0.003296548035\n",
      "Epoch: 139 -> Test Accuracy: 91.25\n",
      "[140, 60] loss: 0.009\n",
      "[140, 120] loss: 0.009\n",
      "[140, 180] loss: 0.010\n",
      "[140, 240] loss: 0.009\n",
      "[140, 300] loss: 0.011\n",
      "[140, 360] loss: 0.011\n",
      "Epoch: 140 -> Loss: 0.0081768091768\n",
      "Epoch: 140 -> Test Accuracy: 91.33\n",
      "[141, 60] loss: 0.010\n",
      "[141, 120] loss: 0.009\n",
      "[141, 180] loss: 0.010\n",
      "[141, 240] loss: 0.011\n",
      "[141, 300] loss: 0.011\n",
      "[141, 360] loss: 0.010\n",
      "Epoch: 141 -> Loss: 0.0161631368101\n",
      "Epoch: 141 -> Test Accuracy: 91.49\n",
      "[142, 60] loss: 0.010\n",
      "[142, 120] loss: 0.009\n",
      "[142, 180] loss: 0.010\n",
      "[142, 240] loss: 0.010\n",
      "[142, 300] loss: 0.009\n",
      "[142, 360] loss: 0.010\n",
      "Epoch: 142 -> Loss: 0.00730358948931\n",
      "Epoch: 142 -> Test Accuracy: 91.35\n",
      "[143, 60] loss: 0.009\n",
      "[143, 120] loss: 0.009\n",
      "[143, 180] loss: 0.009\n",
      "[143, 240] loss: 0.008\n",
      "[143, 300] loss: 0.010\n",
      "[143, 360] loss: 0.011\n",
      "Epoch: 143 -> Loss: 0.0156547427177\n",
      "Epoch: 143 -> Test Accuracy: 91.55\n",
      "[144, 60] loss: 0.009\n",
      "[144, 120] loss: 0.010\n",
      "[144, 180] loss: 0.011\n",
      "[144, 240] loss: 0.010\n",
      "[144, 300] loss: 0.010\n",
      "[144, 360] loss: 0.009\n",
      "Epoch: 144 -> Loss: 0.00534783583134\n",
      "Epoch: 144 -> Test Accuracy: 91.28\n",
      "[145, 60] loss: 0.009\n",
      "[145, 120] loss: 0.009\n",
      "[145, 180] loss: 0.009\n",
      "[145, 240] loss: 0.009\n",
      "[145, 300] loss: 0.010\n",
      "[145, 360] loss: 0.010\n",
      "Epoch: 145 -> Loss: 0.0170316882432\n",
      "Epoch: 145 -> Test Accuracy: 91.53\n",
      "[146, 60] loss: 0.009\n",
      "[146, 120] loss: 0.009\n",
      "[146, 180] loss: 0.009\n",
      "[146, 240] loss: 0.009\n",
      "[146, 300] loss: 0.011\n",
      "[146, 360] loss: 0.009\n",
      "Epoch: 146 -> Loss: 0.0199759565294\n",
      "Epoch: 146 -> Test Accuracy: 91.44\n",
      "[147, 60] loss: 0.008\n",
      "[147, 120] loss: 0.009\n",
      "[147, 180] loss: 0.008\n",
      "[147, 240] loss: 0.009\n",
      "[147, 300] loss: 0.008\n",
      "[147, 360] loss: 0.008\n",
      "Epoch: 147 -> Loss: 0.00666918139905\n",
      "Epoch: 147 -> Test Accuracy: 91.42\n",
      "[148, 60] loss: 0.008\n",
      "[148, 120] loss: 0.008\n",
      "[148, 180] loss: 0.009\n",
      "[148, 240] loss: 0.009\n",
      "[148, 300] loss: 0.008\n",
      "[148, 360] loss: 0.009\n",
      "Epoch: 148 -> Loss: 0.00498628616333\n",
      "Epoch: 148 -> Test Accuracy: 91.48\n",
      "[149, 60] loss: 0.008\n",
      "[149, 120] loss: 0.009\n",
      "[149, 180] loss: 0.008\n",
      "[149, 240] loss: 0.009\n",
      "[149, 300] loss: 0.009\n",
      "[149, 360] loss: 0.009\n",
      "Epoch: 149 -> Loss: 0.0043837307021\n",
      "Epoch: 149 -> Test Accuracy: 91.55\n",
      "[150, 60] loss: 0.008\n",
      "[150, 120] loss: 0.009\n",
      "[150, 180] loss: 0.009\n",
      "[150, 240] loss: 0.010\n",
      "[150, 300] loss: 0.008\n",
      "[150, 360] loss: 0.008\n",
      "Epoch: 150 -> Loss: 0.013131255284\n",
      "Epoch: 150 -> Test Accuracy: 91.41\n",
      "[151, 60] loss: 0.008\n",
      "[151, 120] loss: 0.008\n",
      "[151, 180] loss: 0.009\n",
      "[151, 240] loss: 0.009\n",
      "[151, 300] loss: 0.009\n",
      "[151, 360] loss: 0.010\n",
      "Epoch: 151 -> Loss: 0.00664518494159\n",
      "Epoch: 151 -> Test Accuracy: 91.22\n",
      "[152, 60] loss: 0.008\n",
      "[152, 120] loss: 0.008\n",
      "[152, 180] loss: 0.008\n",
      "[152, 240] loss: 0.009\n",
      "[152, 300] loss: 0.009\n",
      "[152, 360] loss: 0.009\n",
      "Epoch: 152 -> Loss: 0.0107824262232\n",
      "Epoch: 152 -> Test Accuracy: 91.28\n",
      "[153, 60] loss: 0.009\n",
      "[153, 120] loss: 0.008\n",
      "[153, 180] loss: 0.009\n",
      "[153, 240] loss: 0.008\n",
      "[153, 300] loss: 0.009\n",
      "[153, 360] loss: 0.009\n",
      "Epoch: 153 -> Loss: 0.0158017966896\n",
      "Epoch: 153 -> Test Accuracy: 91.48\n",
      "[154, 60] loss: 0.008\n",
      "[154, 120] loss: 0.009\n",
      "[154, 180] loss: 0.008\n",
      "[154, 240] loss: 0.009\n",
      "[154, 300] loss: 0.009\n",
      "[154, 360] loss: 0.010\n",
      "Epoch: 154 -> Loss: 0.00430523138493\n",
      "Epoch: 154 -> Test Accuracy: 91.37\n",
      "[155, 60] loss: 0.008\n",
      "[155, 120] loss: 0.009\n",
      "[155, 180] loss: 0.009\n",
      "[155, 240] loss: 0.008\n",
      "[155, 300] loss: 0.008\n",
      "[155, 360] loss: 0.009\n",
      "Epoch: 155 -> Loss: 0.00885029695928\n",
      "Epoch: 155 -> Test Accuracy: 91.34\n",
      "[156, 60] loss: 0.009\n",
      "[156, 120] loss: 0.008\n",
      "[156, 180] loss: 0.009\n",
      "[156, 240] loss: 0.009\n",
      "[156, 300] loss: 0.008\n",
      "[156, 360] loss: 0.008\n",
      "Epoch: 156 -> Loss: 0.00787709373981\n",
      "Epoch: 156 -> Test Accuracy: 91.24\n",
      "[157, 60] loss: 0.007\n",
      "[157, 120] loss: 0.008\n",
      "[157, 180] loss: 0.009\n",
      "[157, 240] loss: 0.009\n",
      "[157, 300] loss: 0.009\n",
      "[157, 360] loss: 0.009\n",
      "Epoch: 157 -> Loss: 0.0151769965887\n",
      "Epoch: 157 -> Test Accuracy: 91.1\n",
      "[158, 60] loss: 0.007\n",
      "[158, 120] loss: 0.009\n",
      "[158, 180] loss: 0.008\n",
      "[158, 240] loss: 0.008\n",
      "[158, 300] loss: 0.008\n",
      "[158, 360] loss: 0.008\n",
      "Epoch: 158 -> Loss: 0.0158641636372\n",
      "Epoch: 158 -> Test Accuracy: 91.31\n",
      "[159, 60] loss: 0.008\n",
      "[159, 120] loss: 0.008\n",
      "[159, 180] loss: 0.008\n",
      "[159, 240] loss: 0.009\n",
      "[159, 300] loss: 0.008\n",
      "[159, 360] loss: 0.008\n",
      "Epoch: 159 -> Loss: 0.015289997682\n",
      "Epoch: 159 -> Test Accuracy: 91.5\n",
      "[160, 60] loss: 0.007\n",
      "[160, 120] loss: 0.008\n",
      "[160, 180] loss: 0.008\n",
      "[160, 240] loss: 0.009\n",
      "[160, 300] loss: 0.008\n",
      "[160, 360] loss: 0.008\n",
      "Epoch: 160 -> Loss: 0.00746633391827\n",
      "Epoch: 160 -> Test Accuracy: 91.26\n",
      "[161, 60] loss: 0.007\n",
      "[161, 120] loss: 0.008\n",
      "[161, 180] loss: 0.007\n",
      "[161, 240] loss: 0.008\n",
      "[161, 300] loss: 0.007\n",
      "[161, 360] loss: 0.008\n",
      "Epoch: 161 -> Loss: 0.00252706999891\n",
      "Epoch: 161 -> Test Accuracy: 91.49\n",
      "[162, 60] loss: 0.008\n",
      "[162, 120] loss: 0.006\n",
      "[162, 180] loss: 0.006\n",
      "[162, 240] loss: 0.007\n",
      "[162, 300] loss: 0.007\n",
      "[162, 360] loss: 0.007\n",
      "Epoch: 162 -> Loss: 0.00587472319603\n",
      "Epoch: 162 -> Test Accuracy: 91.42\n",
      "[163, 60] loss: 0.006\n",
      "[163, 120] loss: 0.006\n",
      "[163, 180] loss: 0.006\n",
      "[163, 240] loss: 0.007\n",
      "[163, 300] loss: 0.007\n",
      "[163, 360] loss: 0.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 163 -> Loss: 0.0217232648283\n",
      "Epoch: 163 -> Test Accuracy: 91.34\n",
      "[164, 60] loss: 0.007\n",
      "[164, 120] loss: 0.006\n",
      "[164, 180] loss: 0.007\n",
      "[164, 240] loss: 0.007\n",
      "[164, 300] loss: 0.008\n",
      "[164, 360] loss: 0.007\n",
      "Epoch: 164 -> Loss: 0.00491287698969\n",
      "Epoch: 164 -> Test Accuracy: 91.43\n",
      "[165, 60] loss: 0.007\n",
      "[165, 120] loss: 0.006\n",
      "[165, 180] loss: 0.007\n",
      "[165, 240] loss: 0.007\n",
      "[165, 300] loss: 0.007\n",
      "[165, 360] loss: 0.006\n",
      "Epoch: 165 -> Loss: 0.00755018601194\n",
      "Epoch: 165 -> Test Accuracy: 91.38\n",
      "[166, 60] loss: 0.007\n",
      "[166, 120] loss: 0.007\n",
      "[166, 180] loss: 0.006\n",
      "[166, 240] loss: 0.006\n",
      "[166, 300] loss: 0.008\n",
      "[166, 360] loss: 0.007\n",
      "Epoch: 166 -> Loss: 0.00747720012441\n",
      "Epoch: 166 -> Test Accuracy: 91.35\n",
      "[167, 60] loss: 0.007\n",
      "[167, 120] loss: 0.007\n",
      "[167, 180] loss: 0.006\n",
      "[167, 240] loss: 0.006\n",
      "[167, 300] loss: 0.007\n",
      "[167, 360] loss: 0.007\n",
      "Epoch: 167 -> Loss: 0.00682920822874\n",
      "Epoch: 167 -> Test Accuracy: 91.36\n",
      "[168, 60] loss: 0.007\n",
      "[168, 120] loss: 0.006\n",
      "[168, 180] loss: 0.006\n",
      "[168, 240] loss: 0.007\n",
      "[168, 300] loss: 0.007\n",
      "[168, 360] loss: 0.007\n",
      "Epoch: 168 -> Loss: 0.00664998311549\n",
      "Epoch: 168 -> Test Accuracy: 91.37\n",
      "[169, 60] loss: 0.006\n",
      "[169, 120] loss: 0.006\n",
      "[169, 180] loss: 0.007\n",
      "[169, 240] loss: 0.007\n",
      "[169, 300] loss: 0.006\n",
      "[169, 360] loss: 0.007\n",
      "Epoch: 169 -> Loss: 0.00578779587522\n",
      "Epoch: 169 -> Test Accuracy: 91.43\n",
      "[170, 60] loss: 0.006\n",
      "[170, 120] loss: 0.006\n",
      "[170, 180] loss: 0.006\n",
      "[170, 240] loss: 0.006\n",
      "[170, 300] loss: 0.007\n",
      "[170, 360] loss: 0.007\n",
      "Epoch: 170 -> Loss: 0.00725095858797\n",
      "Epoch: 170 -> Test Accuracy: 91.37\n",
      "[171, 60] loss: 0.006\n",
      "[171, 120] loss: 0.007\n",
      "[171, 180] loss: 0.006\n",
      "[171, 240] loss: 0.007\n",
      "[171, 300] loss: 0.007\n",
      "[171, 360] loss: 0.006\n",
      "Epoch: 171 -> Loss: 0.00789576210082\n",
      "Epoch: 171 -> Test Accuracy: 91.38\n",
      "[172, 60] loss: 0.006\n",
      "[172, 120] loss: 0.007\n",
      "[172, 180] loss: 0.007\n",
      "[172, 240] loss: 0.007\n",
      "[172, 300] loss: 0.007\n",
      "[172, 360] loss: 0.007\n",
      "Epoch: 172 -> Loss: 0.00631002197042\n",
      "Epoch: 172 -> Test Accuracy: 91.42\n",
      "[173, 60] loss: 0.007\n",
      "[173, 120] loss: 0.006\n",
      "[173, 180] loss: 0.007\n",
      "[173, 240] loss: 0.007\n",
      "[173, 300] loss: 0.007\n",
      "[173, 360] loss: 0.007\n",
      "Epoch: 173 -> Loss: 0.0154507216066\n",
      "Epoch: 173 -> Test Accuracy: 91.54\n",
      "[174, 60] loss: 0.006\n",
      "[174, 120] loss: 0.007\n",
      "[174, 180] loss: 0.006\n",
      "[174, 240] loss: 0.007\n",
      "[174, 300] loss: 0.006\n",
      "[174, 360] loss: 0.007\n",
      "Epoch: 174 -> Loss: 0.00718631735072\n",
      "Epoch: 174 -> Test Accuracy: 91.48\n",
      "[175, 60] loss: 0.007\n",
      "[175, 120] loss: 0.006\n",
      "[175, 180] loss: 0.007\n",
      "[175, 240] loss: 0.007\n",
      "[175, 300] loss: 0.006\n",
      "[175, 360] loss: 0.006\n",
      "Epoch: 175 -> Loss: 0.0066727520898\n",
      "Epoch: 175 -> Test Accuracy: 91.52\n",
      "[176, 60] loss: 0.006\n",
      "[176, 120] loss: 0.007\n",
      "[176, 180] loss: 0.006\n",
      "[176, 240] loss: 0.006\n",
      "[176, 300] loss: 0.006\n",
      "[176, 360] loss: 0.006\n",
      "Epoch: 176 -> Loss: 0.0105314943939\n",
      "Epoch: 176 -> Test Accuracy: 91.52\n",
      "[177, 60] loss: 0.006\n",
      "[177, 120] loss: 0.005\n",
      "[177, 180] loss: 0.006\n",
      "[177, 240] loss: 0.006\n",
      "[177, 300] loss: 0.007\n",
      "[177, 360] loss: 0.006\n",
      "Epoch: 177 -> Loss: 0.00541695347056\n",
      "Epoch: 177 -> Test Accuracy: 91.43\n",
      "[178, 60] loss: 0.006\n",
      "[178, 120] loss: 0.006\n",
      "[178, 180] loss: 0.007\n",
      "[178, 240] loss: 0.007\n",
      "[178, 300] loss: 0.006\n",
      "[178, 360] loss: 0.006\n",
      "Epoch: 178 -> Loss: 0.00672669429332\n",
      "Epoch: 178 -> Test Accuracy: 91.49\n",
      "[179, 60] loss: 0.006\n",
      "[179, 120] loss: 0.006\n",
      "[179, 180] loss: 0.006\n",
      "[179, 240] loss: 0.008\n",
      "[179, 300] loss: 0.006\n",
      "[179, 360] loss: 0.006\n",
      "Epoch: 179 -> Loss: 0.0129056693986\n",
      "Epoch: 179 -> Test Accuracy: 91.43\n",
      "[180, 60] loss: 0.006\n",
      "[180, 120] loss: 0.006\n",
      "[180, 180] loss: 0.006\n",
      "[180, 240] loss: 0.006\n",
      "[180, 300] loss: 0.006\n",
      "[180, 360] loss: 0.007\n",
      "Epoch: 180 -> Loss: 0.0073016048409\n",
      "Epoch: 180 -> Test Accuracy: 91.45\n",
      "[181, 60] loss: 0.006\n",
      "[181, 120] loss: 0.006\n",
      "[181, 180] loss: 0.006\n",
      "[181, 240] loss: 0.006\n",
      "[181, 300] loss: 0.006\n",
      "[181, 360] loss: 0.006\n",
      "Epoch: 181 -> Loss: 0.0107027534395\n",
      "Epoch: 181 -> Test Accuracy: 91.41\n",
      "[182, 60] loss: 0.006\n",
      "[182, 120] loss: 0.006\n",
      "[182, 180] loss: 0.007\n",
      "[182, 240] loss: 0.006\n",
      "[182, 300] loss: 0.006\n",
      "[182, 360] loss: 0.007\n",
      "Epoch: 182 -> Loss: 0.00626089563593\n",
      "Epoch: 182 -> Test Accuracy: 91.52\n",
      "[183, 60] loss: 0.006\n",
      "[183, 120] loss: 0.006\n",
      "[183, 180] loss: 0.007\n",
      "[183, 240] loss: 0.006\n",
      "[183, 300] loss: 0.007\n",
      "[183, 360] loss: 0.007\n",
      "Epoch: 183 -> Loss: 0.00553894042969\n",
      "Epoch: 183 -> Test Accuracy: 91.59\n",
      "[184, 60] loss: 0.006\n",
      "[184, 120] loss: 0.007\n",
      "[184, 180] loss: 0.006\n",
      "[184, 240] loss: 0.007\n",
      "[184, 300] loss: 0.006\n",
      "[184, 360] loss: 0.006\n",
      "Epoch: 184 -> Loss: 0.00829513091594\n",
      "Epoch: 184 -> Test Accuracy: 91.62\n",
      "[185, 60] loss: 0.006\n",
      "[185, 120] loss: 0.006\n",
      "[185, 180] loss: 0.006\n",
      "[185, 240] loss: 0.006\n",
      "[185, 300] loss: 0.007\n",
      "[185, 360] loss: 0.006\n",
      "Epoch: 185 -> Loss: 0.00739532709122\n",
      "Epoch: 185 -> Test Accuracy: 91.5\n",
      "[186, 60] loss: 0.006\n",
      "[186, 120] loss: 0.006\n",
      "[186, 180] loss: 0.006\n",
      "[186, 240] loss: 0.006\n",
      "[186, 300] loss: 0.006\n",
      "[186, 360] loss: 0.006\n",
      "Epoch: 186 -> Loss: 0.00641471147537\n",
      "Epoch: 186 -> Test Accuracy: 91.56\n",
      "[187, 60] loss: 0.007\n",
      "[187, 120] loss: 0.007\n",
      "[187, 180] loss: 0.006\n",
      "[187, 240] loss: 0.006\n",
      "[187, 300] loss: 0.006\n",
      "[187, 360] loss: 0.007\n",
      "Epoch: 187 -> Loss: 0.00623005628586\n",
      "Epoch: 187 -> Test Accuracy: 91.47\n",
      "[188, 60] loss: 0.007\n",
      "[188, 120] loss: 0.006\n",
      "[188, 180] loss: 0.006\n",
      "[188, 240] loss: 0.007\n",
      "[188, 300] loss: 0.007\n",
      "[188, 360] loss: 0.007\n",
      "Epoch: 188 -> Loss: 0.00677263131365\n",
      "Epoch: 188 -> Test Accuracy: 91.44\n",
      "[189, 60] loss: 0.006\n",
      "[189, 120] loss: 0.007\n",
      "[189, 180] loss: 0.006\n",
      "[189, 240] loss: 0.007\n",
      "[189, 300] loss: 0.006\n",
      "[189, 360] loss: 0.006\n",
      "Epoch: 189 -> Loss: 0.00439889449626\n",
      "Epoch: 189 -> Test Accuracy: 91.42\n",
      "[190, 60] loss: 0.007\n",
      "[190, 120] loss: 0.006\n",
      "[190, 180] loss: 0.006\n",
      "[190, 240] loss: 0.006\n",
      "[190, 300] loss: 0.006\n",
      "[190, 360] loss: 0.006\n",
      "Epoch: 190 -> Loss: 0.00561082968488\n",
      "Epoch: 190 -> Test Accuracy: 91.44\n",
      "[191, 60] loss: 0.007\n",
      "[191, 120] loss: 0.006\n",
      "[191, 180] loss: 0.007\n",
      "[191, 240] loss: 0.007\n",
      "[191, 300] loss: 0.006\n",
      "[191, 360] loss: 0.006\n",
      "Epoch: 191 -> Loss: 0.00696980347857\n",
      "Epoch: 191 -> Test Accuracy: 91.36\n",
      "[192, 60] loss: 0.006\n",
      "[192, 120] loss: 0.006\n",
      "[192, 180] loss: 0.006\n",
      "[192, 240] loss: 0.006\n",
      "[192, 300] loss: 0.007\n",
      "[192, 360] loss: 0.006\n",
      "Epoch: 192 -> Loss: 0.00658121705055\n",
      "Epoch: 192 -> Test Accuracy: 91.4\n",
      "[193, 60] loss: 0.007\n",
      "[193, 120] loss: 0.006\n",
      "[193, 180] loss: 0.007\n",
      "[193, 240] loss: 0.007\n",
      "[193, 300] loss: 0.006\n",
      "[193, 360] loss: 0.006\n",
      "Epoch: 193 -> Loss: 0.0159955378622\n",
      "Epoch: 193 -> Test Accuracy: 91.53\n",
      "[194, 60] loss: 0.006\n",
      "[194, 120] loss: 0.006\n",
      "[194, 180] loss: 0.006\n",
      "[194, 240] loss: 0.006\n",
      "[194, 300] loss: 0.006\n",
      "[194, 360] loss: 0.007\n",
      "Epoch: 194 -> Loss: 0.00327979330905\n",
      "Epoch: 194 -> Test Accuracy: 91.44\n",
      "[195, 60] loss: 0.007\n",
      "[195, 120] loss: 0.007\n",
      "[195, 180] loss: 0.006\n",
      "[195, 240] loss: 0.006\n",
      "[195, 300] loss: 0.006\n",
      "[195, 360] loss: 0.006\n",
      "Epoch: 195 -> Loss: 0.0070840716362\n",
      "Epoch: 195 -> Test Accuracy: 91.49\n",
      "[196, 60] loss: 0.006\n",
      "[196, 120] loss: 0.007\n",
      "[196, 180] loss: 0.006\n",
      "[196, 240] loss: 0.006\n",
      "[196, 300] loss: 0.006\n",
      "[196, 360] loss: 0.006\n",
      "Epoch: 196 -> Loss: 0.00568947196007\n",
      "Epoch: 196 -> Test Accuracy: 91.44\n",
      "[197, 60] loss: 0.006\n",
      "[197, 120] loss: 0.007\n",
      "[197, 180] loss: 0.006\n",
      "[197, 240] loss: 0.006\n",
      "[197, 300] loss: 0.006\n",
      "[197, 360] loss: 0.006\n",
      "Epoch: 197 -> Loss: 0.0105060217902\n",
      "Epoch: 197 -> Test Accuracy: 91.39\n",
      "[198, 60] loss: 0.006\n",
      "[198, 120] loss: 0.007\n",
      "[198, 180] loss: 0.006\n",
      "[198, 240] loss: 0.006\n",
      "[198, 300] loss: 0.006\n",
      "[198, 360] loss: 0.006\n",
      "Epoch: 198 -> Loss: 0.00440440187231\n",
      "Epoch: 198 -> Test Accuracy: 91.48\n",
      "[199, 60] loss: 0.006\n",
      "[199, 120] loss: 0.006\n",
      "[199, 180] loss: 0.006\n",
      "[199, 240] loss: 0.006\n",
      "[199, 300] loss: 0.006\n",
      "[199, 360] loss: 0.005\n",
      "Epoch: 199 -> Loss: 0.0178160853684\n",
      "Epoch: 199 -> Test Accuracy: 91.4\n",
      "[200, 60] loss: 0.006\n",
      "[200, 120] loss: 0.007\n",
      "[200, 180] loss: 0.006\n",
      "[200, 240] loss: 0.006\n",
      "[200, 300] loss: 0.006\n",
      "[200, 360] loss: 0.006\n",
      "Epoch: 200 -> Loss: 0.00646641850471\n",
      "Epoch: 200 -> Test Accuracy: 91.44\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train 3 block RotNet on classification task\n",
    "class_NIN_loss_log, class_NIN_valid_accuracy_log, class_NIN_test_accuracy_log, class_NIN_max_accuracy, \\\n",
    "class_NIN_best_epoch = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], [60, 120, 160, 200], 0.9, 5e-4, net_class, \n",
    "                                            criterion, trainloader, None, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
