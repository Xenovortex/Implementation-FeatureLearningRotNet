{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from functionalities import dataloader as dl\n",
    "from functionalities import evaluater as ev\n",
    "from functionalities import filemanager as fm\n",
    "from functionalities import trainer as tr\n",
    "from architecture import RotNet as RN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset, testset, classes = dl.load_cifar(\"./datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, validloader, testloader = dl.make_dataloaders(trainset, testset, 0, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Loss Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RotNet for Rotation Task and Classifiers on Feature Maps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set rot classes\n",
    "rot_classes = ['original', '90 rotation', '180 rotation', '270 rotation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Block RotNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "net_block3 = RN.RotNet(num_classes=4, num_conv_block=3, add_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.136\n",
      "[1, 120] loss: 0.994\n",
      "[1, 180] loss: 0.926\n",
      "[1, 240] loss: 0.866\n",
      "[1, 300] loss: 0.812\n",
      "[1, 360] loss: 0.788\n",
      "Epoch: 1 -> Loss: 0.622136056423\n",
      "Epoch: 1 -> Test Accuracy: 70.145\n",
      "[2, 60] loss: 0.737\n",
      "[2, 120] loss: 0.700\n",
      "[2, 180] loss: 0.694\n",
      "[2, 240] loss: 0.666\n",
      "[2, 300] loss: 0.648\n",
      "[2, 360] loss: 0.627\n",
      "Epoch: 2 -> Loss: 0.640503168106\n",
      "Epoch: 2 -> Test Accuracy: 75.9675\n",
      "[3, 60] loss: 0.618\n",
      "[3, 120] loss: 0.608\n",
      "[3, 180] loss: 0.589\n",
      "[3, 240] loss: 0.578\n",
      "[3, 300] loss: 0.569\n",
      "[3, 360] loss: 0.552\n",
      "Epoch: 3 -> Loss: 0.608837962151\n",
      "Epoch: 3 -> Test Accuracy: 77.955\n",
      "[4, 60] loss: 0.538\n",
      "[4, 120] loss: 0.543\n",
      "[4, 180] loss: 0.521\n",
      "[4, 240] loss: 0.529\n",
      "[4, 300] loss: 0.520\n",
      "[4, 360] loss: 0.511\n",
      "Epoch: 4 -> Loss: 0.438581287861\n",
      "Epoch: 4 -> Test Accuracy: 79.2975\n",
      "[5, 60] loss: 0.505\n",
      "[5, 120] loss: 0.501\n",
      "[5, 180] loss: 0.488\n",
      "[5, 240] loss: 0.496\n",
      "[5, 300] loss: 0.491\n",
      "[5, 360] loss: 0.494\n",
      "Epoch: 5 -> Loss: 0.529520392418\n",
      "Epoch: 5 -> Test Accuracy: 81.4275\n",
      "[6, 60] loss: 0.469\n",
      "[6, 120] loss: 0.478\n",
      "[6, 180] loss: 0.468\n",
      "[6, 240] loss: 0.465\n",
      "[6, 300] loss: 0.476\n",
      "[6, 360] loss: 0.459\n",
      "Epoch: 6 -> Loss: 0.605117976665\n",
      "Epoch: 6 -> Test Accuracy: 81.1125\n",
      "[7, 60] loss: 0.459\n",
      "[7, 120] loss: 0.446\n",
      "[7, 180] loss: 0.444\n",
      "[7, 240] loss: 0.444\n",
      "[7, 300] loss: 0.456\n",
      "[7, 360] loss: 0.443\n",
      "Epoch: 7 -> Loss: 0.451095342636\n",
      "Epoch: 7 -> Test Accuracy: 82.9125\n",
      "[8, 60] loss: 0.438\n",
      "[8, 120] loss: 0.430\n",
      "[8, 180] loss: 0.445\n",
      "[8, 240] loss: 0.431\n",
      "[8, 300] loss: 0.424\n",
      "[8, 360] loss: 0.421\n",
      "Epoch: 8 -> Loss: 0.407332241535\n",
      "Epoch: 8 -> Test Accuracy: 83.615\n",
      "[9, 60] loss: 0.404\n",
      "[9, 120] loss: 0.411\n",
      "[9, 180] loss: 0.412\n",
      "[9, 240] loss: 0.416\n",
      "[9, 300] loss: 0.424\n",
      "[9, 360] loss: 0.422\n",
      "Epoch: 9 -> Loss: 0.470407634974\n",
      "Epoch: 9 -> Test Accuracy: 83.44\n",
      "[10, 60] loss: 0.389\n",
      "[10, 120] loss: 0.418\n",
      "[10, 180] loss: 0.396\n",
      "[10, 240] loss: 0.393\n",
      "[10, 300] loss: 0.407\n",
      "[10, 360] loss: 0.406\n",
      "Epoch: 10 -> Loss: 0.360766768456\n",
      "Epoch: 10 -> Test Accuracy: 84.0875\n",
      "[11, 60] loss: 0.391\n",
      "[11, 120] loss: 0.390\n",
      "[11, 180] loss: 0.385\n",
      "[11, 240] loss: 0.395\n",
      "[11, 300] loss: 0.390\n",
      "[11, 360] loss: 0.413\n",
      "Epoch: 11 -> Loss: 0.505002915859\n",
      "Epoch: 11 -> Test Accuracy: 83.62\n",
      "[12, 60] loss: 0.378\n",
      "[12, 120] loss: 0.380\n",
      "[12, 180] loss: 0.384\n",
      "[12, 240] loss: 0.391\n",
      "[12, 300] loss: 0.405\n",
      "[12, 360] loss: 0.378\n",
      "Epoch: 12 -> Loss: 0.442788273096\n",
      "Epoch: 12 -> Test Accuracy: 83.7875\n",
      "[13, 60] loss: 0.384\n",
      "[13, 120] loss: 0.368\n",
      "[13, 180] loss: 0.372\n",
      "[13, 240] loss: 0.381\n",
      "[13, 300] loss: 0.378\n",
      "[13, 360] loss: 0.387\n",
      "Epoch: 13 -> Loss: 0.388025462627\n",
      "Epoch: 13 -> Test Accuracy: 84.71\n",
      "[14, 60] loss: 0.368\n",
      "[14, 120] loss: 0.385\n",
      "[14, 180] loss: 0.361\n",
      "[14, 240] loss: 0.359\n",
      "[14, 300] loss: 0.360\n",
      "[14, 360] loss: 0.382\n",
      "Epoch: 14 -> Loss: 0.334664285183\n",
      "Epoch: 14 -> Test Accuracy: 84.75\n",
      "[15, 60] loss: 0.366\n",
      "[15, 120] loss: 0.366\n",
      "[15, 180] loss: 0.368\n",
      "[15, 240] loss: 0.372\n",
      "[15, 300] loss: 0.369\n",
      "[15, 360] loss: 0.354\n",
      "Epoch: 15 -> Loss: 0.440261363983\n",
      "Epoch: 15 -> Test Accuracy: 84.985\n",
      "[16, 60] loss: 0.342\n",
      "[16, 120] loss: 0.353\n",
      "[16, 180] loss: 0.374\n",
      "[16, 240] loss: 0.364\n",
      "[16, 300] loss: 0.362\n",
      "[16, 360] loss: 0.361\n",
      "Epoch: 16 -> Loss: 0.181831732392\n",
      "Epoch: 16 -> Test Accuracy: 84.5575\n",
      "[17, 60] loss: 0.350\n",
      "[17, 120] loss: 0.354\n",
      "[17, 180] loss: 0.351\n",
      "[17, 240] loss: 0.351\n",
      "[17, 300] loss: 0.351\n",
      "[17, 360] loss: 0.361\n",
      "Epoch: 17 -> Loss: 0.289665281773\n",
      "Epoch: 17 -> Test Accuracy: 85.075\n",
      "[18, 60] loss: 0.338\n",
      "[18, 120] loss: 0.351\n",
      "[18, 180] loss: 0.344\n",
      "[18, 240] loss: 0.358\n",
      "[18, 300] loss: 0.346\n",
      "[18, 360] loss: 0.364\n",
      "Epoch: 18 -> Loss: 0.346771657467\n",
      "Epoch: 18 -> Test Accuracy: 84.8275\n",
      "[19, 60] loss: 0.330\n",
      "[19, 120] loss: 0.349\n",
      "[19, 180] loss: 0.345\n",
      "[19, 240] loss: 0.347\n",
      "[19, 300] loss: 0.345\n",
      "[19, 360] loss: 0.353\n",
      "Epoch: 19 -> Loss: 0.296558946371\n",
      "Epoch: 19 -> Test Accuracy: 85.3425\n",
      "[20, 60] loss: 0.340\n",
      "[20, 120] loss: 0.338\n",
      "[20, 180] loss: 0.339\n",
      "[20, 240] loss: 0.356\n",
      "[20, 300] loss: 0.340\n",
      "[20, 360] loss: 0.351\n",
      "Epoch: 20 -> Loss: 0.346271038055\n",
      "Epoch: 20 -> Test Accuracy: 85.9125\n",
      "[21, 60] loss: 0.325\n",
      "[21, 120] loss: 0.336\n",
      "[21, 180] loss: 0.330\n",
      "[21, 240] loss: 0.341\n",
      "[21, 300] loss: 0.342\n",
      "[21, 360] loss: 0.344\n",
      "Epoch: 21 -> Loss: 0.33271509409\n",
      "Epoch: 21 -> Test Accuracy: 86.2125\n",
      "[22, 60] loss: 0.330\n",
      "[22, 120] loss: 0.339\n",
      "[22, 180] loss: 0.344\n",
      "[22, 240] loss: 0.340\n",
      "[22, 300] loss: 0.336\n",
      "[22, 360] loss: 0.340\n",
      "Epoch: 22 -> Loss: 0.403304874897\n",
      "Epoch: 22 -> Test Accuracy: 85.965\n",
      "[23, 60] loss: 0.320\n",
      "[23, 120] loss: 0.333\n",
      "[23, 180] loss: 0.344\n",
      "[23, 240] loss: 0.325\n",
      "[23, 300] loss: 0.336\n",
      "[23, 360] loss: 0.347\n",
      "Epoch: 23 -> Loss: 0.337174236774\n",
      "Epoch: 23 -> Test Accuracy: 85.92\n",
      "[24, 60] loss: 0.308\n",
      "[24, 120] loss: 0.330\n",
      "[24, 180] loss: 0.334\n",
      "[24, 240] loss: 0.343\n",
      "[24, 300] loss: 0.338\n",
      "[24, 360] loss: 0.337\n",
      "Epoch: 24 -> Loss: 0.356583863497\n",
      "Epoch: 24 -> Test Accuracy: 85.6575\n",
      "[25, 60] loss: 0.329\n",
      "[25, 120] loss: 0.324\n",
      "[25, 180] loss: 0.335\n",
      "[25, 240] loss: 0.330\n",
      "[25, 300] loss: 0.333\n",
      "[25, 360] loss: 0.330\n",
      "Epoch: 25 -> Loss: 0.401808261871\n",
      "Epoch: 25 -> Test Accuracy: 85.9175\n",
      "[26, 60] loss: 0.324\n",
      "[26, 120] loss: 0.316\n",
      "[26, 180] loss: 0.314\n",
      "[26, 240] loss: 0.327\n",
      "[26, 300] loss: 0.337\n",
      "[26, 360] loss: 0.336\n",
      "Epoch: 26 -> Loss: 0.457501113415\n",
      "Epoch: 26 -> Test Accuracy: 85.7475\n",
      "[27, 60] loss: 0.310\n",
      "[27, 120] loss: 0.325\n",
      "[27, 180] loss: 0.319\n",
      "[27, 240] loss: 0.323\n",
      "[27, 300] loss: 0.328\n",
      "[27, 360] loss: 0.338\n",
      "Epoch: 27 -> Loss: 0.448860228062\n",
      "Epoch: 27 -> Test Accuracy: 86.3525\n",
      "[28, 60] loss: 0.316\n",
      "[28, 120] loss: 0.316\n",
      "[28, 180] loss: 0.336\n",
      "[28, 240] loss: 0.321\n",
      "[28, 300] loss: 0.325\n",
      "[28, 360] loss: 0.325\n",
      "Epoch: 28 -> Loss: 0.25757175684\n",
      "Epoch: 28 -> Test Accuracy: 85.205\n",
      "[29, 60] loss: 0.304\n",
      "[29, 120] loss: 0.317\n",
      "[29, 180] loss: 0.331\n",
      "[29, 240] loss: 0.337\n",
      "[29, 300] loss: 0.330\n",
      "[29, 360] loss: 0.325\n",
      "Epoch: 29 -> Loss: 0.360455572605\n",
      "Epoch: 29 -> Test Accuracy: 86.205\n",
      "[30, 60] loss: 0.309\n",
      "[30, 120] loss: 0.313\n",
      "[30, 180] loss: 0.317\n",
      "[30, 240] loss: 0.326\n",
      "[30, 300] loss: 0.328\n",
      "[30, 360] loss: 0.340\n",
      "Epoch: 30 -> Loss: 0.342876732349\n",
      "Epoch: 30 -> Test Accuracy: 86.55\n",
      "[31, 60] loss: 0.310\n",
      "[31, 120] loss: 0.318\n",
      "[31, 180] loss: 0.327\n",
      "[31, 240] loss: 0.313\n",
      "[31, 300] loss: 0.325\n",
      "[31, 360] loss: 0.317\n",
      "Epoch: 31 -> Loss: 0.254866778851\n",
      "Epoch: 31 -> Test Accuracy: 86.53\n",
      "[32, 60] loss: 0.294\n",
      "[32, 120] loss: 0.315\n",
      "[32, 180] loss: 0.319\n",
      "[32, 240] loss: 0.337\n",
      "[32, 300] loss: 0.323\n",
      "[32, 360] loss: 0.312\n",
      "Epoch: 32 -> Loss: 0.306332081556\n",
      "Epoch: 32 -> Test Accuracy: 86.2025\n",
      "[33, 60] loss: 0.316\n",
      "[33, 120] loss: 0.314\n",
      "[33, 180] loss: 0.309\n",
      "[33, 240] loss: 0.319\n",
      "[33, 300] loss: 0.329\n",
      "[33, 360] loss: 0.312\n",
      "Epoch: 33 -> Loss: 0.186054557562\n",
      "Epoch: 33 -> Test Accuracy: 86.825\n",
      "[34, 60] loss: 0.308\n",
      "[34, 120] loss: 0.313\n",
      "[34, 180] loss: 0.320\n",
      "[34, 240] loss: 0.325\n",
      "[34, 300] loss: 0.316\n",
      "[34, 360] loss: 0.319\n",
      "Epoch: 34 -> Loss: 0.339311927557\n",
      "Epoch: 34 -> Test Accuracy: 86.725\n",
      "[35, 60] loss: 0.316\n",
      "[35, 120] loss: 0.310\n",
      "[35, 180] loss: 0.311\n",
      "[35, 240] loss: 0.322\n",
      "[35, 300] loss: 0.313\n",
      "[35, 360] loss: 0.319\n",
      "Epoch: 35 -> Loss: 0.372605085373\n",
      "Epoch: 35 -> Test Accuracy: 85.865\n",
      "[36, 60] loss: 0.303\n",
      "[36, 120] loss: 0.310\n",
      "[36, 180] loss: 0.305\n",
      "[36, 240] loss: 0.322\n",
      "[36, 300] loss: 0.325\n",
      "[36, 360] loss: 0.315\n",
      "Epoch: 36 -> Loss: 0.476102441549\n",
      "Epoch: 36 -> Test Accuracy: 85.965\n",
      "[37, 60] loss: 0.305\n",
      "[37, 120] loss: 0.306\n",
      "[37, 180] loss: 0.311\n",
      "[37, 240] loss: 0.311\n",
      "[37, 300] loss: 0.308\n",
      "[37, 360] loss: 0.323\n",
      "Epoch: 37 -> Loss: 0.242652654648\n",
      "Epoch: 37 -> Test Accuracy: 86.825\n",
      "[38, 60] loss: 0.296\n",
      "[38, 120] loss: 0.325\n",
      "[38, 180] loss: 0.296\n",
      "[38, 240] loss: 0.319\n",
      "[38, 300] loss: 0.315\n",
      "[38, 360] loss: 0.318\n",
      "Epoch: 38 -> Loss: 0.340371578932\n",
      "Epoch: 38 -> Test Accuracy: 87.055\n",
      "[39, 60] loss: 0.304\n",
      "[39, 120] loss: 0.303\n",
      "[39, 180] loss: 0.316\n",
      "[39, 240] loss: 0.310\n",
      "[39, 300] loss: 0.306\n",
      "[39, 360] loss: 0.319\n",
      "Epoch: 39 -> Loss: 0.276812314987\n",
      "Epoch: 39 -> Test Accuracy: 85.855\n",
      "[40, 60] loss: 0.300\n",
      "[40, 120] loss: 0.304\n",
      "[40, 180] loss: 0.299\n",
      "[40, 240] loss: 0.313\n",
      "[40, 300] loss: 0.313\n",
      "[40, 360] loss: 0.325\n",
      "Epoch: 40 -> Loss: 0.345504283905\n",
      "Epoch: 40 -> Test Accuracy: 86.7875\n",
      "[41, 60] loss: 0.294\n",
      "[41, 120] loss: 0.296\n",
      "[41, 180] loss: 0.312\n",
      "[41, 240] loss: 0.314\n",
      "[41, 300] loss: 0.305\n",
      "[41, 360] loss: 0.322\n",
      "Epoch: 41 -> Loss: 0.262806266546\n",
      "Epoch: 41 -> Test Accuracy: 87.14\n",
      "[42, 60] loss: 0.311\n",
      "[42, 120] loss: 0.310\n",
      "[42, 180] loss: 0.306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 240] loss: 0.309\n",
      "[42, 300] loss: 0.298\n",
      "[42, 360] loss: 0.321\n",
      "Epoch: 42 -> Loss: 0.376379430294\n",
      "Epoch: 42 -> Test Accuracy: 86.2675\n",
      "[43, 60] loss: 0.293\n",
      "[43, 120] loss: 0.311\n",
      "[43, 180] loss: 0.289\n",
      "[43, 240] loss: 0.314\n",
      "[43, 300] loss: 0.318\n",
      "[43, 360] loss: 0.310\n",
      "Epoch: 43 -> Loss: 0.433914572001\n",
      "Epoch: 43 -> Test Accuracy: 86.505\n",
      "[44, 60] loss: 0.289\n",
      "[44, 120] loss: 0.298\n",
      "[44, 180] loss: 0.313\n",
      "[44, 240] loss: 0.312\n",
      "[44, 300] loss: 0.295\n",
      "[44, 360] loss: 0.324\n",
      "Epoch: 44 -> Loss: 0.233928084373\n",
      "Epoch: 44 -> Test Accuracy: 86.46\n",
      "[45, 60] loss: 0.298\n",
      "[45, 120] loss: 0.296\n",
      "[45, 180] loss: 0.316\n",
      "[45, 240] loss: 0.301\n",
      "[45, 300] loss: 0.314\n",
      "[45, 360] loss: 0.314\n",
      "Epoch: 45 -> Loss: 0.373682260513\n",
      "Epoch: 45 -> Test Accuracy: 86.8825\n",
      "[46, 60] loss: 0.304\n",
      "[46, 120] loss: 0.312\n",
      "[46, 180] loss: 0.295\n",
      "[46, 240] loss: 0.307\n",
      "[46, 300] loss: 0.307\n",
      "[46, 360] loss: 0.312\n",
      "Epoch: 46 -> Loss: 0.465635359287\n",
      "Epoch: 46 -> Test Accuracy: 86.6075\n",
      "[47, 60] loss: 0.297\n",
      "[47, 120] loss: 0.309\n",
      "[47, 180] loss: 0.305\n",
      "[47, 240] loss: 0.303\n",
      "[47, 300] loss: 0.313\n",
      "[47, 360] loss: 0.310\n",
      "Epoch: 47 -> Loss: 0.272398889065\n",
      "Epoch: 47 -> Test Accuracy: 86.5625\n",
      "[48, 60] loss: 0.286\n",
      "[48, 120] loss: 0.303\n",
      "[48, 180] loss: 0.301\n",
      "[48, 240] loss: 0.301\n",
      "[48, 300] loss: 0.311\n",
      "[48, 360] loss: 0.308\n",
      "Epoch: 48 -> Loss: 0.431974261999\n",
      "Epoch: 48 -> Test Accuracy: 86.965\n",
      "[49, 60] loss: 0.293\n",
      "[49, 120] loss: 0.308\n",
      "[49, 180] loss: 0.314\n",
      "[49, 240] loss: 0.304\n",
      "[49, 300] loss: 0.296\n",
      "[49, 360] loss: 0.316\n",
      "Epoch: 49 -> Loss: 0.193006172776\n",
      "Epoch: 49 -> Test Accuracy: 86.685\n",
      "[50, 60] loss: 0.290\n",
      "[50, 120] loss: 0.298\n",
      "[50, 180] loss: 0.301\n",
      "[50, 240] loss: 0.306\n",
      "[50, 300] loss: 0.310\n",
      "[50, 360] loss: 0.300\n",
      "Epoch: 50 -> Loss: 0.239923790097\n",
      "Epoch: 50 -> Test Accuracy: 86.2625\n",
      "[51, 60] loss: 0.297\n",
      "[51, 120] loss: 0.291\n",
      "[51, 180] loss: 0.311\n",
      "[51, 240] loss: 0.308\n",
      "[51, 300] loss: 0.300\n",
      "[51, 360] loss: 0.305\n",
      "Epoch: 51 -> Loss: 0.302880197763\n",
      "Epoch: 51 -> Test Accuracy: 86.5675\n",
      "[52, 60] loss: 0.294\n",
      "[52, 120] loss: 0.295\n",
      "[52, 180] loss: 0.311\n",
      "[52, 240] loss: 0.299\n",
      "[52, 300] loss: 0.302\n",
      "[52, 360] loss: 0.323\n",
      "Epoch: 52 -> Loss: 0.293491631746\n",
      "Epoch: 52 -> Test Accuracy: 87.235\n",
      "[53, 60] loss: 0.289\n",
      "[53, 120] loss: 0.309\n",
      "[53, 180] loss: 0.302\n",
      "[53, 240] loss: 0.311\n",
      "[53, 300] loss: 0.304\n",
      "[53, 360] loss: 0.307\n",
      "Epoch: 53 -> Loss: 0.267398178577\n",
      "Epoch: 53 -> Test Accuracy: 86.995\n",
      "[54, 60] loss: 0.283\n",
      "[54, 120] loss: 0.307\n",
      "[54, 180] loss: 0.293\n",
      "[54, 240] loss: 0.303\n",
      "[54, 300] loss: 0.315\n",
      "[54, 360] loss: 0.302\n",
      "Epoch: 54 -> Loss: 0.242679029703\n",
      "Epoch: 54 -> Test Accuracy: 86.9875\n",
      "[55, 60] loss: 0.280\n",
      "[55, 120] loss: 0.290\n",
      "[55, 180] loss: 0.311\n",
      "[55, 240] loss: 0.310\n",
      "[55, 300] loss: 0.298\n",
      "[55, 360] loss: 0.306\n",
      "Epoch: 55 -> Loss: 0.259468972683\n",
      "Epoch: 55 -> Test Accuracy: 87.175\n",
      "[56, 60] loss: 0.291\n",
      "[56, 120] loss: 0.312\n",
      "[56, 180] loss: 0.312\n",
      "[56, 240] loss: 0.292\n",
      "[56, 300] loss: 0.291\n",
      "[56, 360] loss: 0.314\n",
      "Epoch: 56 -> Loss: 0.439259707928\n",
      "Epoch: 56 -> Test Accuracy: 86.91\n",
      "[57, 60] loss: 0.291\n",
      "[57, 120] loss: 0.289\n",
      "[57, 180] loss: 0.315\n",
      "[57, 240] loss: 0.310\n",
      "[57, 300] loss: 0.312\n",
      "[57, 360] loss: 0.298\n",
      "Epoch: 57 -> Loss: 0.151287257671\n",
      "Epoch: 57 -> Test Accuracy: 87.1025\n",
      "[58, 60] loss: 0.285\n",
      "[58, 120] loss: 0.280\n",
      "[58, 180] loss: 0.301\n",
      "[58, 240] loss: 0.317\n",
      "[58, 300] loss: 0.299\n",
      "[58, 360] loss: 0.306\n",
      "Epoch: 58 -> Loss: 0.193482190371\n",
      "Epoch: 58 -> Test Accuracy: 87.565\n",
      "[59, 60] loss: 0.280\n",
      "[59, 120] loss: 0.298\n",
      "[59, 180] loss: 0.297\n",
      "[59, 240] loss: 0.304\n",
      "[59, 300] loss: 0.305\n",
      "[59, 360] loss: 0.304\n",
      "Epoch: 59 -> Loss: 0.332741349936\n",
      "Epoch: 59 -> Test Accuracy: 86.3\n",
      "[60, 60] loss: 0.293\n",
      "[60, 120] loss: 0.292\n",
      "[60, 180] loss: 0.299\n",
      "[60, 240] loss: 0.305\n",
      "[60, 300] loss: 0.305\n",
      "[60, 360] loss: 0.298\n",
      "Epoch: 60 -> Loss: 0.220597743988\n",
      "Epoch: 60 -> Test Accuracy: 87.2275\n",
      "[61, 60] loss: 0.226\n",
      "[61, 120] loss: 0.209\n",
      "[61, 180] loss: 0.190\n",
      "[61, 240] loss: 0.189\n",
      "[61, 300] loss: 0.179\n",
      "[61, 360] loss: 0.185\n",
      "Epoch: 61 -> Loss: 0.165580898523\n",
      "Epoch: 61 -> Test Accuracy: 91.025\n",
      "[62, 60] loss: 0.163\n",
      "[62, 120] loss: 0.171\n",
      "[62, 180] loss: 0.172\n",
      "[62, 240] loss: 0.170\n",
      "[62, 300] loss: 0.169\n",
      "[62, 360] loss: 0.167\n",
      "Epoch: 62 -> Loss: 0.198534682393\n",
      "Epoch: 62 -> Test Accuracy: 90.885\n",
      "[63, 60] loss: 0.155\n",
      "[63, 120] loss: 0.158\n",
      "[63, 180] loss: 0.164\n",
      "[63, 240] loss: 0.152\n",
      "[63, 300] loss: 0.161\n",
      "[63, 360] loss: 0.159\n",
      "Epoch: 63 -> Loss: 0.14084123075\n",
      "Epoch: 63 -> Test Accuracy: 91.4175\n",
      "[64, 60] loss: 0.136\n",
      "[64, 120] loss: 0.148\n",
      "[64, 180] loss: 0.157\n",
      "[64, 240] loss: 0.166\n",
      "[64, 300] loss: 0.149\n",
      "[64, 360] loss: 0.157\n",
      "Epoch: 64 -> Loss: 0.114685416222\n",
      "Epoch: 64 -> Test Accuracy: 91.205\n",
      "[65, 60] loss: 0.137\n",
      "[65, 120] loss: 0.149\n",
      "[65, 180] loss: 0.147\n",
      "[65, 240] loss: 0.153\n",
      "[65, 300] loss: 0.154\n",
      "[65, 360] loss: 0.163\n",
      "Epoch: 65 -> Loss: 0.123090267181\n",
      "Epoch: 65 -> Test Accuracy: 91.3625\n",
      "[66, 60] loss: 0.138\n",
      "[66, 120] loss: 0.149\n",
      "[66, 180] loss: 0.148\n",
      "[66, 240] loss: 0.144\n",
      "[66, 300] loss: 0.144\n",
      "[66, 360] loss: 0.153\n",
      "Epoch: 66 -> Loss: 0.134114712477\n",
      "Epoch: 66 -> Test Accuracy: 90.83\n",
      "[67, 60] loss: 0.138\n",
      "[67, 120] loss: 0.144\n",
      "[67, 180] loss: 0.147\n",
      "[67, 240] loss: 0.157\n",
      "[67, 300] loss: 0.143\n",
      "[67, 360] loss: 0.146\n",
      "Epoch: 67 -> Loss: 0.221834331751\n",
      "Epoch: 67 -> Test Accuracy: 90.7225\n",
      "[68, 60] loss: 0.132\n",
      "[68, 120] loss: 0.145\n",
      "[68, 180] loss: 0.148\n",
      "[68, 240] loss: 0.146\n",
      "[68, 300] loss: 0.151\n",
      "[68, 360] loss: 0.156\n",
      "Epoch: 68 -> Loss: 0.248655170202\n",
      "Epoch: 68 -> Test Accuracy: 90.8825\n",
      "[69, 60] loss: 0.138\n",
      "[69, 120] loss: 0.147\n",
      "[69, 180] loss: 0.142\n",
      "[69, 240] loss: 0.148\n",
      "[69, 300] loss: 0.150\n",
      "[69, 360] loss: 0.154\n",
      "Epoch: 69 -> Loss: 0.163895621896\n",
      "Epoch: 69 -> Test Accuracy: 90.8175\n",
      "[70, 60] loss: 0.142\n",
      "[70, 120] loss: 0.136\n",
      "[70, 180] loss: 0.136\n",
      "[70, 240] loss: 0.148\n",
      "[70, 300] loss: 0.158\n",
      "[70, 360] loss: 0.160\n",
      "Epoch: 70 -> Loss: 0.179634109139\n",
      "Epoch: 70 -> Test Accuracy: 90.5925\n",
      "[71, 60] loss: 0.138\n",
      "[71, 120] loss: 0.138\n",
      "[71, 180] loss: 0.146\n",
      "[71, 240] loss: 0.147\n",
      "[71, 300] loss: 0.163\n",
      "[71, 360] loss: 0.144\n",
      "Epoch: 71 -> Loss: 0.18849851191\n",
      "Epoch: 71 -> Test Accuracy: 90.725\n",
      "[72, 60] loss: 0.133\n",
      "[72, 120] loss: 0.140\n",
      "[72, 180] loss: 0.143\n",
      "[72, 240] loss: 0.144\n",
      "[72, 300] loss: 0.150\n",
      "[72, 360] loss: 0.157\n",
      "Epoch: 72 -> Loss: 0.207772567868\n",
      "Epoch: 72 -> Test Accuracy: 90.515\n",
      "[73, 60] loss: 0.138\n",
      "[73, 120] loss: 0.147\n",
      "[73, 180] loss: 0.147\n",
      "[73, 240] loss: 0.149\n",
      "[73, 300] loss: 0.154\n",
      "[73, 360] loss: 0.147\n",
      "Epoch: 73 -> Loss: 0.091088488698\n",
      "Epoch: 73 -> Test Accuracy: 90.8675\n",
      "[74, 60] loss: 0.140\n",
      "[74, 120] loss: 0.143\n",
      "[74, 180] loss: 0.149\n",
      "[74, 240] loss: 0.145\n",
      "[74, 300] loss: 0.155\n",
      "[74, 360] loss: 0.148\n",
      "Epoch: 74 -> Loss: 0.119433067739\n",
      "Epoch: 74 -> Test Accuracy: 90.2\n",
      "[75, 60] loss: 0.141\n",
      "[75, 120] loss: 0.143\n",
      "[75, 180] loss: 0.143\n",
      "[75, 240] loss: 0.160\n",
      "[75, 300] loss: 0.148\n",
      "[75, 360] loss: 0.155\n",
      "Epoch: 75 -> Loss: 0.116061523557\n",
      "Epoch: 75 -> Test Accuracy: 90.7075\n",
      "[76, 60] loss: 0.133\n",
      "[76, 120] loss: 0.144\n",
      "[76, 180] loss: 0.147\n",
      "[76, 240] loss: 0.145\n",
      "[76, 300] loss: 0.159\n",
      "[76, 360] loss: 0.153\n",
      "Epoch: 76 -> Loss: 0.152973085642\n",
      "Epoch: 76 -> Test Accuracy: 90.8775\n",
      "[77, 60] loss: 0.143\n",
      "[77, 120] loss: 0.155\n",
      "[77, 180] loss: 0.139\n",
      "[77, 240] loss: 0.148\n",
      "[77, 300] loss: 0.149\n",
      "[77, 360] loss: 0.147\n",
      "Epoch: 77 -> Loss: 0.157280683517\n",
      "Epoch: 77 -> Test Accuracy: 90.67\n",
      "[78, 60] loss: 0.146\n",
      "[78, 120] loss: 0.137\n",
      "[78, 180] loss: 0.157\n",
      "[78, 240] loss: 0.150\n",
      "[78, 300] loss: 0.151\n",
      "[78, 360] loss: 0.150\n",
      "Epoch: 78 -> Loss: 0.141041606665\n",
      "Epoch: 78 -> Test Accuracy: 90.43\n",
      "[79, 60] loss: 0.141\n",
      "[79, 120] loss: 0.142\n",
      "[79, 180] loss: 0.139\n",
      "[79, 240] loss: 0.136\n",
      "[79, 300] loss: 0.147\n",
      "[79, 360] loss: 0.158\n",
      "Epoch: 79 -> Loss: 0.13394805789\n",
      "Epoch: 79 -> Test Accuracy: 90.6075\n",
      "[80, 60] loss: 0.136\n",
      "[80, 120] loss: 0.139\n",
      "[80, 180] loss: 0.139\n",
      "[80, 240] loss: 0.153\n",
      "[80, 300] loss: 0.156\n",
      "[80, 360] loss: 0.152\n",
      "Epoch: 80 -> Loss: 0.19943228364\n",
      "Epoch: 80 -> Test Accuracy: 90.79\n",
      "[81, 60] loss: 0.136\n",
      "[81, 120] loss: 0.142\n",
      "[81, 180] loss: 0.141\n",
      "[81, 240] loss: 0.149\n",
      "[81, 300] loss: 0.150\n",
      "[81, 360] loss: 0.156\n",
      "Epoch: 81 -> Loss: 0.1373013556\n",
      "Epoch: 81 -> Test Accuracy: 89.83\n",
      "[82, 60] loss: 0.140\n",
      "[82, 120] loss: 0.143\n",
      "[82, 180] loss: 0.147\n",
      "[82, 240] loss: 0.143\n",
      "[82, 300] loss: 0.150\n",
      "[82, 360] loss: 0.147\n",
      "Epoch: 82 -> Loss: 0.10877969116\n",
      "Epoch: 82 -> Test Accuracy: 89.845\n",
      "[83, 60] loss: 0.147\n",
      "[83, 120] loss: 0.137\n",
      "[83, 180] loss: 0.139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83, 240] loss: 0.153\n",
      "[83, 300] loss: 0.155\n",
      "[83, 360] loss: 0.162\n",
      "Epoch: 83 -> Loss: 0.103295899928\n",
      "Epoch: 83 -> Test Accuracy: 90.4825\n",
      "[84, 60] loss: 0.133\n",
      "[84, 120] loss: 0.141\n",
      "[84, 180] loss: 0.153\n",
      "[84, 240] loss: 0.148\n",
      "[84, 300] loss: 0.147\n",
      "[84, 360] loss: 0.151\n",
      "Epoch: 84 -> Loss: 0.147079840302\n",
      "Epoch: 84 -> Test Accuracy: 90.51\n",
      "[85, 60] loss: 0.139\n",
      "[85, 120] loss: 0.138\n",
      "[85, 180] loss: 0.152\n",
      "[85, 240] loss: 0.146\n",
      "[85, 300] loss: 0.153\n",
      "[85, 360] loss: 0.150\n",
      "Epoch: 85 -> Loss: 0.214863091707\n",
      "Epoch: 85 -> Test Accuracy: 90.4625\n",
      "[86, 60] loss: 0.138\n",
      "[86, 120] loss: 0.138\n",
      "[86, 180] loss: 0.143\n",
      "[86, 240] loss: 0.148\n",
      "[86, 300] loss: 0.138\n",
      "[86, 360] loss: 0.156\n",
      "Epoch: 86 -> Loss: 0.222716003656\n",
      "Epoch: 86 -> Test Accuracy: 90.4325\n",
      "[87, 60] loss: 0.145\n",
      "[87, 120] loss: 0.133\n",
      "[87, 180] loss: 0.140\n",
      "[87, 240] loss: 0.146\n",
      "[87, 300] loss: 0.151\n",
      "[87, 360] loss: 0.159\n",
      "Epoch: 87 -> Loss: 0.0961948111653\n",
      "Epoch: 87 -> Test Accuracy: 90.4175\n",
      "[88, 60] loss: 0.133\n",
      "[88, 120] loss: 0.125\n",
      "[88, 180] loss: 0.141\n",
      "[88, 240] loss: 0.152\n",
      "[88, 300] loss: 0.151\n",
      "[88, 360] loss: 0.164\n",
      "Epoch: 88 -> Loss: 0.188350990415\n",
      "Epoch: 88 -> Test Accuracy: 90.5175\n",
      "[89, 60] loss: 0.129\n",
      "[89, 120] loss: 0.141\n",
      "[89, 180] loss: 0.142\n",
      "[89, 240] loss: 0.152\n",
      "[89, 300] loss: 0.134\n",
      "[89, 360] loss: 0.146\n",
      "Epoch: 89 -> Loss: 0.124206028879\n",
      "Epoch: 89 -> Test Accuracy: 90.215\n",
      "[90, 60] loss: 0.126\n",
      "[90, 120] loss: 0.142\n",
      "[90, 180] loss: 0.141\n",
      "[90, 240] loss: 0.144\n",
      "[90, 300] loss: 0.157\n",
      "[90, 360] loss: 0.150\n",
      "Epoch: 90 -> Loss: 0.137989237905\n",
      "Epoch: 90 -> Test Accuracy: 90.215\n",
      "[91, 60] loss: 0.131\n",
      "[91, 120] loss: 0.142\n",
      "[91, 180] loss: 0.139\n",
      "[91, 240] loss: 0.143\n",
      "[91, 300] loss: 0.148\n",
      "[91, 360] loss: 0.145\n",
      "Epoch: 91 -> Loss: 0.140888541937\n",
      "Epoch: 91 -> Test Accuracy: 90.3325\n",
      "[92, 60] loss: 0.138\n",
      "[92, 120] loss: 0.136\n",
      "[92, 180] loss: 0.136\n",
      "[92, 240] loss: 0.148\n",
      "[92, 300] loss: 0.145\n",
      "[92, 360] loss: 0.147\n",
      "Epoch: 92 -> Loss: 0.140086203814\n",
      "Epoch: 92 -> Test Accuracy: 90.5\n",
      "[93, 60] loss: 0.137\n",
      "[93, 120] loss: 0.136\n",
      "[93, 180] loss: 0.141\n",
      "[93, 240] loss: 0.151\n",
      "[93, 300] loss: 0.147\n",
      "[93, 360] loss: 0.148\n",
      "Epoch: 93 -> Loss: 0.181547090411\n",
      "Epoch: 93 -> Test Accuracy: 90.125\n",
      "[94, 60] loss: 0.125\n",
      "[94, 120] loss: 0.142\n",
      "[94, 180] loss: 0.132\n",
      "[94, 240] loss: 0.148\n",
      "[94, 300] loss: 0.137\n",
      "[94, 360] loss: 0.150\n",
      "Epoch: 94 -> Loss: 0.164701744914\n",
      "Epoch: 94 -> Test Accuracy: 89.7575\n",
      "[95, 60] loss: 0.138\n",
      "[95, 120] loss: 0.131\n",
      "[95, 180] loss: 0.132\n",
      "[95, 240] loss: 0.143\n",
      "[95, 300] loss: 0.139\n",
      "[95, 360] loss: 0.151\n",
      "Epoch: 95 -> Loss: 0.107503965497\n",
      "Epoch: 95 -> Test Accuracy: 90.22\n",
      "[96, 60] loss: 0.132\n",
      "[96, 120] loss: 0.143\n",
      "[96, 180] loss: 0.146\n",
      "[96, 240] loss: 0.134\n",
      "[96, 300] loss: 0.149\n",
      "[96, 360] loss: 0.147\n",
      "Epoch: 96 -> Loss: 0.142933100462\n",
      "Epoch: 96 -> Test Accuracy: 90.2675\n",
      "[97, 60] loss: 0.130\n",
      "[97, 120] loss: 0.130\n",
      "[97, 180] loss: 0.133\n",
      "[97, 240] loss: 0.140\n",
      "[97, 300] loss: 0.143\n",
      "[97, 360] loss: 0.147\n",
      "Epoch: 97 -> Loss: 0.115016400814\n",
      "Epoch: 97 -> Test Accuracy: 90.585\n",
      "[98, 60] loss: 0.137\n",
      "[98, 120] loss: 0.134\n",
      "[98, 180] loss: 0.138\n",
      "[98, 240] loss: 0.143\n",
      "[98, 300] loss: 0.140\n",
      "[98, 360] loss: 0.142\n",
      "Epoch: 98 -> Loss: 0.143771231174\n",
      "Epoch: 98 -> Test Accuracy: 90.5525\n",
      "[99, 60] loss: 0.130\n",
      "[99, 120] loss: 0.128\n",
      "[99, 180] loss: 0.143\n",
      "[99, 240] loss: 0.137\n",
      "[99, 300] loss: 0.145\n",
      "[99, 360] loss: 0.144\n",
      "Epoch: 99 -> Loss: 0.169886484742\n",
      "Epoch: 99 -> Test Accuracy: 90.615\n",
      "[100, 60] loss: 0.134\n",
      "[100, 120] loss: 0.145\n",
      "[100, 180] loss: 0.135\n",
      "[100, 240] loss: 0.128\n",
      "[100, 300] loss: 0.147\n",
      "[100, 360] loss: 0.145\n",
      "Epoch: 100 -> Loss: 0.162498265505\n",
      "Epoch: 100 -> Test Accuracy: 90.3075\n",
      "[101, 60] loss: 0.130\n",
      "[101, 120] loss: 0.131\n",
      "[101, 180] loss: 0.136\n",
      "[101, 240] loss: 0.140\n",
      "[101, 300] loss: 0.151\n",
      "[101, 360] loss: 0.139\n",
      "Epoch: 101 -> Loss: 0.139770880342\n",
      "Epoch: 101 -> Test Accuracy: 89.9825\n",
      "[102, 60] loss: 0.127\n",
      "[102, 120] loss: 0.134\n",
      "[102, 180] loss: 0.139\n",
      "[102, 240] loss: 0.140\n",
      "[102, 300] loss: 0.140\n",
      "[102, 360] loss: 0.143\n",
      "Epoch: 102 -> Loss: 0.134580343962\n",
      "Epoch: 102 -> Test Accuracy: 90.5225\n",
      "[103, 60] loss: 0.129\n",
      "[103, 120] loss: 0.125\n",
      "[103, 180] loss: 0.136\n",
      "[103, 240] loss: 0.136\n",
      "[103, 300] loss: 0.146\n",
      "[103, 360] loss: 0.136\n",
      "Epoch: 103 -> Loss: 0.133543401957\n",
      "Epoch: 103 -> Test Accuracy: 90.0975\n",
      "[104, 60] loss: 0.126\n",
      "[104, 120] loss: 0.129\n",
      "[104, 180] loss: 0.139\n",
      "[104, 240] loss: 0.150\n",
      "[104, 300] loss: 0.149\n",
      "[104, 360] loss: 0.140\n",
      "Epoch: 104 -> Loss: 0.102110818028\n",
      "Epoch: 104 -> Test Accuracy: 90.44\n",
      "[105, 60] loss: 0.128\n",
      "[105, 120] loss: 0.132\n",
      "[105, 180] loss: 0.133\n",
      "[105, 240] loss: 0.139\n",
      "[105, 300] loss: 0.146\n",
      "[105, 360] loss: 0.143\n",
      "Epoch: 105 -> Loss: 0.086242467165\n",
      "Epoch: 105 -> Test Accuracy: 90.4075\n",
      "[106, 60] loss: 0.128\n",
      "[106, 120] loss: 0.126\n",
      "[106, 180] loss: 0.142\n",
      "[106, 240] loss: 0.137\n",
      "[106, 300] loss: 0.133\n",
      "[106, 360] loss: 0.139\n",
      "Epoch: 106 -> Loss: 0.148943454027\n",
      "Epoch: 106 -> Test Accuracy: 90.385\n",
      "[107, 60] loss: 0.138\n",
      "[107, 120] loss: 0.125\n",
      "[107, 180] loss: 0.126\n",
      "[107, 240] loss: 0.135\n",
      "[107, 300] loss: 0.139\n",
      "[107, 360] loss: 0.142\n",
      "Epoch: 107 -> Loss: 0.229071691632\n",
      "Epoch: 107 -> Test Accuracy: 90.2425\n",
      "[108, 60] loss: 0.130\n",
      "[108, 120] loss: 0.131\n",
      "[108, 180] loss: 0.135\n",
      "[108, 240] loss: 0.144\n",
      "[108, 300] loss: 0.134\n",
      "[108, 360] loss: 0.146\n",
      "Epoch: 108 -> Loss: 0.163387209177\n",
      "Epoch: 108 -> Test Accuracy: 90.24\n",
      "[109, 60] loss: 0.128\n",
      "[109, 120] loss: 0.129\n",
      "[109, 180] loss: 0.134\n",
      "[109, 240] loss: 0.144\n",
      "[109, 300] loss: 0.132\n",
      "[109, 360] loss: 0.142\n",
      "Epoch: 109 -> Loss: 0.144147887826\n",
      "Epoch: 109 -> Test Accuracy: 89.925\n",
      "[110, 60] loss: 0.129\n",
      "[110, 120] loss: 0.129\n",
      "[110, 180] loss: 0.141\n",
      "[110, 240] loss: 0.139\n",
      "[110, 300] loss: 0.140\n",
      "[110, 360] loss: 0.139\n",
      "Epoch: 110 -> Loss: 0.0991406515241\n",
      "Epoch: 110 -> Test Accuracy: 90.085\n",
      "[111, 60] loss: 0.130\n",
      "[111, 120] loss: 0.132\n",
      "[111, 180] loss: 0.127\n",
      "[111, 240] loss: 0.132\n",
      "[111, 300] loss: 0.141\n",
      "[111, 360] loss: 0.146\n",
      "Epoch: 111 -> Loss: 0.160199016333\n",
      "Epoch: 111 -> Test Accuracy: 90.27\n",
      "[112, 60] loss: 0.122\n",
      "[112, 120] loss: 0.130\n",
      "[112, 180] loss: 0.135\n",
      "[112, 240] loss: 0.139\n",
      "[112, 300] loss: 0.138\n",
      "[112, 360] loss: 0.137\n",
      "Epoch: 112 -> Loss: 0.193298876286\n",
      "Epoch: 112 -> Test Accuracy: 89.9125\n",
      "[113, 60] loss: 0.120\n",
      "[113, 120] loss: 0.126\n",
      "[113, 180] loss: 0.137\n",
      "[113, 240] loss: 0.144\n",
      "[113, 300] loss: 0.140\n",
      "[113, 360] loss: 0.143\n",
      "Epoch: 113 -> Loss: 0.159166991711\n",
      "Epoch: 113 -> Test Accuracy: 90.58\n",
      "[114, 60] loss: 0.119\n",
      "[114, 120] loss: 0.138\n",
      "[114, 180] loss: 0.128\n",
      "[114, 240] loss: 0.137\n",
      "[114, 300] loss: 0.148\n",
      "[114, 360] loss: 0.139\n",
      "Epoch: 114 -> Loss: 0.113626554608\n",
      "Epoch: 114 -> Test Accuracy: 90.48\n",
      "[115, 60] loss: 0.124\n",
      "[115, 120] loss: 0.132\n",
      "[115, 180] loss: 0.130\n",
      "[115, 240] loss: 0.133\n",
      "[115, 300] loss: 0.135\n",
      "[115, 360] loss: 0.141\n",
      "Epoch: 115 -> Loss: 0.148457735777\n",
      "Epoch: 115 -> Test Accuracy: 90.31\n",
      "[116, 60] loss: 0.122\n",
      "[116, 120] loss: 0.130\n",
      "[116, 180] loss: 0.138\n",
      "[116, 240] loss: 0.130\n",
      "[116, 300] loss: 0.136\n",
      "[116, 360] loss: 0.142\n",
      "Epoch: 116 -> Loss: 0.100826404989\n",
      "Epoch: 116 -> Test Accuracy: 90.18\n",
      "[117, 60] loss: 0.128\n",
      "[117, 120] loss: 0.129\n",
      "[117, 180] loss: 0.119\n",
      "[117, 240] loss: 0.139\n",
      "[117, 300] loss: 0.145\n",
      "[117, 360] loss: 0.150\n",
      "Epoch: 117 -> Loss: 0.18143889308\n",
      "Epoch: 117 -> Test Accuracy: 90.2\n",
      "[118, 60] loss: 0.130\n",
      "[118, 120] loss: 0.126\n",
      "[118, 180] loss: 0.130\n",
      "[118, 240] loss: 0.130\n",
      "[118, 300] loss: 0.136\n",
      "[118, 360] loss: 0.141\n",
      "Epoch: 118 -> Loss: 0.211490273476\n",
      "Epoch: 118 -> Test Accuracy: 90.25\n",
      "[119, 60] loss: 0.126\n",
      "[119, 120] loss: 0.127\n",
      "[119, 180] loss: 0.128\n",
      "[119, 240] loss: 0.131\n",
      "[119, 300] loss: 0.136\n",
      "[119, 360] loss: 0.147\n",
      "Epoch: 119 -> Loss: 0.107009746134\n",
      "Epoch: 119 -> Test Accuracy: 90.405\n",
      "[120, 60] loss: 0.121\n",
      "[120, 120] loss: 0.124\n",
      "[120, 180] loss: 0.129\n",
      "[120, 240] loss: 0.130\n",
      "[120, 300] loss: 0.137\n",
      "[120, 360] loss: 0.136\n",
      "Epoch: 120 -> Loss: 0.13696295023\n",
      "Epoch: 120 -> Test Accuracy: 90.6125\n",
      "[121, 60] loss: 0.097\n",
      "[121, 120] loss: 0.080\n",
      "[121, 180] loss: 0.077\n",
      "[121, 240] loss: 0.076\n",
      "[121, 300] loss: 0.069\n",
      "[121, 360] loss: 0.072\n",
      "Epoch: 121 -> Loss: 0.0420458205044\n",
      "Epoch: 121 -> Test Accuracy: 92.4025\n",
      "[122, 60] loss: 0.062\n",
      "[122, 120] loss: 0.060\n",
      "[122, 180] loss: 0.061\n",
      "[122, 240] loss: 0.063\n",
      "[122, 300] loss: 0.061\n",
      "[122, 360] loss: 0.057\n",
      "Epoch: 122 -> Loss: 0.0746187418699\n",
      "Epoch: 122 -> Test Accuracy: 92.39\n",
      "[123, 60] loss: 0.054\n",
      "[123, 120] loss: 0.054\n",
      "[123, 180] loss: 0.050\n",
      "[123, 240] loss: 0.053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123, 300] loss: 0.058\n",
      "[123, 360] loss: 0.053\n",
      "Epoch: 123 -> Loss: 0.0764970779419\n",
      "Epoch: 123 -> Test Accuracy: 92.3325\n",
      "[124, 60] loss: 0.050\n",
      "[124, 120] loss: 0.050\n",
      "[124, 180] loss: 0.049\n",
      "[124, 240] loss: 0.052\n",
      "[124, 300] loss: 0.049\n",
      "[124, 360] loss: 0.050\n",
      "Epoch: 124 -> Loss: 0.0354960076511\n",
      "Epoch: 124 -> Test Accuracy: 92.375\n",
      "[125, 60] loss: 0.043\n",
      "[125, 120] loss: 0.043\n",
      "[125, 180] loss: 0.047\n",
      "[125, 240] loss: 0.045\n",
      "[125, 300] loss: 0.049\n",
      "[125, 360] loss: 0.049\n",
      "Epoch: 125 -> Loss: 0.077633947134\n",
      "Epoch: 125 -> Test Accuracy: 92.27\n",
      "[126, 60] loss: 0.041\n",
      "[126, 120] loss: 0.047\n",
      "[126, 180] loss: 0.042\n",
      "[126, 240] loss: 0.043\n",
      "[126, 300] loss: 0.046\n",
      "[126, 360] loss: 0.047\n",
      "Epoch: 126 -> Loss: 0.0515734478831\n",
      "Epoch: 126 -> Test Accuracy: 92.3\n",
      "[127, 60] loss: 0.038\n",
      "[127, 120] loss: 0.040\n",
      "[127, 180] loss: 0.042\n",
      "[127, 240] loss: 0.046\n",
      "[127, 300] loss: 0.041\n",
      "[127, 360] loss: 0.044\n",
      "Epoch: 127 -> Loss: 0.0225582513958\n",
      "Epoch: 127 -> Test Accuracy: 92.275\n",
      "[128, 60] loss: 0.037\n",
      "[128, 120] loss: 0.043\n",
      "[128, 180] loss: 0.041\n",
      "[128, 240] loss: 0.040\n",
      "[128, 300] loss: 0.037\n",
      "[128, 360] loss: 0.040\n",
      "Epoch: 128 -> Loss: 0.0397034659982\n",
      "Epoch: 128 -> Test Accuracy: 92.125\n",
      "[129, 60] loss: 0.038\n",
      "[129, 120] loss: 0.038\n",
      "[129, 180] loss: 0.037\n",
      "[129, 240] loss: 0.036\n",
      "[129, 300] loss: 0.041\n",
      "[129, 360] loss: 0.040\n",
      "Epoch: 129 -> Loss: 0.0425793305039\n",
      "Epoch: 129 -> Test Accuracy: 92.19\n",
      "[130, 60] loss: 0.036\n",
      "[130, 120] loss: 0.035\n",
      "[130, 180] loss: 0.035\n",
      "[130, 240] loss: 0.037\n",
      "[130, 300] loss: 0.038\n",
      "[130, 360] loss: 0.038\n",
      "Epoch: 130 -> Loss: 0.0414976291358\n",
      "Epoch: 130 -> Test Accuracy: 92.285\n",
      "[131, 60] loss: 0.036\n",
      "[131, 120] loss: 0.035\n",
      "[131, 180] loss: 0.035\n",
      "[131, 240] loss: 0.035\n",
      "[131, 300] loss: 0.034\n",
      "[131, 360] loss: 0.037\n",
      "Epoch: 131 -> Loss: 0.0480689816177\n",
      "Epoch: 131 -> Test Accuracy: 92.0575\n",
      "[132, 60] loss: 0.033\n",
      "[132, 120] loss: 0.032\n",
      "[132, 180] loss: 0.035\n",
      "[132, 240] loss: 0.032\n",
      "[132, 300] loss: 0.034\n",
      "[132, 360] loss: 0.034\n",
      "Epoch: 132 -> Loss: 0.0213881768286\n",
      "Epoch: 132 -> Test Accuracy: 92.02\n",
      "[133, 60] loss: 0.031\n",
      "[133, 120] loss: 0.032\n",
      "[133, 180] loss: 0.034\n",
      "[133, 240] loss: 0.031\n",
      "[133, 300] loss: 0.035\n",
      "[133, 360] loss: 0.034\n",
      "Epoch: 133 -> Loss: 0.0156694091856\n",
      "Epoch: 133 -> Test Accuracy: 92.14\n",
      "[134, 60] loss: 0.032\n",
      "[134, 120] loss: 0.029\n",
      "[134, 180] loss: 0.029\n",
      "[134, 240] loss: 0.029\n",
      "[134, 300] loss: 0.032\n",
      "[134, 360] loss: 0.031\n",
      "Epoch: 134 -> Loss: 0.0498161613941\n",
      "Epoch: 134 -> Test Accuracy: 92.28\n",
      "[135, 60] loss: 0.029\n",
      "[135, 120] loss: 0.031\n",
      "[135, 180] loss: 0.030\n",
      "[135, 240] loss: 0.031\n",
      "[135, 300] loss: 0.033\n",
      "[135, 360] loss: 0.033\n",
      "Epoch: 135 -> Loss: 0.0174076873809\n",
      "Epoch: 135 -> Test Accuracy: 92.315\n",
      "[136, 60] loss: 0.029\n",
      "[136, 120] loss: 0.028\n",
      "[136, 180] loss: 0.030\n",
      "[136, 240] loss: 0.032\n",
      "[136, 300] loss: 0.032\n",
      "[136, 360] loss: 0.031\n",
      "Epoch: 136 -> Loss: 0.0354817099869\n",
      "Epoch: 136 -> Test Accuracy: 92.175\n",
      "[137, 60] loss: 0.029\n",
      "[137, 120] loss: 0.029\n",
      "[137, 180] loss: 0.027\n",
      "[137, 240] loss: 0.030\n",
      "[137, 300] loss: 0.029\n",
      "[137, 360] loss: 0.032\n",
      "Epoch: 137 -> Loss: 0.034952942282\n",
      "Epoch: 137 -> Test Accuracy: 92.0175\n",
      "[138, 60] loss: 0.027\n",
      "[138, 120] loss: 0.032\n",
      "[138, 180] loss: 0.031\n",
      "[138, 240] loss: 0.030\n",
      "[138, 300] loss: 0.030\n",
      "[138, 360] loss: 0.031\n",
      "Epoch: 138 -> Loss: 0.0289147906005\n",
      "Epoch: 138 -> Test Accuracy: 92.11\n",
      "[139, 60] loss: 0.029\n",
      "[139, 120] loss: 0.028\n",
      "[139, 180] loss: 0.029\n",
      "[139, 240] loss: 0.028\n",
      "[139, 300] loss: 0.033\n",
      "[139, 360] loss: 0.027\n",
      "Epoch: 139 -> Loss: 0.0212121438235\n",
      "Epoch: 139 -> Test Accuracy: 92.1325\n",
      "[140, 60] loss: 0.027\n",
      "[140, 120] loss: 0.025\n",
      "[140, 180] loss: 0.027\n",
      "[140, 240] loss: 0.030\n",
      "[140, 300] loss: 0.029\n",
      "[140, 360] loss: 0.030\n",
      "Epoch: 140 -> Loss: 0.0177250169218\n",
      "Epoch: 140 -> Test Accuracy: 91.8625\n",
      "[141, 60] loss: 0.027\n",
      "[141, 120] loss: 0.026\n",
      "[141, 180] loss: 0.028\n",
      "[141, 240] loss: 0.027\n",
      "[141, 300] loss: 0.026\n",
      "[141, 360] loss: 0.029\n",
      "Epoch: 141 -> Loss: 0.0201147049665\n",
      "Epoch: 141 -> Test Accuracy: 91.9925\n",
      "[142, 60] loss: 0.025\n",
      "[142, 120] loss: 0.027\n",
      "[142, 180] loss: 0.026\n",
      "[142, 240] loss: 0.027\n",
      "[142, 300] loss: 0.027\n",
      "[142, 360] loss: 0.031\n",
      "Epoch: 142 -> Loss: 0.0238336622715\n",
      "Epoch: 142 -> Test Accuracy: 92.0275\n",
      "[143, 60] loss: 0.024\n",
      "[143, 120] loss: 0.026\n",
      "[143, 180] loss: 0.025\n",
      "[143, 240] loss: 0.028\n",
      "[143, 300] loss: 0.028\n",
      "[143, 360] loss: 0.028\n",
      "Epoch: 143 -> Loss: 0.0369565561414\n",
      "Epoch: 143 -> Test Accuracy: 91.8175\n",
      "[144, 60] loss: 0.025\n",
      "[144, 120] loss: 0.026\n",
      "[144, 180] loss: 0.025\n",
      "[144, 240] loss: 0.027\n",
      "[144, 300] loss: 0.028\n",
      "[144, 360] loss: 0.027\n",
      "Epoch: 144 -> Loss: 0.0428001768887\n",
      "Epoch: 144 -> Test Accuracy: 91.9875\n",
      "[145, 60] loss: 0.023\n",
      "[145, 120] loss: 0.028\n",
      "[145, 180] loss: 0.027\n",
      "[145, 240] loss: 0.025\n",
      "[145, 300] loss: 0.027\n",
      "[145, 360] loss: 0.027\n",
      "Epoch: 145 -> Loss: 0.0284945722669\n",
      "Epoch: 145 -> Test Accuracy: 91.78\n",
      "[146, 60] loss: 0.024\n",
      "[146, 120] loss: 0.025\n",
      "[146, 180] loss: 0.027\n",
      "[146, 240] loss: 0.027\n",
      "[146, 300] loss: 0.027\n",
      "[146, 360] loss: 0.028\n",
      "Epoch: 146 -> Loss: 0.0268977172673\n",
      "Epoch: 146 -> Test Accuracy: 91.8025\n",
      "[147, 60] loss: 0.024\n",
      "[147, 120] loss: 0.025\n",
      "[147, 180] loss: 0.025\n",
      "[147, 240] loss: 0.025\n",
      "[147, 300] loss: 0.026\n",
      "[147, 360] loss: 0.027\n",
      "Epoch: 147 -> Loss: 0.0371397770941\n",
      "Epoch: 147 -> Test Accuracy: 91.86\n",
      "[148, 60] loss: 0.028\n",
      "[148, 120] loss: 0.026\n",
      "[148, 180] loss: 0.025\n",
      "[148, 240] loss: 0.025\n",
      "[148, 300] loss: 0.027\n",
      "[148, 360] loss: 0.026\n",
      "Epoch: 148 -> Loss: 0.0221210904419\n",
      "Epoch: 148 -> Test Accuracy: 91.7575\n",
      "[149, 60] loss: 0.026\n",
      "[149, 120] loss: 0.025\n",
      "[149, 180] loss: 0.024\n",
      "[149, 240] loss: 0.026\n",
      "[149, 300] loss: 0.026\n",
      "[149, 360] loss: 0.023\n",
      "Epoch: 149 -> Loss: 0.0357726924121\n",
      "Epoch: 149 -> Test Accuracy: 91.9575\n",
      "[150, 60] loss: 0.024\n",
      "[150, 120] loss: 0.026\n",
      "[150, 180] loss: 0.024\n",
      "[150, 240] loss: 0.025\n",
      "[150, 300] loss: 0.025\n",
      "[150, 360] loss: 0.029\n",
      "Epoch: 150 -> Loss: 0.012254926376\n",
      "Epoch: 150 -> Test Accuracy: 91.915\n",
      "[151, 60] loss: 0.025\n",
      "[151, 120] loss: 0.026\n",
      "[151, 180] loss: 0.025\n",
      "[151, 240] loss: 0.024\n",
      "[151, 300] loss: 0.026\n",
      "[151, 360] loss: 0.027\n",
      "Epoch: 151 -> Loss: 0.0336840897799\n",
      "Epoch: 151 -> Test Accuracy: 91.7775\n",
      "[152, 60] loss: 0.023\n",
      "[152, 120] loss: 0.024\n",
      "[152, 180] loss: 0.025\n",
      "[152, 240] loss: 0.025\n",
      "[152, 300] loss: 0.025\n",
      "[152, 360] loss: 0.027\n",
      "Epoch: 152 -> Loss: 0.0128999445587\n",
      "Epoch: 152 -> Test Accuracy: 91.8875\n",
      "[153, 60] loss: 0.024\n",
      "[153, 120] loss: 0.023\n",
      "[153, 180] loss: 0.025\n",
      "[153, 240] loss: 0.025\n",
      "[153, 300] loss: 0.025\n",
      "[153, 360] loss: 0.025\n",
      "Epoch: 153 -> Loss: 0.0262708812952\n",
      "Epoch: 153 -> Test Accuracy: 91.7375\n",
      "[154, 60] loss: 0.024\n",
      "[154, 120] loss: 0.025\n",
      "[154, 180] loss: 0.026\n",
      "[154, 240] loss: 0.023\n",
      "[154, 300] loss: 0.026\n",
      "[154, 360] loss: 0.028\n",
      "Epoch: 154 -> Loss: 0.00888414215297\n",
      "Epoch: 154 -> Test Accuracy: 91.7975\n",
      "[155, 60] loss: 0.023\n",
      "[155, 120] loss: 0.024\n",
      "[155, 180] loss: 0.024\n",
      "[155, 240] loss: 0.026\n",
      "[155, 300] loss: 0.025\n",
      "[155, 360] loss: 0.027\n",
      "Epoch: 155 -> Loss: 0.0332946106791\n",
      "Epoch: 155 -> Test Accuracy: 91.785\n",
      "[156, 60] loss: 0.025\n",
      "[156, 120] loss: 0.023\n",
      "[156, 180] loss: 0.026\n",
      "[156, 240] loss: 0.023\n",
      "[156, 300] loss: 0.027\n",
      "[156, 360] loss: 0.028\n",
      "Epoch: 156 -> Loss: 0.0302413292229\n",
      "Epoch: 156 -> Test Accuracy: 91.8625\n",
      "[157, 60] loss: 0.024\n",
      "[157, 120] loss: 0.021\n",
      "[157, 180] loss: 0.023\n",
      "[157, 240] loss: 0.026\n",
      "[157, 300] loss: 0.027\n",
      "[157, 360] loss: 0.025\n",
      "Epoch: 157 -> Loss: 0.0149946901947\n",
      "Epoch: 157 -> Test Accuracy: 91.84\n",
      "[158, 60] loss: 0.023\n",
      "[158, 120] loss: 0.025\n",
      "[158, 180] loss: 0.024\n",
      "[158, 240] loss: 0.026\n",
      "[158, 300] loss: 0.024\n",
      "[158, 360] loss: 0.027\n",
      "Epoch: 158 -> Loss: 0.0388710871339\n",
      "Epoch: 158 -> Test Accuracy: 91.79\n",
      "[159, 60] loss: 0.024\n",
      "[159, 120] loss: 0.025\n",
      "[159, 180] loss: 0.024\n",
      "[159, 240] loss: 0.026\n",
      "[159, 300] loss: 0.026\n",
      "[159, 360] loss: 0.025\n",
      "Epoch: 159 -> Loss: 0.0604827180505\n",
      "Epoch: 159 -> Test Accuracy: 91.6775\n",
      "[160, 60] loss: 0.025\n",
      "[160, 120] loss: 0.023\n",
      "[160, 180] loss: 0.026\n",
      "[160, 240] loss: 0.025\n",
      "[160, 300] loss: 0.027\n",
      "[160, 360] loss: 0.026\n",
      "Epoch: 160 -> Loss: 0.0213848222047\n",
      "Epoch: 160 -> Test Accuracy: 91.6725\n",
      "[161, 60] loss: 0.020\n",
      "[161, 120] loss: 0.019\n",
      "[161, 180] loss: 0.019\n",
      "[161, 240] loss: 0.018\n",
      "[161, 300] loss: 0.016\n",
      "[161, 360] loss: 0.016\n",
      "Epoch: 161 -> Loss: 0.0140937836841\n",
      "Epoch: 161 -> Test Accuracy: 92.105\n",
      "[162, 60] loss: 0.016\n",
      "[162, 120] loss: 0.016\n",
      "[162, 180] loss: 0.015\n",
      "[162, 240] loss: 0.014\n",
      "[162, 300] loss: 0.015\n",
      "[162, 360] loss: 0.015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 162 -> Loss: 0.0166986938566\n",
      "Epoch: 162 -> Test Accuracy: 92.1075\n",
      "[163, 60] loss: 0.014\n",
      "[163, 120] loss: 0.013\n",
      "[163, 180] loss: 0.014\n",
      "[163, 240] loss: 0.014\n",
      "[163, 300] loss: 0.015\n",
      "[163, 360] loss: 0.014\n",
      "Epoch: 163 -> Loss: 0.0162970721722\n",
      "Epoch: 163 -> Test Accuracy: 92.05\n",
      "[164, 60] loss: 0.014\n",
      "[164, 120] loss: 0.014\n",
      "[164, 180] loss: 0.014\n",
      "[164, 240] loss: 0.014\n",
      "[164, 300] loss: 0.013\n",
      "[164, 360] loss: 0.013\n",
      "Epoch: 164 -> Loss: 0.00841785594821\n",
      "Epoch: 164 -> Test Accuracy: 92.0275\n",
      "[165, 60] loss: 0.013\n",
      "[165, 120] loss: 0.013\n",
      "[165, 180] loss: 0.012\n",
      "[165, 240] loss: 0.013\n",
      "[165, 300] loss: 0.013\n",
      "[165, 360] loss: 0.013\n",
      "Epoch: 165 -> Loss: 0.0120249781758\n",
      "Epoch: 165 -> Test Accuracy: 92.0225\n",
      "[166, 60] loss: 0.012\n",
      "[166, 120] loss: 0.012\n",
      "[166, 180] loss: 0.013\n",
      "[166, 240] loss: 0.014\n",
      "[166, 300] loss: 0.013\n",
      "[166, 360] loss: 0.013\n",
      "Epoch: 166 -> Loss: 0.00935164559633\n",
      "Epoch: 166 -> Test Accuracy: 91.97\n",
      "[167, 60] loss: 0.012\n",
      "[167, 120] loss: 0.013\n",
      "[167, 180] loss: 0.012\n",
      "[167, 240] loss: 0.013\n",
      "[167, 300] loss: 0.012\n",
      "[167, 360] loss: 0.013\n",
      "Epoch: 167 -> Loss: 0.00949574541301\n",
      "Epoch: 167 -> Test Accuracy: 92.01\n",
      "[168, 60] loss: 0.011\n",
      "[168, 120] loss: 0.012\n",
      "[168, 180] loss: 0.013\n",
      "[168, 240] loss: 0.012\n",
      "[168, 300] loss: 0.013\n",
      "[168, 360] loss: 0.012\n",
      "Epoch: 168 -> Loss: 0.00625553447753\n",
      "Epoch: 168 -> Test Accuracy: 92.0125\n",
      "[169, 60] loss: 0.011\n",
      "[169, 120] loss: 0.011\n",
      "[169, 180] loss: 0.011\n",
      "[169, 240] loss: 0.013\n",
      "[169, 300] loss: 0.012\n",
      "[169, 360] loss: 0.011\n",
      "Epoch: 169 -> Loss: 0.0146568026394\n",
      "Epoch: 169 -> Test Accuracy: 91.9875\n",
      "[170, 60] loss: 0.011\n",
      "[170, 120] loss: 0.012\n",
      "[170, 180] loss: 0.011\n",
      "[170, 240] loss: 0.012\n",
      "[170, 300] loss: 0.012\n",
      "[170, 360] loss: 0.012\n",
      "Epoch: 170 -> Loss: 0.00958927534521\n",
      "Epoch: 170 -> Test Accuracy: 92.0525\n",
      "[171, 60] loss: 0.012\n",
      "[171, 120] loss: 0.012\n",
      "[171, 180] loss: 0.012\n",
      "[171, 240] loss: 0.012\n",
      "[171, 300] loss: 0.011\n",
      "[171, 360] loss: 0.011\n",
      "Epoch: 171 -> Loss: 0.00810691621155\n",
      "Epoch: 171 -> Test Accuracy: 92.11\n",
      "[172, 60] loss: 0.012\n",
      "[172, 120] loss: 0.012\n",
      "[172, 180] loss: 0.011\n",
      "[172, 240] loss: 0.012\n",
      "[172, 300] loss: 0.011\n",
      "[172, 360] loss: 0.013\n",
      "Epoch: 172 -> Loss: 0.0119596123695\n",
      "Epoch: 172 -> Test Accuracy: 92.0325\n",
      "[173, 60] loss: 0.011\n",
      "[173, 120] loss: 0.010\n",
      "[173, 180] loss: 0.011\n",
      "[173, 240] loss: 0.011\n",
      "[173, 300] loss: 0.011\n",
      "[173, 360] loss: 0.011\n",
      "Epoch: 173 -> Loss: 0.00883429683745\n",
      "Epoch: 173 -> Test Accuracy: 92.1025\n",
      "[174, 60] loss: 0.011\n",
      "[174, 120] loss: 0.010\n",
      "[174, 180] loss: 0.011\n",
      "[174, 240] loss: 0.012\n",
      "[174, 300] loss: 0.013\n",
      "[174, 360] loss: 0.011\n",
      "Epoch: 174 -> Loss: 0.00893728341907\n",
      "Epoch: 174 -> Test Accuracy: 92.02\n",
      "[175, 60] loss: 0.011\n",
      "[175, 120] loss: 0.011\n",
      "[175, 180] loss: 0.012\n",
      "[175, 240] loss: 0.011\n",
      "[175, 300] loss: 0.011\n",
      "[175, 360] loss: 0.011\n",
      "Epoch: 175 -> Loss: 0.0108935590833\n",
      "Epoch: 175 -> Test Accuracy: 92.0675\n",
      "[176, 60] loss: 0.011\n",
      "[176, 120] loss: 0.011\n",
      "[176, 180] loss: 0.011\n",
      "[176, 240] loss: 0.011\n",
      "[176, 300] loss: 0.011\n",
      "[176, 360] loss: 0.010\n",
      "Epoch: 176 -> Loss: 0.00661456724629\n",
      "Epoch: 176 -> Test Accuracy: 92.1225\n",
      "[177, 60] loss: 0.012\n",
      "[177, 120] loss: 0.010\n",
      "[177, 180] loss: 0.011\n",
      "[177, 240] loss: 0.011\n",
      "[177, 300] loss: 0.011\n",
      "[177, 360] loss: 0.012\n",
      "Epoch: 177 -> Loss: 0.00797722581774\n",
      "Epoch: 177 -> Test Accuracy: 92.0325\n",
      "[178, 60] loss: 0.010\n",
      "[178, 120] loss: 0.010\n",
      "[178, 180] loss: 0.011\n",
      "[178, 240] loss: 0.011\n",
      "[178, 300] loss: 0.011\n",
      "[178, 360] loss: 0.011\n",
      "Epoch: 178 -> Loss: 0.0124619919807\n",
      "Epoch: 178 -> Test Accuracy: 92.0725\n",
      "[179, 60] loss: 0.011\n",
      "[179, 120] loss: 0.010\n",
      "[179, 180] loss: 0.010\n",
      "[179, 240] loss: 0.010\n",
      "[179, 300] loss: 0.011\n",
      "[179, 360] loss: 0.010\n",
      "Epoch: 179 -> Loss: 0.0119050918147\n",
      "Epoch: 179 -> Test Accuracy: 92.0725\n",
      "[180, 60] loss: 0.011\n",
      "[180, 120] loss: 0.011\n",
      "[180, 180] loss: 0.010\n",
      "[180, 240] loss: 0.010\n",
      "[180, 300] loss: 0.010\n",
      "[180, 360] loss: 0.011\n",
      "Epoch: 180 -> Loss: 0.0213738791645\n",
      "Epoch: 180 -> Test Accuracy: 92.0525\n",
      "[181, 60] loss: 0.011\n",
      "[181, 120] loss: 0.011\n",
      "[181, 180] loss: 0.011\n",
      "[181, 240] loss: 0.010\n",
      "[181, 300] loss: 0.010\n",
      "[181, 360] loss: 0.010\n",
      "Epoch: 181 -> Loss: 0.00832962524146\n",
      "Epoch: 181 -> Test Accuracy: 92.035\n",
      "[182, 60] loss: 0.010\n",
      "[182, 120] loss: 0.010\n",
      "[182, 180] loss: 0.010\n",
      "[182, 240] loss: 0.012\n",
      "[182, 300] loss: 0.011\n",
      "[182, 360] loss: 0.010\n",
      "Epoch: 182 -> Loss: 0.0132667869329\n",
      "Epoch: 182 -> Test Accuracy: 91.9975\n",
      "[183, 60] loss: 0.010\n",
      "[183, 120] loss: 0.010\n",
      "[183, 180] loss: 0.010\n",
      "[183, 240] loss: 0.010\n",
      "[183, 300] loss: 0.011\n",
      "[183, 360] loss: 0.011\n",
      "Epoch: 183 -> Loss: 0.0150039475411\n",
      "Epoch: 183 -> Test Accuracy: 91.9875\n",
      "[184, 60] loss: 0.011\n",
      "[184, 120] loss: 0.011\n",
      "[184, 180] loss: 0.011\n",
      "[184, 240] loss: 0.009\n",
      "[184, 300] loss: 0.011\n",
      "[184, 360] loss: 0.010\n",
      "Epoch: 184 -> Loss: 0.0129427434877\n",
      "Epoch: 184 -> Test Accuracy: 92.02\n",
      "[185, 60] loss: 0.010\n",
      "[185, 120] loss: 0.010\n",
      "[185, 180] loss: 0.011\n",
      "[185, 240] loss: 0.010\n",
      "[185, 300] loss: 0.009\n",
      "[185, 360] loss: 0.010\n",
      "Epoch: 185 -> Loss: 0.00897286366671\n",
      "Epoch: 185 -> Test Accuracy: 91.965\n",
      "[186, 60] loss: 0.010\n",
      "[186, 120] loss: 0.010\n",
      "[186, 180] loss: 0.010\n",
      "[186, 240] loss: 0.010\n",
      "[186, 300] loss: 0.010\n",
      "[186, 360] loss: 0.009\n",
      "Epoch: 186 -> Loss: 0.00482451776043\n",
      "Epoch: 186 -> Test Accuracy: 92.0475\n",
      "[187, 60] loss: 0.009\n",
      "[187, 120] loss: 0.009\n",
      "[187, 180] loss: 0.010\n",
      "[187, 240] loss: 0.010\n",
      "[187, 300] loss: 0.011\n",
      "[187, 360] loss: 0.010\n",
      "Epoch: 187 -> Loss: 0.00726549047977\n",
      "Epoch: 187 -> Test Accuracy: 92.0025\n",
      "[188, 60] loss: 0.010\n",
      "[188, 120] loss: 0.010\n",
      "[188, 180] loss: 0.010\n",
      "[188, 240] loss: 0.010\n",
      "[188, 300] loss: 0.010\n",
      "[188, 360] loss: 0.010\n",
      "Epoch: 188 -> Loss: 0.010285240598\n",
      "Epoch: 188 -> Test Accuracy: 92.06\n",
      "[189, 60] loss: 0.009\n",
      "[189, 120] loss: 0.010\n",
      "[189, 180] loss: 0.010\n",
      "[189, 240] loss: 0.010\n",
      "[189, 300] loss: 0.010\n",
      "[189, 360] loss: 0.010\n",
      "Epoch: 189 -> Loss: 0.00681288680062\n",
      "Epoch: 189 -> Test Accuracy: 92.0225\n",
      "[190, 60] loss: 0.010\n",
      "[190, 120] loss: 0.010\n",
      "[190, 180] loss: 0.010\n",
      "[190, 240] loss: 0.010\n",
      "[190, 300] loss: 0.010\n",
      "[190, 360] loss: 0.010\n",
      "Epoch: 190 -> Loss: 0.00541976559907\n",
      "Epoch: 190 -> Test Accuracy: 92.0225\n",
      "[191, 60] loss: 0.009\n",
      "[191, 120] loss: 0.009\n",
      "[191, 180] loss: 0.009\n",
      "[191, 240] loss: 0.009\n",
      "[191, 300] loss: 0.010\n",
      "[191, 360] loss: 0.010\n",
      "Epoch: 191 -> Loss: 0.0077538616024\n",
      "Epoch: 191 -> Test Accuracy: 92.055\n",
      "[192, 60] loss: 0.010\n",
      "[192, 120] loss: 0.010\n",
      "[192, 180] loss: 0.009\n",
      "[192, 240] loss: 0.010\n",
      "[192, 300] loss: 0.009\n",
      "[192, 360] loss: 0.010\n",
      "Epoch: 192 -> Loss: 0.00661611836404\n",
      "Epoch: 192 -> Test Accuracy: 92.0725\n",
      "[193, 60] loss: 0.009\n",
      "[193, 120] loss: 0.009\n",
      "[193, 180] loss: 0.009\n",
      "[193, 240] loss: 0.009\n",
      "[193, 300] loss: 0.009\n",
      "[193, 360] loss: 0.010\n",
      "Epoch: 193 -> Loss: 0.0056530139409\n",
      "Epoch: 193 -> Test Accuracy: 92.0575\n",
      "[194, 60] loss: 0.009\n",
      "[194, 120] loss: 0.010\n",
      "[194, 180] loss: 0.010\n",
      "[194, 240] loss: 0.009\n",
      "[194, 300] loss: 0.010\n",
      "[194, 360] loss: 0.010\n",
      "Epoch: 194 -> Loss: 0.00964882131666\n",
      "Epoch: 194 -> Test Accuracy: 92.0275\n",
      "[195, 60] loss: 0.009\n",
      "[195, 120] loss: 0.009\n",
      "[195, 180] loss: 0.010\n",
      "[195, 240] loss: 0.009\n",
      "[195, 300] loss: 0.010\n",
      "[195, 360] loss: 0.010\n",
      "Epoch: 195 -> Loss: 0.0223868545145\n",
      "Epoch: 195 -> Test Accuracy: 92.055\n",
      "[196, 60] loss: 0.009\n",
      "[196, 120] loss: 0.010\n",
      "[196, 180] loss: 0.009\n",
      "[196, 240] loss: 0.010\n",
      "[196, 300] loss: 0.010\n",
      "[196, 360] loss: 0.009\n",
      "Epoch: 196 -> Loss: 0.0182017926127\n",
      "Epoch: 196 -> Test Accuracy: 92.04\n",
      "[197, 60] loss: 0.010\n",
      "[197, 120] loss: 0.010\n",
      "[197, 180] loss: 0.010\n",
      "[197, 240] loss: 0.009\n",
      "[197, 300] loss: 0.009\n",
      "[197, 360] loss: 0.010\n",
      "Epoch: 197 -> Loss: 0.00995472725481\n",
      "Epoch: 197 -> Test Accuracy: 92.075\n",
      "[198, 60] loss: 0.009\n",
      "[198, 120] loss: 0.009\n",
      "[198, 180] loss: 0.010\n",
      "[198, 240] loss: 0.010\n",
      "[198, 300] loss: 0.010\n",
      "[198, 360] loss: 0.010\n",
      "Epoch: 198 -> Loss: 0.00981446169317\n",
      "Epoch: 198 -> Test Accuracy: 92.0425\n",
      "[199, 60] loss: 0.009\n",
      "[199, 120] loss: 0.009\n",
      "[199, 180] loss: 0.009\n",
      "[199, 240] loss: 0.009\n",
      "[199, 300] loss: 0.009\n",
      "[199, 360] loss: 0.009\n",
      "Epoch: 199 -> Loss: 0.00881644897163\n",
      "Epoch: 199 -> Test Accuracy: 92.0875\n",
      "[200, 60] loss: 0.008\n",
      "[200, 120] loss: 0.009\n",
      "[200, 180] loss: 0.010\n",
      "[200, 240] loss: 0.009\n",
      "[200, 300] loss: 0.009\n",
      "[200, 360] loss: 0.009\n",
      "Epoch: 200 -> Loss: 0.00452007586136\n",
      "Epoch: 200 -> Test Accuracy: 91.965\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "rot_block3_loss_log, rot_block3_valid_accuracy_log, rot_block3_test_accuracy_log, rot_block3_max_accuracy, \\\n",
    "rot_block3_best_epoch = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], [60, 120, 160, 200], 0.9, 5e-4, net_block3, \n",
    "                                             criterion, trainloader, None, testloader, rot=['90', '180', '270'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_net_block3 = True\n",
    "\n",
    "if load_net_block3:\n",
    "    net_block3 = fm.load_net(\"RotNet_rotation_200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 2.162\n",
      "[1, 120] loss: 1.231\n",
      "[1, 180] loss: 1.133\n",
      "[1, 240] loss: 1.057\n",
      "[1, 300] loss: 1.026\n",
      "[1, 360] loss: 0.982\n",
      "Epoch: 1 -> Loss: 0.990146994591\n",
      "Epoch: 1 -> Test Accuracy: 68.47\n",
      "[2, 60] loss: 0.915\n",
      "[2, 120] loss: 0.919\n",
      "[2, 180] loss: 0.883\n",
      "[2, 240] loss: 0.892\n",
      "[2, 300] loss: 0.867\n",
      "[2, 360] loss: 0.856\n",
      "Epoch: 2 -> Loss: 0.903752207756\n",
      "Epoch: 2 -> Test Accuracy: 72.74\n",
      "[3, 60] loss: 0.817\n",
      "[3, 120] loss: 0.817\n",
      "[3, 180] loss: 0.798\n",
      "[3, 240] loss: 0.801\n",
      "[3, 300] loss: 0.777\n",
      "[3, 360] loss: 0.791\n",
      "Epoch: 3 -> Loss: 0.756074309349\n",
      "Epoch: 3 -> Test Accuracy: 74.23\n",
      "[4, 60] loss: 0.747\n",
      "[4, 120] loss: 0.754\n",
      "[4, 180] loss: 0.741\n",
      "[4, 240] loss: 0.724\n",
      "[4, 300] loss: 0.756\n",
      "[4, 360] loss: 0.727\n",
      "Epoch: 4 -> Loss: 0.601166129112\n",
      "Epoch: 4 -> Test Accuracy: 75.25\n",
      "[5, 60] loss: 0.719\n",
      "[5, 120] loss: 0.715\n",
      "[5, 180] loss: 0.713\n",
      "[5, 240] loss: 0.711\n",
      "[5, 300] loss: 0.700\n",
      "[5, 360] loss: 0.715\n",
      "Epoch: 5 -> Loss: 0.765639603138\n",
      "Epoch: 5 -> Test Accuracy: 76.35\n",
      "[6, 60] loss: 0.679\n",
      "[6, 120] loss: 0.675\n",
      "[6, 180] loss: 0.702\n",
      "[6, 240] loss: 0.689\n",
      "[6, 300] loss: 0.703\n",
      "[6, 360] loss: 0.695\n",
      "Epoch: 6 -> Loss: 0.599988400936\n",
      "Epoch: 6 -> Test Accuracy: 75.51\n",
      "[7, 60] loss: 0.656\n",
      "[7, 120] loss: 0.663\n",
      "[7, 180] loss: 0.675\n",
      "[7, 240] loss: 0.658\n",
      "[7, 300] loss: 0.701\n",
      "[7, 360] loss: 0.670\n",
      "Epoch: 7 -> Loss: 0.54879128933\n",
      "Epoch: 7 -> Test Accuracy: 76.08\n",
      "[8, 60] loss: 0.642\n",
      "[8, 120] loss: 0.646\n",
      "[8, 180] loss: 0.666\n",
      "[8, 240] loss: 0.660\n",
      "[8, 300] loss: 0.656\n",
      "[8, 360] loss: 0.642\n",
      "Epoch: 8 -> Loss: 0.689035236835\n",
      "Epoch: 8 -> Test Accuracy: 77.22\n",
      "[9, 60] loss: 0.641\n",
      "[9, 120] loss: 0.641\n",
      "[9, 180] loss: 0.635\n",
      "[9, 240] loss: 0.629\n",
      "[9, 300] loss: 0.662\n",
      "[9, 360] loss: 0.651\n",
      "Epoch: 9 -> Loss: 0.722569465637\n",
      "Epoch: 9 -> Test Accuracy: 77.48\n",
      "[10, 60] loss: 0.624\n",
      "[10, 120] loss: 0.616\n",
      "[10, 180] loss: 0.624\n",
      "[10, 240] loss: 0.635\n",
      "[10, 300] loss: 0.646\n",
      "[10, 360] loss: 0.630\n",
      "Epoch: 10 -> Loss: 0.512164950371\n",
      "Epoch: 10 -> Test Accuracy: 77.84\n",
      "[11, 60] loss: 0.609\n",
      "[11, 120] loss: 0.621\n",
      "[11, 180] loss: 0.632\n",
      "[11, 240] loss: 0.618\n",
      "[11, 300] loss: 0.630\n",
      "[11, 360] loss: 0.643\n",
      "Epoch: 11 -> Loss: 0.713616549969\n",
      "Epoch: 11 -> Test Accuracy: 78.05\n",
      "[12, 60] loss: 0.610\n",
      "[12, 120] loss: 0.619\n",
      "[12, 180] loss: 0.636\n",
      "[12, 240] loss: 0.632\n",
      "[12, 300] loss: 0.629\n",
      "[12, 360] loss: 0.609\n",
      "Epoch: 12 -> Loss: 0.59201157093\n",
      "Epoch: 12 -> Test Accuracy: 78.3\n",
      "[13, 60] loss: 0.607\n",
      "[13, 120] loss: 0.595\n",
      "[13, 180] loss: 0.614\n",
      "[13, 240] loss: 0.621\n",
      "[13, 300] loss: 0.598\n",
      "[13, 360] loss: 0.630\n",
      "Epoch: 13 -> Loss: 0.613505959511\n",
      "Epoch: 13 -> Test Accuracy: 77.94\n",
      "[14, 60] loss: 0.595\n",
      "[14, 120] loss: 0.596\n",
      "[14, 180] loss: 0.602\n",
      "[14, 240] loss: 0.615\n",
      "[14, 300] loss: 0.621\n",
      "[14, 360] loss: 0.615\n",
      "Epoch: 14 -> Loss: 0.740029454231\n",
      "Epoch: 14 -> Test Accuracy: 78.04\n",
      "[15, 60] loss: 0.603\n",
      "[15, 120] loss: 0.606\n",
      "[15, 180] loss: 0.588\n",
      "[15, 240] loss: 0.603\n",
      "[15, 300] loss: 0.611\n",
      "[15, 360] loss: 0.618\n",
      "Epoch: 15 -> Loss: 0.588313221931\n",
      "Epoch: 15 -> Test Accuracy: 78.08\n",
      "[16, 60] loss: 0.578\n",
      "[16, 120] loss: 0.591\n",
      "[16, 180] loss: 0.589\n",
      "[16, 240] loss: 0.615\n",
      "[16, 300] loss: 0.594\n",
      "[16, 360] loss: 0.600\n",
      "Epoch: 16 -> Loss: 0.657024085522\n",
      "Epoch: 16 -> Test Accuracy: 78.94\n",
      "[17, 60] loss: 0.590\n",
      "[17, 120] loss: 0.577\n",
      "[17, 180] loss: 0.597\n",
      "[17, 240] loss: 0.594\n",
      "[17, 300] loss: 0.608\n",
      "[17, 360] loss: 0.604\n",
      "Epoch: 17 -> Loss: 0.722378492355\n",
      "Epoch: 17 -> Test Accuracy: 78.55\n",
      "[18, 60] loss: 0.579\n",
      "[18, 120] loss: 0.579\n",
      "[18, 180] loss: 0.602\n",
      "[18, 240] loss: 0.599\n",
      "[18, 300] loss: 0.601\n",
      "[18, 360] loss: 0.603\n",
      "Epoch: 18 -> Loss: 0.557040691376\n",
      "Epoch: 18 -> Test Accuracy: 78.35\n",
      "[19, 60] loss: 0.566\n",
      "[19, 120] loss: 0.578\n",
      "[19, 180] loss: 0.612\n",
      "[19, 240] loss: 0.601\n",
      "[19, 300] loss: 0.607\n",
      "[19, 360] loss: 0.603\n",
      "Epoch: 19 -> Loss: 0.616155326366\n",
      "Epoch: 19 -> Test Accuracy: 78.37\n",
      "[20, 60] loss: 0.561\n",
      "[20, 120] loss: 0.563\n",
      "[20, 180] loss: 0.583\n",
      "[20, 240] loss: 0.619\n",
      "[20, 300] loss: 0.588\n",
      "[20, 360] loss: 0.597\n",
      "Epoch: 20 -> Loss: 0.564059078693\n",
      "Epoch: 20 -> Test Accuracy: 78.77\n",
      "[21, 60] loss: 0.522\n",
      "[21, 120] loss: 0.491\n",
      "[21, 180] loss: 0.511\n",
      "[21, 240] loss: 0.479\n",
      "[21, 300] loss: 0.478\n",
      "[21, 360] loss: 0.472\n",
      "Epoch: 21 -> Loss: 0.605414748192\n",
      "Epoch: 21 -> Test Accuracy: 81.0\n",
      "[22, 60] loss: 0.460\n",
      "[22, 120] loss: 0.453\n",
      "[22, 180] loss: 0.463\n",
      "[22, 240] loss: 0.446\n",
      "[22, 300] loss: 0.447\n",
      "[22, 360] loss: 0.462\n",
      "Epoch: 22 -> Loss: 0.385712653399\n",
      "Epoch: 22 -> Test Accuracy: 81.33\n",
      "[23, 60] loss: 0.441\n",
      "[23, 120] loss: 0.433\n",
      "[23, 180] loss: 0.446\n",
      "[23, 240] loss: 0.439\n",
      "[23, 300] loss: 0.420\n",
      "[23, 360] loss: 0.439\n",
      "Epoch: 23 -> Loss: 0.479295343161\n",
      "Epoch: 23 -> Test Accuracy: 81.58\n",
      "[24, 60] loss: 0.408\n",
      "[24, 120] loss: 0.418\n",
      "[24, 180] loss: 0.434\n",
      "[24, 240] loss: 0.413\n",
      "[24, 300] loss: 0.432\n",
      "[24, 360] loss: 0.436\n",
      "Epoch: 24 -> Loss: 0.398633927107\n",
      "Epoch: 24 -> Test Accuracy: 81.78\n",
      "[25, 60] loss: 0.407\n",
      "[25, 120] loss: 0.421\n",
      "[25, 180] loss: 0.417\n",
      "[25, 240] loss: 0.436\n",
      "[25, 300] loss: 0.435\n",
      "[25, 360] loss: 0.416\n",
      "Epoch: 25 -> Loss: 0.349233448505\n",
      "Epoch: 25 -> Test Accuracy: 81.38\n",
      "[26, 60] loss: 0.399\n",
      "[26, 120] loss: 0.407\n",
      "[26, 180] loss: 0.399\n",
      "[26, 240] loss: 0.416\n",
      "[26, 300] loss: 0.402\n",
      "[26, 360] loss: 0.412\n",
      "Epoch: 26 -> Loss: 0.635837614536\n",
      "Epoch: 26 -> Test Accuracy: 81.64\n",
      "[27, 60] loss: 0.396\n",
      "[27, 120] loss: 0.399\n",
      "[27, 180] loss: 0.415\n",
      "[27, 240] loss: 0.397\n",
      "[27, 300] loss: 0.396\n",
      "[27, 360] loss: 0.405\n",
      "Epoch: 27 -> Loss: 0.247348025441\n",
      "Epoch: 27 -> Test Accuracy: 82.16\n",
      "[28, 60] loss: 0.388\n",
      "[28, 120] loss: 0.397\n",
      "[28, 180] loss: 0.389\n",
      "[28, 240] loss: 0.407\n",
      "[28, 300] loss: 0.420\n",
      "[28, 360] loss: 0.389\n",
      "Epoch: 28 -> Loss: 0.439525365829\n",
      "Epoch: 28 -> Test Accuracy: 81.96\n",
      "[29, 60] loss: 0.391\n",
      "[29, 120] loss: 0.397\n",
      "[29, 180] loss: 0.395\n",
      "[29, 240] loss: 0.394\n",
      "[29, 300] loss: 0.400\n",
      "[29, 360] loss: 0.402\n",
      "Epoch: 29 -> Loss: 0.426328361034\n",
      "Epoch: 29 -> Test Accuracy: 82.33\n",
      "[30, 60] loss: 0.383\n",
      "[30, 120] loss: 0.370\n",
      "[30, 180] loss: 0.380\n",
      "[30, 240] loss: 0.391\n",
      "[30, 300] loss: 0.413\n",
      "[30, 360] loss: 0.418\n",
      "Epoch: 30 -> Loss: 0.495209932327\n",
      "Epoch: 30 -> Test Accuracy: 81.92\n",
      "[31, 60] loss: 0.389\n",
      "[31, 120] loss: 0.391\n",
      "[31, 180] loss: 0.392\n",
      "[31, 240] loss: 0.400\n",
      "[31, 300] loss: 0.393\n",
      "[31, 360] loss: 0.395\n",
      "Epoch: 31 -> Loss: 0.42753559351\n",
      "Epoch: 31 -> Test Accuracy: 81.79\n",
      "[32, 60] loss: 0.373\n",
      "[32, 120] loss: 0.387\n",
      "[32, 180] loss: 0.395\n",
      "[32, 240] loss: 0.388\n",
      "[32, 300] loss: 0.392\n",
      "[32, 360] loss: 0.387\n",
      "Epoch: 32 -> Loss: 0.37325873971\n",
      "Epoch: 32 -> Test Accuracy: 81.84\n",
      "[33, 60] loss: 0.373\n",
      "[33, 120] loss: 0.383\n",
      "[33, 180] loss: 0.390\n",
      "[33, 240] loss: 0.392\n",
      "[33, 300] loss: 0.398\n",
      "[33, 360] loss: 0.380\n",
      "Epoch: 33 -> Loss: 0.3280595541\n",
      "Epoch: 33 -> Test Accuracy: 82.0\n",
      "[34, 60] loss: 0.373\n",
      "[34, 120] loss: 0.383\n",
      "[34, 180] loss: 0.380\n",
      "[34, 240] loss: 0.383\n",
      "[34, 300] loss: 0.402\n",
      "[34, 360] loss: 0.393\n",
      "Epoch: 34 -> Loss: 0.441644012928\n",
      "Epoch: 34 -> Test Accuracy: 81.62\n",
      "[35, 60] loss: 0.365\n",
      "[35, 120] loss: 0.388\n",
      "[35, 180] loss: 0.388\n",
      "[35, 240] loss: 0.394\n",
      "[35, 300] loss: 0.372\n",
      "[35, 360] loss: 0.382\n",
      "Epoch: 35 -> Loss: 0.30990087986\n",
      "Epoch: 35 -> Test Accuracy: 81.7\n",
      "[36, 60] loss: 0.368\n",
      "[36, 120] loss: 0.366\n",
      "[36, 180] loss: 0.389\n",
      "[36, 240] loss: 0.401\n",
      "[36, 300] loss: 0.390\n",
      "[36, 360] loss: 0.379\n",
      "Epoch: 36 -> Loss: 0.488119274378\n",
      "Epoch: 36 -> Test Accuracy: 81.53\n",
      "[37, 60] loss: 0.370\n",
      "[37, 120] loss: 0.357\n",
      "[37, 180] loss: 0.383\n",
      "[37, 240] loss: 0.382\n",
      "[37, 300] loss: 0.383\n",
      "[37, 360] loss: 0.405\n",
      "Epoch: 37 -> Loss: 0.566225290298\n",
      "Epoch: 37 -> Test Accuracy: 81.84\n",
      "[38, 60] loss: 0.372\n",
      "[38, 120] loss: 0.374\n",
      "[38, 180] loss: 0.358\n",
      "[38, 240] loss: 0.378\n",
      "[38, 300] loss: 0.391\n",
      "[38, 360] loss: 0.391\n",
      "Epoch: 38 -> Loss: 0.460942596197\n",
      "Epoch: 38 -> Test Accuracy: 81.84\n",
      "[39, 60] loss: 0.357\n",
      "[39, 120] loss: 0.367\n",
      "[39, 180] loss: 0.363\n",
      "[39, 240] loss: 0.377\n",
      "[39, 300] loss: 0.378\n",
      "[39, 360] loss: 0.391\n",
      "Epoch: 39 -> Loss: 0.293903648853\n",
      "Epoch: 39 -> Test Accuracy: 81.33\n",
      "[40, 60] loss: 0.354\n",
      "[40, 120] loss: 0.368\n",
      "[40, 180] loss: 0.382\n",
      "[40, 240] loss: 0.367\n",
      "[40, 300] loss: 0.395\n",
      "[40, 360] loss: 0.390\n",
      "Epoch: 40 -> Loss: 0.529256463051\n",
      "Epoch: 40 -> Test Accuracy: 81.7\n",
      "[41, 60] loss: 0.363\n",
      "[41, 120] loss: 0.321\n",
      "[41, 180] loss: 0.336\n",
      "[41, 240] loss: 0.334\n",
      "[41, 300] loss: 0.339\n",
      "[41, 360] loss: 0.325\n",
      "Epoch: 41 -> Loss: 0.245809912682\n",
      "Epoch: 41 -> Test Accuracy: 82.77\n",
      "[42, 60] loss: 0.315\n",
      "[42, 120] loss: 0.314\n",
      "[42, 180] loss: 0.316\n",
      "[42, 240] loss: 0.319\n",
      "[42, 300] loss: 0.321\n",
      "[42, 360] loss: 0.318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.173453181982\n",
      "Epoch: 42 -> Test Accuracy: 83.14\n",
      "[43, 60] loss: 0.312\n",
      "[43, 120] loss: 0.310\n",
      "[43, 180] loss: 0.291\n",
      "[43, 240] loss: 0.292\n",
      "[43, 300] loss: 0.300\n",
      "[43, 360] loss: 0.308\n",
      "Epoch: 43 -> Loss: 0.450003147125\n",
      "Epoch: 43 -> Test Accuracy: 82.91\n",
      "[44, 60] loss: 0.300\n",
      "[44, 120] loss: 0.281\n",
      "[44, 180] loss: 0.298\n",
      "[44, 240] loss: 0.281\n",
      "[44, 300] loss: 0.304\n",
      "[44, 360] loss: 0.294\n",
      "Epoch: 44 -> Loss: 0.404316902161\n",
      "Epoch: 44 -> Test Accuracy: 83.25\n",
      "[45, 60] loss: 0.282\n",
      "[45, 120] loss: 0.300\n",
      "[45, 180] loss: 0.287\n",
      "[45, 240] loss: 0.289\n",
      "[45, 300] loss: 0.288\n",
      "[45, 360] loss: 0.288\n",
      "Epoch: 45 -> Loss: 0.344729572535\n",
      "Epoch: 45 -> Test Accuracy: 83.13\n",
      "[46, 60] loss: 0.288\n",
      "[46, 120] loss: 0.272\n",
      "[46, 180] loss: 0.281\n",
      "[46, 240] loss: 0.283\n",
      "[46, 300] loss: 0.277\n",
      "[46, 360] loss: 0.281\n",
      "Epoch: 46 -> Loss: 0.297571182251\n",
      "Epoch: 46 -> Test Accuracy: 83.18\n",
      "[47, 60] loss: 0.289\n",
      "[47, 120] loss: 0.276\n",
      "[47, 180] loss: 0.270\n",
      "[47, 240] loss: 0.262\n",
      "[47, 300] loss: 0.272\n",
      "[47, 360] loss: 0.267\n",
      "Epoch: 47 -> Loss: 0.307625681162\n",
      "Epoch: 47 -> Test Accuracy: 83.29\n",
      "[48, 60] loss: 0.275\n",
      "[48, 120] loss: 0.273\n",
      "[48, 180] loss: 0.264\n",
      "[48, 240] loss: 0.282\n",
      "[48, 300] loss: 0.279\n",
      "[48, 360] loss: 0.278\n",
      "Epoch: 48 -> Loss: 0.268704563379\n",
      "Epoch: 48 -> Test Accuracy: 83.34\n",
      "[49, 60] loss: 0.269\n",
      "[49, 120] loss: 0.281\n",
      "[49, 180] loss: 0.285\n",
      "[49, 240] loss: 0.274\n",
      "[49, 300] loss: 0.273\n",
      "[49, 360] loss: 0.272\n",
      "Epoch: 49 -> Loss: 0.383261531591\n",
      "Epoch: 49 -> Test Accuracy: 83.4\n",
      "[50, 60] loss: 0.267\n",
      "[50, 120] loss: 0.280\n",
      "[50, 180] loss: 0.263\n",
      "[50, 240] loss: 0.264\n",
      "[50, 300] loss: 0.270\n",
      "[50, 360] loss: 0.254\n",
      "Epoch: 50 -> Loss: 0.208925366402\n",
      "Epoch: 50 -> Test Accuracy: 83.44\n",
      "[51, 60] loss: 0.277\n",
      "[51, 120] loss: 0.273\n",
      "[51, 180] loss: 0.267\n",
      "[51, 240] loss: 0.267\n",
      "[51, 300] loss: 0.260\n",
      "[51, 360] loss: 0.259\n",
      "Epoch: 51 -> Loss: 0.3048222363\n",
      "Epoch: 51 -> Test Accuracy: 83.37\n",
      "[52, 60] loss: 0.278\n",
      "[52, 120] loss: 0.257\n",
      "[52, 180] loss: 0.251\n",
      "[52, 240] loss: 0.261\n",
      "[52, 300] loss: 0.271\n",
      "[52, 360] loss: 0.268\n",
      "Epoch: 52 -> Loss: 0.305587232113\n",
      "Epoch: 52 -> Test Accuracy: 83.33\n",
      "[53, 60] loss: 0.260\n",
      "[53, 120] loss: 0.254\n",
      "[53, 180] loss: 0.262\n",
      "[53, 240] loss: 0.259\n",
      "[53, 300] loss: 0.264\n",
      "[53, 360] loss: 0.264\n",
      "Epoch: 53 -> Loss: 0.379165053368\n",
      "Epoch: 53 -> Test Accuracy: 83.41\n",
      "[54, 60] loss: 0.259\n",
      "[54, 120] loss: 0.260\n",
      "[54, 180] loss: 0.262\n",
      "[54, 240] loss: 0.251\n",
      "[54, 300] loss: 0.254\n",
      "[54, 360] loss: 0.260\n",
      "Epoch: 54 -> Loss: 0.30886015296\n",
      "Epoch: 54 -> Test Accuracy: 83.4\n",
      "[55, 60] loss: 0.274\n",
      "[55, 120] loss: 0.257\n",
      "[55, 180] loss: 0.245\n",
      "[55, 240] loss: 0.259\n",
      "[55, 300] loss: 0.268\n",
      "[55, 360] loss: 0.264\n",
      "Epoch: 55 -> Loss: 0.285019725561\n",
      "Epoch: 55 -> Test Accuracy: 83.33\n",
      "[56, 60] loss: 0.259\n",
      "[56, 120] loss: 0.261\n",
      "[56, 180] loss: 0.258\n",
      "[56, 240] loss: 0.255\n",
      "[56, 300] loss: 0.252\n",
      "[56, 360] loss: 0.245\n",
      "Epoch: 56 -> Loss: 0.273119837046\n",
      "Epoch: 56 -> Test Accuracy: 83.42\n",
      "[57, 60] loss: 0.258\n",
      "[57, 120] loss: 0.262\n",
      "[57, 180] loss: 0.255\n",
      "[57, 240] loss: 0.262\n",
      "[57, 300] loss: 0.251\n",
      "[57, 360] loss: 0.263\n",
      "Epoch: 57 -> Loss: 0.233887270093\n",
      "Epoch: 57 -> Test Accuracy: 83.37\n",
      "[58, 60] loss: 0.263\n",
      "[58, 120] loss: 0.249\n",
      "[58, 180] loss: 0.240\n",
      "[58, 240] loss: 0.264\n",
      "[58, 300] loss: 0.262\n",
      "[58, 360] loss: 0.261\n",
      "Epoch: 58 -> Loss: 0.224438384175\n",
      "Epoch: 58 -> Test Accuracy: 83.26\n",
      "[59, 60] loss: 0.250\n",
      "[59, 120] loss: 0.240\n",
      "[59, 180] loss: 0.258\n",
      "[59, 240] loss: 0.269\n",
      "[59, 300] loss: 0.261\n",
      "[59, 360] loss: 0.259\n",
      "Epoch: 59 -> Loss: 0.273801386356\n",
      "Epoch: 59 -> Test Accuracy: 83.31\n",
      "[60, 60] loss: 0.262\n",
      "[60, 120] loss: 0.249\n",
      "[60, 180] loss: 0.258\n",
      "[60, 240] loss: 0.252\n",
      "[60, 300] loss: 0.256\n",
      "[60, 360] loss: 0.248\n",
      "Epoch: 60 -> Loss: 0.377781927586\n",
      "Epoch: 60 -> Test Accuracy: 83.4\n",
      "[61, 60] loss: 0.250\n",
      "[61, 120] loss: 0.246\n",
      "[61, 180] loss: 0.268\n",
      "[61, 240] loss: 0.259\n",
      "[61, 300] loss: 0.241\n",
      "[61, 360] loss: 0.258\n",
      "Epoch: 61 -> Loss: 0.183611422777\n",
      "Epoch: 61 -> Test Accuracy: 83.41\n",
      "[62, 60] loss: 0.253\n",
      "[62, 120] loss: 0.250\n",
      "[62, 180] loss: 0.255\n",
      "[62, 240] loss: 0.251\n",
      "[62, 300] loss: 0.247\n",
      "[62, 360] loss: 0.252\n",
      "Epoch: 62 -> Loss: 0.238436222076\n",
      "Epoch: 62 -> Test Accuracy: 83.41\n",
      "[63, 60] loss: 0.242\n",
      "[63, 120] loss: 0.255\n",
      "[63, 180] loss: 0.250\n",
      "[63, 240] loss: 0.248\n",
      "[63, 300] loss: 0.256\n",
      "[63, 360] loss: 0.247\n",
      "Epoch: 63 -> Loss: 0.214379429817\n",
      "Epoch: 63 -> Test Accuracy: 83.43\n",
      "[64, 60] loss: 0.241\n",
      "[64, 120] loss: 0.245\n",
      "[64, 180] loss: 0.248\n",
      "[64, 240] loss: 0.257\n",
      "[64, 300] loss: 0.246\n",
      "[64, 360] loss: 0.240\n",
      "Epoch: 64 -> Loss: 0.167256265879\n",
      "Epoch: 64 -> Test Accuracy: 83.38\n",
      "[65, 60] loss: 0.249\n",
      "[65, 120] loss: 0.249\n",
      "[65, 180] loss: 0.253\n",
      "[65, 240] loss: 0.241\n",
      "[65, 300] loss: 0.248\n",
      "[65, 360] loss: 0.249\n",
      "Epoch: 65 -> Loss: 0.197989732027\n",
      "Epoch: 65 -> Test Accuracy: 83.53\n",
      "[66, 60] loss: 0.241\n",
      "[66, 120] loss: 0.243\n",
      "[66, 180] loss: 0.254\n",
      "[66, 240] loss: 0.229\n",
      "[66, 300] loss: 0.243\n",
      "[66, 360] loss: 0.259\n",
      "Epoch: 66 -> Loss: 0.270983248949\n",
      "Epoch: 66 -> Test Accuracy: 83.39\n",
      "[67, 60] loss: 0.255\n",
      "[67, 120] loss: 0.245\n",
      "[67, 180] loss: 0.242\n",
      "[67, 240] loss: 0.234\n",
      "[67, 300] loss: 0.245\n",
      "[67, 360] loss: 0.247\n",
      "Epoch: 67 -> Loss: 0.275005787611\n",
      "Epoch: 67 -> Test Accuracy: 83.32\n",
      "[68, 60] loss: 0.240\n",
      "[68, 120] loss: 0.251\n",
      "[68, 180] loss: 0.250\n",
      "[68, 240] loss: 0.236\n",
      "[68, 300] loss: 0.242\n",
      "[68, 360] loss: 0.240\n",
      "Epoch: 68 -> Loss: 0.258368730545\n",
      "Epoch: 68 -> Test Accuracy: 83.49\n",
      "[69, 60] loss: 0.245\n",
      "[69, 120] loss: 0.240\n",
      "[69, 180] loss: 0.234\n",
      "[69, 240] loss: 0.247\n",
      "[69, 300] loss: 0.258\n",
      "[69, 360] loss: 0.245\n",
      "Epoch: 69 -> Loss: 0.427489459515\n",
      "Epoch: 69 -> Test Accuracy: 83.38\n",
      "[70, 60] loss: 0.247\n",
      "[70, 120] loss: 0.248\n",
      "[70, 180] loss: 0.247\n",
      "[70, 240] loss: 0.238\n",
      "[70, 300] loss: 0.252\n",
      "[70, 360] loss: 0.240\n",
      "Epoch: 70 -> Loss: 0.166559383273\n",
      "Epoch: 70 -> Test Accuracy: 83.28\n",
      "[71, 60] loss: 0.250\n",
      "[71, 120] loss: 0.244\n",
      "[71, 180] loss: 0.247\n",
      "[71, 240] loss: 0.244\n",
      "[71, 300] loss: 0.235\n",
      "[71, 360] loss: 0.236\n",
      "Epoch: 71 -> Loss: 0.452302157879\n",
      "Epoch: 71 -> Test Accuracy: 83.32\n",
      "[72, 60] loss: 0.229\n",
      "[72, 120] loss: 0.240\n",
      "[72, 180] loss: 0.236\n",
      "[72, 240] loss: 0.246\n",
      "[72, 300] loss: 0.242\n",
      "[72, 360] loss: 0.233\n",
      "Epoch: 72 -> Loss: 0.305540710688\n",
      "Epoch: 72 -> Test Accuracy: 83.2\n",
      "[73, 60] loss: 0.239\n",
      "[73, 120] loss: 0.243\n",
      "[73, 180] loss: 0.243\n",
      "[73, 240] loss: 0.239\n",
      "[73, 300] loss: 0.247\n",
      "[73, 360] loss: 0.230\n",
      "Epoch: 73 -> Loss: 0.335854500532\n",
      "Epoch: 73 -> Test Accuracy: 83.4\n",
      "[74, 60] loss: 0.230\n",
      "[74, 120] loss: 0.236\n",
      "[74, 180] loss: 0.240\n",
      "[74, 240] loss: 0.247\n",
      "[74, 300] loss: 0.240\n",
      "[74, 360] loss: 0.236\n",
      "Epoch: 74 -> Loss: 0.158597797155\n",
      "Epoch: 74 -> Test Accuracy: 83.31\n",
      "[75, 60] loss: 0.235\n",
      "[75, 120] loss: 0.242\n",
      "[75, 180] loss: 0.240\n",
      "[75, 240] loss: 0.241\n",
      "[75, 300] loss: 0.241\n",
      "[75, 360] loss: 0.237\n",
      "Epoch: 75 -> Loss: 0.318218797445\n",
      "Epoch: 75 -> Test Accuracy: 83.38\n",
      "[76, 60] loss: 0.239\n",
      "[76, 120] loss: 0.248\n",
      "[76, 180] loss: 0.237\n",
      "[76, 240] loss: 0.234\n",
      "[76, 300] loss: 0.244\n",
      "[76, 360] loss: 0.224\n",
      "Epoch: 76 -> Loss: 0.286716163158\n",
      "Epoch: 76 -> Test Accuracy: 83.43\n",
      "[77, 60] loss: 0.236\n",
      "[77, 120] loss: 0.245\n",
      "[77, 180] loss: 0.241\n",
      "[77, 240] loss: 0.230\n",
      "[77, 300] loss: 0.234\n",
      "[77, 360] loss: 0.227\n",
      "Epoch: 77 -> Loss: 0.290097177029\n",
      "Epoch: 77 -> Test Accuracy: 83.26\n",
      "[78, 60] loss: 0.241\n",
      "[78, 120] loss: 0.235\n",
      "[78, 180] loss: 0.246\n",
      "[78, 240] loss: 0.235\n",
      "[78, 300] loss: 0.238\n",
      "[78, 360] loss: 0.224\n",
      "Epoch: 78 -> Loss: 0.234265044332\n",
      "Epoch: 78 -> Test Accuracy: 83.32\n",
      "[79, 60] loss: 0.251\n",
      "[79, 120] loss: 0.231\n",
      "[79, 180] loss: 0.238\n",
      "[79, 240] loss: 0.225\n",
      "[79, 300] loss: 0.234\n",
      "[79, 360] loss: 0.228\n",
      "Epoch: 79 -> Loss: 0.210692614317\n",
      "Epoch: 79 -> Test Accuracy: 83.44\n",
      "[80, 60] loss: 0.231\n",
      "[80, 120] loss: 0.239\n",
      "[80, 180] loss: 0.247\n",
      "[80, 240] loss: 0.228\n",
      "[80, 300] loss: 0.233\n",
      "[80, 360] loss: 0.227\n",
      "Epoch: 80 -> Loss: 0.248990729451\n",
      "Epoch: 80 -> Test Accuracy: 83.3\n",
      "[81, 60] loss: 0.231\n",
      "[81, 120] loss: 0.231\n",
      "[81, 180] loss: 0.228\n",
      "[81, 240] loss: 0.238\n",
      "[81, 300] loss: 0.237\n",
      "[81, 360] loss: 0.238\n",
      "Epoch: 81 -> Loss: 0.227644920349\n",
      "Epoch: 81 -> Test Accuracy: 83.39\n",
      "[82, 60] loss: 0.222\n",
      "[82, 120] loss: 0.231\n",
      "[82, 180] loss: 0.222\n",
      "[82, 240] loss: 0.237\n",
      "[82, 300] loss: 0.233\n",
      "[82, 360] loss: 0.233\n",
      "Epoch: 82 -> Loss: 0.220370575786\n",
      "Epoch: 82 -> Test Accuracy: 83.38\n",
      "[83, 60] loss: 0.233\n",
      "[83, 120] loss: 0.231\n",
      "[83, 180] loss: 0.228\n",
      "[83, 240] loss: 0.230\n",
      "[83, 300] loss: 0.232\n",
      "[83, 360] loss: 0.233\n",
      "Epoch: 83 -> Loss: 0.100116893649\n",
      "Epoch: 83 -> Test Accuracy: 83.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.217\n",
      "[84, 120] loss: 0.230\n",
      "[84, 180] loss: 0.224\n",
      "[84, 240] loss: 0.220\n",
      "[84, 300] loss: 0.240\n",
      "[84, 360] loss: 0.232\n",
      "Epoch: 84 -> Loss: 0.252890765667\n",
      "Epoch: 84 -> Test Accuracy: 83.23\n",
      "[85, 60] loss: 0.224\n",
      "[85, 120] loss: 0.232\n",
      "[85, 180] loss: 0.230\n",
      "[85, 240] loss: 0.233\n",
      "[85, 300] loss: 0.220\n",
      "[85, 360] loss: 0.227\n",
      "Epoch: 85 -> Loss: 0.411238521338\n",
      "Epoch: 85 -> Test Accuracy: 83.36\n",
      "[86, 60] loss: 0.233\n",
      "[86, 120] loss: 0.223\n",
      "[86, 180] loss: 0.228\n",
      "[86, 240] loss: 0.225\n",
      "[86, 300] loss: 0.209\n",
      "[86, 360] loss: 0.220\n",
      "Epoch: 86 -> Loss: 0.225403144956\n",
      "Epoch: 86 -> Test Accuracy: 83.32\n",
      "[87, 60] loss: 0.222\n",
      "[87, 120] loss: 0.220\n",
      "[87, 180] loss: 0.226\n",
      "[87, 240] loss: 0.231\n",
      "[87, 300] loss: 0.228\n",
      "[87, 360] loss: 0.211\n",
      "Epoch: 87 -> Loss: 0.223494291306\n",
      "Epoch: 87 -> Test Accuracy: 83.32\n",
      "[88, 60] loss: 0.233\n",
      "[88, 120] loss: 0.223\n",
      "[88, 180] loss: 0.234\n",
      "[88, 240] loss: 0.223\n",
      "[88, 300] loss: 0.223\n",
      "[88, 360] loss: 0.225\n",
      "Epoch: 88 -> Loss: 0.289132535458\n",
      "Epoch: 88 -> Test Accuracy: 83.28\n",
      "[89, 60] loss: 0.226\n",
      "[89, 120] loss: 0.227\n",
      "[89, 180] loss: 0.219\n",
      "[89, 240] loss: 0.231\n",
      "[89, 300] loss: 0.235\n",
      "[89, 360] loss: 0.220\n",
      "Epoch: 89 -> Loss: 0.183604389429\n",
      "Epoch: 89 -> Test Accuracy: 83.27\n",
      "[90, 60] loss: 0.242\n",
      "[90, 120] loss: 0.226\n",
      "[90, 180] loss: 0.221\n",
      "[90, 240] loss: 0.230\n",
      "[90, 300] loss: 0.215\n",
      "[90, 360] loss: 0.226\n",
      "Epoch: 90 -> Loss: 0.297460615635\n",
      "Epoch: 90 -> Test Accuracy: 83.28\n",
      "[91, 60] loss: 0.214\n",
      "[91, 120] loss: 0.221\n",
      "[91, 180] loss: 0.222\n",
      "[91, 240] loss: 0.230\n",
      "[91, 300] loss: 0.223\n",
      "[91, 360] loss: 0.224\n",
      "Epoch: 91 -> Loss: 0.184289395809\n",
      "Epoch: 91 -> Test Accuracy: 83.21\n",
      "[92, 60] loss: 0.219\n",
      "[92, 120] loss: 0.218\n",
      "[92, 180] loss: 0.228\n",
      "[92, 240] loss: 0.226\n",
      "[92, 300] loss: 0.226\n",
      "[92, 360] loss: 0.230\n",
      "Epoch: 92 -> Loss: 0.134510785341\n",
      "Epoch: 92 -> Test Accuracy: 83.06\n",
      "[93, 60] loss: 0.218\n",
      "[93, 120] loss: 0.215\n",
      "[93, 180] loss: 0.238\n",
      "[93, 240] loss: 0.227\n",
      "[93, 300] loss: 0.214\n",
      "[93, 360] loss: 0.227\n",
      "Epoch: 93 -> Loss: 0.350413262844\n",
      "Epoch: 93 -> Test Accuracy: 83.16\n",
      "[94, 60] loss: 0.222\n",
      "[94, 120] loss: 0.217\n",
      "[94, 180] loss: 0.216\n",
      "[94, 240] loss: 0.220\n",
      "[94, 300] loss: 0.227\n",
      "[94, 360] loss: 0.210\n",
      "Epoch: 94 -> Loss: 0.186244145036\n",
      "Epoch: 94 -> Test Accuracy: 83.24\n",
      "[95, 60] loss: 0.224\n",
      "[95, 120] loss: 0.217\n",
      "[95, 180] loss: 0.213\n",
      "[95, 240] loss: 0.222\n",
      "[95, 300] loss: 0.214\n",
      "[95, 360] loss: 0.224\n",
      "Epoch: 95 -> Loss: 0.143851593137\n",
      "Epoch: 95 -> Test Accuracy: 83.26\n",
      "[96, 60] loss: 0.212\n",
      "[96, 120] loss: 0.201\n",
      "[96, 180] loss: 0.234\n",
      "[96, 240] loss: 0.221\n",
      "[96, 300] loss: 0.219\n",
      "[96, 360] loss: 0.229\n",
      "Epoch: 96 -> Loss: 0.417388141155\n",
      "Epoch: 96 -> Test Accuracy: 83.29\n",
      "[97, 60] loss: 0.224\n",
      "[97, 120] loss: 0.217\n",
      "[97, 180] loss: 0.223\n",
      "[97, 240] loss: 0.209\n",
      "[97, 300] loss: 0.219\n",
      "[97, 360] loss: 0.218\n",
      "Epoch: 97 -> Loss: 0.229695647955\n",
      "Epoch: 97 -> Test Accuracy: 83.21\n",
      "[98, 60] loss: 0.227\n",
      "[98, 120] loss: 0.221\n",
      "[98, 180] loss: 0.210\n",
      "[98, 240] loss: 0.212\n",
      "[98, 300] loss: 0.214\n",
      "[98, 360] loss: 0.222\n",
      "Epoch: 98 -> Loss: 0.245625212789\n",
      "Epoch: 98 -> Test Accuracy: 83.2\n",
      "[99, 60] loss: 0.215\n",
      "[99, 120] loss: 0.210\n",
      "[99, 180] loss: 0.217\n",
      "[99, 240] loss: 0.230\n",
      "[99, 300] loss: 0.223\n",
      "[99, 360] loss: 0.218\n",
      "Epoch: 99 -> Loss: 0.218556687236\n",
      "Epoch: 99 -> Test Accuracy: 83.38\n",
      "[100, 60] loss: 0.212\n",
      "[100, 120] loss: 0.203\n",
      "[100, 180] loss: 0.209\n",
      "[100, 240] loss: 0.207\n",
      "[100, 300] loss: 0.220\n",
      "[100, 360] loss: 0.220\n",
      "Epoch: 100 -> Loss: 0.225704461336\n",
      "Epoch: 100 -> Test Accuracy: 83.22\n",
      "Finished Training\n",
      "[1, 60] loss: 1.666\n",
      "[1, 120] loss: 0.812\n",
      "[1, 180] loss: 0.760\n",
      "[1, 240] loss: 0.708\n",
      "[1, 300] loss: 0.678\n",
      "[1, 360] loss: 0.640\n",
      "Epoch: 1 -> Loss: 0.528734326363\n",
      "Epoch: 1 -> Test Accuracy: 78.85\n",
      "[2, 60] loss: 0.557\n",
      "[2, 120] loss: 0.612\n",
      "[2, 180] loss: 0.585\n",
      "[2, 240] loss: 0.576\n",
      "[2, 300] loss: 0.569\n",
      "[2, 360] loss: 0.545\n",
      "Epoch: 2 -> Loss: 0.748282909393\n",
      "Epoch: 2 -> Test Accuracy: 80.63\n",
      "[3, 60] loss: 0.518\n",
      "[3, 120] loss: 0.519\n",
      "[3, 180] loss: 0.505\n",
      "[3, 240] loss: 0.524\n",
      "[3, 300] loss: 0.526\n",
      "[3, 360] loss: 0.516\n",
      "Epoch: 3 -> Loss: 0.471897512674\n",
      "Epoch: 3 -> Test Accuracy: 81.69\n",
      "[4, 60] loss: 0.487\n",
      "[4, 120] loss: 0.487\n",
      "[4, 180] loss: 0.493\n",
      "[4, 240] loss: 0.463\n",
      "[4, 300] loss: 0.497\n",
      "[4, 360] loss: 0.470\n",
      "Epoch: 4 -> Loss: 0.407703459263\n",
      "Epoch: 4 -> Test Accuracy: 82.45\n",
      "[5, 60] loss: 0.454\n",
      "[5, 120] loss: 0.467\n",
      "[5, 180] loss: 0.466\n",
      "[5, 240] loss: 0.438\n",
      "[5, 300] loss: 0.464\n",
      "[5, 360] loss: 0.472\n",
      "Epoch: 5 -> Loss: 0.376129329205\n",
      "Epoch: 5 -> Test Accuracy: 82.05\n",
      "[6, 60] loss: 0.435\n",
      "[6, 120] loss: 0.441\n",
      "[6, 180] loss: 0.431\n",
      "[6, 240] loss: 0.445\n",
      "[6, 300] loss: 0.447\n",
      "[6, 360] loss: 0.448\n",
      "Epoch: 6 -> Loss: 0.412799924612\n",
      "Epoch: 6 -> Test Accuracy: 82.91\n",
      "[7, 60] loss: 0.405\n",
      "[7, 120] loss: 0.425\n",
      "[7, 180] loss: 0.428\n",
      "[7, 240] loss: 0.421\n",
      "[7, 300] loss: 0.425\n",
      "[7, 360] loss: 0.442\n",
      "Epoch: 7 -> Loss: 0.435140609741\n",
      "Epoch: 7 -> Test Accuracy: 83.02\n",
      "[8, 60] loss: 0.396\n",
      "[8, 120] loss: 0.427\n",
      "[8, 180] loss: 0.413\n",
      "[8, 240] loss: 0.409\n",
      "[8, 300] loss: 0.421\n",
      "[8, 360] loss: 0.441\n",
      "Epoch: 8 -> Loss: 0.49392747879\n",
      "Epoch: 8 -> Test Accuracy: 82.99\n",
      "[9, 60] loss: 0.389\n",
      "[9, 120] loss: 0.395\n",
      "[9, 180] loss: 0.414\n",
      "[9, 240] loss: 0.430\n",
      "[9, 300] loss: 0.403\n",
      "[9, 360] loss: 0.415\n",
      "Epoch: 9 -> Loss: 0.324830144644\n",
      "Epoch: 9 -> Test Accuracy: 83.33\n",
      "[10, 60] loss: 0.391\n",
      "[10, 120] loss: 0.398\n",
      "[10, 180] loss: 0.396\n",
      "[10, 240] loss: 0.407\n",
      "[10, 300] loss: 0.410\n",
      "[10, 360] loss: 0.410\n",
      "Epoch: 10 -> Loss: 0.459988892078\n",
      "Epoch: 10 -> Test Accuracy: 83.49\n",
      "[11, 60] loss: 0.379\n",
      "[11, 120] loss: 0.389\n",
      "[11, 180] loss: 0.406\n",
      "[11, 240] loss: 0.400\n",
      "[11, 300] loss: 0.399\n",
      "[11, 360] loss: 0.401\n",
      "Epoch: 11 -> Loss: 0.477080047131\n",
      "Epoch: 11 -> Test Accuracy: 84.12\n",
      "[12, 60] loss: 0.383\n",
      "[12, 120] loss: 0.381\n",
      "[12, 180] loss: 0.375\n",
      "[12, 240] loss: 0.392\n",
      "[12, 300] loss: 0.406\n",
      "[12, 360] loss: 0.394\n",
      "Epoch: 12 -> Loss: 0.370262026787\n",
      "Epoch: 12 -> Test Accuracy: 83.97\n",
      "[13, 60] loss: 0.363\n",
      "[13, 120] loss: 0.378\n",
      "[13, 180] loss: 0.382\n",
      "[13, 240] loss: 0.390\n",
      "[13, 300] loss: 0.414\n",
      "[13, 360] loss: 0.404\n",
      "Epoch: 13 -> Loss: 0.539183974266\n",
      "Epoch: 13 -> Test Accuracy: 83.58\n",
      "[14, 60] loss: 0.351\n",
      "[14, 120] loss: 0.378\n",
      "[14, 180] loss: 0.384\n",
      "[14, 240] loss: 0.393\n",
      "[14, 300] loss: 0.392\n",
      "[14, 360] loss: 0.395\n",
      "Epoch: 14 -> Loss: 0.392552495003\n",
      "Epoch: 14 -> Test Accuracy: 84.32\n",
      "[15, 60] loss: 0.371\n",
      "[15, 120] loss: 0.370\n",
      "[15, 180] loss: 0.381\n",
      "[15, 240] loss: 0.373\n",
      "[15, 300] loss: 0.374\n",
      "[15, 360] loss: 0.391\n",
      "Epoch: 15 -> Loss: 0.276484012604\n",
      "Epoch: 15 -> Test Accuracy: 83.06\n",
      "[16, 60] loss: 0.367\n",
      "[16, 120] loss: 0.359\n",
      "[16, 180] loss: 0.363\n",
      "[16, 240] loss: 0.384\n",
      "[16, 300] loss: 0.387\n",
      "[16, 360] loss: 0.377\n",
      "Epoch: 16 -> Loss: 0.377467572689\n",
      "Epoch: 16 -> Test Accuracy: 83.77\n",
      "[17, 60] loss: 0.352\n",
      "[17, 120] loss: 0.374\n",
      "[17, 180] loss: 0.385\n",
      "[17, 240] loss: 0.378\n",
      "[17, 300] loss: 0.384\n",
      "[17, 360] loss: 0.378\n",
      "Epoch: 17 -> Loss: 0.353844493628\n",
      "Epoch: 17 -> Test Accuracy: 83.37\n",
      "[18, 60] loss: 0.367\n",
      "[18, 120] loss: 0.365\n",
      "[18, 180] loss: 0.380\n",
      "[18, 240] loss: 0.374\n",
      "[18, 300] loss: 0.390\n",
      "[18, 360] loss: 0.384\n",
      "Epoch: 18 -> Loss: 0.506995856762\n",
      "Epoch: 18 -> Test Accuracy: 83.85\n",
      "[19, 60] loss: 0.361\n",
      "[19, 120] loss: 0.363\n",
      "[19, 180] loss: 0.381\n",
      "[19, 240] loss: 0.373\n",
      "[19, 300] loss: 0.383\n",
      "[19, 360] loss: 0.385\n",
      "Epoch: 19 -> Loss: 0.240659594536\n",
      "Epoch: 19 -> Test Accuracy: 83.89\n",
      "[20, 60] loss: 0.325\n",
      "[20, 120] loss: 0.368\n",
      "[20, 180] loss: 0.368\n",
      "[20, 240] loss: 0.391\n",
      "[20, 300] loss: 0.386\n",
      "[20, 360] loss: 0.368\n",
      "Epoch: 20 -> Loss: 0.429391950369\n",
      "Epoch: 20 -> Test Accuracy: 83.28\n",
      "[21, 60] loss: 0.315\n",
      "[21, 120] loss: 0.310\n",
      "[21, 180] loss: 0.290\n",
      "[21, 240] loss: 0.303\n",
      "[21, 300] loss: 0.289\n",
      "[21, 360] loss: 0.278\n",
      "Epoch: 21 -> Loss: 0.269509881735\n",
      "Epoch: 21 -> Test Accuracy: 85.41\n",
      "[22, 60] loss: 0.266\n",
      "[22, 120] loss: 0.270\n",
      "[22, 180] loss: 0.254\n",
      "[22, 240] loss: 0.271\n",
      "[22, 300] loss: 0.258\n",
      "[22, 360] loss: 0.262\n",
      "Epoch: 22 -> Loss: 0.218567803502\n",
      "Epoch: 22 -> Test Accuracy: 85.31\n",
      "[23, 60] loss: 0.242\n",
      "[23, 120] loss: 0.251\n",
      "[23, 180] loss: 0.246\n",
      "[23, 240] loss: 0.250\n",
      "[23, 300] loss: 0.260\n",
      "[23, 360] loss: 0.245\n",
      "Epoch: 23 -> Loss: 0.261430084705\n",
      "Epoch: 23 -> Test Accuracy: 85.73\n",
      "[24, 60] loss: 0.240\n",
      "[24, 120] loss: 0.245\n",
      "[24, 180] loss: 0.245\n",
      "[24, 240] loss: 0.224\n",
      "[24, 300] loss: 0.226\n",
      "[24, 360] loss: 0.235\n",
      "Epoch: 24 -> Loss: 0.329823851585\n",
      "Epoch: 24 -> Test Accuracy: 85.79\n",
      "[25, 60] loss: 0.216\n",
      "[25, 120] loss: 0.225\n",
      "[25, 180] loss: 0.225\n",
      "[25, 240] loss: 0.232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 300] loss: 0.223\n",
      "[25, 360] loss: 0.224\n",
      "Epoch: 25 -> Loss: 0.322388321161\n",
      "Epoch: 25 -> Test Accuracy: 85.65\n",
      "[26, 60] loss: 0.214\n",
      "[26, 120] loss: 0.225\n",
      "[26, 180] loss: 0.212\n",
      "[26, 240] loss: 0.231\n",
      "[26, 300] loss: 0.225\n",
      "[26, 360] loss: 0.222\n",
      "Epoch: 26 -> Loss: 0.386886686087\n",
      "Epoch: 26 -> Test Accuracy: 85.59\n",
      "[27, 60] loss: 0.208\n",
      "[27, 120] loss: 0.220\n",
      "[27, 180] loss: 0.208\n",
      "[27, 240] loss: 0.209\n",
      "[27, 300] loss: 0.217\n",
      "[27, 360] loss: 0.210\n",
      "Epoch: 27 -> Loss: 0.34619101882\n",
      "Epoch: 27 -> Test Accuracy: 85.71\n",
      "[28, 60] loss: 0.198\n",
      "[28, 120] loss: 0.215\n",
      "[28, 180] loss: 0.216\n",
      "[28, 240] loss: 0.208\n",
      "[28, 300] loss: 0.214\n",
      "[28, 360] loss: 0.204\n",
      "Epoch: 28 -> Loss: 0.256702274084\n",
      "Epoch: 28 -> Test Accuracy: 85.66\n",
      "[29, 60] loss: 0.194\n",
      "[29, 120] loss: 0.201\n",
      "[29, 180] loss: 0.199\n",
      "[29, 240] loss: 0.207\n",
      "[29, 300] loss: 0.215\n",
      "[29, 360] loss: 0.215\n",
      "Epoch: 29 -> Loss: 0.249454781413\n",
      "Epoch: 29 -> Test Accuracy: 85.64\n",
      "[30, 60] loss: 0.189\n",
      "[30, 120] loss: 0.199\n",
      "[30, 180] loss: 0.202\n",
      "[30, 240] loss: 0.216\n",
      "[30, 300] loss: 0.212\n",
      "[30, 360] loss: 0.198\n",
      "Epoch: 30 -> Loss: 0.105788983405\n",
      "Epoch: 30 -> Test Accuracy: 85.44\n",
      "[31, 60] loss: 0.190\n",
      "[31, 120] loss: 0.196\n",
      "[31, 180] loss: 0.204\n",
      "[31, 240] loss: 0.196\n",
      "[31, 300] loss: 0.194\n",
      "[31, 360] loss: 0.208\n",
      "Epoch: 31 -> Loss: 0.0999970063567\n",
      "Epoch: 31 -> Test Accuracy: 85.75\n",
      "[32, 60] loss: 0.198\n",
      "[32, 120] loss: 0.196\n",
      "[32, 180] loss: 0.196\n",
      "[32, 240] loss: 0.211\n",
      "[32, 300] loss: 0.200\n",
      "[32, 360] loss: 0.199\n",
      "Epoch: 32 -> Loss: 0.154513895512\n",
      "Epoch: 32 -> Test Accuracy: 85.61\n",
      "[33, 60] loss: 0.181\n",
      "[33, 120] loss: 0.213\n",
      "[33, 180] loss: 0.209\n",
      "[33, 240] loss: 0.189\n",
      "[33, 300] loss: 0.202\n",
      "[33, 360] loss: 0.209\n",
      "Epoch: 33 -> Loss: 0.258195340633\n",
      "Epoch: 33 -> Test Accuracy: 85.25\n",
      "[34, 60] loss: 0.191\n",
      "[34, 120] loss: 0.191\n",
      "[34, 180] loss: 0.204\n",
      "[34, 240] loss: 0.203\n",
      "[34, 300] loss: 0.209\n",
      "[34, 360] loss: 0.199\n",
      "Epoch: 34 -> Loss: 0.375159293413\n",
      "Epoch: 34 -> Test Accuracy: 85.46\n",
      "[35, 60] loss: 0.190\n",
      "[35, 120] loss: 0.180\n",
      "[35, 180] loss: 0.197\n",
      "[35, 240] loss: 0.198\n",
      "[35, 300] loss: 0.208\n",
      "[35, 360] loss: 0.209\n",
      "Epoch: 35 -> Loss: 0.306605398655\n",
      "Epoch: 35 -> Test Accuracy: 85.26\n",
      "[36, 60] loss: 0.193\n",
      "[36, 120] loss: 0.196\n",
      "[36, 180] loss: 0.208\n",
      "[36, 240] loss: 0.186\n",
      "[36, 300] loss: 0.204\n",
      "[36, 360] loss: 0.204\n",
      "Epoch: 36 -> Loss: 0.290996193886\n",
      "Epoch: 36 -> Test Accuracy: 85.63\n",
      "[37, 60] loss: 0.183\n",
      "[37, 120] loss: 0.185\n",
      "[37, 180] loss: 0.190\n",
      "[37, 240] loss: 0.202\n",
      "[37, 300] loss: 0.204\n",
      "[37, 360] loss: 0.200\n",
      "Epoch: 37 -> Loss: 0.293617725372\n",
      "Epoch: 37 -> Test Accuracy: 85.53\n",
      "[38, 60] loss: 0.185\n",
      "[38, 120] loss: 0.189\n",
      "[38, 180] loss: 0.201\n",
      "[38, 240] loss: 0.198\n",
      "[38, 300] loss: 0.201\n",
      "[38, 360] loss: 0.203\n",
      "Epoch: 38 -> Loss: 0.189019560814\n",
      "Epoch: 38 -> Test Accuracy: 85.07\n",
      "[39, 60] loss: 0.184\n",
      "[39, 120] loss: 0.179\n",
      "[39, 180] loss: 0.198\n",
      "[39, 240] loss: 0.200\n",
      "[39, 300] loss: 0.212\n",
      "[39, 360] loss: 0.193\n",
      "Epoch: 39 -> Loss: 0.26672872901\n",
      "Epoch: 39 -> Test Accuracy: 85.26\n",
      "[40, 60] loss: 0.183\n",
      "[40, 120] loss: 0.183\n",
      "[40, 180] loss: 0.197\n",
      "[40, 240] loss: 0.178\n",
      "[40, 300] loss: 0.205\n",
      "[40, 360] loss: 0.204\n",
      "Epoch: 40 -> Loss: 0.395910412073\n",
      "Epoch: 40 -> Test Accuracy: 85.27\n",
      "[41, 60] loss: 0.179\n",
      "[41, 120] loss: 0.160\n",
      "[41, 180] loss: 0.159\n",
      "[41, 240] loss: 0.152\n",
      "[41, 300] loss: 0.158\n",
      "[41, 360] loss: 0.156\n",
      "Epoch: 41 -> Loss: 0.0943783000112\n",
      "Epoch: 41 -> Test Accuracy: 86.13\n",
      "[42, 60] loss: 0.153\n",
      "[42, 120] loss: 0.140\n",
      "[42, 180] loss: 0.151\n",
      "[42, 240] loss: 0.155\n",
      "[42, 300] loss: 0.148\n",
      "[42, 360] loss: 0.144\n",
      "Epoch: 42 -> Loss: 0.122677065432\n",
      "Epoch: 42 -> Test Accuracy: 86.33\n",
      "[43, 60] loss: 0.136\n",
      "[43, 120] loss: 0.143\n",
      "[43, 180] loss: 0.146\n",
      "[43, 240] loss: 0.134\n",
      "[43, 300] loss: 0.138\n",
      "[43, 360] loss: 0.138\n",
      "Epoch: 43 -> Loss: 0.0947639122605\n",
      "Epoch: 43 -> Test Accuracy: 86.25\n",
      "[44, 60] loss: 0.123\n",
      "[44, 120] loss: 0.133\n",
      "[44, 180] loss: 0.132\n",
      "[44, 240] loss: 0.137\n",
      "[44, 300] loss: 0.134\n",
      "[44, 360] loss: 0.137\n",
      "Epoch: 44 -> Loss: 0.0986238270998\n",
      "Epoch: 44 -> Test Accuracy: 86.31\n",
      "[45, 60] loss: 0.124\n",
      "[45, 120] loss: 0.126\n",
      "[45, 180] loss: 0.118\n",
      "[45, 240] loss: 0.123\n",
      "[45, 300] loss: 0.125\n",
      "[45, 360] loss: 0.133\n",
      "Epoch: 45 -> Loss: 0.122785553336\n",
      "Epoch: 45 -> Test Accuracy: 86.28\n",
      "[46, 60] loss: 0.119\n",
      "[46, 120] loss: 0.121\n",
      "[46, 180] loss: 0.122\n",
      "[46, 240] loss: 0.117\n",
      "[46, 300] loss: 0.112\n",
      "[46, 360] loss: 0.120\n",
      "Epoch: 46 -> Loss: 0.129695028067\n",
      "Epoch: 46 -> Test Accuracy: 86.34\n",
      "[47, 60] loss: 0.109\n",
      "[47, 120] loss: 0.123\n",
      "[47, 180] loss: 0.120\n",
      "[47, 240] loss: 0.126\n",
      "[47, 300] loss: 0.114\n",
      "[47, 360] loss: 0.111\n",
      "Epoch: 47 -> Loss: 0.11444824934\n",
      "Epoch: 47 -> Test Accuracy: 86.44\n",
      "[48, 60] loss: 0.113\n",
      "[48, 120] loss: 0.122\n",
      "[48, 180] loss: 0.117\n",
      "[48, 240] loss: 0.112\n",
      "[48, 300] loss: 0.110\n",
      "[48, 360] loss: 0.116\n",
      "Epoch: 48 -> Loss: 0.107685253024\n",
      "Epoch: 48 -> Test Accuracy: 86.55\n",
      "[49, 60] loss: 0.108\n",
      "[49, 120] loss: 0.115\n",
      "[49, 180] loss: 0.116\n",
      "[49, 240] loss: 0.113\n",
      "[49, 300] loss: 0.119\n",
      "[49, 360] loss: 0.113\n",
      "Epoch: 49 -> Loss: 0.113089598715\n",
      "Epoch: 49 -> Test Accuracy: 86.42\n",
      "[50, 60] loss: 0.115\n",
      "[50, 120] loss: 0.112\n",
      "[50, 180] loss: 0.108\n",
      "[50, 240] loss: 0.107\n",
      "[50, 300] loss: 0.110\n",
      "[50, 360] loss: 0.102\n",
      "Epoch: 50 -> Loss: 0.142826527357\n",
      "Epoch: 50 -> Test Accuracy: 86.49\n",
      "[51, 60] loss: 0.105\n",
      "[51, 120] loss: 0.107\n",
      "[51, 180] loss: 0.115\n",
      "[51, 240] loss: 0.112\n",
      "[51, 300] loss: 0.116\n",
      "[51, 360] loss: 0.113\n",
      "Epoch: 51 -> Loss: 0.112693808973\n",
      "Epoch: 51 -> Test Accuracy: 86.48\n",
      "[52, 60] loss: 0.106\n",
      "[52, 120] loss: 0.111\n",
      "[52, 180] loss: 0.118\n",
      "[52, 240] loss: 0.112\n",
      "[52, 300] loss: 0.109\n",
      "[52, 360] loss: 0.111\n",
      "Epoch: 52 -> Loss: 0.102873206139\n",
      "Epoch: 52 -> Test Accuracy: 86.51\n",
      "[53, 60] loss: 0.109\n",
      "[53, 120] loss: 0.104\n",
      "[53, 180] loss: 0.107\n",
      "[53, 240] loss: 0.109\n",
      "[53, 300] loss: 0.116\n",
      "[53, 360] loss: 0.108\n",
      "Epoch: 53 -> Loss: 0.165378883481\n",
      "Epoch: 53 -> Test Accuracy: 86.52\n",
      "[54, 60] loss: 0.111\n",
      "[54, 120] loss: 0.110\n",
      "[54, 180] loss: 0.107\n",
      "[54, 240] loss: 0.115\n",
      "[54, 300] loss: 0.106\n",
      "[54, 360] loss: 0.106\n",
      "Epoch: 54 -> Loss: 0.20932674408\n",
      "Epoch: 54 -> Test Accuracy: 86.52\n",
      "[55, 60] loss: 0.103\n",
      "[55, 120] loss: 0.108\n",
      "[55, 180] loss: 0.098\n",
      "[55, 240] loss: 0.106\n",
      "[55, 300] loss: 0.110\n",
      "[55, 360] loss: 0.105\n",
      "Epoch: 55 -> Loss: 0.0778907984495\n",
      "Epoch: 55 -> Test Accuracy: 86.51\n",
      "[56, 60] loss: 0.107\n",
      "[56, 120] loss: 0.105\n",
      "[56, 180] loss: 0.115\n",
      "[56, 240] loss: 0.105\n",
      "[56, 300] loss: 0.111\n",
      "[56, 360] loss: 0.097\n",
      "Epoch: 56 -> Loss: 0.0608037933707\n",
      "Epoch: 56 -> Test Accuracy: 86.58\n",
      "[57, 60] loss: 0.097\n",
      "[57, 120] loss: 0.109\n",
      "[57, 180] loss: 0.104\n",
      "[57, 240] loss: 0.103\n",
      "[57, 300] loss: 0.105\n",
      "[57, 360] loss: 0.107\n",
      "Epoch: 57 -> Loss: 0.154722213745\n",
      "Epoch: 57 -> Test Accuracy: 86.51\n",
      "[58, 60] loss: 0.106\n",
      "[58, 120] loss: 0.106\n",
      "[58, 180] loss: 0.102\n",
      "[58, 240] loss: 0.096\n",
      "[58, 300] loss: 0.102\n",
      "[58, 360] loss: 0.100\n",
      "Epoch: 58 -> Loss: 0.0871781185269\n",
      "Epoch: 58 -> Test Accuracy: 86.48\n",
      "[59, 60] loss: 0.103\n",
      "[59, 120] loss: 0.111\n",
      "[59, 180] loss: 0.107\n",
      "[59, 240] loss: 0.109\n",
      "[59, 300] loss: 0.098\n",
      "[59, 360] loss: 0.095\n",
      "Epoch: 59 -> Loss: 0.110949575901\n",
      "Epoch: 59 -> Test Accuracy: 86.54\n",
      "[60, 60] loss: 0.100\n",
      "[60, 120] loss: 0.107\n",
      "[60, 180] loss: 0.101\n",
      "[60, 240] loss: 0.101\n",
      "[60, 300] loss: 0.098\n",
      "[60, 360] loss: 0.101\n",
      "Epoch: 60 -> Loss: 0.114571347833\n",
      "Epoch: 60 -> Test Accuracy: 86.47\n",
      "[61, 60] loss: 0.101\n",
      "[61, 120] loss: 0.102\n",
      "[61, 180] loss: 0.101\n",
      "[61, 240] loss: 0.109\n",
      "[61, 300] loss: 0.101\n",
      "[61, 360] loss: 0.100\n",
      "Epoch: 61 -> Loss: 0.0882179290056\n",
      "Epoch: 61 -> Test Accuracy: 86.59\n",
      "[62, 60] loss: 0.104\n",
      "[62, 120] loss: 0.104\n",
      "[62, 180] loss: 0.100\n",
      "[62, 240] loss: 0.099\n",
      "[62, 300] loss: 0.098\n",
      "[62, 360] loss: 0.090\n",
      "Epoch: 62 -> Loss: 0.0816664248705\n",
      "Epoch: 62 -> Test Accuracy: 86.68\n",
      "[63, 60] loss: 0.107\n",
      "[63, 120] loss: 0.098\n",
      "[63, 180] loss: 0.099\n",
      "[63, 240] loss: 0.102\n",
      "[63, 300] loss: 0.100\n",
      "[63, 360] loss: 0.101\n",
      "Epoch: 63 -> Loss: 0.0926828533411\n",
      "Epoch: 63 -> Test Accuracy: 86.65\n",
      "[64, 60] loss: 0.100\n",
      "[64, 120] loss: 0.094\n",
      "[64, 180] loss: 0.097\n",
      "[64, 240] loss: 0.097\n",
      "[64, 300] loss: 0.096\n",
      "[64, 360] loss: 0.103\n",
      "Epoch: 64 -> Loss: 0.0782715827227\n",
      "Epoch: 64 -> Test Accuracy: 86.57\n",
      "[65, 60] loss: 0.092\n",
      "[65, 120] loss: 0.110\n",
      "[65, 180] loss: 0.090\n",
      "[65, 240] loss: 0.098\n",
      "[65, 300] loss: 0.099\n",
      "[65, 360] loss: 0.106\n",
      "Epoch: 65 -> Loss: 0.117500737309\n",
      "Epoch: 65 -> Test Accuracy: 86.53\n",
      "[66, 60] loss: 0.102\n",
      "[66, 120] loss: 0.090\n",
      "[66, 180] loss: 0.086\n",
      "[66, 240] loss: 0.100\n",
      "[66, 300] loss: 0.095\n",
      "[66, 360] loss: 0.096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Loss: 0.0875278636813\n",
      "Epoch: 66 -> Test Accuracy: 86.62\n",
      "[67, 60] loss: 0.090\n",
      "[67, 120] loss: 0.093\n",
      "[67, 180] loss: 0.097\n",
      "[67, 240] loss: 0.098\n",
      "[67, 300] loss: 0.095\n",
      "[67, 360] loss: 0.091\n",
      "Epoch: 67 -> Loss: 0.279062747955\n",
      "Epoch: 67 -> Test Accuracy: 86.56\n",
      "[68, 60] loss: 0.097\n",
      "[68, 120] loss: 0.097\n",
      "[68, 180] loss: 0.091\n",
      "[68, 240] loss: 0.100\n",
      "[68, 300] loss: 0.092\n",
      "[68, 360] loss: 0.095\n",
      "Epoch: 68 -> Loss: 0.0385071113706\n",
      "Epoch: 68 -> Test Accuracy: 86.58\n",
      "[69, 60] loss: 0.096\n",
      "[69, 120] loss: 0.086\n",
      "[69, 180] loss: 0.098\n",
      "[69, 240] loss: 0.095\n",
      "[69, 300] loss: 0.095\n",
      "[69, 360] loss: 0.100\n",
      "Epoch: 69 -> Loss: 0.0830150395632\n",
      "Epoch: 69 -> Test Accuracy: 86.55\n",
      "[70, 60] loss: 0.092\n",
      "[70, 120] loss: 0.095\n",
      "[70, 180] loss: 0.092\n",
      "[70, 240] loss: 0.100\n",
      "[70, 300] loss: 0.098\n",
      "[70, 360] loss: 0.091\n",
      "Epoch: 70 -> Loss: 0.147570535541\n",
      "Epoch: 70 -> Test Accuracy: 86.54\n",
      "[71, 60] loss: 0.092\n",
      "[71, 120] loss: 0.095\n",
      "[71, 180] loss: 0.094\n",
      "[71, 240] loss: 0.097\n",
      "[71, 300] loss: 0.087\n",
      "[71, 360] loss: 0.095\n",
      "Epoch: 71 -> Loss: 0.166447415948\n",
      "Epoch: 71 -> Test Accuracy: 86.56\n",
      "[72, 60] loss: 0.091\n",
      "[72, 120] loss: 0.090\n",
      "[72, 180] loss: 0.091\n",
      "[72, 240] loss: 0.097\n",
      "[72, 300] loss: 0.088\n",
      "[72, 360] loss: 0.086\n",
      "Epoch: 72 -> Loss: 0.131402149796\n",
      "Epoch: 72 -> Test Accuracy: 86.53\n",
      "[73, 60] loss: 0.094\n",
      "[73, 120] loss: 0.086\n",
      "[73, 180] loss: 0.087\n",
      "[73, 240] loss: 0.086\n",
      "[73, 300] loss: 0.099\n",
      "[73, 360] loss: 0.099\n",
      "Epoch: 73 -> Loss: 0.0341930016875\n",
      "Epoch: 73 -> Test Accuracy: 86.45\n",
      "[74, 60] loss: 0.091\n",
      "[74, 120] loss: 0.090\n",
      "[74, 180] loss: 0.092\n",
      "[74, 240] loss: 0.100\n",
      "[74, 300] loss: 0.092\n",
      "[74, 360] loss: 0.086\n",
      "Epoch: 74 -> Loss: 0.0816075205803\n",
      "Epoch: 74 -> Test Accuracy: 86.45\n",
      "[75, 60] loss: 0.090\n",
      "[75, 120] loss: 0.096\n",
      "[75, 180] loss: 0.093\n",
      "[75, 240] loss: 0.093\n",
      "[75, 300] loss: 0.091\n",
      "[75, 360] loss: 0.084\n",
      "Epoch: 75 -> Loss: 0.135517299175\n",
      "Epoch: 75 -> Test Accuracy: 86.44\n",
      "[76, 60] loss: 0.089\n",
      "[76, 120] loss: 0.090\n",
      "[76, 180] loss: 0.090\n",
      "[76, 240] loss: 0.092\n",
      "[76, 300] loss: 0.089\n",
      "[76, 360] loss: 0.091\n",
      "Epoch: 76 -> Loss: 0.124477602541\n",
      "Epoch: 76 -> Test Accuracy: 86.47\n",
      "[77, 60] loss: 0.087\n",
      "[77, 120] loss: 0.092\n",
      "[77, 180] loss: 0.089\n",
      "[77, 240] loss: 0.086\n",
      "[77, 300] loss: 0.097\n",
      "[77, 360] loss: 0.087\n",
      "Epoch: 77 -> Loss: 0.0466269478202\n",
      "Epoch: 77 -> Test Accuracy: 86.4\n",
      "[78, 60] loss: 0.094\n",
      "[78, 120] loss: 0.088\n",
      "[78, 180] loss: 0.084\n",
      "[78, 240] loss: 0.086\n",
      "[78, 300] loss: 0.099\n",
      "[78, 360] loss: 0.087\n",
      "Epoch: 78 -> Loss: 0.0827061161399\n",
      "Epoch: 78 -> Test Accuracy: 86.6\n",
      "[79, 60] loss: 0.081\n",
      "[79, 120] loss: 0.094\n",
      "[79, 180] loss: 0.083\n",
      "[79, 240] loss: 0.091\n",
      "[79, 300] loss: 0.089\n",
      "[79, 360] loss: 0.088\n",
      "Epoch: 79 -> Loss: 0.0839433148503\n",
      "Epoch: 79 -> Test Accuracy: 86.58\n",
      "[80, 60] loss: 0.086\n",
      "[80, 120] loss: 0.095\n",
      "[80, 180] loss: 0.086\n",
      "[80, 240] loss: 0.093\n",
      "[80, 300] loss: 0.088\n",
      "[80, 360] loss: 0.082\n",
      "Epoch: 80 -> Loss: 0.117639183998\n",
      "Epoch: 80 -> Test Accuracy: 86.41\n",
      "[81, 60] loss: 0.092\n",
      "[81, 120] loss: 0.090\n",
      "[81, 180] loss: 0.088\n",
      "[81, 240] loss: 0.092\n",
      "[81, 300] loss: 0.090\n",
      "[81, 360] loss: 0.090\n",
      "Epoch: 81 -> Loss: 0.0283928867429\n",
      "Epoch: 81 -> Test Accuracy: 86.4\n",
      "[82, 60] loss: 0.093\n",
      "[82, 120] loss: 0.084\n",
      "[82, 180] loss: 0.084\n",
      "[82, 240] loss: 0.084\n",
      "[82, 300] loss: 0.093\n",
      "[82, 360] loss: 0.087\n",
      "Epoch: 82 -> Loss: 0.178500145674\n",
      "Epoch: 82 -> Test Accuracy: 86.38\n",
      "[83, 60] loss: 0.079\n",
      "[83, 120] loss: 0.084\n",
      "[83, 180] loss: 0.089\n",
      "[83, 240] loss: 0.087\n",
      "[83, 300] loss: 0.083\n",
      "[83, 360] loss: 0.081\n",
      "Epoch: 83 -> Loss: 0.0440602749586\n",
      "Epoch: 83 -> Test Accuracy: 86.36\n",
      "[84, 60] loss: 0.084\n",
      "[84, 120] loss: 0.081\n",
      "[84, 180] loss: 0.082\n",
      "[84, 240] loss: 0.089\n",
      "[84, 300] loss: 0.082\n",
      "[84, 360] loss: 0.089\n",
      "Epoch: 84 -> Loss: 0.143937140703\n",
      "Epoch: 84 -> Test Accuracy: 86.44\n",
      "[85, 60] loss: 0.086\n",
      "[85, 120] loss: 0.083\n",
      "[85, 180] loss: 0.090\n",
      "[85, 240] loss: 0.093\n",
      "[85, 300] loss: 0.083\n",
      "[85, 360] loss: 0.080\n",
      "Epoch: 85 -> Loss: 0.141636013985\n",
      "Epoch: 85 -> Test Accuracy: 86.55\n",
      "[86, 60] loss: 0.085\n",
      "[86, 120] loss: 0.085\n",
      "[86, 180] loss: 0.087\n",
      "[86, 240] loss: 0.085\n",
      "[86, 300] loss: 0.081\n",
      "[86, 360] loss: 0.089\n",
      "Epoch: 86 -> Loss: 0.0997038856149\n",
      "Epoch: 86 -> Test Accuracy: 86.49\n",
      "[87, 60] loss: 0.083\n",
      "[87, 120] loss: 0.080\n",
      "[87, 180] loss: 0.083\n",
      "[87, 240] loss: 0.085\n",
      "[87, 300] loss: 0.083\n",
      "[87, 360] loss: 0.078\n",
      "Epoch: 87 -> Loss: 0.126808017492\n",
      "Epoch: 87 -> Test Accuracy: 86.44\n",
      "[88, 60] loss: 0.081\n",
      "[88, 120] loss: 0.077\n",
      "[88, 180] loss: 0.077\n",
      "[88, 240] loss: 0.081\n",
      "[88, 300] loss: 0.085\n",
      "[88, 360] loss: 0.082\n",
      "Epoch: 88 -> Loss: 0.0658229589462\n",
      "Epoch: 88 -> Test Accuracy: 86.46\n",
      "[89, 60] loss: 0.086\n",
      "[89, 120] loss: 0.090\n",
      "[89, 180] loss: 0.085\n",
      "[89, 240] loss: 0.082\n",
      "[89, 300] loss: 0.077\n",
      "[89, 360] loss: 0.086\n",
      "Epoch: 89 -> Loss: 0.0564866252244\n",
      "Epoch: 89 -> Test Accuracy: 86.42\n",
      "[90, 60] loss: 0.083\n",
      "[90, 120] loss: 0.080\n",
      "[90, 180] loss: 0.083\n",
      "[90, 240] loss: 0.085\n",
      "[90, 300] loss: 0.076\n",
      "[90, 360] loss: 0.085\n",
      "Epoch: 90 -> Loss: 0.116924032569\n",
      "Epoch: 90 -> Test Accuracy: 86.32\n",
      "[91, 60] loss: 0.076\n",
      "[91, 120] loss: 0.083\n",
      "[91, 180] loss: 0.079\n",
      "[91, 240] loss: 0.081\n",
      "[91, 300] loss: 0.079\n",
      "[91, 360] loss: 0.081\n",
      "Epoch: 91 -> Loss: 0.0986568406224\n",
      "Epoch: 91 -> Test Accuracy: 86.43\n",
      "[92, 60] loss: 0.079\n",
      "[92, 120] loss: 0.077\n",
      "[92, 180] loss: 0.078\n",
      "[92, 240] loss: 0.077\n",
      "[92, 300] loss: 0.080\n",
      "[92, 360] loss: 0.083\n",
      "Epoch: 92 -> Loss: 0.146330758929\n",
      "Epoch: 92 -> Test Accuracy: 86.48\n",
      "[93, 60] loss: 0.081\n",
      "[93, 120] loss: 0.090\n",
      "[93, 180] loss: 0.080\n",
      "[93, 240] loss: 0.083\n",
      "[93, 300] loss: 0.083\n",
      "[93, 360] loss: 0.074\n",
      "Epoch: 93 -> Loss: 0.0758383870125\n",
      "Epoch: 93 -> Test Accuracy: 86.36\n",
      "[94, 60] loss: 0.073\n",
      "[94, 120] loss: 0.086\n",
      "[94, 180] loss: 0.080\n",
      "[94, 240] loss: 0.082\n",
      "[94, 300] loss: 0.079\n",
      "[94, 360] loss: 0.080\n",
      "Epoch: 94 -> Loss: 0.0661194100976\n",
      "Epoch: 94 -> Test Accuracy: 86.51\n",
      "[95, 60] loss: 0.075\n",
      "[95, 120] loss: 0.082\n",
      "[95, 180] loss: 0.080\n",
      "[95, 240] loss: 0.076\n",
      "[95, 300] loss: 0.081\n",
      "[95, 360] loss: 0.076\n",
      "Epoch: 95 -> Loss: 0.188063040376\n",
      "Epoch: 95 -> Test Accuracy: 86.35\n",
      "[96, 60] loss: 0.076\n",
      "[96, 120] loss: 0.084\n",
      "[96, 180] loss: 0.082\n",
      "[96, 240] loss: 0.080\n",
      "[96, 300] loss: 0.077\n",
      "[96, 360] loss: 0.072\n",
      "Epoch: 96 -> Loss: 0.0441781058908\n",
      "Epoch: 96 -> Test Accuracy: 86.32\n",
      "[97, 60] loss: 0.071\n",
      "[97, 120] loss: 0.077\n",
      "[97, 180] loss: 0.076\n",
      "[97, 240] loss: 0.073\n",
      "[97, 300] loss: 0.075\n",
      "[97, 360] loss: 0.082\n",
      "Epoch: 97 -> Loss: 0.052395761013\n",
      "Epoch: 97 -> Test Accuracy: 86.45\n",
      "[98, 60] loss: 0.073\n",
      "[98, 120] loss: 0.074\n",
      "[98, 180] loss: 0.073\n",
      "[98, 240] loss: 0.072\n",
      "[98, 300] loss: 0.075\n",
      "[98, 360] loss: 0.079\n",
      "Epoch: 98 -> Loss: 0.111148074269\n",
      "Epoch: 98 -> Test Accuracy: 86.42\n",
      "[99, 60] loss: 0.074\n",
      "[99, 120] loss: 0.073\n",
      "[99, 180] loss: 0.075\n",
      "[99, 240] loss: 0.078\n",
      "[99, 300] loss: 0.073\n",
      "[99, 360] loss: 0.073\n",
      "Epoch: 99 -> Loss: 0.0655280798674\n",
      "Epoch: 99 -> Test Accuracy: 86.26\n",
      "[100, 60] loss: 0.070\n",
      "[100, 120] loss: 0.072\n",
      "[100, 180] loss: 0.077\n",
      "[100, 240] loss: 0.081\n",
      "[100, 300] loss: 0.076\n",
      "[100, 360] loss: 0.079\n",
      "Epoch: 100 -> Loss: 0.115976274014\n",
      "Epoch: 100 -> Test Accuracy: 86.44\n",
      "Finished Training\n",
      "[1, 60] loss: 2.676\n",
      "[1, 120] loss: 1.847\n",
      "[1, 180] loss: 1.769\n",
      "[1, 240] loss: 1.736\n",
      "[1, 300] loss: 1.703\n",
      "[1, 360] loss: 1.691\n",
      "Epoch: 1 -> Loss: 1.52364873886\n",
      "Epoch: 1 -> Test Accuracy: 37.53\n",
      "[2, 60] loss: 1.661\n",
      "[2, 120] loss: 1.643\n",
      "[2, 180] loss: 1.634\n",
      "[2, 240] loss: 1.620\n",
      "[2, 300] loss: 1.630\n",
      "[2, 360] loss: 1.596\n",
      "Epoch: 2 -> Loss: 1.39410424232\n",
      "Epoch: 2 -> Test Accuracy: 39.48\n",
      "[3, 60] loss: 1.602\n",
      "[3, 120] loss: 1.561\n",
      "[3, 180] loss: 1.581\n",
      "[3, 240] loss: 1.553\n",
      "[3, 300] loss: 1.564\n",
      "[3, 360] loss: 1.556\n",
      "Epoch: 3 -> Loss: 1.59475851059\n",
      "Epoch: 3 -> Test Accuracy: 41.27\n",
      "[4, 60] loss: 1.542\n",
      "[4, 120] loss: 1.537\n",
      "[4, 180] loss: 1.551\n",
      "[4, 240] loss: 1.532\n",
      "[4, 300] loss: 1.536\n",
      "[4, 360] loss: 1.531\n",
      "Epoch: 4 -> Loss: 1.56952428818\n",
      "Epoch: 4 -> Test Accuracy: 42.17\n",
      "[5, 60] loss: 1.505\n",
      "[5, 120] loss: 1.523\n",
      "[5, 180] loss: 1.512\n",
      "[5, 240] loss: 1.520\n",
      "[5, 300] loss: 1.516\n",
      "[5, 360] loss: 1.520\n",
      "Epoch: 5 -> Loss: 1.53929758072\n",
      "Epoch: 5 -> Test Accuracy: 42.9\n",
      "[6, 60] loss: 1.516\n",
      "[6, 120] loss: 1.509\n",
      "[6, 180] loss: 1.493\n",
      "[6, 240] loss: 1.486\n",
      "[6, 300] loss: 1.500\n",
      "[6, 360] loss: 1.506\n",
      "Epoch: 6 -> Loss: 1.54099071026\n",
      "Epoch: 6 -> Test Accuracy: 43.5\n",
      "[7, 60] loss: 1.478\n",
      "[7, 120] loss: 1.515\n",
      "[7, 180] loss: 1.476\n",
      "[7, 240] loss: 1.496\n",
      "[7, 300] loss: 1.495\n",
      "[7, 360] loss: 1.466\n",
      "Epoch: 7 -> Loss: 1.50421857834\n",
      "Epoch: 7 -> Test Accuracy: 43.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 60] loss: 1.487\n",
      "[8, 120] loss: 1.479\n",
      "[8, 180] loss: 1.488\n",
      "[8, 240] loss: 1.475\n",
      "[8, 300] loss: 1.487\n",
      "[8, 360] loss: 1.480\n",
      "Epoch: 8 -> Loss: 1.39841389656\n",
      "Epoch: 8 -> Test Accuracy: 44.18\n",
      "[9, 60] loss: 1.474\n",
      "[9, 120] loss: 1.471\n",
      "[9, 180] loss: 1.499\n",
      "[9, 240] loss: 1.486\n",
      "[9, 300] loss: 1.474\n",
      "[9, 360] loss: 1.473\n",
      "Epoch: 9 -> Loss: 1.40985012054\n",
      "Epoch: 9 -> Test Accuracy: 44.87\n",
      "[10, 60] loss: 1.468\n",
      "[10, 120] loss: 1.463\n",
      "[10, 180] loss: 1.460\n",
      "[10, 240] loss: 1.483\n",
      "[10, 300] loss: 1.447\n",
      "[10, 360] loss: 1.469\n",
      "Epoch: 10 -> Loss: 1.56842362881\n",
      "Epoch: 10 -> Test Accuracy: 43.93\n",
      "[11, 60] loss: 1.469\n",
      "[11, 120] loss: 1.460\n",
      "[11, 180] loss: 1.476\n",
      "[11, 240] loss: 1.464\n",
      "[11, 300] loss: 1.467\n",
      "[11, 360] loss: 1.446\n",
      "Epoch: 11 -> Loss: 1.55275261402\n",
      "Epoch: 11 -> Test Accuracy: 44.59\n",
      "[12, 60] loss: 1.471\n",
      "[12, 120] loss: 1.435\n",
      "[12, 180] loss: 1.458\n",
      "[12, 240] loss: 1.470\n",
      "[12, 300] loss: 1.470\n",
      "[12, 360] loss: 1.465\n",
      "Epoch: 12 -> Loss: 1.53223562241\n",
      "Epoch: 12 -> Test Accuracy: 44.68\n",
      "[13, 60] loss: 1.473\n",
      "[13, 120] loss: 1.474\n",
      "[13, 180] loss: 1.448\n",
      "[13, 240] loss: 1.459\n",
      "[13, 300] loss: 1.474\n",
      "[13, 360] loss: 1.465\n",
      "Epoch: 13 -> Loss: 1.45059394836\n",
      "Epoch: 13 -> Test Accuracy: 44.06\n",
      "[14, 60] loss: 1.456\n",
      "[14, 120] loss: 1.473\n",
      "[14, 180] loss: 1.456\n",
      "[14, 240] loss: 1.460\n",
      "[14, 300] loss: 1.449\n",
      "[14, 360] loss: 1.455\n",
      "Epoch: 14 -> Loss: 1.60295009613\n",
      "Epoch: 14 -> Test Accuracy: 44.67\n",
      "[15, 60] loss: 1.468\n",
      "[15, 120] loss: 1.435\n",
      "[15, 180] loss: 1.452\n",
      "[15, 240] loss: 1.460\n",
      "[15, 300] loss: 1.457\n",
      "[15, 360] loss: 1.439\n",
      "Epoch: 15 -> Loss: 1.56296885014\n",
      "Epoch: 15 -> Test Accuracy: 44.76\n",
      "[16, 60] loss: 1.438\n",
      "[16, 120] loss: 1.449\n",
      "[16, 180] loss: 1.471\n",
      "[16, 240] loss: 1.459\n",
      "[16, 300] loss: 1.451\n",
      "[16, 360] loss: 1.455\n",
      "Epoch: 16 -> Loss: 1.60495281219\n",
      "Epoch: 16 -> Test Accuracy: 45.25\n",
      "[17, 60] loss: 1.447\n",
      "[17, 120] loss: 1.431\n",
      "[17, 180] loss: 1.455\n",
      "[17, 240] loss: 1.478\n",
      "[17, 300] loss: 1.450\n",
      "[17, 360] loss: 1.450\n",
      "Epoch: 17 -> Loss: 1.3824365139\n",
      "Epoch: 17 -> Test Accuracy: 44.85\n",
      "[18, 60] loss: 1.461\n",
      "[18, 120] loss: 1.446\n",
      "[18, 180] loss: 1.471\n",
      "[18, 240] loss: 1.437\n",
      "[18, 300] loss: 1.457\n",
      "[18, 360] loss: 1.444\n",
      "Epoch: 18 -> Loss: 1.41462767124\n",
      "Epoch: 18 -> Test Accuracy: 45.03\n",
      "[19, 60] loss: 1.451\n",
      "[19, 120] loss: 1.448\n",
      "[19, 180] loss: 1.467\n",
      "[19, 240] loss: 1.423\n",
      "[19, 300] loss: 1.441\n",
      "[19, 360] loss: 1.473\n",
      "Epoch: 19 -> Loss: 1.51573812962\n",
      "Epoch: 19 -> Test Accuracy: 44.37\n",
      "[20, 60] loss: 1.436\n",
      "[20, 120] loss: 1.453\n",
      "[20, 180] loss: 1.425\n",
      "[20, 240] loss: 1.471\n",
      "[20, 300] loss: 1.459\n",
      "[20, 360] loss: 1.451\n",
      "Epoch: 20 -> Loss: 1.47630524635\n",
      "Epoch: 20 -> Test Accuracy: 43.78\n",
      "[21, 60] loss: 1.409\n",
      "[21, 120] loss: 1.367\n",
      "[21, 180] loss: 1.358\n",
      "[21, 240] loss: 1.373\n",
      "[21, 300] loss: 1.361\n",
      "[21, 360] loss: 1.336\n",
      "Epoch: 21 -> Loss: 1.30584740639\n",
      "Epoch: 21 -> Test Accuracy: 48.16\n",
      "[22, 60] loss: 1.339\n",
      "[22, 120] loss: 1.321\n",
      "[22, 180] loss: 1.328\n",
      "[22, 240] loss: 1.325\n",
      "[22, 300] loss: 1.337\n",
      "[22, 360] loss: 1.341\n",
      "Epoch: 22 -> Loss: 1.34226715565\n",
      "Epoch: 22 -> Test Accuracy: 48.58\n",
      "[23, 60] loss: 1.316\n",
      "[23, 120] loss: 1.318\n",
      "[23, 180] loss: 1.302\n",
      "[23, 240] loss: 1.338\n",
      "[23, 300] loss: 1.317\n",
      "[23, 360] loss: 1.312\n",
      "Epoch: 23 -> Loss: 1.28418838978\n",
      "Epoch: 23 -> Test Accuracy: 49.0\n",
      "[24, 60] loss: 1.332\n",
      "[24, 120] loss: 1.320\n",
      "[24, 180] loss: 1.310\n",
      "[24, 240] loss: 1.314\n",
      "[24, 300] loss: 1.297\n",
      "[24, 360] loss: 1.318\n",
      "Epoch: 24 -> Loss: 1.45560765266\n",
      "Epoch: 24 -> Test Accuracy: 49.54\n",
      "[25, 60] loss: 1.303\n",
      "[25, 120] loss: 1.291\n",
      "[25, 180] loss: 1.306\n",
      "[25, 240] loss: 1.292\n",
      "[25, 300] loss: 1.294\n",
      "[25, 360] loss: 1.292\n",
      "Epoch: 25 -> Loss: 1.37691283226\n",
      "Epoch: 25 -> Test Accuracy: 48.88\n",
      "[26, 60] loss: 1.295\n",
      "[26, 120] loss: 1.302\n",
      "[26, 180] loss: 1.293\n",
      "[26, 240] loss: 1.293\n",
      "[26, 300] loss: 1.297\n",
      "[26, 360] loss: 1.306\n",
      "Epoch: 26 -> Loss: 1.1634786129\n",
      "Epoch: 26 -> Test Accuracy: 49.75\n",
      "[27, 60] loss: 1.288\n",
      "[27, 120] loss: 1.297\n",
      "[27, 180] loss: 1.277\n",
      "[27, 240] loss: 1.305\n",
      "[27, 300] loss: 1.300\n",
      "[27, 360] loss: 1.311\n",
      "Epoch: 27 -> Loss: 1.36242198944\n",
      "Epoch: 27 -> Test Accuracy: 49.05\n",
      "[28, 60] loss: 1.299\n",
      "[28, 120] loss: 1.290\n",
      "[28, 180] loss: 1.291\n",
      "[28, 240] loss: 1.287\n",
      "[28, 300] loss: 1.298\n",
      "[28, 360] loss: 1.287\n",
      "Epoch: 28 -> Loss: 1.25336778164\n",
      "Epoch: 28 -> Test Accuracy: 49.76\n",
      "[29, 60] loss: 1.287\n",
      "[29, 120] loss: 1.303\n",
      "[29, 180] loss: 1.278\n",
      "[29, 240] loss: 1.325\n",
      "[29, 300] loss: 1.302\n",
      "[29, 360] loss: 1.293\n",
      "Epoch: 29 -> Loss: 1.3518807888\n",
      "Epoch: 29 -> Test Accuracy: 49.73\n",
      "[30, 60] loss: 1.288\n",
      "[30, 120] loss: 1.282\n",
      "[30, 180] loss: 1.307\n",
      "[30, 240] loss: 1.306\n",
      "[30, 300] loss: 1.297\n",
      "[30, 360] loss: 1.277\n",
      "Epoch: 30 -> Loss: 1.23199999332\n",
      "Epoch: 30 -> Test Accuracy: 49.13\n",
      "[31, 60] loss: 1.280\n",
      "[31, 120] loss: 1.299\n",
      "[31, 180] loss: 1.293\n",
      "[31, 240] loss: 1.300\n",
      "[31, 300] loss: 1.304\n",
      "[31, 360] loss: 1.290\n",
      "Epoch: 31 -> Loss: 1.19559311867\n",
      "Epoch: 31 -> Test Accuracy: 49.63\n",
      "[32, 60] loss: 1.295\n",
      "[32, 120] loss: 1.297\n",
      "[32, 180] loss: 1.282\n",
      "[32, 240] loss: 1.289\n",
      "[32, 300] loss: 1.289\n",
      "[32, 360] loss: 1.319\n",
      "Epoch: 32 -> Loss: 1.56193220615\n",
      "Epoch: 32 -> Test Accuracy: 50.07\n",
      "[33, 60] loss: 1.275\n",
      "[33, 120] loss: 1.282\n",
      "[33, 180] loss: 1.305\n",
      "[33, 240] loss: 1.299\n",
      "[33, 300] loss: 1.275\n",
      "[33, 360] loss: 1.291\n",
      "Epoch: 33 -> Loss: 1.4914098978\n",
      "Epoch: 33 -> Test Accuracy: 49.37\n",
      "[34, 60] loss: 1.268\n",
      "[34, 120] loss: 1.290\n",
      "[34, 180] loss: 1.299\n",
      "[34, 240] loss: 1.311\n",
      "[34, 300] loss: 1.265\n",
      "[34, 360] loss: 1.300\n",
      "Epoch: 34 -> Loss: 1.40532243252\n",
      "Epoch: 34 -> Test Accuracy: 49.98\n",
      "[35, 60] loss: 1.263\n",
      "[35, 120] loss: 1.294\n",
      "[35, 180] loss: 1.260\n",
      "[35, 240] loss: 1.316\n",
      "[35, 300] loss: 1.308\n",
      "[35, 360] loss: 1.291\n",
      "Epoch: 35 -> Loss: 1.11464571953\n",
      "Epoch: 35 -> Test Accuracy: 49.84\n",
      "[36, 60] loss: 1.269\n",
      "[36, 120] loss: 1.282\n",
      "[36, 180] loss: 1.288\n",
      "[36, 240] loss: 1.291\n",
      "[36, 300] loss: 1.298\n",
      "[36, 360] loss: 1.298\n",
      "Epoch: 36 -> Loss: 1.22665953636\n",
      "Epoch: 36 -> Test Accuracy: 49.74\n",
      "[37, 60] loss: 1.271\n",
      "[37, 120] loss: 1.287\n",
      "[37, 180] loss: 1.279\n",
      "[37, 240] loss: 1.285\n",
      "[37, 300] loss: 1.300\n",
      "[37, 360] loss: 1.277\n",
      "Epoch: 37 -> Loss: 1.38238608837\n",
      "Epoch: 37 -> Test Accuracy: 49.46\n",
      "[38, 60] loss: 1.303\n",
      "[38, 120] loss: 1.269\n",
      "[38, 180] loss: 1.273\n",
      "[38, 240] loss: 1.280\n",
      "[38, 300] loss: 1.281\n",
      "[38, 360] loss: 1.278\n",
      "Epoch: 38 -> Loss: 1.46829009056\n",
      "Epoch: 38 -> Test Accuracy: 49.7\n",
      "[39, 60] loss: 1.274\n",
      "[39, 120] loss: 1.282\n",
      "[39, 180] loss: 1.293\n",
      "[39, 240] loss: 1.286\n",
      "[39, 300] loss: 1.285\n",
      "[39, 360] loss: 1.298\n",
      "Epoch: 39 -> Loss: 1.38687849045\n",
      "Epoch: 39 -> Test Accuracy: 49.82\n",
      "[40, 60] loss: 1.278\n",
      "[40, 120] loss: 1.277\n",
      "[40, 180] loss: 1.278\n",
      "[40, 240] loss: 1.277\n",
      "[40, 300] loss: 1.289\n",
      "[40, 360] loss: 1.299\n",
      "Epoch: 40 -> Loss: 1.26408076286\n",
      "Epoch: 40 -> Test Accuracy: 50.36\n",
      "[41, 60] loss: 1.251\n",
      "[41, 120] loss: 1.233\n",
      "[41, 180] loss: 1.229\n",
      "[41, 240] loss: 1.229\n",
      "[41, 300] loss: 1.231\n",
      "[41, 360] loss: 1.208\n",
      "Epoch: 41 -> Loss: 1.44304168224\n",
      "Epoch: 41 -> Test Accuracy: 52.01\n",
      "[42, 60] loss: 1.227\n",
      "[42, 120] loss: 1.216\n",
      "[42, 180] loss: 1.214\n",
      "[42, 240] loss: 1.206\n",
      "[42, 300] loss: 1.206\n",
      "[42, 360] loss: 1.209\n",
      "Epoch: 42 -> Loss: 1.24358153343\n",
      "Epoch: 42 -> Test Accuracy: 52.34\n",
      "[43, 60] loss: 1.217\n",
      "[43, 120] loss: 1.204\n",
      "[43, 180] loss: 1.198\n",
      "[43, 240] loss: 1.198\n",
      "[43, 300] loss: 1.186\n",
      "[43, 360] loss: 1.187\n",
      "Epoch: 43 -> Loss: 1.12743115425\n",
      "Epoch: 43 -> Test Accuracy: 52.41\n",
      "[44, 60] loss: 1.206\n",
      "[44, 120] loss: 1.194\n",
      "[44, 180] loss: 1.199\n",
      "[44, 240] loss: 1.178\n",
      "[44, 300] loss: 1.208\n",
      "[44, 360] loss: 1.206\n",
      "Epoch: 44 -> Loss: 1.01291584969\n",
      "Epoch: 44 -> Test Accuracy: 52.66\n",
      "[45, 60] loss: 1.189\n",
      "[45, 120] loss: 1.195\n",
      "[45, 180] loss: 1.203\n",
      "[45, 240] loss: 1.222\n",
      "[45, 300] loss: 1.178\n",
      "[45, 360] loss: 1.192\n",
      "Epoch: 45 -> Loss: 1.1227915287\n",
      "Epoch: 45 -> Test Accuracy: 52.35\n",
      "[46, 60] loss: 1.177\n",
      "[46, 120] loss: 1.186\n",
      "[46, 180] loss: 1.180\n",
      "[46, 240] loss: 1.171\n",
      "[46, 300] loss: 1.173\n",
      "[46, 360] loss: 1.187\n",
      "Epoch: 46 -> Loss: 1.30463385582\n",
      "Epoch: 46 -> Test Accuracy: 53.23\n",
      "[47, 60] loss: 1.179\n",
      "[47, 120] loss: 1.185\n",
      "[47, 180] loss: 1.178\n",
      "[47, 240] loss: 1.166\n",
      "[47, 300] loss: 1.182\n",
      "[47, 360] loss: 1.161\n",
      "Epoch: 47 -> Loss: 1.29994130135\n",
      "Epoch: 47 -> Test Accuracy: 53.2\n",
      "[48, 60] loss: 1.170\n",
      "[48, 120] loss: 1.176\n",
      "[48, 180] loss: 1.169\n",
      "[48, 240] loss: 1.180\n",
      "[48, 300] loss: 1.165\n",
      "[48, 360] loss: 1.155\n",
      "Epoch: 48 -> Loss: 1.22175383568\n",
      "Epoch: 48 -> Test Accuracy: 53.45\n",
      "[49, 60] loss: 1.170\n",
      "[49, 120] loss: 1.165\n",
      "[49, 180] loss: 1.170\n",
      "[49, 240] loss: 1.177\n",
      "[49, 300] loss: 1.165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 360] loss: 1.176\n",
      "Epoch: 49 -> Loss: 1.12264847755\n",
      "Epoch: 49 -> Test Accuracy: 53.43\n",
      "[50, 60] loss: 1.160\n",
      "[50, 120] loss: 1.153\n",
      "[50, 180] loss: 1.169\n",
      "[50, 240] loss: 1.190\n",
      "[50, 300] loss: 1.155\n",
      "[50, 360] loss: 1.153\n",
      "Epoch: 50 -> Loss: 1.2540705204\n",
      "Epoch: 50 -> Test Accuracy: 53.44\n",
      "[51, 60] loss: 1.178\n",
      "[51, 120] loss: 1.159\n",
      "[51, 180] loss: 1.162\n",
      "[51, 240] loss: 1.160\n",
      "[51, 300] loss: 1.167\n",
      "[51, 360] loss: 1.167\n",
      "Epoch: 51 -> Loss: 1.0436899662\n",
      "Epoch: 51 -> Test Accuracy: 54.03\n",
      "[52, 60] loss: 1.161\n",
      "[52, 120] loss: 1.167\n",
      "[52, 180] loss: 1.169\n",
      "[52, 240] loss: 1.169\n",
      "[52, 300] loss: 1.182\n",
      "[52, 360] loss: 1.158\n",
      "Epoch: 52 -> Loss: 1.2312848568\n",
      "Epoch: 52 -> Test Accuracy: 53.62\n",
      "[53, 60] loss: 1.157\n",
      "[53, 120] loss: 1.176\n",
      "[53, 180] loss: 1.160\n",
      "[53, 240] loss: 1.145\n",
      "[53, 300] loss: 1.174\n",
      "[53, 360] loss: 1.146\n",
      "Epoch: 53 -> Loss: 0.86311852932\n",
      "Epoch: 53 -> Test Accuracy: 53.58\n",
      "[54, 60] loss: 1.151\n",
      "[54, 120] loss: 1.180\n",
      "[54, 180] loss: 1.166\n",
      "[54, 240] loss: 1.151\n",
      "[54, 300] loss: 1.160\n",
      "[54, 360] loss: 1.180\n",
      "Epoch: 54 -> Loss: 1.30519127846\n",
      "Epoch: 54 -> Test Accuracy: 53.26\n",
      "[55, 60] loss: 1.166\n",
      "[55, 120] loss: 1.171\n",
      "[55, 180] loss: 1.161\n",
      "[55, 240] loss: 1.151\n",
      "[55, 300] loss: 1.153\n",
      "[55, 360] loss: 1.162\n",
      "Epoch: 55 -> Loss: 1.16083908081\n",
      "Epoch: 55 -> Test Accuracy: 53.59\n",
      "[56, 60] loss: 1.149\n",
      "[56, 120] loss: 1.154\n",
      "[56, 180] loss: 1.164\n",
      "[56, 240] loss: 1.150\n",
      "[56, 300] loss: 1.154\n",
      "[56, 360] loss: 1.146\n",
      "Epoch: 56 -> Loss: 0.965551376343\n",
      "Epoch: 56 -> Test Accuracy: 53.4\n",
      "[57, 60] loss: 1.174\n",
      "[57, 120] loss: 1.161\n",
      "[57, 180] loss: 1.151\n",
      "[57, 240] loss: 1.146\n",
      "[57, 300] loss: 1.153\n",
      "[57, 360] loss: 1.141\n",
      "Epoch: 57 -> Loss: 0.99353569746\n",
      "Epoch: 57 -> Test Accuracy: 53.71\n",
      "[58, 60] loss: 1.143\n",
      "[58, 120] loss: 1.153\n",
      "[58, 180] loss: 1.165\n",
      "[58, 240] loss: 1.156\n",
      "[58, 300] loss: 1.165\n",
      "[58, 360] loss: 1.146\n",
      "Epoch: 58 -> Loss: 1.19122099876\n",
      "Epoch: 58 -> Test Accuracy: 53.8\n",
      "[59, 60] loss: 1.146\n",
      "[59, 120] loss: 1.149\n",
      "[59, 180] loss: 1.149\n",
      "[59, 240] loss: 1.157\n",
      "[59, 300] loss: 1.156\n",
      "[59, 360] loss: 1.177\n",
      "Epoch: 59 -> Loss: 1.34651267529\n",
      "Epoch: 59 -> Test Accuracy: 53.65\n",
      "[60, 60] loss: 1.157\n",
      "[60, 120] loss: 1.148\n",
      "[60, 180] loss: 1.165\n",
      "[60, 240] loss: 1.148\n",
      "[60, 300] loss: 1.152\n",
      "[60, 360] loss: 1.147\n",
      "Epoch: 60 -> Loss: 1.29902338982\n",
      "Epoch: 60 -> Test Accuracy: 53.96\n",
      "[61, 60] loss: 1.168\n",
      "[61, 120] loss: 1.143\n",
      "[61, 180] loss: 1.165\n",
      "[61, 240] loss: 1.160\n",
      "[61, 300] loss: 1.157\n",
      "[61, 360] loss: 1.141\n",
      "Epoch: 61 -> Loss: 0.988267600536\n",
      "Epoch: 61 -> Test Accuracy: 53.5\n",
      "[62, 60] loss: 1.143\n",
      "[62, 120] loss: 1.135\n",
      "[62, 180] loss: 1.170\n",
      "[62, 240] loss: 1.171\n",
      "[62, 300] loss: 1.140\n",
      "[62, 360] loss: 1.147\n",
      "Epoch: 62 -> Loss: 1.20420229435\n",
      "Epoch: 62 -> Test Accuracy: 53.7\n",
      "[63, 60] loss: 1.144\n",
      "[63, 120] loss: 1.159\n",
      "[63, 180] loss: 1.139\n",
      "[63, 240] loss: 1.148\n",
      "[63, 300] loss: 1.177\n",
      "[63, 360] loss: 1.137\n",
      "Epoch: 63 -> Loss: 1.22136712074\n",
      "Epoch: 63 -> Test Accuracy: 53.91\n",
      "[64, 60] loss: 1.168\n",
      "[64, 120] loss: 1.159\n",
      "[64, 180] loss: 1.129\n",
      "[64, 240] loss: 1.147\n",
      "[64, 300] loss: 1.139\n",
      "[64, 360] loss: 1.145\n",
      "Epoch: 64 -> Loss: 0.9995418787\n",
      "Epoch: 64 -> Test Accuracy: 53.91\n",
      "[65, 60] loss: 1.141\n",
      "[65, 120] loss: 1.153\n",
      "[65, 180] loss: 1.143\n",
      "[65, 240] loss: 1.143\n",
      "[65, 300] loss: 1.142\n",
      "[65, 360] loss: 1.162\n",
      "Epoch: 65 -> Loss: 1.08076930046\n",
      "Epoch: 65 -> Test Accuracy: 53.83\n",
      "[66, 60] loss: 1.152\n",
      "[66, 120] loss: 1.158\n",
      "[66, 180] loss: 1.136\n",
      "[66, 240] loss: 1.166\n",
      "[66, 300] loss: 1.139\n",
      "[66, 360] loss: 1.136\n",
      "Epoch: 66 -> Loss: 1.03643941879\n",
      "Epoch: 66 -> Test Accuracy: 54.08\n",
      "[67, 60] loss: 1.147\n",
      "[67, 120] loss: 1.146\n",
      "[67, 180] loss: 1.146\n",
      "[67, 240] loss: 1.146\n",
      "[67, 300] loss: 1.175\n",
      "[67, 360] loss: 1.161\n",
      "Epoch: 67 -> Loss: 1.27927052975\n",
      "Epoch: 67 -> Test Accuracy: 53.85\n",
      "[68, 60] loss: 1.147\n",
      "[68, 120] loss: 1.157\n",
      "[68, 180] loss: 1.143\n",
      "[68, 240] loss: 1.148\n",
      "[68, 300] loss: 1.144\n",
      "[68, 360] loss: 1.142\n",
      "Epoch: 68 -> Loss: 1.25751423836\n",
      "Epoch: 68 -> Test Accuracy: 54.13\n",
      "[69, 60] loss: 1.139\n",
      "[69, 120] loss: 1.168\n",
      "[69, 180] loss: 1.138\n",
      "[69, 240] loss: 1.135\n",
      "[69, 300] loss: 1.144\n",
      "[69, 360] loss: 1.156\n",
      "Epoch: 69 -> Loss: 1.22045636177\n",
      "Epoch: 69 -> Test Accuracy: 53.83\n",
      "[70, 60] loss: 1.147\n",
      "[70, 120] loss: 1.151\n",
      "[70, 180] loss: 1.150\n",
      "[70, 240] loss: 1.146\n",
      "[70, 300] loss: 1.122\n",
      "[70, 360] loss: 1.148\n",
      "Epoch: 70 -> Loss: 0.950262904167\n",
      "Epoch: 70 -> Test Accuracy: 53.65\n",
      "[71, 60] loss: 1.157\n",
      "[71, 120] loss: 1.127\n",
      "[71, 180] loss: 1.151\n",
      "[71, 240] loss: 1.178\n",
      "[71, 300] loss: 1.143\n",
      "[71, 360] loss: 1.138\n",
      "Epoch: 71 -> Loss: 1.02964651585\n",
      "Epoch: 71 -> Test Accuracy: 53.83\n",
      "[72, 60] loss: 1.148\n",
      "[72, 120] loss: 1.133\n",
      "[72, 180] loss: 1.111\n",
      "[72, 240] loss: 1.155\n",
      "[72, 300] loss: 1.140\n",
      "[72, 360] loss: 1.150\n",
      "Epoch: 72 -> Loss: 1.14374279976\n",
      "Epoch: 72 -> Test Accuracy: 53.86\n",
      "[73, 60] loss: 1.153\n",
      "[73, 120] loss: 1.143\n",
      "[73, 180] loss: 1.142\n",
      "[73, 240] loss: 1.153\n",
      "[73, 300] loss: 1.147\n",
      "[73, 360] loss: 1.131\n",
      "Epoch: 73 -> Loss: 1.16744399071\n",
      "Epoch: 73 -> Test Accuracy: 54.07\n",
      "[74, 60] loss: 1.158\n",
      "[74, 120] loss: 1.133\n",
      "[74, 180] loss: 1.138\n",
      "[74, 240] loss: 1.133\n",
      "[74, 300] loss: 1.146\n",
      "[74, 360] loss: 1.149\n",
      "Epoch: 74 -> Loss: 1.03210711479\n",
      "Epoch: 74 -> Test Accuracy: 54.0\n",
      "[75, 60] loss: 1.164\n",
      "[75, 120] loss: 1.152\n",
      "[75, 180] loss: 1.138\n",
      "[75, 240] loss: 1.140\n",
      "[75, 300] loss: 1.150\n",
      "[75, 360] loss: 1.133\n",
      "Epoch: 75 -> Loss: 1.02564013004\n",
      "Epoch: 75 -> Test Accuracy: 54.04\n",
      "[76, 60] loss: 1.143\n",
      "[76, 120] loss: 1.143\n",
      "[76, 180] loss: 1.151\n",
      "[76, 240] loss: 1.154\n",
      "[76, 300] loss: 1.141\n",
      "[76, 360] loss: 1.124\n",
      "Epoch: 76 -> Loss: 1.23263084888\n",
      "Epoch: 76 -> Test Accuracy: 53.89\n",
      "[77, 60] loss: 1.150\n",
      "[77, 120] loss: 1.124\n",
      "[77, 180] loss: 1.140\n",
      "[77, 240] loss: 1.142\n",
      "[77, 300] loss: 1.158\n",
      "[77, 360] loss: 1.141\n",
      "Epoch: 77 -> Loss: 1.18999922276\n",
      "Epoch: 77 -> Test Accuracy: 53.84\n",
      "[78, 60] loss: 1.155\n",
      "[78, 120] loss: 1.133\n",
      "[78, 180] loss: 1.122\n",
      "[78, 240] loss: 1.139\n",
      "[78, 300] loss: 1.140\n",
      "[78, 360] loss: 1.128\n",
      "Epoch: 78 -> Loss: 1.32205367088\n",
      "Epoch: 78 -> Test Accuracy: 54.32\n",
      "[79, 60] loss: 1.131\n",
      "[79, 120] loss: 1.133\n",
      "[79, 180] loss: 1.135\n",
      "[79, 240] loss: 1.133\n",
      "[79, 300] loss: 1.143\n",
      "[79, 360] loss: 1.133\n",
      "Epoch: 79 -> Loss: 1.37259197235\n",
      "Epoch: 79 -> Test Accuracy: 54.06\n",
      "[80, 60] loss: 1.140\n",
      "[80, 120] loss: 1.138\n",
      "[80, 180] loss: 1.134\n",
      "[80, 240] loss: 1.142\n",
      "[80, 300] loss: 1.138\n",
      "[80, 360] loss: 1.143\n",
      "Epoch: 80 -> Loss: 1.33836054802\n",
      "Epoch: 80 -> Test Accuracy: 54.11\n",
      "[81, 60] loss: 1.124\n",
      "[81, 120] loss: 1.129\n",
      "[81, 180] loss: 1.115\n",
      "[81, 240] loss: 1.129\n",
      "[81, 300] loss: 1.133\n",
      "[81, 360] loss: 1.139\n",
      "Epoch: 81 -> Loss: 1.20920598507\n",
      "Epoch: 81 -> Test Accuracy: 54.22\n",
      "[82, 60] loss: 1.137\n",
      "[82, 120] loss: 1.121\n",
      "[82, 180] loss: 1.137\n",
      "[82, 240] loss: 1.123\n",
      "[82, 300] loss: 1.130\n",
      "[82, 360] loss: 1.138\n",
      "Epoch: 82 -> Loss: 1.04067492485\n",
      "Epoch: 82 -> Test Accuracy: 54.1\n",
      "[83, 60] loss: 1.148\n",
      "[83, 120] loss: 1.122\n",
      "[83, 180] loss: 1.136\n",
      "[83, 240] loss: 1.121\n",
      "[83, 300] loss: 1.143\n",
      "[83, 360] loss: 1.120\n",
      "Epoch: 83 -> Loss: 0.943351387978\n",
      "Epoch: 83 -> Test Accuracy: 53.93\n",
      "[84, 60] loss: 1.137\n",
      "[84, 120] loss: 1.151\n",
      "[84, 180] loss: 1.133\n",
      "[84, 240] loss: 1.129\n",
      "[84, 300] loss: 1.113\n",
      "[84, 360] loss: 1.156\n",
      "Epoch: 84 -> Loss: 1.18425834179\n",
      "Epoch: 84 -> Test Accuracy: 54.27\n",
      "[85, 60] loss: 1.129\n",
      "[85, 120] loss: 1.138\n",
      "[85, 180] loss: 1.128\n",
      "[85, 240] loss: 1.122\n",
      "[85, 300] loss: 1.136\n",
      "[85, 360] loss: 1.120\n",
      "Epoch: 85 -> Loss: 1.11996746063\n",
      "Epoch: 85 -> Test Accuracy: 54.32\n",
      "[86, 60] loss: 1.113\n",
      "[86, 120] loss: 1.146\n",
      "[86, 180] loss: 1.143\n",
      "[86, 240] loss: 1.121\n",
      "[86, 300] loss: 1.129\n",
      "[86, 360] loss: 1.126\n",
      "Epoch: 86 -> Loss: 1.20799696445\n",
      "Epoch: 86 -> Test Accuracy: 54.29\n",
      "[87, 60] loss: 1.121\n",
      "[87, 120] loss: 1.155\n",
      "[87, 180] loss: 1.140\n",
      "[87, 240] loss: 1.110\n",
      "[87, 300] loss: 1.139\n",
      "[87, 360] loss: 1.111\n",
      "Epoch: 87 -> Loss: 1.35962677002\n",
      "Epoch: 87 -> Test Accuracy: 53.95\n",
      "[88, 60] loss: 1.128\n",
      "[88, 120] loss: 1.134\n",
      "[88, 180] loss: 1.123\n",
      "[88, 240] loss: 1.125\n",
      "[88, 300] loss: 1.125\n",
      "[88, 360] loss: 1.157\n",
      "Epoch: 88 -> Loss: 1.12541782856\n",
      "Epoch: 88 -> Test Accuracy: 54.1\n",
      "[89, 60] loss: 1.123\n",
      "[89, 120] loss: 1.137\n",
      "[89, 180] loss: 1.129\n",
      "[89, 240] loss: 1.122\n",
      "[89, 300] loss: 1.126\n",
      "[89, 360] loss: 1.142\n",
      "Epoch: 89 -> Loss: 1.39412915707\n",
      "Epoch: 89 -> Test Accuracy: 54.15\n",
      "[90, 60] loss: 1.132\n",
      "[90, 120] loss: 1.128\n",
      "[90, 180] loss: 1.126\n",
      "[90, 240] loss: 1.121\n",
      "[90, 300] loss: 1.118\n",
      "[90, 360] loss: 1.138\n",
      "Epoch: 90 -> Loss: 1.15801095963\n",
      "Epoch: 90 -> Test Accuracy: 54.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[91, 60] loss: 1.156\n",
      "[91, 120] loss: 1.133\n",
      "[91, 180] loss: 1.121\n",
      "[91, 240] loss: 1.136\n",
      "[91, 300] loss: 1.130\n",
      "[91, 360] loss: 1.132\n",
      "Epoch: 91 -> Loss: 1.09939694405\n",
      "Epoch: 91 -> Test Accuracy: 54.37\n",
      "[92, 60] loss: 1.145\n",
      "[92, 120] loss: 1.118\n",
      "[92, 180] loss: 1.112\n",
      "[92, 240] loss: 1.145\n",
      "[92, 300] loss: 1.108\n",
      "[92, 360] loss: 1.145\n",
      "Epoch: 92 -> Loss: 1.24633836746\n",
      "Epoch: 92 -> Test Accuracy: 54.29\n",
      "[93, 60] loss: 1.136\n",
      "[93, 120] loss: 1.124\n",
      "[93, 180] loss: 1.138\n",
      "[93, 240] loss: 1.124\n",
      "[93, 300] loss: 1.132\n",
      "[93, 360] loss: 1.119\n",
      "Epoch: 93 -> Loss: 1.10955047607\n",
      "Epoch: 93 -> Test Accuracy: 54.27\n",
      "[94, 60] loss: 1.124\n",
      "[94, 120] loss: 1.106\n",
      "[94, 180] loss: 1.142\n",
      "[94, 240] loss: 1.140\n",
      "[94, 300] loss: 1.127\n",
      "[94, 360] loss: 1.129\n",
      "Epoch: 94 -> Loss: 1.20155501366\n",
      "Epoch: 94 -> Test Accuracy: 54.45\n",
      "[95, 60] loss: 1.118\n",
      "[95, 120] loss: 1.138\n",
      "[95, 180] loss: 1.129\n",
      "[95, 240] loss: 1.133\n",
      "[95, 300] loss: 1.136\n",
      "[95, 360] loss: 1.130\n",
      "Epoch: 95 -> Loss: 0.918730735779\n",
      "Epoch: 95 -> Test Accuracy: 54.25\n",
      "[96, 60] loss: 1.128\n",
      "[96, 120] loss: 1.116\n",
      "[96, 180] loss: 1.140\n",
      "[96, 240] loss: 1.123\n",
      "[96, 300] loss: 1.131\n",
      "[96, 360] loss: 1.123\n",
      "Epoch: 96 -> Loss: 1.27564752102\n",
      "Epoch: 96 -> Test Accuracy: 54.17\n",
      "[97, 60] loss: 1.124\n",
      "[97, 120] loss: 1.123\n",
      "[97, 180] loss: 1.106\n",
      "[97, 240] loss: 1.115\n",
      "[97, 300] loss: 1.139\n",
      "[97, 360] loss: 1.128\n",
      "Epoch: 97 -> Loss: 1.06130695343\n",
      "Epoch: 97 -> Test Accuracy: 54.37\n",
      "[98, 60] loss: 1.107\n",
      "[98, 120] loss: 1.128\n",
      "[98, 180] loss: 1.112\n",
      "[98, 240] loss: 1.138\n",
      "[98, 300] loss: 1.127\n",
      "[98, 360] loss: 1.142\n",
      "Epoch: 98 -> Loss: 1.23829877377\n",
      "Epoch: 98 -> Test Accuracy: 54.01\n",
      "[99, 60] loss: 1.135\n",
      "[99, 120] loss: 1.138\n",
      "[99, 180] loss: 1.130\n",
      "[99, 240] loss: 1.126\n",
      "[99, 300] loss: 1.100\n",
      "[99, 360] loss: 1.136\n",
      "Epoch: 99 -> Loss: 1.20202481747\n",
      "Epoch: 99 -> Test Accuracy: 54.47\n",
      "[100, 60] loss: 1.106\n",
      "[100, 120] loss: 1.110\n",
      "[100, 180] loss: 1.129\n",
      "[100, 240] loss: 1.139\n",
      "[100, 300] loss: 1.121\n",
      "[100, 360] loss: 1.133\n",
      "Epoch: 100 -> Loss: 1.06607985497\n",
      "Epoch: 100 -> Test Accuracy: 54.4\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train NonLinearClassifiers on feature map of net_3block\n",
    "block3_loss_log, block3_valid_accuracy_log, block3_test_accuracy_log, block3_max_accuracy, block3_best_epoch = \\\n",
    "tr.train_all_blocks(3, 10, [0.1, 0.02, 0.004, 0.0008], [20, 40, 45, 100], 0.9, 5e-4, net_block3, criterion, trainloader,\n",
    "                    None, testloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight[192, 24576, 3, 3], so expected input[128, 96, 16, 16] to have 24576 channels, but got 96 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-df7408d0d501>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train ConvClassifiers on feature map of net_3block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m conv_block3_loss_log, conv_block3_valid_accuracy_log, conv_block3_test_accuracy_log, conv_block3_max_accuracy, conv_block3_best_epoch = tr.train_all_blocks(3, 10, [0.1, 0.02, 0.004, 0.0008], [35, 70, 85, 100], 0.9, 5e-4, net_block3, \n\u001b[0;32m----> 3\u001b[0;31m                                             criterion, trainloader, None, testloader, use_ConvClassifier=True) \n\u001b[0m",
      "\u001b[0;32m/home/leo/Dropbox/Bachelorarbeit/Peer Review FeatureLearningRotNet/functionalities/trainer.pyc\u001b[0m in \u001b[0;36mtrain_all_blocks\u001b[0;34m(conv_block_num, num_classes, lr_list, epoch_change, momentum, weight_decay, net, criterion, trainloader, validloader, testloader, use_paper_metric, use_ConvClassifier)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mtmp_loss_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_valid_accuracy_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_test_accuracy_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_max_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_best_epoch\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             adaptive_learning(lr_list, epoch_change, momentum, weight_decay, net, criterion, trainloader, validloader,\n\u001b[0;32m--> 332\u001b[0;31m                               testloader, clf, i+1, None, use_paper_metric, use_ConvClassifier)\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mloss_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_loss_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/Dropbox/Bachelorarbeit/Peer Review FeatureLearningRotNet/functionalities/trainer.pyc\u001b[0m in \u001b[0;36madaptive_learning\u001b[0;34m(lr_list, epoch_change, momentum, weight_decay, net, criterion, trainloader, validloader, testloader, classifier, conv_block_num, rot, use_paper_metric, use_ConvClassifier)\u001b[0m\n\u001b[1;32m    274\u001b[0m             train(num_epoch, net, criterion, optimizer, trainloader, validloader, testloader, classifier,\n\u001b[1;32m    275\u001b[0m                   \u001b[0mconv_block_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprinting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_paper_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                   use_ConvClassifier)\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mloss_log\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtmp_loss_log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/Dropbox/Bachelorarbeit/Peer Review FeatureLearningRotNet/functionalities/trainer.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_epoch, net, criterion, optimizer, trainloader, validloader, testloader, classifier, conv_block_num, epoch_offset, rot, printing, max_accuracy, best_epoch, use_paper_metric, use_ConvClassifier)\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                     \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_feat_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_feat_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconv_block_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/Dropbox/Bachelorarbeit/Peer Review FeatureLearningRotNet/architecture/ConvClassifier.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, feat)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \"\"\"\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/torch/nn/modules/container.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/Dropbox/Bachelorarbeit/Peer Review FeatureLearningRotNet/architecture/ConvBlock.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \"\"\"\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/leo/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/torch/nn/modules/container.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/Dropbox/Bachelorarbeit/Peer Review FeatureLearningRotNet/architecture/BasicBlock.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \"\"\"\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/leo/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/torch/nn/modules/container.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/anaconda3/envs/ipykernel_py2/lib/python2.7/site-packages/torch/nn/modules/conv.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight[192, 24576, 3, 3], so expected input[128, 96, 16, 16] to have 24576 channels, but got 96 channels instead"
     ]
    }
   ],
   "source": [
    "# train ConvClassifiers on feature map of net_3block\n",
    "conv_block3_loss_log, conv_block3_valid_accuracy_log, conv_block3_test_accuracy_log, conv_block3_max_accuracy, \\\n",
    "conv_block3_best_epoch = tr.train_all_blocks(3, 10, [0.1, 0.02, 0.004, 0.0008], [35, 70, 85, 100], 0.9, 5e-4, net_block3, \n",
    "                                            criterion, trainloader, None, testloader, use_ConvClassifier=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename files\n",
    "fm.add_block_to_name(3, [100, 200], list(rot_block3_best_epoch) + block3_best_epoch + conv_block3_best_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Block RotNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "net_block4 = RN.RotNet(num_classes=4, num_conv_block=4, add_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train network\n",
    "rot_block4_loss_log, rot_block4_valid_accuracy_log, rot_block4_test_accuracy_log, rot_block4_max_accuracy, \\\n",
    "rot_block4_best_epoch = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], [60, 120, 160, 200], 0.9, 5e-4, net_block4, \n",
    "                                             criterion, trainloader, None, testloader, rot=['90', '180', '270'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train NonLinearClassifiers on feature map of net_3block\n",
    "block4_loss_log, block4_valid_accuracy_log, block4_test_accuracy_log, block4_max_accuracy, block4_best_epoch = \\\n",
    "tr.train_all_blocks(4, 10, [0.1, 0.02, 0.004, 0.0008], [20, 40, 45, 100], 0.9, 5e-4, net_block4, criterion, trainloader,\n",
    "                    None, testloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train ConvClassifiers on feature map of net_3block\n",
    "conv_block4_loss_log, conv_block4_valid_accuracy_log, conv_block4_test_accuracy_log, conv_block4_max_accuracy, \\\n",
    "conv_block4_best_epoch = tr.train_all_blocks(4, 10, [0.1, 0.02, 0.004, 0.0008], [35, 70, 85, 100], 0.9, 5e-4, net_block4, \n",
    "                                            criterion, trainloader, None, testloader, use_ConvClassifier=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename files\n",
    "fm.add_block_to_name(4, [100, 200], list(rot_block4_best_epoch) + block4_best_epoch + conv_block4_best_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Block RotNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "net_block5 = RN.RotNet(num_classes=4, num_conv_block=5, add_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train network\n",
    "rot_block5_loss_log, rot_block5_valid_accuracy_log, rot_block5_test_accuracy_log, rot_block5_max_accuracy, \\\n",
    "rot_block5_best_epoch = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], [60, 120, 160, 200], 0.9, 5e-4, net_block5, \n",
    "                                             criterion, trainloader, None, testloader, rot=['90', '180', '270'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train NonLinearClassifiers on feature map of net_3block\n",
    "block5_loss_log, block5_valid_accuracy_log, block5_test_accuracy_log, block5_max_accuracy, block5_best_epoch = \\\n",
    "tr.train_all_blocks(5, 10, [0.1, 0.02, 0.004, 0.0008], [20, 40, 45, 100], 0.9, 5e-4, net_block5, criterion, trainloader,\n",
    "                    None, testloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train ConvClassifiers on feature map of net_3block\n",
    "conv_block5_loss_log, conv_block5_valid_accuracy_log, conv_block5_test_accuracy_log, conv_block5_max_accuracy, \\\n",
    "conv_block5_best_epoch = tr.train_all_blocks(5, 10, [0.1, 0.02, 0.004, 0.0008], [35, 70, 85, 100], 0.9, 5e-4, net_block5, \n",
    "                                            criterion, trainloader, None, testloader, use_ConvClassifier=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename files\n",
    "fm.add_block_to_name(5, [100, 200], list(rot_block5_best_epoch) + block5_best_epoch + conv_block5_best_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Block RotNet with Average Pooling after ConvBlock 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "net_block5_avg = RN.RotNet(num_classes=4, num_conv_block=5, add_avg_pool=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train network\n",
    "rot_block5_avg_loss_log, rot_block5_avg_valid_accuracy_log, rot_block5_avg_test_accuracy_log, \\\n",
    "rot_block5_avg_max_accuracy, rot_block5_avg_best_epoch = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], \n",
    "    [60, 120, 160, 200], 0.9, 5e-4, net_block5_avg, criterion, trainloader, None, testloader, rot=['90', '180', '270'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train NonLinearClassifiers on feature map of net_3block\n",
    "block5_avg_loss_log, block5_avg_valid_accuracy_log, block5_avg_test_accuracy_log, block5_avg_max_accuracy, \\\n",
    "block5_best_epoch = tr.train_all_blocks(5, 10, [0.1, 0.02, 0.004, 0.0008], [20, 40, 45, 100], 0.9, 5e-4, net_block5_avg, \n",
    "                                        criterion, trainloader, None, testloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train ConvClassifiers on feature map of net_3block\n",
    "conv_block5_avg_loss_log, conv_block5_avg_valid_accuracy_log, conv_block5_avg_test_accuracy_log, \\\n",
    "conv_block5_avg_max_accuracy, conv_block5_avg_best_epoch = tr.train_all_blocks(5, 10, [0.1, 0.02, 0.004, 0.0008], \\\n",
    "    [35, 70, 85, 100], 0.9, 5e-4, net_block5_avg, criterion, trainloader, None, testloader, use_ConvClassifier=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename files\n",
    "fm.add_block_to_name(5, [100, 200], list(rot_block5_avg_best_epoch) + block5_avg_best_epoch + conv_block5_avg_best_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised NIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In the code of the paper a 3 convolutional block RotNet was used for the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize networks\n",
    "net_class = RN.RotNet(num_classes=10, num_conv_block=3, add_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 3 block RotNet on classification task\n",
    "class_NIN_loss_log, class_NIN_valid_accuracy_log, class_NIN_test_accuracy_log, class_NIN_max_accuracy, \\\n",
    "class_NIN_best_epoch = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], [60, 120, 160, 200], 0.9, 5e-4, net_class, \n",
    "                                            criterion, trainloader, None, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
