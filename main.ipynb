{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from functionalities import dataloader as dl\n",
    "from functionalities import evaluater as ev\n",
    "from functionalities import filemanager as fm\n",
    "from functionalities import trainer as tr\n",
    "from functionalities import plot as p\n",
    "from architecture import RotNet as RN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset, testset, classes = dl.load_cifar(\"./datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, validloader, testloader = dl.make_dataloaders(trainset, testset, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Loss Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train RotNet for Rotation Task and Classifiers on Feature Maps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set rot classes\n",
    "rot_classes = ['original', '90 rotation', '180 rotation', '270 rotation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Block RotNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "net_block3 = RN.RotNet(num_classes=4, num_conv_block=3, add_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.131\n",
      "[1, 120] loss: 0.976\n",
      "[1, 180] loss: 0.907\n",
      "[1, 240] loss: 0.849\n",
      "[1, 300] loss: 0.791\n",
      "[1, 360] loss: 0.766\n",
      "Epoch: 1 -> Loss: 0.680784225464\n",
      "Epoch: 1 -> Test Accuracy: 69.8975\n",
      "[2, 60] loss: 0.699\n",
      "[2, 120] loss: 0.683\n",
      "[2, 180] loss: 0.672\n",
      "[2, 240] loss: 0.659\n",
      "[2, 300] loss: 0.638\n",
      "[2, 360] loss: 0.626\n",
      "Epoch: 2 -> Loss: 0.737947106361\n",
      "Epoch: 2 -> Test Accuracy: 75.53\n",
      "[3, 60] loss: 0.608\n",
      "[3, 120] loss: 0.595\n",
      "[3, 180] loss: 0.579\n",
      "[3, 240] loss: 0.557\n",
      "[3, 300] loss: 0.571\n",
      "[3, 360] loss: 0.547\n",
      "Epoch: 3 -> Loss: 0.533422529697\n",
      "Epoch: 3 -> Test Accuracy: 77.88\n",
      "[4, 60] loss: 0.527\n",
      "[4, 120] loss: 0.535\n",
      "[4, 180] loss: 0.514\n",
      "[4, 240] loss: 0.510\n",
      "[4, 300] loss: 0.519\n",
      "[4, 360] loss: 0.513\n",
      "Epoch: 4 -> Loss: 0.522677898407\n",
      "Epoch: 4 -> Test Accuracy: 80.2525\n",
      "[5, 60] loss: 0.492\n",
      "[5, 120] loss: 0.486\n",
      "[5, 180] loss: 0.503\n",
      "[5, 240] loss: 0.487\n",
      "[5, 300] loss: 0.486\n",
      "[5, 360] loss: 0.464\n",
      "Epoch: 5 -> Loss: 0.504644989967\n",
      "Epoch: 5 -> Test Accuracy: 80.67\n",
      "[6, 60] loss: 0.462\n",
      "[6, 120] loss: 0.472\n",
      "[6, 180] loss: 0.450\n",
      "[6, 240] loss: 0.462\n",
      "[6, 300] loss: 0.464\n",
      "[6, 360] loss: 0.456\n",
      "Epoch: 6 -> Loss: 0.686868667603\n",
      "Epoch: 6 -> Test Accuracy: 82.02\n",
      "[7, 60] loss: 0.437\n",
      "[7, 120] loss: 0.433\n",
      "[7, 180] loss: 0.445\n",
      "[7, 240] loss: 0.448\n",
      "[7, 300] loss: 0.437\n",
      "[7, 360] loss: 0.431\n",
      "Epoch: 7 -> Loss: 0.490416586399\n",
      "Epoch: 7 -> Test Accuracy: 83.1925\n",
      "[8, 60] loss: 0.424\n",
      "[8, 120] loss: 0.422\n",
      "[8, 180] loss: 0.424\n",
      "[8, 240] loss: 0.421\n",
      "[8, 300] loss: 0.430\n",
      "[8, 360] loss: 0.428\n",
      "Epoch: 8 -> Loss: 0.553188621998\n",
      "Epoch: 8 -> Test Accuracy: 83.96\n",
      "[9, 60] loss: 0.406\n",
      "[9, 120] loss: 0.398\n",
      "[9, 180] loss: 0.418\n",
      "[9, 240] loss: 0.418\n",
      "[9, 300] loss: 0.414\n",
      "[9, 360] loss: 0.397\n",
      "Epoch: 9 -> Loss: 0.507232546806\n",
      "Epoch: 9 -> Test Accuracy: 83.215\n",
      "[10, 60] loss: 0.395\n",
      "[10, 120] loss: 0.401\n",
      "[10, 180] loss: 0.384\n",
      "[10, 240] loss: 0.397\n",
      "[10, 300] loss: 0.415\n",
      "[10, 360] loss: 0.401\n",
      "Epoch: 10 -> Loss: 0.604861021042\n",
      "Epoch: 10 -> Test Accuracy: 84.5325\n",
      "[11, 60] loss: 0.387\n",
      "[11, 120] loss: 0.394\n",
      "[11, 180] loss: 0.394\n",
      "[11, 240] loss: 0.400\n",
      "[11, 300] loss: 0.394\n",
      "[11, 360] loss: 0.383\n",
      "Epoch: 11 -> Loss: 0.423508107662\n",
      "Epoch: 11 -> Test Accuracy: 83.875\n",
      "[12, 60] loss: 0.379\n",
      "[12, 120] loss: 0.381\n",
      "[12, 180] loss: 0.379\n",
      "[12, 240] loss: 0.389\n",
      "[12, 300] loss: 0.379\n",
      "[12, 360] loss: 0.393\n",
      "Epoch: 12 -> Loss: 0.480721771717\n",
      "Epoch: 12 -> Test Accuracy: 84.8025\n",
      "[13, 60] loss: 0.364\n",
      "[13, 120] loss: 0.369\n",
      "[13, 180] loss: 0.391\n",
      "[13, 240] loss: 0.375\n",
      "[13, 300] loss: 0.369\n",
      "[13, 360] loss: 0.383\n",
      "Epoch: 13 -> Loss: 0.347966581583\n",
      "Epoch: 13 -> Test Accuracy: 84.84\n",
      "[14, 60] loss: 0.359\n",
      "[14, 120] loss: 0.366\n",
      "[14, 180] loss: 0.374\n",
      "[14, 240] loss: 0.367\n",
      "[14, 300] loss: 0.372\n",
      "[14, 360] loss: 0.363\n",
      "Epoch: 14 -> Loss: 0.288730978966\n",
      "Epoch: 14 -> Test Accuracy: 84.1175\n",
      "[15, 60] loss: 0.352\n",
      "[15, 120] loss: 0.357\n",
      "[15, 180] loss: 0.353\n",
      "[15, 240] loss: 0.380\n",
      "[15, 300] loss: 0.365\n",
      "[15, 360] loss: 0.362\n",
      "Epoch: 15 -> Loss: 0.427661657333\n",
      "Epoch: 15 -> Test Accuracy: 84.1675\n",
      "[16, 60] loss: 0.346\n",
      "[16, 120] loss: 0.362\n",
      "[16, 180] loss: 0.364\n",
      "[16, 240] loss: 0.353\n",
      "[16, 300] loss: 0.362\n",
      "[16, 360] loss: 0.359\n",
      "Epoch: 16 -> Loss: 0.345564126968\n",
      "Epoch: 16 -> Test Accuracy: 85.19\n",
      "[17, 60] loss: 0.341\n",
      "[17, 120] loss: 0.346\n",
      "[17, 180] loss: 0.354\n",
      "[17, 240] loss: 0.355\n",
      "[17, 300] loss: 0.373\n",
      "[17, 360] loss: 0.366\n",
      "Epoch: 17 -> Loss: 0.327844202518\n",
      "Epoch: 17 -> Test Accuracy: 85.03\n",
      "[18, 60] loss: 0.339\n",
      "[18, 120] loss: 0.344\n",
      "[18, 180] loss: 0.340\n",
      "[18, 240] loss: 0.350\n",
      "[18, 300] loss: 0.368\n",
      "[18, 360] loss: 0.368\n",
      "Epoch: 18 -> Loss: 0.337501138449\n",
      "Epoch: 18 -> Test Accuracy: 85.5825\n",
      "[19, 60] loss: 0.332\n",
      "[19, 120] loss: 0.345\n",
      "[19, 180] loss: 0.355\n",
      "[19, 240] loss: 0.342\n",
      "[19, 300] loss: 0.350\n",
      "[19, 360] loss: 0.344\n",
      "Epoch: 19 -> Loss: 0.247544571757\n",
      "Epoch: 19 -> Test Accuracy: 85.9075\n",
      "[20, 60] loss: 0.326\n",
      "[20, 120] loss: 0.342\n",
      "[20, 180] loss: 0.346\n",
      "[20, 240] loss: 0.343\n",
      "[20, 300] loss: 0.346\n",
      "[20, 360] loss: 0.347\n",
      "Epoch: 20 -> Loss: 0.249266415834\n",
      "Epoch: 20 -> Test Accuracy: 85.0625\n",
      "[21, 60] loss: 0.331\n",
      "[21, 120] loss: 0.344\n",
      "[21, 180] loss: 0.340\n",
      "[21, 240] loss: 0.351\n",
      "[21, 300] loss: 0.340\n",
      "[21, 360] loss: 0.338\n",
      "Epoch: 21 -> Loss: 0.35905867815\n",
      "Epoch: 21 -> Test Accuracy: 86.1825\n",
      "[22, 60] loss: 0.321\n",
      "[22, 120] loss: 0.331\n",
      "[22, 180] loss: 0.336\n",
      "[22, 240] loss: 0.356\n",
      "[22, 300] loss: 0.338\n",
      "[22, 360] loss: 0.336\n",
      "Epoch: 22 -> Loss: 0.357327342033\n",
      "Epoch: 22 -> Test Accuracy: 86.455\n",
      "[23, 60] loss: 0.324\n",
      "[23, 120] loss: 0.339\n",
      "[23, 180] loss: 0.333\n",
      "[23, 240] loss: 0.330\n",
      "[23, 300] loss: 0.343\n",
      "[23, 360] loss: 0.351\n",
      "Epoch: 23 -> Loss: 0.312273919582\n",
      "Epoch: 23 -> Test Accuracy: 85.96\n",
      "[24, 60] loss: 0.319\n",
      "[24, 120] loss: 0.330\n",
      "[24, 180] loss: 0.336\n",
      "[24, 240] loss: 0.341\n",
      "[24, 300] loss: 0.331\n",
      "[24, 360] loss: 0.332\n",
      "Epoch: 24 -> Loss: 0.337024748325\n",
      "Epoch: 24 -> Test Accuracy: 84.885\n",
      "[25, 60] loss: 0.322\n",
      "[25, 120] loss: 0.332\n",
      "[25, 180] loss: 0.331\n",
      "[25, 240] loss: 0.323\n",
      "[25, 300] loss: 0.342\n",
      "[25, 360] loss: 0.325\n",
      "Epoch: 25 -> Loss: 0.367140382528\n",
      "Epoch: 25 -> Test Accuracy: 86.985\n",
      "[26, 60] loss: 0.312\n",
      "[26, 120] loss: 0.342\n",
      "[26, 180] loss: 0.336\n",
      "[26, 240] loss: 0.318\n",
      "[26, 300] loss: 0.321\n",
      "[26, 360] loss: 0.338\n",
      "Epoch: 26 -> Loss: 0.253477871418\n",
      "Epoch: 26 -> Test Accuracy: 86.5925\n",
      "[27, 60] loss: 0.312\n",
      "[27, 120] loss: 0.325\n",
      "[27, 180] loss: 0.316\n",
      "[27, 240] loss: 0.334\n",
      "[27, 300] loss: 0.320\n",
      "[27, 360] loss: 0.334\n",
      "Epoch: 27 -> Loss: 0.378106564283\n",
      "Epoch: 27 -> Test Accuracy: 86.01\n",
      "[28, 60] loss: 0.322\n",
      "[28, 120] loss: 0.313\n",
      "[28, 180] loss: 0.324\n",
      "[28, 240] loss: 0.332\n",
      "[28, 300] loss: 0.322\n",
      "[28, 360] loss: 0.335\n",
      "Epoch: 28 -> Loss: 0.339754790068\n",
      "Epoch: 28 -> Test Accuracy: 85.335\n",
      "[29, 60] loss: 0.312\n",
      "[29, 120] loss: 0.319\n",
      "[29, 180] loss: 0.314\n",
      "[29, 240] loss: 0.321\n",
      "[29, 300] loss: 0.311\n",
      "[29, 360] loss: 0.360\n",
      "Epoch: 29 -> Loss: 0.333819776773\n",
      "Epoch: 29 -> Test Accuracy: 86.7\n",
      "[30, 60] loss: 0.301\n",
      "[30, 120] loss: 0.317\n",
      "[30, 180] loss: 0.328\n",
      "[30, 240] loss: 0.313\n",
      "[30, 300] loss: 0.330\n",
      "[30, 360] loss: 0.323\n",
      "Epoch: 30 -> Loss: 0.36256891489\n",
      "Epoch: 30 -> Test Accuracy: 86.6425\n",
      "[31, 60] loss: 0.317\n",
      "[31, 120] loss: 0.311\n",
      "[31, 180] loss: 0.319\n",
      "[31, 240] loss: 0.328\n",
      "[31, 300] loss: 0.325\n",
      "[31, 360] loss: 0.320\n",
      "Epoch: 31 -> Loss: 0.251239985228\n",
      "Epoch: 31 -> Test Accuracy: 87.04\n",
      "[32, 60] loss: 0.300\n",
      "[32, 120] loss: 0.321\n",
      "[32, 180] loss: 0.322\n",
      "[32, 240] loss: 0.328\n",
      "[32, 300] loss: 0.306\n",
      "[32, 360] loss: 0.324\n",
      "Epoch: 32 -> Loss: 0.334061086178\n",
      "Epoch: 32 -> Test Accuracy: 86.39\n",
      "[33, 60] loss: 0.304\n",
      "[33, 120] loss: 0.311\n",
      "[33, 180] loss: 0.318\n",
      "[33, 240] loss: 0.323\n",
      "[33, 300] loss: 0.322\n",
      "[33, 360] loss: 0.332\n",
      "Epoch: 33 -> Loss: 0.217529252172\n",
      "Epoch: 33 -> Test Accuracy: 87.0375\n",
      "[34, 60] loss: 0.305\n",
      "[34, 120] loss: 0.314\n",
      "[34, 180] loss: 0.313\n",
      "[34, 240] loss: 0.332\n",
      "[34, 300] loss: 0.310\n",
      "[34, 360] loss: 0.322\n",
      "Epoch: 34 -> Loss: 0.252018988132\n",
      "Epoch: 34 -> Test Accuracy: 86.9325\n",
      "[35, 60] loss: 0.303\n",
      "[35, 120] loss: 0.314\n",
      "[35, 180] loss: 0.299\n",
      "[35, 240] loss: 0.327\n",
      "[35, 300] loss: 0.319\n",
      "[35, 360] loss: 0.317\n",
      "Epoch: 35 -> Loss: 0.302196979523\n",
      "Epoch: 35 -> Test Accuracy: 86.3425\n",
      "[36, 60] loss: 0.307\n",
      "[36, 120] loss: 0.321\n",
      "[36, 180] loss: 0.316\n",
      "[36, 240] loss: 0.316\n",
      "[36, 300] loss: 0.333\n",
      "[36, 360] loss: 0.303\n",
      "Epoch: 36 -> Loss: 0.31414026022\n",
      "Epoch: 36 -> Test Accuracy: 86.255\n",
      "[37, 60] loss: 0.299\n",
      "[37, 120] loss: 0.317\n",
      "[37, 180] loss: 0.316\n",
      "[37, 240] loss: 0.310\n",
      "[37, 300] loss: 0.311\n",
      "[37, 360] loss: 0.314\n",
      "Epoch: 37 -> Loss: 0.367029428482\n",
      "Epoch: 37 -> Test Accuracy: 86.2375\n",
      "[38, 60] loss: 0.309\n",
      "[38, 120] loss: 0.301\n",
      "[38, 180] loss: 0.311\n",
      "[38, 240] loss: 0.298\n",
      "[38, 300] loss: 0.318\n",
      "[38, 360] loss: 0.330\n",
      "Epoch: 38 -> Loss: 0.299027621746\n",
      "Epoch: 38 -> Test Accuracy: 86.9875\n",
      "[39, 60] loss: 0.305\n",
      "[39, 120] loss: 0.302\n",
      "[39, 180] loss: 0.306\n",
      "[39, 240] loss: 0.304\n",
      "[39, 300] loss: 0.322\n",
      "[39, 360] loss: 0.325\n",
      "Epoch: 39 -> Loss: 0.314734816551\n",
      "Epoch: 39 -> Test Accuracy: 87.3675\n",
      "[40, 60] loss: 0.315\n",
      "[40, 120] loss: 0.293\n",
      "[40, 180] loss: 0.313\n",
      "[40, 240] loss: 0.303\n",
      "[40, 300] loss: 0.313\n",
      "[40, 360] loss: 0.311\n",
      "Epoch: 40 -> Loss: 0.36648273468\n",
      "Epoch: 40 -> Test Accuracy: 86.3725\n",
      "[41, 60] loss: 0.294\n",
      "[41, 120] loss: 0.302\n",
      "[41, 180] loss: 0.305\n",
      "[41, 240] loss: 0.317\n",
      "[41, 300] loss: 0.317\n",
      "[41, 360] loss: 0.323\n",
      "Epoch: 41 -> Loss: 0.264878213406\n",
      "Epoch: 41 -> Test Accuracy: 86.8\n",
      "[42, 60] loss: 0.316\n",
      "[42, 120] loss: 0.306\n",
      "[42, 180] loss: 0.298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 240] loss: 0.310\n",
      "[42, 300] loss: 0.320\n",
      "[42, 360] loss: 0.303\n",
      "Epoch: 42 -> Loss: 0.324565410614\n",
      "Epoch: 42 -> Test Accuracy: 86.6675\n",
      "[43, 60] loss: 0.300\n",
      "[43, 120] loss: 0.299\n",
      "[43, 180] loss: 0.306\n",
      "[43, 240] loss: 0.317\n",
      "[43, 300] loss: 0.308\n",
      "[43, 360] loss: 0.325\n",
      "Epoch: 43 -> Loss: 0.44145283103\n",
      "Epoch: 43 -> Test Accuracy: 87.7575\n",
      "[44, 60] loss: 0.302\n",
      "[44, 120] loss: 0.300\n",
      "[44, 180] loss: 0.304\n",
      "[44, 240] loss: 0.310\n",
      "[44, 300] loss: 0.315\n",
      "[44, 360] loss: 0.323\n",
      "Epoch: 44 -> Loss: 0.278142631054\n",
      "Epoch: 44 -> Test Accuracy: 86.5475\n",
      "[45, 60] loss: 0.295\n",
      "[45, 120] loss: 0.288\n",
      "[45, 180] loss: 0.320\n",
      "[45, 240] loss: 0.310\n",
      "[45, 300] loss: 0.307\n",
      "[45, 360] loss: 0.303\n",
      "Epoch: 45 -> Loss: 0.273495495319\n",
      "Epoch: 45 -> Test Accuracy: 86.545\n",
      "[46, 60] loss: 0.298\n",
      "[46, 120] loss: 0.302\n",
      "[46, 180] loss: 0.308\n",
      "[46, 240] loss: 0.322\n",
      "[46, 300] loss: 0.309\n",
      "[46, 360] loss: 0.310\n",
      "Epoch: 46 -> Loss: 0.282479614019\n",
      "Epoch: 46 -> Test Accuracy: 86.7825\n",
      "[47, 60] loss: 0.296\n",
      "[47, 120] loss: 0.293\n",
      "[47, 180] loss: 0.307\n",
      "[47, 240] loss: 0.290\n",
      "[47, 300] loss: 0.311\n",
      "[47, 360] loss: 0.314\n",
      "Epoch: 47 -> Loss: 0.389905512333\n",
      "Epoch: 47 -> Test Accuracy: 85.595\n",
      "[48, 60] loss: 0.289\n",
      "[48, 120] loss: 0.313\n",
      "[48, 180] loss: 0.303\n",
      "[48, 240] loss: 0.304\n",
      "[48, 300] loss: 0.307\n",
      "[48, 360] loss: 0.315\n",
      "Epoch: 48 -> Loss: 0.234692662954\n",
      "Epoch: 48 -> Test Accuracy: 86.9425\n",
      "[49, 60] loss: 0.280\n",
      "[49, 120] loss: 0.297\n",
      "[49, 180] loss: 0.310\n",
      "[49, 240] loss: 0.319\n",
      "[49, 300] loss: 0.302\n",
      "[49, 360] loss: 0.311\n",
      "Epoch: 49 -> Loss: 0.283383756876\n",
      "Epoch: 49 -> Test Accuracy: 85.935\n",
      "[50, 60] loss: 0.308\n",
      "[50, 120] loss: 0.305\n",
      "[50, 180] loss: 0.300\n",
      "[50, 240] loss: 0.312\n",
      "[50, 300] loss: 0.300\n",
      "[50, 360] loss: 0.302\n",
      "Epoch: 50 -> Loss: 0.30039536953\n",
      "Epoch: 50 -> Test Accuracy: 85.67\n",
      "[51, 60] loss: 0.283\n",
      "[51, 120] loss: 0.291\n",
      "[51, 180] loss: 0.307\n",
      "[51, 240] loss: 0.308\n",
      "[51, 300] loss: 0.307\n",
      "[51, 360] loss: 0.307\n",
      "Epoch: 51 -> Loss: 0.339302152395\n",
      "Epoch: 51 -> Test Accuracy: 86.7925\n",
      "[52, 60] loss: 0.286\n",
      "[52, 120] loss: 0.300\n",
      "[52, 180] loss: 0.319\n",
      "[52, 240] loss: 0.298\n",
      "[52, 300] loss: 0.302\n",
      "[52, 360] loss: 0.299\n",
      "Epoch: 52 -> Loss: 0.280481874943\n",
      "Epoch: 52 -> Test Accuracy: 86.695\n",
      "[53, 60] loss: 0.291\n",
      "[53, 120] loss: 0.302\n",
      "[53, 180] loss: 0.304\n",
      "[53, 240] loss: 0.310\n",
      "[53, 300] loss: 0.304\n",
      "[53, 360] loss: 0.300\n",
      "Epoch: 53 -> Loss: 0.247449919581\n",
      "Epoch: 53 -> Test Accuracy: 86.46\n",
      "[54, 60] loss: 0.300\n",
      "[54, 120] loss: 0.302\n",
      "[54, 180] loss: 0.303\n",
      "[54, 240] loss: 0.295\n",
      "[54, 300] loss: 0.304\n",
      "[54, 360] loss: 0.309\n",
      "Epoch: 54 -> Loss: 0.283528625965\n",
      "Epoch: 54 -> Test Accuracy: 86.6175\n",
      "[55, 60] loss: 0.279\n",
      "[55, 120] loss: 0.304\n",
      "[55, 180] loss: 0.308\n",
      "[55, 240] loss: 0.290\n",
      "[55, 300] loss: 0.313\n",
      "[55, 360] loss: 0.304\n",
      "Epoch: 55 -> Loss: 0.39961463213\n",
      "Epoch: 55 -> Test Accuracy: 86.1525\n",
      "[56, 60] loss: 0.294\n",
      "[56, 120] loss: 0.295\n",
      "[56, 180] loss: 0.304\n",
      "[56, 240] loss: 0.303\n",
      "[56, 300] loss: 0.300\n",
      "[56, 360] loss: 0.293\n",
      "Epoch: 56 -> Loss: 0.370287895203\n",
      "Epoch: 56 -> Test Accuracy: 87.07\n",
      "[57, 60] loss: 0.298\n",
      "[57, 120] loss: 0.297\n",
      "[57, 180] loss: 0.308\n",
      "[57, 240] loss: 0.306\n",
      "[57, 300] loss: 0.295\n",
      "[57, 360] loss: 0.299\n",
      "Epoch: 57 -> Loss: 0.381079703569\n",
      "Epoch: 57 -> Test Accuracy: 87.93\n",
      "[58, 60] loss: 0.277\n",
      "[58, 120] loss: 0.288\n",
      "[58, 180] loss: 0.301\n",
      "[58, 240] loss: 0.298\n",
      "[58, 300] loss: 0.319\n",
      "[58, 360] loss: 0.314\n",
      "Epoch: 58 -> Loss: 0.26558843255\n",
      "Epoch: 58 -> Test Accuracy: 85.88\n",
      "[59, 60] loss: 0.289\n",
      "[59, 120] loss: 0.298\n",
      "[59, 180] loss: 0.292\n",
      "[59, 240] loss: 0.296\n",
      "[59, 300] loss: 0.301\n",
      "[59, 360] loss: 0.299\n",
      "Epoch: 59 -> Loss: 0.312070548534\n",
      "Epoch: 59 -> Test Accuracy: 87.1375\n",
      "[60, 60] loss: 0.279\n",
      "[60, 120] loss: 0.303\n",
      "[60, 180] loss: 0.297\n",
      "[60, 240] loss: 0.298\n",
      "[60, 300] loss: 0.291\n",
      "[60, 360] loss: 0.315\n",
      "Epoch: 60 -> Loss: 0.299725115299\n",
      "Epoch: 60 -> Test Accuracy: 87.175\n",
      "[61, 60] loss: 0.230\n",
      "[61, 120] loss: 0.204\n",
      "[61, 180] loss: 0.188\n",
      "[61, 240] loss: 0.190\n",
      "[61, 300] loss: 0.185\n",
      "[61, 360] loss: 0.181\n",
      "Epoch: 61 -> Loss: 0.264819651842\n",
      "Epoch: 61 -> Test Accuracy: 90.95\n",
      "[62, 60] loss: 0.171\n",
      "[62, 120] loss: 0.165\n",
      "[62, 180] loss: 0.170\n",
      "[62, 240] loss: 0.167\n",
      "[62, 300] loss: 0.167\n",
      "[62, 360] loss: 0.166\n",
      "Epoch: 62 -> Loss: 0.153748035431\n",
      "Epoch: 62 -> Test Accuracy: 91.2825\n",
      "[63, 60] loss: 0.143\n",
      "[63, 120] loss: 0.157\n",
      "[63, 180] loss: 0.155\n",
      "[63, 240] loss: 0.163\n",
      "[63, 300] loss: 0.159\n",
      "[63, 360] loss: 0.168\n",
      "Epoch: 63 -> Loss: 0.120768167078\n",
      "Epoch: 63 -> Test Accuracy: 91.2675\n",
      "[64, 60] loss: 0.142\n",
      "[64, 120] loss: 0.147\n",
      "[64, 180] loss: 0.148\n",
      "[64, 240] loss: 0.152\n",
      "[64, 300] loss: 0.160\n",
      "[64, 360] loss: 0.154\n",
      "Epoch: 64 -> Loss: 0.205818578601\n",
      "Epoch: 64 -> Test Accuracy: 91.01\n",
      "[65, 60] loss: 0.140\n",
      "[65, 120] loss: 0.146\n",
      "[65, 180] loss: 0.147\n",
      "[65, 240] loss: 0.155\n",
      "[65, 300] loss: 0.155\n",
      "[65, 360] loss: 0.154\n",
      "Epoch: 65 -> Loss: 0.129873663187\n",
      "Epoch: 65 -> Test Accuracy: 91.39\n",
      "[66, 60] loss: 0.139\n",
      "[66, 120] loss: 0.153\n",
      "[66, 180] loss: 0.150\n",
      "[66, 240] loss: 0.145\n",
      "[66, 300] loss: 0.151\n",
      "[66, 360] loss: 0.145\n",
      "Epoch: 66 -> Loss: 0.08860437572\n",
      "Epoch: 66 -> Test Accuracy: 90.915\n",
      "[67, 60] loss: 0.140\n",
      "[67, 120] loss: 0.145\n",
      "[67, 180] loss: 0.146\n",
      "[67, 240] loss: 0.146\n",
      "[67, 300] loss: 0.155\n",
      "[67, 360] loss: 0.148\n",
      "Epoch: 67 -> Loss: 0.190403565764\n",
      "Epoch: 67 -> Test Accuracy: 90.8725\n",
      "[68, 60] loss: 0.138\n",
      "[68, 120] loss: 0.140\n",
      "[68, 180] loss: 0.138\n",
      "[68, 240] loss: 0.150\n",
      "[68, 300] loss: 0.150\n",
      "[68, 360] loss: 0.149\n",
      "Epoch: 68 -> Loss: 0.107370272279\n",
      "Epoch: 68 -> Test Accuracy: 90.595\n",
      "[69, 60] loss: 0.135\n",
      "[69, 120] loss: 0.135\n",
      "[69, 180] loss: 0.139\n",
      "[69, 240] loss: 0.146\n",
      "[69, 300] loss: 0.159\n",
      "[69, 360] loss: 0.150\n",
      "Epoch: 69 -> Loss: 0.104421772063\n",
      "Epoch: 69 -> Test Accuracy: 90.72\n",
      "[70, 60] loss: 0.132\n",
      "[70, 120] loss: 0.133\n",
      "[70, 180] loss: 0.154\n",
      "[70, 240] loss: 0.146\n",
      "[70, 300] loss: 0.164\n",
      "[70, 360] loss: 0.151\n",
      "Epoch: 70 -> Loss: 0.216716095805\n",
      "Epoch: 70 -> Test Accuracy: 90.7925\n",
      "[71, 60] loss: 0.143\n",
      "[71, 120] loss: 0.136\n",
      "[71, 180] loss: 0.141\n",
      "[71, 240] loss: 0.149\n",
      "[71, 300] loss: 0.152\n",
      "[71, 360] loss: 0.150\n",
      "Epoch: 71 -> Loss: 0.147930294275\n",
      "Epoch: 71 -> Test Accuracy: 90.84\n",
      "[72, 60] loss: 0.137\n",
      "[72, 120] loss: 0.143\n",
      "[72, 180] loss: 0.150\n",
      "[72, 240] loss: 0.144\n",
      "[72, 300] loss: 0.151\n",
      "[72, 360] loss: 0.146\n",
      "Epoch: 72 -> Loss: 0.0720790103078\n",
      "Epoch: 72 -> Test Accuracy: 90.5825\n",
      "[73, 60] loss: 0.139\n",
      "[73, 120] loss: 0.145\n",
      "[73, 180] loss: 0.138\n",
      "[73, 240] loss: 0.152\n",
      "[73, 300] loss: 0.150\n",
      "[73, 360] loss: 0.157\n",
      "Epoch: 73 -> Loss: 0.14691324532\n",
      "Epoch: 73 -> Test Accuracy: 90.1075\n",
      "[74, 60] loss: 0.136\n",
      "[74, 120] loss: 0.144\n",
      "[74, 180] loss: 0.142\n",
      "[74, 240] loss: 0.151\n",
      "[74, 300] loss: 0.150\n",
      "[74, 360] loss: 0.156\n",
      "Epoch: 74 -> Loss: 0.253999143839\n",
      "Epoch: 74 -> Test Accuracy: 90.53\n",
      "[75, 60] loss: 0.141\n",
      "[75, 120] loss: 0.141\n",
      "[75, 180] loss: 0.149\n",
      "[75, 240] loss: 0.143\n",
      "[75, 300] loss: 0.155\n",
      "[75, 360] loss: 0.151\n",
      "Epoch: 75 -> Loss: 0.155599191785\n",
      "Epoch: 75 -> Test Accuracy: 90.505\n",
      "[76, 60] loss: 0.131\n",
      "[76, 120] loss: 0.134\n",
      "[76, 180] loss: 0.143\n",
      "[76, 240] loss: 0.152\n",
      "[76, 300] loss: 0.158\n",
      "[76, 360] loss: 0.155\n",
      "Epoch: 76 -> Loss: 0.12601582706\n",
      "Epoch: 76 -> Test Accuracy: 90.1975\n",
      "[77, 60] loss: 0.138\n",
      "[77, 120] loss: 0.139\n",
      "[77, 180] loss: 0.142\n",
      "[77, 240] loss: 0.157\n",
      "[77, 300] loss: 0.152\n",
      "[77, 360] loss: 0.156\n",
      "Epoch: 77 -> Loss: 0.238944083452\n",
      "Epoch: 77 -> Test Accuracy: 89.9775\n",
      "[78, 60] loss: 0.131\n",
      "[78, 120] loss: 0.148\n",
      "[78, 180] loss: 0.142\n",
      "[78, 240] loss: 0.154\n",
      "[78, 300] loss: 0.145\n",
      "[78, 360] loss: 0.155\n",
      "Epoch: 78 -> Loss: 0.0957691073418\n",
      "Epoch: 78 -> Test Accuracy: 90.4075\n",
      "[79, 60] loss: 0.139\n",
      "[79, 120] loss: 0.137\n",
      "[79, 180] loss: 0.140\n",
      "[79, 240] loss: 0.154\n",
      "[79, 300] loss: 0.152\n",
      "[79, 360] loss: 0.149\n",
      "Epoch: 79 -> Loss: 0.0941844135523\n",
      "Epoch: 79 -> Test Accuracy: 89.8525\n",
      "[80, 60] loss: 0.137\n",
      "[80, 120] loss: 0.131\n",
      "[80, 180] loss: 0.151\n",
      "[80, 240] loss: 0.145\n",
      "[80, 300] loss: 0.155\n",
      "[80, 360] loss: 0.159\n",
      "Epoch: 80 -> Loss: 0.091240927577\n",
      "Epoch: 80 -> Test Accuracy: 90.1375\n",
      "[81, 60] loss: 0.137\n",
      "[81, 120] loss: 0.143\n",
      "[81, 180] loss: 0.144\n",
      "[81, 240] loss: 0.150\n",
      "[81, 300] loss: 0.145\n",
      "[81, 360] loss: 0.152\n",
      "Epoch: 81 -> Loss: 0.160947829485\n",
      "Epoch: 81 -> Test Accuracy: 90.3025\n",
      "[82, 60] loss: 0.133\n",
      "[82, 120] loss: 0.140\n",
      "[82, 180] loss: 0.151\n",
      "[82, 240] loss: 0.144\n",
      "[82, 300] loss: 0.157\n",
      "[82, 360] loss: 0.155\n",
      "Epoch: 82 -> Loss: 0.172871589661\n",
      "Epoch: 82 -> Test Accuracy: 90.235\n",
      "[83, 60] loss: 0.135\n",
      "[83, 120] loss: 0.133\n",
      "[83, 180] loss: 0.134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83, 240] loss: 0.155\n",
      "[83, 300] loss: 0.159\n",
      "[83, 360] loss: 0.155\n",
      "Epoch: 83 -> Loss: 0.147573813796\n",
      "Epoch: 83 -> Test Accuracy: 90.2125\n",
      "[84, 60] loss: 0.138\n",
      "[84, 120] loss: 0.139\n",
      "[84, 180] loss: 0.147\n",
      "[84, 240] loss: 0.144\n",
      "[84, 300] loss: 0.142\n",
      "[84, 360] loss: 0.154\n",
      "Epoch: 84 -> Loss: 0.0975830703974\n",
      "Epoch: 84 -> Test Accuracy: 90.3\n",
      "[85, 60] loss: 0.137\n",
      "[85, 120] loss: 0.132\n",
      "[85, 180] loss: 0.148\n",
      "[85, 240] loss: 0.153\n",
      "[85, 300] loss: 0.147\n",
      "[85, 360] loss: 0.156\n",
      "Epoch: 85 -> Loss: 0.157554775476\n",
      "Epoch: 85 -> Test Accuracy: 90.2225\n",
      "[86, 60] loss: 0.133\n",
      "[86, 120] loss: 0.136\n",
      "[86, 180] loss: 0.140\n",
      "[86, 240] loss: 0.153\n",
      "[86, 300] loss: 0.148\n",
      "[86, 360] loss: 0.150\n",
      "Epoch: 86 -> Loss: 0.118725478649\n",
      "Epoch: 86 -> Test Accuracy: 90.295\n",
      "[87, 60] loss: 0.144\n",
      "[87, 120] loss: 0.133\n",
      "[87, 180] loss: 0.135\n",
      "[87, 240] loss: 0.147\n",
      "[87, 300] loss: 0.150\n",
      "[87, 360] loss: 0.150\n",
      "Epoch: 87 -> Loss: 0.139809191227\n",
      "Epoch: 87 -> Test Accuracy: 90.015\n",
      "[88, 60] loss: 0.135\n",
      "[88, 120] loss: 0.136\n",
      "[88, 180] loss: 0.142\n",
      "[88, 240] loss: 0.154\n",
      "[88, 300] loss: 0.149\n",
      "[88, 360] loss: 0.150\n",
      "Epoch: 88 -> Loss: 0.115471169353\n",
      "Epoch: 88 -> Test Accuracy: 90.3525\n",
      "[89, 60] loss: 0.128\n",
      "[89, 120] loss: 0.140\n",
      "[89, 180] loss: 0.138\n",
      "[89, 240] loss: 0.152\n",
      "[89, 300] loss: 0.143\n",
      "[89, 360] loss: 0.155\n",
      "Epoch: 89 -> Loss: 0.190714254975\n",
      "Epoch: 89 -> Test Accuracy: 90.2825\n",
      "[90, 60] loss: 0.138\n",
      "[90, 120] loss: 0.137\n",
      "[90, 180] loss: 0.142\n",
      "[90, 240] loss: 0.139\n",
      "[90, 300] loss: 0.151\n",
      "[90, 360] loss: 0.140\n",
      "Epoch: 90 -> Loss: 0.0907204821706\n",
      "Epoch: 90 -> Test Accuracy: 90.76\n",
      "[91, 60] loss: 0.136\n",
      "[91, 120] loss: 0.135\n",
      "[91, 180] loss: 0.149\n",
      "[91, 240] loss: 0.150\n",
      "[91, 300] loss: 0.147\n",
      "[91, 360] loss: 0.150\n",
      "Epoch: 91 -> Loss: 0.130708575249\n",
      "Epoch: 91 -> Test Accuracy: 90.64\n",
      "[92, 60] loss: 0.143\n",
      "[92, 120] loss: 0.147\n",
      "[92, 180] loss: 0.133\n",
      "[92, 240] loss: 0.142\n",
      "[92, 300] loss: 0.144\n",
      "[92, 360] loss: 0.140\n",
      "Epoch: 92 -> Loss: 0.146538034081\n",
      "Epoch: 92 -> Test Accuracy: 90.1375\n",
      "[93, 60] loss: 0.126\n",
      "[93, 120] loss: 0.133\n",
      "[93, 180] loss: 0.148\n",
      "[93, 240] loss: 0.146\n",
      "[93, 300] loss: 0.155\n",
      "[93, 360] loss: 0.143\n",
      "Epoch: 93 -> Loss: 0.101746119559\n",
      "Epoch: 93 -> Test Accuracy: 90.3\n",
      "[94, 60] loss: 0.135\n",
      "[94, 120] loss: 0.133\n",
      "[94, 180] loss: 0.142\n",
      "[94, 240] loss: 0.141\n",
      "[94, 300] loss: 0.138\n",
      "[94, 360] loss: 0.150\n",
      "Epoch: 94 -> Loss: 0.279359728098\n",
      "Epoch: 94 -> Test Accuracy: 89.76\n",
      "[95, 60] loss: 0.126\n",
      "[95, 120] loss: 0.132\n",
      "[95, 180] loss: 0.134\n",
      "[95, 240] loss: 0.135\n",
      "[95, 300] loss: 0.157\n",
      "[95, 360] loss: 0.150\n",
      "Epoch: 95 -> Loss: 0.156734138727\n",
      "Epoch: 95 -> Test Accuracy: 90.475\n",
      "[96, 60] loss: 0.136\n",
      "[96, 120] loss: 0.135\n",
      "[96, 180] loss: 0.135\n",
      "[96, 240] loss: 0.137\n",
      "[96, 300] loss: 0.141\n",
      "[96, 360] loss: 0.146\n",
      "Epoch: 96 -> Loss: 0.122312352061\n",
      "Epoch: 96 -> Test Accuracy: 90.12\n",
      "[97, 60] loss: 0.128\n",
      "[97, 120] loss: 0.132\n",
      "[97, 180] loss: 0.146\n",
      "[97, 240] loss: 0.143\n",
      "[97, 300] loss: 0.148\n",
      "[97, 360] loss: 0.148\n",
      "Epoch: 97 -> Loss: 0.200551122427\n",
      "Epoch: 97 -> Test Accuracy: 90.375\n",
      "[98, 60] loss: 0.132\n",
      "[98, 120] loss: 0.132\n",
      "[98, 180] loss: 0.135\n",
      "[98, 240] loss: 0.140\n",
      "[98, 300] loss: 0.143\n",
      "[98, 360] loss: 0.150\n",
      "Epoch: 98 -> Loss: 0.113036714494\n",
      "Epoch: 98 -> Test Accuracy: 89.935\n",
      "[99, 60] loss: 0.134\n",
      "[99, 120] loss: 0.131\n",
      "[99, 180] loss: 0.133\n",
      "[99, 240] loss: 0.136\n",
      "[99, 300] loss: 0.149\n",
      "[99, 360] loss: 0.142\n",
      "Epoch: 99 -> Loss: 0.24099329114\n",
      "Epoch: 99 -> Test Accuracy: 89.9925\n",
      "[100, 60] loss: 0.136\n",
      "[100, 120] loss: 0.137\n",
      "[100, 180] loss: 0.141\n",
      "[100, 240] loss: 0.138\n",
      "[100, 300] loss: 0.143\n",
      "[100, 360] loss: 0.144\n",
      "Epoch: 100 -> Loss: 0.152291730046\n",
      "Epoch: 100 -> Test Accuracy: 90.2525\n",
      "[101, 60] loss: 0.122\n",
      "[101, 120] loss: 0.128\n",
      "[101, 180] loss: 0.134\n",
      "[101, 240] loss: 0.137\n",
      "[101, 300] loss: 0.147\n",
      "[101, 360] loss: 0.139\n",
      "Epoch: 101 -> Loss: 0.114834487438\n",
      "Epoch: 101 -> Test Accuracy: 90.085\n",
      "[102, 60] loss: 0.130\n",
      "[102, 120] loss: 0.133\n",
      "[102, 180] loss: 0.132\n",
      "[102, 240] loss: 0.136\n",
      "[102, 300] loss: 0.141\n",
      "[102, 360] loss: 0.147\n",
      "Epoch: 102 -> Loss: 0.156157523394\n",
      "Epoch: 102 -> Test Accuracy: 90.41\n",
      "[103, 60] loss: 0.129\n",
      "[103, 120] loss: 0.135\n",
      "[103, 180] loss: 0.135\n",
      "[103, 240] loss: 0.139\n",
      "[103, 300] loss: 0.139\n",
      "[103, 360] loss: 0.141\n",
      "Epoch: 103 -> Loss: 0.177048057318\n",
      "Epoch: 103 -> Test Accuracy: 90.5725\n",
      "[104, 60] loss: 0.120\n",
      "[104, 120] loss: 0.131\n",
      "[104, 180] loss: 0.135\n",
      "[104, 240] loss: 0.143\n",
      "[104, 300] loss: 0.138\n",
      "[104, 360] loss: 0.145\n",
      "Epoch: 104 -> Loss: 0.0994145795703\n",
      "Epoch: 104 -> Test Accuracy: 90.2175\n",
      "[105, 60] loss: 0.127\n",
      "[105, 120] loss: 0.128\n",
      "[105, 180] loss: 0.135\n",
      "[105, 240] loss: 0.152\n",
      "[105, 300] loss: 0.137\n",
      "[105, 360] loss: 0.149\n",
      "Epoch: 105 -> Loss: 0.123633310199\n",
      "Epoch: 105 -> Test Accuracy: 90.2675\n",
      "[106, 60] loss: 0.131\n",
      "[106, 120] loss: 0.128\n",
      "[106, 180] loss: 0.137\n",
      "[106, 240] loss: 0.133\n",
      "[106, 300] loss: 0.138\n",
      "[106, 360] loss: 0.142\n",
      "Epoch: 106 -> Loss: 0.181755810976\n",
      "Epoch: 106 -> Test Accuracy: 90.07\n",
      "[107, 60] loss: 0.129\n",
      "[107, 120] loss: 0.130\n",
      "[107, 180] loss: 0.131\n",
      "[107, 240] loss: 0.139\n",
      "[107, 300] loss: 0.136\n",
      "[107, 360] loss: 0.137\n",
      "Epoch: 107 -> Loss: 0.0956983715296\n",
      "Epoch: 107 -> Test Accuracy: 90.6775\n",
      "[108, 60] loss: 0.127\n",
      "[108, 120] loss: 0.135\n",
      "[108, 180] loss: 0.134\n",
      "[108, 240] loss: 0.138\n",
      "[108, 300] loss: 0.139\n",
      "[108, 360] loss: 0.145\n",
      "Epoch: 108 -> Loss: 0.0928385928273\n",
      "Epoch: 108 -> Test Accuracy: 90.28\n",
      "[109, 60] loss: 0.125\n",
      "[109, 120] loss: 0.128\n",
      "[109, 180] loss: 0.137\n",
      "[109, 240] loss: 0.138\n",
      "[109, 300] loss: 0.133\n",
      "[109, 360] loss: 0.139\n",
      "Epoch: 109 -> Loss: 0.143992885947\n",
      "Epoch: 109 -> Test Accuracy: 89.87\n",
      "[110, 60] loss: 0.130\n",
      "[110, 120] loss: 0.137\n",
      "[110, 180] loss: 0.127\n",
      "[110, 240] loss: 0.136\n",
      "[110, 300] loss: 0.139\n",
      "[110, 360] loss: 0.148\n",
      "Epoch: 110 -> Loss: 0.117945455015\n",
      "Epoch: 110 -> Test Accuracy: 89.36\n",
      "[111, 60] loss: 0.129\n",
      "[111, 120] loss: 0.132\n",
      "[111, 180] loss: 0.135\n",
      "[111, 240] loss: 0.128\n",
      "[111, 300] loss: 0.132\n",
      "[111, 360] loss: 0.142\n",
      "Epoch: 111 -> Loss: 0.158993527293\n",
      "Epoch: 111 -> Test Accuracy: 89.785\n",
      "[112, 60] loss: 0.128\n",
      "[112, 120] loss: 0.123\n",
      "[112, 180] loss: 0.132\n",
      "[112, 240] loss: 0.136\n",
      "[112, 300] loss: 0.140\n",
      "[112, 360] loss: 0.136\n",
      "Epoch: 112 -> Loss: 0.155993163586\n",
      "Epoch: 112 -> Test Accuracy: 90.685\n",
      "[113, 60] loss: 0.124\n",
      "[113, 120] loss: 0.123\n",
      "[113, 180] loss: 0.136\n",
      "[113, 240] loss: 0.136\n",
      "[113, 300] loss: 0.141\n",
      "[113, 360] loss: 0.143\n",
      "Epoch: 113 -> Loss: 0.152463316917\n",
      "Epoch: 113 -> Test Accuracy: 90.245\n",
      "[114, 60] loss: 0.121\n",
      "[114, 120] loss: 0.128\n",
      "[114, 180] loss: 0.130\n",
      "[114, 240] loss: 0.139\n",
      "[114, 300] loss: 0.132\n",
      "[114, 360] loss: 0.144\n",
      "Epoch: 114 -> Loss: 0.177935436368\n",
      "Epoch: 114 -> Test Accuracy: 90.4425\n",
      "[115, 60] loss: 0.118\n",
      "[115, 120] loss: 0.125\n",
      "[115, 180] loss: 0.123\n",
      "[115, 240] loss: 0.141\n",
      "[115, 300] loss: 0.139\n",
      "[115, 360] loss: 0.141\n",
      "Epoch: 115 -> Loss: 0.109330654144\n",
      "Epoch: 115 -> Test Accuracy: 89.9325\n",
      "[116, 60] loss: 0.123\n",
      "[116, 120] loss: 0.131\n",
      "[116, 180] loss: 0.130\n",
      "[116, 240] loss: 0.131\n",
      "[116, 300] loss: 0.144\n",
      "[116, 360] loss: 0.142\n",
      "Epoch: 116 -> Loss: 0.135161519051\n",
      "Epoch: 116 -> Test Accuracy: 90.5225\n",
      "[117, 60] loss: 0.122\n",
      "[117, 120] loss: 0.113\n",
      "[117, 180] loss: 0.134\n",
      "[117, 240] loss: 0.129\n",
      "[117, 300] loss: 0.143\n",
      "[117, 360] loss: 0.133\n",
      "Epoch: 117 -> Loss: 0.135910227895\n",
      "Epoch: 117 -> Test Accuracy: 90.015\n",
      "[118, 60] loss: 0.126\n",
      "[118, 120] loss: 0.128\n",
      "[118, 180] loss: 0.139\n",
      "[118, 240] loss: 0.136\n",
      "[118, 300] loss: 0.136\n",
      "[118, 360] loss: 0.138\n",
      "Epoch: 118 -> Loss: 0.213188931346\n",
      "Epoch: 118 -> Test Accuracy: 90.8575\n",
      "[119, 60] loss: 0.126\n",
      "[119, 120] loss: 0.127\n",
      "[119, 180] loss: 0.132\n",
      "[119, 240] loss: 0.134\n",
      "[119, 300] loss: 0.143\n",
      "[119, 360] loss: 0.139\n",
      "Epoch: 119 -> Loss: 0.0643893405795\n",
      "Epoch: 119 -> Test Accuracy: 90.7375\n",
      "[120, 60] loss: 0.120\n",
      "[120, 120] loss: 0.120\n",
      "[120, 180] loss: 0.131\n",
      "[120, 240] loss: 0.135\n",
      "[120, 300] loss: 0.136\n",
      "[120, 360] loss: 0.141\n",
      "Epoch: 120 -> Loss: 0.152717143297\n",
      "Epoch: 120 -> Test Accuracy: 90.4075\n",
      "[121, 60] loss: 0.099\n",
      "[121, 120] loss: 0.086\n",
      "[121, 180] loss: 0.076\n",
      "[121, 240] loss: 0.073\n",
      "[121, 300] loss: 0.068\n",
      "[121, 360] loss: 0.074\n",
      "Epoch: 121 -> Loss: 0.0417011976242\n",
      "Epoch: 121 -> Test Accuracy: 92.1525\n",
      "[122, 60] loss: 0.059\n",
      "[122, 120] loss: 0.057\n",
      "[122, 180] loss: 0.062\n",
      "[122, 240] loss: 0.062\n",
      "[122, 300] loss: 0.060\n",
      "[122, 360] loss: 0.064\n",
      "Epoch: 122 -> Loss: 0.0532085373998\n",
      "Epoch: 122 -> Test Accuracy: 92.1375\n",
      "[123, 60] loss: 0.053\n",
      "[123, 120] loss: 0.054\n",
      "[123, 180] loss: 0.054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123, 240] loss: 0.053\n",
      "[123, 300] loss: 0.055\n",
      "[123, 360] loss: 0.056\n",
      "Epoch: 123 -> Loss: 0.0241162218153\n",
      "Epoch: 123 -> Test Accuracy: 92.355\n",
      "[124, 60] loss: 0.052\n",
      "[124, 120] loss: 0.046\n",
      "[124, 180] loss: 0.049\n",
      "[124, 240] loss: 0.052\n",
      "[124, 300] loss: 0.050\n",
      "[124, 360] loss: 0.051\n",
      "Epoch: 124 -> Loss: 0.0235836915672\n",
      "Epoch: 124 -> Test Accuracy: 92.38\n",
      "[125, 60] loss: 0.045\n",
      "[125, 120] loss: 0.046\n",
      "[125, 180] loss: 0.047\n",
      "[125, 240] loss: 0.046\n",
      "[125, 300] loss: 0.049\n",
      "[125, 360] loss: 0.047\n",
      "Epoch: 125 -> Loss: 0.056631308049\n",
      "Epoch: 125 -> Test Accuracy: 92.3125\n",
      "[126, 60] loss: 0.040\n",
      "[126, 120] loss: 0.042\n",
      "[126, 180] loss: 0.044\n",
      "[126, 240] loss: 0.046\n",
      "[126, 300] loss: 0.042\n",
      "[126, 360] loss: 0.044\n",
      "Epoch: 126 -> Loss: 0.0198171045631\n",
      "Epoch: 126 -> Test Accuracy: 92.32\n",
      "[127, 60] loss: 0.038\n",
      "[127, 120] loss: 0.040\n",
      "[127, 180] loss: 0.041\n",
      "[127, 240] loss: 0.040\n",
      "[127, 300] loss: 0.041\n",
      "[127, 360] loss: 0.043\n",
      "Epoch: 127 -> Loss: 0.0345460250974\n",
      "Epoch: 127 -> Test Accuracy: 92.24\n",
      "[128, 60] loss: 0.038\n",
      "[128, 120] loss: 0.035\n",
      "[128, 180] loss: 0.039\n",
      "[128, 240] loss: 0.039\n",
      "[128, 300] loss: 0.040\n",
      "[128, 360] loss: 0.041\n",
      "Epoch: 128 -> Loss: 0.0209658052772\n",
      "Epoch: 128 -> Test Accuracy: 92.3225\n",
      "[129, 60] loss: 0.036\n",
      "[129, 120] loss: 0.036\n",
      "[129, 180] loss: 0.036\n",
      "[129, 240] loss: 0.039\n",
      "[129, 300] loss: 0.039\n",
      "[129, 360] loss: 0.040\n",
      "Epoch: 129 -> Loss: 0.0392682179809\n",
      "Epoch: 129 -> Test Accuracy: 92.11\n",
      "[130, 60] loss: 0.042\n",
      "[130, 120] loss: 0.036\n",
      "[130, 180] loss: 0.035\n",
      "[130, 240] loss: 0.034\n",
      "[130, 300] loss: 0.037\n",
      "[130, 360] loss: 0.037\n",
      "Epoch: 130 -> Loss: 0.0723239630461\n",
      "Epoch: 130 -> Test Accuracy: 92.18\n",
      "[131, 60] loss: 0.034\n",
      "[131, 120] loss: 0.035\n",
      "[131, 180] loss: 0.036\n",
      "[131, 240] loss: 0.038\n",
      "[131, 300] loss: 0.038\n",
      "[131, 360] loss: 0.034\n",
      "Epoch: 131 -> Loss: 0.054421775043\n",
      "Epoch: 131 -> Test Accuracy: 92.25\n",
      "[132, 60] loss: 0.032\n",
      "[132, 120] loss: 0.031\n",
      "[132, 180] loss: 0.036\n",
      "[132, 240] loss: 0.039\n",
      "[132, 300] loss: 0.033\n",
      "[132, 360] loss: 0.037\n",
      "Epoch: 132 -> Loss: 0.0341352261603\n",
      "Epoch: 132 -> Test Accuracy: 92.1625\n",
      "[133, 60] loss: 0.033\n",
      "[133, 120] loss: 0.033\n",
      "[133, 180] loss: 0.035\n",
      "[133, 240] loss: 0.032\n",
      "[133, 300] loss: 0.034\n",
      "[133, 360] loss: 0.036\n",
      "Epoch: 133 -> Loss: 0.0355919264257\n",
      "Epoch: 133 -> Test Accuracy: 92.2625\n",
      "[134, 60] loss: 0.030\n",
      "[134, 120] loss: 0.031\n",
      "[134, 180] loss: 0.032\n",
      "[134, 240] loss: 0.033\n",
      "[134, 300] loss: 0.034\n",
      "[134, 360] loss: 0.033\n",
      "Epoch: 134 -> Loss: 0.0199987310916\n",
      "Epoch: 134 -> Test Accuracy: 92.1675\n",
      "[135, 60] loss: 0.031\n",
      "[135, 120] loss: 0.030\n",
      "[135, 180] loss: 0.031\n",
      "[135, 240] loss: 0.033\n",
      "[135, 300] loss: 0.030\n",
      "[135, 360] loss: 0.033\n",
      "Epoch: 135 -> Loss: 0.0262734405696\n",
      "Epoch: 135 -> Test Accuracy: 92.25\n",
      "[136, 60] loss: 0.029\n",
      "[136, 120] loss: 0.032\n",
      "[136, 180] loss: 0.029\n",
      "[136, 240] loss: 0.029\n",
      "[136, 300] loss: 0.032\n",
      "[136, 360] loss: 0.032\n",
      "Epoch: 136 -> Loss: 0.0273963063955\n",
      "Epoch: 136 -> Test Accuracy: 92.09\n",
      "[137, 60] loss: 0.028\n",
      "[137, 120] loss: 0.027\n",
      "[137, 180] loss: 0.031\n",
      "[137, 240] loss: 0.032\n",
      "[137, 300] loss: 0.031\n",
      "[137, 360] loss: 0.028\n",
      "Epoch: 137 -> Loss: 0.0261355098337\n",
      "Epoch: 137 -> Test Accuracy: 92.25\n",
      "[138, 60] loss: 0.026\n",
      "[138, 120] loss: 0.026\n",
      "[138, 180] loss: 0.026\n",
      "[138, 240] loss: 0.033\n",
      "[138, 300] loss: 0.032\n",
      "[138, 360] loss: 0.032\n",
      "Epoch: 138 -> Loss: 0.0181944612414\n",
      "Epoch: 138 -> Test Accuracy: 91.9625\n",
      "[139, 60] loss: 0.028\n",
      "[139, 120] loss: 0.027\n",
      "[139, 180] loss: 0.029\n",
      "[139, 240] loss: 0.030\n",
      "[139, 300] loss: 0.031\n",
      "[139, 360] loss: 0.028\n",
      "Epoch: 139 -> Loss: 0.0281481482089\n",
      "Epoch: 139 -> Test Accuracy: 92.03\n",
      "[140, 60] loss: 0.025\n",
      "[140, 120] loss: 0.027\n",
      "[140, 180] loss: 0.028\n",
      "[140, 240] loss: 0.030\n",
      "[140, 300] loss: 0.030\n",
      "[140, 360] loss: 0.031\n",
      "Epoch: 140 -> Loss: 0.0314240828156\n",
      "Epoch: 140 -> Test Accuracy: 92.11\n",
      "[141, 60] loss: 0.029\n",
      "[141, 120] loss: 0.026\n",
      "[141, 180] loss: 0.028\n",
      "[141, 240] loss: 0.029\n",
      "[141, 300] loss: 0.026\n",
      "[141, 360] loss: 0.029\n",
      "Epoch: 141 -> Loss: 0.0302843656391\n",
      "Epoch: 141 -> Test Accuracy: 91.9575\n",
      "[142, 60] loss: 0.026\n",
      "[142, 120] loss: 0.027\n",
      "[142, 180] loss: 0.025\n",
      "[142, 240] loss: 0.027\n",
      "[142, 300] loss: 0.029\n",
      "[142, 360] loss: 0.028\n",
      "Epoch: 142 -> Loss: 0.0548400878906\n",
      "Epoch: 142 -> Test Accuracy: 91.9975\n",
      "[143, 60] loss: 0.025\n",
      "[143, 120] loss: 0.025\n",
      "[143, 180] loss: 0.030\n",
      "[143, 240] loss: 0.027\n",
      "[143, 300] loss: 0.027\n",
      "[143, 360] loss: 0.029\n",
      "Epoch: 143 -> Loss: 0.0386905707419\n",
      "Epoch: 143 -> Test Accuracy: 91.9375\n",
      "[144, 60] loss: 0.024\n",
      "[144, 120] loss: 0.024\n",
      "[144, 180] loss: 0.028\n",
      "[144, 240] loss: 0.027\n",
      "[144, 300] loss: 0.028\n",
      "[144, 360] loss: 0.028\n",
      "Epoch: 144 -> Loss: 0.0349388346076\n",
      "Epoch: 144 -> Test Accuracy: 92.2025\n",
      "[145, 60] loss: 0.024\n",
      "[145, 120] loss: 0.025\n",
      "[145, 180] loss: 0.025\n",
      "[145, 240] loss: 0.028\n",
      "[145, 300] loss: 0.026\n",
      "[145, 360] loss: 0.027\n",
      "Epoch: 145 -> Loss: 0.0302007384598\n",
      "Epoch: 145 -> Test Accuracy: 91.7625\n",
      "[146, 60] loss: 0.026\n",
      "[146, 120] loss: 0.024\n",
      "[146, 180] loss: 0.024\n",
      "[146, 240] loss: 0.024\n",
      "[146, 300] loss: 0.027\n",
      "[146, 360] loss: 0.027\n",
      "Epoch: 146 -> Loss: 0.0373889580369\n",
      "Epoch: 146 -> Test Accuracy: 91.9375\n",
      "[147, 60] loss: 0.024\n",
      "[147, 120] loss: 0.026\n",
      "[147, 180] loss: 0.024\n",
      "[147, 240] loss: 0.027\n",
      "[147, 300] loss: 0.026\n",
      "[147, 360] loss: 0.027\n",
      "Epoch: 147 -> Loss: 0.0186978597194\n",
      "Epoch: 147 -> Test Accuracy: 92.07\n",
      "[148, 60] loss: 0.025\n",
      "[148, 120] loss: 0.026\n",
      "[148, 180] loss: 0.028\n",
      "[148, 240] loss: 0.027\n",
      "[148, 300] loss: 0.027\n",
      "[148, 360] loss: 0.028\n",
      "Epoch: 148 -> Loss: 0.014425329864\n",
      "Epoch: 148 -> Test Accuracy: 91.925\n",
      "[149, 60] loss: 0.025\n",
      "[149, 120] loss: 0.023\n",
      "[149, 180] loss: 0.024\n",
      "[149, 240] loss: 0.027\n",
      "[149, 300] loss: 0.027\n",
      "[149, 360] loss: 0.029\n",
      "Epoch: 149 -> Loss: 0.0290602855384\n",
      "Epoch: 149 -> Test Accuracy: 91.7825\n",
      "[150, 60] loss: 0.025\n",
      "[150, 120] loss: 0.025\n",
      "[150, 180] loss: 0.023\n",
      "[150, 240] loss: 0.027\n",
      "[150, 300] loss: 0.026\n",
      "[150, 360] loss: 0.028\n",
      "Epoch: 150 -> Loss: 0.0239087231457\n",
      "Epoch: 150 -> Test Accuracy: 91.915\n",
      "[151, 60] loss: 0.023\n",
      "[151, 120] loss: 0.023\n",
      "[151, 180] loss: 0.025\n",
      "[151, 240] loss: 0.028\n",
      "[151, 300] loss: 0.025\n",
      "[151, 360] loss: 0.025\n",
      "Epoch: 151 -> Loss: 0.0150496605784\n",
      "Epoch: 151 -> Test Accuracy: 91.895\n",
      "[152, 60] loss: 0.024\n",
      "[152, 120] loss: 0.022\n",
      "[152, 180] loss: 0.024\n",
      "[152, 240] loss: 0.026\n",
      "[152, 300] loss: 0.025\n",
      "[152, 360] loss: 0.026\n",
      "Epoch: 152 -> Loss: 0.0200606919825\n",
      "Epoch: 152 -> Test Accuracy: 92.035\n",
      "[153, 60] loss: 0.022\n",
      "[153, 120] loss: 0.026\n",
      "[153, 180] loss: 0.025\n",
      "[153, 240] loss: 0.024\n",
      "[153, 300] loss: 0.026\n",
      "[153, 360] loss: 0.026\n",
      "Epoch: 153 -> Loss: 0.0257685892284\n",
      "Epoch: 153 -> Test Accuracy: 91.9625\n",
      "[154, 60] loss: 0.023\n",
      "[154, 120] loss: 0.024\n",
      "[154, 180] loss: 0.025\n",
      "[154, 240] loss: 0.024\n",
      "[154, 300] loss: 0.023\n",
      "[154, 360] loss: 0.027\n",
      "Epoch: 154 -> Loss: 0.0392384938896\n",
      "Epoch: 154 -> Test Accuracy: 91.935\n",
      "[155, 60] loss: 0.024\n",
      "[155, 120] loss: 0.024\n",
      "[155, 180] loss: 0.025\n",
      "[155, 240] loss: 0.025\n",
      "[155, 300] loss: 0.028\n",
      "[155, 360] loss: 0.024\n",
      "Epoch: 155 -> Loss: 0.0213266797364\n",
      "Epoch: 155 -> Test Accuracy: 91.995\n",
      "[156, 60] loss: 0.024\n",
      "[156, 120] loss: 0.024\n",
      "[156, 180] loss: 0.025\n",
      "[156, 240] loss: 0.024\n",
      "[156, 300] loss: 0.024\n",
      "[156, 360] loss: 0.027\n",
      "Epoch: 156 -> Loss: 0.0213869772851\n",
      "Epoch: 156 -> Test Accuracy: 91.9775\n",
      "[157, 60] loss: 0.024\n",
      "[157, 120] loss: 0.026\n",
      "[157, 180] loss: 0.025\n",
      "[157, 240] loss: 0.025\n",
      "[157, 300] loss: 0.025\n",
      "[157, 360] loss: 0.026\n",
      "Epoch: 157 -> Loss: 0.0178738366812\n",
      "Epoch: 157 -> Test Accuracy: 91.78\n",
      "[158, 60] loss: 0.023\n",
      "[158, 120] loss: 0.024\n",
      "[158, 180] loss: 0.026\n",
      "[158, 240] loss: 0.027\n",
      "[158, 300] loss: 0.025\n",
      "[158, 360] loss: 0.027\n",
      "Epoch: 158 -> Loss: 0.027533698827\n",
      "Epoch: 158 -> Test Accuracy: 92.0325\n",
      "[159, 60] loss: 0.024\n",
      "[159, 120] loss: 0.025\n",
      "[159, 180] loss: 0.025\n",
      "[159, 240] loss: 0.024\n",
      "[159, 300] loss: 0.026\n",
      "[159, 360] loss: 0.026\n",
      "Epoch: 159 -> Loss: 0.0299608018249\n",
      "Epoch: 159 -> Test Accuracy: 91.74\n",
      "[160, 60] loss: 0.022\n",
      "[160, 120] loss: 0.027\n",
      "[160, 180] loss: 0.023\n",
      "[160, 240] loss: 0.026\n",
      "[160, 300] loss: 0.026\n",
      "[160, 360] loss: 0.029\n",
      "Epoch: 160 -> Loss: 0.0286855641752\n",
      "Epoch: 160 -> Test Accuracy: 91.67\n",
      "[161, 60] loss: 0.020\n",
      "[161, 120] loss: 0.020\n",
      "[161, 180] loss: 0.017\n",
      "[161, 240] loss: 0.017\n",
      "[161, 300] loss: 0.016\n",
      "[161, 360] loss: 0.017\n",
      "Epoch: 161 -> Loss: 0.0156821496785\n",
      "Epoch: 161 -> Test Accuracy: 92.1775\n",
      "[162, 60] loss: 0.016\n",
      "[162, 120] loss: 0.014\n",
      "[162, 180] loss: 0.015\n",
      "[162, 240] loss: 0.016\n",
      "[162, 300] loss: 0.015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[162, 360] loss: 0.014\n",
      "Epoch: 162 -> Loss: 0.00652187177911\n",
      "Epoch: 162 -> Test Accuracy: 92.3025\n",
      "[163, 60] loss: 0.013\n",
      "[163, 120] loss: 0.013\n",
      "[163, 180] loss: 0.014\n",
      "[163, 240] loss: 0.015\n",
      "[163, 300] loss: 0.015\n",
      "[163, 360] loss: 0.014\n",
      "Epoch: 163 -> Loss: 0.0233575738966\n",
      "Epoch: 163 -> Test Accuracy: 92.27\n",
      "[164, 60] loss: 0.013\n",
      "[164, 120] loss: 0.014\n",
      "[164, 180] loss: 0.015\n",
      "[164, 240] loss: 0.013\n",
      "[164, 300] loss: 0.013\n",
      "[164, 360] loss: 0.013\n",
      "Epoch: 164 -> Loss: 0.00919873826206\n",
      "Epoch: 164 -> Test Accuracy: 92.365\n",
      "[165, 60] loss: 0.013\n",
      "[165, 120] loss: 0.013\n",
      "[165, 180] loss: 0.013\n",
      "[165, 240] loss: 0.012\n",
      "[165, 300] loss: 0.014\n",
      "[165, 360] loss: 0.013\n",
      "Epoch: 165 -> Loss: 0.00694509129971\n",
      "Epoch: 165 -> Test Accuracy: 92.285\n",
      "[166, 60] loss: 0.012\n",
      "[166, 120] loss: 0.012\n",
      "[166, 180] loss: 0.012\n",
      "[166, 240] loss: 0.013\n",
      "[166, 300] loss: 0.014\n",
      "[166, 360] loss: 0.011\n",
      "Epoch: 166 -> Loss: 0.022670449689\n",
      "Epoch: 166 -> Test Accuracy: 92.32\n",
      "[167, 60] loss: 0.012\n",
      "[167, 120] loss: 0.012\n",
      "[167, 180] loss: 0.013\n",
      "[167, 240] loss: 0.012\n",
      "[167, 300] loss: 0.012\n",
      "[167, 360] loss: 0.012\n",
      "Epoch: 167 -> Loss: 0.0191885773093\n",
      "Epoch: 167 -> Test Accuracy: 92.355\n",
      "[168, 60] loss: 0.012\n",
      "[168, 120] loss: 0.012\n",
      "[168, 180] loss: 0.012\n",
      "[168, 240] loss: 0.012\n",
      "[168, 300] loss: 0.012\n",
      "[168, 360] loss: 0.013\n",
      "Epoch: 168 -> Loss: 0.00976878032088\n",
      "Epoch: 168 -> Test Accuracy: 92.2525\n",
      "[169, 60] loss: 0.011\n",
      "[169, 120] loss: 0.011\n",
      "[169, 180] loss: 0.013\n",
      "[169, 240] loss: 0.013\n",
      "[169, 300] loss: 0.012\n",
      "[169, 360] loss: 0.013\n",
      "Epoch: 169 -> Loss: 0.0193349327892\n",
      "Epoch: 169 -> Test Accuracy: 92.305\n",
      "[170, 60] loss: 0.012\n",
      "[170, 120] loss: 0.011\n",
      "[170, 180] loss: 0.011\n",
      "[170, 240] loss: 0.011\n",
      "[170, 300] loss: 0.012\n",
      "[170, 360] loss: 0.012\n",
      "Epoch: 170 -> Loss: 0.00671108905226\n",
      "Epoch: 170 -> Test Accuracy: 92.3\n",
      "[171, 60] loss: 0.012\n",
      "[171, 120] loss: 0.012\n",
      "[171, 180] loss: 0.011\n",
      "[171, 240] loss: 0.012\n",
      "[171, 300] loss: 0.011\n",
      "[171, 360] loss: 0.011\n",
      "Epoch: 171 -> Loss: 0.0132475551218\n",
      "Epoch: 171 -> Test Accuracy: 92.3425\n",
      "[172, 60] loss: 0.011\n",
      "[172, 120] loss: 0.011\n",
      "[172, 180] loss: 0.012\n",
      "[172, 240] loss: 0.011\n",
      "[172, 300] loss: 0.012\n",
      "[172, 360] loss: 0.012\n",
      "Epoch: 172 -> Loss: 0.012542960234\n",
      "Epoch: 172 -> Test Accuracy: 92.2275\n",
      "[173, 60] loss: 0.011\n",
      "[173, 120] loss: 0.011\n",
      "[173, 180] loss: 0.011\n",
      "[173, 240] loss: 0.011\n",
      "[173, 300] loss: 0.011\n",
      "[173, 360] loss: 0.011\n",
      "Epoch: 173 -> Loss: 0.0127477180213\n",
      "Epoch: 173 -> Test Accuracy: 92.29\n",
      "[174, 60] loss: 0.011\n",
      "[174, 120] loss: 0.011\n",
      "[174, 180] loss: 0.010\n",
      "[174, 240] loss: 0.011\n",
      "[174, 300] loss: 0.011\n",
      "[174, 360] loss: 0.011\n",
      "Epoch: 174 -> Loss: 0.0189004428685\n",
      "Epoch: 174 -> Test Accuracy: 92.3675\n",
      "[175, 60] loss: 0.011\n",
      "[175, 120] loss: 0.011\n",
      "[175, 180] loss: 0.011\n",
      "[175, 240] loss: 0.012\n",
      "[175, 300] loss: 0.011\n",
      "[175, 360] loss: 0.011\n",
      "Epoch: 175 -> Loss: 0.0145041197538\n",
      "Epoch: 175 -> Test Accuracy: 92.3025\n",
      "[176, 60] loss: 0.011\n",
      "[176, 120] loss: 0.010\n",
      "[176, 180] loss: 0.011\n",
      "[176, 240] loss: 0.012\n",
      "[176, 300] loss: 0.010\n",
      "[176, 360] loss: 0.011\n",
      "Epoch: 176 -> Loss: 0.00716020679101\n",
      "Epoch: 176 -> Test Accuracy: 92.2875\n",
      "[177, 60] loss: 0.011\n",
      "[177, 120] loss: 0.011\n",
      "[177, 180] loss: 0.010\n",
      "[177, 240] loss: 0.010\n",
      "[177, 300] loss: 0.010\n",
      "[177, 360] loss: 0.010\n",
      "Epoch: 177 -> Loss: 0.00730877975002\n",
      "Epoch: 177 -> Test Accuracy: 92.3125\n",
      "[178, 60] loss: 0.011\n",
      "[178, 120] loss: 0.010\n",
      "[178, 180] loss: 0.010\n",
      "[178, 240] loss: 0.011\n",
      "[178, 300] loss: 0.011\n",
      "[178, 360] loss: 0.011\n",
      "Epoch: 178 -> Loss: 0.0102537814528\n",
      "Epoch: 178 -> Test Accuracy: 92.2075\n",
      "[179, 60] loss: 0.010\n",
      "[179, 120] loss: 0.010\n",
      "[179, 180] loss: 0.011\n",
      "[179, 240] loss: 0.010\n",
      "[179, 300] loss: 0.011\n",
      "[179, 360] loss: 0.011\n",
      "Epoch: 179 -> Loss: 0.0098673067987\n",
      "Epoch: 179 -> Test Accuracy: 92.275\n",
      "[180, 60] loss: 0.011\n",
      "[180, 120] loss: 0.010\n",
      "[180, 180] loss: 0.011\n",
      "[180, 240] loss: 0.010\n",
      "[180, 300] loss: 0.011\n",
      "[180, 360] loss: 0.010\n",
      "Epoch: 180 -> Loss: 0.0147517351434\n",
      "Epoch: 180 -> Test Accuracy: 92.2875\n",
      "[181, 60] loss: 0.010\n",
      "[181, 120] loss: 0.010\n",
      "[181, 180] loss: 0.010\n",
      "[181, 240] loss: 0.010\n",
      "[181, 300] loss: 0.011\n",
      "[181, 360] loss: 0.011\n",
      "Epoch: 181 -> Loss: 0.0207433365285\n",
      "Epoch: 181 -> Test Accuracy: 92.2725\n",
      "[182, 60] loss: 0.011\n",
      "[182, 120] loss: 0.010\n",
      "[182, 180] loss: 0.010\n",
      "[182, 240] loss: 0.010\n",
      "[182, 300] loss: 0.010\n",
      "[182, 360] loss: 0.011\n",
      "Epoch: 182 -> Loss: 0.0101811168715\n",
      "Epoch: 182 -> Test Accuracy: 92.1975\n",
      "[183, 60] loss: 0.010\n",
      "[183, 120] loss: 0.010\n",
      "[183, 180] loss: 0.010\n",
      "[183, 240] loss: 0.010\n",
      "[183, 300] loss: 0.010\n",
      "[183, 360] loss: 0.011\n",
      "Epoch: 183 -> Loss: 0.00410572299734\n",
      "Epoch: 183 -> Test Accuracy: 92.24\n",
      "[184, 60] loss: 0.010\n",
      "[184, 120] loss: 0.010\n",
      "[184, 180] loss: 0.010\n",
      "[184, 240] loss: 0.010\n",
      "[184, 300] loss: 0.011\n",
      "[184, 360] loss: 0.010\n",
      "Epoch: 184 -> Loss: 0.00823272857815\n",
      "Epoch: 184 -> Test Accuracy: 92.2475\n",
      "[185, 60] loss: 0.010\n",
      "[185, 120] loss: 0.010\n",
      "[185, 180] loss: 0.010\n",
      "[185, 240] loss: 0.010\n",
      "[185, 300] loss: 0.010\n",
      "[185, 360] loss: 0.010\n",
      "Epoch: 185 -> Loss: 0.00455053988844\n",
      "Epoch: 185 -> Test Accuracy: 92.1875\n",
      "[186, 60] loss: 0.010\n",
      "[186, 120] loss: 0.010\n",
      "[186, 180] loss: 0.009\n",
      "[186, 240] loss: 0.010\n",
      "[186, 300] loss: 0.010\n",
      "[186, 360] loss: 0.010\n",
      "Epoch: 186 -> Loss: 0.0152216823772\n",
      "Epoch: 186 -> Test Accuracy: 92.2075\n",
      "[187, 60] loss: 0.010\n",
      "[187, 120] loss: 0.010\n",
      "[187, 180] loss: 0.010\n",
      "[187, 240] loss: 0.010\n",
      "[187, 300] loss: 0.010\n",
      "[187, 360] loss: 0.010\n",
      "Epoch: 187 -> Loss: 0.0144632682204\n",
      "Epoch: 187 -> Test Accuracy: 92.1175\n",
      "[188, 60] loss: 0.010\n",
      "[188, 120] loss: 0.009\n",
      "[188, 180] loss: 0.009\n",
      "[188, 240] loss: 0.009\n",
      "[188, 300] loss: 0.010\n",
      "[188, 360] loss: 0.011\n",
      "Epoch: 188 -> Loss: 0.00909430906177\n",
      "Epoch: 188 -> Test Accuracy: 92.2775\n",
      "[189, 60] loss: 0.009\n",
      "[189, 120] loss: 0.010\n",
      "[189, 180] loss: 0.010\n",
      "[189, 240] loss: 0.010\n",
      "[189, 300] loss: 0.010\n",
      "[189, 360] loss: 0.010\n",
      "Epoch: 189 -> Loss: 0.00626015011221\n",
      "Epoch: 189 -> Test Accuracy: 92.25\n",
      "[190, 60] loss: 0.009\n",
      "[190, 120] loss: 0.010\n",
      "[190, 180] loss: 0.010\n",
      "[190, 240] loss: 0.009\n",
      "[190, 300] loss: 0.010\n",
      "[190, 360] loss: 0.010\n",
      "Epoch: 190 -> Loss: 0.0110142864287\n",
      "Epoch: 190 -> Test Accuracy: 92.2825\n",
      "[191, 60] loss: 0.010\n",
      "[191, 120] loss: 0.009\n",
      "[191, 180] loss: 0.010\n",
      "[191, 240] loss: 0.010\n",
      "[191, 300] loss: 0.010\n",
      "[191, 360] loss: 0.011\n",
      "Epoch: 191 -> Loss: 0.00648774206638\n",
      "Epoch: 191 -> Test Accuracy: 92.2425\n",
      "[192, 60] loss: 0.009\n",
      "[192, 120] loss: 0.009\n",
      "[192, 180] loss: 0.009\n",
      "[192, 240] loss: 0.011\n",
      "[192, 300] loss: 0.010\n",
      "[192, 360] loss: 0.010\n",
      "Epoch: 192 -> Loss: 0.00899463333189\n",
      "Epoch: 192 -> Test Accuracy: 92.1375\n",
      "[193, 60] loss: 0.010\n",
      "[193, 120] loss: 0.010\n",
      "[193, 180] loss: 0.009\n",
      "[193, 240] loss: 0.009\n",
      "[193, 300] loss: 0.010\n",
      "[193, 360] loss: 0.009\n",
      "Epoch: 193 -> Loss: 0.010002230294\n",
      "Epoch: 193 -> Test Accuracy: 92.2375\n",
      "[194, 60] loss: 0.009\n",
      "[194, 120] loss: 0.009\n",
      "[194, 180] loss: 0.009\n",
      "[194, 240] loss: 0.010\n",
      "[194, 300] loss: 0.010\n",
      "[194, 360] loss: 0.010\n",
      "Epoch: 194 -> Loss: 0.00691138440743\n",
      "Epoch: 194 -> Test Accuracy: 92.3025\n",
      "[195, 60] loss: 0.009\n",
      "[195, 120] loss: 0.010\n",
      "[195, 180] loss: 0.010\n",
      "[195, 240] loss: 0.009\n",
      "[195, 300] loss: 0.010\n",
      "[195, 360] loss: 0.010\n",
      "Epoch: 195 -> Loss: 0.0063196932897\n",
      "Epoch: 195 -> Test Accuracy: 92.21\n",
      "[196, 60] loss: 0.009\n",
      "[196, 120] loss: 0.010\n",
      "[196, 180] loss: 0.010\n",
      "[196, 240] loss: 0.009\n",
      "[196, 300] loss: 0.010\n",
      "[196, 360] loss: 0.009\n",
      "Epoch: 196 -> Loss: 0.00390409305692\n",
      "Epoch: 196 -> Test Accuracy: 92.2775\n",
      "[197, 60] loss: 0.009\n",
      "[197, 120] loss: 0.010\n",
      "[197, 180] loss: 0.010\n",
      "[197, 240] loss: 0.009\n",
      "[197, 300] loss: 0.009\n",
      "[197, 360] loss: 0.009\n",
      "Epoch: 197 -> Loss: 0.012697884813\n",
      "Epoch: 197 -> Test Accuracy: 92.2025\n",
      "[198, 60] loss: 0.009\n",
      "[198, 120] loss: 0.010\n",
      "[198, 180] loss: 0.009\n",
      "[198, 240] loss: 0.010\n",
      "[198, 300] loss: 0.010\n",
      "[198, 360] loss: 0.010\n",
      "Epoch: 198 -> Loss: 0.0152053683996\n",
      "Epoch: 198 -> Test Accuracy: 92.2075\n",
      "[199, 60] loss: 0.009\n",
      "[199, 120] loss: 0.009\n",
      "[199, 180] loss: 0.009\n",
      "[199, 240] loss: 0.010\n",
      "[199, 300] loss: 0.010\n",
      "[199, 360] loss: 0.010\n",
      "Epoch: 199 -> Loss: 0.00748345116153\n",
      "Epoch: 199 -> Test Accuracy: 92.15\n",
      "[200, 60] loss: 0.009\n",
      "[200, 120] loss: 0.010\n",
      "[200, 180] loss: 0.009\n",
      "[200, 240] loss: 0.009\n",
      "[200, 300] loss: 0.009\n",
      "[200, 360] loss: 0.009\n",
      "Epoch: 200 -> Loss: 0.0125301079825\n",
      "Epoch: 200 -> Test Accuracy: 92.18\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "rot_block3_loss_log, _, rot_block3_test_accuracy_log, _, _ = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], \n",
    "    [60, 120, 160, 200], 0.9, 5e-4, net_block3, criterion, trainloader, None, testloader, rot=['90', '180', '270'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 2.171\n",
      "[1, 120] loss: 1.240\n",
      "[1, 180] loss: 1.114\n",
      "[1, 240] loss: 1.067\n",
      "[1, 300] loss: 1.028\n",
      "[1, 360] loss: 0.990\n",
      "Epoch: 1 -> Loss: 0.935978889465\n",
      "Epoch: 1 -> Test Accuracy: 68.16\n",
      "[2, 60] loss: 0.913\n",
      "[2, 120] loss: 0.896\n",
      "[2, 180] loss: 0.910\n",
      "[2, 240] loss: 0.884\n",
      "[2, 300] loss: 0.879\n",
      "[2, 360] loss: 0.859\n",
      "Epoch: 2 -> Loss: 0.848209738731\n",
      "Epoch: 2 -> Test Accuracy: 71.56\n",
      "[3, 60] loss: 0.802\n",
      "[3, 120] loss: 0.815\n",
      "[3, 180] loss: 0.818\n",
      "[3, 240] loss: 0.781\n",
      "[3, 300] loss: 0.791\n",
      "[3, 360] loss: 0.771\n",
      "Epoch: 3 -> Loss: 0.718413710594\n",
      "Epoch: 3 -> Test Accuracy: 73.4\n",
      "[4, 60] loss: 0.744\n",
      "[4, 120] loss: 0.753\n",
      "[4, 180] loss: 0.751\n",
      "[4, 240] loss: 0.761\n",
      "[4, 300] loss: 0.748\n",
      "[4, 360] loss: 0.744\n",
      "Epoch: 4 -> Loss: 0.582391858101\n",
      "Epoch: 4 -> Test Accuracy: 74.99\n",
      "[5, 60] loss: 0.729\n",
      "[5, 120] loss: 0.721\n",
      "[5, 180] loss: 0.717\n",
      "[5, 240] loss: 0.706\n",
      "[5, 300] loss: 0.729\n",
      "[5, 360] loss: 0.719\n",
      "Epoch: 5 -> Loss: 0.591608643532\n",
      "Epoch: 5 -> Test Accuracy: 75.53\n",
      "[6, 60] loss: 0.685\n",
      "[6, 120] loss: 0.674\n",
      "[6, 180] loss: 0.706\n",
      "[6, 240] loss: 0.687\n",
      "[6, 300] loss: 0.702\n",
      "[6, 360] loss: 0.677\n",
      "Epoch: 6 -> Loss: 0.626615226269\n",
      "Epoch: 6 -> Test Accuracy: 76.43\n",
      "[7, 60] loss: 0.673\n",
      "[7, 120] loss: 0.645\n",
      "[7, 180] loss: 0.680\n",
      "[7, 240] loss: 0.684\n",
      "[7, 300] loss: 0.696\n",
      "[7, 360] loss: 0.668\n",
      "Epoch: 7 -> Loss: 0.672529160976\n",
      "Epoch: 7 -> Test Accuracy: 76.97\n",
      "[8, 60] loss: 0.655\n",
      "[8, 120] loss: 0.671\n",
      "[8, 180] loss: 0.655\n",
      "[8, 240] loss: 0.645\n",
      "[8, 300] loss: 0.660\n",
      "[8, 360] loss: 0.675\n",
      "Epoch: 8 -> Loss: 0.705289661884\n",
      "Epoch: 8 -> Test Accuracy: 77.44\n",
      "[9, 60] loss: 0.634\n",
      "[9, 120] loss: 0.649\n",
      "[9, 180] loss: 0.657\n",
      "[9, 240] loss: 0.638\n",
      "[9, 300] loss: 0.656\n",
      "[9, 360] loss: 0.650\n",
      "Epoch: 9 -> Loss: 0.605553150177\n",
      "Epoch: 9 -> Test Accuracy: 77.15\n",
      "[10, 60] loss: 0.614\n",
      "[10, 120] loss: 0.632\n",
      "[10, 180] loss: 0.639\n",
      "[10, 240] loss: 0.633\n",
      "[10, 300] loss: 0.629\n",
      "[10, 360] loss: 0.649\n",
      "Epoch: 10 -> Loss: 0.607420086861\n",
      "Epoch: 10 -> Test Accuracy: 77.0\n",
      "[11, 60] loss: 0.636\n",
      "[11, 120] loss: 0.616\n",
      "[11, 180] loss: 0.615\n",
      "[11, 240] loss: 0.634\n",
      "[11, 300] loss: 0.628\n",
      "[11, 360] loss: 0.632\n",
      "Epoch: 11 -> Loss: 0.743800461292\n",
      "Epoch: 11 -> Test Accuracy: 78.85\n",
      "[12, 60] loss: 0.603\n",
      "[12, 120] loss: 0.628\n",
      "[12, 180] loss: 0.620\n",
      "[12, 240] loss: 0.616\n",
      "[12, 300] loss: 0.639\n",
      "[12, 360] loss: 0.603\n",
      "Epoch: 12 -> Loss: 0.564823687077\n",
      "Epoch: 12 -> Test Accuracy: 78.48\n",
      "[13, 60] loss: 0.607\n",
      "[13, 120] loss: 0.606\n",
      "[13, 180] loss: 0.615\n",
      "[13, 240] loss: 0.610\n",
      "[13, 300] loss: 0.638\n",
      "[13, 360] loss: 0.617\n",
      "Epoch: 13 -> Loss: 0.723250031471\n",
      "Epoch: 13 -> Test Accuracy: 78.26\n",
      "[14, 60] loss: 0.605\n",
      "[14, 120] loss: 0.608\n",
      "[14, 180] loss: 0.582\n",
      "[14, 240] loss: 0.630\n",
      "[14, 300] loss: 0.615\n",
      "[14, 360] loss: 0.630\n",
      "Epoch: 14 -> Loss: 0.584359049797\n",
      "Epoch: 14 -> Test Accuracy: 78.44\n",
      "[15, 60] loss: 0.592\n",
      "[15, 120] loss: 0.598\n",
      "[15, 180] loss: 0.593\n",
      "[15, 240] loss: 0.614\n",
      "[15, 300] loss: 0.618\n",
      "[15, 360] loss: 0.608\n",
      "Epoch: 15 -> Loss: 0.799444377422\n",
      "Epoch: 15 -> Test Accuracy: 78.93\n",
      "[16, 60] loss: 0.596\n",
      "[16, 120] loss: 0.599\n",
      "[16, 180] loss: 0.611\n",
      "[16, 240] loss: 0.604\n",
      "[16, 300] loss: 0.608\n",
      "[16, 360] loss: 0.611\n",
      "Epoch: 16 -> Loss: 0.72094643116\n",
      "Epoch: 16 -> Test Accuracy: 78.57\n",
      "[17, 60] loss: 0.565\n",
      "[17, 120] loss: 0.591\n",
      "[17, 180] loss: 0.610\n",
      "[17, 240] loss: 0.597\n",
      "[17, 300] loss: 0.616\n",
      "[17, 360] loss: 0.618\n",
      "Epoch: 17 -> Loss: 0.698877930641\n",
      "Epoch: 17 -> Test Accuracy: 78.85\n",
      "[18, 60] loss: 0.583\n",
      "[18, 120] loss: 0.572\n",
      "[18, 180] loss: 0.602\n",
      "[18, 240] loss: 0.589\n",
      "[18, 300] loss: 0.606\n",
      "[18, 360] loss: 0.608\n",
      "Epoch: 18 -> Loss: 0.715551555157\n",
      "Epoch: 18 -> Test Accuracy: 78.77\n",
      "[19, 60] loss: 0.591\n",
      "[19, 120] loss: 0.578\n",
      "[19, 180] loss: 0.607\n",
      "[19, 240] loss: 0.583\n",
      "[19, 300] loss: 0.589\n",
      "[19, 360] loss: 0.600\n",
      "Epoch: 19 -> Loss: 0.487865626812\n",
      "Epoch: 19 -> Test Accuracy: 78.86\n",
      "[20, 60] loss: 0.576\n",
      "[20, 120] loss: 0.602\n",
      "[20, 180] loss: 0.601\n",
      "[20, 240] loss: 0.606\n",
      "[20, 300] loss: 0.578\n",
      "[20, 360] loss: 0.602\n",
      "Epoch: 20 -> Loss: 0.7206813097\n",
      "Epoch: 20 -> Test Accuracy: 78.67\n",
      "[21, 60] loss: 0.530\n",
      "[21, 120] loss: 0.510\n",
      "[21, 180] loss: 0.506\n",
      "[21, 240] loss: 0.476\n",
      "[21, 300] loss: 0.497\n",
      "[21, 360] loss: 0.488\n",
      "Epoch: 21 -> Loss: 0.604942619801\n",
      "Epoch: 21 -> Test Accuracy: 81.07\n",
      "[22, 60] loss: 0.469\n",
      "[22, 120] loss: 0.455\n",
      "[22, 180] loss: 0.455\n",
      "[22, 240] loss: 0.458\n",
      "[22, 300] loss: 0.465\n",
      "[22, 360] loss: 0.457\n",
      "Epoch: 22 -> Loss: 0.371254235506\n",
      "Epoch: 22 -> Test Accuracy: 81.34\n",
      "[23, 60] loss: 0.444\n",
      "[23, 120] loss: 0.442\n",
      "[23, 180] loss: 0.435\n",
      "[23, 240] loss: 0.428\n",
      "[23, 300] loss: 0.445\n",
      "[23, 360] loss: 0.436\n",
      "Epoch: 23 -> Loss: 0.716889023781\n",
      "Epoch: 23 -> Test Accuracy: 81.72\n",
      "[24, 60] loss: 0.415\n",
      "[24, 120] loss: 0.431\n",
      "[24, 180] loss: 0.432\n",
      "[24, 240] loss: 0.424\n",
      "[24, 300] loss: 0.422\n",
      "[24, 360] loss: 0.436\n",
      "Epoch: 24 -> Loss: 0.651299595833\n",
      "Epoch: 24 -> Test Accuracy: 81.64\n",
      "[25, 60] loss: 0.424\n",
      "[25, 120] loss: 0.420\n",
      "[25, 180] loss: 0.410\n",
      "[25, 240] loss: 0.419\n",
      "[25, 300] loss: 0.431\n",
      "[25, 360] loss: 0.419\n",
      "Epoch: 25 -> Loss: 0.400850921869\n",
      "Epoch: 25 -> Test Accuracy: 82.02\n",
      "[26, 60] loss: 0.418\n",
      "[26, 120] loss: 0.416\n",
      "[26, 180] loss: 0.404\n",
      "[26, 240] loss: 0.420\n",
      "[26, 300] loss: 0.410\n",
      "[26, 360] loss: 0.423\n",
      "Epoch: 26 -> Loss: 0.449383735657\n",
      "Epoch: 26 -> Test Accuracy: 82.0\n",
      "[27, 60] loss: 0.401\n",
      "[27, 120] loss: 0.398\n",
      "[27, 180] loss: 0.408\n",
      "[27, 240] loss: 0.398\n",
      "[27, 300] loss: 0.401\n",
      "[27, 360] loss: 0.413\n",
      "Epoch: 27 -> Loss: 0.648454189301\n",
      "Epoch: 27 -> Test Accuracy: 81.92\n",
      "[28, 60] loss: 0.402\n",
      "[28, 120] loss: 0.383\n",
      "[28, 180] loss: 0.402\n",
      "[28, 240] loss: 0.401\n",
      "[28, 300] loss: 0.400\n",
      "[28, 360] loss: 0.402\n",
      "Epoch: 28 -> Loss: 0.475708663464\n",
      "Epoch: 28 -> Test Accuracy: 82.04\n",
      "[29, 60] loss: 0.385\n",
      "[29, 120] loss: 0.420\n",
      "[29, 180] loss: 0.403\n",
      "[29, 240] loss: 0.393\n",
      "[29, 300] loss: 0.390\n",
      "[29, 360] loss: 0.403\n",
      "Epoch: 29 -> Loss: 0.422724664211\n",
      "Epoch: 29 -> Test Accuracy: 81.85\n",
      "[30, 60] loss: 0.395\n",
      "[30, 120] loss: 0.390\n",
      "[30, 180] loss: 0.380\n",
      "[30, 240] loss: 0.411\n",
      "[30, 300] loss: 0.402\n",
      "[30, 360] loss: 0.403\n",
      "Epoch: 30 -> Loss: 0.481606096029\n",
      "Epoch: 30 -> Test Accuracy: 82.27\n",
      "[31, 60] loss: 0.371\n",
      "[31, 120] loss: 0.400\n",
      "[31, 180] loss: 0.373\n",
      "[31, 240] loss: 0.403\n",
      "[31, 300] loss: 0.384\n",
      "[31, 360] loss: 0.423\n",
      "Epoch: 31 -> Loss: 0.47257900238\n",
      "Epoch: 31 -> Test Accuracy: 81.67\n",
      "[32, 60] loss: 0.385\n",
      "[32, 120] loss: 0.390\n",
      "[32, 180] loss: 0.377\n",
      "[32, 240] loss: 0.386\n",
      "[32, 300] loss: 0.403\n",
      "[32, 360] loss: 0.391\n",
      "Epoch: 32 -> Loss: 0.616293132305\n",
      "Epoch: 32 -> Test Accuracy: 81.65\n",
      "[33, 60] loss: 0.375\n",
      "[33, 120] loss: 0.395\n",
      "[33, 180] loss: 0.389\n",
      "[33, 240] loss: 0.387\n",
      "[33, 300] loss: 0.376\n",
      "[33, 360] loss: 0.396\n",
      "Epoch: 33 -> Loss: 0.266899764538\n",
      "Epoch: 33 -> Test Accuracy: 82.07\n",
      "[34, 60] loss: 0.372\n",
      "[34, 120] loss: 0.375\n",
      "[34, 180] loss: 0.399\n",
      "[34, 240] loss: 0.386\n",
      "[34, 300] loss: 0.397\n",
      "[34, 360] loss: 0.384\n",
      "Epoch: 34 -> Loss: 0.325466662645\n",
      "Epoch: 34 -> Test Accuracy: 81.89\n",
      "[35, 60] loss: 0.380\n",
      "[35, 120] loss: 0.374\n",
      "[35, 180] loss: 0.391\n",
      "[35, 240] loss: 0.374\n",
      "[35, 300] loss: 0.386\n",
      "[35, 360] loss: 0.405\n",
      "Epoch: 35 -> Loss: 0.374347239733\n",
      "Epoch: 35 -> Test Accuracy: 81.74\n",
      "[36, 60] loss: 0.364\n",
      "[36, 120] loss: 0.383\n",
      "[36, 180] loss: 0.378\n",
      "[36, 240] loss: 0.378\n",
      "[36, 300] loss: 0.396\n",
      "[36, 360] loss: 0.397\n",
      "Epoch: 36 -> Loss: 0.390222370625\n",
      "Epoch: 36 -> Test Accuracy: 81.7\n",
      "[37, 60] loss: 0.383\n",
      "[37, 120] loss: 0.361\n",
      "[37, 180] loss: 0.381\n",
      "[37, 240] loss: 0.374\n",
      "[37, 300] loss: 0.396\n",
      "[37, 360] loss: 0.399\n",
      "Epoch: 37 -> Loss: 0.276094555855\n",
      "Epoch: 37 -> Test Accuracy: 81.64\n",
      "[38, 60] loss: 0.363\n",
      "[38, 120] loss: 0.382\n",
      "[38, 180] loss: 0.394\n",
      "[38, 240] loss: 0.382\n",
      "[38, 300] loss: 0.373\n",
      "[38, 360] loss: 0.378\n",
      "Epoch: 38 -> Loss: 0.326752573252\n",
      "Epoch: 38 -> Test Accuracy: 82.17\n",
      "[39, 60] loss: 0.361\n",
      "[39, 120] loss: 0.380\n",
      "[39, 180] loss: 0.394\n",
      "[39, 240] loss: 0.372\n",
      "[39, 300] loss: 0.396\n",
      "[39, 360] loss: 0.396\n",
      "Epoch: 39 -> Loss: 0.265857458115\n",
      "Epoch: 39 -> Test Accuracy: 81.58\n",
      "[40, 60] loss: 0.350\n",
      "[40, 120] loss: 0.372\n",
      "[40, 180] loss: 0.377\n",
      "[40, 240] loss: 0.405\n",
      "[40, 300] loss: 0.384\n",
      "[40, 360] loss: 0.374\n",
      "Epoch: 40 -> Loss: 0.530530691147\n",
      "Epoch: 40 -> Test Accuracy: 81.58\n",
      "[41, 60] loss: 0.370\n",
      "[41, 120] loss: 0.336\n",
      "[41, 180] loss: 0.326\n",
      "[41, 240] loss: 0.327\n",
      "[41, 300] loss: 0.326\n",
      "[41, 360] loss: 0.341\n",
      "Epoch: 41 -> Loss: 0.302820771933\n",
      "Epoch: 41 -> Test Accuracy: 82.14\n",
      "[42, 60] loss: 0.322\n",
      "[42, 120] loss: 0.310\n",
      "[42, 180] loss: 0.317\n",
      "[42, 240] loss: 0.311\n",
      "[42, 300] loss: 0.320\n",
      "[42, 360] loss: 0.309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.499528080225\n",
      "Epoch: 42 -> Test Accuracy: 82.43\n",
      "[43, 60] loss: 0.316\n",
      "[43, 120] loss: 0.297\n",
      "[43, 180] loss: 0.300\n",
      "[43, 240] loss: 0.293\n",
      "[43, 300] loss: 0.321\n",
      "[43, 360] loss: 0.311\n",
      "Epoch: 43 -> Loss: 0.406891971827\n",
      "Epoch: 43 -> Test Accuracy: 82.62\n",
      "[44, 60] loss: 0.304\n",
      "[44, 120] loss: 0.303\n",
      "[44, 180] loss: 0.296\n",
      "[44, 240] loss: 0.310\n",
      "[44, 300] loss: 0.314\n",
      "[44, 360] loss: 0.302\n",
      "Epoch: 44 -> Loss: 0.320390552282\n",
      "Epoch: 44 -> Test Accuracy: 82.83\n",
      "[45, 60] loss: 0.294\n",
      "[45, 120] loss: 0.283\n",
      "[45, 180] loss: 0.301\n",
      "[45, 240] loss: 0.303\n",
      "[45, 300] loss: 0.288\n",
      "[45, 360] loss: 0.295\n",
      "Epoch: 45 -> Loss: 0.312586247921\n",
      "Epoch: 45 -> Test Accuracy: 82.91\n",
      "[46, 60] loss: 0.270\n",
      "[46, 120] loss: 0.291\n",
      "[46, 180] loss: 0.273\n",
      "[46, 240] loss: 0.280\n",
      "[46, 300] loss: 0.279\n",
      "[46, 360] loss: 0.280\n",
      "Epoch: 46 -> Loss: 0.194979950786\n",
      "Epoch: 46 -> Test Accuracy: 82.96\n",
      "[47, 60] loss: 0.265\n",
      "[47, 120] loss: 0.262\n",
      "[47, 180] loss: 0.281\n",
      "[47, 240] loss: 0.273\n",
      "[47, 300] loss: 0.284\n",
      "[47, 360] loss: 0.283\n",
      "Epoch: 47 -> Loss: 0.269471824169\n",
      "Epoch: 47 -> Test Accuracy: 82.88\n",
      "[48, 60] loss: 0.272\n",
      "[48, 120] loss: 0.279\n",
      "[48, 180] loss: 0.277\n",
      "[48, 240] loss: 0.279\n",
      "[48, 300] loss: 0.271\n",
      "[48, 360] loss: 0.285\n",
      "Epoch: 48 -> Loss: 0.315538585186\n",
      "Epoch: 48 -> Test Accuracy: 83.07\n",
      "[49, 60] loss: 0.271\n",
      "[49, 120] loss: 0.272\n",
      "[49, 180] loss: 0.276\n",
      "[49, 240] loss: 0.271\n",
      "[49, 300] loss: 0.270\n",
      "[49, 360] loss: 0.274\n",
      "Epoch: 49 -> Loss: 0.239281222224\n",
      "Epoch: 49 -> Test Accuracy: 83.16\n",
      "[50, 60] loss: 0.265\n",
      "[50, 120] loss: 0.265\n",
      "[50, 180] loss: 0.280\n",
      "[50, 240] loss: 0.268\n",
      "[50, 300] loss: 0.255\n",
      "[50, 360] loss: 0.276\n",
      "Epoch: 50 -> Loss: 0.236351445317\n",
      "Epoch: 50 -> Test Accuracy: 82.96\n",
      "[51, 60] loss: 0.269\n",
      "[51, 120] loss: 0.279\n",
      "[51, 180] loss: 0.286\n",
      "[51, 240] loss: 0.268\n",
      "[51, 300] loss: 0.260\n",
      "[51, 360] loss: 0.258\n",
      "Epoch: 51 -> Loss: 0.373202264309\n",
      "Epoch: 51 -> Test Accuracy: 83.12\n",
      "[52, 60] loss: 0.282\n",
      "[52, 120] loss: 0.282\n",
      "[52, 180] loss: 0.272\n",
      "[52, 240] loss: 0.250\n",
      "[52, 300] loss: 0.269\n",
      "[52, 360] loss: 0.263\n",
      "Epoch: 52 -> Loss: 0.249074488878\n",
      "Epoch: 52 -> Test Accuracy: 83.22\n",
      "[53, 60] loss: 0.271\n",
      "[53, 120] loss: 0.262\n",
      "[53, 180] loss: 0.269\n",
      "[53, 240] loss: 0.265\n",
      "[53, 300] loss: 0.269\n",
      "[53, 360] loss: 0.270\n",
      "Epoch: 53 -> Loss: 0.26648670435\n",
      "Epoch: 53 -> Test Accuracy: 83.21\n",
      "[54, 60] loss: 0.261\n",
      "[54, 120] loss: 0.262\n",
      "[54, 180] loss: 0.255\n",
      "[54, 240] loss: 0.270\n",
      "[54, 300] loss: 0.262\n",
      "[54, 360] loss: 0.254\n",
      "Epoch: 54 -> Loss: 0.318266391754\n",
      "Epoch: 54 -> Test Accuracy: 83.18\n",
      "[55, 60] loss: 0.252\n",
      "[55, 120] loss: 0.272\n",
      "[55, 180] loss: 0.274\n",
      "[55, 240] loss: 0.245\n",
      "[55, 300] loss: 0.271\n",
      "[55, 360] loss: 0.262\n",
      "Epoch: 55 -> Loss: 0.249261707067\n",
      "Epoch: 55 -> Test Accuracy: 83.19\n",
      "[56, 60] loss: 0.262\n",
      "[56, 120] loss: 0.260\n",
      "[56, 180] loss: 0.275\n",
      "[56, 240] loss: 0.252\n",
      "[56, 300] loss: 0.269\n",
      "[56, 360] loss: 0.262\n",
      "Epoch: 56 -> Loss: 0.209169432521\n",
      "Epoch: 56 -> Test Accuracy: 83.02\n",
      "[57, 60] loss: 0.274\n",
      "[57, 120] loss: 0.247\n",
      "[57, 180] loss: 0.263\n",
      "[57, 240] loss: 0.251\n",
      "[57, 300] loss: 0.262\n",
      "[57, 360] loss: 0.262\n",
      "Epoch: 57 -> Loss: 0.360153824091\n",
      "Epoch: 57 -> Test Accuracy: 83.03\n",
      "[58, 60] loss: 0.263\n",
      "[58, 120] loss: 0.268\n",
      "[58, 180] loss: 0.262\n",
      "[58, 240] loss: 0.254\n",
      "[58, 300] loss: 0.262\n",
      "[58, 360] loss: 0.269\n",
      "Epoch: 58 -> Loss: 0.252646684647\n",
      "Epoch: 58 -> Test Accuracy: 83.09\n",
      "[59, 60] loss: 0.242\n",
      "[59, 120] loss: 0.259\n",
      "[59, 180] loss: 0.265\n",
      "[59, 240] loss: 0.254\n",
      "[59, 300] loss: 0.253\n",
      "[59, 360] loss: 0.266\n",
      "Epoch: 59 -> Loss: 0.328783601522\n",
      "Epoch: 59 -> Test Accuracy: 82.87\n",
      "[60, 60] loss: 0.245\n",
      "[60, 120] loss: 0.262\n",
      "[60, 180] loss: 0.260\n",
      "[60, 240] loss: 0.256\n",
      "[60, 300] loss: 0.248\n",
      "[60, 360] loss: 0.252\n",
      "Epoch: 60 -> Loss: 0.131860256195\n",
      "Epoch: 60 -> Test Accuracy: 83.0\n",
      "[61, 60] loss: 0.258\n",
      "[61, 120] loss: 0.254\n",
      "[61, 180] loss: 0.263\n",
      "[61, 240] loss: 0.260\n",
      "[61, 300] loss: 0.254\n",
      "[61, 360] loss: 0.258\n",
      "Epoch: 61 -> Loss: 0.300913959742\n",
      "Epoch: 61 -> Test Accuracy: 83.1\n",
      "[62, 60] loss: 0.260\n",
      "[62, 120] loss: 0.257\n",
      "[62, 180] loss: 0.255\n",
      "[62, 240] loss: 0.254\n",
      "[62, 300] loss: 0.256\n",
      "[62, 360] loss: 0.257\n",
      "Epoch: 62 -> Loss: 0.306914627552\n",
      "Epoch: 62 -> Test Accuracy: 83.01\n",
      "[63, 60] loss: 0.244\n",
      "[63, 120] loss: 0.256\n",
      "[63, 180] loss: 0.257\n",
      "[63, 240] loss: 0.250\n",
      "[63, 300] loss: 0.257\n",
      "[63, 360] loss: 0.255\n",
      "Epoch: 63 -> Loss: 0.130491942167\n",
      "Epoch: 63 -> Test Accuracy: 83.05\n",
      "[64, 60] loss: 0.253\n",
      "[64, 120] loss: 0.255\n",
      "[64, 180] loss: 0.256\n",
      "[64, 240] loss: 0.253\n",
      "[64, 300] loss: 0.256\n",
      "[64, 360] loss: 0.257\n",
      "Epoch: 64 -> Loss: 0.266778707504\n",
      "Epoch: 64 -> Test Accuracy: 82.99\n",
      "[65, 60] loss: 0.245\n",
      "[65, 120] loss: 0.261\n",
      "[65, 180] loss: 0.251\n",
      "[65, 240] loss: 0.255\n",
      "[65, 300] loss: 0.243\n",
      "[65, 360] loss: 0.248\n",
      "Epoch: 65 -> Loss: 0.214233279228\n",
      "Epoch: 65 -> Test Accuracy: 83.06\n",
      "[66, 60] loss: 0.260\n",
      "[66, 120] loss: 0.253\n",
      "[66, 180] loss: 0.253\n",
      "[66, 240] loss: 0.255\n",
      "[66, 300] loss: 0.242\n",
      "[66, 360] loss: 0.244\n",
      "Epoch: 66 -> Loss: 0.168213576078\n",
      "Epoch: 66 -> Test Accuracy: 83.04\n",
      "[67, 60] loss: 0.244\n",
      "[67, 120] loss: 0.239\n",
      "[67, 180] loss: 0.255\n",
      "[67, 240] loss: 0.256\n",
      "[67, 300] loss: 0.251\n",
      "[67, 360] loss: 0.253\n",
      "Epoch: 67 -> Loss: 0.353157371283\n",
      "Epoch: 67 -> Test Accuracy: 83.09\n",
      "[68, 60] loss: 0.256\n",
      "[68, 120] loss: 0.260\n",
      "[68, 180] loss: 0.253\n",
      "[68, 240] loss: 0.242\n",
      "[68, 300] loss: 0.244\n",
      "[68, 360] loss: 0.248\n",
      "Epoch: 68 -> Loss: 0.450031578541\n",
      "Epoch: 68 -> Test Accuracy: 83.05\n",
      "[69, 60] loss: 0.256\n",
      "[69, 120] loss: 0.248\n",
      "[69, 180] loss: 0.244\n",
      "[69, 240] loss: 0.241\n",
      "[69, 300] loss: 0.248\n",
      "[69, 360] loss: 0.264\n",
      "Epoch: 69 -> Loss: 0.213656306267\n",
      "Epoch: 69 -> Test Accuracy: 83.12\n",
      "[70, 60] loss: 0.249\n",
      "[70, 120] loss: 0.252\n",
      "[70, 180] loss: 0.245\n",
      "[70, 240] loss: 0.233\n",
      "[70, 300] loss: 0.253\n",
      "[70, 360] loss: 0.244\n",
      "Epoch: 70 -> Loss: 0.204089492559\n",
      "Epoch: 70 -> Test Accuracy: 83.29\n",
      "[71, 60] loss: 0.248\n",
      "[71, 120] loss: 0.243\n",
      "[71, 180] loss: 0.248\n",
      "[71, 240] loss: 0.244\n",
      "[71, 300] loss: 0.252\n",
      "[71, 360] loss: 0.249\n",
      "Epoch: 71 -> Loss: 0.274948507547\n",
      "Epoch: 71 -> Test Accuracy: 83.03\n",
      "[72, 60] loss: 0.241\n",
      "[72, 120] loss: 0.230\n",
      "[72, 180] loss: 0.243\n",
      "[72, 240] loss: 0.245\n",
      "[72, 300] loss: 0.239\n",
      "[72, 360] loss: 0.240\n",
      "Epoch: 72 -> Loss: 0.202334210277\n",
      "Epoch: 72 -> Test Accuracy: 83.1\n",
      "[73, 60] loss: 0.231\n",
      "[73, 120] loss: 0.248\n",
      "[73, 180] loss: 0.242\n",
      "[73, 240] loss: 0.232\n",
      "[73, 300] loss: 0.245\n",
      "[73, 360] loss: 0.244\n",
      "Epoch: 73 -> Loss: 0.223441168666\n",
      "Epoch: 73 -> Test Accuracy: 83.19\n",
      "[74, 60] loss: 0.236\n",
      "[74, 120] loss: 0.243\n",
      "[74, 180] loss: 0.237\n",
      "[74, 240] loss: 0.242\n",
      "[74, 300] loss: 0.241\n",
      "[74, 360] loss: 0.237\n",
      "Epoch: 74 -> Loss: 0.264511048794\n",
      "Epoch: 74 -> Test Accuracy: 83.15\n",
      "[75, 60] loss: 0.233\n",
      "[75, 120] loss: 0.234\n",
      "[75, 180] loss: 0.243\n",
      "[75, 240] loss: 0.245\n",
      "[75, 300] loss: 0.243\n",
      "[75, 360] loss: 0.250\n",
      "Epoch: 75 -> Loss: 0.220622971654\n",
      "Epoch: 75 -> Test Accuracy: 83.21\n",
      "[76, 60] loss: 0.225\n",
      "[76, 120] loss: 0.232\n",
      "[76, 180] loss: 0.236\n",
      "[76, 240] loss: 0.247\n",
      "[76, 300] loss: 0.257\n",
      "[76, 360] loss: 0.236\n",
      "Epoch: 76 -> Loss: 0.278841912746\n",
      "Epoch: 76 -> Test Accuracy: 83.14\n",
      "[77, 60] loss: 0.238\n",
      "[77, 120] loss: 0.246\n",
      "[77, 180] loss: 0.222\n",
      "[77, 240] loss: 0.234\n",
      "[77, 300] loss: 0.235\n",
      "[77, 360] loss: 0.242\n",
      "Epoch: 77 -> Loss: 0.360500156879\n",
      "Epoch: 77 -> Test Accuracy: 83.11\n",
      "[78, 60] loss: 0.245\n",
      "[78, 120] loss: 0.231\n",
      "[78, 180] loss: 0.243\n",
      "[78, 240] loss: 0.247\n",
      "[78, 300] loss: 0.239\n",
      "[78, 360] loss: 0.228\n",
      "Epoch: 78 -> Loss: 0.221616119146\n",
      "Epoch: 78 -> Test Accuracy: 83.12\n",
      "[79, 60] loss: 0.226\n",
      "[79, 120] loss: 0.231\n",
      "[79, 180] loss: 0.242\n",
      "[79, 240] loss: 0.228\n",
      "[79, 300] loss: 0.239\n",
      "[79, 360] loss: 0.251\n",
      "Epoch: 79 -> Loss: 0.396942287683\n",
      "Epoch: 79 -> Test Accuracy: 83.27\n",
      "[80, 60] loss: 0.239\n",
      "[80, 120] loss: 0.240\n",
      "[80, 180] loss: 0.239\n",
      "[80, 240] loss: 0.239\n",
      "[80, 300] loss: 0.227\n",
      "[80, 360] loss: 0.245\n",
      "Epoch: 80 -> Loss: 0.179501473904\n",
      "Epoch: 80 -> Test Accuracy: 83.07\n",
      "[81, 60] loss: 0.236\n",
      "[81, 120] loss: 0.240\n",
      "[81, 180] loss: 0.225\n",
      "[81, 240] loss: 0.223\n",
      "[81, 300] loss: 0.231\n",
      "[81, 360] loss: 0.239\n",
      "Epoch: 81 -> Loss: 0.301698207855\n",
      "Epoch: 81 -> Test Accuracy: 83.2\n",
      "[82, 60] loss: 0.235\n",
      "[82, 120] loss: 0.228\n",
      "[82, 180] loss: 0.240\n",
      "[82, 240] loss: 0.237\n",
      "[82, 300] loss: 0.239\n",
      "[82, 360] loss: 0.232\n",
      "Epoch: 82 -> Loss: 0.238362938166\n",
      "Epoch: 82 -> Test Accuracy: 83.18\n",
      "[83, 60] loss: 0.239\n",
      "[83, 120] loss: 0.235\n",
      "[83, 180] loss: 0.240\n",
      "[83, 240] loss: 0.235\n",
      "[83, 300] loss: 0.234\n",
      "[83, 360] loss: 0.236\n",
      "Epoch: 83 -> Loss: 0.219481185079\n",
      "Epoch: 83 -> Test Accuracy: 83.17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.225\n",
      "[84, 120] loss: 0.233\n",
      "[84, 180] loss: 0.226\n",
      "[84, 240] loss: 0.234\n",
      "[84, 300] loss: 0.219\n",
      "[84, 360] loss: 0.229\n",
      "Epoch: 84 -> Loss: 0.274143129587\n",
      "Epoch: 84 -> Test Accuracy: 83.05\n",
      "[85, 60] loss: 0.234\n",
      "[85, 120] loss: 0.235\n",
      "[85, 180] loss: 0.235\n",
      "[85, 240] loss: 0.224\n",
      "[85, 300] loss: 0.223\n",
      "[85, 360] loss: 0.221\n",
      "Epoch: 85 -> Loss: 0.231608301401\n",
      "Epoch: 85 -> Test Accuracy: 83.24\n",
      "[86, 60] loss: 0.215\n",
      "[86, 120] loss: 0.228\n",
      "[86, 180] loss: 0.226\n",
      "[86, 240] loss: 0.252\n",
      "[86, 300] loss: 0.234\n",
      "[86, 360] loss: 0.225\n",
      "Epoch: 86 -> Loss: 0.314946234226\n",
      "Epoch: 86 -> Test Accuracy: 83.16\n",
      "[87, 60] loss: 0.224\n",
      "[87, 120] loss: 0.233\n",
      "[87, 180] loss: 0.233\n",
      "[87, 240] loss: 0.229\n",
      "[87, 300] loss: 0.230\n",
      "[87, 360] loss: 0.237\n",
      "Epoch: 87 -> Loss: 0.226608663797\n",
      "Epoch: 87 -> Test Accuracy: 83.24\n",
      "[88, 60] loss: 0.228\n",
      "[88, 120] loss: 0.227\n",
      "[88, 180] loss: 0.237\n",
      "[88, 240] loss: 0.228\n",
      "[88, 300] loss: 0.216\n",
      "[88, 360] loss: 0.233\n",
      "Epoch: 88 -> Loss: 0.336185872555\n",
      "Epoch: 88 -> Test Accuracy: 83.25\n",
      "[89, 60] loss: 0.231\n",
      "[89, 120] loss: 0.224\n",
      "[89, 180] loss: 0.227\n",
      "[89, 240] loss: 0.230\n",
      "[89, 300] loss: 0.232\n",
      "[89, 360] loss: 0.229\n",
      "Epoch: 89 -> Loss: 0.274785578251\n",
      "Epoch: 89 -> Test Accuracy: 83.35\n",
      "[90, 60] loss: 0.219\n",
      "[90, 120] loss: 0.231\n",
      "[90, 180] loss: 0.221\n",
      "[90, 240] loss: 0.224\n",
      "[90, 300] loss: 0.227\n",
      "[90, 360] loss: 0.221\n",
      "Epoch: 90 -> Loss: 0.109966441989\n",
      "Epoch: 90 -> Test Accuracy: 83.26\n",
      "[91, 60] loss: 0.224\n",
      "[91, 120] loss: 0.229\n",
      "[91, 180] loss: 0.221\n",
      "[91, 240] loss: 0.234\n",
      "[91, 300] loss: 0.231\n",
      "[91, 360] loss: 0.226\n",
      "Epoch: 91 -> Loss: 0.26854968071\n",
      "Epoch: 91 -> Test Accuracy: 83.25\n",
      "[92, 60] loss: 0.220\n",
      "[92, 120] loss: 0.224\n",
      "[92, 180] loss: 0.228\n",
      "[92, 240] loss: 0.221\n",
      "[92, 300] loss: 0.220\n",
      "[92, 360] loss: 0.239\n",
      "Epoch: 92 -> Loss: 0.246461555362\n",
      "Epoch: 92 -> Test Accuracy: 83.13\n",
      "[93, 60] loss: 0.220\n",
      "[93, 120] loss: 0.214\n",
      "[93, 180] loss: 0.237\n",
      "[93, 240] loss: 0.223\n",
      "[93, 300] loss: 0.226\n",
      "[93, 360] loss: 0.227\n",
      "Epoch: 93 -> Loss: 0.216363951564\n",
      "Epoch: 93 -> Test Accuracy: 82.97\n",
      "[94, 60] loss: 0.225\n",
      "[94, 120] loss: 0.212\n",
      "[94, 180] loss: 0.223\n",
      "[94, 240] loss: 0.232\n",
      "[94, 300] loss: 0.214\n",
      "[94, 360] loss: 0.217\n",
      "Epoch: 94 -> Loss: 0.195717900991\n",
      "Epoch: 94 -> Test Accuracy: 83.01\n",
      "[95, 60] loss: 0.220\n",
      "[95, 120] loss: 0.234\n",
      "[95, 180] loss: 0.221\n",
      "[95, 240] loss: 0.227\n",
      "[95, 300] loss: 0.218\n",
      "[95, 360] loss: 0.222\n",
      "Epoch: 95 -> Loss: 0.364811241627\n",
      "Epoch: 95 -> Test Accuracy: 83.13\n",
      "[96, 60] loss: 0.212\n",
      "[96, 120] loss: 0.226\n",
      "[96, 180] loss: 0.221\n",
      "[96, 240] loss: 0.227\n",
      "[96, 300] loss: 0.222\n",
      "[96, 360] loss: 0.221\n",
      "Epoch: 96 -> Loss: 0.284765213728\n",
      "Epoch: 96 -> Test Accuracy: 83.07\n",
      "[97, 60] loss: 0.227\n",
      "[97, 120] loss: 0.224\n",
      "[97, 180] loss: 0.223\n",
      "[97, 240] loss: 0.224\n",
      "[97, 300] loss: 0.224\n",
      "[97, 360] loss: 0.224\n",
      "Epoch: 97 -> Loss: 0.162503868341\n",
      "Epoch: 97 -> Test Accuracy: 83.21\n",
      "[98, 60] loss: 0.220\n",
      "[98, 120] loss: 0.218\n",
      "[98, 180] loss: 0.218\n",
      "[98, 240] loss: 0.223\n",
      "[98, 300] loss: 0.220\n",
      "[98, 360] loss: 0.227\n",
      "Epoch: 98 -> Loss: 0.182535171509\n",
      "Epoch: 98 -> Test Accuracy: 83.11\n",
      "[99, 60] loss: 0.230\n",
      "[99, 120] loss: 0.213\n",
      "[99, 180] loss: 0.218\n",
      "[99, 240] loss: 0.220\n",
      "[99, 300] loss: 0.229\n",
      "[99, 360] loss: 0.222\n",
      "Epoch: 99 -> Loss: 0.38889503479\n",
      "Epoch: 99 -> Test Accuracy: 82.98\n",
      "[100, 60] loss: 0.220\n",
      "[100, 120] loss: 0.227\n",
      "[100, 180] loss: 0.218\n",
      "[100, 240] loss: 0.217\n",
      "[100, 300] loss: 0.229\n",
      "[100, 360] loss: 0.213\n",
      "Epoch: 100 -> Loss: 0.217172712088\n",
      "Epoch: 100 -> Test Accuracy: 83.11\n",
      "Finished Training\n",
      "[1, 60] loss: 1.633\n",
      "[1, 120] loss: 0.820\n",
      "[1, 180] loss: 0.752\n",
      "[1, 240] loss: 0.691\n",
      "[1, 300] loss: 0.677\n",
      "[1, 360] loss: 0.650\n",
      "Epoch: 1 -> Loss: 0.777661263943\n",
      "Epoch: 1 -> Test Accuracy: 78.31\n",
      "[2, 60] loss: 0.581\n",
      "[2, 120] loss: 0.566\n",
      "[2, 180] loss: 0.587\n",
      "[2, 240] loss: 0.573\n",
      "[2, 300] loss: 0.557\n",
      "[2, 360] loss: 0.543\n",
      "Epoch: 2 -> Loss: 0.557449996471\n",
      "Epoch: 2 -> Test Accuracy: 80.53\n",
      "[3, 60] loss: 0.515\n",
      "[3, 120] loss: 0.527\n",
      "[3, 180] loss: 0.512\n",
      "[3, 240] loss: 0.500\n",
      "[3, 300] loss: 0.514\n",
      "[3, 360] loss: 0.506\n",
      "Epoch: 3 -> Loss: 0.622103393078\n",
      "Epoch: 3 -> Test Accuracy: 81.32\n",
      "[4, 60] loss: 0.489\n",
      "[4, 120] loss: 0.467\n",
      "[4, 180] loss: 0.481\n",
      "[4, 240] loss: 0.473\n",
      "[4, 300] loss: 0.470\n",
      "[4, 360] loss: 0.472\n",
      "Epoch: 4 -> Loss: 0.441720813513\n",
      "Epoch: 4 -> Test Accuracy: 81.7\n",
      "[5, 60] loss: 0.456\n",
      "[5, 120] loss: 0.437\n",
      "[5, 180] loss: 0.448\n",
      "[5, 240] loss: 0.463\n",
      "[5, 300] loss: 0.452\n",
      "[5, 360] loss: 0.474\n",
      "Epoch: 5 -> Loss: 0.473736763\n",
      "Epoch: 5 -> Test Accuracy: 82.12\n",
      "[6, 60] loss: 0.413\n",
      "[6, 120] loss: 0.428\n",
      "[6, 180] loss: 0.449\n",
      "[6, 240] loss: 0.433\n",
      "[6, 300] loss: 0.446\n",
      "[6, 360] loss: 0.456\n",
      "Epoch: 6 -> Loss: 0.579617142677\n",
      "Epoch: 6 -> Test Accuracy: 82.67\n",
      "[7, 60] loss: 0.395\n",
      "[7, 120] loss: 0.416\n",
      "[7, 180] loss: 0.432\n",
      "[7, 240] loss: 0.443\n",
      "[7, 300] loss: 0.435\n",
      "[7, 360] loss: 0.427\n",
      "Epoch: 7 -> Loss: 0.419815957546\n",
      "Epoch: 7 -> Test Accuracy: 82.82\n",
      "[8, 60] loss: 0.406\n",
      "[8, 120] loss: 0.411\n",
      "[8, 180] loss: 0.417\n",
      "[8, 240] loss: 0.416\n",
      "[8, 300] loss: 0.410\n",
      "[8, 360] loss: 0.424\n",
      "Epoch: 8 -> Loss: 0.438278019428\n",
      "Epoch: 8 -> Test Accuracy: 82.99\n",
      "[9, 60] loss: 0.401\n",
      "[9, 120] loss: 0.386\n",
      "[9, 180] loss: 0.404\n",
      "[9, 240] loss: 0.408\n",
      "[9, 300] loss: 0.425\n",
      "[9, 360] loss: 0.407\n",
      "Epoch: 9 -> Loss: 0.238662987947\n",
      "Epoch: 9 -> Test Accuracy: 82.83\n",
      "[10, 60] loss: 0.389\n",
      "[10, 120] loss: 0.402\n",
      "[10, 180] loss: 0.398\n",
      "[10, 240] loss: 0.396\n",
      "[10, 300] loss: 0.404\n",
      "[10, 360] loss: 0.393\n",
      "Epoch: 10 -> Loss: 0.429576396942\n",
      "Epoch: 10 -> Test Accuracy: 83.17\n",
      "[11, 60] loss: 0.365\n",
      "[11, 120] loss: 0.374\n",
      "[11, 180] loss: 0.375\n",
      "[11, 240] loss: 0.401\n",
      "[11, 300] loss: 0.388\n",
      "[11, 360] loss: 0.405\n",
      "Epoch: 11 -> Loss: 0.367703050375\n",
      "Epoch: 11 -> Test Accuracy: 83.1\n",
      "[12, 60] loss: 0.354\n",
      "[12, 120] loss: 0.369\n",
      "[12, 180] loss: 0.387\n",
      "[12, 240] loss: 0.399\n",
      "[12, 300] loss: 0.414\n",
      "[12, 360] loss: 0.393\n",
      "Epoch: 12 -> Loss: 0.362608343363\n",
      "Epoch: 12 -> Test Accuracy: 82.44\n",
      "[13, 60] loss: 0.361\n",
      "[13, 120] loss: 0.364\n",
      "[13, 180] loss: 0.374\n",
      "[13, 240] loss: 0.393\n",
      "[13, 300] loss: 0.400\n",
      "[13, 360] loss: 0.397\n",
      "Epoch: 13 -> Loss: 0.31224656105\n",
      "Epoch: 13 -> Test Accuracy: 83.92\n",
      "[14, 60] loss: 0.349\n",
      "[14, 120] loss: 0.368\n",
      "[14, 180] loss: 0.375\n",
      "[14, 240] loss: 0.398\n",
      "[14, 300] loss: 0.393\n",
      "[14, 360] loss: 0.394\n",
      "Epoch: 14 -> Loss: 0.486145347357\n",
      "Epoch: 14 -> Test Accuracy: 83.33\n",
      "[15, 60] loss: 0.349\n",
      "[15, 120] loss: 0.372\n",
      "[15, 180] loss: 0.373\n",
      "[15, 240] loss: 0.379\n",
      "[15, 300] loss: 0.382\n",
      "[15, 360] loss: 0.398\n",
      "Epoch: 15 -> Loss: 0.404132783413\n",
      "Epoch: 15 -> Test Accuracy: 83.2\n",
      "[16, 60] loss: 0.351\n",
      "[16, 120] loss: 0.354\n",
      "[16, 180] loss: 0.366\n",
      "[16, 240] loss: 0.358\n",
      "[16, 300] loss: 0.393\n",
      "[16, 360] loss: 0.388\n",
      "Epoch: 16 -> Loss: 0.348648428917\n",
      "Epoch: 16 -> Test Accuracy: 83.47\n",
      "[17, 60] loss: 0.358\n",
      "[17, 120] loss: 0.369\n",
      "[17, 180] loss: 0.354\n",
      "[17, 240] loss: 0.375\n",
      "[17, 300] loss: 0.380\n",
      "[17, 360] loss: 0.380\n",
      "Epoch: 17 -> Loss: 0.447795003653\n",
      "Epoch: 17 -> Test Accuracy: 83.9\n",
      "[18, 60] loss: 0.347\n",
      "[18, 120] loss: 0.358\n",
      "[18, 180] loss: 0.378\n",
      "[18, 240] loss: 0.374\n",
      "[18, 300] loss: 0.363\n",
      "[18, 360] loss: 0.374\n",
      "Epoch: 18 -> Loss: 0.4171833992\n",
      "Epoch: 18 -> Test Accuracy: 84.1\n",
      "[19, 60] loss: 0.332\n",
      "[19, 120] loss: 0.370\n",
      "[19, 180] loss: 0.377\n",
      "[19, 240] loss: 0.365\n",
      "[19, 300] loss: 0.361\n",
      "[19, 360] loss: 0.376\n",
      "Epoch: 19 -> Loss: 0.619427859783\n",
      "Epoch: 19 -> Test Accuracy: 84.05\n",
      "[20, 60] loss: 0.325\n",
      "[20, 120] loss: 0.351\n",
      "[20, 180] loss: 0.347\n",
      "[20, 240] loss: 0.374\n",
      "[20, 300] loss: 0.385\n",
      "[20, 360] loss: 0.389\n",
      "Epoch: 20 -> Loss: 0.340908706188\n",
      "Epoch: 20 -> Test Accuracy: 83.41\n",
      "[21, 60] loss: 0.324\n",
      "[21, 120] loss: 0.303\n",
      "[21, 180] loss: 0.295\n",
      "[21, 240] loss: 0.286\n",
      "[21, 300] loss: 0.268\n",
      "[21, 360] loss: 0.278\n",
      "Epoch: 21 -> Loss: 0.334835201502\n",
      "Epoch: 21 -> Test Accuracy: 85.3\n",
      "[22, 60] loss: 0.262\n",
      "[22, 120] loss: 0.256\n",
      "[22, 180] loss: 0.258\n",
      "[22, 240] loss: 0.254\n",
      "[22, 300] loss: 0.261\n",
      "[22, 360] loss: 0.263\n",
      "Epoch: 22 -> Loss: 0.245100498199\n",
      "Epoch: 22 -> Test Accuracy: 85.95\n",
      "[23, 60] loss: 0.245\n",
      "[23, 120] loss: 0.238\n",
      "[23, 180] loss: 0.240\n",
      "[23, 240] loss: 0.235\n",
      "[23, 300] loss: 0.242\n",
      "[23, 360] loss: 0.243\n",
      "Epoch: 23 -> Loss: 0.143813252449\n",
      "Epoch: 23 -> Test Accuracy: 85.99\n",
      "[24, 60] loss: 0.233\n",
      "[24, 120] loss: 0.231\n",
      "[24, 180] loss: 0.238\n",
      "[24, 240] loss: 0.222\n",
      "[24, 300] loss: 0.226\n",
      "[24, 360] loss: 0.227\n",
      "Epoch: 24 -> Loss: 0.200893551111\n",
      "Epoch: 24 -> Test Accuracy: 86.02\n",
      "[25, 60] loss: 0.209\n",
      "[25, 120] loss: 0.222\n",
      "[25, 180] loss: 0.223\n",
      "[25, 240] loss: 0.226\n",
      "[25, 300] loss: 0.242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 360] loss: 0.237\n",
      "Epoch: 25 -> Loss: 0.259282678366\n",
      "Epoch: 25 -> Test Accuracy: 85.81\n",
      "[26, 60] loss: 0.216\n",
      "[26, 120] loss: 0.217\n",
      "[26, 180] loss: 0.222\n",
      "[26, 240] loss: 0.221\n",
      "[26, 300] loss: 0.218\n",
      "[26, 360] loss: 0.219\n",
      "Epoch: 26 -> Loss: 0.146848484874\n",
      "Epoch: 26 -> Test Accuracy: 85.91\n",
      "[27, 60] loss: 0.197\n",
      "[27, 120] loss: 0.210\n",
      "[27, 180] loss: 0.209\n",
      "[27, 240] loss: 0.225\n",
      "[27, 300] loss: 0.213\n",
      "[27, 360] loss: 0.223\n",
      "Epoch: 27 -> Loss: 0.19789108634\n",
      "Epoch: 27 -> Test Accuracy: 85.62\n",
      "[28, 60] loss: 0.200\n",
      "[28, 120] loss: 0.206\n",
      "[28, 180] loss: 0.221\n",
      "[28, 240] loss: 0.204\n",
      "[28, 300] loss: 0.211\n",
      "[28, 360] loss: 0.203\n",
      "Epoch: 28 -> Loss: 0.214612439275\n",
      "Epoch: 28 -> Test Accuracy: 85.59\n",
      "[29, 60] loss: 0.198\n",
      "[29, 120] loss: 0.190\n",
      "[29, 180] loss: 0.212\n",
      "[29, 240] loss: 0.191\n",
      "[29, 300] loss: 0.200\n",
      "[29, 360] loss: 0.209\n",
      "Epoch: 29 -> Loss: 0.273387014866\n",
      "Epoch: 29 -> Test Accuracy: 86.15\n",
      "[30, 60] loss: 0.186\n",
      "[30, 120] loss: 0.189\n",
      "[30, 180] loss: 0.206\n",
      "[30, 240] loss: 0.196\n",
      "[30, 300] loss: 0.205\n",
      "[30, 360] loss: 0.211\n",
      "Epoch: 30 -> Loss: 0.214208990335\n",
      "Epoch: 30 -> Test Accuracy: 85.66\n",
      "[31, 60] loss: 0.194\n",
      "[31, 120] loss: 0.205\n",
      "[31, 180] loss: 0.201\n",
      "[31, 240] loss: 0.204\n",
      "[31, 300] loss: 0.211\n",
      "[31, 360] loss: 0.208\n",
      "Epoch: 31 -> Loss: 0.317800402641\n",
      "Epoch: 31 -> Test Accuracy: 85.39\n",
      "[32, 60] loss: 0.186\n",
      "[32, 120] loss: 0.192\n",
      "[32, 180] loss: 0.201\n",
      "[32, 240] loss: 0.187\n",
      "[32, 300] loss: 0.200\n",
      "[32, 360] loss: 0.210\n",
      "Epoch: 32 -> Loss: 0.227470010519\n",
      "Epoch: 32 -> Test Accuracy: 85.32\n",
      "[33, 60] loss: 0.193\n",
      "[33, 120] loss: 0.185\n",
      "[33, 180] loss: 0.188\n",
      "[33, 240] loss: 0.196\n",
      "[33, 300] loss: 0.204\n",
      "[33, 360] loss: 0.203\n",
      "Epoch: 33 -> Loss: 0.384006053209\n",
      "Epoch: 33 -> Test Accuracy: 85.73\n",
      "[34, 60] loss: 0.185\n",
      "[34, 120] loss: 0.191\n",
      "[34, 180] loss: 0.187\n",
      "[34, 240] loss: 0.183\n",
      "[34, 300] loss: 0.201\n",
      "[34, 360] loss: 0.205\n",
      "Epoch: 34 -> Loss: 0.205549329519\n",
      "Epoch: 34 -> Test Accuracy: 85.03\n",
      "[35, 60] loss: 0.190\n",
      "[35, 120] loss: 0.196\n",
      "[35, 180] loss: 0.195\n",
      "[35, 240] loss: 0.200\n",
      "[35, 300] loss: 0.187\n",
      "[35, 360] loss: 0.209\n",
      "Epoch: 35 -> Loss: 0.11928280443\n",
      "Epoch: 35 -> Test Accuracy: 85.74\n",
      "[36, 60] loss: 0.182\n",
      "[36, 120] loss: 0.197\n",
      "[36, 180] loss: 0.193\n",
      "[36, 240] loss: 0.191\n",
      "[36, 300] loss: 0.196\n",
      "[36, 360] loss: 0.195\n",
      "Epoch: 36 -> Loss: 0.311351388693\n",
      "Epoch: 36 -> Test Accuracy: 85.76\n",
      "[37, 60] loss: 0.186\n",
      "[37, 120] loss: 0.191\n",
      "[37, 180] loss: 0.198\n",
      "[37, 240] loss: 0.189\n",
      "[37, 300] loss: 0.198\n",
      "[37, 360] loss: 0.197\n",
      "Epoch: 37 -> Loss: 0.182782903314\n",
      "Epoch: 37 -> Test Accuracy: 85.79\n",
      "[38, 60] loss: 0.185\n",
      "[38, 120] loss: 0.184\n",
      "[38, 180] loss: 0.202\n",
      "[38, 240] loss: 0.201\n",
      "[38, 300] loss: 0.196\n",
      "[38, 360] loss: 0.201\n",
      "Epoch: 38 -> Loss: 0.345670700073\n",
      "Epoch: 38 -> Test Accuracy: 85.38\n",
      "[39, 60] loss: 0.203\n",
      "[39, 120] loss: 0.180\n",
      "[39, 180] loss: 0.191\n",
      "[39, 240] loss: 0.201\n",
      "[39, 300] loss: 0.196\n",
      "[39, 360] loss: 0.200\n",
      "Epoch: 39 -> Loss: 0.248354315758\n",
      "Epoch: 39 -> Test Accuracy: 85.61\n",
      "[40, 60] loss: 0.177\n",
      "[40, 120] loss: 0.189\n",
      "[40, 180] loss: 0.188\n",
      "[40, 240] loss: 0.188\n",
      "[40, 300] loss: 0.188\n",
      "[40, 360] loss: 0.205\n",
      "Epoch: 40 -> Loss: 0.229021951556\n",
      "Epoch: 40 -> Test Accuracy: 85.31\n",
      "[41, 60] loss: 0.175\n",
      "[41, 120] loss: 0.163\n",
      "[41, 180] loss: 0.166\n",
      "[41, 240] loss: 0.165\n",
      "[41, 300] loss: 0.162\n",
      "[41, 360] loss: 0.148\n",
      "Epoch: 41 -> Loss: 0.135858684778\n",
      "Epoch: 41 -> Test Accuracy: 86.35\n",
      "[42, 60] loss: 0.147\n",
      "[42, 120] loss: 0.146\n",
      "[42, 180] loss: 0.140\n",
      "[42, 240] loss: 0.143\n",
      "[42, 300] loss: 0.141\n",
      "[42, 360] loss: 0.145\n",
      "Epoch: 42 -> Loss: 0.184745460749\n",
      "Epoch: 42 -> Test Accuracy: 86.24\n",
      "[43, 60] loss: 0.141\n",
      "[43, 120] loss: 0.139\n",
      "[43, 180] loss: 0.135\n",
      "[43, 240] loss: 0.140\n",
      "[43, 300] loss: 0.134\n",
      "[43, 360] loss: 0.125\n",
      "Epoch: 43 -> Loss: 0.151546284556\n",
      "Epoch: 43 -> Test Accuracy: 86.48\n",
      "[44, 60] loss: 0.127\n",
      "[44, 120] loss: 0.137\n",
      "[44, 180] loss: 0.124\n",
      "[44, 240] loss: 0.128\n",
      "[44, 300] loss: 0.124\n",
      "[44, 360] loss: 0.137\n",
      "Epoch: 44 -> Loss: 0.146401137114\n",
      "Epoch: 44 -> Test Accuracy: 86.13\n",
      "[45, 60] loss: 0.126\n",
      "[45, 120] loss: 0.130\n",
      "[45, 180] loss: 0.122\n",
      "[45, 240] loss: 0.119\n",
      "[45, 300] loss: 0.120\n",
      "[45, 360] loss: 0.114\n",
      "Epoch: 45 -> Loss: 0.0512803569436\n",
      "Epoch: 45 -> Test Accuracy: 86.38\n",
      "[46, 60] loss: 0.119\n",
      "[46, 120] loss: 0.111\n",
      "[46, 180] loss: 0.115\n",
      "[46, 240] loss: 0.123\n",
      "[46, 300] loss: 0.114\n",
      "[46, 360] loss: 0.125\n",
      "Epoch: 46 -> Loss: 0.088256508112\n",
      "Epoch: 46 -> Test Accuracy: 86.4\n",
      "[47, 60] loss: 0.110\n",
      "[47, 120] loss: 0.110\n",
      "[47, 180] loss: 0.116\n",
      "[47, 240] loss: 0.121\n",
      "[47, 300] loss: 0.116\n",
      "[47, 360] loss: 0.115\n",
      "Epoch: 47 -> Loss: 0.0941146761179\n",
      "Epoch: 47 -> Test Accuracy: 86.37\n",
      "[48, 60] loss: 0.117\n",
      "[48, 120] loss: 0.116\n",
      "[48, 180] loss: 0.112\n",
      "[48, 240] loss: 0.105\n",
      "[48, 300] loss: 0.114\n",
      "[48, 360] loss: 0.120\n",
      "Epoch: 48 -> Loss: 0.12986086309\n",
      "Epoch: 48 -> Test Accuracy: 86.33\n",
      "[49, 60] loss: 0.115\n",
      "[49, 120] loss: 0.112\n",
      "[49, 180] loss: 0.118\n",
      "[49, 240] loss: 0.106\n",
      "[49, 300] loss: 0.107\n",
      "[49, 360] loss: 0.112\n",
      "Epoch: 49 -> Loss: 0.204173177481\n",
      "Epoch: 49 -> Test Accuracy: 86.41\n",
      "[50, 60] loss: 0.115\n",
      "[50, 120] loss: 0.110\n",
      "[50, 180] loss: 0.111\n",
      "[50, 240] loss: 0.101\n",
      "[50, 300] loss: 0.118\n",
      "[50, 360] loss: 0.116\n",
      "Epoch: 50 -> Loss: 0.103502251208\n",
      "Epoch: 50 -> Test Accuracy: 86.37\n",
      "[51, 60] loss: 0.107\n",
      "[51, 120] loss: 0.107\n",
      "[51, 180] loss: 0.105\n",
      "[51, 240] loss: 0.107\n",
      "[51, 300] loss: 0.105\n",
      "[51, 360] loss: 0.106\n",
      "Epoch: 51 -> Loss: 0.107869230211\n",
      "Epoch: 51 -> Test Accuracy: 86.38\n",
      "[52, 60] loss: 0.107\n",
      "[52, 120] loss: 0.103\n",
      "[52, 180] loss: 0.107\n",
      "[52, 240] loss: 0.102\n",
      "[52, 300] loss: 0.109\n",
      "[52, 360] loss: 0.116\n",
      "Epoch: 52 -> Loss: 0.129855304956\n",
      "Epoch: 52 -> Test Accuracy: 86.43\n",
      "[53, 60] loss: 0.110\n",
      "[53, 120] loss: 0.110\n",
      "[53, 180] loss: 0.115\n",
      "[53, 240] loss: 0.106\n",
      "[53, 300] loss: 0.114\n",
      "[53, 360] loss: 0.094\n",
      "Epoch: 53 -> Loss: 0.0968175530434\n",
      "Epoch: 53 -> Test Accuracy: 86.38\n",
      "[54, 60] loss: 0.108\n",
      "[54, 120] loss: 0.102\n",
      "[54, 180] loss: 0.106\n",
      "[54, 240] loss: 0.100\n",
      "[54, 300] loss: 0.103\n",
      "[54, 360] loss: 0.104\n",
      "Epoch: 54 -> Loss: 0.18261501193\n",
      "Epoch: 54 -> Test Accuracy: 86.43\n",
      "[55, 60] loss: 0.110\n",
      "[55, 120] loss: 0.097\n",
      "[55, 180] loss: 0.110\n",
      "[55, 240] loss: 0.105\n",
      "[55, 300] loss: 0.113\n",
      "[55, 360] loss: 0.105\n",
      "Epoch: 55 -> Loss: 0.1118292436\n",
      "Epoch: 55 -> Test Accuracy: 86.5\n",
      "[56, 60] loss: 0.102\n",
      "[56, 120] loss: 0.105\n",
      "[56, 180] loss: 0.102\n",
      "[56, 240] loss: 0.102\n",
      "[56, 300] loss: 0.102\n",
      "[56, 360] loss: 0.098\n",
      "Epoch: 56 -> Loss: 0.158414438367\n",
      "Epoch: 56 -> Test Accuracy: 86.52\n",
      "[57, 60] loss: 0.103\n",
      "[57, 120] loss: 0.099\n",
      "[57, 180] loss: 0.100\n",
      "[57, 240] loss: 0.098\n",
      "[57, 300] loss: 0.105\n",
      "[57, 360] loss: 0.103\n",
      "Epoch: 57 -> Loss: 0.0669610947371\n",
      "Epoch: 57 -> Test Accuracy: 86.4\n",
      "[58, 60] loss: 0.109\n",
      "[58, 120] loss: 0.093\n",
      "[58, 180] loss: 0.092\n",
      "[58, 240] loss: 0.102\n",
      "[58, 300] loss: 0.099\n",
      "[58, 360] loss: 0.104\n",
      "Epoch: 58 -> Loss: 0.180979698896\n",
      "Epoch: 58 -> Test Accuracy: 86.55\n",
      "[59, 60] loss: 0.097\n",
      "[59, 120] loss: 0.107\n",
      "[59, 180] loss: 0.107\n",
      "[59, 240] loss: 0.100\n",
      "[59, 300] loss: 0.094\n",
      "[59, 360] loss: 0.103\n",
      "Epoch: 59 -> Loss: 0.0410734638572\n",
      "Epoch: 59 -> Test Accuracy: 86.55\n",
      "[60, 60] loss: 0.095\n",
      "[60, 120] loss: 0.104\n",
      "[60, 180] loss: 0.098\n",
      "[60, 240] loss: 0.099\n",
      "[60, 300] loss: 0.097\n",
      "[60, 360] loss: 0.098\n",
      "Epoch: 60 -> Loss: 0.0690426528454\n",
      "Epoch: 60 -> Test Accuracy: 86.54\n",
      "[61, 60] loss: 0.103\n",
      "[61, 120] loss: 0.098\n",
      "[61, 180] loss: 0.094\n",
      "[61, 240] loss: 0.095\n",
      "[61, 300] loss: 0.096\n",
      "[61, 360] loss: 0.102\n",
      "Epoch: 61 -> Loss: 0.0572507791221\n",
      "Epoch: 61 -> Test Accuracy: 86.57\n",
      "[62, 60] loss: 0.093\n",
      "[62, 120] loss: 0.101\n",
      "[62, 180] loss: 0.106\n",
      "[62, 240] loss: 0.098\n",
      "[62, 300] loss: 0.091\n",
      "[62, 360] loss: 0.096\n",
      "Epoch: 62 -> Loss: 0.0833388417959\n",
      "Epoch: 62 -> Test Accuracy: 86.57\n",
      "[63, 60] loss: 0.100\n",
      "[63, 120] loss: 0.096\n",
      "[63, 180] loss: 0.096\n",
      "[63, 240] loss: 0.104\n",
      "[63, 300] loss: 0.095\n",
      "[63, 360] loss: 0.092\n",
      "Epoch: 63 -> Loss: 0.191756010056\n",
      "Epoch: 63 -> Test Accuracy: 86.58\n",
      "[64, 60] loss: 0.094\n",
      "[64, 120] loss: 0.094\n",
      "[64, 180] loss: 0.098\n",
      "[64, 240] loss: 0.105\n",
      "[64, 300] loss: 0.093\n",
      "[64, 360] loss: 0.097\n",
      "Epoch: 64 -> Loss: 0.0697780102491\n",
      "Epoch: 64 -> Test Accuracy: 86.55\n",
      "[65, 60] loss: 0.094\n",
      "[65, 120] loss: 0.097\n",
      "[65, 180] loss: 0.093\n",
      "[65, 240] loss: 0.102\n",
      "[65, 300] loss: 0.100\n",
      "[65, 360] loss: 0.093\n",
      "Epoch: 65 -> Loss: 0.0781807377934\n",
      "Epoch: 65 -> Test Accuracy: 86.55\n",
      "[66, 60] loss: 0.094\n",
      "[66, 120] loss: 0.093\n",
      "[66, 180] loss: 0.094\n",
      "[66, 240] loss: 0.099\n",
      "[66, 300] loss: 0.087\n",
      "[66, 360] loss: 0.093\n",
      "Epoch: 66 -> Loss: 0.140216305852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Test Accuracy: 86.68\n",
      "[67, 60] loss: 0.092\n",
      "[67, 120] loss: 0.096\n",
      "[67, 180] loss: 0.089\n",
      "[67, 240] loss: 0.091\n",
      "[67, 300] loss: 0.094\n",
      "[67, 360] loss: 0.089\n",
      "Epoch: 67 -> Loss: 0.131401851773\n",
      "Epoch: 67 -> Test Accuracy: 86.69\n",
      "[68, 60] loss: 0.094\n",
      "[68, 120] loss: 0.092\n",
      "[68, 180] loss: 0.094\n",
      "[68, 240] loss: 0.093\n",
      "[68, 300] loss: 0.099\n",
      "[68, 360] loss: 0.089\n",
      "Epoch: 68 -> Loss: 0.0799077898264\n",
      "Epoch: 68 -> Test Accuracy: 86.54\n",
      "[69, 60] loss: 0.098\n",
      "[69, 120] loss: 0.089\n",
      "[69, 180] loss: 0.092\n",
      "[69, 240] loss: 0.088\n",
      "[69, 300] loss: 0.096\n",
      "[69, 360] loss: 0.096\n",
      "Epoch: 69 -> Loss: 0.129445925355\n",
      "Epoch: 69 -> Test Accuracy: 86.51\n",
      "[70, 60] loss: 0.092\n",
      "[70, 120] loss: 0.085\n",
      "[70, 180] loss: 0.088\n",
      "[70, 240] loss: 0.093\n",
      "[70, 300] loss: 0.089\n",
      "[70, 360] loss: 0.090\n",
      "Epoch: 70 -> Loss: 0.106624186039\n",
      "Epoch: 70 -> Test Accuracy: 86.7\n",
      "[71, 60] loss: 0.095\n",
      "[71, 120] loss: 0.094\n",
      "[71, 180] loss: 0.088\n",
      "[71, 240] loss: 0.098\n",
      "[71, 300] loss: 0.093\n",
      "[71, 360] loss: 0.096\n",
      "Epoch: 71 -> Loss: 0.134414643049\n",
      "Epoch: 71 -> Test Accuracy: 86.7\n",
      "[72, 60] loss: 0.088\n",
      "[72, 120] loss: 0.095\n",
      "[72, 180] loss: 0.085\n",
      "[72, 240] loss: 0.087\n",
      "[72, 300] loss: 0.083\n",
      "[72, 360] loss: 0.096\n",
      "Epoch: 72 -> Loss: 0.0859427377582\n",
      "Epoch: 72 -> Test Accuracy: 86.71\n",
      "[73, 60] loss: 0.092\n",
      "[73, 120] loss: 0.087\n",
      "[73, 180] loss: 0.090\n",
      "[73, 240] loss: 0.089\n",
      "[73, 300] loss: 0.094\n",
      "[73, 360] loss: 0.091\n",
      "Epoch: 73 -> Loss: 0.0609702989459\n",
      "Epoch: 73 -> Test Accuracy: 86.61\n",
      "[74, 60] loss: 0.089\n",
      "[74, 120] loss: 0.091\n",
      "[74, 180] loss: 0.085\n",
      "[74, 240] loss: 0.093\n",
      "[74, 300] loss: 0.086\n",
      "[74, 360] loss: 0.084\n",
      "Epoch: 74 -> Loss: 0.0550076439977\n",
      "Epoch: 74 -> Test Accuracy: 86.64\n",
      "[75, 60] loss: 0.088\n",
      "[75, 120] loss: 0.089\n",
      "[75, 180] loss: 0.082\n",
      "[75, 240] loss: 0.090\n",
      "[75, 300] loss: 0.087\n",
      "[75, 360] loss: 0.091\n",
      "Epoch: 75 -> Loss: 0.0803281515837\n",
      "Epoch: 75 -> Test Accuracy: 86.64\n",
      "[76, 60] loss: 0.085\n",
      "[76, 120] loss: 0.095\n",
      "[76, 180] loss: 0.088\n",
      "[76, 240] loss: 0.092\n",
      "[76, 300] loss: 0.082\n",
      "[76, 360] loss: 0.087\n",
      "Epoch: 76 -> Loss: 0.0438816919923\n",
      "Epoch: 76 -> Test Accuracy: 86.66\n",
      "[77, 60] loss: 0.093\n",
      "[77, 120] loss: 0.095\n",
      "[77, 180] loss: 0.079\n",
      "[77, 240] loss: 0.084\n",
      "[77, 300] loss: 0.087\n",
      "[77, 360] loss: 0.090\n",
      "Epoch: 77 -> Loss: 0.118667639792\n",
      "Epoch: 77 -> Test Accuracy: 86.7\n",
      "[78, 60] loss: 0.093\n",
      "[78, 120] loss: 0.082\n",
      "[78, 180] loss: 0.086\n",
      "[78, 240] loss: 0.091\n",
      "[78, 300] loss: 0.086\n",
      "[78, 360] loss: 0.082\n",
      "Epoch: 78 -> Loss: 0.097342774272\n",
      "Epoch: 78 -> Test Accuracy: 86.63\n",
      "[79, 60] loss: 0.085\n",
      "[79, 120] loss: 0.088\n",
      "[79, 180] loss: 0.087\n",
      "[79, 240] loss: 0.078\n",
      "[79, 300] loss: 0.086\n",
      "[79, 360] loss: 0.084\n",
      "Epoch: 79 -> Loss: 0.0289073102176\n",
      "Epoch: 79 -> Test Accuracy: 86.57\n",
      "[80, 60] loss: 0.077\n",
      "[80, 120] loss: 0.087\n",
      "[80, 180] loss: 0.093\n",
      "[80, 240] loss: 0.081\n",
      "[80, 300] loss: 0.087\n",
      "[80, 360] loss: 0.088\n",
      "Epoch: 80 -> Loss: 0.144211679697\n",
      "Epoch: 80 -> Test Accuracy: 86.57\n",
      "[81, 60] loss: 0.085\n",
      "[81, 120] loss: 0.089\n",
      "[81, 180] loss: 0.082\n",
      "[81, 240] loss: 0.085\n",
      "[81, 300] loss: 0.084\n",
      "[81, 360] loss: 0.083\n",
      "Epoch: 81 -> Loss: 0.063359439373\n",
      "Epoch: 81 -> Test Accuracy: 86.55\n",
      "[82, 60] loss: 0.082\n",
      "[82, 120] loss: 0.082\n",
      "[82, 180] loss: 0.090\n",
      "[82, 240] loss: 0.079\n",
      "[82, 300] loss: 0.086\n",
      "[82, 360] loss: 0.092\n",
      "Epoch: 82 -> Loss: 0.0582887232304\n",
      "Epoch: 82 -> Test Accuracy: 86.74\n",
      "[83, 60] loss: 0.083\n",
      "[83, 120] loss: 0.084\n",
      "[83, 180] loss: 0.089\n",
      "[83, 240] loss: 0.084\n",
      "[83, 300] loss: 0.084\n",
      "[83, 360] loss: 0.083\n",
      "Epoch: 83 -> Loss: 0.088147893548\n",
      "Epoch: 83 -> Test Accuracy: 86.61\n",
      "[84, 60] loss: 0.082\n",
      "[84, 120] loss: 0.086\n",
      "[84, 180] loss: 0.083\n",
      "[84, 240] loss: 0.083\n",
      "[84, 300] loss: 0.085\n",
      "[84, 360] loss: 0.081\n",
      "Epoch: 84 -> Loss: 0.111724451184\n",
      "Epoch: 84 -> Test Accuracy: 86.58\n",
      "[85, 60] loss: 0.082\n",
      "[85, 120] loss: 0.079\n",
      "[85, 180] loss: 0.087\n",
      "[85, 240] loss: 0.081\n",
      "[85, 300] loss: 0.081\n",
      "[85, 360] loss: 0.085\n",
      "Epoch: 85 -> Loss: 0.113486036658\n",
      "Epoch: 85 -> Test Accuracy: 86.61\n",
      "[86, 60] loss: 0.086\n",
      "[86, 120] loss: 0.077\n",
      "[86, 180] loss: 0.081\n",
      "[86, 240] loss: 0.081\n",
      "[86, 300] loss: 0.085\n",
      "[86, 360] loss: 0.078\n",
      "Epoch: 86 -> Loss: 0.111698269844\n",
      "Epoch: 86 -> Test Accuracy: 86.46\n",
      "[87, 60] loss: 0.080\n",
      "[87, 120] loss: 0.083\n",
      "[87, 180] loss: 0.080\n",
      "[87, 240] loss: 0.075\n",
      "[87, 300] loss: 0.075\n",
      "[87, 360] loss: 0.076\n",
      "Epoch: 87 -> Loss: 0.0575171783566\n",
      "Epoch: 87 -> Test Accuracy: 86.56\n",
      "[88, 60] loss: 0.082\n",
      "[88, 120] loss: 0.074\n",
      "[88, 180] loss: 0.078\n",
      "[88, 240] loss: 0.083\n",
      "[88, 300] loss: 0.077\n",
      "[88, 360] loss: 0.085\n",
      "Epoch: 88 -> Loss: 0.110804080963\n",
      "Epoch: 88 -> Test Accuracy: 86.65\n",
      "[89, 60] loss: 0.077\n",
      "[89, 120] loss: 0.076\n",
      "[89, 180] loss: 0.081\n",
      "[89, 240] loss: 0.078\n",
      "[89, 300] loss: 0.083\n",
      "[89, 360] loss: 0.083\n",
      "Epoch: 89 -> Loss: 0.0734381973743\n",
      "Epoch: 89 -> Test Accuracy: 86.68\n",
      "[90, 60] loss: 0.083\n",
      "[90, 120] loss: 0.081\n",
      "[90, 180] loss: 0.083\n",
      "[90, 240] loss: 0.077\n",
      "[90, 300] loss: 0.081\n",
      "[90, 360] loss: 0.080\n",
      "Epoch: 90 -> Loss: 0.0998461991549\n",
      "Epoch: 90 -> Test Accuracy: 86.58\n",
      "[91, 60] loss: 0.080\n",
      "[91, 120] loss: 0.079\n",
      "[91, 180] loss: 0.072\n",
      "[91, 240] loss: 0.080\n",
      "[91, 300] loss: 0.083\n",
      "[91, 360] loss: 0.083\n",
      "Epoch: 91 -> Loss: 0.0827145576477\n",
      "Epoch: 91 -> Test Accuracy: 86.66\n",
      "[92, 60] loss: 0.077\n",
      "[92, 120] loss: 0.082\n",
      "[92, 180] loss: 0.080\n",
      "[92, 240] loss: 0.083\n",
      "[92, 300] loss: 0.083\n",
      "[92, 360] loss: 0.081\n",
      "Epoch: 92 -> Loss: 0.0978662148118\n",
      "Epoch: 92 -> Test Accuracy: 86.68\n",
      "[93, 60] loss: 0.070\n",
      "[93, 120] loss: 0.073\n",
      "[93, 180] loss: 0.075\n",
      "[93, 240] loss: 0.076\n",
      "[93, 300] loss: 0.079\n",
      "[93, 360] loss: 0.082\n",
      "Epoch: 93 -> Loss: 0.112104937434\n",
      "Epoch: 93 -> Test Accuracy: 86.63\n",
      "[94, 60] loss: 0.084\n",
      "[94, 120] loss: 0.078\n",
      "[94, 180] loss: 0.081\n",
      "[94, 240] loss: 0.077\n",
      "[94, 300] loss: 0.087\n",
      "[94, 360] loss: 0.073\n",
      "Epoch: 94 -> Loss: 0.0450734980404\n",
      "Epoch: 94 -> Test Accuracy: 86.61\n",
      "[95, 60] loss: 0.075\n",
      "[95, 120] loss: 0.079\n",
      "[95, 180] loss: 0.080\n",
      "[95, 240] loss: 0.070\n",
      "[95, 300] loss: 0.080\n",
      "[95, 360] loss: 0.074\n",
      "Epoch: 95 -> Loss: 0.0621650591493\n",
      "Epoch: 95 -> Test Accuracy: 86.54\n",
      "[96, 60] loss: 0.071\n",
      "[96, 120] loss: 0.085\n",
      "[96, 180] loss: 0.073\n",
      "[96, 240] loss: 0.083\n",
      "[96, 300] loss: 0.085\n",
      "[96, 360] loss: 0.080\n",
      "Epoch: 96 -> Loss: 0.12893357873\n",
      "Epoch: 96 -> Test Accuracy: 86.49\n",
      "[97, 60] loss: 0.085\n",
      "[97, 120] loss: 0.074\n",
      "[97, 180] loss: 0.079\n",
      "[97, 240] loss: 0.078\n",
      "[97, 300] loss: 0.074\n",
      "[97, 360] loss: 0.078\n",
      "Epoch: 97 -> Loss: 0.0484696403146\n",
      "Epoch: 97 -> Test Accuracy: 86.55\n",
      "[98, 60] loss: 0.075\n",
      "[98, 120] loss: 0.074\n",
      "[98, 180] loss: 0.079\n",
      "[98, 240] loss: 0.083\n",
      "[98, 300] loss: 0.072\n",
      "[98, 360] loss: 0.081\n",
      "Epoch: 98 -> Loss: 0.0909014940262\n",
      "Epoch: 98 -> Test Accuracy: 86.57\n",
      "[99, 60] loss: 0.075\n",
      "[99, 120] loss: 0.082\n",
      "[99, 180] loss: 0.076\n",
      "[99, 240] loss: 0.070\n",
      "[99, 300] loss: 0.078\n",
      "[99, 360] loss: 0.071\n",
      "Epoch: 99 -> Loss: 0.0530854351819\n",
      "Epoch: 99 -> Test Accuracy: 86.53\n",
      "[100, 60] loss: 0.074\n",
      "[100, 120] loss: 0.081\n",
      "[100, 180] loss: 0.081\n",
      "[100, 240] loss: 0.076\n",
      "[100, 300] loss: 0.076\n",
      "[100, 360] loss: 0.077\n",
      "Epoch: 100 -> Loss: 0.0661495029926\n",
      "Epoch: 100 -> Test Accuracy: 86.54\n",
      "Finished Training\n",
      "[1, 60] loss: 2.743\n",
      "[1, 120] loss: 1.840\n",
      "[1, 180] loss: 1.761\n",
      "[1, 240] loss: 1.743\n",
      "[1, 300] loss: 1.726\n",
      "[1, 360] loss: 1.692\n",
      "Epoch: 1 -> Loss: 1.79976201057\n",
      "Epoch: 1 -> Test Accuracy: 37.59\n",
      "[2, 60] loss: 1.675\n",
      "[2, 120] loss: 1.641\n",
      "[2, 180] loss: 1.649\n",
      "[2, 240] loss: 1.629\n",
      "[2, 300] loss: 1.620\n",
      "[2, 360] loss: 1.598\n",
      "Epoch: 2 -> Loss: 1.50460410118\n",
      "Epoch: 2 -> Test Accuracy: 39.6\n",
      "[3, 60] loss: 1.602\n",
      "[3, 120] loss: 1.591\n",
      "[3, 180] loss: 1.579\n",
      "[3, 240] loss: 1.578\n",
      "[3, 300] loss: 1.553\n",
      "[3, 360] loss: 1.562\n",
      "Epoch: 3 -> Loss: 1.63704371452\n",
      "Epoch: 3 -> Test Accuracy: 40.89\n",
      "[4, 60] loss: 1.548\n",
      "[4, 120] loss: 1.535\n",
      "[4, 180] loss: 1.549\n",
      "[4, 240] loss: 1.538\n",
      "[4, 300] loss: 1.533\n",
      "[4, 360] loss: 1.538\n",
      "Epoch: 4 -> Loss: 1.74453127384\n",
      "Epoch: 4 -> Test Accuracy: 42.9\n",
      "[5, 60] loss: 1.526\n",
      "[5, 120] loss: 1.526\n",
      "[5, 180] loss: 1.510\n",
      "[5, 240] loss: 1.507\n",
      "[5, 300] loss: 1.534\n",
      "[5, 360] loss: 1.511\n",
      "Epoch: 5 -> Loss: 1.58145666122\n",
      "Epoch: 5 -> Test Accuracy: 42.55\n",
      "[6, 60] loss: 1.501\n",
      "[6, 120] loss: 1.519\n",
      "[6, 180] loss: 1.488\n",
      "[6, 240] loss: 1.507\n",
      "[6, 300] loss: 1.500\n",
      "[6, 360] loss: 1.506\n",
      "Epoch: 6 -> Loss: 1.32637107372\n",
      "Epoch: 6 -> Test Accuracy: 43.24\n",
      "[7, 60] loss: 1.502\n",
      "[7, 120] loss: 1.479\n",
      "[7, 180] loss: 1.498\n",
      "[7, 240] loss: 1.499\n",
      "[7, 300] loss: 1.459\n",
      "[7, 360] loss: 1.490\n",
      "Epoch: 7 -> Loss: 1.55076313019\n",
      "Epoch: 7 -> Test Accuracy: 43.46\n",
      "[8, 60] loss: 1.481\n",
      "[8, 120] loss: 1.472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 180] loss: 1.477\n",
      "[8, 240] loss: 1.493\n",
      "[8, 300] loss: 1.490\n",
      "[8, 360] loss: 1.490\n",
      "Epoch: 8 -> Loss: 1.69367945194\n",
      "Epoch: 8 -> Test Accuracy: 43.32\n",
      "[9, 60] loss: 1.443\n",
      "[9, 120] loss: 1.489\n",
      "[9, 180] loss: 1.482\n",
      "[9, 240] loss: 1.479\n",
      "[9, 300] loss: 1.480\n",
      "[9, 360] loss: 1.467\n",
      "Epoch: 9 -> Loss: 1.49393200874\n",
      "Epoch: 9 -> Test Accuracy: 43.77\n",
      "[10, 60] loss: 1.452\n",
      "[10, 120] loss: 1.457\n",
      "[10, 180] loss: 1.476\n",
      "[10, 240] loss: 1.476\n",
      "[10, 300] loss: 1.458\n",
      "[10, 360] loss: 1.478\n",
      "Epoch: 10 -> Loss: 1.44611656666\n",
      "Epoch: 10 -> Test Accuracy: 43.32\n",
      "[11, 60] loss: 1.457\n",
      "[11, 120] loss: 1.454\n",
      "[11, 180] loss: 1.461\n",
      "[11, 240] loss: 1.449\n",
      "[11, 300] loss: 1.469\n",
      "[11, 360] loss: 1.463\n",
      "Epoch: 11 -> Loss: 1.60790133476\n",
      "Epoch: 11 -> Test Accuracy: 43.73\n",
      "[12, 60] loss: 1.479\n",
      "[12, 120] loss: 1.450\n",
      "[12, 180] loss: 1.454\n",
      "[12, 240] loss: 1.448\n",
      "[12, 300] loss: 1.494\n",
      "[12, 360] loss: 1.440\n",
      "Epoch: 12 -> Loss: 1.38102173805\n",
      "Epoch: 12 -> Test Accuracy: 43.83\n",
      "[13, 60] loss: 1.461\n",
      "[13, 120] loss: 1.453\n",
      "[13, 180] loss: 1.456\n",
      "[13, 240] loss: 1.452\n",
      "[13, 300] loss: 1.451\n",
      "[13, 360] loss: 1.478\n",
      "Epoch: 13 -> Loss: 1.38783383369\n",
      "Epoch: 13 -> Test Accuracy: 43.53\n",
      "[14, 60] loss: 1.446\n",
      "[14, 120] loss: 1.473\n",
      "[14, 180] loss: 1.455\n",
      "[14, 240] loss: 1.449\n",
      "[14, 300] loss: 1.459\n",
      "[14, 360] loss: 1.447\n",
      "Epoch: 14 -> Loss: 1.47860503197\n",
      "Epoch: 14 -> Test Accuracy: 43.2\n",
      "[15, 60] loss: 1.445\n",
      "[15, 120] loss: 1.475\n",
      "[15, 180] loss: 1.463\n",
      "[15, 240] loss: 1.444\n",
      "[15, 300] loss: 1.453\n",
      "[15, 360] loss: 1.457\n",
      "Epoch: 15 -> Loss: 1.5768892765\n",
      "Epoch: 15 -> Test Accuracy: 44.06\n",
      "[16, 60] loss: 1.439\n",
      "[16, 120] loss: 1.448\n",
      "[16, 180] loss: 1.459\n",
      "[16, 240] loss: 1.453\n",
      "[16, 300] loss: 1.461\n",
      "[16, 360] loss: 1.470\n",
      "Epoch: 16 -> Loss: 1.42380928993\n",
      "Epoch: 16 -> Test Accuracy: 44.12\n",
      "[17, 60] loss: 1.449\n",
      "[17, 120] loss: 1.457\n",
      "[17, 180] loss: 1.449\n",
      "[17, 240] loss: 1.443\n",
      "[17, 300] loss: 1.454\n",
      "[17, 360] loss: 1.440\n",
      "Epoch: 17 -> Loss: 1.38471055031\n",
      "Epoch: 17 -> Test Accuracy: 44.12\n",
      "[18, 60] loss: 1.469\n",
      "[18, 120] loss: 1.438\n",
      "[18, 180] loss: 1.452\n",
      "[18, 240] loss: 1.441\n",
      "[18, 300] loss: 1.458\n",
      "[18, 360] loss: 1.439\n",
      "Epoch: 18 -> Loss: 1.61181128025\n",
      "Epoch: 18 -> Test Accuracy: 44.51\n",
      "[19, 60] loss: 1.438\n",
      "[19, 120] loss: 1.430\n",
      "[19, 180] loss: 1.437\n",
      "[19, 240] loss: 1.447\n",
      "[19, 300] loss: 1.458\n",
      "[19, 360] loss: 1.453\n",
      "Epoch: 19 -> Loss: 1.43102538586\n",
      "Epoch: 19 -> Test Accuracy: 45.3\n",
      "[20, 60] loss: 1.417\n",
      "[20, 120] loss: 1.421\n",
      "[20, 180] loss: 1.443\n",
      "[20, 240] loss: 1.460\n",
      "[20, 300] loss: 1.454\n",
      "[20, 360] loss: 1.433\n",
      "Epoch: 20 -> Loss: 1.34625291824\n",
      "Epoch: 20 -> Test Accuracy: 43.78\n",
      "[21, 60] loss: 1.408\n",
      "[21, 120] loss: 1.356\n",
      "[21, 180] loss: 1.365\n",
      "[21, 240] loss: 1.354\n",
      "[21, 300] loss: 1.352\n",
      "[21, 360] loss: 1.337\n",
      "Epoch: 21 -> Loss: 1.42788147926\n",
      "Epoch: 21 -> Test Accuracy: 47.7\n",
      "[22, 60] loss: 1.334\n",
      "[22, 120] loss: 1.327\n",
      "[22, 180] loss: 1.316\n",
      "[22, 240] loss: 1.330\n",
      "[22, 300] loss: 1.332\n",
      "[22, 360] loss: 1.327\n",
      "Epoch: 22 -> Loss: 1.37356877327\n",
      "Epoch: 22 -> Test Accuracy: 48.25\n",
      "[23, 60] loss: 1.323\n",
      "[23, 120] loss: 1.312\n",
      "[23, 180] loss: 1.320\n",
      "[23, 240] loss: 1.323\n",
      "[23, 300] loss: 1.319\n",
      "[23, 360] loss: 1.308\n",
      "Epoch: 23 -> Loss: 1.29625499249\n",
      "Epoch: 23 -> Test Accuracy: 48.27\n",
      "[24, 60] loss: 1.306\n",
      "[24, 120] loss: 1.274\n",
      "[24, 180] loss: 1.322\n",
      "[24, 240] loss: 1.315\n",
      "[24, 300] loss: 1.314\n",
      "[24, 360] loss: 1.319\n",
      "Epoch: 24 -> Loss: 1.38672196865\n",
      "Epoch: 24 -> Test Accuracy: 48.21\n",
      "[25, 60] loss: 1.324\n",
      "[25, 120] loss: 1.304\n",
      "[25, 180] loss: 1.305\n",
      "[25, 240] loss: 1.290\n",
      "[25, 300] loss: 1.311\n",
      "[25, 360] loss: 1.290\n",
      "Epoch: 25 -> Loss: 1.4292986393\n",
      "Epoch: 25 -> Test Accuracy: 48.33\n",
      "[26, 60] loss: 1.297\n",
      "[26, 120] loss: 1.291\n",
      "[26, 180] loss: 1.299\n",
      "[26, 240] loss: 1.317\n",
      "[26, 300] loss: 1.283\n",
      "[26, 360] loss: 1.302\n",
      "Epoch: 26 -> Loss: 1.35974431038\n",
      "Epoch: 26 -> Test Accuracy: 48.87\n",
      "[27, 60] loss: 1.290\n",
      "[27, 120] loss: 1.286\n",
      "[27, 180] loss: 1.282\n",
      "[27, 240] loss: 1.312\n",
      "[27, 300] loss: 1.286\n",
      "[27, 360] loss: 1.283\n",
      "Epoch: 27 -> Loss: 1.18260025978\n",
      "Epoch: 27 -> Test Accuracy: 49.06\n",
      "[28, 60] loss: 1.286\n",
      "[28, 120] loss: 1.309\n",
      "[28, 180] loss: 1.302\n",
      "[28, 240] loss: 1.293\n",
      "[28, 300] loss: 1.301\n",
      "[28, 360] loss: 1.284\n",
      "Epoch: 28 -> Loss: 1.54231119156\n",
      "Epoch: 28 -> Test Accuracy: 48.66\n",
      "[29, 60] loss: 1.293\n",
      "[29, 120] loss: 1.274\n",
      "[29, 180] loss: 1.296\n",
      "[29, 240] loss: 1.290\n",
      "[29, 300] loss: 1.287\n",
      "[29, 360] loss: 1.284\n",
      "Epoch: 29 -> Loss: 1.16807937622\n",
      "Epoch: 29 -> Test Accuracy: 48.57\n",
      "[30, 60] loss: 1.278\n",
      "[30, 120] loss: 1.290\n",
      "[30, 180] loss: 1.289\n",
      "[30, 240] loss: 1.290\n",
      "[30, 300] loss: 1.282\n",
      "[30, 360] loss: 1.272\n",
      "Epoch: 30 -> Loss: 1.2184984684\n",
      "Epoch: 30 -> Test Accuracy: 48.99\n",
      "[31, 60] loss: 1.275\n",
      "[31, 120] loss: 1.295\n",
      "[31, 180] loss: 1.260\n",
      "[31, 240] loss: 1.300\n",
      "[31, 300] loss: 1.306\n",
      "[31, 360] loss: 1.282\n",
      "Epoch: 31 -> Loss: 1.1702272892\n",
      "Epoch: 31 -> Test Accuracy: 48.86\n",
      "[32, 60] loss: 1.282\n",
      "[32, 120] loss: 1.287\n",
      "[32, 180] loss: 1.294\n",
      "[32, 240] loss: 1.292\n",
      "[32, 300] loss: 1.283\n",
      "[32, 360] loss: 1.277\n",
      "Epoch: 32 -> Loss: 1.25006377697\n",
      "Epoch: 32 -> Test Accuracy: 48.86\n",
      "[33, 60] loss: 1.301\n",
      "[33, 120] loss: 1.274\n",
      "[33, 180] loss: 1.262\n",
      "[33, 240] loss: 1.307\n",
      "[33, 300] loss: 1.303\n",
      "[33, 360] loss: 1.285\n",
      "Epoch: 33 -> Loss: 1.50377738476\n",
      "Epoch: 33 -> Test Accuracy: 49.15\n",
      "[34, 60] loss: 1.298\n",
      "[34, 120] loss: 1.288\n",
      "[34, 180] loss: 1.280\n",
      "[34, 240] loss: 1.283\n",
      "[34, 300] loss: 1.284\n",
      "[34, 360] loss: 1.302\n",
      "Epoch: 34 -> Loss: 1.33399617672\n",
      "Epoch: 34 -> Test Accuracy: 48.72\n",
      "[35, 60] loss: 1.289\n",
      "[35, 120] loss: 1.292\n",
      "[35, 180] loss: 1.293\n",
      "[35, 240] loss: 1.290\n",
      "[35, 300] loss: 1.278\n",
      "[35, 360] loss: 1.292\n",
      "Epoch: 35 -> Loss: 1.14501142502\n",
      "Epoch: 35 -> Test Accuracy: 48.94\n",
      "[36, 60] loss: 1.294\n",
      "[36, 120] loss: 1.286\n",
      "[36, 180] loss: 1.275\n",
      "[36, 240] loss: 1.279\n",
      "[36, 300] loss: 1.269\n",
      "[36, 360] loss: 1.281\n",
      "Epoch: 36 -> Loss: 1.18841850758\n",
      "Epoch: 36 -> Test Accuracy: 48.91\n",
      "[37, 60] loss: 1.291\n",
      "[37, 120] loss: 1.270\n",
      "[37, 180] loss: 1.276\n",
      "[37, 240] loss: 1.291\n",
      "[37, 300] loss: 1.276\n",
      "[37, 360] loss: 1.295\n",
      "Epoch: 37 -> Loss: 1.31258368492\n",
      "Epoch: 37 -> Test Accuracy: 48.76\n",
      "[38, 60] loss: 1.283\n",
      "[38, 120] loss: 1.280\n",
      "[38, 180] loss: 1.278\n",
      "[38, 240] loss: 1.283\n",
      "[38, 300] loss: 1.284\n",
      "[38, 360] loss: 1.295\n",
      "Epoch: 38 -> Loss: 1.14831244946\n",
      "Epoch: 38 -> Test Accuracy: 48.9\n",
      "[39, 60] loss: 1.280\n",
      "[39, 120] loss: 1.298\n",
      "[39, 180] loss: 1.284\n",
      "[39, 240] loss: 1.272\n",
      "[39, 300] loss: 1.295\n",
      "[39, 360] loss: 1.276\n",
      "Epoch: 39 -> Loss: 1.4078348875\n",
      "Epoch: 39 -> Test Accuracy: 48.96\n",
      "[40, 60] loss: 1.280\n",
      "[40, 120] loss: 1.284\n",
      "[40, 180] loss: 1.284\n",
      "[40, 240] loss: 1.289\n",
      "[40, 300] loss: 1.283\n",
      "[40, 360] loss: 1.298\n",
      "Epoch: 40 -> Loss: 1.37079298496\n",
      "Epoch: 40 -> Test Accuracy: 48.75\n",
      "[41, 60] loss: 1.262\n",
      "[41, 120] loss: 1.247\n",
      "[41, 180] loss: 1.233\n",
      "[41, 240] loss: 1.222\n",
      "[41, 300] loss: 1.225\n",
      "[41, 360] loss: 1.212\n",
      "Epoch: 41 -> Loss: 1.14455831051\n",
      "Epoch: 41 -> Test Accuracy: 50.72\n",
      "[42, 60] loss: 1.210\n",
      "[42, 120] loss: 1.198\n",
      "[42, 180] loss: 1.207\n",
      "[42, 240] loss: 1.208\n",
      "[42, 300] loss: 1.198\n",
      "[42, 360] loss: 1.216\n",
      "Epoch: 42 -> Loss: 1.16773033142\n",
      "Epoch: 42 -> Test Accuracy: 51.23\n",
      "[43, 60] loss: 1.187\n",
      "[43, 120] loss: 1.199\n",
      "[43, 180] loss: 1.185\n",
      "[43, 240] loss: 1.198\n",
      "[43, 300] loss: 1.197\n",
      "[43, 360] loss: 1.188\n",
      "Epoch: 43 -> Loss: 1.30326867104\n",
      "Epoch: 43 -> Test Accuracy: 51.55\n",
      "[44, 60] loss: 1.184\n",
      "[44, 120] loss: 1.188\n",
      "[44, 180] loss: 1.201\n",
      "[44, 240] loss: 1.183\n",
      "[44, 300] loss: 1.192\n",
      "[44, 360] loss: 1.181\n",
      "Epoch: 44 -> Loss: 1.21895432472\n",
      "Epoch: 44 -> Test Accuracy: 51.95\n",
      "[45, 60] loss: 1.185\n",
      "[45, 120] loss: 1.190\n",
      "[45, 180] loss: 1.167\n",
      "[45, 240] loss: 1.185\n",
      "[45, 300] loss: 1.209\n",
      "[45, 360] loss: 1.201\n",
      "Epoch: 45 -> Loss: 1.24358344078\n",
      "Epoch: 45 -> Test Accuracy: 51.7\n",
      "[46, 60] loss: 1.168\n",
      "[46, 120] loss: 1.181\n",
      "[46, 180] loss: 1.161\n",
      "[46, 240] loss: 1.166\n",
      "[46, 300] loss: 1.175\n",
      "[46, 360] loss: 1.181\n",
      "Epoch: 46 -> Loss: 1.2643648386\n",
      "Epoch: 46 -> Test Accuracy: 52.47\n",
      "[47, 60] loss: 1.188\n",
      "[47, 120] loss: 1.169\n",
      "[47, 180] loss: 1.180\n",
      "[47, 240] loss: 1.168\n",
      "[47, 300] loss: 1.163\n",
      "[47, 360] loss: 1.158\n",
      "Epoch: 47 -> Loss: 1.27342128754\n",
      "Epoch: 47 -> Test Accuracy: 52.67\n",
      "[48, 60] loss: 1.147\n",
      "[48, 120] loss: 1.160\n",
      "[48, 180] loss: 1.177\n",
      "[48, 240] loss: 1.162\n",
      "[48, 300] loss: 1.170\n",
      "[48, 360] loss: 1.182\n",
      "Epoch: 48 -> Loss: 1.34531521797\n",
      "Epoch: 48 -> Test Accuracy: 52.43\n",
      "[49, 60] loss: 1.175\n",
      "[49, 120] loss: 1.161\n",
      "[49, 180] loss: 1.169\n",
      "[49, 240] loss: 1.147\n",
      "[49, 300] loss: 1.156\n",
      "[49, 360] loss: 1.162\n",
      "Epoch: 49 -> Loss: 1.07561945915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49 -> Test Accuracy: 52.74\n",
      "[50, 60] loss: 1.180\n",
      "[50, 120] loss: 1.179\n",
      "[50, 180] loss: 1.136\n",
      "[50, 240] loss: 1.157\n",
      "[50, 300] loss: 1.163\n",
      "[50, 360] loss: 1.161\n",
      "Epoch: 50 -> Loss: 1.12166047096\n",
      "Epoch: 50 -> Test Accuracy: 52.61\n",
      "[51, 60] loss: 1.173\n",
      "[51, 120] loss: 1.142\n",
      "[51, 180] loss: 1.160\n",
      "[51, 240] loss: 1.163\n",
      "[51, 300] loss: 1.152\n",
      "[51, 360] loss: 1.161\n",
      "Epoch: 51 -> Loss: 0.956628918648\n",
      "Epoch: 51 -> Test Accuracy: 52.73\n",
      "[52, 60] loss: 1.178\n",
      "[52, 120] loss: 1.161\n",
      "[52, 180] loss: 1.156\n",
      "[52, 240] loss: 1.163\n",
      "[52, 300] loss: 1.158\n",
      "[52, 360] loss: 1.166\n",
      "Epoch: 52 -> Loss: 1.04398977757\n",
      "Epoch: 52 -> Test Accuracy: 52.8\n",
      "[53, 60] loss: 1.147\n",
      "[53, 120] loss: 1.134\n",
      "[53, 180] loss: 1.160\n",
      "[53, 240] loss: 1.155\n",
      "[53, 300] loss: 1.172\n",
      "[53, 360] loss: 1.169\n",
      "Epoch: 53 -> Loss: 1.19881725311\n",
      "Epoch: 53 -> Test Accuracy: 52.62\n",
      "[54, 60] loss: 1.149\n",
      "[54, 120] loss: 1.159\n",
      "[54, 180] loss: 1.166\n",
      "[54, 240] loss: 1.143\n",
      "[54, 300] loss: 1.170\n",
      "[54, 360] loss: 1.156\n",
      "Epoch: 54 -> Loss: 1.16287732124\n",
      "Epoch: 54 -> Test Accuracy: 52.55\n",
      "[55, 60] loss: 1.151\n",
      "[55, 120] loss: 1.175\n",
      "[55, 180] loss: 1.163\n",
      "[55, 240] loss: 1.157\n",
      "[55, 300] loss: 1.161\n",
      "[55, 360] loss: 1.148\n",
      "Epoch: 55 -> Loss: 1.00995290279\n",
      "Epoch: 55 -> Test Accuracy: 52.5\n",
      "[56, 60] loss: 1.142\n",
      "[56, 120] loss: 1.160\n",
      "[56, 180] loss: 1.144\n",
      "[56, 240] loss: 1.136\n",
      "[56, 300] loss: 1.152\n",
      "[56, 360] loss: 1.168\n",
      "Epoch: 56 -> Loss: 1.09746861458\n",
      "Epoch: 56 -> Test Accuracy: 52.54\n",
      "[57, 60] loss: 1.142\n",
      "[57, 120] loss: 1.160\n",
      "[57, 180] loss: 1.154\n",
      "[57, 240] loss: 1.146\n",
      "[57, 300] loss: 1.148\n",
      "[57, 360] loss: 1.150\n",
      "Epoch: 57 -> Loss: 1.37084436417\n",
      "Epoch: 57 -> Test Accuracy: 52.62\n",
      "[58, 60] loss: 1.157\n",
      "[58, 120] loss: 1.149\n",
      "[58, 180] loss: 1.148\n",
      "[58, 240] loss: 1.144\n",
      "[58, 300] loss: 1.152\n",
      "[58, 360] loss: 1.155\n",
      "Epoch: 58 -> Loss: 1.38788068295\n",
      "Epoch: 58 -> Test Accuracy: 52.84\n",
      "[59, 60] loss: 1.145\n",
      "[59, 120] loss: 1.137\n",
      "[59, 180] loss: 1.136\n",
      "[59, 240] loss: 1.143\n",
      "[59, 300] loss: 1.164\n",
      "[59, 360] loss: 1.146\n",
      "Epoch: 59 -> Loss: 1.01267361641\n",
      "Epoch: 59 -> Test Accuracy: 52.61\n",
      "[60, 60] loss: 1.149\n",
      "[60, 120] loss: 1.152\n",
      "[60, 180] loss: 1.138\n",
      "[60, 240] loss: 1.172\n",
      "[60, 300] loss: 1.169\n",
      "[60, 360] loss: 1.136\n",
      "Epoch: 60 -> Loss: 1.32549905777\n",
      "Epoch: 60 -> Test Accuracy: 52.7\n",
      "[61, 60] loss: 1.144\n",
      "[61, 120] loss: 1.145\n",
      "[61, 180] loss: 1.133\n",
      "[61, 240] loss: 1.149\n",
      "[61, 300] loss: 1.161\n",
      "[61, 360] loss: 1.143\n",
      "Epoch: 61 -> Loss: 1.12684226036\n",
      "Epoch: 61 -> Test Accuracy: 52.71\n",
      "[62, 60] loss: 1.157\n",
      "[62, 120] loss: 1.138\n",
      "[62, 180] loss: 1.143\n",
      "[62, 240] loss: 1.154\n",
      "[62, 300] loss: 1.138\n",
      "[62, 360] loss: 1.149\n",
      "Epoch: 62 -> Loss: 1.15542471409\n",
      "Epoch: 62 -> Test Accuracy: 52.91\n",
      "[63, 60] loss: 1.146\n",
      "[63, 120] loss: 1.154\n",
      "[63, 180] loss: 1.146\n",
      "[63, 240] loss: 1.146\n",
      "[63, 300] loss: 1.154\n",
      "[63, 360] loss: 1.119\n",
      "Epoch: 63 -> Loss: 1.23004436493\n",
      "Epoch: 63 -> Test Accuracy: 52.59\n",
      "[64, 60] loss: 1.143\n",
      "[64, 120] loss: 1.150\n",
      "[64, 180] loss: 1.149\n",
      "[64, 240] loss: 1.140\n",
      "[64, 300] loss: 1.139\n",
      "[64, 360] loss: 1.147\n",
      "Epoch: 64 -> Loss: 1.24117457867\n",
      "Epoch: 64 -> Test Accuracy: 52.66\n",
      "[65, 60] loss: 1.162\n",
      "[65, 120] loss: 1.162\n",
      "[65, 180] loss: 1.139\n",
      "[65, 240] loss: 1.121\n",
      "[65, 300] loss: 1.130\n",
      "[65, 360] loss: 1.135\n",
      "Epoch: 65 -> Loss: 1.28125357628\n",
      "Epoch: 65 -> Test Accuracy: 52.68\n",
      "[66, 60] loss: 1.141\n",
      "[66, 120] loss: 1.148\n",
      "[66, 180] loss: 1.152\n",
      "[66, 240] loss: 1.132\n",
      "[66, 300] loss: 1.139\n",
      "[66, 360] loss: 1.143\n",
      "Epoch: 66 -> Loss: 1.1799582243\n",
      "Epoch: 66 -> Test Accuracy: 52.8\n",
      "[67, 60] loss: 1.147\n",
      "[67, 120] loss: 1.149\n",
      "[67, 180] loss: 1.160\n",
      "[67, 240] loss: 1.142\n",
      "[67, 300] loss: 1.144\n",
      "[67, 360] loss: 1.124\n",
      "Epoch: 67 -> Loss: 0.999987483025\n",
      "Epoch: 67 -> Test Accuracy: 52.81\n",
      "[68, 60] loss: 1.164\n",
      "[68, 120] loss: 1.149\n",
      "[68, 180] loss: 1.158\n",
      "[68, 240] loss: 1.121\n",
      "[68, 300] loss: 1.162\n",
      "[68, 360] loss: 1.127\n",
      "Epoch: 68 -> Loss: 1.19334959984\n",
      "Epoch: 68 -> Test Accuracy: 52.65\n",
      "[69, 60] loss: 1.148\n",
      "[69, 120] loss: 1.136\n",
      "[69, 180] loss: 1.150\n",
      "[69, 240] loss: 1.144\n",
      "[69, 300] loss: 1.141\n",
      "[69, 360] loss: 1.139\n",
      "Epoch: 69 -> Loss: 1.10553133488\n",
      "Epoch: 69 -> Test Accuracy: 52.89\n",
      "[70, 60] loss: 1.139\n",
      "[70, 120] loss: 1.157\n",
      "[70, 180] loss: 1.141\n",
      "[70, 240] loss: 1.120\n",
      "[70, 300] loss: 1.127\n",
      "[70, 360] loss: 1.128\n",
      "Epoch: 70 -> Loss: 1.19519758224\n",
      "Epoch: 70 -> Test Accuracy: 53.2\n",
      "[71, 60] loss: 1.156\n",
      "[71, 120] loss: 1.148\n",
      "[71, 180] loss: 1.140\n",
      "[71, 240] loss: 1.130\n",
      "[71, 300] loss: 1.124\n",
      "[71, 360] loss: 1.130\n",
      "Epoch: 71 -> Loss: 1.09731030464\n",
      "Epoch: 71 -> Test Accuracy: 53.11\n",
      "[72, 60] loss: 1.160\n",
      "[72, 120] loss: 1.124\n",
      "[72, 180] loss: 1.145\n",
      "[72, 240] loss: 1.150\n",
      "[72, 300] loss: 1.137\n",
      "[72, 360] loss: 1.147\n",
      "Epoch: 72 -> Loss: 1.21530544758\n",
      "Epoch: 72 -> Test Accuracy: 52.96\n",
      "[73, 60] loss: 1.141\n",
      "[73, 120] loss: 1.145\n",
      "[73, 180] loss: 1.129\n",
      "[73, 240] loss: 1.134\n",
      "[73, 300] loss: 1.123\n",
      "[73, 360] loss: 1.144\n",
      "Epoch: 73 -> Loss: 1.28356492519\n",
      "Epoch: 73 -> Test Accuracy: 52.84\n",
      "[74, 60] loss: 1.153\n",
      "[74, 120] loss: 1.135\n",
      "[74, 180] loss: 1.139\n",
      "[74, 240] loss: 1.147\n",
      "[74, 300] loss: 1.129\n",
      "[74, 360] loss: 1.136\n",
      "Epoch: 74 -> Loss: 0.92085057497\n",
      "Epoch: 74 -> Test Accuracy: 52.89\n",
      "[75, 60] loss: 1.148\n",
      "[75, 120] loss: 1.123\n",
      "[75, 180] loss: 1.135\n",
      "[75, 240] loss: 1.147\n",
      "[75, 300] loss: 1.122\n",
      "[75, 360] loss: 1.135\n",
      "Epoch: 75 -> Loss: 0.999118149281\n",
      "Epoch: 75 -> Test Accuracy: 52.95\n",
      "[76, 60] loss: 1.126\n",
      "[76, 120] loss: 1.133\n",
      "[76, 180] loss: 1.154\n",
      "[76, 240] loss: 1.151\n",
      "[76, 300] loss: 1.136\n",
      "[76, 360] loss: 1.116\n",
      "Epoch: 76 -> Loss: 1.30229628086\n",
      "Epoch: 76 -> Test Accuracy: 52.86\n",
      "[77, 60] loss: 1.128\n",
      "[77, 120] loss: 1.136\n",
      "[77, 180] loss: 1.127\n",
      "[77, 240] loss: 1.130\n",
      "[77, 300] loss: 1.135\n",
      "[77, 360] loss: 1.139\n",
      "Epoch: 77 -> Loss: 1.07567310333\n",
      "Epoch: 77 -> Test Accuracy: 53.33\n",
      "[78, 60] loss: 1.144\n",
      "[78, 120] loss: 1.118\n",
      "[78, 180] loss: 1.132\n",
      "[78, 240] loss: 1.124\n",
      "[78, 300] loss: 1.126\n",
      "[78, 360] loss: 1.122\n",
      "Epoch: 78 -> Loss: 1.19175601006\n",
      "Epoch: 78 -> Test Accuracy: 53.08\n",
      "[79, 60] loss: 1.130\n",
      "[79, 120] loss: 1.132\n",
      "[79, 180] loss: 1.150\n",
      "[79, 240] loss: 1.130\n",
      "[79, 300] loss: 1.138\n",
      "[79, 360] loss: 1.135\n",
      "Epoch: 79 -> Loss: 1.12518525124\n",
      "Epoch: 79 -> Test Accuracy: 53.15\n",
      "[80, 60] loss: 1.144\n",
      "[80, 120] loss: 1.114\n",
      "[80, 180] loss: 1.121\n",
      "[80, 240] loss: 1.151\n",
      "[80, 300] loss: 1.125\n",
      "[80, 360] loss: 1.132\n",
      "Epoch: 80 -> Loss: 1.18988192081\n",
      "Epoch: 80 -> Test Accuracy: 52.64\n",
      "[81, 60] loss: 1.118\n",
      "[81, 120] loss: 1.141\n",
      "[81, 180] loss: 1.105\n",
      "[81, 240] loss: 1.127\n",
      "[81, 300] loss: 1.138\n",
      "[81, 360] loss: 1.128\n",
      "Epoch: 81 -> Loss: 1.09647727013\n",
      "Epoch: 81 -> Test Accuracy: 53.03\n",
      "[82, 60] loss: 1.128\n",
      "[82, 120] loss: 1.131\n",
      "[82, 180] loss: 1.140\n",
      "[82, 240] loss: 1.113\n",
      "[82, 300] loss: 1.136\n",
      "[82, 360] loss: 1.126\n",
      "Epoch: 82 -> Loss: 1.24683308601\n",
      "Epoch: 82 -> Test Accuracy: 53.09\n",
      "[83, 60] loss: 1.136\n",
      "[83, 120] loss: 1.123\n",
      "[83, 180] loss: 1.113\n",
      "[83, 240] loss: 1.109\n",
      "[83, 300] loss: 1.137\n",
      "[83, 360] loss: 1.138\n",
      "Epoch: 83 -> Loss: 1.0753133297\n",
      "Epoch: 83 -> Test Accuracy: 52.92\n",
      "[84, 60] loss: 1.123\n",
      "[84, 120] loss: 1.118\n",
      "[84, 180] loss: 1.147\n",
      "[84, 240] loss: 1.131\n",
      "[84, 300] loss: 1.125\n",
      "[84, 360] loss: 1.135\n",
      "Epoch: 84 -> Loss: 1.22076845169\n",
      "Epoch: 84 -> Test Accuracy: 53.45\n",
      "[85, 60] loss: 1.118\n",
      "[85, 120] loss: 1.121\n",
      "[85, 180] loss: 1.139\n",
      "[85, 240] loss: 1.137\n",
      "[85, 300] loss: 1.119\n",
      "[85, 360] loss: 1.122\n",
      "Epoch: 85 -> Loss: 1.06381237507\n",
      "Epoch: 85 -> Test Accuracy: 53.05\n",
      "[86, 60] loss: 1.130\n",
      "[86, 120] loss: 1.125\n",
      "[86, 180] loss: 1.134\n",
      "[86, 240] loss: 1.146\n",
      "[86, 300] loss: 1.125\n",
      "[86, 360] loss: 1.124\n",
      "Epoch: 86 -> Loss: 1.14586007595\n",
      "Epoch: 86 -> Test Accuracy: 53.17\n",
      "[87, 60] loss: 1.133\n",
      "[87, 120] loss: 1.128\n",
      "[87, 180] loss: 1.113\n",
      "[87, 240] loss: 1.130\n",
      "[87, 300] loss: 1.126\n",
      "[87, 360] loss: 1.130\n",
      "Epoch: 87 -> Loss: 1.46234035492\n",
      "Epoch: 87 -> Test Accuracy: 53.72\n",
      "[88, 60] loss: 1.127\n",
      "[88, 120] loss: 1.131\n",
      "[88, 180] loss: 1.114\n",
      "[88, 240] loss: 1.131\n",
      "[88, 300] loss: 1.151\n",
      "[88, 360] loss: 1.121\n",
      "Epoch: 88 -> Loss: 1.13638007641\n",
      "Epoch: 88 -> Test Accuracy: 53.51\n",
      "[89, 60] loss: 1.116\n",
      "[89, 120] loss: 1.121\n",
      "[89, 180] loss: 1.139\n",
      "[89, 240] loss: 1.127\n",
      "[89, 300] loss: 1.108\n",
      "[89, 360] loss: 1.136\n",
      "Epoch: 89 -> Loss: 0.914415359497\n",
      "Epoch: 89 -> Test Accuracy: 53.33\n",
      "[90, 60] loss: 1.115\n",
      "[90, 120] loss: 1.123\n",
      "[90, 180] loss: 1.144\n",
      "[90, 240] loss: 1.110\n",
      "[90, 300] loss: 1.140\n",
      "[90, 360] loss: 1.121\n",
      "Epoch: 90 -> Loss: 1.16015648842\n",
      "Epoch: 90 -> Test Accuracy: 53.14\n",
      "[91, 60] loss: 1.118\n",
      "[91, 120] loss: 1.130\n",
      "[91, 180] loss: 1.126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[91, 240] loss: 1.126\n",
      "[91, 300] loss: 1.133\n",
      "[91, 360] loss: 1.105\n",
      "Epoch: 91 -> Loss: 1.17570328712\n",
      "Epoch: 91 -> Test Accuracy: 53.34\n",
      "[92, 60] loss: 1.121\n",
      "[92, 120] loss: 1.130\n",
      "[92, 180] loss: 1.132\n",
      "[92, 240] loss: 1.105\n",
      "[92, 300] loss: 1.131\n",
      "[92, 360] loss: 1.123\n",
      "Epoch: 92 -> Loss: 1.17059707642\n",
      "Epoch: 92 -> Test Accuracy: 53.2\n",
      "[93, 60] loss: 1.117\n",
      "[93, 120] loss: 1.123\n",
      "[93, 180] loss: 1.140\n",
      "[93, 240] loss: 1.137\n",
      "[93, 300] loss: 1.122\n",
      "[93, 360] loss: 1.117\n",
      "Epoch: 93 -> Loss: 0.936094105244\n",
      "Epoch: 93 -> Test Accuracy: 53.68\n",
      "[94, 60] loss: 1.131\n",
      "[94, 120] loss: 1.119\n",
      "[94, 180] loss: 1.111\n",
      "[94, 240] loss: 1.132\n",
      "[94, 300] loss: 1.117\n",
      "[94, 360] loss: 1.131\n",
      "Epoch: 94 -> Loss: 1.03828883171\n",
      "Epoch: 94 -> Test Accuracy: 53.54\n",
      "[95, 60] loss: 1.119\n",
      "[95, 120] loss: 1.130\n",
      "[95, 180] loss: 1.127\n",
      "[95, 240] loss: 1.115\n",
      "[95, 300] loss: 1.130\n",
      "[95, 360] loss: 1.105\n",
      "Epoch: 95 -> Loss: 1.13088405132\n",
      "Epoch: 95 -> Test Accuracy: 53.34\n",
      "[96, 60] loss: 1.110\n",
      "[96, 120] loss: 1.116\n",
      "[96, 180] loss: 1.125\n",
      "[96, 240] loss: 1.134\n",
      "[96, 300] loss: 1.129\n",
      "[96, 360] loss: 1.126\n",
      "Epoch: 96 -> Loss: 1.29257190228\n",
      "Epoch: 96 -> Test Accuracy: 53.41\n",
      "[97, 60] loss: 1.144\n",
      "[97, 120] loss: 1.127\n",
      "[97, 180] loss: 1.114\n",
      "[97, 240] loss: 1.117\n",
      "[97, 300] loss: 1.113\n",
      "[97, 360] loss: 1.105\n",
      "Epoch: 97 -> Loss: 1.06284403801\n",
      "Epoch: 97 -> Test Accuracy: 53.43\n",
      "[98, 60] loss: 1.115\n",
      "[98, 120] loss: 1.128\n",
      "[98, 180] loss: 1.114\n",
      "[98, 240] loss: 1.123\n",
      "[98, 300] loss: 1.126\n",
      "[98, 360] loss: 1.128\n",
      "Epoch: 98 -> Loss: 1.17992377281\n",
      "Epoch: 98 -> Test Accuracy: 53.69\n",
      "[99, 60] loss: 1.114\n",
      "[99, 120] loss: 1.110\n",
      "[99, 180] loss: 1.125\n",
      "[99, 240] loss: 1.109\n",
      "[99, 300] loss: 1.146\n",
      "[99, 360] loss: 1.124\n",
      "Epoch: 99 -> Loss: 1.12767267227\n",
      "Epoch: 99 -> Test Accuracy: 53.29\n",
      "[100, 60] loss: 1.109\n",
      "[100, 120] loss: 1.138\n",
      "[100, 180] loss: 1.104\n",
      "[100, 240] loss: 1.147\n",
      "[100, 300] loss: 1.107\n",
      "[100, 360] loss: 1.116\n",
      "Epoch: 100 -> Loss: 1.17429542542\n",
      "Epoch: 100 -> Test Accuracy: 53.6\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train NonLinearClassifiers on feature map of net_3block\n",
    "block3_loss_log, _, block3_test_accuracy_log, _, _ = tr.train_all_blocks(3, 10, [0.1, 0.02, 0.004, 0.0008], \n",
    "    [20, 40, 45, 100], 0.9, 5e-4, net_block3, criterion, trainloader, None, testloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.362\n",
      "[1, 120] loss: 1.037\n",
      "[1, 180] loss: 0.942\n",
      "[1, 240] loss: 0.872\n",
      "[1, 300] loss: 0.815\n",
      "[1, 360] loss: 0.807\n",
      "Epoch: 1 -> Loss: 0.792883634567\n",
      "Epoch: 1 -> Test Accuracy: 70.59\n",
      "[2, 60] loss: 0.715\n",
      "[2, 120] loss: 0.705\n",
      "[2, 180] loss: 0.713\n",
      "[2, 240] loss: 0.710\n",
      "[2, 300] loss: 0.695\n",
      "[2, 360] loss: 0.668\n",
      "Epoch: 2 -> Loss: 0.751881837845\n",
      "Epoch: 2 -> Test Accuracy: 73.94\n",
      "[3, 60] loss: 0.621\n",
      "[3, 120] loss: 0.632\n",
      "[3, 180] loss: 0.633\n",
      "[3, 240] loss: 0.632\n",
      "[3, 300] loss: 0.616\n",
      "[3, 360] loss: 0.591\n",
      "Epoch: 3 -> Loss: 0.438733756542\n",
      "Epoch: 3 -> Test Accuracy: 73.93\n",
      "[4, 60] loss: 0.558\n",
      "[4, 120] loss: 0.559\n",
      "[4, 180] loss: 0.553\n",
      "[4, 240] loss: 0.595\n",
      "[4, 300] loss: 0.574\n",
      "[4, 360] loss: 0.568\n",
      "Epoch: 4 -> Loss: 0.731389284134\n",
      "Epoch: 4 -> Test Accuracy: 77.82\n",
      "[5, 60] loss: 0.530\n",
      "[5, 120] loss: 0.539\n",
      "[5, 180] loss: 0.546\n",
      "[5, 240] loss: 0.534\n",
      "[5, 300] loss: 0.536\n",
      "[5, 360] loss: 0.552\n",
      "Epoch: 5 -> Loss: 0.509520590305\n",
      "Epoch: 5 -> Test Accuracy: 77.6\n",
      "[6, 60] loss: 0.513\n",
      "[6, 120] loss: 0.529\n",
      "[6, 180] loss: 0.512\n",
      "[6, 240] loss: 0.519\n",
      "[6, 300] loss: 0.540\n",
      "[6, 360] loss: 0.519\n",
      "Epoch: 6 -> Loss: 0.624110341072\n",
      "Epoch: 6 -> Test Accuracy: 79.02\n",
      "[7, 60] loss: 0.504\n",
      "[7, 120] loss: 0.492\n",
      "[7, 180] loss: 0.503\n",
      "[7, 240] loss: 0.519\n",
      "[7, 300] loss: 0.506\n",
      "[7, 360] loss: 0.515\n",
      "Epoch: 7 -> Loss: 0.634994566441\n",
      "Epoch: 7 -> Test Accuracy: 78.92\n",
      "[8, 60] loss: 0.461\n",
      "[8, 120] loss: 0.490\n",
      "[8, 180] loss: 0.484\n",
      "[8, 240] loss: 0.496\n",
      "[8, 300] loss: 0.480\n",
      "[8, 360] loss: 0.502\n",
      "Epoch: 8 -> Loss: 0.57943046093\n",
      "Epoch: 8 -> Test Accuracy: 79.42\n",
      "[9, 60] loss: 0.451\n",
      "[9, 120] loss: 0.459\n",
      "[9, 180] loss: 0.483\n",
      "[9, 240] loss: 0.474\n",
      "[9, 300] loss: 0.480\n",
      "[9, 360] loss: 0.499\n",
      "Epoch: 9 -> Loss: 0.455070793629\n",
      "Epoch: 9 -> Test Accuracy: 79.3\n",
      "[10, 60] loss: 0.464\n",
      "[10, 120] loss: 0.473\n",
      "[10, 180] loss: 0.450\n",
      "[10, 240] loss: 0.472\n",
      "[10, 300] loss: 0.458\n",
      "[10, 360] loss: 0.472\n",
      "Epoch: 10 -> Loss: 0.430081546307\n",
      "Epoch: 10 -> Test Accuracy: 78.84\n",
      "[11, 60] loss: 0.448\n",
      "[11, 120] loss: 0.445\n",
      "[11, 180] loss: 0.467\n",
      "[11, 240] loss: 0.463\n",
      "[11, 300] loss: 0.475\n",
      "[11, 360] loss: 0.469\n",
      "Epoch: 11 -> Loss: 0.431666374207\n",
      "Epoch: 11 -> Test Accuracy: 78.75\n",
      "[12, 60] loss: 0.467\n",
      "[12, 120] loss: 0.442\n",
      "[12, 180] loss: 0.443\n",
      "[12, 240] loss: 0.461\n",
      "[12, 300] loss: 0.460\n",
      "[12, 360] loss: 0.466\n",
      "Epoch: 12 -> Loss: 0.415230840445\n",
      "Epoch: 12 -> Test Accuracy: 80.02\n",
      "[13, 60] loss: 0.441\n",
      "[13, 120] loss: 0.450\n",
      "[13, 180] loss: 0.452\n",
      "[13, 240] loss: 0.449\n",
      "[13, 300] loss: 0.474\n",
      "[13, 360] loss: 0.453\n",
      "Epoch: 13 -> Loss: 0.401607692242\n",
      "Epoch: 13 -> Test Accuracy: 79.89\n",
      "[14, 60] loss: 0.424\n",
      "[14, 120] loss: 0.442\n",
      "[14, 180] loss: 0.428\n",
      "[14, 240] loss: 0.450\n",
      "[14, 300] loss: 0.447\n",
      "[14, 360] loss: 0.442\n",
      "Epoch: 14 -> Loss: 0.457617104053\n",
      "Epoch: 14 -> Test Accuracy: 80.42\n",
      "[15, 60] loss: 0.413\n",
      "[15, 120] loss: 0.433\n",
      "[15, 180] loss: 0.429\n",
      "[15, 240] loss: 0.443\n",
      "[15, 300] loss: 0.459\n",
      "[15, 360] loss: 0.437\n",
      "Epoch: 15 -> Loss: 0.48553198576\n",
      "Epoch: 15 -> Test Accuracy: 79.78\n",
      "[16, 60] loss: 0.444\n",
      "[16, 120] loss: 0.429\n",
      "[16, 180] loss: 0.431\n",
      "[16, 240] loss: 0.438\n",
      "[16, 300] loss: 0.459\n",
      "[16, 360] loss: 0.426\n",
      "Epoch: 16 -> Loss: 0.422204494476\n",
      "Epoch: 16 -> Test Accuracy: 80.62\n",
      "[17, 60] loss: 0.424\n",
      "[17, 120] loss: 0.426\n",
      "[17, 180] loss: 0.451\n",
      "[17, 240] loss: 0.426\n",
      "[17, 300] loss: 0.446\n",
      "[17, 360] loss: 0.450\n",
      "Epoch: 17 -> Loss: 0.614605307579\n",
      "Epoch: 17 -> Test Accuracy: 80.7\n",
      "[18, 60] loss: 0.425\n",
      "[18, 120] loss: 0.427\n",
      "[18, 180] loss: 0.425\n",
      "[18, 240] loss: 0.444\n",
      "[18, 300] loss: 0.423\n",
      "[18, 360] loss: 0.444\n",
      "Epoch: 18 -> Loss: 0.518989920616\n",
      "Epoch: 18 -> Test Accuracy: 80.59\n",
      "[19, 60] loss: 0.425\n",
      "[19, 120] loss: 0.409\n",
      "[19, 180] loss: 0.429\n",
      "[19, 240] loss: 0.403\n",
      "[19, 300] loss: 0.437\n",
      "[19, 360] loss: 0.446\n",
      "Epoch: 19 -> Loss: 0.335473924875\n",
      "Epoch: 19 -> Test Accuracy: 79.66\n",
      "[20, 60] loss: 0.406\n",
      "[20, 120] loss: 0.420\n",
      "[20, 180] loss: 0.421\n",
      "[20, 240] loss: 0.426\n",
      "[20, 300] loss: 0.434\n",
      "[20, 360] loss: 0.439\n",
      "Epoch: 20 -> Loss: 0.524476408958\n",
      "Epoch: 20 -> Test Accuracy: 81.32\n",
      "[21, 60] loss: 0.410\n",
      "[21, 120] loss: 0.418\n",
      "[21, 180] loss: 0.437\n",
      "[21, 240] loss: 0.420\n",
      "[21, 300] loss: 0.410\n",
      "[21, 360] loss: 0.444\n",
      "Epoch: 21 -> Loss: 0.425741434097\n",
      "Epoch: 21 -> Test Accuracy: 81.55\n",
      "[22, 60] loss: 0.392\n",
      "[22, 120] loss: 0.396\n",
      "[22, 180] loss: 0.415\n",
      "[22, 240] loss: 0.432\n",
      "[22, 300] loss: 0.444\n",
      "[22, 360] loss: 0.431\n",
      "Epoch: 22 -> Loss: 0.600199341774\n",
      "Epoch: 22 -> Test Accuracy: 80.09\n",
      "[23, 60] loss: 0.407\n",
      "[23, 120] loss: 0.414\n",
      "[23, 180] loss: 0.432\n",
      "[23, 240] loss: 0.431\n",
      "[23, 300] loss: 0.430\n",
      "[23, 360] loss: 0.418\n",
      "Epoch: 23 -> Loss: 0.265299379826\n",
      "Epoch: 23 -> Test Accuracy: 80.16\n",
      "[24, 60] loss: 0.401\n",
      "[24, 120] loss: 0.409\n",
      "[24, 180] loss: 0.420\n",
      "[24, 240] loss: 0.413\n",
      "[24, 300] loss: 0.427\n",
      "[24, 360] loss: 0.425\n",
      "Epoch: 24 -> Loss: 0.418722331524\n",
      "Epoch: 24 -> Test Accuracy: 80.11\n",
      "[25, 60] loss: 0.394\n",
      "[25, 120] loss: 0.414\n",
      "[25, 180] loss: 0.401\n",
      "[25, 240] loss: 0.414\n",
      "[25, 300] loss: 0.420\n",
      "[25, 360] loss: 0.434\n",
      "Epoch: 25 -> Loss: 0.564521729946\n",
      "Epoch: 25 -> Test Accuracy: 81.43\n",
      "[26, 60] loss: 0.403\n",
      "[26, 120] loss: 0.397\n",
      "[26, 180] loss: 0.420\n",
      "[26, 240] loss: 0.417\n",
      "[26, 300] loss: 0.419\n",
      "[26, 360] loss: 0.424\n",
      "Epoch: 26 -> Loss: 0.611900806427\n",
      "Epoch: 26 -> Test Accuracy: 81.62\n",
      "[27, 60] loss: 0.393\n",
      "[27, 120] loss: 0.397\n",
      "[27, 180] loss: 0.421\n",
      "[27, 240] loss: 0.424\n",
      "[27, 300] loss: 0.434\n",
      "[27, 360] loss: 0.413\n",
      "Epoch: 27 -> Loss: 0.360693961382\n",
      "Epoch: 27 -> Test Accuracy: 81.31\n",
      "[28, 60] loss: 0.390\n",
      "[28, 120] loss: 0.392\n",
      "[28, 180] loss: 0.389\n",
      "[28, 240] loss: 0.437\n",
      "[28, 300] loss: 0.424\n",
      "[28, 360] loss: 0.414\n",
      "Epoch: 28 -> Loss: 0.289470255375\n",
      "Epoch: 28 -> Test Accuracy: 81.07\n",
      "[29, 60] loss: 0.403\n",
      "[29, 120] loss: 0.408\n",
      "[29, 180] loss: 0.403\n",
      "[29, 240] loss: 0.420\n",
      "[29, 300] loss: 0.423\n",
      "[29, 360] loss: 0.423\n",
      "Epoch: 29 -> Loss: 0.424772083759\n",
      "Epoch: 29 -> Test Accuracy: 81.9\n",
      "[30, 60] loss: 0.388\n",
      "[30, 120] loss: 0.392\n",
      "[30, 180] loss: 0.412\n",
      "[30, 240] loss: 0.411\n",
      "[30, 300] loss: 0.419\n",
      "[30, 360] loss: 0.417\n",
      "Epoch: 30 -> Loss: 0.41766127944\n",
      "Epoch: 30 -> Test Accuracy: 80.21\n",
      "[31, 60] loss: 0.399\n",
      "[31, 120] loss: 0.397\n",
      "[31, 180] loss: 0.414\n",
      "[31, 240] loss: 0.401\n",
      "[31, 300] loss: 0.422\n",
      "[31, 360] loss: 0.423\n",
      "Epoch: 31 -> Loss: 0.404598087072\n",
      "Epoch: 31 -> Test Accuracy: 80.78\n",
      "[32, 60] loss: 0.380\n",
      "[32, 120] loss: 0.394\n",
      "[32, 180] loss: 0.397\n",
      "[32, 240] loss: 0.414\n",
      "[32, 300] loss: 0.414\n",
      "[32, 360] loss: 0.444\n",
      "Epoch: 32 -> Loss: 0.413601219654\n",
      "Epoch: 32 -> Test Accuracy: 81.99\n",
      "[33, 60] loss: 0.368\n",
      "[33, 120] loss: 0.403\n",
      "[33, 180] loss: 0.398\n",
      "[33, 240] loss: 0.398\n",
      "[33, 300] loss: 0.423\n",
      "[33, 360] loss: 0.422\n",
      "Epoch: 33 -> Loss: 0.393446534872\n",
      "Epoch: 33 -> Test Accuracy: 82.46\n",
      "[34, 60] loss: 0.381\n",
      "[34, 120] loss: 0.388\n",
      "[34, 180] loss: 0.404\n",
      "[34, 240] loss: 0.411\n",
      "[34, 300] loss: 0.414\n",
      "[34, 360] loss: 0.425\n",
      "Epoch: 34 -> Loss: 0.432740300894\n",
      "Epoch: 34 -> Test Accuracy: 82.0\n",
      "[35, 60] loss: 0.395\n",
      "[35, 120] loss: 0.389\n",
      "[35, 180] loss: 0.379\n",
      "[35, 240] loss: 0.413\n",
      "[35, 300] loss: 0.410\n",
      "[35, 360] loss: 0.434\n",
      "Epoch: 35 -> Loss: 0.516286492348\n",
      "Epoch: 35 -> Test Accuracy: 81.06\n",
      "[36, 60] loss: 0.336\n",
      "[36, 120] loss: 0.288\n",
      "[36, 180] loss: 0.281\n",
      "[36, 240] loss: 0.280\n",
      "[36, 300] loss: 0.275\n",
      "[36, 360] loss: 0.270\n",
      "Epoch: 36 -> Loss: 0.422071695328\n",
      "Epoch: 36 -> Test Accuracy: 85.35\n",
      "[37, 60] loss: 0.248\n",
      "[37, 120] loss: 0.256\n",
      "[37, 180] loss: 0.250\n",
      "[37, 240] loss: 0.233\n",
      "[37, 300] loss: 0.263\n",
      "[37, 360] loss: 0.248\n",
      "Epoch: 37 -> Loss: 0.191427692771\n",
      "Epoch: 37 -> Test Accuracy: 85.75\n",
      "[38, 60] loss: 0.230\n",
      "[38, 120] loss: 0.241\n",
      "[38, 180] loss: 0.234\n",
      "[38, 240] loss: 0.236\n",
      "[38, 300] loss: 0.253\n",
      "[38, 360] loss: 0.235\n",
      "Epoch: 38 -> Loss: 0.254433870316\n",
      "Epoch: 38 -> Test Accuracy: 85.52\n",
      "[39, 60] loss: 0.222\n",
      "[39, 120] loss: 0.222\n",
      "[39, 180] loss: 0.229\n",
      "[39, 240] loss: 0.239\n",
      "[39, 300] loss: 0.245\n",
      "[39, 360] loss: 0.239\n",
      "Epoch: 39 -> Loss: 0.244102790952\n",
      "Epoch: 39 -> Test Accuracy: 85.59\n",
      "[40, 60] loss: 0.221\n",
      "[40, 120] loss: 0.218\n",
      "[40, 180] loss: 0.220\n",
      "[40, 240] loss: 0.229\n",
      "[40, 300] loss: 0.231\n",
      "[40, 360] loss: 0.238\n",
      "Epoch: 40 -> Loss: 0.168945088983\n",
      "Epoch: 40 -> Test Accuracy: 85.9\n",
      "[41, 60] loss: 0.201\n",
      "[41, 120] loss: 0.211\n",
      "[41, 180] loss: 0.229\n",
      "[41, 240] loss: 0.223\n",
      "[41, 300] loss: 0.238\n",
      "[41, 360] loss: 0.233\n",
      "Epoch: 41 -> Loss: 0.279966413975\n",
      "Epoch: 41 -> Test Accuracy: 85.11\n",
      "[42, 60] loss: 0.215\n",
      "[42, 120] loss: 0.217\n",
      "[42, 180] loss: 0.222\n",
      "[42, 240] loss: 0.221\n",
      "[42, 300] loss: 0.219\n",
      "[42, 360] loss: 0.222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.20328810811\n",
      "Epoch: 42 -> Test Accuracy: 85.43\n",
      "[43, 60] loss: 0.214\n",
      "[43, 120] loss: 0.208\n",
      "[43, 180] loss: 0.210\n",
      "[43, 240] loss: 0.226\n",
      "[43, 300] loss: 0.233\n",
      "[43, 360] loss: 0.228\n",
      "Epoch: 43 -> Loss: 0.269247233868\n",
      "Epoch: 43 -> Test Accuracy: 85.26\n",
      "[44, 60] loss: 0.209\n",
      "[44, 120] loss: 0.213\n",
      "[44, 180] loss: 0.216\n",
      "[44, 240] loss: 0.209\n",
      "[44, 300] loss: 0.228\n",
      "[44, 360] loss: 0.238\n",
      "Epoch: 44 -> Loss: 0.296880304813\n",
      "Epoch: 44 -> Test Accuracy: 85.2\n",
      "[45, 60] loss: 0.195\n",
      "[45, 120] loss: 0.210\n",
      "[45, 180] loss: 0.213\n",
      "[45, 240] loss: 0.226\n",
      "[45, 300] loss: 0.223\n",
      "[45, 360] loss: 0.244\n",
      "Epoch: 45 -> Loss: 0.314031511545\n",
      "Epoch: 45 -> Test Accuracy: 85.3\n",
      "[46, 60] loss: 0.207\n",
      "[46, 120] loss: 0.222\n",
      "[46, 180] loss: 0.219\n",
      "[46, 240] loss: 0.221\n",
      "[46, 300] loss: 0.227\n",
      "[46, 360] loss: 0.236\n",
      "Epoch: 46 -> Loss: 0.335136651993\n",
      "Epoch: 46 -> Test Accuracy: 85.11\n",
      "[47, 60] loss: 0.217\n",
      "[47, 120] loss: 0.209\n",
      "[47, 180] loss: 0.218\n",
      "[47, 240] loss: 0.218\n",
      "[47, 300] loss: 0.223\n",
      "[47, 360] loss: 0.228\n",
      "Epoch: 47 -> Loss: 0.241845935583\n",
      "Epoch: 47 -> Test Accuracy: 84.6\n",
      "[48, 60] loss: 0.207\n",
      "[48, 120] loss: 0.214\n",
      "[48, 180] loss: 0.219\n",
      "[48, 240] loss: 0.217\n",
      "[48, 300] loss: 0.239\n",
      "[48, 360] loss: 0.220\n",
      "Epoch: 48 -> Loss: 0.288785070181\n",
      "Epoch: 48 -> Test Accuracy: 84.17\n",
      "[49, 60] loss: 0.206\n",
      "[49, 120] loss: 0.215\n",
      "[49, 180] loss: 0.222\n",
      "[49, 240] loss: 0.227\n",
      "[49, 300] loss: 0.215\n",
      "[49, 360] loss: 0.218\n",
      "Epoch: 49 -> Loss: 0.242222309113\n",
      "Epoch: 49 -> Test Accuracy: 84.98\n",
      "[50, 60] loss: 0.201\n",
      "[50, 120] loss: 0.215\n",
      "[50, 180] loss: 0.219\n",
      "[50, 240] loss: 0.215\n",
      "[50, 300] loss: 0.220\n",
      "[50, 360] loss: 0.220\n",
      "Epoch: 50 -> Loss: 0.284704864025\n",
      "Epoch: 50 -> Test Accuracy: 84.59\n",
      "[51, 60] loss: 0.213\n",
      "[51, 120] loss: 0.209\n",
      "[51, 180] loss: 0.222\n",
      "[51, 240] loss: 0.223\n",
      "[51, 300] loss: 0.229\n",
      "[51, 360] loss: 0.222\n",
      "Epoch: 51 -> Loss: 0.227006405592\n",
      "Epoch: 51 -> Test Accuracy: 83.94\n",
      "[52, 60] loss: 0.197\n",
      "[52, 120] loss: 0.215\n",
      "[52, 180] loss: 0.220\n",
      "[52, 240] loss: 0.214\n",
      "[52, 300] loss: 0.232\n",
      "[52, 360] loss: 0.228\n",
      "Epoch: 52 -> Loss: 0.211768954992\n",
      "Epoch: 52 -> Test Accuracy: 84.55\n",
      "[53, 60] loss: 0.209\n",
      "[53, 120] loss: 0.210\n",
      "[53, 180] loss: 0.210\n",
      "[53, 240] loss: 0.219\n",
      "[53, 300] loss: 0.220\n",
      "[53, 360] loss: 0.233\n",
      "Epoch: 53 -> Loss: 0.271092712879\n",
      "Epoch: 53 -> Test Accuracy: 84.29\n",
      "[54, 60] loss: 0.196\n",
      "[54, 120] loss: 0.207\n",
      "[54, 180] loss: 0.209\n",
      "[54, 240] loss: 0.213\n",
      "[54, 300] loss: 0.225\n",
      "[54, 360] loss: 0.227\n",
      "Epoch: 54 -> Loss: 0.379067331553\n",
      "Epoch: 54 -> Test Accuracy: 85.07\n",
      "[55, 60] loss: 0.203\n",
      "[55, 120] loss: 0.198\n",
      "[55, 180] loss: 0.218\n",
      "[55, 240] loss: 0.226\n",
      "[55, 300] loss: 0.235\n",
      "[55, 360] loss: 0.230\n",
      "Epoch: 55 -> Loss: 0.186972260475\n",
      "Epoch: 55 -> Test Accuracy: 83.7\n",
      "[56, 60] loss: 0.214\n",
      "[56, 120] loss: 0.213\n",
      "[56, 180] loss: 0.214\n",
      "[56, 240] loss: 0.228\n",
      "[56, 300] loss: 0.212\n",
      "[56, 360] loss: 0.237\n",
      "Epoch: 56 -> Loss: 0.313044309616\n",
      "Epoch: 56 -> Test Accuracy: 84.64\n",
      "[57, 60] loss: 0.201\n",
      "[57, 120] loss: 0.200\n",
      "[57, 180] loss: 0.206\n",
      "[57, 240] loss: 0.219\n",
      "[57, 300] loss: 0.224\n",
      "[57, 360] loss: 0.239\n",
      "Epoch: 57 -> Loss: 0.178555816412\n",
      "Epoch: 57 -> Test Accuracy: 83.83\n",
      "[58, 60] loss: 0.198\n",
      "[58, 120] loss: 0.214\n",
      "[58, 180] loss: 0.215\n",
      "[58, 240] loss: 0.220\n",
      "[58, 300] loss: 0.218\n",
      "[58, 360] loss: 0.227\n",
      "Epoch: 58 -> Loss: 0.212146565318\n",
      "Epoch: 58 -> Test Accuracy: 84.33\n",
      "[59, 60] loss: 0.202\n",
      "[59, 120] loss: 0.212\n",
      "[59, 180] loss: 0.212\n",
      "[59, 240] loss: 0.217\n",
      "[59, 300] loss: 0.215\n",
      "[59, 360] loss: 0.218\n",
      "Epoch: 59 -> Loss: 0.198148131371\n",
      "Epoch: 59 -> Test Accuracy: 84.83\n",
      "[60, 60] loss: 0.206\n",
      "[60, 120] loss: 0.192\n",
      "[60, 180] loss: 0.216\n",
      "[60, 240] loss: 0.211\n",
      "[60, 300] loss: 0.217\n",
      "[60, 360] loss: 0.226\n",
      "Epoch: 60 -> Loss: 0.175246447325\n",
      "Epoch: 60 -> Test Accuracy: 83.96\n",
      "[61, 60] loss: 0.211\n",
      "[61, 120] loss: 0.215\n",
      "[61, 180] loss: 0.221\n",
      "[61, 240] loss: 0.208\n",
      "[61, 300] loss: 0.217\n",
      "[61, 360] loss: 0.224\n",
      "Epoch: 61 -> Loss: 0.211447000504\n",
      "Epoch: 61 -> Test Accuracy: 84.19\n",
      "[62, 60] loss: 0.193\n",
      "[62, 120] loss: 0.202\n",
      "[62, 180] loss: 0.224\n",
      "[62, 240] loss: 0.223\n",
      "[62, 300] loss: 0.220\n",
      "[62, 360] loss: 0.230\n",
      "Epoch: 62 -> Loss: 0.271758019924\n",
      "Epoch: 62 -> Test Accuracy: 85.39\n",
      "[63, 60] loss: 0.197\n",
      "[63, 120] loss: 0.205\n",
      "[63, 180] loss: 0.212\n",
      "[63, 240] loss: 0.210\n",
      "[63, 300] loss: 0.216\n",
      "[63, 360] loss: 0.220\n",
      "Epoch: 63 -> Loss: 0.164512589574\n",
      "Epoch: 63 -> Test Accuracy: 83.7\n",
      "[64, 60] loss: 0.196\n",
      "[64, 120] loss: 0.190\n",
      "[64, 180] loss: 0.202\n",
      "[64, 240] loss: 0.209\n",
      "[64, 300] loss: 0.222\n",
      "[64, 360] loss: 0.211\n",
      "Epoch: 64 -> Loss: 0.27257591486\n",
      "Epoch: 64 -> Test Accuracy: 83.67\n",
      "[65, 60] loss: 0.199\n",
      "[65, 120] loss: 0.201\n",
      "[65, 180] loss: 0.205\n",
      "[65, 240] loss: 0.227\n",
      "[65, 300] loss: 0.209\n",
      "[65, 360] loss: 0.216\n",
      "Epoch: 65 -> Loss: 0.273677110672\n",
      "Epoch: 65 -> Test Accuracy: 84.36\n",
      "[66, 60] loss: 0.195\n",
      "[66, 120] loss: 0.206\n",
      "[66, 180] loss: 0.207\n",
      "[66, 240] loss: 0.220\n",
      "[66, 300] loss: 0.201\n",
      "[66, 360] loss: 0.216\n",
      "Epoch: 66 -> Loss: 0.247540071607\n",
      "Epoch: 66 -> Test Accuracy: 83.96\n",
      "[67, 60] loss: 0.199\n",
      "[67, 120] loss: 0.194\n",
      "[67, 180] loss: 0.213\n",
      "[67, 240] loss: 0.214\n",
      "[67, 300] loss: 0.216\n",
      "[67, 360] loss: 0.221\n",
      "Epoch: 67 -> Loss: 0.185533612967\n",
      "Epoch: 67 -> Test Accuracy: 83.43\n",
      "[68, 60] loss: 0.196\n",
      "[68, 120] loss: 0.197\n",
      "[68, 180] loss: 0.215\n",
      "[68, 240] loss: 0.208\n",
      "[68, 300] loss: 0.224\n",
      "[68, 360] loss: 0.219\n",
      "Epoch: 68 -> Loss: 0.361555427313\n",
      "Epoch: 68 -> Test Accuracy: 84.75\n",
      "[69, 60] loss: 0.205\n",
      "[69, 120] loss: 0.206\n",
      "[69, 180] loss: 0.210\n",
      "[69, 240] loss: 0.205\n",
      "[69, 300] loss: 0.218\n",
      "[69, 360] loss: 0.216\n",
      "Epoch: 69 -> Loss: 0.353217601776\n",
      "Epoch: 69 -> Test Accuracy: 84.14\n",
      "[70, 60] loss: 0.191\n",
      "[70, 120] loss: 0.195\n",
      "[70, 180] loss: 0.208\n",
      "[70, 240] loss: 0.221\n",
      "[70, 300] loss: 0.215\n",
      "[70, 360] loss: 0.210\n",
      "Epoch: 70 -> Loss: 0.323803126812\n",
      "Epoch: 70 -> Test Accuracy: 84.47\n",
      "[71, 60] loss: 0.167\n",
      "[71, 120] loss: 0.145\n",
      "[71, 180] loss: 0.142\n",
      "[71, 240] loss: 0.145\n",
      "[71, 300] loss: 0.134\n",
      "[71, 360] loss: 0.132\n",
      "Epoch: 71 -> Loss: 0.162738755345\n",
      "Epoch: 71 -> Test Accuracy: 86.3\n",
      "[72, 60] loss: 0.128\n",
      "[72, 120] loss: 0.121\n",
      "[72, 180] loss: 0.127\n",
      "[72, 240] loss: 0.127\n",
      "[72, 300] loss: 0.128\n",
      "[72, 360] loss: 0.133\n",
      "Epoch: 72 -> Loss: 0.146627679467\n",
      "Epoch: 72 -> Test Accuracy: 86.54\n",
      "[73, 60] loss: 0.123\n",
      "[73, 120] loss: 0.117\n",
      "[73, 180] loss: 0.118\n",
      "[73, 240] loss: 0.119\n",
      "[73, 300] loss: 0.120\n",
      "[73, 360] loss: 0.130\n",
      "Epoch: 73 -> Loss: 0.0586969442666\n",
      "Epoch: 73 -> Test Accuracy: 86.37\n",
      "[74, 60] loss: 0.113\n",
      "[74, 120] loss: 0.119\n",
      "[74, 180] loss: 0.115\n",
      "[74, 240] loss: 0.118\n",
      "[74, 300] loss: 0.115\n",
      "[74, 360] loss: 0.119\n",
      "Epoch: 74 -> Loss: 0.224319130182\n",
      "Epoch: 74 -> Test Accuracy: 86.35\n",
      "[75, 60] loss: 0.115\n",
      "[75, 120] loss: 0.109\n",
      "[75, 180] loss: 0.114\n",
      "[75, 240] loss: 0.116\n",
      "[75, 300] loss: 0.114\n",
      "[75, 360] loss: 0.114\n",
      "Epoch: 75 -> Loss: 0.111555896699\n",
      "Epoch: 75 -> Test Accuracy: 86.55\n",
      "[76, 60] loss: 0.100\n",
      "[76, 120] loss: 0.109\n",
      "[76, 180] loss: 0.115\n",
      "[76, 240] loss: 0.111\n",
      "[76, 300] loss: 0.107\n",
      "[76, 360] loss: 0.111\n",
      "Epoch: 76 -> Loss: 0.196151822805\n",
      "Epoch: 76 -> Test Accuracy: 86.47\n",
      "[77, 60] loss: 0.106\n",
      "[77, 120] loss: 0.109\n",
      "[77, 180] loss: 0.107\n",
      "[77, 240] loss: 0.111\n",
      "[77, 300] loss: 0.103\n",
      "[77, 360] loss: 0.105\n",
      "Epoch: 77 -> Loss: 0.0613335780799\n",
      "Epoch: 77 -> Test Accuracy: 86.43\n",
      "[78, 60] loss: 0.099\n",
      "[78, 120] loss: 0.099\n",
      "[78, 180] loss: 0.102\n",
      "[78, 240] loss: 0.106\n",
      "[78, 300] loss: 0.112\n",
      "[78, 360] loss: 0.114\n",
      "Epoch: 78 -> Loss: 0.116870425642\n",
      "Epoch: 78 -> Test Accuracy: 86.43\n",
      "[79, 60] loss: 0.103\n",
      "[79, 120] loss: 0.102\n",
      "[79, 180] loss: 0.102\n",
      "[79, 240] loss: 0.102\n",
      "[79, 300] loss: 0.107\n",
      "[79, 360] loss: 0.109\n",
      "Epoch: 79 -> Loss: 0.140382915735\n",
      "Epoch: 79 -> Test Accuracy: 86.16\n",
      "[80, 60] loss: 0.101\n",
      "[80, 120] loss: 0.092\n",
      "[80, 180] loss: 0.099\n",
      "[80, 240] loss: 0.099\n",
      "[80, 300] loss: 0.103\n",
      "[80, 360] loss: 0.105\n",
      "Epoch: 80 -> Loss: 0.102045968175\n",
      "Epoch: 80 -> Test Accuracy: 86.08\n",
      "[81, 60] loss: 0.091\n",
      "[81, 120] loss: 0.096\n",
      "[81, 180] loss: 0.105\n",
      "[81, 240] loss: 0.104\n",
      "[81, 300] loss: 0.099\n",
      "[81, 360] loss: 0.104\n",
      "Epoch: 81 -> Loss: 0.109508536756\n",
      "Epoch: 81 -> Test Accuracy: 86.44\n",
      "[82, 60] loss: 0.094\n",
      "[82, 120] loss: 0.101\n",
      "[82, 180] loss: 0.096\n",
      "[82, 240] loss: 0.100\n",
      "[82, 300] loss: 0.103\n",
      "[82, 360] loss: 0.105\n",
      "Epoch: 82 -> Loss: 0.0661332830787\n",
      "Epoch: 82 -> Test Accuracy: 86.39\n",
      "[83, 60] loss: 0.090\n",
      "[83, 120] loss: 0.096\n",
      "[83, 180] loss: 0.096\n",
      "[83, 240] loss: 0.097\n",
      "[83, 300] loss: 0.103\n",
      "[83, 360] loss: 0.105\n",
      "Epoch: 83 -> Loss: 0.0906256586313\n",
      "Epoch: 83 -> Test Accuracy: 85.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.101\n",
      "[84, 120] loss: 0.095\n",
      "[84, 180] loss: 0.092\n",
      "[84, 240] loss: 0.095\n",
      "[84, 300] loss: 0.102\n",
      "[84, 360] loss: 0.094\n",
      "Epoch: 84 -> Loss: 0.194360494614\n",
      "Epoch: 84 -> Test Accuracy: 86.21\n",
      "[85, 60] loss: 0.095\n",
      "[85, 120] loss: 0.092\n",
      "[85, 180] loss: 0.095\n",
      "[85, 240] loss: 0.101\n",
      "[85, 300] loss: 0.102\n",
      "[85, 360] loss: 0.094\n",
      "Epoch: 85 -> Loss: 0.10455699265\n",
      "Epoch: 85 -> Test Accuracy: 86.1\n",
      "[86, 60] loss: 0.087\n",
      "[86, 120] loss: 0.082\n",
      "[86, 180] loss: 0.087\n",
      "[86, 240] loss: 0.084\n",
      "[86, 300] loss: 0.078\n",
      "[86, 360] loss: 0.085\n",
      "Epoch: 86 -> Loss: 0.0832486376166\n",
      "Epoch: 86 -> Test Accuracy: 86.68\n",
      "[87, 60] loss: 0.084\n",
      "[87, 120] loss: 0.081\n",
      "[87, 180] loss: 0.079\n",
      "[87, 240] loss: 0.086\n",
      "[87, 300] loss: 0.087\n",
      "[87, 360] loss: 0.079\n",
      "Epoch: 87 -> Loss: 0.0660256668925\n",
      "Epoch: 87 -> Test Accuracy: 86.52\n",
      "[88, 60] loss: 0.081\n",
      "[88, 120] loss: 0.088\n",
      "[88, 180] loss: 0.081\n",
      "[88, 240] loss: 0.082\n",
      "[88, 300] loss: 0.081\n",
      "[88, 360] loss: 0.081\n",
      "Epoch: 88 -> Loss: 0.0787039250135\n",
      "Epoch: 88 -> Test Accuracy: 86.42\n",
      "[89, 60] loss: 0.085\n",
      "[89, 120] loss: 0.085\n",
      "[89, 180] loss: 0.084\n",
      "[89, 240] loss: 0.084\n",
      "[89, 300] loss: 0.078\n",
      "[89, 360] loss: 0.084\n",
      "Epoch: 89 -> Loss: 0.0824829638004\n",
      "Epoch: 89 -> Test Accuracy: 86.5\n",
      "[90, 60] loss: 0.078\n",
      "[90, 120] loss: 0.079\n",
      "[90, 180] loss: 0.081\n",
      "[90, 240] loss: 0.079\n",
      "[90, 300] loss: 0.081\n",
      "[90, 360] loss: 0.079\n",
      "Epoch: 90 -> Loss: 0.0517584681511\n",
      "Epoch: 90 -> Test Accuracy: 86.6\n",
      "[91, 60] loss: 0.077\n",
      "[91, 120] loss: 0.077\n",
      "[91, 180] loss: 0.087\n",
      "[91, 240] loss: 0.075\n",
      "[91, 300] loss: 0.084\n",
      "[91, 360] loss: 0.079\n",
      "Epoch: 91 -> Loss: 0.099382892251\n",
      "Epoch: 91 -> Test Accuracy: 86.52\n",
      "[92, 60] loss: 0.077\n",
      "[92, 120] loss: 0.074\n",
      "[92, 180] loss: 0.081\n",
      "[92, 240] loss: 0.077\n",
      "[92, 300] loss: 0.074\n",
      "[92, 360] loss: 0.081\n",
      "Epoch: 92 -> Loss: 0.0626267567277\n",
      "Epoch: 92 -> Test Accuracy: 86.41\n",
      "[93, 60] loss: 0.076\n",
      "[93, 120] loss: 0.080\n",
      "[93, 180] loss: 0.076\n",
      "[93, 240] loss: 0.077\n",
      "[93, 300] loss: 0.080\n",
      "[93, 360] loss: 0.076\n",
      "Epoch: 93 -> Loss: 0.100612305105\n",
      "Epoch: 93 -> Test Accuracy: 86.38\n",
      "[94, 60] loss: 0.075\n",
      "[94, 120] loss: 0.079\n",
      "[94, 180] loss: 0.075\n",
      "[94, 240] loss: 0.079\n",
      "[94, 300] loss: 0.079\n",
      "[94, 360] loss: 0.077\n",
      "Epoch: 94 -> Loss: 0.0596847310662\n",
      "Epoch: 94 -> Test Accuracy: 86.37\n",
      "[95, 60] loss: 0.079\n",
      "[95, 120] loss: 0.075\n",
      "[95, 180] loss: 0.078\n",
      "[95, 240] loss: 0.077\n",
      "[95, 300] loss: 0.076\n",
      "[95, 360] loss: 0.078\n",
      "Epoch: 95 -> Loss: 0.0471930801868\n",
      "Epoch: 95 -> Test Accuracy: 86.42\n",
      "[96, 60] loss: 0.077\n",
      "[96, 120] loss: 0.076\n",
      "[96, 180] loss: 0.074\n",
      "[96, 240] loss: 0.079\n",
      "[96, 300] loss: 0.080\n",
      "[96, 360] loss: 0.078\n",
      "Epoch: 96 -> Loss: 0.10640245676\n",
      "Epoch: 96 -> Test Accuracy: 86.29\n",
      "[97, 60] loss: 0.075\n",
      "[97, 120] loss: 0.081\n",
      "[97, 180] loss: 0.076\n",
      "[97, 240] loss: 0.077\n",
      "[97, 300] loss: 0.076\n",
      "[97, 360] loss: 0.078\n",
      "Epoch: 97 -> Loss: 0.0738745927811\n",
      "Epoch: 97 -> Test Accuracy: 86.45\n",
      "[98, 60] loss: 0.080\n",
      "[98, 120] loss: 0.072\n",
      "[98, 180] loss: 0.072\n",
      "[98, 240] loss: 0.080\n",
      "[98, 300] loss: 0.078\n",
      "[98, 360] loss: 0.078\n",
      "Epoch: 98 -> Loss: 0.0789629220963\n",
      "Epoch: 98 -> Test Accuracy: 86.21\n",
      "[99, 60] loss: 0.078\n",
      "[99, 120] loss: 0.075\n",
      "[99, 180] loss: 0.075\n",
      "[99, 240] loss: 0.076\n",
      "[99, 300] loss: 0.077\n",
      "[99, 360] loss: 0.078\n",
      "Epoch: 99 -> Loss: 0.11601062119\n",
      "Epoch: 99 -> Test Accuracy: 86.34\n",
      "[100, 60] loss: 0.077\n",
      "[100, 120] loss: 0.074\n",
      "[100, 180] loss: 0.075\n",
      "[100, 240] loss: 0.074\n",
      "[100, 300] loss: 0.078\n",
      "[100, 360] loss: 0.076\n",
      "Epoch: 100 -> Loss: 0.0978377610445\n",
      "Epoch: 100 -> Test Accuracy: 86.4\n",
      "Finished Training\n",
      "[1, 60] loss: 0.889\n",
      "[1, 120] loss: 0.640\n",
      "[1, 180] loss: 0.582\n",
      "[1, 240] loss: 0.518\n",
      "[1, 300] loss: 0.522\n",
      "[1, 360] loss: 0.484\n",
      "Epoch: 1 -> Loss: 0.601750195026\n",
      "Epoch: 1 -> Test Accuracy: 80.49\n",
      "[2, 60] loss: 0.446\n",
      "[2, 120] loss: 0.443\n",
      "[2, 180] loss: 0.461\n",
      "[2, 240] loss: 0.429\n",
      "[2, 300] loss: 0.438\n",
      "[2, 360] loss: 0.425\n",
      "Epoch: 2 -> Loss: 0.417422115803\n",
      "Epoch: 2 -> Test Accuracy: 81.69\n",
      "[3, 60] loss: 0.404\n",
      "[3, 120] loss: 0.390\n",
      "[3, 180] loss: 0.415\n",
      "[3, 240] loss: 0.390\n",
      "[3, 300] loss: 0.391\n",
      "[3, 360] loss: 0.397\n",
      "Epoch: 3 -> Loss: 0.489453792572\n",
      "Epoch: 3 -> Test Accuracy: 84.04\n",
      "[4, 60] loss: 0.347\n",
      "[4, 120] loss: 0.352\n",
      "[4, 180] loss: 0.356\n",
      "[4, 240] loss: 0.379\n",
      "[4, 300] loss: 0.384\n",
      "[4, 360] loss: 0.398\n",
      "Epoch: 4 -> Loss: 0.509384036064\n",
      "Epoch: 4 -> Test Accuracy: 83.06\n",
      "[5, 60] loss: 0.341\n",
      "[5, 120] loss: 0.341\n",
      "[5, 180] loss: 0.362\n",
      "[5, 240] loss: 0.355\n",
      "[5, 300] loss: 0.336\n",
      "[5, 360] loss: 0.369\n",
      "Epoch: 5 -> Loss: 0.306725412607\n",
      "Epoch: 5 -> Test Accuracy: 83.63\n",
      "[6, 60] loss: 0.312\n",
      "[6, 120] loss: 0.331\n",
      "[6, 180] loss: 0.335\n",
      "[6, 240] loss: 0.339\n",
      "[6, 300] loss: 0.348\n",
      "[6, 360] loss: 0.333\n",
      "Epoch: 6 -> Loss: 0.301770359278\n",
      "Epoch: 6 -> Test Accuracy: 84.24\n",
      "[7, 60] loss: 0.306\n",
      "[7, 120] loss: 0.313\n",
      "[7, 180] loss: 0.312\n",
      "[7, 240] loss: 0.343\n",
      "[7, 300] loss: 0.353\n",
      "[7, 360] loss: 0.332\n",
      "Epoch: 7 -> Loss: 0.423497736454\n",
      "Epoch: 7 -> Test Accuracy: 84.22\n",
      "[8, 60] loss: 0.307\n",
      "[8, 120] loss: 0.310\n",
      "[8, 180] loss: 0.316\n",
      "[8, 240] loss: 0.318\n",
      "[8, 300] loss: 0.332\n",
      "[8, 360] loss: 0.323\n",
      "Epoch: 8 -> Loss: 0.242952659726\n",
      "Epoch: 8 -> Test Accuracy: 84.6\n",
      "[9, 60] loss: 0.299\n",
      "[9, 120] loss: 0.312\n",
      "[9, 180] loss: 0.301\n",
      "[9, 240] loss: 0.309\n",
      "[9, 300] loss: 0.327\n",
      "[9, 360] loss: 0.316\n",
      "Epoch: 9 -> Loss: 0.243154495955\n",
      "Epoch: 9 -> Test Accuracy: 85.28\n",
      "[10, 60] loss: 0.301\n",
      "[10, 120] loss: 0.295\n",
      "[10, 180] loss: 0.298\n",
      "[10, 240] loss: 0.318\n",
      "[10, 300] loss: 0.321\n",
      "[10, 360] loss: 0.319\n",
      "Epoch: 10 -> Loss: 0.368662506342\n",
      "Epoch: 10 -> Test Accuracy: 85.03\n",
      "[11, 60] loss: 0.274\n",
      "[11, 120] loss: 0.304\n",
      "[11, 180] loss: 0.297\n",
      "[11, 240] loss: 0.306\n",
      "[11, 300] loss: 0.302\n",
      "[11, 360] loss: 0.320\n",
      "Epoch: 11 -> Loss: 0.385421514511\n",
      "Epoch: 11 -> Test Accuracy: 85.05\n",
      "[12, 60] loss: 0.272\n",
      "[12, 120] loss: 0.308\n",
      "[12, 180] loss: 0.291\n",
      "[12, 240] loss: 0.296\n",
      "[12, 300] loss: 0.310\n",
      "[12, 360] loss: 0.329\n",
      "Epoch: 12 -> Loss: 0.211615487933\n",
      "Epoch: 12 -> Test Accuracy: 85.73\n",
      "[13, 60] loss: 0.284\n",
      "[13, 120] loss: 0.275\n",
      "[13, 180] loss: 0.297\n",
      "[13, 240] loss: 0.303\n",
      "[13, 300] loss: 0.311\n",
      "[13, 360] loss: 0.295\n",
      "Epoch: 13 -> Loss: 0.309644818306\n",
      "Epoch: 13 -> Test Accuracy: 84.95\n",
      "[14, 60] loss: 0.287\n",
      "[14, 120] loss: 0.285\n",
      "[14, 180] loss: 0.297\n",
      "[14, 240] loss: 0.278\n",
      "[14, 300] loss: 0.311\n",
      "[14, 360] loss: 0.298\n",
      "Epoch: 14 -> Loss: 0.407134920359\n",
      "Epoch: 14 -> Test Accuracy: 85.17\n",
      "[15, 60] loss: 0.267\n",
      "[15, 120] loss: 0.280\n",
      "[15, 180] loss: 0.285\n",
      "[15, 240] loss: 0.292\n",
      "[15, 300] loss: 0.301\n",
      "[15, 360] loss: 0.300\n",
      "Epoch: 15 -> Loss: 0.283707499504\n",
      "Epoch: 15 -> Test Accuracy: 84.36\n",
      "[16, 60] loss: 0.257\n",
      "[16, 120] loss: 0.279\n",
      "[16, 180] loss: 0.287\n",
      "[16, 240] loss: 0.279\n",
      "[16, 300] loss: 0.294\n",
      "[16, 360] loss: 0.306\n",
      "Epoch: 16 -> Loss: 0.430595874786\n",
      "Epoch: 16 -> Test Accuracy: 85.15\n",
      "[17, 60] loss: 0.256\n",
      "[17, 120] loss: 0.271\n",
      "[17, 180] loss: 0.298\n",
      "[17, 240] loss: 0.301\n",
      "[17, 300] loss: 0.291\n",
      "[17, 360] loss: 0.301\n",
      "Epoch: 17 -> Loss: 0.187386110425\n",
      "Epoch: 17 -> Test Accuracy: 85.01\n",
      "[18, 60] loss: 0.262\n",
      "[18, 120] loss: 0.284\n",
      "[18, 180] loss: 0.292\n",
      "[18, 240] loss: 0.292\n",
      "[18, 300] loss: 0.282\n",
      "[18, 360] loss: 0.300\n",
      "Epoch: 18 -> Loss: 0.38392829895\n",
      "Epoch: 18 -> Test Accuracy: 85.61\n",
      "[19, 60] loss: 0.258\n",
      "[19, 120] loss: 0.269\n",
      "[19, 180] loss: 0.290\n",
      "[19, 240] loss: 0.294\n",
      "[19, 300] loss: 0.277\n",
      "[19, 360] loss: 0.284\n",
      "Epoch: 19 -> Loss: 0.255623728037\n",
      "Epoch: 19 -> Test Accuracy: 85.05\n",
      "[20, 60] loss: 0.266\n",
      "[20, 120] loss: 0.260\n",
      "[20, 180] loss: 0.266\n",
      "[20, 240] loss: 0.287\n",
      "[20, 300] loss: 0.287\n",
      "[20, 360] loss: 0.297\n",
      "Epoch: 20 -> Loss: 0.198698759079\n",
      "Epoch: 20 -> Test Accuracy: 84.83\n",
      "[21, 60] loss: 0.255\n",
      "[21, 120] loss: 0.274\n",
      "[21, 180] loss: 0.276\n",
      "[21, 240] loss: 0.272\n",
      "[21, 300] loss: 0.294\n",
      "[21, 360] loss: 0.297\n",
      "Epoch: 21 -> Loss: 0.261927515268\n",
      "Epoch: 21 -> Test Accuracy: 84.98\n",
      "[22, 60] loss: 0.249\n",
      "[22, 120] loss: 0.263\n",
      "[22, 180] loss: 0.293\n",
      "[22, 240] loss: 0.286\n",
      "[22, 300] loss: 0.277\n",
      "[22, 360] loss: 0.286\n",
      "Epoch: 22 -> Loss: 0.308242976665\n",
      "Epoch: 22 -> Test Accuracy: 84.23\n",
      "[23, 60] loss: 0.265\n",
      "[23, 120] loss: 0.262\n",
      "[23, 180] loss: 0.266\n",
      "[23, 240] loss: 0.269\n",
      "[23, 300] loss: 0.297\n",
      "[23, 360] loss: 0.290\n",
      "Epoch: 23 -> Loss: 0.255080908537\n",
      "Epoch: 23 -> Test Accuracy: 84.56\n",
      "[24, 60] loss: 0.249\n",
      "[24, 120] loss: 0.258\n",
      "[24, 180] loss: 0.282\n",
      "[24, 240] loss: 0.279\n",
      "[24, 300] loss: 0.280\n",
      "[24, 360] loss: 0.289\n",
      "Epoch: 24 -> Loss: 0.262317717075\n",
      "Epoch: 24 -> Test Accuracy: 85.7\n",
      "[25, 60] loss: 0.266\n",
      "[25, 120] loss: 0.280\n",
      "[25, 180] loss: 0.260\n",
      "[25, 240] loss: 0.281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 300] loss: 0.276\n",
      "[25, 360] loss: 0.287\n",
      "Epoch: 25 -> Loss: 0.171951457858\n",
      "Epoch: 25 -> Test Accuracy: 84.94\n",
      "[26, 60] loss: 0.253\n",
      "[26, 120] loss: 0.286\n",
      "[26, 180] loss: 0.262\n",
      "[26, 240] loss: 0.281\n",
      "[26, 300] loss: 0.264\n",
      "[26, 360] loss: 0.285\n",
      "Epoch: 26 -> Loss: 0.319078981876\n",
      "Epoch: 26 -> Test Accuracy: 85.32\n",
      "[27, 60] loss: 0.246\n",
      "[27, 120] loss: 0.244\n",
      "[27, 180] loss: 0.268\n",
      "[27, 240] loss: 0.288\n",
      "[27, 300] loss: 0.270\n",
      "[27, 360] loss: 0.289\n",
      "Epoch: 27 -> Loss: 0.353828132153\n",
      "Epoch: 27 -> Test Accuracy: 85.33\n",
      "[28, 60] loss: 0.244\n",
      "[28, 120] loss: 0.264\n",
      "[28, 180] loss: 0.272\n",
      "[28, 240] loss: 0.273\n",
      "[28, 300] loss: 0.286\n",
      "[28, 360] loss: 0.286\n",
      "Epoch: 28 -> Loss: 0.203239396214\n",
      "Epoch: 28 -> Test Accuracy: 85.75\n",
      "[29, 60] loss: 0.251\n",
      "[29, 120] loss: 0.271\n",
      "[29, 180] loss: 0.265\n",
      "[29, 240] loss: 0.263\n",
      "[29, 300] loss: 0.298\n",
      "[29, 360] loss: 0.276\n",
      "Epoch: 29 -> Loss: 0.330868393183\n",
      "Epoch: 29 -> Test Accuracy: 84.06\n",
      "[30, 60] loss: 0.254\n",
      "[30, 120] loss: 0.266\n",
      "[30, 180] loss: 0.268\n",
      "[30, 240] loss: 0.273\n",
      "[30, 300] loss: 0.279\n",
      "[30, 360] loss: 0.288\n",
      "Epoch: 30 -> Loss: 0.360421001911\n",
      "Epoch: 30 -> Test Accuracy: 85.49\n",
      "[31, 60] loss: 0.257\n",
      "[31, 120] loss: 0.255\n",
      "[31, 180] loss: 0.258\n",
      "[31, 240] loss: 0.273\n",
      "[31, 300] loss: 0.285\n",
      "[31, 360] loss: 0.277\n",
      "Epoch: 31 -> Loss: 0.284671396017\n",
      "Epoch: 31 -> Test Accuracy: 85.83\n",
      "[32, 60] loss: 0.253\n",
      "[32, 120] loss: 0.252\n",
      "[32, 180] loss: 0.264\n",
      "[32, 240] loss: 0.278\n",
      "[32, 300] loss: 0.283\n",
      "[32, 360] loss: 0.279\n",
      "Epoch: 32 -> Loss: 0.445972025394\n",
      "Epoch: 32 -> Test Accuracy: 84.69\n",
      "[33, 60] loss: 0.251\n",
      "[33, 120] loss: 0.245\n",
      "[33, 180] loss: 0.258\n",
      "[33, 240] loss: 0.283\n",
      "[33, 300] loss: 0.281\n",
      "[33, 360] loss: 0.271\n",
      "Epoch: 33 -> Loss: 0.513584077358\n",
      "Epoch: 33 -> Test Accuracy: 86.37\n",
      "[34, 60] loss: 0.255\n",
      "[34, 120] loss: 0.253\n",
      "[34, 180] loss: 0.271\n",
      "[34, 240] loss: 0.277\n",
      "[34, 300] loss: 0.270\n",
      "[34, 360] loss: 0.265\n",
      "Epoch: 34 -> Loss: 0.341367900372\n",
      "Epoch: 34 -> Test Accuracy: 85.44\n",
      "[35, 60] loss: 0.236\n",
      "[35, 120] loss: 0.241\n",
      "[35, 180] loss: 0.269\n",
      "[35, 240] loss: 0.270\n",
      "[35, 300] loss: 0.288\n",
      "[35, 360] loss: 0.284\n",
      "Epoch: 35 -> Loss: 0.329723656178\n",
      "Epoch: 35 -> Test Accuracy: 84.64\n",
      "[36, 60] loss: 0.199\n",
      "[36, 120] loss: 0.191\n",
      "[36, 180] loss: 0.169\n",
      "[36, 240] loss: 0.173\n",
      "[36, 300] loss: 0.178\n",
      "[36, 360] loss: 0.161\n",
      "Epoch: 36 -> Loss: 0.0961438417435\n",
      "Epoch: 36 -> Test Accuracy: 87.99\n",
      "[37, 60] loss: 0.147\n",
      "[37, 120] loss: 0.158\n",
      "[37, 180] loss: 0.154\n",
      "[37, 240] loss: 0.146\n",
      "[37, 300] loss: 0.146\n",
      "[37, 360] loss: 0.144\n",
      "Epoch: 37 -> Loss: 0.118583105505\n",
      "Epoch: 37 -> Test Accuracy: 88.31\n",
      "[38, 60] loss: 0.134\n",
      "[38, 120] loss: 0.138\n",
      "[38, 180] loss: 0.136\n",
      "[38, 240] loss: 0.133\n",
      "[38, 300] loss: 0.137\n",
      "[38, 360] loss: 0.139\n",
      "Epoch: 38 -> Loss: 0.175427943468\n",
      "Epoch: 38 -> Test Accuracy: 88.06\n",
      "[39, 60] loss: 0.126\n",
      "[39, 120] loss: 0.114\n",
      "[39, 180] loss: 0.123\n",
      "[39, 240] loss: 0.134\n",
      "[39, 300] loss: 0.127\n",
      "[39, 360] loss: 0.132\n",
      "Epoch: 39 -> Loss: 0.13324315846\n",
      "Epoch: 39 -> Test Accuracy: 88.21\n",
      "[40, 60] loss: 0.113\n",
      "[40, 120] loss: 0.116\n",
      "[40, 180] loss: 0.122\n",
      "[40, 240] loss: 0.122\n",
      "[40, 300] loss: 0.126\n",
      "[40, 360] loss: 0.132\n",
      "Epoch: 40 -> Loss: 0.152892753482\n",
      "Epoch: 40 -> Test Accuracy: 87.87\n",
      "[41, 60] loss: 0.112\n",
      "[41, 120] loss: 0.118\n",
      "[41, 180] loss: 0.117\n",
      "[41, 240] loss: 0.112\n",
      "[41, 300] loss: 0.125\n",
      "[41, 360] loss: 0.126\n",
      "Epoch: 41 -> Loss: 0.131439939141\n",
      "Epoch: 41 -> Test Accuracy: 88.03\n",
      "[42, 60] loss: 0.106\n",
      "[42, 120] loss: 0.111\n",
      "[42, 180] loss: 0.117\n",
      "[42, 240] loss: 0.115\n",
      "[42, 300] loss: 0.115\n",
      "[42, 360] loss: 0.121\n",
      "Epoch: 42 -> Loss: 0.209842011333\n",
      "Epoch: 42 -> Test Accuracy: 87.82\n",
      "[43, 60] loss: 0.108\n",
      "[43, 120] loss: 0.106\n",
      "[43, 180] loss: 0.114\n",
      "[43, 240] loss: 0.105\n",
      "[43, 300] loss: 0.112\n",
      "[43, 360] loss: 0.124\n",
      "Epoch: 43 -> Loss: 0.058845885098\n",
      "Epoch: 43 -> Test Accuracy: 88.05\n",
      "[44, 60] loss: 0.105\n",
      "[44, 120] loss: 0.105\n",
      "[44, 180] loss: 0.109\n",
      "[44, 240] loss: 0.107\n",
      "[44, 300] loss: 0.119\n",
      "[44, 360] loss: 0.121\n",
      "Epoch: 44 -> Loss: 0.103462837636\n",
      "Epoch: 44 -> Test Accuracy: 87.78\n",
      "[45, 60] loss: 0.103\n",
      "[45, 120] loss: 0.106\n",
      "[45, 180] loss: 0.107\n",
      "[45, 240] loss: 0.111\n",
      "[45, 300] loss: 0.114\n",
      "[45, 360] loss: 0.108\n",
      "Epoch: 45 -> Loss: 0.143724352121\n",
      "Epoch: 45 -> Test Accuracy: 87.83\n",
      "[46, 60] loss: 0.100\n",
      "[46, 120] loss: 0.100\n",
      "[46, 180] loss: 0.109\n",
      "[46, 240] loss: 0.108\n",
      "[46, 300] loss: 0.119\n",
      "[46, 360] loss: 0.125\n",
      "Epoch: 46 -> Loss: 0.0667201653123\n",
      "Epoch: 46 -> Test Accuracy: 87.72\n",
      "[47, 60] loss: 0.092\n",
      "[47, 120] loss: 0.111\n",
      "[47, 180] loss: 0.121\n",
      "[47, 240] loss: 0.117\n",
      "[47, 300] loss: 0.115\n",
      "[47, 360] loss: 0.116\n",
      "Epoch: 47 -> Loss: 0.127395287156\n",
      "Epoch: 47 -> Test Accuracy: 87.57\n",
      "[48, 60] loss: 0.108\n",
      "[48, 120] loss: 0.107\n",
      "[48, 180] loss: 0.111\n",
      "[48, 240] loss: 0.119\n",
      "[48, 300] loss: 0.116\n",
      "[48, 360] loss: 0.115\n",
      "Epoch: 48 -> Loss: 0.221414521337\n",
      "Epoch: 48 -> Test Accuracy: 87.37\n",
      "[49, 60] loss: 0.108\n",
      "[49, 120] loss: 0.110\n",
      "[49, 180] loss: 0.108\n",
      "[49, 240] loss: 0.115\n",
      "[49, 300] loss: 0.120\n",
      "[49, 360] loss: 0.126\n",
      "Epoch: 49 -> Loss: 0.0928696990013\n",
      "Epoch: 49 -> Test Accuracy: 87.56\n",
      "[50, 60] loss: 0.114\n",
      "[50, 120] loss: 0.112\n",
      "[50, 180] loss: 0.111\n",
      "[50, 240] loss: 0.108\n",
      "[50, 300] loss: 0.119\n",
      "[50, 360] loss: 0.118\n",
      "Epoch: 50 -> Loss: 0.0800099298358\n",
      "Epoch: 50 -> Test Accuracy: 87.64\n",
      "[51, 60] loss: 0.106\n",
      "[51, 120] loss: 0.093\n",
      "[51, 180] loss: 0.108\n",
      "[51, 240] loss: 0.108\n",
      "[51, 300] loss: 0.114\n",
      "[51, 360] loss: 0.113\n",
      "Epoch: 51 -> Loss: 0.176026031375\n",
      "Epoch: 51 -> Test Accuracy: 87.21\n",
      "[52, 60] loss: 0.104\n",
      "[52, 120] loss: 0.106\n",
      "[52, 180] loss: 0.107\n",
      "[52, 240] loss: 0.113\n",
      "[52, 300] loss: 0.122\n",
      "[52, 360] loss: 0.121\n",
      "Epoch: 52 -> Loss: 0.169025018811\n",
      "Epoch: 52 -> Test Accuracy: 87.17\n",
      "[53, 60] loss: 0.105\n",
      "[53, 120] loss: 0.106\n",
      "[53, 180] loss: 0.101\n",
      "[53, 240] loss: 0.120\n",
      "[53, 300] loss: 0.122\n",
      "[53, 360] loss: 0.115\n",
      "Epoch: 53 -> Loss: 0.144137218595\n",
      "Epoch: 53 -> Test Accuracy: 87.27\n",
      "[54, 60] loss: 0.098\n",
      "[54, 120] loss: 0.102\n",
      "[54, 180] loss: 0.109\n",
      "[54, 240] loss: 0.113\n",
      "[54, 300] loss: 0.108\n",
      "[54, 360] loss: 0.123\n",
      "Epoch: 54 -> Loss: 0.116811946034\n",
      "Epoch: 54 -> Test Accuracy: 86.86\n",
      "[55, 60] loss: 0.107\n",
      "[55, 120] loss: 0.103\n",
      "[55, 180] loss: 0.117\n",
      "[55, 240] loss: 0.115\n",
      "[55, 300] loss: 0.111\n",
      "[55, 360] loss: 0.126\n",
      "Epoch: 55 -> Loss: 0.138547345996\n",
      "Epoch: 55 -> Test Accuracy: 87.45\n",
      "[56, 60] loss: 0.097\n",
      "[56, 120] loss: 0.107\n",
      "[56, 180] loss: 0.110\n",
      "[56, 240] loss: 0.109\n",
      "[56, 300] loss: 0.110\n",
      "[56, 360] loss: 0.116\n",
      "Epoch: 56 -> Loss: 0.180342257023\n",
      "Epoch: 56 -> Test Accuracy: 87.24\n",
      "[57, 60] loss: 0.113\n",
      "[57, 120] loss: 0.111\n",
      "[57, 180] loss: 0.098\n",
      "[57, 240] loss: 0.116\n",
      "[57, 300] loss: 0.122\n",
      "[57, 360] loss: 0.132\n",
      "Epoch: 57 -> Loss: 0.0614099130034\n",
      "Epoch: 57 -> Test Accuracy: 87.34\n",
      "[58, 60] loss: 0.110\n",
      "[58, 120] loss: 0.106\n",
      "[58, 180] loss: 0.111\n",
      "[58, 240] loss: 0.112\n",
      "[58, 300] loss: 0.118\n",
      "[58, 360] loss: 0.124\n",
      "Epoch: 58 -> Loss: 0.105969011784\n",
      "Epoch: 58 -> Test Accuracy: 86.86\n",
      "[59, 60] loss: 0.111\n",
      "[59, 120] loss: 0.112\n",
      "[59, 180] loss: 0.110\n",
      "[59, 240] loss: 0.109\n",
      "[59, 300] loss: 0.114\n",
      "[59, 360] loss: 0.116\n",
      "Epoch: 59 -> Loss: 0.0882211774588\n",
      "Epoch: 59 -> Test Accuracy: 86.99\n",
      "[60, 60] loss: 0.102\n",
      "[60, 120] loss: 0.105\n",
      "[60, 180] loss: 0.111\n",
      "[60, 240] loss: 0.111\n",
      "[60, 300] loss: 0.122\n",
      "[60, 360] loss: 0.121\n",
      "Epoch: 60 -> Loss: 0.1824939996\n",
      "Epoch: 60 -> Test Accuracy: 87.3\n",
      "[61, 60] loss: 0.105\n",
      "[61, 120] loss: 0.094\n",
      "[61, 180] loss: 0.106\n",
      "[61, 240] loss: 0.103\n",
      "[61, 300] loss: 0.113\n",
      "[61, 360] loss: 0.111\n",
      "Epoch: 61 -> Loss: 0.139293506742\n",
      "Epoch: 61 -> Test Accuracy: 87.02\n",
      "[62, 60] loss: 0.097\n",
      "[62, 120] loss: 0.095\n",
      "[62, 180] loss: 0.113\n",
      "[62, 240] loss: 0.105\n",
      "[62, 300] loss: 0.113\n",
      "[62, 360] loss: 0.130\n",
      "Epoch: 62 -> Loss: 0.209203153849\n",
      "Epoch: 62 -> Test Accuracy: 87.26\n",
      "[63, 60] loss: 0.099\n",
      "[63, 120] loss: 0.103\n",
      "[63, 180] loss: 0.102\n",
      "[63, 240] loss: 0.110\n",
      "[63, 300] loss: 0.112\n",
      "[63, 360] loss: 0.126\n",
      "Epoch: 63 -> Loss: 0.0835044831038\n",
      "Epoch: 63 -> Test Accuracy: 87.53\n",
      "[64, 60] loss: 0.103\n",
      "[64, 120] loss: 0.099\n",
      "[64, 180] loss: 0.100\n",
      "[64, 240] loss: 0.109\n",
      "[64, 300] loss: 0.115\n",
      "[64, 360] loss: 0.111\n",
      "Epoch: 64 -> Loss: 0.125872656703\n",
      "Epoch: 64 -> Test Accuracy: 87.16\n",
      "[65, 60] loss: 0.098\n",
      "[65, 120] loss: 0.095\n",
      "[65, 180] loss: 0.109\n",
      "[65, 240] loss: 0.104\n",
      "[65, 300] loss: 0.112\n",
      "[65, 360] loss: 0.115\n",
      "Epoch: 65 -> Loss: 0.0657823607326\n",
      "Epoch: 65 -> Test Accuracy: 87.3\n",
      "[66, 60] loss: 0.097\n",
      "[66, 120] loss: 0.096\n",
      "[66, 180] loss: 0.110\n",
      "[66, 240] loss: 0.102\n",
      "[66, 300] loss: 0.117\n",
      "[66, 360] loss: 0.108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Loss: 0.245276257396\n",
      "Epoch: 66 -> Test Accuracy: 86.88\n",
      "[67, 60] loss: 0.105\n",
      "[67, 120] loss: 0.103\n",
      "[67, 180] loss: 0.112\n",
      "[67, 240] loss: 0.109\n",
      "[67, 300] loss: 0.105\n",
      "[67, 360] loss: 0.115\n",
      "Epoch: 67 -> Loss: 0.214009493589\n",
      "Epoch: 67 -> Test Accuracy: 86.66\n",
      "[68, 60] loss: 0.093\n",
      "[68, 120] loss: 0.088\n",
      "[68, 180] loss: 0.097\n",
      "[68, 240] loss: 0.115\n",
      "[68, 300] loss: 0.110\n",
      "[68, 360] loss: 0.108\n",
      "Epoch: 68 -> Loss: 0.0804050117731\n",
      "Epoch: 68 -> Test Accuracy: 86.73\n",
      "[69, 60] loss: 0.106\n",
      "[69, 120] loss: 0.107\n",
      "[69, 180] loss: 0.107\n",
      "[69, 240] loss: 0.117\n",
      "[69, 300] loss: 0.105\n",
      "[69, 360] loss: 0.111\n",
      "Epoch: 69 -> Loss: 0.0827852338552\n",
      "Epoch: 69 -> Test Accuracy: 87.3\n",
      "[70, 60] loss: 0.093\n",
      "[70, 120] loss: 0.106\n",
      "[70, 180] loss: 0.101\n",
      "[70, 240] loss: 0.099\n",
      "[70, 300] loss: 0.107\n",
      "[70, 360] loss: 0.113\n",
      "Epoch: 70 -> Loss: 0.159878671169\n",
      "Epoch: 70 -> Test Accuracy: 87.26\n",
      "[71, 60] loss: 0.084\n",
      "[71, 120] loss: 0.071\n",
      "[71, 180] loss: 0.067\n",
      "[71, 240] loss: 0.066\n",
      "[71, 300] loss: 0.066\n",
      "[71, 360] loss: 0.064\n",
      "Epoch: 71 -> Loss: 0.0656325370073\n",
      "Epoch: 71 -> Test Accuracy: 88.5\n",
      "[72, 60] loss: 0.054\n",
      "[72, 120] loss: 0.055\n",
      "[72, 180] loss: 0.056\n",
      "[72, 240] loss: 0.054\n",
      "[72, 300] loss: 0.057\n",
      "[72, 360] loss: 0.058\n",
      "Epoch: 72 -> Loss: 0.0656724125147\n",
      "Epoch: 72 -> Test Accuracy: 88.6\n",
      "[73, 60] loss: 0.048\n",
      "[73, 120] loss: 0.050\n",
      "[73, 180] loss: 0.052\n",
      "[73, 240] loss: 0.051\n",
      "[73, 300] loss: 0.048\n",
      "[73, 360] loss: 0.050\n",
      "Epoch: 73 -> Loss: 0.10300757736\n",
      "Epoch: 73 -> Test Accuracy: 88.6\n",
      "[74, 60] loss: 0.044\n",
      "[74, 120] loss: 0.045\n",
      "[74, 180] loss: 0.046\n",
      "[74, 240] loss: 0.049\n",
      "[74, 300] loss: 0.050\n",
      "[74, 360] loss: 0.045\n",
      "Epoch: 74 -> Loss: 0.0430081710219\n",
      "Epoch: 74 -> Test Accuracy: 88.46\n",
      "[75, 60] loss: 0.042\n",
      "[75, 120] loss: 0.041\n",
      "[75, 180] loss: 0.042\n",
      "[75, 240] loss: 0.045\n",
      "[75, 300] loss: 0.046\n",
      "[75, 360] loss: 0.044\n",
      "Epoch: 75 -> Loss: 0.0293522141874\n",
      "Epoch: 75 -> Test Accuracy: 88.53\n",
      "[76, 60] loss: 0.044\n",
      "[76, 120] loss: 0.039\n",
      "[76, 180] loss: 0.044\n",
      "[76, 240] loss: 0.042\n",
      "[76, 300] loss: 0.046\n",
      "[76, 360] loss: 0.043\n",
      "Epoch: 76 -> Loss: 0.0329231545329\n",
      "Epoch: 76 -> Test Accuracy: 88.64\n",
      "[77, 60] loss: 0.039\n",
      "[77, 120] loss: 0.041\n",
      "[77, 180] loss: 0.039\n",
      "[77, 240] loss: 0.037\n",
      "[77, 300] loss: 0.042\n",
      "[77, 360] loss: 0.042\n",
      "Epoch: 77 -> Loss: 0.0242421980947\n",
      "Epoch: 77 -> Test Accuracy: 88.53\n",
      "[78, 60] loss: 0.038\n",
      "[78, 120] loss: 0.038\n",
      "[78, 180] loss: 0.039\n",
      "[78, 240] loss: 0.040\n",
      "[78, 300] loss: 0.043\n",
      "[78, 360] loss: 0.040\n",
      "Epoch: 78 -> Loss: 0.0710976049304\n",
      "Epoch: 78 -> Test Accuracy: 88.68\n",
      "[79, 60] loss: 0.037\n",
      "[79, 120] loss: 0.036\n",
      "[79, 180] loss: 0.038\n",
      "[79, 240] loss: 0.039\n",
      "[79, 300] loss: 0.037\n",
      "[79, 360] loss: 0.039\n",
      "Epoch: 79 -> Loss: 0.0723778307438\n",
      "Epoch: 79 -> Test Accuracy: 88.55\n",
      "[80, 60] loss: 0.038\n",
      "[80, 120] loss: 0.035\n",
      "[80, 180] loss: 0.037\n",
      "[80, 240] loss: 0.038\n",
      "[80, 300] loss: 0.038\n",
      "[80, 360] loss: 0.037\n",
      "Epoch: 80 -> Loss: 0.0659976378083\n",
      "Epoch: 80 -> Test Accuracy: 88.55\n",
      "[81, 60] loss: 0.035\n",
      "[81, 120] loss: 0.037\n",
      "[81, 180] loss: 0.036\n",
      "[81, 240] loss: 0.036\n",
      "[81, 300] loss: 0.038\n",
      "[81, 360] loss: 0.035\n",
      "Epoch: 81 -> Loss: 0.0166778508574\n",
      "Epoch: 81 -> Test Accuracy: 88.54\n",
      "[82, 60] loss: 0.035\n",
      "[82, 120] loss: 0.035\n",
      "[82, 180] loss: 0.032\n",
      "[82, 240] loss: 0.035\n",
      "[82, 300] loss: 0.037\n",
      "[82, 360] loss: 0.037\n",
      "Epoch: 82 -> Loss: 0.0135609032586\n",
      "Epoch: 82 -> Test Accuracy: 88.59\n",
      "[83, 60] loss: 0.036\n",
      "[83, 120] loss: 0.033\n",
      "[83, 180] loss: 0.037\n",
      "[83, 240] loss: 0.036\n",
      "[83, 300] loss: 0.037\n",
      "[83, 360] loss: 0.037\n",
      "Epoch: 83 -> Loss: 0.0275029502809\n",
      "Epoch: 83 -> Test Accuracy: 88.59\n",
      "[84, 60] loss: 0.035\n",
      "[84, 120] loss: 0.035\n",
      "[84, 180] loss: 0.033\n",
      "[84, 240] loss: 0.032\n",
      "[84, 300] loss: 0.034\n",
      "[84, 360] loss: 0.034\n",
      "Epoch: 84 -> Loss: 0.0229504108429\n",
      "Epoch: 84 -> Test Accuracy: 88.52\n",
      "[85, 60] loss: 0.033\n",
      "[85, 120] loss: 0.033\n",
      "[85, 180] loss: 0.035\n",
      "[85, 240] loss: 0.034\n",
      "[85, 300] loss: 0.035\n",
      "[85, 360] loss: 0.034\n",
      "Epoch: 85 -> Loss: 0.0371476337314\n",
      "Epoch: 85 -> Test Accuracy: 88.4\n",
      "[86, 60] loss: 0.033\n",
      "[86, 120] loss: 0.031\n",
      "[86, 180] loss: 0.031\n",
      "[86, 240] loss: 0.031\n",
      "[86, 300] loss: 0.029\n",
      "[86, 360] loss: 0.031\n",
      "Epoch: 86 -> Loss: 0.0384119153023\n",
      "Epoch: 86 -> Test Accuracy: 88.6\n",
      "[87, 60] loss: 0.030\n",
      "[87, 120] loss: 0.029\n",
      "[87, 180] loss: 0.029\n",
      "[87, 240] loss: 0.032\n",
      "[87, 300] loss: 0.027\n",
      "[87, 360] loss: 0.029\n",
      "Epoch: 87 -> Loss: 0.0530640073121\n",
      "Epoch: 87 -> Test Accuracy: 88.74\n",
      "[88, 60] loss: 0.029\n",
      "[88, 120] loss: 0.028\n",
      "[88, 180] loss: 0.030\n",
      "[88, 240] loss: 0.030\n",
      "[88, 300] loss: 0.028\n",
      "[88, 360] loss: 0.028\n",
      "Epoch: 88 -> Loss: 0.065884873271\n",
      "Epoch: 88 -> Test Accuracy: 88.63\n",
      "[89, 60] loss: 0.028\n",
      "[89, 120] loss: 0.029\n",
      "[89, 180] loss: 0.026\n",
      "[89, 240] loss: 0.028\n",
      "[89, 300] loss: 0.028\n",
      "[89, 360] loss: 0.030\n",
      "Epoch: 89 -> Loss: 0.0323155634105\n",
      "Epoch: 89 -> Test Accuracy: 88.75\n",
      "[90, 60] loss: 0.029\n",
      "[90, 120] loss: 0.029\n",
      "[90, 180] loss: 0.030\n",
      "[90, 240] loss: 0.026\n",
      "[90, 300] loss: 0.028\n",
      "[90, 360] loss: 0.027\n",
      "Epoch: 90 -> Loss: 0.0235948376358\n",
      "Epoch: 90 -> Test Accuracy: 88.67\n",
      "[91, 60] loss: 0.029\n",
      "[91, 120] loss: 0.030\n",
      "[91, 180] loss: 0.028\n",
      "[91, 240] loss: 0.026\n",
      "[91, 300] loss: 0.029\n",
      "[91, 360] loss: 0.027\n",
      "Epoch: 91 -> Loss: 0.0261907223612\n",
      "Epoch: 91 -> Test Accuracy: 88.69\n",
      "[92, 60] loss: 0.027\n",
      "[92, 120] loss: 0.030\n",
      "[92, 180] loss: 0.026\n",
      "[92, 240] loss: 0.028\n",
      "[92, 300] loss: 0.025\n",
      "[92, 360] loss: 0.028\n",
      "Epoch: 92 -> Loss: 0.0601335950196\n",
      "Epoch: 92 -> Test Accuracy: 88.58\n",
      "[93, 60] loss: 0.028\n",
      "[93, 120] loss: 0.026\n",
      "[93, 180] loss: 0.029\n",
      "[93, 240] loss: 0.026\n",
      "[93, 300] loss: 0.030\n",
      "[93, 360] loss: 0.029\n",
      "Epoch: 93 -> Loss: 0.015637839213\n",
      "Epoch: 93 -> Test Accuracy: 88.63\n",
      "[94, 60] loss: 0.029\n",
      "[94, 120] loss: 0.025\n",
      "[94, 180] loss: 0.025\n",
      "[94, 240] loss: 0.026\n",
      "[94, 300] loss: 0.029\n",
      "[94, 360] loss: 0.027\n",
      "Epoch: 94 -> Loss: 0.024247456342\n",
      "Epoch: 94 -> Test Accuracy: 88.73\n",
      "[95, 60] loss: 0.027\n",
      "[95, 120] loss: 0.028\n",
      "[95, 180] loss: 0.028\n",
      "[95, 240] loss: 0.027\n",
      "[95, 300] loss: 0.027\n",
      "[95, 360] loss: 0.027\n",
      "Epoch: 95 -> Loss: 0.0255880765617\n",
      "Epoch: 95 -> Test Accuracy: 88.69\n",
      "[96, 60] loss: 0.025\n",
      "[96, 120] loss: 0.024\n",
      "[96, 180] loss: 0.029\n",
      "[96, 240] loss: 0.029\n",
      "[96, 300] loss: 0.027\n",
      "[96, 360] loss: 0.030\n",
      "Epoch: 96 -> Loss: 0.0410464145243\n",
      "Epoch: 96 -> Test Accuracy: 88.67\n",
      "[97, 60] loss: 0.028\n",
      "[97, 120] loss: 0.027\n",
      "[97, 180] loss: 0.026\n",
      "[97, 240] loss: 0.026\n",
      "[97, 300] loss: 0.026\n",
      "[97, 360] loss: 0.027\n",
      "Epoch: 97 -> Loss: 0.0359158888459\n",
      "Epoch: 97 -> Test Accuracy: 88.56\n",
      "[98, 60] loss: 0.029\n",
      "[98, 120] loss: 0.028\n",
      "[98, 180] loss: 0.026\n",
      "[98, 240] loss: 0.026\n",
      "[98, 300] loss: 0.028\n",
      "[98, 360] loss: 0.029\n",
      "Epoch: 98 -> Loss: 0.0157739371061\n",
      "Epoch: 98 -> Test Accuracy: 88.58\n",
      "[99, 60] loss: 0.025\n",
      "[99, 120] loss: 0.027\n",
      "[99, 180] loss: 0.026\n",
      "[99, 240] loss: 0.025\n",
      "[99, 300] loss: 0.027\n",
      "[99, 360] loss: 0.025\n",
      "Epoch: 99 -> Loss: 0.0315552130342\n",
      "Epoch: 99 -> Test Accuracy: 88.68\n",
      "[100, 60] loss: 0.026\n",
      "[100, 120] loss: 0.026\n",
      "[100, 180] loss: 0.027\n",
      "[100, 240] loss: 0.026\n",
      "[100, 300] loss: 0.028\n",
      "[100, 360] loss: 0.026\n",
      "Epoch: 100 -> Loss: 0.0305181443691\n",
      "Epoch: 100 -> Test Accuracy: 88.71\n",
      "Finished Training\n",
      "[1, 60] loss: 1.891\n",
      "[1, 120] loss: 1.676\n",
      "[1, 180] loss: 1.590\n",
      "[1, 240] loss: 1.557\n",
      "[1, 300] loss: 1.511\n",
      "[1, 360] loss: 1.478\n",
      "Epoch: 1 -> Loss: 1.34067082405\n",
      "Epoch: 1 -> Test Accuracy: 42.56\n",
      "[2, 60] loss: 1.466\n",
      "[2, 120] loss: 1.451\n",
      "[2, 180] loss: 1.417\n",
      "[2, 240] loss: 1.434\n",
      "[2, 300] loss: 1.409\n",
      "[2, 360] loss: 1.392\n",
      "Epoch: 2 -> Loss: 1.33017230034\n",
      "Epoch: 2 -> Test Accuracy: 42.58\n",
      "[3, 60] loss: 1.393\n",
      "[3, 120] loss: 1.395\n",
      "[3, 180] loss: 1.385\n",
      "[3, 240] loss: 1.367\n",
      "[3, 300] loss: 1.369\n",
      "[3, 360] loss: 1.363\n",
      "Epoch: 3 -> Loss: 1.29421293736\n",
      "Epoch: 3 -> Test Accuracy: 45.78\n",
      "[4, 60] loss: 1.353\n",
      "[4, 120] loss: 1.356\n",
      "[4, 180] loss: 1.339\n",
      "[4, 240] loss: 1.325\n",
      "[4, 300] loss: 1.327\n",
      "[4, 360] loss: 1.351\n",
      "Epoch: 4 -> Loss: 1.39948320389\n",
      "Epoch: 4 -> Test Accuracy: 45.75\n",
      "[5, 60] loss: 1.310\n",
      "[5, 120] loss: 1.313\n",
      "[5, 180] loss: 1.307\n",
      "[5, 240] loss: 1.318\n",
      "[5, 300] loss: 1.314\n",
      "[5, 360] loss: 1.332\n",
      "Epoch: 5 -> Loss: 1.51405858994\n",
      "Epoch: 5 -> Test Accuracy: 48.36\n",
      "[6, 60] loss: 1.305\n",
      "[6, 120] loss: 1.307\n",
      "[6, 180] loss: 1.317\n",
      "[6, 240] loss: 1.290\n",
      "[6, 300] loss: 1.305\n",
      "[6, 360] loss: 1.293\n",
      "Epoch: 6 -> Loss: 1.41194176674\n",
      "Epoch: 6 -> Test Accuracy: 49.06\n",
      "[7, 60] loss: 1.285\n",
      "[7, 120] loss: 1.301\n",
      "[7, 180] loss: 1.302\n",
      "[7, 240] loss: 1.298\n",
      "[7, 300] loss: 1.289\n",
      "[7, 360] loss: 1.277\n",
      "Epoch: 7 -> Loss: 1.42627286911\n",
      "Epoch: 7 -> Test Accuracy: 48.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 60] loss: 1.283\n",
      "[8, 120] loss: 1.277\n",
      "[8, 180] loss: 1.286\n",
      "[8, 240] loss: 1.311\n",
      "[8, 300] loss: 1.265\n",
      "[8, 360] loss: 1.293\n",
      "Epoch: 8 -> Loss: 1.29113197327\n",
      "Epoch: 8 -> Test Accuracy: 49.39\n",
      "[9, 60] loss: 1.301\n",
      "[9, 120] loss: 1.279\n",
      "[9, 180] loss: 1.260\n",
      "[9, 240] loss: 1.284\n",
      "[9, 300] loss: 1.272\n",
      "[9, 360] loss: 1.277\n",
      "Epoch: 9 -> Loss: 1.35623145103\n",
      "Epoch: 9 -> Test Accuracy: 48.4\n",
      "[10, 60] loss: 1.275\n",
      "[10, 120] loss: 1.255\n",
      "[10, 180] loss: 1.262\n",
      "[10, 240] loss: 1.274\n",
      "[10, 300] loss: 1.249\n",
      "[10, 360] loss: 1.266\n",
      "Epoch: 10 -> Loss: 1.29763555527\n",
      "Epoch: 10 -> Test Accuracy: 50.93\n",
      "[11, 60] loss: 1.277\n",
      "[11, 120] loss: 1.257\n",
      "[11, 180] loss: 1.260\n",
      "[11, 240] loss: 1.255\n",
      "[11, 300] loss: 1.266\n",
      "[11, 360] loss: 1.283\n",
      "Epoch: 11 -> Loss: 1.51121926308\n",
      "Epoch: 11 -> Test Accuracy: 48.44\n",
      "[12, 60] loss: 1.255\n",
      "[12, 120] loss: 1.246\n",
      "[12, 180] loss: 1.252\n",
      "[12, 240] loss: 1.257\n",
      "[12, 300] loss: 1.259\n",
      "[12, 360] loss: 1.254\n",
      "Epoch: 12 -> Loss: 1.26686346531\n",
      "Epoch: 12 -> Test Accuracy: 49.95\n",
      "[13, 60] loss: 1.265\n",
      "[13, 120] loss: 1.254\n",
      "[13, 180] loss: 1.262\n",
      "[13, 240] loss: 1.253\n",
      "[13, 300] loss: 1.238\n",
      "[13, 360] loss: 1.262\n",
      "Epoch: 13 -> Loss: 1.33817899227\n",
      "Epoch: 13 -> Test Accuracy: 50.78\n",
      "[14, 60] loss: 1.248\n",
      "[14, 120] loss: 1.254\n",
      "[14, 180] loss: 1.255\n",
      "[14, 240] loss: 1.263\n",
      "[14, 300] loss: 1.242\n",
      "[14, 360] loss: 1.250\n",
      "Epoch: 14 -> Loss: 1.27904808521\n",
      "Epoch: 14 -> Test Accuracy: 49.48\n",
      "[15, 60] loss: 1.229\n",
      "[15, 120] loss: 1.233\n",
      "[15, 180] loss: 1.283\n",
      "[15, 240] loss: 1.252\n",
      "[15, 300] loss: 1.240\n",
      "[15, 360] loss: 1.249\n",
      "Epoch: 15 -> Loss: 1.42069268227\n",
      "Epoch: 15 -> Test Accuracy: 50.18\n",
      "[16, 60] loss: 1.247\n",
      "[16, 120] loss: 1.271\n",
      "[16, 180] loss: 1.236\n",
      "[16, 240] loss: 1.246\n",
      "[16, 300] loss: 1.249\n",
      "[16, 360] loss: 1.217\n",
      "Epoch: 16 -> Loss: 1.24900591373\n",
      "Epoch: 16 -> Test Accuracy: 48.59\n",
      "[17, 60] loss: 1.250\n",
      "[17, 120] loss: 1.254\n",
      "[17, 180] loss: 1.240\n",
      "[17, 240] loss: 1.246\n",
      "[17, 300] loss: 1.228\n",
      "[17, 360] loss: 1.246\n",
      "Epoch: 17 -> Loss: 1.34005475044\n",
      "Epoch: 17 -> Test Accuracy: 50.89\n",
      "[18, 60] loss: 1.235\n",
      "[18, 120] loss: 1.239\n",
      "[18, 180] loss: 1.222\n",
      "[18, 240] loss: 1.240\n",
      "[18, 300] loss: 1.239\n",
      "[18, 360] loss: 1.246\n",
      "Epoch: 18 -> Loss: 1.08878648281\n",
      "Epoch: 18 -> Test Accuracy: 50.42\n",
      "[19, 60] loss: 1.250\n",
      "[19, 120] loss: 1.218\n",
      "[19, 180] loss: 1.246\n",
      "[19, 240] loss: 1.245\n",
      "[19, 300] loss: 1.215\n",
      "[19, 360] loss: 1.220\n",
      "Epoch: 19 -> Loss: 1.19916927814\n",
      "Epoch: 19 -> Test Accuracy: 49.91\n",
      "[20, 60] loss: 1.220\n",
      "[20, 120] loss: 1.241\n",
      "[20, 180] loss: 1.211\n",
      "[20, 240] loss: 1.237\n",
      "[20, 300] loss: 1.228\n",
      "[20, 360] loss: 1.246\n",
      "Epoch: 20 -> Loss: 1.26215720177\n",
      "Epoch: 20 -> Test Accuracy: 50.39\n",
      "[21, 60] loss: 1.247\n",
      "[21, 120] loss: 1.239\n",
      "[21, 180] loss: 1.246\n",
      "[21, 240] loss: 1.222\n",
      "[21, 300] loss: 1.241\n",
      "[21, 360] loss: 1.206\n",
      "Epoch: 21 -> Loss: 1.21091198921\n",
      "Epoch: 21 -> Test Accuracy: 49.74\n",
      "[22, 60] loss: 1.250\n",
      "[22, 120] loss: 1.226\n",
      "[22, 180] loss: 1.238\n",
      "[22, 240] loss: 1.230\n",
      "[22, 300] loss: 1.223\n",
      "[22, 360] loss: 1.250\n",
      "Epoch: 22 -> Loss: 1.18547594547\n",
      "Epoch: 22 -> Test Accuracy: 50.93\n",
      "[23, 60] loss: 1.227\n",
      "[23, 120] loss: 1.233\n",
      "[23, 180] loss: 1.224\n",
      "[23, 240] loss: 1.225\n",
      "[23, 300] loss: 1.220\n",
      "[23, 360] loss: 1.251\n",
      "Epoch: 23 -> Loss: 1.48962557316\n",
      "Epoch: 23 -> Test Accuracy: 51.87\n",
      "[24, 60] loss: 1.248\n",
      "[24, 120] loss: 1.220\n",
      "[24, 180] loss: 1.236\n",
      "[24, 240] loss: 1.205\n",
      "[24, 300] loss: 1.222\n",
      "[24, 360] loss: 1.227\n",
      "Epoch: 24 -> Loss: 1.18852305412\n",
      "Epoch: 24 -> Test Accuracy: 49.75\n",
      "[25, 60] loss: 1.216\n",
      "[25, 120] loss: 1.222\n",
      "[25, 180] loss: 1.215\n",
      "[25, 240] loss: 1.244\n",
      "[25, 300] loss: 1.231\n",
      "[25, 360] loss: 1.231\n",
      "Epoch: 25 -> Loss: 1.41260457039\n",
      "Epoch: 25 -> Test Accuracy: 50.43\n",
      "[26, 60] loss: 1.223\n",
      "[26, 120] loss: 1.228\n",
      "[26, 180] loss: 1.232\n",
      "[26, 240] loss: 1.230\n",
      "[26, 300] loss: 1.216\n",
      "[26, 360] loss: 1.223\n",
      "Epoch: 26 -> Loss: 1.30759644508\n",
      "Epoch: 26 -> Test Accuracy: 50.93\n",
      "[27, 60] loss: 1.220\n",
      "[27, 120] loss: 1.223\n",
      "[27, 180] loss: 1.214\n",
      "[27, 240] loss: 1.229\n",
      "[27, 300] loss: 1.242\n",
      "[27, 360] loss: 1.230\n",
      "Epoch: 27 -> Loss: 1.17010343075\n",
      "Epoch: 27 -> Test Accuracy: 51.54\n",
      "[28, 60] loss: 1.223\n",
      "[28, 120] loss: 1.217\n",
      "[28, 180] loss: 1.237\n",
      "[28, 240] loss: 1.229\n",
      "[28, 300] loss: 1.225\n",
      "[28, 360] loss: 1.221\n",
      "Epoch: 28 -> Loss: 1.12656950951\n",
      "Epoch: 28 -> Test Accuracy: 49.82\n",
      "[29, 60] loss: 1.228\n",
      "[29, 120] loss: 1.222\n",
      "[29, 180] loss: 1.219\n",
      "[29, 240] loss: 1.210\n",
      "[29, 300] loss: 1.249\n",
      "[29, 360] loss: 1.207\n",
      "Epoch: 29 -> Loss: 1.10987365246\n",
      "Epoch: 29 -> Test Accuracy: 51.22\n",
      "[30, 60] loss: 1.230\n",
      "[30, 120] loss: 1.230\n",
      "[30, 180] loss: 1.226\n",
      "[30, 240] loss: 1.188\n",
      "[30, 300] loss: 1.243\n",
      "[30, 360] loss: 1.218\n",
      "Epoch: 30 -> Loss: 1.24452233315\n",
      "Epoch: 30 -> Test Accuracy: 51.25\n",
      "[31, 60] loss: 1.216\n",
      "[31, 120] loss: 1.211\n",
      "[31, 180] loss: 1.228\n",
      "[31, 240] loss: 1.205\n",
      "[31, 300] loss: 1.239\n",
      "[31, 360] loss: 1.224\n",
      "Epoch: 31 -> Loss: 1.19059300423\n",
      "Epoch: 31 -> Test Accuracy: 51.02\n",
      "[32, 60] loss: 1.225\n",
      "[32, 120] loss: 1.220\n",
      "[32, 180] loss: 1.196\n",
      "[32, 240] loss: 1.220\n",
      "[32, 300] loss: 1.227\n",
      "[32, 360] loss: 1.222\n",
      "Epoch: 32 -> Loss: 1.26153230667\n",
      "Epoch: 32 -> Test Accuracy: 52.16\n",
      "[33, 60] loss: 1.239\n",
      "[33, 120] loss: 1.213\n",
      "[33, 180] loss: 1.221\n",
      "[33, 240] loss: 1.224\n",
      "[33, 300] loss: 1.221\n",
      "[33, 360] loss: 1.225\n",
      "Epoch: 33 -> Loss: 1.26838386059\n",
      "Epoch: 33 -> Test Accuracy: 51.12\n",
      "[34, 60] loss: 1.222\n",
      "[34, 120] loss: 1.243\n",
      "[34, 180] loss: 1.224\n",
      "[34, 240] loss: 1.239\n",
      "[34, 300] loss: 1.217\n",
      "[34, 360] loss: 1.191\n",
      "Epoch: 34 -> Loss: 1.1343473196\n",
      "Epoch: 34 -> Test Accuracy: 51.89\n",
      "[35, 60] loss: 1.241\n",
      "[35, 120] loss: 1.227\n",
      "[35, 180] loss: 1.221\n",
      "[35, 240] loss: 1.217\n",
      "[35, 300] loss: 1.233\n",
      "[35, 360] loss: 1.203\n",
      "Epoch: 35 -> Loss: 1.22861588001\n",
      "Epoch: 35 -> Test Accuracy: 50.11\n",
      "[36, 60] loss: 1.135\n",
      "[36, 120] loss: 1.112\n",
      "[36, 180] loss: 1.104\n",
      "[36, 240] loss: 1.086\n",
      "[36, 300] loss: 1.105\n",
      "[36, 360] loss: 1.104\n",
      "Epoch: 36 -> Loss: 1.16480576992\n",
      "Epoch: 36 -> Test Accuracy: 56.16\n",
      "[37, 60] loss: 1.097\n",
      "[37, 120] loss: 1.069\n",
      "[37, 180] loss: 1.089\n",
      "[37, 240] loss: 1.059\n",
      "[37, 300] loss: 1.071\n",
      "[37, 360] loss: 1.087\n",
      "Epoch: 37 -> Loss: 1.05177390575\n",
      "Epoch: 37 -> Test Accuracy: 56.16\n",
      "[38, 60] loss: 1.066\n",
      "[38, 120] loss: 1.039\n",
      "[38, 180] loss: 1.066\n",
      "[38, 240] loss: 1.082\n",
      "[38, 300] loss: 1.096\n",
      "[38, 360] loss: 1.078\n",
      "Epoch: 38 -> Loss: 1.00243461132\n",
      "Epoch: 38 -> Test Accuracy: 56.12\n",
      "[39, 60] loss: 1.062\n",
      "[39, 120] loss: 1.083\n",
      "[39, 180] loss: 1.065\n",
      "[39, 240] loss: 1.061\n",
      "[39, 300] loss: 1.062\n",
      "[39, 360] loss: 1.088\n",
      "Epoch: 39 -> Loss: 1.17989909649\n",
      "Epoch: 39 -> Test Accuracy: 56.88\n",
      "[40, 60] loss: 1.076\n",
      "[40, 120] loss: 1.058\n",
      "[40, 180] loss: 1.065\n",
      "[40, 240] loss: 1.059\n",
      "[40, 300] loss: 1.073\n",
      "[40, 360] loss: 1.069\n",
      "Epoch: 40 -> Loss: 0.964320003986\n",
      "Epoch: 40 -> Test Accuracy: 55.88\n",
      "[41, 60] loss: 1.064\n",
      "[41, 120] loss: 1.057\n",
      "[41, 180] loss: 1.069\n",
      "[41, 240] loss: 1.062\n",
      "[41, 300] loss: 1.060\n",
      "[41, 360] loss: 1.074\n",
      "Epoch: 41 -> Loss: 0.975991070271\n",
      "Epoch: 41 -> Test Accuracy: 55.9\n",
      "[42, 60] loss: 1.063\n",
      "[42, 120] loss: 1.057\n",
      "[42, 180] loss: 1.063\n",
      "[42, 240] loss: 1.059\n",
      "[42, 300] loss: 1.072\n",
      "[42, 360] loss: 1.073\n",
      "Epoch: 42 -> Loss: 1.04248964787\n",
      "Epoch: 42 -> Test Accuracy: 57.03\n",
      "[43, 60] loss: 1.063\n",
      "[43, 120] loss: 1.079\n",
      "[43, 180] loss: 1.048\n",
      "[43, 240] loss: 1.025\n",
      "[43, 300] loss: 1.080\n",
      "[43, 360] loss: 1.073\n",
      "Epoch: 43 -> Loss: 1.26203584671\n",
      "Epoch: 43 -> Test Accuracy: 56.39\n",
      "[44, 60] loss: 1.059\n",
      "[44, 120] loss: 1.061\n",
      "[44, 180] loss: 1.054\n",
      "[44, 240] loss: 1.074\n",
      "[44, 300] loss: 1.092\n",
      "[44, 360] loss: 1.069\n",
      "Epoch: 44 -> Loss: 1.04751336575\n",
      "Epoch: 44 -> Test Accuracy: 56.38\n",
      "[45, 60] loss: 1.061\n",
      "[45, 120] loss: 1.066\n",
      "[45, 180] loss: 1.055\n",
      "[45, 240] loss: 1.065\n",
      "[45, 300] loss: 1.055\n",
      "[45, 360] loss: 1.061\n",
      "Epoch: 45 -> Loss: 1.0019119978\n",
      "Epoch: 45 -> Test Accuracy: 56.04\n",
      "[46, 60] loss: 1.048\n",
      "[46, 120] loss: 1.059\n",
      "[46, 180] loss: 1.068\n",
      "[46, 240] loss: 1.074\n",
      "[46, 300] loss: 1.057\n",
      "[46, 360] loss: 1.061\n",
      "Epoch: 46 -> Loss: 1.0409668684\n",
      "Epoch: 46 -> Test Accuracy: 55.9\n",
      "[47, 60] loss: 1.048\n",
      "[47, 120] loss: 1.044\n",
      "[47, 180] loss: 1.064\n",
      "[47, 240] loss: 1.057\n",
      "[47, 300] loss: 1.058\n",
      "[47, 360] loss: 1.064\n",
      "Epoch: 47 -> Loss: 1.06989943981\n",
      "Epoch: 47 -> Test Accuracy: 55.75\n",
      "[48, 60] loss: 1.055\n",
      "[48, 120] loss: 1.060\n",
      "[48, 180] loss: 1.054\n",
      "[48, 240] loss: 1.059\n",
      "[48, 300] loss: 1.062\n",
      "[48, 360] loss: 1.060\n",
      "Epoch: 48 -> Loss: 1.22302591801\n",
      "Epoch: 48 -> Test Accuracy: 55.66\n",
      "[49, 60] loss: 1.062\n",
      "[49, 120] loss: 1.052\n",
      "[49, 180] loss: 1.049\n",
      "[49, 240] loss: 1.055\n",
      "[49, 300] loss: 1.072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 360] loss: 1.058\n",
      "Epoch: 49 -> Loss: 1.04007863998\n",
      "Epoch: 49 -> Test Accuracy: 56.56\n",
      "[50, 60] loss: 1.042\n",
      "[50, 120] loss: 1.072\n",
      "[50, 180] loss: 1.046\n",
      "[50, 240] loss: 1.046\n",
      "[50, 300] loss: 1.089\n",
      "[50, 360] loss: 1.053\n",
      "Epoch: 50 -> Loss: 1.31148076057\n",
      "Epoch: 50 -> Test Accuracy: 55.81\n",
      "[51, 60] loss: 1.082\n",
      "[51, 120] loss: 1.051\n",
      "[51, 180] loss: 1.063\n",
      "[51, 240] loss: 1.061\n",
      "[51, 300] loss: 1.053\n",
      "[51, 360] loss: 1.060\n",
      "Epoch: 51 -> Loss: 0.992772936821\n",
      "Epoch: 51 -> Test Accuracy: 56.11\n",
      "[52, 60] loss: 1.054\n",
      "[52, 120] loss: 1.049\n",
      "[52, 180] loss: 1.075\n",
      "[52, 240] loss: 1.040\n",
      "[52, 300] loss: 1.067\n",
      "[52, 360] loss: 1.057\n",
      "Epoch: 52 -> Loss: 1.18972527981\n",
      "Epoch: 52 -> Test Accuracy: 55.19\n",
      "[53, 60] loss: 1.036\n",
      "[53, 120] loss: 1.058\n",
      "[53, 180] loss: 1.054\n",
      "[53, 240] loss: 1.089\n",
      "[53, 300] loss: 1.045\n",
      "[53, 360] loss: 1.063\n",
      "Epoch: 53 -> Loss: 1.13427042961\n",
      "Epoch: 53 -> Test Accuracy: 55.42\n",
      "[54, 60] loss: 1.041\n",
      "[54, 120] loss: 1.060\n",
      "[54, 180] loss: 1.057\n",
      "[54, 240] loss: 1.060\n",
      "[54, 300] loss: 1.061\n",
      "[54, 360] loss: 1.081\n",
      "Epoch: 54 -> Loss: 1.00517892838\n",
      "Epoch: 54 -> Test Accuracy: 55.95\n",
      "[55, 60] loss: 1.060\n",
      "[55, 120] loss: 1.051\n",
      "[55, 180] loss: 1.063\n",
      "[55, 240] loss: 1.067\n",
      "[55, 300] loss: 1.069\n",
      "[55, 360] loss: 1.052\n",
      "Epoch: 55 -> Loss: 1.03402662277\n",
      "Epoch: 55 -> Test Accuracy: 56.38\n",
      "[56, 60] loss: 1.047\n",
      "[56, 120] loss: 1.052\n",
      "[56, 180] loss: 1.050\n",
      "[56, 240] loss: 1.036\n",
      "[56, 300] loss: 1.062\n",
      "[56, 360] loss: 1.066\n",
      "Epoch: 56 -> Loss: 1.0565328598\n",
      "Epoch: 56 -> Test Accuracy: 56.78\n",
      "[57, 60] loss: 1.032\n",
      "[57, 120] loss: 1.044\n",
      "[57, 180] loss: 1.049\n",
      "[57, 240] loss: 1.055\n",
      "[57, 300] loss: 1.059\n",
      "[57, 360] loss: 1.057\n",
      "Epoch: 57 -> Loss: 0.980120837688\n",
      "Epoch: 57 -> Test Accuracy: 56.31\n",
      "[58, 60] loss: 1.063\n",
      "[58, 120] loss: 1.039\n",
      "[58, 180] loss: 1.046\n",
      "[58, 240] loss: 1.084\n",
      "[58, 300] loss: 1.034\n",
      "[58, 360] loss: 1.074\n",
      "Epoch: 58 -> Loss: 1.11403274536\n",
      "Epoch: 58 -> Test Accuracy: 56.66\n",
      "[59, 60] loss: 1.058\n",
      "[59, 120] loss: 1.069\n",
      "[59, 180] loss: 1.055\n",
      "[59, 240] loss: 1.032\n",
      "[59, 300] loss: 1.041\n",
      "[59, 360] loss: 1.064\n",
      "Epoch: 59 -> Loss: 1.10258376598\n",
      "Epoch: 59 -> Test Accuracy: 56.59\n",
      "[60, 60] loss: 1.059\n",
      "[60, 120] loss: 1.053\n",
      "[60, 180] loss: 1.052\n",
      "[60, 240] loss: 1.047\n",
      "[60, 300] loss: 1.051\n",
      "[60, 360] loss: 1.049\n",
      "Epoch: 60 -> Loss: 1.16968166828\n",
      "Epoch: 60 -> Test Accuracy: 55.99\n",
      "[61, 60] loss: 1.043\n",
      "[61, 120] loss: 1.048\n",
      "[61, 180] loss: 1.037\n",
      "[61, 240] loss: 1.065\n",
      "[61, 300] loss: 1.055\n",
      "[61, 360] loss: 1.049\n",
      "Epoch: 61 -> Loss: 0.912785828114\n",
      "Epoch: 61 -> Test Accuracy: 56.25\n",
      "[62, 60] loss: 1.045\n",
      "[62, 120] loss: 1.037\n",
      "[62, 180] loss: 1.064\n",
      "[62, 240] loss: 1.049\n",
      "[62, 300] loss: 1.049\n",
      "[62, 360] loss: 1.074\n",
      "Epoch: 62 -> Loss: 1.21334862709\n",
      "Epoch: 62 -> Test Accuracy: 56.28\n",
      "[63, 60] loss: 1.047\n",
      "[63, 120] loss: 1.041\n",
      "[63, 180] loss: 1.051\n",
      "[63, 240] loss: 1.062\n",
      "[63, 300] loss: 1.040\n",
      "[63, 360] loss: 1.047\n",
      "Epoch: 63 -> Loss: 1.14445590973\n",
      "Epoch: 63 -> Test Accuracy: 55.89\n",
      "[64, 60] loss: 1.028\n",
      "[64, 120] loss: 1.061\n",
      "[64, 180] loss: 1.064\n",
      "[64, 240] loss: 1.059\n",
      "[64, 300] loss: 1.057\n",
      "[64, 360] loss: 1.039\n",
      "Epoch: 64 -> Loss: 1.04257392883\n",
      "Epoch: 64 -> Test Accuracy: 56.35\n",
      "[65, 60] loss: 1.050\n",
      "[65, 120] loss: 1.063\n",
      "[65, 180] loss: 1.029\n",
      "[65, 240] loss: 1.062\n",
      "[65, 300] loss: 1.055\n",
      "[65, 360] loss: 1.044\n",
      "Epoch: 65 -> Loss: 1.14292597771\n",
      "Epoch: 65 -> Test Accuracy: 56.29\n",
      "[66, 60] loss: 1.051\n",
      "[66, 120] loss: 1.042\n",
      "[66, 180] loss: 1.058\n",
      "[66, 240] loss: 1.049\n",
      "[66, 300] loss: 1.056\n",
      "[66, 360] loss: 1.039\n",
      "Epoch: 66 -> Loss: 0.976394832134\n",
      "Epoch: 66 -> Test Accuracy: 55.93\n",
      "[67, 60] loss: 1.031\n",
      "[67, 120] loss: 1.062\n",
      "[67, 180] loss: 1.051\n",
      "[67, 240] loss: 1.045\n",
      "[67, 300] loss: 1.054\n",
      "[67, 360] loss: 1.059\n",
      "Epoch: 67 -> Loss: 1.02292823792\n",
      "Epoch: 67 -> Test Accuracy: 55.78\n",
      "[68, 60] loss: 1.058\n",
      "[68, 120] loss: 1.026\n",
      "[68, 180] loss: 1.053\n",
      "[68, 240] loss: 1.057\n",
      "[68, 300] loss: 1.040\n",
      "[68, 360] loss: 1.044\n",
      "Epoch: 68 -> Loss: 1.03027248383\n",
      "Epoch: 68 -> Test Accuracy: 57.18\n",
      "[69, 60] loss: 1.049\n",
      "[69, 120] loss: 1.058\n",
      "[69, 180] loss: 1.042\n",
      "[69, 240] loss: 1.038\n",
      "[69, 300] loss: 1.021\n",
      "[69, 360] loss: 1.060\n",
      "Epoch: 69 -> Loss: 0.994867622852\n",
      "Epoch: 69 -> Test Accuracy: 56.92\n",
      "[70, 60] loss: 1.042\n",
      "[70, 120] loss: 1.044\n",
      "[70, 180] loss: 1.054\n",
      "[70, 240] loss: 1.058\n",
      "[70, 300] loss: 1.035\n",
      "[70, 360] loss: 1.047\n",
      "Epoch: 70 -> Loss: 1.05578589439\n",
      "Epoch: 70 -> Test Accuracy: 57.13\n",
      "[71, 60] loss: 0.973\n",
      "[71, 120] loss: 0.982\n",
      "[71, 180] loss: 0.979\n",
      "[71, 240] loss: 0.951\n",
      "[71, 300] loss: 0.964\n",
      "[71, 360] loss: 0.954\n",
      "Epoch: 71 -> Loss: 1.24139368534\n",
      "Epoch: 71 -> Test Accuracy: 59.98\n",
      "[72, 60] loss: 0.950\n",
      "[72, 120] loss: 0.942\n",
      "[72, 180] loss: 0.972\n",
      "[72, 240] loss: 0.948\n",
      "[72, 300] loss: 0.932\n",
      "[72, 360] loss: 0.942\n",
      "Epoch: 72 -> Loss: 0.834207892418\n",
      "Epoch: 72 -> Test Accuracy: 60.43\n",
      "[73, 60] loss: 0.965\n",
      "[73, 120] loss: 0.931\n",
      "[73, 180] loss: 0.942\n",
      "[73, 240] loss: 0.949\n",
      "[73, 300] loss: 0.941\n",
      "[73, 360] loss: 0.929\n",
      "Epoch: 73 -> Loss: 1.26830649376\n",
      "Epoch: 73 -> Test Accuracy: 60.42\n",
      "[74, 60] loss: 0.928\n",
      "[74, 120] loss: 0.950\n",
      "[74, 180] loss: 0.946\n",
      "[74, 240] loss: 0.936\n",
      "[74, 300] loss: 0.944\n",
      "[74, 360] loss: 0.910\n",
      "Epoch: 74 -> Loss: 0.75281894207\n",
      "Epoch: 74 -> Test Accuracy: 59.99\n",
      "[75, 60] loss: 0.933\n",
      "[75, 120] loss: 0.940\n",
      "[75, 180] loss: 0.925\n",
      "[75, 240] loss: 0.924\n",
      "[75, 300] loss: 0.961\n",
      "[75, 360] loss: 0.939\n",
      "Epoch: 75 -> Loss: 0.799407124519\n",
      "Epoch: 75 -> Test Accuracy: 60.19\n",
      "[76, 60] loss: 0.918\n",
      "[76, 120] loss: 0.938\n",
      "[76, 180] loss: 0.932\n",
      "[76, 240] loss: 0.944\n",
      "[76, 300] loss: 0.935\n",
      "[76, 360] loss: 0.923\n",
      "Epoch: 76 -> Loss: 1.16572880745\n",
      "Epoch: 76 -> Test Accuracy: 60.5\n",
      "[77, 60] loss: 0.911\n",
      "[77, 120] loss: 0.921\n",
      "[77, 180] loss: 0.919\n",
      "[77, 240] loss: 0.950\n",
      "[77, 300] loss: 0.933\n",
      "[77, 360] loss: 0.943\n",
      "Epoch: 77 -> Loss: 0.838848412037\n",
      "Epoch: 77 -> Test Accuracy: 60.58\n",
      "[78, 60] loss: 0.914\n",
      "[78, 120] loss: 0.924\n",
      "[78, 180] loss: 0.939\n",
      "[78, 240] loss: 0.925\n",
      "[78, 300] loss: 0.945\n",
      "[78, 360] loss: 0.926\n",
      "Epoch: 78 -> Loss: 0.903173923492\n",
      "Epoch: 78 -> Test Accuracy: 60.61\n",
      "[79, 60] loss: 0.910\n",
      "[79, 120] loss: 0.933\n",
      "[79, 180] loss: 0.932\n",
      "[79, 240] loss: 0.927\n",
      "[79, 300] loss: 0.924\n",
      "[79, 360] loss: 0.937\n",
      "Epoch: 79 -> Loss: 0.88650906086\n",
      "Epoch: 79 -> Test Accuracy: 60.67\n",
      "[80, 60] loss: 0.934\n",
      "[80, 120] loss: 0.925\n",
      "[80, 180] loss: 0.915\n",
      "[80, 240] loss: 0.925\n",
      "[80, 300] loss: 0.918\n",
      "[80, 360] loss: 0.930\n",
      "Epoch: 80 -> Loss: 0.9672549963\n",
      "Epoch: 80 -> Test Accuracy: 60.62\n",
      "[81, 60] loss: 0.943\n",
      "[81, 120] loss: 0.946\n",
      "[81, 180] loss: 0.912\n",
      "[81, 240] loss: 0.928\n",
      "[81, 300] loss: 0.914\n",
      "[81, 360] loss: 0.929\n",
      "Epoch: 81 -> Loss: 0.978289008141\n",
      "Epoch: 81 -> Test Accuracy: 60.89\n",
      "[82, 60] loss: 0.907\n",
      "[82, 120] loss: 0.920\n",
      "[82, 180] loss: 0.922\n",
      "[82, 240] loss: 0.921\n",
      "[82, 300] loss: 0.940\n",
      "[82, 360] loss: 0.904\n",
      "Epoch: 82 -> Loss: 0.901263356209\n",
      "Epoch: 82 -> Test Accuracy: 60.64\n",
      "[83, 60] loss: 0.920\n",
      "[83, 120] loss: 0.921\n",
      "[83, 180] loss: 0.900\n",
      "[83, 240] loss: 0.938\n",
      "[83, 300] loss: 0.942\n",
      "[83, 360] loss: 0.893\n",
      "Epoch: 83 -> Loss: 0.99513399601\n",
      "Epoch: 83 -> Test Accuracy: 60.92\n",
      "[84, 60] loss: 0.906\n",
      "[84, 120] loss: 0.921\n",
      "[84, 180] loss: 0.905\n",
      "[84, 240] loss: 0.922\n",
      "[84, 300] loss: 0.942\n",
      "[84, 360] loss: 0.942\n",
      "Epoch: 84 -> Loss: 0.891474366188\n",
      "Epoch: 84 -> Test Accuracy: 60.31\n",
      "[85, 60] loss: 0.907\n",
      "[85, 120] loss: 0.936\n",
      "[85, 180] loss: 0.939\n",
      "[85, 240] loss: 0.935\n",
      "[85, 300] loss: 0.916\n",
      "[85, 360] loss: 0.933\n",
      "Epoch: 85 -> Loss: 1.06688153744\n",
      "Epoch: 85 -> Test Accuracy: 60.72\n",
      "[86, 60] loss: 0.904\n",
      "[86, 120] loss: 0.900\n",
      "[86, 180] loss: 0.878\n",
      "[86, 240] loss: 0.888\n",
      "[86, 300] loss: 0.907\n",
      "[86, 360] loss: 0.887\n",
      "Epoch: 86 -> Loss: 1.11288881302\n",
      "Epoch: 86 -> Test Accuracy: 62.02\n",
      "[87, 60] loss: 0.882\n",
      "[87, 120] loss: 0.874\n",
      "[87, 180] loss: 0.889\n",
      "[87, 240] loss: 0.873\n",
      "[87, 300] loss: 0.872\n",
      "[87, 360] loss: 0.893\n",
      "Epoch: 87 -> Loss: 0.94067299366\n",
      "Epoch: 87 -> Test Accuracy: 61.9\n",
      "[88, 60] loss: 0.877\n",
      "[88, 120] loss: 0.880\n",
      "[88, 180] loss: 0.895\n",
      "[88, 240] loss: 0.881\n",
      "[88, 300] loss: 0.874\n",
      "[88, 360] loss: 0.890\n",
      "Epoch: 88 -> Loss: 0.983687281609\n",
      "Epoch: 88 -> Test Accuracy: 62.34\n",
      "[89, 60] loss: 0.875\n",
      "[89, 120] loss: 0.880\n",
      "[89, 180] loss: 0.879\n",
      "[89, 240] loss: 0.897\n",
      "[89, 300] loss: 0.868\n",
      "[89, 360] loss: 0.886\n",
      "Epoch: 89 -> Loss: 0.942603588104\n",
      "Epoch: 89 -> Test Accuracy: 61.89\n",
      "[90, 60] loss: 0.875\n",
      "[90, 120] loss: 0.880\n",
      "[90, 180] loss: 0.875\n",
      "[90, 240] loss: 0.873\n",
      "[90, 300] loss: 0.874\n",
      "[90, 360] loss: 0.890\n",
      "Epoch: 90 -> Loss: 0.783483982086\n",
      "Epoch: 90 -> Test Accuracy: 62.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[91, 60] loss: 0.892\n",
      "[91, 120] loss: 0.867\n",
      "[91, 180] loss: 0.866\n",
      "[91, 240] loss: 0.885\n",
      "[91, 300] loss: 0.864\n",
      "[91, 360] loss: 0.891\n",
      "Epoch: 91 -> Loss: 0.731607079506\n",
      "Epoch: 91 -> Test Accuracy: 62.01\n",
      "[92, 60] loss: 0.869\n",
      "[92, 120] loss: 0.875\n",
      "[92, 180] loss: 0.882\n",
      "[92, 240] loss: 0.865\n",
      "[92, 300] loss: 0.869\n",
      "[92, 360] loss: 0.874\n",
      "Epoch: 92 -> Loss: 0.920016944408\n",
      "Epoch: 92 -> Test Accuracy: 61.89\n",
      "[93, 60] loss: 0.863\n",
      "[93, 120] loss: 0.878\n",
      "[93, 180] loss: 0.884\n",
      "[93, 240] loss: 0.881\n",
      "[93, 300] loss: 0.871\n",
      "[93, 360] loss: 0.876\n",
      "Epoch: 93 -> Loss: 1.03743028641\n",
      "Epoch: 93 -> Test Accuracy: 62.12\n",
      "[94, 60] loss: 0.879\n",
      "[94, 120] loss: 0.884\n",
      "[94, 180] loss: 0.892\n",
      "[94, 240] loss: 0.865\n",
      "[94, 300] loss: 0.893\n",
      "[94, 360] loss: 0.869\n",
      "Epoch: 94 -> Loss: 0.85540086031\n",
      "Epoch: 94 -> Test Accuracy: 61.94\n",
      "[95, 60] loss: 0.877\n",
      "[95, 120] loss: 0.887\n",
      "[95, 180] loss: 0.859\n",
      "[95, 240] loss: 0.872\n",
      "[95, 300] loss: 0.869\n",
      "[95, 360] loss: 0.880\n",
      "Epoch: 95 -> Loss: 1.02554631233\n",
      "Epoch: 95 -> Test Accuracy: 62.5\n",
      "[96, 60] loss: 0.872\n",
      "[96, 120] loss: 0.891\n",
      "[96, 180] loss: 0.864\n",
      "[96, 240] loss: 0.872\n",
      "[96, 300] loss: 0.859\n",
      "[96, 360] loss: 0.856\n",
      "Epoch: 96 -> Loss: 0.801133453846\n",
      "Epoch: 96 -> Test Accuracy: 62.48\n",
      "[97, 60] loss: 0.862\n",
      "[97, 120] loss: 0.870\n",
      "[97, 180] loss: 0.867\n",
      "[97, 240] loss: 0.871\n",
      "[97, 300] loss: 0.864\n",
      "[97, 360] loss: 0.874\n",
      "Epoch: 97 -> Loss: 1.14482223988\n",
      "Epoch: 97 -> Test Accuracy: 62.17\n",
      "[98, 60] loss: 0.884\n",
      "[98, 120] loss: 0.861\n",
      "[98, 180] loss: 0.886\n",
      "[98, 240] loss: 0.877\n",
      "[98, 300] loss: 0.848\n",
      "[98, 360] loss: 0.872\n",
      "Epoch: 98 -> Loss: 0.752579689026\n",
      "Epoch: 98 -> Test Accuracy: 62.32\n",
      "[99, 60] loss: 0.855\n",
      "[99, 120] loss: 0.868\n",
      "[99, 180] loss: 0.867\n",
      "[99, 240] loss: 0.880\n",
      "[99, 300] loss: 0.840\n",
      "[99, 360] loss: 0.868\n",
      "Epoch: 99 -> Loss: 0.769469022751\n",
      "Epoch: 99 -> Test Accuracy: 62.89\n",
      "[100, 60] loss: 0.862\n",
      "[100, 120] loss: 0.868\n",
      "[100, 180] loss: 0.865\n",
      "[100, 240] loss: 0.864\n",
      "[100, 300] loss: 0.865\n",
      "[100, 360] loss: 0.879\n",
      "Epoch: 100 -> Loss: 0.952458560467\n",
      "Epoch: 100 -> Test Accuracy: 62.75\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train ConvClassifiers on feature map of net_3block\n",
    "conv_block3_loss_log, _, conv_block3_test_accuracy_log, _, _ = tr.train_all_blocks(3, 10, [0.1, 0.02, 0.004, 0.0008], \n",
    "    [35, 70, 85, 100], 0.9, 5e-4, net_block3, criterion, trainloader, None, testloader, use_ConvClassifier=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save variables\n",
    "fm.save_variable([rot_block3_loss_log, rot_block3_test_accuracy_log, \n",
    "                  block3_loss_log, block3_test_accuracy_log, \n",
    "                  conv_block3_loss_log, conv_block3_test_accuracy_log], \"3_block_net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename files\n",
    "fm.add_block_to_name(3, [100, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Block RotNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "net_block4 = RN.RotNet(num_classes=4, num_conv_block=4, add_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.150\n",
      "[1, 120] loss: 1.001\n",
      "[1, 180] loss: 0.922\n",
      "[1, 240] loss: 0.876\n",
      "[1, 300] loss: 0.833\n",
      "[1, 360] loss: 0.786\n",
      "Epoch: 1 -> Loss: 0.781775653362\n",
      "Epoch: 1 -> Test Accuracy: 68.8775\n",
      "[2, 60] loss: 0.729\n",
      "[2, 120] loss: 0.725\n",
      "[2, 180] loss: 0.698\n",
      "[2, 240] loss: 0.684\n",
      "[2, 300] loss: 0.641\n",
      "[2, 360] loss: 0.656\n",
      "Epoch: 2 -> Loss: 0.584232747555\n",
      "Epoch: 2 -> Test Accuracy: 75.1475\n",
      "[3, 60] loss: 0.621\n",
      "[3, 120] loss: 0.594\n",
      "[3, 180] loss: 0.595\n",
      "[3, 240] loss: 0.587\n",
      "[3, 300] loss: 0.584\n",
      "[3, 360] loss: 0.564\n",
      "Epoch: 3 -> Loss: 0.645894467831\n",
      "Epoch: 3 -> Test Accuracy: 77.05\n",
      "[4, 60] loss: 0.544\n",
      "[4, 120] loss: 0.551\n",
      "[4, 180] loss: 0.521\n",
      "[4, 240] loss: 0.532\n",
      "[4, 300] loss: 0.520\n",
      "[4, 360] loss: 0.524\n",
      "Epoch: 4 -> Loss: 0.476690769196\n",
      "Epoch: 4 -> Test Accuracy: 79.5825\n",
      "[5, 60] loss: 0.497\n",
      "[5, 120] loss: 0.492\n",
      "[5, 180] loss: 0.496\n",
      "[5, 240] loss: 0.500\n",
      "[5, 300] loss: 0.484\n",
      "[5, 360] loss: 0.487\n",
      "Epoch: 5 -> Loss: 0.413071870804\n",
      "Epoch: 5 -> Test Accuracy: 80.7575\n",
      "[6, 60] loss: 0.473\n",
      "[6, 120] loss: 0.467\n",
      "[6, 180] loss: 0.470\n",
      "[6, 240] loss: 0.455\n",
      "[6, 300] loss: 0.469\n",
      "[6, 360] loss: 0.468\n",
      "Epoch: 6 -> Loss: 0.490919649601\n",
      "Epoch: 6 -> Test Accuracy: 81.94\n",
      "[7, 60] loss: 0.451\n",
      "[7, 120] loss: 0.453\n",
      "[7, 180] loss: 0.450\n",
      "[7, 240] loss: 0.445\n",
      "[7, 300] loss: 0.423\n",
      "[7, 360] loss: 0.426\n",
      "Epoch: 7 -> Loss: 0.441243261099\n",
      "Epoch: 7 -> Test Accuracy: 83.77\n",
      "[8, 60] loss: 0.426\n",
      "[8, 120] loss: 0.430\n",
      "[8, 180] loss: 0.418\n",
      "[8, 240] loss: 0.424\n",
      "[8, 300] loss: 0.431\n",
      "[8, 360] loss: 0.423\n",
      "Epoch: 8 -> Loss: 0.366954118013\n",
      "Epoch: 8 -> Test Accuracy: 83.95\n",
      "[9, 60] loss: 0.416\n",
      "[9, 120] loss: 0.420\n",
      "[9, 180] loss: 0.423\n",
      "[9, 240] loss: 0.410\n",
      "[9, 300] loss: 0.419\n",
      "[9, 360] loss: 0.412\n",
      "Epoch: 9 -> Loss: 0.4629791677\n",
      "Epoch: 9 -> Test Accuracy: 83.1375\n",
      "[10, 60] loss: 0.396\n",
      "[10, 120] loss: 0.395\n",
      "[10, 180] loss: 0.405\n",
      "[10, 240] loss: 0.415\n",
      "[10, 300] loss: 0.404\n",
      "[10, 360] loss: 0.410\n",
      "Epoch: 10 -> Loss: 0.331673562527\n",
      "Epoch: 10 -> Test Accuracy: 84.0275\n",
      "[11, 60] loss: 0.400\n",
      "[11, 120] loss: 0.387\n",
      "[11, 180] loss: 0.396\n",
      "[11, 240] loss: 0.404\n",
      "[11, 300] loss: 0.387\n",
      "[11, 360] loss: 0.388\n",
      "Epoch: 11 -> Loss: 0.323923885822\n",
      "Epoch: 11 -> Test Accuracy: 84.075\n",
      "[12, 60] loss: 0.387\n",
      "[12, 120] loss: 0.374\n",
      "[12, 180] loss: 0.387\n",
      "[12, 240] loss: 0.384\n",
      "[12, 300] loss: 0.373\n",
      "[12, 360] loss: 0.392\n",
      "Epoch: 12 -> Loss: 0.488639354706\n",
      "Epoch: 12 -> Test Accuracy: 84.335\n",
      "[13, 60] loss: 0.380\n",
      "[13, 120] loss: 0.385\n",
      "[13, 180] loss: 0.370\n",
      "[13, 240] loss: 0.369\n",
      "[13, 300] loss: 0.379\n",
      "[13, 360] loss: 0.391\n",
      "Epoch: 13 -> Loss: 0.208872437477\n",
      "Epoch: 13 -> Test Accuracy: 85.0275\n",
      "[14, 60] loss: 0.360\n",
      "[14, 120] loss: 0.362\n",
      "[14, 180] loss: 0.385\n",
      "[14, 240] loss: 0.388\n",
      "[14, 300] loss: 0.381\n",
      "[14, 360] loss: 0.357\n",
      "Epoch: 14 -> Loss: 0.461386829615\n",
      "Epoch: 14 -> Test Accuracy: 85.4725\n",
      "[15, 60] loss: 0.357\n",
      "[15, 120] loss: 0.363\n",
      "[15, 180] loss: 0.358\n",
      "[15, 240] loss: 0.378\n",
      "[15, 300] loss: 0.358\n",
      "[15, 360] loss: 0.375\n",
      "Epoch: 15 -> Loss: 0.305442273617\n",
      "Epoch: 15 -> Test Accuracy: 84.4975\n",
      "[16, 60] loss: 0.354\n",
      "[16, 120] loss: 0.373\n",
      "[16, 180] loss: 0.363\n",
      "[16, 240] loss: 0.358\n",
      "[16, 300] loss: 0.362\n",
      "[16, 360] loss: 0.369\n",
      "Epoch: 16 -> Loss: 0.401940524578\n",
      "Epoch: 16 -> Test Accuracy: 86.29\n",
      "[17, 60] loss: 0.347\n",
      "[17, 120] loss: 0.346\n",
      "[17, 180] loss: 0.359\n",
      "[17, 240] loss: 0.353\n",
      "[17, 300] loss: 0.363\n",
      "[17, 360] loss: 0.357\n",
      "Epoch: 17 -> Loss: 0.285796821117\n",
      "Epoch: 17 -> Test Accuracy: 85.44\n",
      "[18, 60] loss: 0.347\n",
      "[18, 120] loss: 0.335\n",
      "[18, 180] loss: 0.354\n",
      "[18, 240] loss: 0.351\n",
      "[18, 300] loss: 0.362\n",
      "[18, 360] loss: 0.361\n",
      "Epoch: 18 -> Loss: 0.348131626844\n",
      "Epoch: 18 -> Test Accuracy: 85.83\n",
      "[19, 60] loss: 0.333\n",
      "[19, 120] loss: 0.341\n",
      "[19, 180] loss: 0.349\n",
      "[19, 240] loss: 0.346\n",
      "[19, 300] loss: 0.367\n",
      "[19, 360] loss: 0.348\n",
      "Epoch: 19 -> Loss: 0.316087156534\n",
      "Epoch: 19 -> Test Accuracy: 85.805\n",
      "[20, 60] loss: 0.327\n",
      "[20, 120] loss: 0.338\n",
      "[20, 180] loss: 0.348\n",
      "[20, 240] loss: 0.336\n",
      "[20, 300] loss: 0.355\n",
      "[20, 360] loss: 0.355\n",
      "Epoch: 20 -> Loss: 0.455764204264\n",
      "Epoch: 20 -> Test Accuracy: 86.075\n",
      "[21, 60] loss: 0.335\n",
      "[21, 120] loss: 0.342\n",
      "[21, 180] loss: 0.341\n",
      "[21, 240] loss: 0.347\n",
      "[21, 300] loss: 0.341\n",
      "[21, 360] loss: 0.328\n",
      "Epoch: 21 -> Loss: 0.346121132374\n",
      "Epoch: 21 -> Test Accuracy: 85.815\n",
      "[22, 60] loss: 0.324\n",
      "[22, 120] loss: 0.339\n",
      "[22, 180] loss: 0.349\n",
      "[22, 240] loss: 0.343\n",
      "[22, 300] loss: 0.336\n",
      "[22, 360] loss: 0.333\n",
      "Epoch: 22 -> Loss: 0.349208116531\n",
      "Epoch: 22 -> Test Accuracy: 85.4025\n",
      "[23, 60] loss: 0.330\n",
      "[23, 120] loss: 0.331\n",
      "[23, 180] loss: 0.340\n",
      "[23, 240] loss: 0.344\n",
      "[23, 300] loss: 0.343\n",
      "[23, 360] loss: 0.343\n",
      "Epoch: 23 -> Loss: 0.42324385047\n",
      "Epoch: 23 -> Test Accuracy: 85.7925\n",
      "[24, 60] loss: 0.324\n",
      "[24, 120] loss: 0.337\n",
      "[24, 180] loss: 0.335\n",
      "[24, 240] loss: 0.338\n",
      "[24, 300] loss: 0.334\n",
      "[24, 360] loss: 0.335\n",
      "Epoch: 24 -> Loss: 0.357789635658\n",
      "Epoch: 24 -> Test Accuracy: 86.2775\n",
      "[25, 60] loss: 0.325\n",
      "[25, 120] loss: 0.321\n",
      "[25, 180] loss: 0.320\n",
      "[25, 240] loss: 0.339\n",
      "[25, 300] loss: 0.337\n",
      "[25, 360] loss: 0.347\n",
      "Epoch: 25 -> Loss: 0.275826126337\n",
      "Epoch: 25 -> Test Accuracy: 86.375\n",
      "[26, 60] loss: 0.312\n",
      "[26, 120] loss: 0.327\n",
      "[26, 180] loss: 0.331\n",
      "[26, 240] loss: 0.333\n",
      "[26, 300] loss: 0.322\n",
      "[26, 360] loss: 0.330\n",
      "Epoch: 26 -> Loss: 0.319354474545\n",
      "Epoch: 26 -> Test Accuracy: 86.7075\n",
      "[27, 60] loss: 0.307\n",
      "[27, 120] loss: 0.330\n",
      "[27, 180] loss: 0.327\n",
      "[27, 240] loss: 0.334\n",
      "[27, 300] loss: 0.331\n",
      "[27, 360] loss: 0.321\n",
      "Epoch: 27 -> Loss: 0.28556483984\n",
      "Epoch: 27 -> Test Accuracy: 86.415\n",
      "[28, 60] loss: 0.304\n",
      "[28, 120] loss: 0.330\n",
      "[28, 180] loss: 0.317\n",
      "[28, 240] loss: 0.321\n",
      "[28, 300] loss: 0.336\n",
      "[28, 360] loss: 0.346\n",
      "Epoch: 28 -> Loss: 0.387163460255\n",
      "Epoch: 28 -> Test Accuracy: 85.8\n",
      "[29, 60] loss: 0.313\n",
      "[29, 120] loss: 0.330\n",
      "[29, 180] loss: 0.321\n",
      "[29, 240] loss: 0.331\n",
      "[29, 300] loss: 0.333\n",
      "[29, 360] loss: 0.338\n",
      "Epoch: 29 -> Loss: 0.538499712944\n",
      "Epoch: 29 -> Test Accuracy: 86.705\n",
      "[30, 60] loss: 0.318\n",
      "[30, 120] loss: 0.315\n",
      "[30, 180] loss: 0.332\n",
      "[30, 240] loss: 0.319\n",
      "[30, 300] loss: 0.312\n",
      "[30, 360] loss: 0.327\n",
      "Epoch: 30 -> Loss: 0.394170969725\n",
      "Epoch: 30 -> Test Accuracy: 86.49\n",
      "[31, 60] loss: 0.310\n",
      "[31, 120] loss: 0.314\n",
      "[31, 180] loss: 0.318\n",
      "[31, 240] loss: 0.334\n",
      "[31, 300] loss: 0.326\n",
      "[31, 360] loss: 0.320\n",
      "Epoch: 31 -> Loss: 0.322353422642\n",
      "Epoch: 31 -> Test Accuracy: 86.22\n",
      "[32, 60] loss: 0.296\n",
      "[32, 120] loss: 0.319\n",
      "[32, 180] loss: 0.317\n",
      "[32, 240] loss: 0.312\n",
      "[32, 300] loss: 0.325\n",
      "[32, 360] loss: 0.327\n",
      "Epoch: 32 -> Loss: 0.426513671875\n",
      "Epoch: 32 -> Test Accuracy: 86.6475\n",
      "[33, 60] loss: 0.315\n",
      "[33, 120] loss: 0.323\n",
      "[33, 180] loss: 0.314\n",
      "[33, 240] loss: 0.327\n",
      "[33, 300] loss: 0.318\n",
      "[33, 360] loss: 0.312\n",
      "Epoch: 33 -> Loss: 0.352553933859\n",
      "Epoch: 33 -> Test Accuracy: 87.2725\n",
      "[34, 60] loss: 0.310\n",
      "[34, 120] loss: 0.310\n",
      "[34, 180] loss: 0.315\n",
      "[34, 240] loss: 0.323\n",
      "[34, 300] loss: 0.324\n",
      "[34, 360] loss: 0.316\n",
      "Epoch: 34 -> Loss: 0.224912017584\n",
      "Epoch: 34 -> Test Accuracy: 86.6925\n",
      "[35, 60] loss: 0.299\n",
      "[35, 120] loss: 0.309\n",
      "[35, 180] loss: 0.315\n",
      "[35, 240] loss: 0.316\n",
      "[35, 300] loss: 0.325\n",
      "[35, 360] loss: 0.317\n",
      "Epoch: 35 -> Loss: 0.433116137981\n",
      "Epoch: 35 -> Test Accuracy: 86.055\n",
      "[36, 60] loss: 0.312\n",
      "[36, 120] loss: 0.309\n",
      "[36, 180] loss: 0.310\n",
      "[36, 240] loss: 0.321\n",
      "[36, 300] loss: 0.330\n",
      "[36, 360] loss: 0.314\n",
      "Epoch: 36 -> Loss: 0.273465812206\n",
      "Epoch: 36 -> Test Accuracy: 87.76\n",
      "[37, 60] loss: 0.297\n",
      "[37, 120] loss: 0.318\n",
      "[37, 180] loss: 0.311\n",
      "[37, 240] loss: 0.313\n",
      "[37, 300] loss: 0.325\n",
      "[37, 360] loss: 0.322\n",
      "Epoch: 37 -> Loss: 0.353146255016\n",
      "Epoch: 37 -> Test Accuracy: 86.3725\n",
      "[38, 60] loss: 0.294\n",
      "[38, 120] loss: 0.308\n",
      "[38, 180] loss: 0.318\n",
      "[38, 240] loss: 0.315\n",
      "[38, 300] loss: 0.322\n",
      "[38, 360] loss: 0.321\n",
      "Epoch: 38 -> Loss: 0.210616707802\n",
      "Epoch: 38 -> Test Accuracy: 86.3525\n",
      "[39, 60] loss: 0.296\n",
      "[39, 120] loss: 0.322\n",
      "[39, 180] loss: 0.307\n",
      "[39, 240] loss: 0.309\n",
      "[39, 300] loss: 0.314\n",
      "[39, 360] loss: 0.310\n",
      "Epoch: 39 -> Loss: 0.305145710707\n",
      "Epoch: 39 -> Test Accuracy: 86.0825\n",
      "[40, 60] loss: 0.303\n",
      "[40, 120] loss: 0.313\n",
      "[40, 180] loss: 0.317\n",
      "[40, 240] loss: 0.297\n",
      "[40, 300] loss: 0.323\n",
      "[40, 360] loss: 0.320\n",
      "Epoch: 40 -> Loss: 0.322410672903\n",
      "Epoch: 40 -> Test Accuracy: 86.355\n",
      "[41, 60] loss: 0.297\n",
      "[41, 120] loss: 0.298\n",
      "[41, 180] loss: 0.313\n",
      "[41, 240] loss: 0.326\n",
      "[41, 300] loss: 0.303\n",
      "[41, 360] loss: 0.316\n",
      "Epoch: 41 -> Loss: 0.377940863371\n",
      "Epoch: 41 -> Test Accuracy: 86.6425\n",
      "[42, 60] loss: 0.301\n",
      "[42, 120] loss: 0.310\n",
      "[42, 180] loss: 0.317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 240] loss: 0.304\n",
      "[42, 300] loss: 0.308\n",
      "[42, 360] loss: 0.322\n",
      "Epoch: 42 -> Loss: 0.24705453217\n",
      "Epoch: 42 -> Test Accuracy: 87.725\n",
      "[43, 60] loss: 0.308\n",
      "[43, 120] loss: 0.302\n",
      "[43, 180] loss: 0.311\n",
      "[43, 240] loss: 0.315\n",
      "[43, 300] loss: 0.301\n",
      "[43, 360] loss: 0.313\n",
      "Epoch: 43 -> Loss: 0.284123122692\n",
      "Epoch: 43 -> Test Accuracy: 86.16\n",
      "[44, 60] loss: 0.311\n",
      "[44, 120] loss: 0.296\n",
      "[44, 180] loss: 0.311\n",
      "[44, 240] loss: 0.321\n",
      "[44, 300] loss: 0.301\n",
      "[44, 360] loss: 0.305\n",
      "Epoch: 44 -> Loss: 0.261650413275\n",
      "Epoch: 44 -> Test Accuracy: 87.1175\n",
      "[45, 60] loss: 0.300\n",
      "[45, 120] loss: 0.308\n",
      "[45, 180] loss: 0.308\n",
      "[45, 240] loss: 0.308\n",
      "[45, 300] loss: 0.299\n",
      "[45, 360] loss: 0.309\n",
      "Epoch: 45 -> Loss: 0.355645358562\n",
      "Epoch: 45 -> Test Accuracy: 87.105\n",
      "[46, 60] loss: 0.304\n",
      "[46, 120] loss: 0.297\n",
      "[46, 180] loss: 0.302\n",
      "[46, 240] loss: 0.293\n",
      "[46, 300] loss: 0.307\n",
      "[46, 360] loss: 0.314\n",
      "Epoch: 46 -> Loss: 0.321740746498\n",
      "Epoch: 46 -> Test Accuracy: 86.2225\n",
      "[47, 60] loss: 0.296\n",
      "[47, 120] loss: 0.305\n",
      "[47, 180] loss: 0.299\n",
      "[47, 240] loss: 0.310\n",
      "[47, 300] loss: 0.304\n",
      "[47, 360] loss: 0.326\n",
      "Epoch: 47 -> Loss: 0.296863108873\n",
      "Epoch: 47 -> Test Accuracy: 86.935\n",
      "[48, 60] loss: 0.308\n",
      "[48, 120] loss: 0.306\n",
      "[48, 180] loss: 0.301\n",
      "[48, 240] loss: 0.301\n",
      "[48, 300] loss: 0.310\n",
      "[48, 360] loss: 0.303\n",
      "Epoch: 48 -> Loss: 0.276964962482\n",
      "Epoch: 48 -> Test Accuracy: 87.07\n",
      "[49, 60] loss: 0.296\n",
      "[49, 120] loss: 0.306\n",
      "[49, 180] loss: 0.296\n",
      "[49, 240] loss: 0.311\n",
      "[49, 300] loss: 0.310\n",
      "[49, 360] loss: 0.314\n",
      "Epoch: 49 -> Loss: 0.437825858593\n",
      "Epoch: 49 -> Test Accuracy: 87.25\n",
      "[50, 60] loss: 0.290\n",
      "[50, 120] loss: 0.289\n",
      "[50, 180] loss: 0.301\n",
      "[50, 240] loss: 0.304\n",
      "[50, 300] loss: 0.305\n",
      "[50, 360] loss: 0.306\n",
      "Epoch: 50 -> Loss: 0.40210968256\n",
      "Epoch: 50 -> Test Accuracy: 86.765\n",
      "[51, 60] loss: 0.278\n",
      "[51, 120] loss: 0.302\n",
      "[51, 180] loss: 0.307\n",
      "[51, 240] loss: 0.304\n",
      "[51, 300] loss: 0.311\n",
      "[51, 360] loss: 0.307\n",
      "Epoch: 51 -> Loss: 0.1984500736\n",
      "Epoch: 51 -> Test Accuracy: 86.675\n",
      "[52, 60] loss: 0.300\n",
      "[52, 120] loss: 0.303\n",
      "[52, 180] loss: 0.301\n",
      "[52, 240] loss: 0.303\n",
      "[52, 300] loss: 0.304\n",
      "[52, 360] loss: 0.294\n",
      "Epoch: 52 -> Loss: 0.327635288239\n",
      "Epoch: 52 -> Test Accuracy: 86.7325\n",
      "[53, 60] loss: 0.291\n",
      "[53, 120] loss: 0.296\n",
      "[53, 180] loss: 0.307\n",
      "[53, 240] loss: 0.303\n",
      "[53, 300] loss: 0.307\n",
      "[53, 360] loss: 0.291\n",
      "Epoch: 53 -> Loss: 0.340356588364\n",
      "Epoch: 53 -> Test Accuracy: 86.845\n",
      "[54, 60] loss: 0.290\n",
      "[54, 120] loss: 0.299\n",
      "[54, 180] loss: 0.309\n",
      "[54, 240] loss: 0.299\n",
      "[54, 300] loss: 0.297\n",
      "[54, 360] loss: 0.322\n",
      "Epoch: 54 -> Loss: 0.337031364441\n",
      "Epoch: 54 -> Test Accuracy: 88.11\n",
      "[55, 60] loss: 0.278\n",
      "[55, 120] loss: 0.301\n",
      "[55, 180] loss: 0.297\n",
      "[55, 240] loss: 0.307\n",
      "[55, 300] loss: 0.306\n",
      "[55, 360] loss: 0.304\n",
      "Epoch: 55 -> Loss: 0.221755385399\n",
      "Epoch: 55 -> Test Accuracy: 87.595\n",
      "[56, 60] loss: 0.289\n",
      "[56, 120] loss: 0.289\n",
      "[56, 180] loss: 0.308\n",
      "[56, 240] loss: 0.308\n",
      "[56, 300] loss: 0.309\n",
      "[56, 360] loss: 0.299\n",
      "Epoch: 56 -> Loss: 0.263359606266\n",
      "Epoch: 56 -> Test Accuracy: 87.4925\n",
      "[57, 60] loss: 0.302\n",
      "[57, 120] loss: 0.301\n",
      "[57, 180] loss: 0.302\n",
      "[57, 240] loss: 0.288\n",
      "[57, 300] loss: 0.296\n",
      "[57, 360] loss: 0.305\n",
      "Epoch: 57 -> Loss: 0.282748967409\n",
      "Epoch: 57 -> Test Accuracy: 87.735\n",
      "[58, 60] loss: 0.286\n",
      "[58, 120] loss: 0.282\n",
      "[58, 180] loss: 0.304\n",
      "[58, 240] loss: 0.316\n",
      "[58, 300] loss: 0.297\n",
      "[58, 360] loss: 0.310\n",
      "Epoch: 58 -> Loss: 0.238300606608\n",
      "Epoch: 58 -> Test Accuracy: 87.51\n",
      "[59, 60] loss: 0.284\n",
      "[59, 120] loss: 0.306\n",
      "[59, 180] loss: 0.297\n",
      "[59, 240] loss: 0.300\n",
      "[59, 300] loss: 0.298\n",
      "[59, 360] loss: 0.307\n",
      "Epoch: 59 -> Loss: 0.253601968288\n",
      "Epoch: 59 -> Test Accuracy: 86.815\n",
      "[60, 60] loss: 0.288\n",
      "[60, 120] loss: 0.290\n",
      "[60, 180] loss: 0.297\n",
      "[60, 240] loss: 0.320\n",
      "[60, 300] loss: 0.295\n",
      "[60, 360] loss: 0.301\n",
      "Epoch: 60 -> Loss: 0.252720683813\n",
      "Epoch: 60 -> Test Accuracy: 87.5325\n",
      "[61, 60] loss: 0.215\n",
      "[61, 120] loss: 0.193\n",
      "[61, 180] loss: 0.183\n",
      "[61, 240] loss: 0.170\n",
      "[61, 300] loss: 0.193\n",
      "[61, 360] loss: 0.193\n",
      "Epoch: 61 -> Loss: 0.152619630098\n",
      "Epoch: 61 -> Test Accuracy: 91.34\n",
      "[62, 60] loss: 0.154\n",
      "[62, 120] loss: 0.163\n",
      "[62, 180] loss: 0.171\n",
      "[62, 240] loss: 0.164\n",
      "[62, 300] loss: 0.159\n",
      "[62, 360] loss: 0.170\n",
      "Epoch: 62 -> Loss: 0.25391420722\n",
      "Epoch: 62 -> Test Accuracy: 91.295\n",
      "[63, 60] loss: 0.154\n",
      "[63, 120] loss: 0.149\n",
      "[63, 180] loss: 0.155\n",
      "[63, 240] loss: 0.163\n",
      "[63, 300] loss: 0.149\n",
      "[63, 360] loss: 0.154\n",
      "Epoch: 63 -> Loss: 0.145848482847\n",
      "Epoch: 63 -> Test Accuracy: 91.54\n",
      "[64, 60] loss: 0.137\n",
      "[64, 120] loss: 0.146\n",
      "[64, 180] loss: 0.155\n",
      "[64, 240] loss: 0.145\n",
      "[64, 300] loss: 0.150\n",
      "[64, 360] loss: 0.163\n",
      "Epoch: 64 -> Loss: 0.0731259733438\n",
      "Epoch: 64 -> Test Accuracy: 91.34\n",
      "[65, 60] loss: 0.136\n",
      "[65, 120] loss: 0.140\n",
      "[65, 180] loss: 0.145\n",
      "[65, 240] loss: 0.154\n",
      "[65, 300] loss: 0.156\n",
      "[65, 360] loss: 0.144\n",
      "Epoch: 65 -> Loss: 0.117941997945\n",
      "Epoch: 65 -> Test Accuracy: 91.3025\n",
      "[66, 60] loss: 0.133\n",
      "[66, 120] loss: 0.143\n",
      "[66, 180] loss: 0.143\n",
      "[66, 240] loss: 0.150\n",
      "[66, 300] loss: 0.149\n",
      "[66, 360] loss: 0.147\n",
      "Epoch: 66 -> Loss: 0.0987311452627\n",
      "Epoch: 66 -> Test Accuracy: 91.51\n",
      "[67, 60] loss: 0.130\n",
      "[67, 120] loss: 0.137\n",
      "[67, 180] loss: 0.135\n",
      "[67, 240] loss: 0.144\n",
      "[67, 300] loss: 0.144\n",
      "[67, 360] loss: 0.152\n",
      "Epoch: 67 -> Loss: 0.182628676295\n",
      "Epoch: 67 -> Test Accuracy: 91.065\n",
      "[68, 60] loss: 0.132\n",
      "[68, 120] loss: 0.147\n",
      "[68, 180] loss: 0.153\n",
      "[68, 240] loss: 0.135\n",
      "[68, 300] loss: 0.149\n",
      "[68, 360] loss: 0.145\n",
      "Epoch: 68 -> Loss: 0.0978967696428\n",
      "Epoch: 68 -> Test Accuracy: 91.0475\n",
      "[69, 60] loss: 0.136\n",
      "[69, 120] loss: 0.141\n",
      "[69, 180] loss: 0.134\n",
      "[69, 240] loss: 0.152\n",
      "[69, 300] loss: 0.143\n",
      "[69, 360] loss: 0.144\n",
      "Epoch: 69 -> Loss: 0.147503316402\n",
      "Epoch: 69 -> Test Accuracy: 91.0075\n",
      "[70, 60] loss: 0.137\n",
      "[70, 120] loss: 0.143\n",
      "[70, 180] loss: 0.144\n",
      "[70, 240] loss: 0.134\n",
      "[70, 300] loss: 0.148\n",
      "[70, 360] loss: 0.153\n",
      "Epoch: 70 -> Loss: 0.0837320536375\n",
      "Epoch: 70 -> Test Accuracy: 90.8325\n",
      "[71, 60] loss: 0.136\n",
      "[71, 120] loss: 0.134\n",
      "[71, 180] loss: 0.153\n",
      "[71, 240] loss: 0.149\n",
      "[71, 300] loss: 0.144\n",
      "[71, 360] loss: 0.151\n",
      "Epoch: 71 -> Loss: 0.247880861163\n",
      "Epoch: 71 -> Test Accuracy: 91.0425\n",
      "[72, 60] loss: 0.144\n",
      "[72, 120] loss: 0.137\n",
      "[72, 180] loss: 0.146\n",
      "[72, 240] loss: 0.145\n",
      "[72, 300] loss: 0.145\n",
      "[72, 360] loss: 0.157\n",
      "Epoch: 72 -> Loss: 0.215179473162\n",
      "Epoch: 72 -> Test Accuracy: 90.86\n",
      "[73, 60] loss: 0.131\n",
      "[73, 120] loss: 0.141\n",
      "[73, 180] loss: 0.149\n",
      "[73, 240] loss: 0.156\n",
      "[73, 300] loss: 0.145\n",
      "[73, 360] loss: 0.153\n",
      "Epoch: 73 -> Loss: 0.147053033113\n",
      "Epoch: 73 -> Test Accuracy: 90.905\n",
      "[74, 60] loss: 0.134\n",
      "[74, 120] loss: 0.141\n",
      "[74, 180] loss: 0.141\n",
      "[74, 240] loss: 0.151\n",
      "[74, 300] loss: 0.152\n",
      "[74, 360] loss: 0.148\n",
      "Epoch: 74 -> Loss: 0.115112781525\n",
      "Epoch: 74 -> Test Accuracy: 90.775\n",
      "[75, 60] loss: 0.131\n",
      "[75, 120] loss: 0.141\n",
      "[75, 180] loss: 0.150\n",
      "[75, 240] loss: 0.144\n",
      "[75, 300] loss: 0.140\n",
      "[75, 360] loss: 0.155\n",
      "Epoch: 75 -> Loss: 0.0943397805095\n",
      "Epoch: 75 -> Test Accuracy: 90.59\n",
      "[76, 60] loss: 0.135\n",
      "[76, 120] loss: 0.138\n",
      "[76, 180] loss: 0.142\n",
      "[76, 240] loss: 0.147\n",
      "[76, 300] loss: 0.160\n",
      "[76, 360] loss: 0.150\n",
      "Epoch: 76 -> Loss: 0.167947486043\n",
      "Epoch: 76 -> Test Accuracy: 90.4\n",
      "[77, 60] loss: 0.136\n",
      "[77, 120] loss: 0.136\n",
      "[77, 180] loss: 0.139\n",
      "[77, 240] loss: 0.151\n",
      "[77, 300] loss: 0.144\n",
      "[77, 360] loss: 0.146\n",
      "Epoch: 77 -> Loss: 0.113348640501\n",
      "Epoch: 77 -> Test Accuracy: 90.755\n",
      "[78, 60] loss: 0.144\n",
      "[78, 120] loss: 0.146\n",
      "[78, 180] loss: 0.144\n",
      "[78, 240] loss: 0.148\n",
      "[78, 300] loss: 0.139\n",
      "[78, 360] loss: 0.154\n",
      "Epoch: 78 -> Loss: 0.150995999575\n",
      "Epoch: 78 -> Test Accuracy: 90.625\n",
      "[79, 60] loss: 0.128\n",
      "[79, 120] loss: 0.143\n",
      "[79, 180] loss: 0.137\n",
      "[79, 240] loss: 0.151\n",
      "[79, 300] loss: 0.157\n",
      "[79, 360] loss: 0.142\n",
      "Epoch: 79 -> Loss: 0.135096788406\n",
      "Epoch: 79 -> Test Accuracy: 90.59\n",
      "[80, 60] loss: 0.130\n",
      "[80, 120] loss: 0.149\n",
      "[80, 180] loss: 0.149\n",
      "[80, 240] loss: 0.139\n",
      "[80, 300] loss: 0.153\n",
      "[80, 360] loss: 0.147\n",
      "Epoch: 80 -> Loss: 0.10762874037\n",
      "Epoch: 80 -> Test Accuracy: 90.54\n",
      "[81, 60] loss: 0.137\n",
      "[81, 120] loss: 0.140\n",
      "[81, 180] loss: 0.156\n",
      "[81, 240] loss: 0.142\n",
      "[81, 300] loss: 0.149\n",
      "[81, 360] loss: 0.154\n",
      "Epoch: 81 -> Loss: 0.172462910414\n",
      "Epoch: 81 -> Test Accuracy: 90.23\n",
      "[82, 60] loss: 0.134\n",
      "[82, 120] loss: 0.146\n",
      "[82, 180] loss: 0.147\n",
      "[82, 240] loss: 0.141\n",
      "[82, 300] loss: 0.149\n",
      "[82, 360] loss: 0.152\n",
      "Epoch: 82 -> Loss: 0.111282989383\n",
      "Epoch: 82 -> Test Accuracy: 90.885\n",
      "[83, 60] loss: 0.140\n",
      "[83, 120] loss: 0.134\n",
      "[83, 180] loss: 0.136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83, 240] loss: 0.148\n",
      "[83, 300] loss: 0.142\n",
      "[83, 360] loss: 0.164\n",
      "Epoch: 83 -> Loss: 0.129991531372\n",
      "Epoch: 83 -> Test Accuracy: 90.685\n",
      "[84, 60] loss: 0.135\n",
      "[84, 120] loss: 0.132\n",
      "[84, 180] loss: 0.148\n",
      "[84, 240] loss: 0.144\n",
      "[84, 300] loss: 0.152\n",
      "[84, 360] loss: 0.151\n",
      "Epoch: 84 -> Loss: 0.122033432126\n",
      "Epoch: 84 -> Test Accuracy: 90.7275\n",
      "[85, 60] loss: 0.140\n",
      "[85, 120] loss: 0.135\n",
      "[85, 180] loss: 0.140\n",
      "[85, 240] loss: 0.143\n",
      "[85, 300] loss: 0.144\n",
      "[85, 360] loss: 0.158\n",
      "Epoch: 85 -> Loss: 0.0600674524903\n",
      "Epoch: 85 -> Test Accuracy: 90.425\n",
      "[86, 60] loss: 0.124\n",
      "[86, 120] loss: 0.133\n",
      "[86, 180] loss: 0.136\n",
      "[86, 240] loss: 0.149\n",
      "[86, 300] loss: 0.143\n",
      "[86, 360] loss: 0.155\n",
      "Epoch: 86 -> Loss: 0.141129478812\n",
      "Epoch: 86 -> Test Accuracy: 90.59\n",
      "[87, 60] loss: 0.132\n",
      "[87, 120] loss: 0.139\n",
      "[87, 180] loss: 0.147\n",
      "[87, 240] loss: 0.140\n",
      "[87, 300] loss: 0.147\n",
      "[87, 360] loss: 0.144\n",
      "Epoch: 87 -> Loss: 0.127103477716\n",
      "Epoch: 87 -> Test Accuracy: 90.5525\n",
      "[88, 60] loss: 0.139\n",
      "[88, 120] loss: 0.138\n",
      "[88, 180] loss: 0.140\n",
      "[88, 240] loss: 0.149\n",
      "[88, 300] loss: 0.147\n",
      "[88, 360] loss: 0.147\n",
      "Epoch: 88 -> Loss: 0.11277256161\n",
      "Epoch: 88 -> Test Accuracy: 90.6625\n",
      "[89, 60] loss: 0.133\n",
      "[89, 120] loss: 0.134\n",
      "[89, 180] loss: 0.145\n",
      "[89, 240] loss: 0.150\n",
      "[89, 300] loss: 0.144\n",
      "[89, 360] loss: 0.146\n",
      "Epoch: 89 -> Loss: 0.14569170773\n",
      "Epoch: 89 -> Test Accuracy: 90.6025\n",
      "[90, 60] loss: 0.134\n",
      "[90, 120] loss: 0.139\n",
      "[90, 180] loss: 0.144\n",
      "[90, 240] loss: 0.144\n",
      "[90, 300] loss: 0.144\n",
      "[90, 360] loss: 0.142\n",
      "Epoch: 90 -> Loss: 0.209268018603\n",
      "Epoch: 90 -> Test Accuracy: 90.3425\n",
      "[91, 60] loss: 0.141\n",
      "[91, 120] loss: 0.134\n",
      "[91, 180] loss: 0.138\n",
      "[91, 240] loss: 0.139\n",
      "[91, 300] loss: 0.146\n",
      "[91, 360] loss: 0.147\n",
      "Epoch: 91 -> Loss: 0.206640213728\n",
      "Epoch: 91 -> Test Accuracy: 90.41\n",
      "[92, 60] loss: 0.125\n",
      "[92, 120] loss: 0.138\n",
      "[92, 180] loss: 0.138\n",
      "[92, 240] loss: 0.144\n",
      "[92, 300] loss: 0.143\n",
      "[92, 360] loss: 0.141\n",
      "Epoch: 92 -> Loss: 0.11847076565\n",
      "Epoch: 92 -> Test Accuracy: 90.5725\n",
      "[93, 60] loss: 0.131\n",
      "[93, 120] loss: 0.139\n",
      "[93, 180] loss: 0.136\n",
      "[93, 240] loss: 0.152\n",
      "[93, 300] loss: 0.139\n",
      "[93, 360] loss: 0.145\n",
      "Epoch: 93 -> Loss: 0.109613835812\n",
      "Epoch: 93 -> Test Accuracy: 90.665\n",
      "[94, 60] loss: 0.132\n",
      "[94, 120] loss: 0.133\n",
      "[94, 180] loss: 0.142\n",
      "[94, 240] loss: 0.139\n",
      "[94, 300] loss: 0.140\n",
      "[94, 360] loss: 0.148\n",
      "Epoch: 94 -> Loss: 0.135416731238\n",
      "Epoch: 94 -> Test Accuracy: 90.4875\n",
      "[95, 60] loss: 0.127\n",
      "[95, 120] loss: 0.132\n",
      "[95, 180] loss: 0.136\n",
      "[95, 240] loss: 0.143\n",
      "[95, 300] loss: 0.146\n",
      "[95, 360] loss: 0.151\n",
      "Epoch: 95 -> Loss: 0.173524618149\n",
      "Epoch: 95 -> Test Accuracy: 90.5275\n",
      "[96, 60] loss: 0.132\n",
      "[96, 120] loss: 0.124\n",
      "[96, 180] loss: 0.139\n",
      "[96, 240] loss: 0.141\n",
      "[96, 300] loss: 0.135\n",
      "[96, 360] loss: 0.145\n",
      "Epoch: 96 -> Loss: 0.0816012322903\n",
      "Epoch: 96 -> Test Accuracy: 90.4775\n",
      "[97, 60] loss: 0.129\n",
      "[97, 120] loss: 0.134\n",
      "[97, 180] loss: 0.141\n",
      "[97, 240] loss: 0.146\n",
      "[97, 300] loss: 0.137\n",
      "[97, 360] loss: 0.143\n",
      "Epoch: 97 -> Loss: 0.205771565437\n",
      "Epoch: 97 -> Test Accuracy: 90.4925\n",
      "[98, 60] loss: 0.128\n",
      "[98, 120] loss: 0.133\n",
      "[98, 180] loss: 0.139\n",
      "[98, 240] loss: 0.137\n",
      "[98, 300] loss: 0.144\n",
      "[98, 360] loss: 0.146\n",
      "Epoch: 98 -> Loss: 0.107984088361\n",
      "Epoch: 98 -> Test Accuracy: 90.605\n",
      "[99, 60] loss: 0.128\n",
      "[99, 120] loss: 0.131\n",
      "[99, 180] loss: 0.136\n",
      "[99, 240] loss: 0.139\n",
      "[99, 300] loss: 0.149\n",
      "[99, 360] loss: 0.140\n",
      "Epoch: 99 -> Loss: 0.081191919744\n",
      "Epoch: 99 -> Test Accuracy: 90.4425\n",
      "[100, 60] loss: 0.130\n",
      "[100, 120] loss: 0.118\n",
      "[100, 180] loss: 0.133\n",
      "[100, 240] loss: 0.151\n",
      "[100, 300] loss: 0.140\n",
      "[100, 360] loss: 0.144\n",
      "Epoch: 100 -> Loss: 0.105543039739\n",
      "Epoch: 100 -> Test Accuracy: 90.765\n",
      "[101, 60] loss: 0.127\n",
      "[101, 120] loss: 0.134\n",
      "[101, 180] loss: 0.144\n",
      "[101, 240] loss: 0.127\n",
      "[101, 300] loss: 0.133\n",
      "[101, 360] loss: 0.142\n",
      "Epoch: 101 -> Loss: 0.180552095175\n",
      "Epoch: 101 -> Test Accuracy: 90.5875\n",
      "[102, 60] loss: 0.127\n",
      "[102, 120] loss: 0.130\n",
      "[102, 180] loss: 0.137\n",
      "[102, 240] loss: 0.137\n",
      "[102, 300] loss: 0.145\n",
      "[102, 360] loss: 0.143\n",
      "Epoch: 102 -> Loss: 0.160800248384\n",
      "Epoch: 102 -> Test Accuracy: 90.92\n",
      "[103, 60] loss: 0.127\n",
      "[103, 120] loss: 0.136\n",
      "[103, 180] loss: 0.125\n",
      "[103, 240] loss: 0.134\n",
      "[103, 300] loss: 0.135\n",
      "[103, 360] loss: 0.147\n",
      "Epoch: 103 -> Loss: 0.116889819503\n",
      "Epoch: 103 -> Test Accuracy: 90.5275\n",
      "[104, 60] loss: 0.119\n",
      "[104, 120] loss: 0.133\n",
      "[104, 180] loss: 0.132\n",
      "[104, 240] loss: 0.138\n",
      "[104, 300] loss: 0.142\n",
      "[104, 360] loss: 0.145\n",
      "Epoch: 104 -> Loss: 0.200918585062\n",
      "Epoch: 104 -> Test Accuracy: 90.595\n",
      "[105, 60] loss: 0.132\n",
      "[105, 120] loss: 0.140\n",
      "[105, 180] loss: 0.134\n",
      "[105, 240] loss: 0.132\n",
      "[105, 300] loss: 0.138\n",
      "[105, 360] loss: 0.136\n",
      "Epoch: 105 -> Loss: 0.104610286653\n",
      "Epoch: 105 -> Test Accuracy: 90.485\n",
      "[106, 60] loss: 0.123\n",
      "[106, 120] loss: 0.134\n",
      "[106, 180] loss: 0.133\n",
      "[106, 240] loss: 0.149\n",
      "[106, 300] loss: 0.138\n",
      "[106, 360] loss: 0.132\n",
      "Epoch: 106 -> Loss: 0.130360633135\n",
      "Epoch: 106 -> Test Accuracy: 89.965\n",
      "[107, 60] loss: 0.129\n",
      "[107, 120] loss: 0.132\n",
      "[107, 180] loss: 0.125\n",
      "[107, 240] loss: 0.138\n",
      "[107, 300] loss: 0.140\n",
      "[107, 360] loss: 0.133\n",
      "Epoch: 107 -> Loss: 0.169668465853\n",
      "Epoch: 107 -> Test Accuracy: 90.6275\n",
      "[108, 60] loss: 0.121\n",
      "[108, 120] loss: 0.129\n",
      "[108, 180] loss: 0.127\n",
      "[108, 240] loss: 0.142\n",
      "[108, 300] loss: 0.129\n",
      "[108, 360] loss: 0.140\n",
      "Epoch: 108 -> Loss: 0.108999744058\n",
      "Epoch: 108 -> Test Accuracy: 90.2125\n",
      "[109, 60] loss: 0.125\n",
      "[109, 120] loss: 0.120\n",
      "[109, 180] loss: 0.135\n",
      "[109, 240] loss: 0.140\n",
      "[109, 300] loss: 0.132\n",
      "[109, 360] loss: 0.134\n",
      "Epoch: 109 -> Loss: 0.0899091660976\n",
      "Epoch: 109 -> Test Accuracy: 90.1775\n",
      "[110, 60] loss: 0.117\n",
      "[110, 120] loss: 0.134\n",
      "[110, 180] loss: 0.134\n",
      "[110, 240] loss: 0.139\n",
      "[110, 300] loss: 0.137\n",
      "[110, 360] loss: 0.140\n",
      "Epoch: 110 -> Loss: 0.102836310863\n",
      "Epoch: 110 -> Test Accuracy: 90.67\n",
      "[111, 60] loss: 0.123\n",
      "[111, 120] loss: 0.124\n",
      "[111, 180] loss: 0.137\n",
      "[111, 240] loss: 0.138\n",
      "[111, 300] loss: 0.129\n",
      "[111, 360] loss: 0.138\n",
      "Epoch: 111 -> Loss: 0.151582479477\n",
      "Epoch: 111 -> Test Accuracy: 90.7625\n",
      "[112, 60] loss: 0.127\n",
      "[112, 120] loss: 0.127\n",
      "[112, 180] loss: 0.126\n",
      "[112, 240] loss: 0.140\n",
      "[112, 300] loss: 0.142\n",
      "[112, 360] loss: 0.134\n",
      "Epoch: 112 -> Loss: 0.0810271203518\n",
      "Epoch: 112 -> Test Accuracy: 90.82\n",
      "[113, 60] loss: 0.118\n",
      "[113, 120] loss: 0.126\n",
      "[113, 180] loss: 0.127\n",
      "[113, 240] loss: 0.137\n",
      "[113, 300] loss: 0.141\n",
      "[113, 360] loss: 0.139\n",
      "Epoch: 113 -> Loss: 0.13760907948\n",
      "Epoch: 113 -> Test Accuracy: 90.65\n",
      "[114, 60] loss: 0.134\n",
      "[114, 120] loss: 0.118\n",
      "[114, 180] loss: 0.132\n",
      "[114, 240] loss: 0.130\n",
      "[114, 300] loss: 0.127\n",
      "[114, 360] loss: 0.139\n",
      "Epoch: 114 -> Loss: 0.174084663391\n",
      "Epoch: 114 -> Test Accuracy: 90.5075\n",
      "[115, 60] loss: 0.130\n",
      "[115, 120] loss: 0.124\n",
      "[115, 180] loss: 0.124\n",
      "[115, 240] loss: 0.136\n",
      "[115, 300] loss: 0.142\n",
      "[115, 360] loss: 0.137\n",
      "Epoch: 115 -> Loss: 0.133950278163\n",
      "Epoch: 115 -> Test Accuracy: 90.6025\n",
      "[116, 60] loss: 0.118\n",
      "[116, 120] loss: 0.129\n",
      "[116, 180] loss: 0.126\n",
      "[116, 240] loss: 0.132\n",
      "[116, 300] loss: 0.140\n",
      "[116, 360] loss: 0.143\n",
      "Epoch: 116 -> Loss: 0.123666666448\n",
      "Epoch: 116 -> Test Accuracy: 90.51\n",
      "[117, 60] loss: 0.118\n",
      "[117, 120] loss: 0.129\n",
      "[117, 180] loss: 0.132\n",
      "[117, 240] loss: 0.140\n",
      "[117, 300] loss: 0.129\n",
      "[117, 360] loss: 0.133\n",
      "Epoch: 117 -> Loss: 0.151506990194\n",
      "Epoch: 117 -> Test Accuracy: 90.2525\n",
      "[118, 60] loss: 0.119\n",
      "[118, 120] loss: 0.124\n",
      "[118, 180] loss: 0.133\n",
      "[118, 240] loss: 0.133\n",
      "[118, 300] loss: 0.134\n",
      "[118, 360] loss: 0.134\n",
      "Epoch: 118 -> Loss: 0.177436128259\n",
      "Epoch: 118 -> Test Accuracy: 90.375\n",
      "[119, 60] loss: 0.123\n",
      "[119, 120] loss: 0.131\n",
      "[119, 180] loss: 0.129\n",
      "[119, 240] loss: 0.128\n",
      "[119, 300] loss: 0.133\n",
      "[119, 360] loss: 0.131\n",
      "Epoch: 119 -> Loss: 0.204024404287\n",
      "Epoch: 119 -> Test Accuracy: 90.6725\n",
      "[120, 60] loss: 0.124\n",
      "[120, 120] loss: 0.135\n",
      "[120, 180] loss: 0.124\n",
      "[120, 240] loss: 0.126\n",
      "[120, 300] loss: 0.135\n",
      "[120, 360] loss: 0.143\n",
      "Epoch: 120 -> Loss: 0.149588868022\n",
      "Epoch: 120 -> Test Accuracy: 91.1225\n",
      "[121, 60] loss: 0.095\n",
      "[121, 120] loss: 0.075\n",
      "[121, 180] loss: 0.068\n",
      "[121, 240] loss: 0.068\n",
      "[121, 300] loss: 0.063\n",
      "[121, 360] loss: 0.065\n",
      "Epoch: 121 -> Loss: 0.0463750883937\n",
      "Epoch: 121 -> Test Accuracy: 92.4175\n",
      "[122, 60] loss: 0.056\n",
      "[122, 120] loss: 0.054\n",
      "[122, 180] loss: 0.059\n",
      "[122, 240] loss: 0.056\n",
      "[122, 300] loss: 0.052\n",
      "[122, 360] loss: 0.056\n",
      "Epoch: 122 -> Loss: 0.0309983380139\n",
      "Epoch: 122 -> Test Accuracy: 92.55\n",
      "[123, 60] loss: 0.049\n",
      "[123, 120] loss: 0.048\n",
      "[123, 180] loss: 0.050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123, 240] loss: 0.047\n",
      "[123, 300] loss: 0.048\n",
      "[123, 360] loss: 0.046\n",
      "Epoch: 123 -> Loss: 0.0228638090193\n",
      "Epoch: 123 -> Test Accuracy: 92.5825\n",
      "[124, 60] loss: 0.044\n",
      "[124, 120] loss: 0.045\n",
      "[124, 180] loss: 0.042\n",
      "[124, 240] loss: 0.047\n",
      "[124, 300] loss: 0.043\n",
      "[124, 360] loss: 0.046\n",
      "Epoch: 124 -> Loss: 0.032440982759\n",
      "Epoch: 124 -> Test Accuracy: 92.4675\n",
      "[125, 60] loss: 0.039\n",
      "[125, 120] loss: 0.041\n",
      "[125, 180] loss: 0.039\n",
      "[125, 240] loss: 0.039\n",
      "[125, 300] loss: 0.038\n",
      "[125, 360] loss: 0.041\n",
      "Epoch: 125 -> Loss: 0.0157813932747\n",
      "Epoch: 125 -> Test Accuracy: 92.535\n",
      "[126, 60] loss: 0.037\n",
      "[126, 120] loss: 0.033\n",
      "[126, 180] loss: 0.039\n",
      "[126, 240] loss: 0.039\n",
      "[126, 300] loss: 0.040\n",
      "[126, 360] loss: 0.037\n",
      "Epoch: 126 -> Loss: 0.0508316271007\n",
      "Epoch: 126 -> Test Accuracy: 92.5525\n",
      "[127, 60] loss: 0.032\n",
      "[127, 120] loss: 0.035\n",
      "[127, 180] loss: 0.038\n",
      "[127, 240] loss: 0.036\n",
      "[127, 300] loss: 0.037\n",
      "[127, 360] loss: 0.036\n",
      "Epoch: 127 -> Loss: 0.0440130233765\n",
      "Epoch: 127 -> Test Accuracy: 92.5325\n",
      "[128, 60] loss: 0.031\n",
      "[128, 120] loss: 0.033\n",
      "[128, 180] loss: 0.035\n",
      "[128, 240] loss: 0.032\n",
      "[128, 300] loss: 0.031\n",
      "[128, 360] loss: 0.035\n",
      "Epoch: 128 -> Loss: 0.0272819213569\n",
      "Epoch: 128 -> Test Accuracy: 92.575\n",
      "[129, 60] loss: 0.030\n",
      "[129, 120] loss: 0.030\n",
      "[129, 180] loss: 0.034\n",
      "[129, 240] loss: 0.031\n",
      "[129, 300] loss: 0.031\n",
      "[129, 360] loss: 0.034\n",
      "Epoch: 129 -> Loss: 0.0569029524922\n",
      "Epoch: 129 -> Test Accuracy: 92.5175\n",
      "[130, 60] loss: 0.029\n",
      "[130, 120] loss: 0.031\n",
      "[130, 180] loss: 0.034\n",
      "[130, 240] loss: 0.026\n",
      "[130, 300] loss: 0.031\n",
      "[130, 360] loss: 0.031\n",
      "Epoch: 130 -> Loss: 0.036101013422\n",
      "Epoch: 130 -> Test Accuracy: 92.505\n",
      "[131, 60] loss: 0.028\n",
      "[131, 120] loss: 0.029\n",
      "[131, 180] loss: 0.033\n",
      "[131, 240] loss: 0.029\n",
      "[131, 300] loss: 0.031\n",
      "[131, 360] loss: 0.029\n",
      "Epoch: 131 -> Loss: 0.11333425343\n",
      "Epoch: 131 -> Test Accuracy: 92.4325\n",
      "[132, 60] loss: 0.027\n",
      "[132, 120] loss: 0.030\n",
      "[132, 180] loss: 0.030\n",
      "[132, 240] loss: 0.032\n",
      "[132, 300] loss: 0.031\n",
      "[132, 360] loss: 0.031\n",
      "Epoch: 132 -> Loss: 0.0187119729817\n",
      "Epoch: 132 -> Test Accuracy: 92.445\n",
      "[133, 60] loss: 0.025\n",
      "[133, 120] loss: 0.029\n",
      "[133, 180] loss: 0.028\n",
      "[133, 240] loss: 0.032\n",
      "[133, 300] loss: 0.029\n",
      "[133, 360] loss: 0.030\n",
      "Epoch: 133 -> Loss: 0.0253859069198\n",
      "Epoch: 133 -> Test Accuracy: 92.4175\n",
      "[134, 60] loss: 0.029\n",
      "[134, 120] loss: 0.027\n",
      "[134, 180] loss: 0.028\n",
      "[134, 240] loss: 0.027\n",
      "[134, 300] loss: 0.030\n",
      "[134, 360] loss: 0.028\n",
      "Epoch: 134 -> Loss: 0.0226332247257\n",
      "Epoch: 134 -> Test Accuracy: 92.28\n",
      "[135, 60] loss: 0.026\n",
      "[135, 120] loss: 0.028\n",
      "[135, 180] loss: 0.025\n",
      "[135, 240] loss: 0.028\n",
      "[135, 300] loss: 0.030\n",
      "[135, 360] loss: 0.028\n",
      "Epoch: 135 -> Loss: 0.0399969294667\n",
      "Epoch: 135 -> Test Accuracy: 92.2075\n",
      "[136, 60] loss: 0.026\n",
      "[136, 120] loss: 0.025\n",
      "[136, 180] loss: 0.025\n",
      "[136, 240] loss: 0.026\n",
      "[136, 300] loss: 0.027\n",
      "[136, 360] loss: 0.029\n",
      "Epoch: 136 -> Loss: 0.0469338521361\n",
      "Epoch: 136 -> Test Accuracy: 92.6175\n",
      "[137, 60] loss: 0.025\n",
      "[137, 120] loss: 0.025\n",
      "[137, 180] loss: 0.026\n",
      "[137, 240] loss: 0.026\n",
      "[137, 300] loss: 0.028\n",
      "[137, 360] loss: 0.026\n",
      "Epoch: 137 -> Loss: 0.0720406770706\n",
      "Epoch: 137 -> Test Accuracy: 92.1825\n",
      "[138, 60] loss: 0.024\n",
      "[138, 120] loss: 0.024\n",
      "[138, 180] loss: 0.023\n",
      "[138, 240] loss: 0.022\n",
      "[138, 300] loss: 0.027\n",
      "[138, 360] loss: 0.029\n",
      "Epoch: 138 -> Loss: 0.0252997037023\n",
      "Epoch: 138 -> Test Accuracy: 92.3825\n",
      "[139, 60] loss: 0.023\n",
      "[139, 120] loss: 0.023\n",
      "[139, 180] loss: 0.026\n",
      "[139, 240] loss: 0.021\n",
      "[139, 300] loss: 0.025\n",
      "[139, 360] loss: 0.029\n",
      "Epoch: 139 -> Loss: 0.027771089226\n",
      "Epoch: 139 -> Test Accuracy: 92.4575\n",
      "[140, 60] loss: 0.024\n",
      "[140, 120] loss: 0.023\n",
      "[140, 180] loss: 0.026\n",
      "[140, 240] loss: 0.025\n",
      "[140, 300] loss: 0.025\n",
      "[140, 360] loss: 0.027\n",
      "Epoch: 140 -> Loss: 0.0185356475413\n",
      "Epoch: 140 -> Test Accuracy: 92.32\n",
      "[141, 60] loss: 0.023\n",
      "[141, 120] loss: 0.023\n",
      "[141, 180] loss: 0.022\n",
      "[141, 240] loss: 0.024\n",
      "[141, 300] loss: 0.027\n",
      "[141, 360] loss: 0.026\n",
      "Epoch: 141 -> Loss: 0.0407850556076\n",
      "Epoch: 141 -> Test Accuracy: 92.07\n",
      "[142, 60] loss: 0.023\n",
      "[142, 120] loss: 0.023\n",
      "[142, 180] loss: 0.025\n",
      "[142, 240] loss: 0.026\n",
      "[142, 300] loss: 0.028\n",
      "[142, 360] loss: 0.026\n",
      "Epoch: 142 -> Loss: 0.0341884121299\n",
      "Epoch: 142 -> Test Accuracy: 92.1725\n",
      "[143, 60] loss: 0.021\n",
      "[143, 120] loss: 0.022\n",
      "[143, 180] loss: 0.027\n",
      "[143, 240] loss: 0.024\n",
      "[143, 300] loss: 0.026\n",
      "[143, 360] loss: 0.026\n",
      "Epoch: 143 -> Loss: 0.0246761534363\n",
      "Epoch: 143 -> Test Accuracy: 91.865\n",
      "[144, 60] loss: 0.025\n",
      "[144, 120] loss: 0.023\n",
      "[144, 180] loss: 0.025\n",
      "[144, 240] loss: 0.023\n",
      "[144, 300] loss: 0.027\n",
      "[144, 360] loss: 0.023\n",
      "Epoch: 144 -> Loss: 0.0208922885358\n",
      "Epoch: 144 -> Test Accuracy: 92.1525\n",
      "[145, 60] loss: 0.022\n",
      "[145, 120] loss: 0.023\n",
      "[145, 180] loss: 0.024\n",
      "[145, 240] loss: 0.025\n",
      "[145, 300] loss: 0.027\n",
      "[145, 360] loss: 0.026\n",
      "Epoch: 145 -> Loss: 0.021285187453\n",
      "Epoch: 145 -> Test Accuracy: 92.16\n",
      "[146, 60] loss: 0.023\n",
      "[146, 120] loss: 0.021\n",
      "[146, 180] loss: 0.024\n",
      "[146, 240] loss: 0.023\n",
      "[146, 300] loss: 0.023\n",
      "[146, 360] loss: 0.024\n",
      "Epoch: 146 -> Loss: 0.0307263489813\n",
      "Epoch: 146 -> Test Accuracy: 92.035\n",
      "[147, 60] loss: 0.023\n",
      "[147, 120] loss: 0.023\n",
      "[147, 180] loss: 0.022\n",
      "[147, 240] loss: 0.025\n",
      "[147, 300] loss: 0.025\n",
      "[147, 360] loss: 0.027\n",
      "Epoch: 147 -> Loss: 0.0193719528615\n",
      "Epoch: 147 -> Test Accuracy: 92.09\n",
      "[148, 60] loss: 0.024\n",
      "[148, 120] loss: 0.024\n",
      "[148, 180] loss: 0.025\n",
      "[148, 240] loss: 0.023\n",
      "[148, 300] loss: 0.024\n",
      "[148, 360] loss: 0.024\n",
      "Epoch: 148 -> Loss: 0.0235477648675\n",
      "Epoch: 148 -> Test Accuracy: 92.205\n",
      "[149, 60] loss: 0.022\n",
      "[149, 120] loss: 0.022\n",
      "[149, 180] loss: 0.025\n",
      "[149, 240] loss: 0.026\n",
      "[149, 300] loss: 0.026\n",
      "[149, 360] loss: 0.024\n",
      "Epoch: 149 -> Loss: 0.0187628548592\n",
      "Epoch: 149 -> Test Accuracy: 92.2325\n",
      "[150, 60] loss: 0.026\n",
      "[150, 120] loss: 0.023\n",
      "[150, 180] loss: 0.024\n",
      "[150, 240] loss: 0.021\n",
      "[150, 300] loss: 0.024\n",
      "[150, 360] loss: 0.027\n",
      "Epoch: 150 -> Loss: 0.0298950411379\n",
      "Epoch: 150 -> Test Accuracy: 92.1525\n",
      "[151, 60] loss: 0.023\n",
      "[151, 120] loss: 0.027\n",
      "[151, 180] loss: 0.021\n",
      "[151, 240] loss: 0.023\n",
      "[151, 300] loss: 0.025\n",
      "[151, 360] loss: 0.024\n",
      "Epoch: 151 -> Loss: 0.0108523461968\n",
      "Epoch: 151 -> Test Accuracy: 91.8825\n",
      "[152, 60] loss: 0.023\n",
      "[152, 120] loss: 0.023\n",
      "[152, 180] loss: 0.023\n",
      "[152, 240] loss: 0.026\n",
      "[152, 300] loss: 0.027\n",
      "[152, 360] loss: 0.030\n",
      "Epoch: 152 -> Loss: 0.0359091572464\n",
      "Epoch: 152 -> Test Accuracy: 91.9175\n",
      "[153, 60] loss: 0.024\n",
      "[153, 120] loss: 0.024\n",
      "[153, 180] loss: 0.025\n",
      "[153, 240] loss: 0.026\n",
      "[153, 300] loss: 0.023\n",
      "[153, 360] loss: 0.024\n",
      "Epoch: 153 -> Loss: 0.0175263304263\n",
      "Epoch: 153 -> Test Accuracy: 91.9575\n",
      "[154, 60] loss: 0.023\n",
      "[154, 120] loss: 0.022\n",
      "[154, 180] loss: 0.023\n",
      "[154, 240] loss: 0.025\n",
      "[154, 300] loss: 0.026\n",
      "[154, 360] loss: 0.028\n",
      "Epoch: 154 -> Loss: 0.0346248075366\n",
      "Epoch: 154 -> Test Accuracy: 91.9975\n",
      "[155, 60] loss: 0.025\n",
      "[155, 120] loss: 0.025\n",
      "[155, 180] loss: 0.025\n",
      "[155, 240] loss: 0.024\n",
      "[155, 300] loss: 0.025\n",
      "[155, 360] loss: 0.028\n",
      "Epoch: 155 -> Loss: 0.026807224378\n",
      "Epoch: 155 -> Test Accuracy: 91.905\n",
      "[156, 60] loss: 0.026\n",
      "[156, 120] loss: 0.023\n",
      "[156, 180] loss: 0.022\n",
      "[156, 240] loss: 0.026\n",
      "[156, 300] loss: 0.030\n",
      "[156, 360] loss: 0.026\n",
      "Epoch: 156 -> Loss: 0.0134270368144\n",
      "Epoch: 156 -> Test Accuracy: 92.0375\n",
      "[157, 60] loss: 0.023\n",
      "[157, 120] loss: 0.024\n",
      "[157, 180] loss: 0.025\n",
      "[157, 240] loss: 0.026\n",
      "[157, 300] loss: 0.027\n",
      "[157, 360] loss: 0.027\n",
      "Epoch: 157 -> Loss: 0.0234397388995\n",
      "Epoch: 157 -> Test Accuracy: 91.7925\n",
      "[158, 60] loss: 0.022\n",
      "[158, 120] loss: 0.024\n",
      "[158, 180] loss: 0.029\n",
      "[158, 240] loss: 0.025\n",
      "[158, 300] loss: 0.024\n",
      "[158, 360] loss: 0.027\n",
      "Epoch: 158 -> Loss: 0.0457395389676\n",
      "Epoch: 158 -> Test Accuracy: 91.7475\n",
      "[159, 60] loss: 0.024\n",
      "[159, 120] loss: 0.028\n",
      "[159, 180] loss: 0.025\n",
      "[159, 240] loss: 0.025\n",
      "[159, 300] loss: 0.026\n",
      "[159, 360] loss: 0.027\n",
      "Epoch: 159 -> Loss: 0.00993794761598\n",
      "Epoch: 159 -> Test Accuracy: 91.925\n",
      "[160, 60] loss: 0.024\n",
      "[160, 120] loss: 0.023\n",
      "[160, 180] loss: 0.025\n",
      "[160, 240] loss: 0.027\n",
      "[160, 300] loss: 0.030\n",
      "[160, 360] loss: 0.027\n",
      "Epoch: 160 -> Loss: 0.02675620839\n",
      "Epoch: 160 -> Test Accuracy: 91.74\n",
      "[161, 60] loss: 0.020\n",
      "[161, 120] loss: 0.018\n",
      "[161, 180] loss: 0.016\n",
      "[161, 240] loss: 0.014\n",
      "[161, 300] loss: 0.015\n",
      "[161, 360] loss: 0.014\n",
      "Epoch: 161 -> Loss: 0.0249451454729\n",
      "Epoch: 161 -> Test Accuracy: 92.31\n",
      "[162, 60] loss: 0.013\n",
      "[162, 120] loss: 0.011\n",
      "[162, 180] loss: 0.012\n",
      "[162, 240] loss: 0.012\n",
      "[162, 300] loss: 0.011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[162, 360] loss: 0.013\n",
      "Epoch: 162 -> Loss: 0.0078805796802\n",
      "Epoch: 162 -> Test Accuracy: 92.2875\n",
      "[163, 60] loss: 0.012\n",
      "[163, 120] loss: 0.010\n",
      "[163, 180] loss: 0.011\n",
      "[163, 240] loss: 0.011\n",
      "[163, 300] loss: 0.011\n",
      "[163, 360] loss: 0.011\n",
      "Epoch: 163 -> Loss: 0.00940859504044\n",
      "Epoch: 163 -> Test Accuracy: 92.4025\n",
      "[164, 60] loss: 0.010\n",
      "[164, 120] loss: 0.010\n",
      "[164, 180] loss: 0.011\n",
      "[164, 240] loss: 0.009\n",
      "[164, 300] loss: 0.010\n",
      "[164, 360] loss: 0.010\n",
      "Epoch: 164 -> Loss: 0.0069149537012\n",
      "Epoch: 164 -> Test Accuracy: 92.4375\n",
      "[165, 60] loss: 0.009\n",
      "[165, 120] loss: 0.009\n",
      "[165, 180] loss: 0.011\n",
      "[165, 240] loss: 0.008\n",
      "[165, 300] loss: 0.010\n",
      "[165, 360] loss: 0.010\n",
      "Epoch: 165 -> Loss: 0.0208732225001\n",
      "Epoch: 165 -> Test Accuracy: 92.4625\n",
      "[166, 60] loss: 0.009\n",
      "[166, 120] loss: 0.009\n",
      "[166, 180] loss: 0.009\n",
      "[166, 240] loss: 0.010\n",
      "[166, 300] loss: 0.008\n",
      "[166, 360] loss: 0.011\n",
      "Epoch: 166 -> Loss: 0.0108460579067\n",
      "Epoch: 166 -> Test Accuracy: 92.3875\n",
      "[167, 60] loss: 0.009\n",
      "[167, 120] loss: 0.008\n",
      "[167, 180] loss: 0.008\n",
      "[167, 240] loss: 0.009\n",
      "[167, 300] loss: 0.009\n",
      "[167, 360] loss: 0.010\n",
      "Epoch: 167 -> Loss: 0.00746094807982\n",
      "Epoch: 167 -> Test Accuracy: 92.4875\n",
      "[168, 60] loss: 0.008\n",
      "[168, 120] loss: 0.008\n",
      "[168, 180] loss: 0.008\n",
      "[168, 240] loss: 0.009\n",
      "[168, 300] loss: 0.008\n",
      "[168, 360] loss: 0.008\n",
      "Epoch: 168 -> Loss: 0.00780395930633\n",
      "Epoch: 168 -> Test Accuracy: 92.355\n",
      "[169, 60] loss: 0.008\n",
      "[169, 120] loss: 0.008\n",
      "[169, 180] loss: 0.008\n",
      "[169, 240] loss: 0.008\n",
      "[169, 300] loss: 0.007\n",
      "[169, 360] loss: 0.008\n",
      "Epoch: 169 -> Loss: 0.0204166229814\n",
      "Epoch: 169 -> Test Accuracy: 92.46\n",
      "[170, 60] loss: 0.007\n",
      "[170, 120] loss: 0.009\n",
      "[170, 180] loss: 0.008\n",
      "[170, 240] loss: 0.008\n",
      "[170, 300] loss: 0.008\n",
      "[170, 360] loss: 0.007\n",
      "Epoch: 170 -> Loss: 0.0104831410572\n",
      "Epoch: 170 -> Test Accuracy: 92.55\n",
      "[171, 60] loss: 0.008\n",
      "[171, 120] loss: 0.008\n",
      "[171, 180] loss: 0.009\n",
      "[171, 240] loss: 0.008\n",
      "[171, 300] loss: 0.008\n",
      "[171, 360] loss: 0.008\n",
      "Epoch: 171 -> Loss: 0.00669729104266\n",
      "Epoch: 171 -> Test Accuracy: 92.475\n",
      "[172, 60] loss: 0.007\n",
      "[172, 120] loss: 0.008\n",
      "[172, 180] loss: 0.008\n",
      "[172, 240] loss: 0.008\n",
      "[172, 300] loss: 0.008\n",
      "[172, 360] loss: 0.007\n",
      "Epoch: 172 -> Loss: 0.0101674329489\n",
      "Epoch: 172 -> Test Accuracy: 92.425\n",
      "[173, 60] loss: 0.007\n",
      "[173, 120] loss: 0.008\n",
      "[173, 180] loss: 0.007\n",
      "[173, 240] loss: 0.007\n",
      "[173, 300] loss: 0.007\n",
      "[173, 360] loss: 0.007\n",
      "Epoch: 173 -> Loss: 0.00870885513723\n",
      "Epoch: 173 -> Test Accuracy: 92.4175\n",
      "[174, 60] loss: 0.007\n",
      "[174, 120] loss: 0.007\n",
      "[174, 180] loss: 0.008\n",
      "[174, 240] loss: 0.007\n",
      "[174, 300] loss: 0.007\n",
      "[174, 360] loss: 0.008\n",
      "Epoch: 174 -> Loss: 0.00530012557283\n",
      "Epoch: 174 -> Test Accuracy: 92.4725\n",
      "[175, 60] loss: 0.007\n",
      "[175, 120] loss: 0.007\n",
      "[175, 180] loss: 0.007\n",
      "[175, 240] loss: 0.007\n",
      "[175, 300] loss: 0.008\n",
      "[175, 360] loss: 0.007\n",
      "Epoch: 175 -> Loss: 0.00573242362589\n",
      "Epoch: 175 -> Test Accuracy: 92.3075\n",
      "[176, 60] loss: 0.006\n",
      "[176, 120] loss: 0.007\n",
      "[176, 180] loss: 0.007\n",
      "[176, 240] loss: 0.007\n",
      "[176, 300] loss: 0.007\n",
      "[176, 360] loss: 0.007\n",
      "Epoch: 176 -> Loss: 0.009098501876\n",
      "Epoch: 176 -> Test Accuracy: 92.345\n",
      "[177, 60] loss: 0.007\n",
      "[177, 120] loss: 0.006\n",
      "[177, 180] loss: 0.007\n",
      "[177, 240] loss: 0.006\n",
      "[177, 300] loss: 0.007\n",
      "[177, 360] loss: 0.007\n",
      "Epoch: 177 -> Loss: 0.00370613858104\n",
      "Epoch: 177 -> Test Accuracy: 92.4225\n",
      "[178, 60] loss: 0.007\n",
      "[178, 120] loss: 0.007\n",
      "[178, 180] loss: 0.006\n",
      "[178, 240] loss: 0.006\n",
      "[178, 300] loss: 0.008\n",
      "[178, 360] loss: 0.007\n",
      "Epoch: 178 -> Loss: 0.00418675690889\n",
      "Epoch: 178 -> Test Accuracy: 92.43\n",
      "[179, 60] loss: 0.007\n",
      "[179, 120] loss: 0.007\n",
      "[179, 180] loss: 0.006\n",
      "[179, 240] loss: 0.006\n",
      "[179, 300] loss: 0.006\n",
      "[179, 360] loss: 0.007\n",
      "Epoch: 179 -> Loss: 0.00536827277392\n",
      "Epoch: 179 -> Test Accuracy: 92.3675\n",
      "[180, 60] loss: 0.006\n",
      "[180, 120] loss: 0.006\n",
      "[180, 180] loss: 0.007\n",
      "[180, 240] loss: 0.006\n",
      "[180, 300] loss: 0.007\n",
      "[180, 360] loss: 0.006\n",
      "Epoch: 180 -> Loss: 0.0103755053133\n",
      "Epoch: 180 -> Test Accuracy: 92.4075\n",
      "[181, 60] loss: 0.006\n",
      "[181, 120] loss: 0.007\n",
      "[181, 180] loss: 0.006\n",
      "[181, 240] loss: 0.006\n",
      "[181, 300] loss: 0.006\n",
      "[181, 360] loss: 0.006\n",
      "Epoch: 181 -> Loss: 0.0030746825505\n",
      "Epoch: 181 -> Test Accuracy: 92.4075\n",
      "[182, 60] loss: 0.006\n",
      "[182, 120] loss: 0.006\n",
      "[182, 180] loss: 0.006\n",
      "[182, 240] loss: 0.007\n",
      "[182, 300] loss: 0.006\n",
      "[182, 360] loss: 0.006\n",
      "Epoch: 182 -> Loss: 0.00637945812196\n",
      "Epoch: 182 -> Test Accuracy: 92.3375\n",
      "[183, 60] loss: 0.006\n",
      "[183, 120] loss: 0.006\n",
      "[183, 180] loss: 0.006\n",
      "[183, 240] loss: 0.006\n",
      "[183, 300] loss: 0.006\n",
      "[183, 360] loss: 0.006\n",
      "Epoch: 183 -> Loss: 0.00946585740894\n",
      "Epoch: 183 -> Test Accuracy: 92.3225\n",
      "[184, 60] loss: 0.007\n",
      "[184, 120] loss: 0.005\n",
      "[184, 180] loss: 0.006\n",
      "[184, 240] loss: 0.006\n",
      "[184, 300] loss: 0.006\n",
      "[184, 360] loss: 0.006\n",
      "Epoch: 184 -> Loss: 0.00522606959566\n",
      "Epoch: 184 -> Test Accuracy: 92.41\n",
      "[185, 60] loss: 0.006\n",
      "[185, 120] loss: 0.006\n",
      "[185, 180] loss: 0.006\n",
      "[185, 240] loss: 0.006\n",
      "[185, 300] loss: 0.006\n",
      "[185, 360] loss: 0.006\n",
      "Epoch: 185 -> Loss: 0.0103128952906\n",
      "Epoch: 185 -> Test Accuracy: 92.405\n",
      "[186, 60] loss: 0.005\n",
      "[186, 120] loss: 0.006\n",
      "[186, 180] loss: 0.006\n",
      "[186, 240] loss: 0.006\n",
      "[186, 300] loss: 0.006\n",
      "[186, 360] loss: 0.006\n",
      "Epoch: 186 -> Loss: 0.00342901656404\n",
      "Epoch: 186 -> Test Accuracy: 92.48\n",
      "[187, 60] loss: 0.005\n",
      "[187, 120] loss: 0.006\n",
      "[187, 180] loss: 0.006\n",
      "[187, 240] loss: 0.006\n",
      "[187, 300] loss: 0.006\n",
      "[187, 360] loss: 0.005\n",
      "Epoch: 187 -> Loss: 0.00499102752656\n",
      "Epoch: 187 -> Test Accuracy: 92.5225\n",
      "[188, 60] loss: 0.005\n",
      "[188, 120] loss: 0.005\n",
      "[188, 180] loss: 0.006\n",
      "[188, 240] loss: 0.005\n",
      "[188, 300] loss: 0.006\n",
      "[188, 360] loss: 0.006\n",
      "Epoch: 188 -> Loss: 0.00427847728133\n",
      "Epoch: 188 -> Test Accuracy: 92.4675\n",
      "[189, 60] loss: 0.006\n",
      "[189, 120] loss: 0.006\n",
      "[189, 180] loss: 0.005\n",
      "[189, 240] loss: 0.005\n",
      "[189, 300] loss: 0.006\n",
      "[189, 360] loss: 0.006\n",
      "Epoch: 189 -> Loss: 0.00554900337011\n",
      "Epoch: 189 -> Test Accuracy: 92.5175\n",
      "[190, 60] loss: 0.006\n",
      "[190, 120] loss: 0.006\n",
      "[190, 180] loss: 0.006\n",
      "[190, 240] loss: 0.006\n",
      "[190, 300] loss: 0.006\n",
      "[190, 360] loss: 0.006\n",
      "Epoch: 190 -> Loss: 0.00808160379529\n",
      "Epoch: 190 -> Test Accuracy: 92.525\n",
      "[191, 60] loss: 0.005\n",
      "[191, 120] loss: 0.006\n",
      "[191, 180] loss: 0.005\n",
      "[191, 240] loss: 0.006\n",
      "[191, 300] loss: 0.006\n",
      "[191, 360] loss: 0.005\n",
      "Epoch: 191 -> Loss: 0.00242019956931\n",
      "Epoch: 191 -> Test Accuracy: 92.5075\n",
      "[192, 60] loss: 0.006\n",
      "[192, 120] loss: 0.005\n",
      "[192, 180] loss: 0.006\n",
      "[192, 240] loss: 0.006\n",
      "[192, 300] loss: 0.006\n",
      "[192, 360] loss: 0.005\n",
      "Epoch: 192 -> Loss: 0.00493824202567\n",
      "Epoch: 192 -> Test Accuracy: 92.565\n",
      "[193, 60] loss: 0.006\n",
      "[193, 120] loss: 0.005\n",
      "[193, 180] loss: 0.006\n",
      "[193, 240] loss: 0.006\n",
      "[193, 300] loss: 0.005\n",
      "[193, 360] loss: 0.005\n",
      "Epoch: 193 -> Loss: 0.00681554060429\n",
      "Epoch: 193 -> Test Accuracy: 92.47\n",
      "[194, 60] loss: 0.005\n",
      "[194, 120] loss: 0.005\n",
      "[194, 180] loss: 0.005\n",
      "[194, 240] loss: 0.005\n",
      "[194, 300] loss: 0.006\n",
      "[194, 360] loss: 0.006\n",
      "Epoch: 194 -> Loss: 0.00583994435146\n",
      "Epoch: 194 -> Test Accuracy: 92.3775\n",
      "[195, 60] loss: 0.005\n",
      "[195, 120] loss: 0.005\n",
      "[195, 180] loss: 0.005\n",
      "[195, 240] loss: 0.005\n",
      "[195, 300] loss: 0.005\n",
      "[195, 360] loss: 0.005\n",
      "Epoch: 195 -> Loss: 0.0176346562803\n",
      "Epoch: 195 -> Test Accuracy: 92.49\n",
      "[196, 60] loss: 0.005\n",
      "[196, 120] loss: 0.005\n",
      "[196, 180] loss: 0.006\n",
      "[196, 240] loss: 0.005\n",
      "[196, 300] loss: 0.005\n",
      "[196, 360] loss: 0.006\n",
      "Epoch: 196 -> Loss: 0.00446013081819\n",
      "Epoch: 196 -> Test Accuracy: 92.5275\n",
      "[197, 60] loss: 0.006\n",
      "[197, 120] loss: 0.006\n",
      "[197, 180] loss: 0.005\n",
      "[197, 240] loss: 0.005\n",
      "[197, 300] loss: 0.005\n",
      "[197, 360] loss: 0.006\n",
      "Epoch: 197 -> Loss: 0.00411885883659\n",
      "Epoch: 197 -> Test Accuracy: 92.5\n",
      "[198, 60] loss: 0.005\n",
      "[198, 120] loss: 0.005\n",
      "[198, 180] loss: 0.006\n",
      "[198, 240] loss: 0.006\n",
      "[198, 300] loss: 0.005\n",
      "[198, 360] loss: 0.004\n",
      "Epoch: 198 -> Loss: 0.00713303592056\n",
      "Epoch: 198 -> Test Accuracy: 92.455\n",
      "[199, 60] loss: 0.006\n",
      "[199, 120] loss: 0.006\n",
      "[199, 180] loss: 0.005\n",
      "[199, 240] loss: 0.005\n",
      "[199, 300] loss: 0.005\n",
      "[199, 360] loss: 0.006\n",
      "Epoch: 199 -> Loss: 0.00838072318584\n",
      "Epoch: 199 -> Test Accuracy: 92.39\n",
      "[200, 60] loss: 0.005\n",
      "[200, 120] loss: 0.006\n",
      "[200, 180] loss: 0.005\n",
      "[200, 240] loss: 0.006\n",
      "[200, 300] loss: 0.005\n",
      "[200, 360] loss: 0.005\n",
      "Epoch: 200 -> Loss: 0.00303649227135\n",
      "Epoch: 200 -> Test Accuracy: 92.5725\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "rot_block4_loss_log, _, rot_block4_test_accuracy_log, _, _ = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], \n",
    "    [60, 120, 160, 200], 0.9, 5e-4, net_block4, criterion, trainloader, None, testloader, rot=['90', '180', '270'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 2.238\n",
      "[1, 120] loss: 1.261\n",
      "[1, 180] loss: 1.156\n",
      "[1, 240] loss: 1.097\n",
      "[1, 300] loss: 1.037\n",
      "[1, 360] loss: 1.002\n",
      "Epoch: 1 -> Loss: 0.864320397377\n",
      "Epoch: 1 -> Test Accuracy: 67.59\n",
      "[2, 60] loss: 0.958\n",
      "[2, 120] loss: 0.947\n",
      "[2, 180] loss: 0.895\n",
      "[2, 240] loss: 0.903\n",
      "[2, 300] loss: 0.886\n",
      "[2, 360] loss: 0.873\n",
      "Epoch: 2 -> Loss: 0.746971905231\n",
      "Epoch: 2 -> Test Accuracy: 71.14\n",
      "[3, 60] loss: 0.795\n",
      "[3, 120] loss: 0.840\n",
      "[3, 180] loss: 0.824\n",
      "[3, 240] loss: 0.805\n",
      "[3, 300] loss: 0.822\n",
      "[3, 360] loss: 0.830\n",
      "Epoch: 3 -> Loss: 0.729731142521\n",
      "Epoch: 3 -> Test Accuracy: 73.89\n",
      "[4, 60] loss: 0.808\n",
      "[4, 120] loss: 0.759\n",
      "[4, 180] loss: 0.779\n",
      "[4, 240] loss: 0.755\n",
      "[4, 300] loss: 0.752\n",
      "[4, 360] loss: 0.766\n",
      "Epoch: 4 -> Loss: 0.678737938404\n",
      "Epoch: 4 -> Test Accuracy: 74.01\n",
      "[5, 60] loss: 0.738\n",
      "[5, 120] loss: 0.744\n",
      "[5, 180] loss: 0.750\n",
      "[5, 240] loss: 0.730\n",
      "[5, 300] loss: 0.733\n",
      "[5, 360] loss: 0.737\n",
      "Epoch: 5 -> Loss: 0.692242085934\n",
      "Epoch: 5 -> Test Accuracy: 75.33\n",
      "[6, 60] loss: 0.703\n",
      "[6, 120] loss: 0.700\n",
      "[6, 180] loss: 0.719\n",
      "[6, 240] loss: 0.713\n",
      "[6, 300] loss: 0.717\n",
      "[6, 360] loss: 0.703\n",
      "Epoch: 6 -> Loss: 0.89252024889\n",
      "Epoch: 6 -> Test Accuracy: 76.11\n",
      "[7, 60] loss: 0.695\n",
      "[7, 120] loss: 0.679\n",
      "[7, 180] loss: 0.721\n",
      "[7, 240] loss: 0.690\n",
      "[7, 300] loss: 0.699\n",
      "[7, 360] loss: 0.683\n",
      "Epoch: 7 -> Loss: 0.829494178295\n",
      "Epoch: 7 -> Test Accuracy: 75.69\n",
      "[8, 60] loss: 0.686\n",
      "[8, 120] loss: 0.663\n",
      "[8, 180] loss: 0.672\n",
      "[8, 240] loss: 0.667\n",
      "[8, 300] loss: 0.679\n",
      "[8, 360] loss: 0.711\n",
      "Epoch: 8 -> Loss: 0.504419445992\n",
      "Epoch: 8 -> Test Accuracy: 77.04\n",
      "[9, 60] loss: 0.655\n",
      "[9, 120] loss: 0.645\n",
      "[9, 180] loss: 0.663\n",
      "[9, 240] loss: 0.659\n",
      "[9, 300] loss: 0.683\n",
      "[9, 360] loss: 0.682\n",
      "Epoch: 9 -> Loss: 0.684047281742\n",
      "Epoch: 9 -> Test Accuracy: 77.07\n",
      "[10, 60] loss: 0.648\n",
      "[10, 120] loss: 0.655\n",
      "[10, 180] loss: 0.648\n",
      "[10, 240] loss: 0.666\n",
      "[10, 300] loss: 0.652\n",
      "[10, 360] loss: 0.675\n",
      "Epoch: 10 -> Loss: 0.687480807304\n",
      "Epoch: 10 -> Test Accuracy: 77.46\n",
      "[11, 60] loss: 0.636\n",
      "[11, 120] loss: 0.654\n",
      "[11, 180] loss: 0.644\n",
      "[11, 240] loss: 0.635\n",
      "[11, 300] loss: 0.639\n",
      "[11, 360] loss: 0.681\n",
      "Epoch: 11 -> Loss: 0.629271090031\n",
      "Epoch: 11 -> Test Accuracy: 77.2\n",
      "[12, 60] loss: 0.636\n",
      "[12, 120] loss: 0.628\n",
      "[12, 180] loss: 0.641\n",
      "[12, 240] loss: 0.647\n",
      "[12, 300] loss: 0.638\n",
      "[12, 360] loss: 0.672\n",
      "Epoch: 12 -> Loss: 0.648207306862\n",
      "Epoch: 12 -> Test Accuracy: 77.59\n",
      "[13, 60] loss: 0.611\n",
      "[13, 120] loss: 0.649\n",
      "[13, 180] loss: 0.628\n",
      "[13, 240] loss: 0.633\n",
      "[13, 300] loss: 0.638\n",
      "[13, 360] loss: 0.647\n",
      "Epoch: 13 -> Loss: 0.85742866993\n",
      "Epoch: 13 -> Test Accuracy: 77.55\n",
      "[14, 60] loss: 0.621\n",
      "[14, 120] loss: 0.621\n",
      "[14, 180] loss: 0.624\n",
      "[14, 240] loss: 0.618\n",
      "[14, 300] loss: 0.641\n",
      "[14, 360] loss: 0.650\n",
      "Epoch: 14 -> Loss: 0.68805283308\n",
      "Epoch: 14 -> Test Accuracy: 77.64\n",
      "[15, 60] loss: 0.610\n",
      "[15, 120] loss: 0.620\n",
      "[15, 180] loss: 0.635\n",
      "[15, 240] loss: 0.615\n",
      "[15, 300] loss: 0.651\n",
      "[15, 360] loss: 0.642\n",
      "Epoch: 15 -> Loss: 0.745658814907\n",
      "Epoch: 15 -> Test Accuracy: 78.01\n",
      "[16, 60] loss: 0.608\n",
      "[16, 120] loss: 0.619\n",
      "[16, 180] loss: 0.635\n",
      "[16, 240] loss: 0.612\n",
      "[16, 300] loss: 0.634\n",
      "[16, 360] loss: 0.645\n",
      "Epoch: 16 -> Loss: 0.538056135178\n",
      "Epoch: 16 -> Test Accuracy: 77.84\n",
      "[17, 60] loss: 0.603\n",
      "[17, 120] loss: 0.609\n",
      "[17, 180] loss: 0.629\n",
      "[17, 240] loss: 0.630\n",
      "[17, 300] loss: 0.635\n",
      "[17, 360] loss: 0.616\n",
      "Epoch: 17 -> Loss: 0.656677484512\n",
      "Epoch: 17 -> Test Accuracy: 78.38\n",
      "[18, 60] loss: 0.625\n",
      "[18, 120] loss: 0.613\n",
      "[18, 180] loss: 0.628\n",
      "[18, 240] loss: 0.622\n",
      "[18, 300] loss: 0.619\n",
      "[18, 360] loss: 0.630\n",
      "Epoch: 18 -> Loss: 0.569094777107\n",
      "Epoch: 18 -> Test Accuracy: 77.74\n",
      "[19, 60] loss: 0.608\n",
      "[19, 120] loss: 0.598\n",
      "[19, 180] loss: 0.601\n",
      "[19, 240] loss: 0.632\n",
      "[19, 300] loss: 0.608\n",
      "[19, 360] loss: 0.632\n",
      "Epoch: 19 -> Loss: 0.610912680626\n",
      "Epoch: 19 -> Test Accuracy: 78.51\n",
      "[20, 60] loss: 0.592\n",
      "[20, 120] loss: 0.600\n",
      "[20, 180] loss: 0.614\n",
      "[20, 240] loss: 0.625\n",
      "[20, 300] loss: 0.608\n",
      "[20, 360] loss: 0.634\n",
      "Epoch: 20 -> Loss: 0.762179970741\n",
      "Epoch: 20 -> Test Accuracy: 77.85\n",
      "[21, 60] loss: 0.565\n",
      "[21, 120] loss: 0.521\n",
      "[21, 180] loss: 0.517\n",
      "[21, 240] loss: 0.504\n",
      "[21, 300] loss: 0.503\n",
      "[21, 360] loss: 0.495\n",
      "Epoch: 21 -> Loss: 0.491512358189\n",
      "Epoch: 21 -> Test Accuracy: 80.53\n",
      "[22, 60] loss: 0.474\n",
      "[22, 120] loss: 0.481\n",
      "[22, 180] loss: 0.472\n",
      "[22, 240] loss: 0.478\n",
      "[22, 300] loss: 0.472\n",
      "[22, 360] loss: 0.488\n",
      "Epoch: 22 -> Loss: 0.396187931299\n",
      "Epoch: 22 -> Test Accuracy: 81.22\n",
      "[23, 60] loss: 0.449\n",
      "[23, 120] loss: 0.468\n",
      "[23, 180] loss: 0.453\n",
      "[23, 240] loss: 0.460\n",
      "[23, 300] loss: 0.460\n",
      "[23, 360] loss: 0.456\n",
      "Epoch: 23 -> Loss: 0.541031301022\n",
      "Epoch: 23 -> Test Accuracy: 80.76\n",
      "[24, 60] loss: 0.440\n",
      "[24, 120] loss: 0.446\n",
      "[24, 180] loss: 0.458\n",
      "[24, 240] loss: 0.453\n",
      "[24, 300] loss: 0.448\n",
      "[24, 360] loss: 0.432\n",
      "Epoch: 24 -> Loss: 0.330266803503\n",
      "Epoch: 24 -> Test Accuracy: 81.63\n",
      "[25, 60] loss: 0.446\n",
      "[25, 120] loss: 0.433\n",
      "[25, 180] loss: 0.443\n",
      "[25, 240] loss: 0.441\n",
      "[25, 300] loss: 0.446\n",
      "[25, 360] loss: 0.444\n",
      "Epoch: 25 -> Loss: 0.398762911558\n",
      "Epoch: 25 -> Test Accuracy: 81.52\n",
      "[26, 60] loss: 0.408\n",
      "[26, 120] loss: 0.429\n",
      "[26, 180] loss: 0.450\n",
      "[26, 240] loss: 0.416\n",
      "[26, 300] loss: 0.430\n",
      "[26, 360] loss: 0.434\n",
      "Epoch: 26 -> Loss: 0.54675000906\n",
      "Epoch: 26 -> Test Accuracy: 81.49\n",
      "[27, 60] loss: 0.415\n",
      "[27, 120] loss: 0.422\n",
      "[27, 180] loss: 0.432\n",
      "[27, 240] loss: 0.432\n",
      "[27, 300] loss: 0.425\n",
      "[27, 360] loss: 0.438\n",
      "Epoch: 27 -> Loss: 0.39271146059\n",
      "Epoch: 27 -> Test Accuracy: 81.27\n",
      "[28, 60] loss: 0.417\n",
      "[28, 120] loss: 0.402\n",
      "[28, 180] loss: 0.424\n",
      "[28, 240] loss: 0.424\n",
      "[28, 300] loss: 0.395\n",
      "[28, 360] loss: 0.416\n",
      "Epoch: 28 -> Loss: 0.323850810528\n",
      "Epoch: 28 -> Test Accuracy: 81.43\n",
      "[29, 60] loss: 0.430\n",
      "[29, 120] loss: 0.412\n",
      "[29, 180] loss: 0.408\n",
      "[29, 240] loss: 0.415\n",
      "[29, 300] loss: 0.407\n",
      "[29, 360] loss: 0.427\n",
      "Epoch: 29 -> Loss: 0.41956692934\n",
      "Epoch: 29 -> Test Accuracy: 81.21\n",
      "[30, 60] loss: 0.397\n",
      "[30, 120] loss: 0.410\n",
      "[30, 180] loss: 0.398\n",
      "[30, 240] loss: 0.411\n",
      "[30, 300] loss: 0.410\n",
      "[30, 360] loss: 0.441\n",
      "Epoch: 30 -> Loss: 0.426371097565\n",
      "Epoch: 30 -> Test Accuracy: 81.77\n",
      "[31, 60] loss: 0.397\n",
      "[31, 120] loss: 0.405\n",
      "[31, 180] loss: 0.411\n",
      "[31, 240] loss: 0.418\n",
      "[31, 300] loss: 0.418\n",
      "[31, 360] loss: 0.431\n",
      "Epoch: 31 -> Loss: 0.4768435359\n",
      "Epoch: 31 -> Test Accuracy: 81.41\n",
      "[32, 60] loss: 0.391\n",
      "[32, 120] loss: 0.427\n",
      "[32, 180] loss: 0.407\n",
      "[32, 240] loss: 0.412\n",
      "[32, 300] loss: 0.425\n",
      "[32, 360] loss: 0.404\n",
      "Epoch: 32 -> Loss: 0.511290311813\n",
      "Epoch: 32 -> Test Accuracy: 80.94\n",
      "[33, 60] loss: 0.405\n",
      "[33, 120] loss: 0.388\n",
      "[33, 180] loss: 0.415\n",
      "[33, 240] loss: 0.414\n",
      "[33, 300] loss: 0.406\n",
      "[33, 360] loss: 0.400\n",
      "Epoch: 33 -> Loss: 0.419922053814\n",
      "Epoch: 33 -> Test Accuracy: 81.75\n",
      "[34, 60] loss: 0.405\n",
      "[34, 120] loss: 0.400\n",
      "[34, 180] loss: 0.401\n",
      "[34, 240] loss: 0.411\n",
      "[34, 300] loss: 0.403\n",
      "[34, 360] loss: 0.410\n",
      "Epoch: 34 -> Loss: 0.498727023602\n",
      "Epoch: 34 -> Test Accuracy: 81.62\n",
      "[35, 60] loss: 0.401\n",
      "[35, 120] loss: 0.380\n",
      "[35, 180] loss: 0.395\n",
      "[35, 240] loss: 0.407\n",
      "[35, 300] loss: 0.411\n",
      "[35, 360] loss: 0.411\n",
      "Epoch: 35 -> Loss: 0.633063316345\n",
      "Epoch: 35 -> Test Accuracy: 81.12\n",
      "[36, 60] loss: 0.391\n",
      "[36, 120] loss: 0.401\n",
      "[36, 180] loss: 0.406\n",
      "[36, 240] loss: 0.398\n",
      "[36, 300] loss: 0.414\n",
      "[36, 360] loss: 0.412\n",
      "Epoch: 36 -> Loss: 0.389758884907\n",
      "Epoch: 36 -> Test Accuracy: 81.29\n",
      "[37, 60] loss: 0.393\n",
      "[37, 120] loss: 0.406\n",
      "[37, 180] loss: 0.376\n",
      "[37, 240] loss: 0.402\n",
      "[37, 300] loss: 0.417\n",
      "[37, 360] loss: 0.412\n",
      "Epoch: 37 -> Loss: 0.491264164448\n",
      "Epoch: 37 -> Test Accuracy: 81.38\n",
      "[38, 60] loss: 0.407\n",
      "[38, 120] loss: 0.392\n",
      "[38, 180] loss: 0.388\n",
      "[38, 240] loss: 0.400\n",
      "[38, 300] loss: 0.418\n",
      "[38, 360] loss: 0.390\n",
      "Epoch: 38 -> Loss: 0.467126756907\n",
      "Epoch: 38 -> Test Accuracy: 81.08\n",
      "[39, 60] loss: 0.377\n",
      "[39, 120] loss: 0.386\n",
      "[39, 180] loss: 0.396\n",
      "[39, 240] loss: 0.399\n",
      "[39, 300] loss: 0.421\n",
      "[39, 360] loss: 0.395\n",
      "Epoch: 39 -> Loss: 0.405251443386\n",
      "Epoch: 39 -> Test Accuracy: 81.6\n",
      "[40, 60] loss: 0.404\n",
      "[40, 120] loss: 0.391\n",
      "[40, 180] loss: 0.402\n",
      "[40, 240] loss: 0.378\n",
      "[40, 300] loss: 0.416\n",
      "[40, 360] loss: 0.396\n",
      "Epoch: 40 -> Loss: 0.329759895802\n",
      "Epoch: 40 -> Test Accuracy: 81.13\n",
      "[41, 60] loss: 0.368\n",
      "[41, 120] loss: 0.350\n",
      "[41, 180] loss: 0.346\n",
      "[41, 240] loss: 0.349\n",
      "[41, 300] loss: 0.361\n",
      "[41, 360] loss: 0.360\n",
      "Epoch: 41 -> Loss: 0.413007974625\n",
      "Epoch: 41 -> Test Accuracy: 82.17\n",
      "[42, 60] loss: 0.349\n",
      "[42, 120] loss: 0.341\n",
      "[42, 180] loss: 0.321\n",
      "[42, 240] loss: 0.322\n",
      "[42, 300] loss: 0.324\n",
      "[42, 360] loss: 0.341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.354045569897\n",
      "Epoch: 42 -> Test Accuracy: 82.32\n",
      "[43, 60] loss: 0.328\n",
      "[43, 120] loss: 0.307\n",
      "[43, 180] loss: 0.335\n",
      "[43, 240] loss: 0.308\n",
      "[43, 300] loss: 0.315\n",
      "[43, 360] loss: 0.313\n",
      "Epoch: 43 -> Loss: 0.410318374634\n",
      "Epoch: 43 -> Test Accuracy: 82.41\n",
      "[44, 60] loss: 0.316\n",
      "[44, 120] loss: 0.294\n",
      "[44, 180] loss: 0.314\n",
      "[44, 240] loss: 0.309\n",
      "[44, 300] loss: 0.322\n",
      "[44, 360] loss: 0.311\n",
      "Epoch: 44 -> Loss: 0.43537157774\n",
      "Epoch: 44 -> Test Accuracy: 82.66\n",
      "[45, 60] loss: 0.301\n",
      "[45, 120] loss: 0.311\n",
      "[45, 180] loss: 0.304\n",
      "[45, 240] loss: 0.309\n",
      "[45, 300] loss: 0.317\n",
      "[45, 360] loss: 0.299\n",
      "Epoch: 45 -> Loss: 0.335314333439\n",
      "Epoch: 45 -> Test Accuracy: 82.78\n",
      "[46, 60] loss: 0.300\n",
      "[46, 120] loss: 0.294\n",
      "[46, 180] loss: 0.297\n",
      "[46, 240] loss: 0.294\n",
      "[46, 300] loss: 0.294\n",
      "[46, 360] loss: 0.292\n",
      "Epoch: 46 -> Loss: 0.316843062639\n",
      "Epoch: 46 -> Test Accuracy: 83.09\n",
      "[47, 60] loss: 0.284\n",
      "[47, 120] loss: 0.296\n",
      "[47, 180] loss: 0.289\n",
      "[47, 240] loss: 0.292\n",
      "[47, 300] loss: 0.292\n",
      "[47, 360] loss: 0.300\n",
      "Epoch: 47 -> Loss: 0.208519265056\n",
      "Epoch: 47 -> Test Accuracy: 83.03\n",
      "[48, 60] loss: 0.283\n",
      "[48, 120] loss: 0.283\n",
      "[48, 180] loss: 0.294\n",
      "[48, 240] loss: 0.295\n",
      "[48, 300] loss: 0.292\n",
      "[48, 360] loss: 0.288\n",
      "Epoch: 48 -> Loss: 0.406782567501\n",
      "Epoch: 48 -> Test Accuracy: 83.19\n",
      "[49, 60] loss: 0.289\n",
      "[49, 120] loss: 0.278\n",
      "[49, 180] loss: 0.282\n",
      "[49, 240] loss: 0.297\n",
      "[49, 300] loss: 0.293\n",
      "[49, 360] loss: 0.283\n",
      "Epoch: 49 -> Loss: 0.222862437367\n",
      "Epoch: 49 -> Test Accuracy: 83.19\n",
      "[50, 60] loss: 0.295\n",
      "[50, 120] loss: 0.283\n",
      "[50, 180] loss: 0.293\n",
      "[50, 240] loss: 0.281\n",
      "[50, 300] loss: 0.278\n",
      "[50, 360] loss: 0.295\n",
      "Epoch: 50 -> Loss: 0.30034789443\n",
      "Epoch: 50 -> Test Accuracy: 83.14\n",
      "[51, 60] loss: 0.284\n",
      "[51, 120] loss: 0.295\n",
      "[51, 180] loss: 0.285\n",
      "[51, 240] loss: 0.281\n",
      "[51, 300] loss: 0.286\n",
      "[51, 360] loss: 0.288\n",
      "Epoch: 51 -> Loss: 0.298651605844\n",
      "Epoch: 51 -> Test Accuracy: 82.99\n",
      "[52, 60] loss: 0.274\n",
      "[52, 120] loss: 0.283\n",
      "[52, 180] loss: 0.274\n",
      "[52, 240] loss: 0.284\n",
      "[52, 300] loss: 0.280\n",
      "[52, 360] loss: 0.292\n",
      "Epoch: 52 -> Loss: 0.303963959217\n",
      "Epoch: 52 -> Test Accuracy: 82.99\n",
      "[53, 60] loss: 0.284\n",
      "[53, 120] loss: 0.289\n",
      "[53, 180] loss: 0.287\n",
      "[53, 240] loss: 0.280\n",
      "[53, 300] loss: 0.282\n",
      "[53, 360] loss: 0.277\n",
      "Epoch: 53 -> Loss: 0.236382052302\n",
      "Epoch: 53 -> Test Accuracy: 83.23\n",
      "[54, 60] loss: 0.272\n",
      "[54, 120] loss: 0.287\n",
      "[54, 180] loss: 0.273\n",
      "[54, 240] loss: 0.293\n",
      "[54, 300] loss: 0.269\n",
      "[54, 360] loss: 0.282\n",
      "Epoch: 54 -> Loss: 0.335891902447\n",
      "Epoch: 54 -> Test Accuracy: 83.2\n",
      "[55, 60] loss: 0.275\n",
      "[55, 120] loss: 0.285\n",
      "[55, 180] loss: 0.281\n",
      "[55, 240] loss: 0.283\n",
      "[55, 300] loss: 0.279\n",
      "[55, 360] loss: 0.278\n",
      "Epoch: 55 -> Loss: 0.323663383722\n",
      "Epoch: 55 -> Test Accuracy: 83.11\n",
      "[56, 60] loss: 0.280\n",
      "[56, 120] loss: 0.274\n",
      "[56, 180] loss: 0.281\n",
      "[56, 240] loss: 0.272\n",
      "[56, 300] loss: 0.277\n",
      "[56, 360] loss: 0.286\n",
      "Epoch: 56 -> Loss: 0.256812393665\n",
      "Epoch: 56 -> Test Accuracy: 83.06\n",
      "[57, 60] loss: 0.273\n",
      "[57, 120] loss: 0.283\n",
      "[57, 180] loss: 0.272\n",
      "[57, 240] loss: 0.267\n",
      "[57, 300] loss: 0.272\n",
      "[57, 360] loss: 0.284\n",
      "Epoch: 57 -> Loss: 0.223030477762\n",
      "Epoch: 57 -> Test Accuracy: 83.02\n",
      "[58, 60] loss: 0.264\n",
      "[58, 120] loss: 0.279\n",
      "[58, 180] loss: 0.277\n",
      "[58, 240] loss: 0.272\n",
      "[58, 300] loss: 0.262\n",
      "[58, 360] loss: 0.272\n",
      "Epoch: 58 -> Loss: 0.457053273916\n",
      "Epoch: 58 -> Test Accuracy: 83.14\n",
      "[59, 60] loss: 0.278\n",
      "[59, 120] loss: 0.274\n",
      "[59, 180] loss: 0.275\n",
      "[59, 240] loss: 0.273\n",
      "[59, 300] loss: 0.280\n",
      "[59, 360] loss: 0.278\n",
      "Epoch: 59 -> Loss: 0.475919336081\n",
      "Epoch: 59 -> Test Accuracy: 83.11\n",
      "[60, 60] loss: 0.274\n",
      "[60, 120] loss: 0.277\n",
      "[60, 180] loss: 0.277\n",
      "[60, 240] loss: 0.277\n",
      "[60, 300] loss: 0.264\n",
      "[60, 360] loss: 0.260\n",
      "Epoch: 60 -> Loss: 0.2705540061\n",
      "Epoch: 60 -> Test Accuracy: 83.15\n",
      "[61, 60] loss: 0.268\n",
      "[61, 120] loss: 0.265\n",
      "[61, 180] loss: 0.270\n",
      "[61, 240] loss: 0.276\n",
      "[61, 300] loss: 0.267\n",
      "[61, 360] loss: 0.277\n",
      "Epoch: 61 -> Loss: 0.19783398509\n",
      "Epoch: 61 -> Test Accuracy: 82.99\n",
      "[62, 60] loss: 0.257\n",
      "[62, 120] loss: 0.265\n",
      "[62, 180] loss: 0.263\n",
      "[62, 240] loss: 0.268\n",
      "[62, 300] loss: 0.271\n",
      "[62, 360] loss: 0.265\n",
      "Epoch: 62 -> Loss: 0.239679694176\n",
      "Epoch: 62 -> Test Accuracy: 83.04\n",
      "[63, 60] loss: 0.268\n",
      "[63, 120] loss: 0.257\n",
      "[63, 180] loss: 0.269\n",
      "[63, 240] loss: 0.261\n",
      "[63, 300] loss: 0.270\n",
      "[63, 360] loss: 0.278\n",
      "Epoch: 63 -> Loss: 0.312110900879\n",
      "Epoch: 63 -> Test Accuracy: 83.08\n",
      "[64, 60] loss: 0.269\n",
      "[64, 120] loss: 0.258\n",
      "[64, 180] loss: 0.261\n",
      "[64, 240] loss: 0.269\n",
      "[64, 300] loss: 0.264\n",
      "[64, 360] loss: 0.271\n",
      "Epoch: 64 -> Loss: 0.284883320332\n",
      "Epoch: 64 -> Test Accuracy: 83.14\n",
      "[65, 60] loss: 0.254\n",
      "[65, 120] loss: 0.268\n",
      "[65, 180] loss: 0.266\n",
      "[65, 240] loss: 0.279\n",
      "[65, 300] loss: 0.264\n",
      "[65, 360] loss: 0.266\n",
      "Epoch: 65 -> Loss: 0.298399567604\n",
      "Epoch: 65 -> Test Accuracy: 83.06\n",
      "[66, 60] loss: 0.265\n",
      "[66, 120] loss: 0.266\n",
      "[66, 180] loss: 0.261\n",
      "[66, 240] loss: 0.263\n",
      "[66, 300] loss: 0.262\n",
      "[66, 360] loss: 0.259\n",
      "Epoch: 66 -> Loss: 0.190776109695\n",
      "Epoch: 66 -> Test Accuracy: 83.09\n",
      "[67, 60] loss: 0.269\n",
      "[67, 120] loss: 0.260\n",
      "[67, 180] loss: 0.269\n",
      "[67, 240] loss: 0.257\n",
      "[67, 300] loss: 0.276\n",
      "[67, 360] loss: 0.267\n",
      "Epoch: 67 -> Loss: 0.323469310999\n",
      "Epoch: 67 -> Test Accuracy: 83.09\n",
      "[68, 60] loss: 0.263\n",
      "[68, 120] loss: 0.252\n",
      "[68, 180] loss: 0.272\n",
      "[68, 240] loss: 0.273\n",
      "[68, 300] loss: 0.262\n",
      "[68, 360] loss: 0.265\n",
      "Epoch: 68 -> Loss: 0.290797948837\n",
      "Epoch: 68 -> Test Accuracy: 83.11\n",
      "[69, 60] loss: 0.270\n",
      "[69, 120] loss: 0.273\n",
      "[69, 180] loss: 0.247\n",
      "[69, 240] loss: 0.278\n",
      "[69, 300] loss: 0.258\n",
      "[69, 360] loss: 0.263\n",
      "Epoch: 69 -> Loss: 0.222391366959\n",
      "Epoch: 69 -> Test Accuracy: 83.17\n",
      "[70, 60] loss: 0.257\n",
      "[70, 120] loss: 0.259\n",
      "[70, 180] loss: 0.262\n",
      "[70, 240] loss: 0.270\n",
      "[70, 300] loss: 0.262\n",
      "[70, 360] loss: 0.265\n",
      "Epoch: 70 -> Loss: 0.459917455912\n",
      "Epoch: 70 -> Test Accuracy: 83.11\n",
      "[71, 60] loss: 0.259\n",
      "[71, 120] loss: 0.258\n",
      "[71, 180] loss: 0.264\n",
      "[71, 240] loss: 0.255\n",
      "[71, 300] loss: 0.262\n",
      "[71, 360] loss: 0.257\n",
      "Epoch: 71 -> Loss: 0.341872870922\n",
      "Epoch: 71 -> Test Accuracy: 83.2\n",
      "[72, 60] loss: 0.258\n",
      "[72, 120] loss: 0.268\n",
      "[72, 180] loss: 0.257\n",
      "[72, 240] loss: 0.261\n",
      "[72, 300] loss: 0.257\n",
      "[72, 360] loss: 0.253\n",
      "Epoch: 72 -> Loss: 0.194927975535\n",
      "Epoch: 72 -> Test Accuracy: 83.15\n",
      "[73, 60] loss: 0.259\n",
      "[73, 120] loss: 0.256\n",
      "[73, 180] loss: 0.263\n",
      "[73, 240] loss: 0.268\n",
      "[73, 300] loss: 0.257\n",
      "[73, 360] loss: 0.256\n",
      "Epoch: 73 -> Loss: 0.212895795703\n",
      "Epoch: 73 -> Test Accuracy: 83.15\n",
      "[74, 60] loss: 0.256\n",
      "[74, 120] loss: 0.265\n",
      "[74, 180] loss: 0.259\n",
      "[74, 240] loss: 0.251\n",
      "[74, 300] loss: 0.263\n",
      "[74, 360] loss: 0.251\n",
      "Epoch: 74 -> Loss: 0.173325702548\n",
      "Epoch: 74 -> Test Accuracy: 83.15\n",
      "[75, 60] loss: 0.245\n",
      "[75, 120] loss: 0.250\n",
      "[75, 180] loss: 0.257\n",
      "[75, 240] loss: 0.262\n",
      "[75, 300] loss: 0.255\n",
      "[75, 360] loss: 0.256\n",
      "Epoch: 75 -> Loss: 0.275193065405\n",
      "Epoch: 75 -> Test Accuracy: 83.1\n",
      "[76, 60] loss: 0.254\n",
      "[76, 120] loss: 0.243\n",
      "[76, 180] loss: 0.247\n",
      "[76, 240] loss: 0.262\n",
      "[76, 300] loss: 0.250\n",
      "[76, 360] loss: 0.255\n",
      "Epoch: 76 -> Loss: 0.293977439404\n",
      "Epoch: 76 -> Test Accuracy: 83.14\n",
      "[77, 60] loss: 0.250\n",
      "[77, 120] loss: 0.249\n",
      "[77, 180] loss: 0.264\n",
      "[77, 240] loss: 0.255\n",
      "[77, 300] loss: 0.254\n",
      "[77, 360] loss: 0.257\n",
      "Epoch: 77 -> Loss: 0.195675820112\n",
      "Epoch: 77 -> Test Accuracy: 83.14\n",
      "[78, 60] loss: 0.251\n",
      "[78, 120] loss: 0.246\n",
      "[78, 180] loss: 0.254\n",
      "[78, 240] loss: 0.239\n",
      "[78, 300] loss: 0.252\n",
      "[78, 360] loss: 0.254\n",
      "Epoch: 78 -> Loss: 0.236958771944\n",
      "Epoch: 78 -> Test Accuracy: 83.14\n",
      "[79, 60] loss: 0.260\n",
      "[79, 120] loss: 0.247\n",
      "[79, 180] loss: 0.240\n",
      "[79, 240] loss: 0.260\n",
      "[79, 300] loss: 0.257\n",
      "[79, 360] loss: 0.254\n",
      "Epoch: 79 -> Loss: 0.294223457575\n",
      "Epoch: 79 -> Test Accuracy: 83.2\n",
      "[80, 60] loss: 0.256\n",
      "[80, 120] loss: 0.237\n",
      "[80, 180] loss: 0.234\n",
      "[80, 240] loss: 0.254\n",
      "[80, 300] loss: 0.253\n",
      "[80, 360] loss: 0.261\n",
      "Epoch: 80 -> Loss: 0.261307507753\n",
      "Epoch: 80 -> Test Accuracy: 83.23\n",
      "[81, 60] loss: 0.248\n",
      "[81, 120] loss: 0.249\n",
      "[81, 180] loss: 0.251\n",
      "[81, 240] loss: 0.244\n",
      "[81, 300] loss: 0.261\n",
      "[81, 360] loss: 0.250\n",
      "Epoch: 81 -> Loss: 0.201400950551\n",
      "Epoch: 81 -> Test Accuracy: 83.06\n",
      "[82, 60] loss: 0.244\n",
      "[82, 120] loss: 0.253\n",
      "[82, 180] loss: 0.250\n",
      "[82, 240] loss: 0.264\n",
      "[82, 300] loss: 0.245\n",
      "[82, 360] loss: 0.258\n",
      "Epoch: 82 -> Loss: 0.356736272573\n",
      "Epoch: 82 -> Test Accuracy: 82.94\n",
      "[83, 60] loss: 0.252\n",
      "[83, 120] loss: 0.257\n",
      "[83, 180] loss: 0.240\n",
      "[83, 240] loss: 0.245\n",
      "[83, 300] loss: 0.243\n",
      "[83, 360] loss: 0.247\n",
      "Epoch: 83 -> Loss: 0.240639045835\n",
      "Epoch: 83 -> Test Accuracy: 83.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.257\n",
      "[84, 120] loss: 0.246\n",
      "[84, 180] loss: 0.244\n",
      "[84, 240] loss: 0.238\n",
      "[84, 300] loss: 0.248\n",
      "[84, 360] loss: 0.252\n",
      "Epoch: 84 -> Loss: 0.350840747356\n",
      "Epoch: 84 -> Test Accuracy: 82.97\n",
      "[85, 60] loss: 0.259\n",
      "[85, 120] loss: 0.244\n",
      "[85, 180] loss: 0.235\n",
      "[85, 240] loss: 0.243\n",
      "[85, 300] loss: 0.244\n",
      "[85, 360] loss: 0.253\n",
      "Epoch: 85 -> Loss: 0.240564629436\n",
      "Epoch: 85 -> Test Accuracy: 82.98\n",
      "[86, 60] loss: 0.255\n",
      "[86, 120] loss: 0.249\n",
      "[86, 180] loss: 0.254\n",
      "[86, 240] loss: 0.256\n",
      "[86, 300] loss: 0.245\n",
      "[86, 360] loss: 0.245\n",
      "Epoch: 86 -> Loss: 0.224809333682\n",
      "Epoch: 86 -> Test Accuracy: 82.97\n",
      "[87, 60] loss: 0.242\n",
      "[87, 120] loss: 0.225\n",
      "[87, 180] loss: 0.247\n",
      "[87, 240] loss: 0.246\n",
      "[87, 300] loss: 0.260\n",
      "[87, 360] loss: 0.246\n",
      "Epoch: 87 -> Loss: 0.407147020102\n",
      "Epoch: 87 -> Test Accuracy: 83.05\n",
      "[88, 60] loss: 0.246\n",
      "[88, 120] loss: 0.239\n",
      "[88, 180] loss: 0.246\n",
      "[88, 240] loss: 0.232\n",
      "[88, 300] loss: 0.257\n",
      "[88, 360] loss: 0.254\n",
      "Epoch: 88 -> Loss: 0.194575741887\n",
      "Epoch: 88 -> Test Accuracy: 83.04\n",
      "[89, 60] loss: 0.242\n",
      "[89, 120] loss: 0.236\n",
      "[89, 180] loss: 0.247\n",
      "[89, 240] loss: 0.244\n",
      "[89, 300] loss: 0.240\n",
      "[89, 360] loss: 0.251\n",
      "Epoch: 89 -> Loss: 0.32242372632\n",
      "Epoch: 89 -> Test Accuracy: 82.97\n",
      "[90, 60] loss: 0.237\n",
      "[90, 120] loss: 0.230\n",
      "[90, 180] loss: 0.246\n",
      "[90, 240] loss: 0.235\n",
      "[90, 300] loss: 0.239\n",
      "[90, 360] loss: 0.247\n",
      "Epoch: 90 -> Loss: 0.382278084755\n",
      "Epoch: 90 -> Test Accuracy: 83.1\n",
      "[91, 60] loss: 0.240\n",
      "[91, 120] loss: 0.247\n",
      "[91, 180] loss: 0.227\n",
      "[91, 240] loss: 0.240\n",
      "[91, 300] loss: 0.241\n",
      "[91, 360] loss: 0.246\n",
      "Epoch: 91 -> Loss: 0.379574179649\n",
      "Epoch: 91 -> Test Accuracy: 83.0\n",
      "[92, 60] loss: 0.255\n",
      "[92, 120] loss: 0.244\n",
      "[92, 180] loss: 0.232\n",
      "[92, 240] loss: 0.233\n",
      "[92, 300] loss: 0.237\n",
      "[92, 360] loss: 0.235\n",
      "Epoch: 92 -> Loss: 0.205751091242\n",
      "Epoch: 92 -> Test Accuracy: 82.9\n",
      "[93, 60] loss: 0.247\n",
      "[93, 120] loss: 0.236\n",
      "[93, 180] loss: 0.235\n",
      "[93, 240] loss: 0.240\n",
      "[93, 300] loss: 0.245\n",
      "[93, 360] loss: 0.247\n",
      "Epoch: 93 -> Loss: 0.278762578964\n",
      "Epoch: 93 -> Test Accuracy: 83.12\n",
      "[94, 60] loss: 0.249\n",
      "[94, 120] loss: 0.234\n",
      "[94, 180] loss: 0.238\n",
      "[94, 240] loss: 0.237\n",
      "[94, 300] loss: 0.235\n",
      "[94, 360] loss: 0.243\n",
      "Epoch: 94 -> Loss: 0.11246625334\n",
      "Epoch: 94 -> Test Accuracy: 83.08\n",
      "[95, 60] loss: 0.217\n",
      "[95, 120] loss: 0.248\n",
      "[95, 180] loss: 0.236\n",
      "[95, 240] loss: 0.235\n",
      "[95, 300] loss: 0.238\n",
      "[95, 360] loss: 0.245\n",
      "Epoch: 95 -> Loss: 0.370458036661\n",
      "Epoch: 95 -> Test Accuracy: 83.05\n",
      "[96, 60] loss: 0.235\n",
      "[96, 120] loss: 0.244\n",
      "[96, 180] loss: 0.246\n",
      "[96, 240] loss: 0.230\n",
      "[96, 300] loss: 0.227\n",
      "[96, 360] loss: 0.233\n",
      "Epoch: 96 -> Loss: 0.300017774105\n",
      "Epoch: 96 -> Test Accuracy: 82.98\n",
      "[97, 60] loss: 0.234\n",
      "[97, 120] loss: 0.245\n",
      "[97, 180] loss: 0.230\n",
      "[97, 240] loss: 0.255\n",
      "[97, 300] loss: 0.236\n",
      "[97, 360] loss: 0.238\n",
      "Epoch: 97 -> Loss: 0.32901340723\n",
      "Epoch: 97 -> Test Accuracy: 83.03\n",
      "[98, 60] loss: 0.238\n",
      "[98, 120] loss: 0.237\n",
      "[98, 180] loss: 0.238\n",
      "[98, 240] loss: 0.247\n",
      "[98, 300] loss: 0.237\n",
      "[98, 360] loss: 0.242\n",
      "Epoch: 98 -> Loss: 0.284159094095\n",
      "Epoch: 98 -> Test Accuracy: 83.01\n",
      "[99, 60] loss: 0.234\n",
      "[99, 120] loss: 0.237\n",
      "[99, 180] loss: 0.231\n",
      "[99, 240] loss: 0.245\n",
      "[99, 300] loss: 0.235\n",
      "[99, 360] loss: 0.228\n",
      "Epoch: 99 -> Loss: 0.356139957905\n",
      "Epoch: 99 -> Test Accuracy: 83.08\n",
      "[100, 60] loss: 0.232\n",
      "[100, 120] loss: 0.223\n",
      "[100, 180] loss: 0.237\n",
      "[100, 240] loss: 0.242\n",
      "[100, 300] loss: 0.229\n",
      "[100, 360] loss: 0.235\n",
      "Epoch: 100 -> Loss: 0.321199119091\n",
      "Epoch: 100 -> Test Accuracy: 83.14\n",
      "Finished Training\n",
      "[1, 60] loss: 1.678\n",
      "[1, 120] loss: 0.845\n",
      "[1, 180] loss: 0.803\n",
      "[1, 240] loss: 0.720\n",
      "[1, 300] loss: 0.669\n",
      "[1, 360] loss: 0.659\n",
      "Epoch: 1 -> Loss: 0.580461978912\n",
      "Epoch: 1 -> Test Accuracy: 78.22\n",
      "[2, 60] loss: 0.614\n",
      "[2, 120] loss: 0.594\n",
      "[2, 180] loss: 0.586\n",
      "[2, 240] loss: 0.563\n",
      "[2, 300] loss: 0.575\n",
      "[2, 360] loss: 0.563\n",
      "Epoch: 2 -> Loss: 0.436353504658\n",
      "Epoch: 2 -> Test Accuracy: 81.01\n",
      "[3, 60] loss: 0.508\n",
      "[3, 120] loss: 0.525\n",
      "[3, 180] loss: 0.519\n",
      "[3, 240] loss: 0.527\n",
      "[3, 300] loss: 0.523\n",
      "[3, 360] loss: 0.524\n",
      "Epoch: 3 -> Loss: 0.600462734699\n",
      "Epoch: 3 -> Test Accuracy: 81.67\n",
      "[4, 60] loss: 0.484\n",
      "[4, 120] loss: 0.481\n",
      "[4, 180] loss: 0.498\n",
      "[4, 240] loss: 0.487\n",
      "[4, 300] loss: 0.491\n",
      "[4, 360] loss: 0.490\n",
      "Epoch: 4 -> Loss: 0.361589670181\n",
      "Epoch: 4 -> Test Accuracy: 82.61\n",
      "[5, 60] loss: 0.449\n",
      "[5, 120] loss: 0.434\n",
      "[5, 180] loss: 0.465\n",
      "[5, 240] loss: 0.469\n",
      "[5, 300] loss: 0.468\n",
      "[5, 360] loss: 0.452\n",
      "Epoch: 5 -> Loss: 0.547302603722\n",
      "Epoch: 5 -> Test Accuracy: 83.24\n",
      "[6, 60] loss: 0.437\n",
      "[6, 120] loss: 0.449\n",
      "[6, 180] loss: 0.451\n",
      "[6, 240] loss: 0.441\n",
      "[6, 300] loss: 0.447\n",
      "[6, 360] loss: 0.446\n",
      "Epoch: 6 -> Loss: 0.331470578909\n",
      "Epoch: 6 -> Test Accuracy: 83.25\n",
      "[7, 60] loss: 0.446\n",
      "[7, 120] loss: 0.425\n",
      "[7, 180] loss: 0.429\n",
      "[7, 240] loss: 0.415\n",
      "[7, 300] loss: 0.430\n",
      "[7, 360] loss: 0.435\n",
      "Epoch: 7 -> Loss: 0.353511273861\n",
      "Epoch: 7 -> Test Accuracy: 83.67\n",
      "[8, 60] loss: 0.406\n",
      "[8, 120] loss: 0.393\n",
      "[8, 180] loss: 0.410\n",
      "[8, 240] loss: 0.422\n",
      "[8, 300] loss: 0.422\n",
      "[8, 360] loss: 0.438\n",
      "Epoch: 8 -> Loss: 0.411957085133\n",
      "Epoch: 8 -> Test Accuracy: 83.1\n",
      "[9, 60] loss: 0.406\n",
      "[9, 120] loss: 0.408\n",
      "[9, 180] loss: 0.411\n",
      "[9, 240] loss: 0.410\n",
      "[9, 300] loss: 0.418\n",
      "[9, 360] loss: 0.425\n",
      "Epoch: 9 -> Loss: 0.366218328476\n",
      "Epoch: 9 -> Test Accuracy: 83.86\n",
      "[10, 60] loss: 0.391\n",
      "[10, 120] loss: 0.389\n",
      "[10, 180] loss: 0.419\n",
      "[10, 240] loss: 0.417\n",
      "[10, 300] loss: 0.408\n",
      "[10, 360] loss: 0.401\n",
      "Epoch: 10 -> Loss: 0.340219080448\n",
      "Epoch: 10 -> Test Accuracy: 83.7\n",
      "[11, 60] loss: 0.382\n",
      "[11, 120] loss: 0.387\n",
      "[11, 180] loss: 0.396\n",
      "[11, 240] loss: 0.400\n",
      "[11, 300] loss: 0.390\n",
      "[11, 360] loss: 0.408\n",
      "Epoch: 11 -> Loss: 0.613965570927\n",
      "Epoch: 11 -> Test Accuracy: 83.12\n",
      "[12, 60] loss: 0.369\n",
      "[12, 120] loss: 0.390\n",
      "[12, 180] loss: 0.387\n",
      "[12, 240] loss: 0.409\n",
      "[12, 300] loss: 0.392\n",
      "[12, 360] loss: 0.405\n",
      "Epoch: 12 -> Loss: 0.371563047171\n",
      "Epoch: 12 -> Test Accuracy: 83.52\n",
      "[13, 60] loss: 0.373\n",
      "[13, 120] loss: 0.382\n",
      "[13, 180] loss: 0.385\n",
      "[13, 240] loss: 0.392\n",
      "[13, 300] loss: 0.419\n",
      "[13, 360] loss: 0.419\n",
      "Epoch: 13 -> Loss: 0.453376352787\n",
      "Epoch: 13 -> Test Accuracy: 82.82\n",
      "[14, 60] loss: 0.367\n",
      "[14, 120] loss: 0.385\n",
      "[14, 180] loss: 0.380\n",
      "[14, 240] loss: 0.395\n",
      "[14, 300] loss: 0.405\n",
      "[14, 360] loss: 0.382\n",
      "Epoch: 14 -> Loss: 0.469321250916\n",
      "Epoch: 14 -> Test Accuracy: 83.75\n",
      "[15, 60] loss: 0.363\n",
      "[15, 120] loss: 0.396\n",
      "[15, 180] loss: 0.392\n",
      "[15, 240] loss: 0.377\n",
      "[15, 300] loss: 0.385\n",
      "[15, 360] loss: 0.400\n",
      "Epoch: 15 -> Loss: 0.379113465548\n",
      "Epoch: 15 -> Test Accuracy: 83.46\n",
      "[16, 60] loss: 0.374\n",
      "[16, 120] loss: 0.387\n",
      "[16, 180] loss: 0.366\n",
      "[16, 240] loss: 0.401\n",
      "[16, 300] loss: 0.386\n",
      "[16, 360] loss: 0.390\n",
      "Epoch: 16 -> Loss: 0.364026933908\n",
      "Epoch: 16 -> Test Accuracy: 83.64\n",
      "[17, 60] loss: 0.341\n",
      "[17, 120] loss: 0.360\n",
      "[17, 180] loss: 0.376\n",
      "[17, 240] loss: 0.387\n",
      "[17, 300] loss: 0.381\n",
      "[17, 360] loss: 0.383\n",
      "Epoch: 17 -> Loss: 0.526303946972\n",
      "Epoch: 17 -> Test Accuracy: 84.37\n",
      "[18, 60] loss: 0.356\n",
      "[18, 120] loss: 0.370\n",
      "[18, 180] loss: 0.375\n",
      "[18, 240] loss: 0.396\n",
      "[18, 300] loss: 0.374\n",
      "[18, 360] loss: 0.392\n",
      "Epoch: 18 -> Loss: 0.450930297375\n",
      "Epoch: 18 -> Test Accuracy: 83.9\n",
      "[19, 60] loss: 0.365\n",
      "[19, 120] loss: 0.354\n",
      "[19, 180] loss: 0.372\n",
      "[19, 240] loss: 0.384\n",
      "[19, 300] loss: 0.395\n",
      "[19, 360] loss: 0.369\n",
      "Epoch: 19 -> Loss: 0.403427362442\n",
      "Epoch: 19 -> Test Accuracy: 84.32\n",
      "[20, 60] loss: 0.341\n",
      "[20, 120] loss: 0.374\n",
      "[20, 180] loss: 0.358\n",
      "[20, 240] loss: 0.387\n",
      "[20, 300] loss: 0.396\n",
      "[20, 360] loss: 0.383\n",
      "Epoch: 20 -> Loss: 0.318495959044\n",
      "Epoch: 20 -> Test Accuracy: 83.88\n",
      "[21, 60] loss: 0.325\n",
      "[21, 120] loss: 0.304\n",
      "[21, 180] loss: 0.297\n",
      "[21, 240] loss: 0.280\n",
      "[21, 300] loss: 0.304\n",
      "[21, 360] loss: 0.296\n",
      "Epoch: 21 -> Loss: 0.190835878253\n",
      "Epoch: 21 -> Test Accuracy: 86.01\n",
      "[22, 60] loss: 0.270\n",
      "[22, 120] loss: 0.267\n",
      "[22, 180] loss: 0.267\n",
      "[22, 240] loss: 0.268\n",
      "[22, 300] loss: 0.266\n",
      "[22, 360] loss: 0.260\n",
      "Epoch: 22 -> Loss: 0.309925466776\n",
      "Epoch: 22 -> Test Accuracy: 86.12\n",
      "[23, 60] loss: 0.242\n",
      "[23, 120] loss: 0.251\n",
      "[23, 180] loss: 0.254\n",
      "[23, 240] loss: 0.244\n",
      "[23, 300] loss: 0.243\n",
      "[23, 360] loss: 0.261\n",
      "Epoch: 23 -> Loss: 0.173868343234\n",
      "Epoch: 23 -> Test Accuracy: 85.83\n",
      "[24, 60] loss: 0.219\n",
      "[24, 120] loss: 0.234\n",
      "[24, 180] loss: 0.232\n",
      "[24, 240] loss: 0.243\n",
      "[24, 300] loss: 0.253\n",
      "[24, 360] loss: 0.241\n",
      "Epoch: 24 -> Loss: 0.259579181671\n",
      "Epoch: 24 -> Test Accuracy: 86.45\n",
      "[25, 60] loss: 0.216\n",
      "[25, 120] loss: 0.226\n",
      "[25, 180] loss: 0.230\n",
      "[25, 240] loss: 0.218\n",
      "[25, 300] loss: 0.238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 360] loss: 0.233\n",
      "Epoch: 25 -> Loss: 0.300466686487\n",
      "Epoch: 25 -> Test Accuracy: 85.95\n",
      "[26, 60] loss: 0.223\n",
      "[26, 120] loss: 0.206\n",
      "[26, 180] loss: 0.207\n",
      "[26, 240] loss: 0.230\n",
      "[26, 300] loss: 0.232\n",
      "[26, 360] loss: 0.231\n",
      "Epoch: 26 -> Loss: 0.195571139455\n",
      "Epoch: 26 -> Test Accuracy: 86.42\n",
      "[27, 60] loss: 0.212\n",
      "[27, 120] loss: 0.218\n",
      "[27, 180] loss: 0.221\n",
      "[27, 240] loss: 0.198\n",
      "[27, 300] loss: 0.216\n",
      "[27, 360] loss: 0.221\n",
      "Epoch: 27 -> Loss: 0.248861312866\n",
      "Epoch: 27 -> Test Accuracy: 86.08\n",
      "[28, 60] loss: 0.200\n",
      "[28, 120] loss: 0.200\n",
      "[28, 180] loss: 0.208\n",
      "[28, 240] loss: 0.205\n",
      "[28, 300] loss: 0.221\n",
      "[28, 360] loss: 0.231\n",
      "Epoch: 28 -> Loss: 0.247321411967\n",
      "Epoch: 28 -> Test Accuracy: 86.31\n",
      "[29, 60] loss: 0.203\n",
      "[29, 120] loss: 0.205\n",
      "[29, 180] loss: 0.196\n",
      "[29, 240] loss: 0.217\n",
      "[29, 300] loss: 0.203\n",
      "[29, 360] loss: 0.204\n",
      "Epoch: 29 -> Loss: 0.273793399334\n",
      "Epoch: 29 -> Test Accuracy: 86.1\n",
      "[30, 60] loss: 0.202\n",
      "[30, 120] loss: 0.196\n",
      "[30, 180] loss: 0.216\n",
      "[30, 240] loss: 0.199\n",
      "[30, 300] loss: 0.210\n",
      "[30, 360] loss: 0.210\n",
      "Epoch: 30 -> Loss: 0.186239600182\n",
      "Epoch: 30 -> Test Accuracy: 85.75\n",
      "[31, 60] loss: 0.200\n",
      "[31, 120] loss: 0.202\n",
      "[31, 180] loss: 0.199\n",
      "[31, 240] loss: 0.213\n",
      "[31, 300] loss: 0.213\n",
      "[31, 360] loss: 0.217\n",
      "Epoch: 31 -> Loss: 0.252953976393\n",
      "Epoch: 31 -> Test Accuracy: 85.98\n",
      "[32, 60] loss: 0.190\n",
      "[32, 120] loss: 0.201\n",
      "[32, 180] loss: 0.202\n",
      "[32, 240] loss: 0.205\n",
      "[32, 300] loss: 0.217\n",
      "[32, 360] loss: 0.201\n",
      "Epoch: 32 -> Loss: 0.323598325253\n",
      "Epoch: 32 -> Test Accuracy: 85.91\n",
      "[33, 60] loss: 0.193\n",
      "[33, 120] loss: 0.186\n",
      "[33, 180] loss: 0.202\n",
      "[33, 240] loss: 0.214\n",
      "[33, 300] loss: 0.210\n",
      "[33, 360] loss: 0.213\n",
      "Epoch: 33 -> Loss: 0.258311003447\n",
      "Epoch: 33 -> Test Accuracy: 85.55\n",
      "[34, 60] loss: 0.194\n",
      "[34, 120] loss: 0.197\n",
      "[34, 180] loss: 0.201\n",
      "[34, 240] loss: 0.204\n",
      "[34, 300] loss: 0.199\n",
      "[34, 360] loss: 0.199\n",
      "Epoch: 34 -> Loss: 0.238776057959\n",
      "Epoch: 34 -> Test Accuracy: 85.86\n",
      "[35, 60] loss: 0.186\n",
      "[35, 120] loss: 0.201\n",
      "[35, 180] loss: 0.203\n",
      "[35, 240] loss: 0.203\n",
      "[35, 300] loss: 0.207\n",
      "[35, 360] loss: 0.198\n",
      "Epoch: 35 -> Loss: 0.276169925928\n",
      "Epoch: 35 -> Test Accuracy: 85.97\n",
      "[36, 60] loss: 0.187\n",
      "[36, 120] loss: 0.190\n",
      "[36, 180] loss: 0.203\n",
      "[36, 240] loss: 0.204\n",
      "[36, 300] loss: 0.202\n",
      "[36, 360] loss: 0.216\n",
      "Epoch: 36 -> Loss: 0.211791604757\n",
      "Epoch: 36 -> Test Accuracy: 85.85\n",
      "[37, 60] loss: 0.202\n",
      "[37, 120] loss: 0.195\n",
      "[37, 180] loss: 0.199\n",
      "[37, 240] loss: 0.211\n",
      "[37, 300] loss: 0.205\n",
      "[37, 360] loss: 0.213\n",
      "Epoch: 37 -> Loss: 0.160185068846\n",
      "Epoch: 37 -> Test Accuracy: 85.65\n",
      "[38, 60] loss: 0.188\n",
      "[38, 120] loss: 0.176\n",
      "[38, 180] loss: 0.188\n",
      "[38, 240] loss: 0.198\n",
      "[38, 300] loss: 0.195\n",
      "[38, 360] loss: 0.206\n",
      "Epoch: 38 -> Loss: 0.304122269154\n",
      "Epoch: 38 -> Test Accuracy: 85.38\n",
      "[39, 60] loss: 0.195\n",
      "[39, 120] loss: 0.184\n",
      "[39, 180] loss: 0.191\n",
      "[39, 240] loss: 0.191\n",
      "[39, 300] loss: 0.202\n",
      "[39, 360] loss: 0.193\n",
      "Epoch: 39 -> Loss: 0.107170984149\n",
      "Epoch: 39 -> Test Accuracy: 85.61\n",
      "[40, 60] loss: 0.197\n",
      "[40, 120] loss: 0.196\n",
      "[40, 180] loss: 0.194\n",
      "[40, 240] loss: 0.198\n",
      "[40, 300] loss: 0.204\n",
      "[40, 360] loss: 0.218\n",
      "Epoch: 40 -> Loss: 0.227625176311\n",
      "Epoch: 40 -> Test Accuracy: 85.61\n",
      "[41, 60] loss: 0.179\n",
      "[41, 120] loss: 0.162\n",
      "[41, 180] loss: 0.177\n",
      "[41, 240] loss: 0.154\n",
      "[41, 300] loss: 0.152\n",
      "[41, 360] loss: 0.161\n",
      "Epoch: 41 -> Loss: 0.212245866656\n",
      "Epoch: 41 -> Test Accuracy: 86.66\n",
      "[42, 60] loss: 0.152\n",
      "[42, 120] loss: 0.141\n",
      "[42, 180] loss: 0.153\n",
      "[42, 240] loss: 0.142\n",
      "[42, 300] loss: 0.152\n",
      "[42, 360] loss: 0.145\n",
      "Epoch: 42 -> Loss: 0.111113384366\n",
      "Epoch: 42 -> Test Accuracy: 86.94\n",
      "[43, 60] loss: 0.138\n",
      "[43, 120] loss: 0.144\n",
      "[43, 180] loss: 0.142\n",
      "[43, 240] loss: 0.137\n",
      "[43, 300] loss: 0.133\n",
      "[43, 360] loss: 0.130\n",
      "Epoch: 43 -> Loss: 0.131183460355\n",
      "Epoch: 43 -> Test Accuracy: 86.77\n",
      "[44, 60] loss: 0.129\n",
      "[44, 120] loss: 0.130\n",
      "[44, 180] loss: 0.132\n",
      "[44, 240] loss: 0.132\n",
      "[44, 300] loss: 0.139\n",
      "[44, 360] loss: 0.133\n",
      "Epoch: 44 -> Loss: 0.129694700241\n",
      "Epoch: 44 -> Test Accuracy: 87.04\n",
      "[45, 60] loss: 0.129\n",
      "[45, 120] loss: 0.122\n",
      "[45, 180] loss: 0.132\n",
      "[45, 240] loss: 0.131\n",
      "[45, 300] loss: 0.131\n",
      "[45, 360] loss: 0.124\n",
      "Epoch: 45 -> Loss: 0.0863885581493\n",
      "Epoch: 45 -> Test Accuracy: 86.97\n",
      "[46, 60] loss: 0.117\n",
      "[46, 120] loss: 0.117\n",
      "[46, 180] loss: 0.120\n",
      "[46, 240] loss: 0.126\n",
      "[46, 300] loss: 0.115\n",
      "[46, 360] loss: 0.119\n",
      "Epoch: 46 -> Loss: 0.150406032801\n",
      "Epoch: 46 -> Test Accuracy: 87.22\n",
      "[47, 60] loss: 0.116\n",
      "[47, 120] loss: 0.120\n",
      "[47, 180] loss: 0.118\n",
      "[47, 240] loss: 0.118\n",
      "[47, 300] loss: 0.111\n",
      "[47, 360] loss: 0.114\n",
      "Epoch: 47 -> Loss: 0.150071114302\n",
      "Epoch: 47 -> Test Accuracy: 87.1\n",
      "[48, 60] loss: 0.118\n",
      "[48, 120] loss: 0.114\n",
      "[48, 180] loss: 0.111\n",
      "[48, 240] loss: 0.117\n",
      "[48, 300] loss: 0.117\n",
      "[48, 360] loss: 0.116\n",
      "Epoch: 48 -> Loss: 0.130282133818\n",
      "Epoch: 48 -> Test Accuracy: 87.12\n",
      "[49, 60] loss: 0.117\n",
      "[49, 120] loss: 0.113\n",
      "[49, 180] loss: 0.118\n",
      "[49, 240] loss: 0.109\n",
      "[49, 300] loss: 0.116\n",
      "[49, 360] loss: 0.107\n",
      "Epoch: 49 -> Loss: 0.136827155948\n",
      "Epoch: 49 -> Test Accuracy: 87.03\n",
      "[50, 60] loss: 0.110\n",
      "[50, 120] loss: 0.111\n",
      "[50, 180] loss: 0.117\n",
      "[50, 240] loss: 0.114\n",
      "[50, 300] loss: 0.114\n",
      "[50, 360] loss: 0.111\n",
      "Epoch: 50 -> Loss: 0.0707293301821\n",
      "Epoch: 50 -> Test Accuracy: 87.08\n",
      "[51, 60] loss: 0.111\n",
      "[51, 120] loss: 0.116\n",
      "[51, 180] loss: 0.113\n",
      "[51, 240] loss: 0.107\n",
      "[51, 300] loss: 0.112\n",
      "[51, 360] loss: 0.113\n",
      "Epoch: 51 -> Loss: 0.11585149914\n",
      "Epoch: 51 -> Test Accuracy: 86.99\n",
      "[52, 60] loss: 0.118\n",
      "[52, 120] loss: 0.112\n",
      "[52, 180] loss: 0.111\n",
      "[52, 240] loss: 0.114\n",
      "[52, 300] loss: 0.098\n",
      "[52, 360] loss: 0.110\n",
      "Epoch: 52 -> Loss: 0.0442343465984\n",
      "Epoch: 52 -> Test Accuracy: 86.99\n",
      "[53, 60] loss: 0.108\n",
      "[53, 120] loss: 0.114\n",
      "[53, 180] loss: 0.112\n",
      "[53, 240] loss: 0.105\n",
      "[53, 300] loss: 0.115\n",
      "[53, 360] loss: 0.104\n",
      "Epoch: 53 -> Loss: 0.11087924242\n",
      "Epoch: 53 -> Test Accuracy: 87.09\n",
      "[54, 60] loss: 0.105\n",
      "[54, 120] loss: 0.103\n",
      "[54, 180] loss: 0.113\n",
      "[54, 240] loss: 0.109\n",
      "[54, 300] loss: 0.115\n",
      "[54, 360] loss: 0.109\n",
      "Epoch: 54 -> Loss: 0.0905200317502\n",
      "Epoch: 54 -> Test Accuracy: 87.06\n",
      "[55, 60] loss: 0.101\n",
      "[55, 120] loss: 0.114\n",
      "[55, 180] loss: 0.102\n",
      "[55, 240] loss: 0.109\n",
      "[55, 300] loss: 0.109\n",
      "[55, 360] loss: 0.103\n",
      "Epoch: 55 -> Loss: 0.0764545574784\n",
      "Epoch: 55 -> Test Accuracy: 87.11\n",
      "[56, 60] loss: 0.104\n",
      "[56, 120] loss: 0.100\n",
      "[56, 180] loss: 0.102\n",
      "[56, 240] loss: 0.104\n",
      "[56, 300] loss: 0.111\n",
      "[56, 360] loss: 0.098\n",
      "Epoch: 56 -> Loss: 0.178016364574\n",
      "Epoch: 56 -> Test Accuracy: 87.16\n",
      "[57, 60] loss: 0.102\n",
      "[57, 120] loss: 0.104\n",
      "[57, 180] loss: 0.098\n",
      "[57, 240] loss: 0.100\n",
      "[57, 300] loss: 0.100\n",
      "[57, 360] loss: 0.100\n",
      "Epoch: 57 -> Loss: 0.163721442223\n",
      "Epoch: 57 -> Test Accuracy: 87.18\n",
      "[58, 60] loss: 0.106\n",
      "[58, 120] loss: 0.103\n",
      "[58, 180] loss: 0.102\n",
      "[58, 240] loss: 0.108\n",
      "[58, 300] loss: 0.107\n",
      "[58, 360] loss: 0.109\n",
      "Epoch: 58 -> Loss: 0.143146723509\n",
      "Epoch: 58 -> Test Accuracy: 87.04\n",
      "[59, 60] loss: 0.107\n",
      "[59, 120] loss: 0.102\n",
      "[59, 180] loss: 0.103\n",
      "[59, 240] loss: 0.099\n",
      "[59, 300] loss: 0.103\n",
      "[59, 360] loss: 0.099\n",
      "Epoch: 59 -> Loss: 0.119568489492\n",
      "Epoch: 59 -> Test Accuracy: 86.98\n",
      "[60, 60] loss: 0.104\n",
      "[60, 120] loss: 0.104\n",
      "[60, 180] loss: 0.097\n",
      "[60, 240] loss: 0.096\n",
      "[60, 300] loss: 0.101\n",
      "[60, 360] loss: 0.103\n",
      "Epoch: 60 -> Loss: 0.106781184673\n",
      "Epoch: 60 -> Test Accuracy: 86.96\n",
      "[61, 60] loss: 0.104\n",
      "[61, 120] loss: 0.098\n",
      "[61, 180] loss: 0.100\n",
      "[61, 240] loss: 0.100\n",
      "[61, 300] loss: 0.105\n",
      "[61, 360] loss: 0.100\n",
      "Epoch: 61 -> Loss: 0.0389527976513\n",
      "Epoch: 61 -> Test Accuracy: 87.05\n",
      "[62, 60] loss: 0.102\n",
      "[62, 120] loss: 0.103\n",
      "[62, 180] loss: 0.100\n",
      "[62, 240] loss: 0.099\n",
      "[62, 300] loss: 0.093\n",
      "[62, 360] loss: 0.106\n",
      "Epoch: 62 -> Loss: 0.0931862220168\n",
      "Epoch: 62 -> Test Accuracy: 87.02\n",
      "[63, 60] loss: 0.099\n",
      "[63, 120] loss: 0.102\n",
      "[63, 180] loss: 0.101\n",
      "[63, 240] loss: 0.097\n",
      "[63, 300] loss: 0.090\n",
      "[63, 360] loss: 0.100\n",
      "Epoch: 63 -> Loss: 0.192437231541\n",
      "Epoch: 63 -> Test Accuracy: 87.06\n",
      "[64, 60] loss: 0.103\n",
      "[64, 120] loss: 0.098\n",
      "[64, 180] loss: 0.102\n",
      "[64, 240] loss: 0.101\n",
      "[64, 300] loss: 0.099\n",
      "[64, 360] loss: 0.092\n",
      "Epoch: 64 -> Loss: 0.089717246592\n",
      "Epoch: 64 -> Test Accuracy: 87.06\n",
      "[65, 60] loss: 0.097\n",
      "[65, 120] loss: 0.097\n",
      "[65, 180] loss: 0.096\n",
      "[65, 240] loss: 0.100\n",
      "[65, 300] loss: 0.103\n",
      "[65, 360] loss: 0.095\n",
      "Epoch: 65 -> Loss: 0.169849857688\n",
      "Epoch: 65 -> Test Accuracy: 87.2\n",
      "[66, 60] loss: 0.099\n",
      "[66, 120] loss: 0.095\n",
      "[66, 180] loss: 0.097\n",
      "[66, 240] loss: 0.100\n",
      "[66, 300] loss: 0.097\n",
      "[66, 360] loss: 0.097\n",
      "Epoch: 66 -> Loss: 0.136743590236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Test Accuracy: 86.99\n",
      "[67, 60] loss: 0.100\n",
      "[67, 120] loss: 0.095\n",
      "[67, 180] loss: 0.091\n",
      "[67, 240] loss: 0.096\n",
      "[67, 300] loss: 0.099\n",
      "[67, 360] loss: 0.095\n",
      "Epoch: 67 -> Loss: 0.107475541532\n",
      "Epoch: 67 -> Test Accuracy: 87.05\n",
      "[68, 60] loss: 0.096\n",
      "[68, 120] loss: 0.104\n",
      "[68, 180] loss: 0.098\n",
      "[68, 240] loss: 0.089\n",
      "[68, 300] loss: 0.095\n",
      "[68, 360] loss: 0.098\n",
      "Epoch: 68 -> Loss: 0.0491379313171\n",
      "Epoch: 68 -> Test Accuracy: 87.13\n",
      "[69, 60] loss: 0.098\n",
      "[69, 120] loss: 0.097\n",
      "[69, 180] loss: 0.097\n",
      "[69, 240] loss: 0.092\n",
      "[69, 300] loss: 0.093\n",
      "[69, 360] loss: 0.102\n",
      "Epoch: 69 -> Loss: 0.0430906303227\n",
      "Epoch: 69 -> Test Accuracy: 86.96\n",
      "[70, 60] loss: 0.092\n",
      "[70, 120] loss: 0.093\n",
      "[70, 180] loss: 0.095\n",
      "[70, 240] loss: 0.095\n",
      "[70, 300] loss: 0.088\n",
      "[70, 360] loss: 0.095\n",
      "Epoch: 70 -> Loss: 0.110732994974\n",
      "Epoch: 70 -> Test Accuracy: 87.04\n",
      "[71, 60] loss: 0.093\n",
      "[71, 120] loss: 0.091\n",
      "[71, 180] loss: 0.090\n",
      "[71, 240] loss: 0.088\n",
      "[71, 300] loss: 0.089\n",
      "[71, 360] loss: 0.097\n",
      "Epoch: 71 -> Loss: 0.159320011735\n",
      "Epoch: 71 -> Test Accuracy: 87.13\n",
      "[72, 60] loss: 0.091\n",
      "[72, 120] loss: 0.099\n",
      "[72, 180] loss: 0.086\n",
      "[72, 240] loss: 0.094\n",
      "[72, 300] loss: 0.092\n",
      "[72, 360] loss: 0.092\n",
      "Epoch: 72 -> Loss: 0.135629788041\n",
      "Epoch: 72 -> Test Accuracy: 87.08\n",
      "[73, 60] loss: 0.091\n",
      "[73, 120] loss: 0.082\n",
      "[73, 180] loss: 0.086\n",
      "[73, 240] loss: 0.092\n",
      "[73, 300] loss: 0.089\n",
      "[73, 360] loss: 0.095\n",
      "Epoch: 73 -> Loss: 0.0456289127469\n",
      "Epoch: 73 -> Test Accuracy: 87.15\n",
      "[74, 60] loss: 0.085\n",
      "[74, 120] loss: 0.094\n",
      "[74, 180] loss: 0.092\n",
      "[74, 240] loss: 0.088\n",
      "[74, 300] loss: 0.092\n",
      "[74, 360] loss: 0.092\n",
      "Epoch: 74 -> Loss: 0.0756517648697\n",
      "Epoch: 74 -> Test Accuracy: 87.19\n",
      "[75, 60] loss: 0.091\n",
      "[75, 120] loss: 0.095\n",
      "[75, 180] loss: 0.089\n",
      "[75, 240] loss: 0.097\n",
      "[75, 300] loss: 0.094\n",
      "[75, 360] loss: 0.091\n",
      "Epoch: 75 -> Loss: 0.0589314810932\n",
      "Epoch: 75 -> Test Accuracy: 87.15\n",
      "[76, 60] loss: 0.088\n",
      "[76, 120] loss: 0.085\n",
      "[76, 180] loss: 0.084\n",
      "[76, 240] loss: 0.088\n",
      "[76, 300] loss: 0.090\n",
      "[76, 360] loss: 0.091\n",
      "Epoch: 76 -> Loss: 0.139656707644\n",
      "Epoch: 76 -> Test Accuracy: 87.14\n",
      "[77, 60] loss: 0.087\n",
      "[77, 120] loss: 0.087\n",
      "[77, 180] loss: 0.089\n",
      "[77, 240] loss: 0.093\n",
      "[77, 300] loss: 0.085\n",
      "[77, 360] loss: 0.087\n",
      "Epoch: 77 -> Loss: 0.0726390704513\n",
      "Epoch: 77 -> Test Accuracy: 87.23\n",
      "[78, 60] loss: 0.092\n",
      "[78, 120] loss: 0.082\n",
      "[78, 180] loss: 0.089\n",
      "[78, 240] loss: 0.091\n",
      "[78, 300] loss: 0.096\n",
      "[78, 360] loss: 0.094\n",
      "Epoch: 78 -> Loss: 0.141506671906\n",
      "Epoch: 78 -> Test Accuracy: 87.1\n",
      "[79, 60] loss: 0.088\n",
      "[79, 120] loss: 0.081\n",
      "[79, 180] loss: 0.087\n",
      "[79, 240] loss: 0.081\n",
      "[79, 300] loss: 0.093\n",
      "[79, 360] loss: 0.090\n",
      "Epoch: 79 -> Loss: 0.0424521453679\n",
      "Epoch: 79 -> Test Accuracy: 87.12\n",
      "[80, 60] loss: 0.082\n",
      "[80, 120] loss: 0.085\n",
      "[80, 180] loss: 0.094\n",
      "[80, 240] loss: 0.086\n",
      "[80, 300] loss: 0.086\n",
      "[80, 360] loss: 0.083\n",
      "Epoch: 80 -> Loss: 0.0938408076763\n",
      "Epoch: 80 -> Test Accuracy: 87.1\n",
      "[81, 60] loss: 0.090\n",
      "[81, 120] loss: 0.082\n",
      "[81, 180] loss: 0.086\n",
      "[81, 240] loss: 0.089\n",
      "[81, 300] loss: 0.086\n",
      "[81, 360] loss: 0.091\n",
      "Epoch: 81 -> Loss: 0.12126468122\n",
      "Epoch: 81 -> Test Accuracy: 87.21\n",
      "[82, 60] loss: 0.089\n",
      "[82, 120] loss: 0.082\n",
      "[82, 180] loss: 0.089\n",
      "[82, 240] loss: 0.093\n",
      "[82, 300] loss: 0.087\n",
      "[82, 360] loss: 0.087\n",
      "Epoch: 82 -> Loss: 0.130244344473\n",
      "Epoch: 82 -> Test Accuracy: 87.11\n",
      "[83, 60] loss: 0.085\n",
      "[83, 120] loss: 0.083\n",
      "[83, 180] loss: 0.084\n",
      "[83, 240] loss: 0.079\n",
      "[83, 300] loss: 0.085\n",
      "[83, 360] loss: 0.087\n",
      "Epoch: 83 -> Loss: 0.145569801331\n",
      "Epoch: 83 -> Test Accuracy: 87.03\n",
      "[84, 60] loss: 0.087\n",
      "[84, 120] loss: 0.081\n",
      "[84, 180] loss: 0.077\n",
      "[84, 240] loss: 0.085\n",
      "[84, 300] loss: 0.078\n",
      "[84, 360] loss: 0.083\n",
      "Epoch: 84 -> Loss: 0.0573188178241\n",
      "Epoch: 84 -> Test Accuracy: 87.01\n",
      "[85, 60] loss: 0.087\n",
      "[85, 120] loss: 0.081\n",
      "[85, 180] loss: 0.083\n",
      "[85, 240] loss: 0.086\n",
      "[85, 300] loss: 0.089\n",
      "[85, 360] loss: 0.087\n",
      "Epoch: 85 -> Loss: 0.0559469275177\n",
      "Epoch: 85 -> Test Accuracy: 86.96\n",
      "[86, 60] loss: 0.089\n",
      "[86, 120] loss: 0.082\n",
      "[86, 180] loss: 0.083\n",
      "[86, 240] loss: 0.080\n",
      "[86, 300] loss: 0.086\n",
      "[86, 360] loss: 0.088\n",
      "Epoch: 86 -> Loss: 0.0832186043262\n",
      "Epoch: 86 -> Test Accuracy: 87.03\n",
      "[87, 60] loss: 0.085\n",
      "[87, 120] loss: 0.087\n",
      "[87, 180] loss: 0.082\n",
      "[87, 240] loss: 0.082\n",
      "[87, 300] loss: 0.078\n",
      "[87, 360] loss: 0.087\n",
      "Epoch: 87 -> Loss: 0.0846623927355\n",
      "Epoch: 87 -> Test Accuracy: 86.89\n",
      "[88, 60] loss: 0.088\n",
      "[88, 120] loss: 0.085\n",
      "[88, 180] loss: 0.078\n",
      "[88, 240] loss: 0.081\n",
      "[88, 300] loss: 0.081\n",
      "[88, 360] loss: 0.080\n",
      "Epoch: 88 -> Loss: 0.192275077105\n",
      "Epoch: 88 -> Test Accuracy: 87.04\n",
      "[89, 60] loss: 0.089\n",
      "[89, 120] loss: 0.079\n",
      "[89, 180] loss: 0.082\n",
      "[89, 240] loss: 0.082\n",
      "[89, 300] loss: 0.089\n",
      "[89, 360] loss: 0.086\n",
      "Epoch: 89 -> Loss: 0.0764065310359\n",
      "Epoch: 89 -> Test Accuracy: 86.94\n",
      "[90, 60] loss: 0.081\n",
      "[90, 120] loss: 0.082\n",
      "[90, 180] loss: 0.080\n",
      "[90, 240] loss: 0.079\n",
      "[90, 300] loss: 0.083\n",
      "[90, 360] loss: 0.079\n",
      "Epoch: 90 -> Loss: 0.166915237904\n",
      "Epoch: 90 -> Test Accuracy: 86.93\n",
      "[91, 60] loss: 0.081\n",
      "[91, 120] loss: 0.078\n",
      "[91, 180] loss: 0.075\n",
      "[91, 240] loss: 0.082\n",
      "[91, 300] loss: 0.082\n",
      "[91, 360] loss: 0.077\n",
      "Epoch: 91 -> Loss: 0.216646552086\n",
      "Epoch: 91 -> Test Accuracy: 87.03\n",
      "[92, 60] loss: 0.079\n",
      "[92, 120] loss: 0.081\n",
      "[92, 180] loss: 0.078\n",
      "[92, 240] loss: 0.078\n",
      "[92, 300] loss: 0.081\n",
      "[92, 360] loss: 0.075\n",
      "Epoch: 92 -> Loss: 0.0774283930659\n",
      "Epoch: 92 -> Test Accuracy: 87.1\n",
      "[93, 60] loss: 0.075\n",
      "[93, 120] loss: 0.089\n",
      "[93, 180] loss: 0.079\n",
      "[93, 240] loss: 0.083\n",
      "[93, 300] loss: 0.079\n",
      "[93, 360] loss: 0.080\n",
      "Epoch: 93 -> Loss: 0.130640864372\n",
      "Epoch: 93 -> Test Accuracy: 87.01\n",
      "[94, 60] loss: 0.075\n",
      "[94, 120] loss: 0.075\n",
      "[94, 180] loss: 0.083\n",
      "[94, 240] loss: 0.078\n",
      "[94, 300] loss: 0.079\n",
      "[94, 360] loss: 0.077\n",
      "Epoch: 94 -> Loss: 0.173591434956\n",
      "Epoch: 94 -> Test Accuracy: 87.13\n",
      "[95, 60] loss: 0.079\n",
      "[95, 120] loss: 0.079\n",
      "[95, 180] loss: 0.072\n",
      "[95, 240] loss: 0.072\n",
      "[95, 300] loss: 0.082\n",
      "[95, 360] loss: 0.076\n",
      "Epoch: 95 -> Loss: 0.143856018782\n",
      "Epoch: 95 -> Test Accuracy: 86.98\n",
      "[96, 60] loss: 0.086\n",
      "[96, 120] loss: 0.074\n",
      "[96, 180] loss: 0.079\n",
      "[96, 240] loss: 0.075\n",
      "[96, 300] loss: 0.075\n",
      "[96, 360] loss: 0.078\n",
      "Epoch: 96 -> Loss: 0.019065618515\n",
      "Epoch: 96 -> Test Accuracy: 86.97\n",
      "[97, 60] loss: 0.077\n",
      "[97, 120] loss: 0.075\n",
      "[97, 180] loss: 0.073\n",
      "[97, 240] loss: 0.078\n",
      "[97, 300] loss: 0.074\n",
      "[97, 360] loss: 0.079\n",
      "Epoch: 97 -> Loss: 0.0200864132494\n",
      "Epoch: 97 -> Test Accuracy: 87.05\n",
      "[98, 60] loss: 0.073\n",
      "[98, 120] loss: 0.075\n",
      "[98, 180] loss: 0.080\n",
      "[98, 240] loss: 0.076\n",
      "[98, 300] loss: 0.085\n",
      "[98, 360] loss: 0.078\n",
      "Epoch: 98 -> Loss: 0.0972757339478\n",
      "Epoch: 98 -> Test Accuracy: 87.11\n",
      "[99, 60] loss: 0.072\n",
      "[99, 120] loss: 0.071\n",
      "[99, 180] loss: 0.079\n",
      "[99, 240] loss: 0.082\n",
      "[99, 300] loss: 0.078\n",
      "[99, 360] loss: 0.069\n",
      "Epoch: 99 -> Loss: 0.152419239283\n",
      "Epoch: 99 -> Test Accuracy: 87.12\n",
      "[100, 60] loss: 0.079\n",
      "[100, 120] loss: 0.074\n",
      "[100, 180] loss: 0.076\n",
      "[100, 240] loss: 0.081\n",
      "[100, 300] loss: 0.076\n",
      "[100, 360] loss: 0.076\n",
      "Epoch: 100 -> Loss: 0.0718118995428\n",
      "Epoch: 100 -> Test Accuracy: 87.05\n",
      "Finished Training\n",
      "[1, 60] loss: 1.699\n",
      "[1, 120] loss: 0.913\n",
      "[1, 180] loss: 0.798\n",
      "[1, 240] loss: 0.783\n",
      "[1, 300] loss: 0.753\n",
      "[1, 360] loss: 0.730\n",
      "Epoch: 1 -> Loss: 0.54692620039\n",
      "Epoch: 1 -> Test Accuracy: 72.76\n",
      "[2, 60] loss: 0.678\n",
      "[2, 120] loss: 0.676\n",
      "[2, 180] loss: 0.663\n",
      "[2, 240] loss: 0.665\n",
      "[2, 300] loss: 0.644\n",
      "[2, 360] loss: 0.642\n",
      "Epoch: 2 -> Loss: 0.518667399883\n",
      "Epoch: 2 -> Test Accuracy: 76.12\n",
      "[3, 60] loss: 0.610\n",
      "[3, 120] loss: 0.636\n",
      "[3, 180] loss: 0.609\n",
      "[3, 240] loss: 0.590\n",
      "[3, 300] loss: 0.608\n",
      "[3, 360] loss: 0.614\n",
      "Epoch: 3 -> Loss: 0.535774588585\n",
      "Epoch: 3 -> Test Accuracy: 76.89\n",
      "[4, 60] loss: 0.574\n",
      "[4, 120] loss: 0.578\n",
      "[4, 180] loss: 0.573\n",
      "[4, 240] loss: 0.583\n",
      "[4, 300] loss: 0.611\n",
      "[4, 360] loss: 0.590\n",
      "Epoch: 4 -> Loss: 0.547659993172\n",
      "Epoch: 4 -> Test Accuracy: 76.68\n",
      "[5, 60] loss: 0.560\n",
      "[5, 120] loss: 0.562\n",
      "[5, 180] loss: 0.552\n",
      "[5, 240] loss: 0.535\n",
      "[5, 300] loss: 0.584\n",
      "[5, 360] loss: 0.576\n",
      "Epoch: 5 -> Loss: 0.59639441967\n",
      "Epoch: 5 -> Test Accuracy: 77.78\n",
      "[6, 60] loss: 0.554\n",
      "[6, 120] loss: 0.528\n",
      "[6, 180] loss: 0.554\n",
      "[6, 240] loss: 0.569\n",
      "[6, 300] loss: 0.560\n",
      "[6, 360] loss: 0.546\n",
      "Epoch: 6 -> Loss: 0.663693130016\n",
      "Epoch: 6 -> Test Accuracy: 77.64\n",
      "[7, 60] loss: 0.533\n",
      "[7, 120] loss: 0.538\n",
      "[7, 180] loss: 0.558\n",
      "[7, 240] loss: 0.521\n",
      "[7, 300] loss: 0.546\n",
      "[7, 360] loss: 0.549\n",
      "Epoch: 7 -> Loss: 0.484107106924\n",
      "Epoch: 7 -> Test Accuracy: 77.33\n",
      "[8, 60] loss: 0.538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 120] loss: 0.524\n",
      "[8, 180] loss: 0.527\n",
      "[8, 240] loss: 0.534\n",
      "[8, 300] loss: 0.525\n",
      "[8, 360] loss: 0.542\n",
      "Epoch: 8 -> Loss: 0.47324219346\n",
      "Epoch: 8 -> Test Accuracy: 78.48\n",
      "[9, 60] loss: 0.523\n",
      "[9, 120] loss: 0.518\n",
      "[9, 180] loss: 0.526\n",
      "[9, 240] loss: 0.535\n",
      "[9, 300] loss: 0.528\n",
      "[9, 360] loss: 0.543\n",
      "Epoch: 9 -> Loss: 0.716715335846\n",
      "Epoch: 9 -> Test Accuracy: 78.55\n",
      "[10, 60] loss: 0.518\n",
      "[10, 120] loss: 0.518\n",
      "[10, 180] loss: 0.528\n",
      "[10, 240] loss: 0.522\n",
      "[10, 300] loss: 0.525\n",
      "[10, 360] loss: 0.522\n",
      "Epoch: 10 -> Loss: 0.647689819336\n",
      "Epoch: 10 -> Test Accuracy: 78.1\n",
      "[11, 60] loss: 0.518\n",
      "[11, 120] loss: 0.498\n",
      "[11, 180] loss: 0.511\n",
      "[11, 240] loss: 0.521\n",
      "[11, 300] loss: 0.519\n",
      "[11, 360] loss: 0.536\n",
      "Epoch: 11 -> Loss: 0.603722453117\n",
      "Epoch: 11 -> Test Accuracy: 78.08\n",
      "[12, 60] loss: 0.509\n",
      "[12, 120] loss: 0.521\n",
      "[12, 180] loss: 0.490\n",
      "[12, 240] loss: 0.513\n",
      "[12, 300] loss: 0.522\n",
      "[12, 360] loss: 0.522\n",
      "Epoch: 12 -> Loss: 0.797437250614\n",
      "Epoch: 12 -> Test Accuracy: 79.33\n",
      "[13, 60] loss: 0.499\n",
      "[13, 120] loss: 0.505\n",
      "[13, 180] loss: 0.519\n",
      "[13, 240] loss: 0.513\n",
      "[13, 300] loss: 0.521\n",
      "[13, 360] loss: 0.506\n",
      "Epoch: 13 -> Loss: 0.372500419617\n",
      "Epoch: 13 -> Test Accuracy: 79.02\n",
      "[14, 60] loss: 0.488\n",
      "[14, 120] loss: 0.496\n",
      "[14, 180] loss: 0.505\n",
      "[14, 240] loss: 0.512\n",
      "[14, 300] loss: 0.523\n",
      "[14, 360] loss: 0.514\n",
      "Epoch: 14 -> Loss: 0.597904801369\n",
      "Epoch: 14 -> Test Accuracy: 78.15\n",
      "[15, 60] loss: 0.508\n",
      "[15, 120] loss: 0.491\n",
      "[15, 180] loss: 0.510\n",
      "[15, 240] loss: 0.510\n",
      "[15, 300] loss: 0.505\n",
      "[15, 360] loss: 0.500\n",
      "Epoch: 15 -> Loss: 0.520391345024\n",
      "Epoch: 15 -> Test Accuracy: 79.55\n",
      "[16, 60] loss: 0.494\n",
      "[16, 120] loss: 0.482\n",
      "[16, 180] loss: 0.487\n",
      "[16, 240] loss: 0.505\n",
      "[16, 300] loss: 0.518\n",
      "[16, 360] loss: 0.521\n",
      "Epoch: 16 -> Loss: 0.620915651321\n",
      "Epoch: 16 -> Test Accuracy: 79.21\n",
      "[17, 60] loss: 0.495\n",
      "[17, 120] loss: 0.487\n",
      "[17, 180] loss: 0.494\n",
      "[17, 240] loss: 0.510\n",
      "[17, 300] loss: 0.496\n",
      "[17, 360] loss: 0.514\n",
      "Epoch: 17 -> Loss: 0.491417169571\n",
      "Epoch: 17 -> Test Accuracy: 79.12\n",
      "[18, 60] loss: 0.479\n",
      "[18, 120] loss: 0.475\n",
      "[18, 180] loss: 0.509\n",
      "[18, 240] loss: 0.499\n",
      "[18, 300] loss: 0.504\n",
      "[18, 360] loss: 0.509\n",
      "Epoch: 18 -> Loss: 0.659747362137\n",
      "Epoch: 18 -> Test Accuracy: 78.56\n",
      "[19, 60] loss: 0.485\n",
      "[19, 120] loss: 0.475\n",
      "[19, 180] loss: 0.499\n",
      "[19, 240] loss: 0.503\n",
      "[19, 300] loss: 0.491\n",
      "[19, 360] loss: 0.495\n",
      "Epoch: 19 -> Loss: 0.687236964703\n",
      "Epoch: 19 -> Test Accuracy: 78.43\n",
      "[20, 60] loss: 0.492\n",
      "[20, 120] loss: 0.495\n",
      "[20, 180] loss: 0.493\n",
      "[20, 240] loss: 0.513\n",
      "[20, 300] loss: 0.471\n",
      "[20, 360] loss: 0.520\n",
      "Epoch: 20 -> Loss: 0.48336020112\n",
      "Epoch: 20 -> Test Accuracy: 78.13\n",
      "[21, 60] loss: 0.452\n",
      "[21, 120] loss: 0.417\n",
      "[21, 180] loss: 0.430\n",
      "[21, 240] loss: 0.416\n",
      "[21, 300] loss: 0.417\n",
      "[21, 360] loss: 0.418\n",
      "Epoch: 21 -> Loss: 0.593812227249\n",
      "Epoch: 21 -> Test Accuracy: 80.58\n",
      "[22, 60] loss: 0.412\n",
      "[22, 120] loss: 0.411\n",
      "[22, 180] loss: 0.380\n",
      "[22, 240] loss: 0.395\n",
      "[22, 300] loss: 0.403\n",
      "[22, 360] loss: 0.397\n",
      "Epoch: 22 -> Loss: 0.596472084522\n",
      "Epoch: 22 -> Test Accuracy: 80.61\n",
      "[23, 60] loss: 0.396\n",
      "[23, 120] loss: 0.405\n",
      "[23, 180] loss: 0.371\n",
      "[23, 240] loss: 0.384\n",
      "[23, 300] loss: 0.373\n",
      "[23, 360] loss: 0.386\n",
      "Epoch: 23 -> Loss: 0.477716296911\n",
      "Epoch: 23 -> Test Accuracy: 81.01\n",
      "[24, 60] loss: 0.370\n",
      "[24, 120] loss: 0.372\n",
      "[24, 180] loss: 0.373\n",
      "[24, 240] loss: 0.387\n",
      "[24, 300] loss: 0.386\n",
      "[24, 360] loss: 0.366\n",
      "Epoch: 24 -> Loss: 0.332958132029\n",
      "Epoch: 24 -> Test Accuracy: 80.68\n",
      "[25, 60] loss: 0.371\n",
      "[25, 120] loss: 0.347\n",
      "[25, 180] loss: 0.366\n",
      "[25, 240] loss: 0.359\n",
      "[25, 300] loss: 0.373\n",
      "[25, 360] loss: 0.381\n",
      "Epoch: 25 -> Loss: 0.583416044712\n",
      "Epoch: 25 -> Test Accuracy: 80.64\n",
      "[26, 60] loss: 0.365\n",
      "[26, 120] loss: 0.363\n",
      "[26, 180] loss: 0.367\n",
      "[26, 240] loss: 0.353\n",
      "[26, 300] loss: 0.363\n",
      "[26, 360] loss: 0.378\n",
      "Epoch: 26 -> Loss: 0.380301654339\n",
      "Epoch: 26 -> Test Accuracy: 81.29\n",
      "[27, 60] loss: 0.353\n",
      "[27, 120] loss: 0.348\n",
      "[27, 180] loss: 0.357\n",
      "[27, 240] loss: 0.372\n",
      "[27, 300] loss: 0.359\n",
      "[27, 360] loss: 0.347\n",
      "Epoch: 27 -> Loss: 0.518339514732\n",
      "Epoch: 27 -> Test Accuracy: 81.28\n",
      "[28, 60] loss: 0.351\n",
      "[28, 120] loss: 0.356\n",
      "[28, 180] loss: 0.359\n",
      "[28, 240] loss: 0.343\n",
      "[28, 300] loss: 0.356\n",
      "[28, 360] loss: 0.354\n",
      "Epoch: 28 -> Loss: 0.420798480511\n",
      "Epoch: 28 -> Test Accuracy: 81.25\n",
      "[29, 60] loss: 0.354\n",
      "[29, 120] loss: 0.346\n",
      "[29, 180] loss: 0.341\n",
      "[29, 240] loss: 0.345\n",
      "[29, 300] loss: 0.357\n",
      "[29, 360] loss: 0.354\n",
      "Epoch: 29 -> Loss: 0.290192812681\n",
      "Epoch: 29 -> Test Accuracy: 81.31\n",
      "[30, 60] loss: 0.335\n",
      "[30, 120] loss: 0.351\n",
      "[30, 180] loss: 0.364\n",
      "[30, 240] loss: 0.351\n",
      "[30, 300] loss: 0.349\n",
      "[30, 360] loss: 0.362\n",
      "Epoch: 30 -> Loss: 0.41212105751\n",
      "Epoch: 30 -> Test Accuracy: 80.9\n",
      "[31, 60] loss: 0.336\n",
      "[31, 120] loss: 0.336\n",
      "[31, 180] loss: 0.345\n",
      "[31, 240] loss: 0.358\n",
      "[31, 300] loss: 0.355\n",
      "[31, 360] loss: 0.361\n",
      "Epoch: 31 -> Loss: 0.299244046211\n",
      "Epoch: 31 -> Test Accuracy: 80.76\n",
      "[32, 60] loss: 0.336\n",
      "[32, 120] loss: 0.332\n",
      "[32, 180] loss: 0.348\n",
      "[32, 240] loss: 0.346\n",
      "[32, 300] loss: 0.348\n",
      "[32, 360] loss: 0.354\n",
      "Epoch: 32 -> Loss: 0.193388342857\n",
      "Epoch: 32 -> Test Accuracy: 81.34\n",
      "[33, 60] loss: 0.324\n",
      "[33, 120] loss: 0.339\n",
      "[33, 180] loss: 0.348\n",
      "[33, 240] loss: 0.318\n",
      "[33, 300] loss: 0.352\n",
      "[33, 360] loss: 0.365\n",
      "Epoch: 33 -> Loss: 0.345343291759\n",
      "Epoch: 33 -> Test Accuracy: 80.74\n",
      "[34, 60] loss: 0.336\n",
      "[34, 120] loss: 0.345\n",
      "[34, 180] loss: 0.356\n",
      "[34, 240] loss: 0.344\n",
      "[34, 300] loss: 0.339\n",
      "[34, 360] loss: 0.339\n",
      "Epoch: 34 -> Loss: 0.441053628922\n",
      "Epoch: 34 -> Test Accuracy: 81.04\n",
      "[35, 60] loss: 0.329\n",
      "[35, 120] loss: 0.328\n",
      "[35, 180] loss: 0.327\n",
      "[35, 240] loss: 0.359\n",
      "[35, 300] loss: 0.351\n",
      "[35, 360] loss: 0.359\n",
      "Epoch: 35 -> Loss: 0.563822925091\n",
      "Epoch: 35 -> Test Accuracy: 80.86\n",
      "[36, 60] loss: 0.338\n",
      "[36, 120] loss: 0.335\n",
      "[36, 180] loss: 0.342\n",
      "[36, 240] loss: 0.339\n",
      "[36, 300] loss: 0.338\n",
      "[36, 360] loss: 0.338\n",
      "Epoch: 36 -> Loss: 0.383585929871\n",
      "Epoch: 36 -> Test Accuracy: 80.84\n",
      "[37, 60] loss: 0.334\n",
      "[37, 120] loss: 0.344\n",
      "[37, 180] loss: 0.335\n",
      "[37, 240] loss: 0.342\n",
      "[37, 300] loss: 0.346\n",
      "[37, 360] loss: 0.351\n",
      "Epoch: 37 -> Loss: 0.292511582375\n",
      "Epoch: 37 -> Test Accuracy: 81.23\n",
      "[38, 60] loss: 0.318\n",
      "[38, 120] loss: 0.344\n",
      "[38, 180] loss: 0.335\n",
      "[38, 240] loss: 0.338\n",
      "[38, 300] loss: 0.333\n",
      "[38, 360] loss: 0.344\n",
      "Epoch: 38 -> Loss: 0.369464933872\n",
      "Epoch: 38 -> Test Accuracy: 80.64\n",
      "[39, 60] loss: 0.318\n",
      "[39, 120] loss: 0.328\n",
      "[39, 180] loss: 0.349\n",
      "[39, 240] loss: 0.339\n",
      "[39, 300] loss: 0.337\n",
      "[39, 360] loss: 0.337\n",
      "Epoch: 39 -> Loss: 0.253609716892\n",
      "Epoch: 39 -> Test Accuracy: 80.53\n",
      "[40, 60] loss: 0.317\n",
      "[40, 120] loss: 0.330\n",
      "[40, 180] loss: 0.345\n",
      "[40, 240] loss: 0.339\n",
      "[40, 300] loss: 0.343\n",
      "[40, 360] loss: 0.346\n",
      "Epoch: 40 -> Loss: 0.451118081808\n",
      "Epoch: 40 -> Test Accuracy: 80.3\n",
      "[41, 60] loss: 0.312\n",
      "[41, 120] loss: 0.317\n",
      "[41, 180] loss: 0.298\n",
      "[41, 240] loss: 0.298\n",
      "[41, 300] loss: 0.296\n",
      "[41, 360] loss: 0.306\n",
      "Epoch: 41 -> Loss: 0.352387964725\n",
      "Epoch: 41 -> Test Accuracy: 81.28\n",
      "[42, 60] loss: 0.288\n",
      "[42, 120] loss: 0.296\n",
      "[42, 180] loss: 0.284\n",
      "[42, 240] loss: 0.272\n",
      "[42, 300] loss: 0.275\n",
      "[42, 360] loss: 0.274\n",
      "Epoch: 42 -> Loss: 0.357509166002\n",
      "Epoch: 42 -> Test Accuracy: 81.32\n",
      "[43, 60] loss: 0.270\n",
      "[43, 120] loss: 0.270\n",
      "[43, 180] loss: 0.270\n",
      "[43, 240] loss: 0.275\n",
      "[43, 300] loss: 0.269\n",
      "[43, 360] loss: 0.281\n",
      "Epoch: 43 -> Loss: 0.322040677071\n",
      "Epoch: 43 -> Test Accuracy: 81.32\n",
      "[44, 60] loss: 0.263\n",
      "[44, 120] loss: 0.260\n",
      "[44, 180] loss: 0.259\n",
      "[44, 240] loss: 0.266\n",
      "[44, 300] loss: 0.270\n",
      "[44, 360] loss: 0.268\n",
      "Epoch: 44 -> Loss: 0.261559635401\n",
      "Epoch: 44 -> Test Accuracy: 81.41\n",
      "[45, 60] loss: 0.266\n",
      "[45, 120] loss: 0.267\n",
      "[45, 180] loss: 0.257\n",
      "[45, 240] loss: 0.268\n",
      "[45, 300] loss: 0.260\n",
      "[45, 360] loss: 0.276\n",
      "Epoch: 45 -> Loss: 0.176658630371\n",
      "Epoch: 45 -> Test Accuracy: 81.63\n",
      "[46, 60] loss: 0.255\n",
      "[46, 120] loss: 0.247\n",
      "[46, 180] loss: 0.264\n",
      "[46, 240] loss: 0.252\n",
      "[46, 300] loss: 0.259\n",
      "[46, 360] loss: 0.239\n",
      "Epoch: 46 -> Loss: 0.29684945941\n",
      "Epoch: 46 -> Test Accuracy: 81.77\n",
      "[47, 60] loss: 0.261\n",
      "[47, 120] loss: 0.242\n",
      "[47, 180] loss: 0.244\n",
      "[47, 240] loss: 0.267\n",
      "[47, 300] loss: 0.258\n",
      "[47, 360] loss: 0.244\n",
      "Epoch: 47 -> Loss: 0.317887157202\n",
      "Epoch: 47 -> Test Accuracy: 81.94\n",
      "[48, 60] loss: 0.235\n",
      "[48, 120] loss: 0.251\n",
      "[48, 180] loss: 0.255\n",
      "[48, 240] loss: 0.234\n",
      "[48, 300] loss: 0.251\n",
      "[48, 360] loss: 0.255\n",
      "Epoch: 48 -> Loss: 0.263595402241\n",
      "Epoch: 48 -> Test Accuracy: 81.72\n",
      "[49, 60] loss: 0.245\n",
      "[49, 120] loss: 0.247\n",
      "[49, 180] loss: 0.248\n",
      "[49, 240] loss: 0.247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 300] loss: 0.246\n",
      "[49, 360] loss: 0.246\n",
      "Epoch: 49 -> Loss: 0.498691171408\n",
      "Epoch: 49 -> Test Accuracy: 81.74\n",
      "[50, 60] loss: 0.242\n",
      "[50, 120] loss: 0.233\n",
      "[50, 180] loss: 0.238\n",
      "[50, 240] loss: 0.256\n",
      "[50, 300] loss: 0.239\n",
      "[50, 360] loss: 0.237\n",
      "Epoch: 50 -> Loss: 0.240729287267\n",
      "Epoch: 50 -> Test Accuracy: 81.75\n",
      "[51, 60] loss: 0.229\n",
      "[51, 120] loss: 0.255\n",
      "[51, 180] loss: 0.236\n",
      "[51, 240] loss: 0.239\n",
      "[51, 300] loss: 0.249\n",
      "[51, 360] loss: 0.246\n",
      "Epoch: 51 -> Loss: 0.222125843167\n",
      "Epoch: 51 -> Test Accuracy: 81.65\n",
      "[52, 60] loss: 0.236\n",
      "[52, 120] loss: 0.243\n",
      "[52, 180] loss: 0.240\n",
      "[52, 240] loss: 0.245\n",
      "[52, 300] loss: 0.254\n",
      "[52, 360] loss: 0.249\n",
      "Epoch: 52 -> Loss: 0.196796581149\n",
      "Epoch: 52 -> Test Accuracy: 81.89\n",
      "[53, 60] loss: 0.228\n",
      "[53, 120] loss: 0.238\n",
      "[53, 180] loss: 0.258\n",
      "[53, 240] loss: 0.233\n",
      "[53, 300] loss: 0.234\n",
      "[53, 360] loss: 0.235\n",
      "Epoch: 53 -> Loss: 0.359286755323\n",
      "Epoch: 53 -> Test Accuracy: 81.79\n",
      "[54, 60] loss: 0.250\n",
      "[54, 120] loss: 0.236\n",
      "[54, 180] loss: 0.240\n",
      "[54, 240] loss: 0.253\n",
      "[54, 300] loss: 0.239\n",
      "[54, 360] loss: 0.236\n",
      "Epoch: 54 -> Loss: 0.159798547626\n",
      "Epoch: 54 -> Test Accuracy: 81.88\n",
      "[55, 60] loss: 0.235\n",
      "[55, 120] loss: 0.237\n",
      "[55, 180] loss: 0.240\n",
      "[55, 240] loss: 0.230\n",
      "[55, 300] loss: 0.237\n",
      "[55, 360] loss: 0.233\n",
      "Epoch: 55 -> Loss: 0.167512208223\n",
      "Epoch: 55 -> Test Accuracy: 81.75\n",
      "[56, 60] loss: 0.228\n",
      "[56, 120] loss: 0.236\n",
      "[56, 180] loss: 0.231\n",
      "[56, 240] loss: 0.244\n",
      "[56, 300] loss: 0.224\n",
      "[56, 360] loss: 0.243\n",
      "Epoch: 56 -> Loss: 0.356665790081\n",
      "Epoch: 56 -> Test Accuracy: 81.65\n",
      "[57, 60] loss: 0.236\n",
      "[57, 120] loss: 0.235\n",
      "[57, 180] loss: 0.243\n",
      "[57, 240] loss: 0.241\n",
      "[57, 300] loss: 0.235\n",
      "[57, 360] loss: 0.224\n",
      "Epoch: 57 -> Loss: 0.215654581785\n",
      "Epoch: 57 -> Test Accuracy: 81.95\n",
      "[58, 60] loss: 0.230\n",
      "[58, 120] loss: 0.245\n",
      "[58, 180] loss: 0.246\n",
      "[58, 240] loss: 0.236\n",
      "[58, 300] loss: 0.227\n",
      "[58, 360] loss: 0.231\n",
      "Epoch: 58 -> Loss: 0.16846768558\n",
      "Epoch: 58 -> Test Accuracy: 81.88\n",
      "[59, 60] loss: 0.234\n",
      "[59, 120] loss: 0.232\n",
      "[59, 180] loss: 0.236\n",
      "[59, 240] loss: 0.234\n",
      "[59, 300] loss: 0.242\n",
      "[59, 360] loss: 0.225\n",
      "Epoch: 59 -> Loss: 0.172052279115\n",
      "Epoch: 59 -> Test Accuracy: 82.05\n",
      "[60, 60] loss: 0.238\n",
      "[60, 120] loss: 0.235\n",
      "[60, 180] loss: 0.221\n",
      "[60, 240] loss: 0.229\n",
      "[60, 300] loss: 0.234\n",
      "[60, 360] loss: 0.232\n",
      "Epoch: 60 -> Loss: 0.130763620138\n",
      "Epoch: 60 -> Test Accuracy: 81.95\n",
      "[61, 60] loss: 0.230\n",
      "[61, 120] loss: 0.228\n",
      "[61, 180] loss: 0.225\n",
      "[61, 240] loss: 0.234\n",
      "[61, 300] loss: 0.236\n",
      "[61, 360] loss: 0.227\n",
      "Epoch: 61 -> Loss: 0.168467327952\n",
      "Epoch: 61 -> Test Accuracy: 82.02\n",
      "[62, 60] loss: 0.230\n",
      "[62, 120] loss: 0.232\n",
      "[62, 180] loss: 0.228\n",
      "[62, 240] loss: 0.234\n",
      "[62, 300] loss: 0.241\n",
      "[62, 360] loss: 0.222\n",
      "Epoch: 62 -> Loss: 0.289818108082\n",
      "Epoch: 62 -> Test Accuracy: 82.14\n",
      "[63, 60] loss: 0.229\n",
      "[63, 120] loss: 0.241\n",
      "[63, 180] loss: 0.232\n",
      "[63, 240] loss: 0.219\n",
      "[63, 300] loss: 0.222\n",
      "[63, 360] loss: 0.233\n",
      "Epoch: 63 -> Loss: 0.273625254631\n",
      "Epoch: 63 -> Test Accuracy: 81.85\n",
      "[64, 60] loss: 0.218\n",
      "[64, 120] loss: 0.213\n",
      "[64, 180] loss: 0.216\n",
      "[64, 240] loss: 0.236\n",
      "[64, 300] loss: 0.219\n",
      "[64, 360] loss: 0.242\n",
      "Epoch: 64 -> Loss: 0.255795657635\n",
      "Epoch: 64 -> Test Accuracy: 81.87\n",
      "[65, 60] loss: 0.217\n",
      "[65, 120] loss: 0.234\n",
      "[65, 180] loss: 0.235\n",
      "[65, 240] loss: 0.223\n",
      "[65, 300] loss: 0.228\n",
      "[65, 360] loss: 0.222\n",
      "Epoch: 65 -> Loss: 0.164185106754\n",
      "Epoch: 65 -> Test Accuracy: 81.83\n",
      "[66, 60] loss: 0.218\n",
      "[66, 120] loss: 0.225\n",
      "[66, 180] loss: 0.234\n",
      "[66, 240] loss: 0.221\n",
      "[66, 300] loss: 0.223\n",
      "[66, 360] loss: 0.237\n",
      "Epoch: 66 -> Loss: 0.269090145826\n",
      "Epoch: 66 -> Test Accuracy: 81.86\n",
      "[67, 60] loss: 0.226\n",
      "[67, 120] loss: 0.230\n",
      "[67, 180] loss: 0.233\n",
      "[67, 240] loss: 0.230\n",
      "[67, 300] loss: 0.227\n",
      "[67, 360] loss: 0.226\n",
      "Epoch: 67 -> Loss: 0.367041766644\n",
      "Epoch: 67 -> Test Accuracy: 81.95\n",
      "[68, 60] loss: 0.215\n",
      "[68, 120] loss: 0.229\n",
      "[68, 180] loss: 0.223\n",
      "[68, 240] loss: 0.222\n",
      "[68, 300] loss: 0.234\n",
      "[68, 360] loss: 0.217\n",
      "Epoch: 68 -> Loss: 0.277330905199\n",
      "Epoch: 68 -> Test Accuracy: 81.96\n",
      "[69, 60] loss: 0.227\n",
      "[69, 120] loss: 0.224\n",
      "[69, 180] loss: 0.228\n",
      "[69, 240] loss: 0.218\n",
      "[69, 300] loss: 0.209\n",
      "[69, 360] loss: 0.229\n",
      "Epoch: 69 -> Loss: 0.337979525328\n",
      "Epoch: 69 -> Test Accuracy: 81.91\n",
      "[70, 60] loss: 0.226\n",
      "[70, 120] loss: 0.224\n",
      "[70, 180] loss: 0.216\n",
      "[70, 240] loss: 0.219\n",
      "[70, 300] loss: 0.217\n",
      "[70, 360] loss: 0.230\n",
      "Epoch: 70 -> Loss: 0.259454667568\n",
      "Epoch: 70 -> Test Accuracy: 81.95\n",
      "[71, 60] loss: 0.220\n",
      "[71, 120] loss: 0.232\n",
      "[71, 180] loss: 0.221\n",
      "[71, 240] loss: 0.218\n",
      "[71, 300] loss: 0.222\n",
      "[71, 360] loss: 0.212\n",
      "Epoch: 71 -> Loss: 0.15403226018\n",
      "Epoch: 71 -> Test Accuracy: 81.94\n",
      "[72, 60] loss: 0.224\n",
      "[72, 120] loss: 0.205\n",
      "[72, 180] loss: 0.221\n",
      "[72, 240] loss: 0.229\n",
      "[72, 300] loss: 0.216\n",
      "[72, 360] loss: 0.224\n",
      "Epoch: 72 -> Loss: 0.200760364532\n",
      "Epoch: 72 -> Test Accuracy: 82.06\n",
      "[73, 60] loss: 0.210\n",
      "[73, 120] loss: 0.220\n",
      "[73, 180] loss: 0.221\n",
      "[73, 240] loss: 0.218\n",
      "[73, 300] loss: 0.219\n",
      "[73, 360] loss: 0.216\n",
      "Epoch: 73 -> Loss: 0.168803423643\n",
      "Epoch: 73 -> Test Accuracy: 81.95\n",
      "[74, 60] loss: 0.225\n",
      "[74, 120] loss: 0.236\n",
      "[74, 180] loss: 0.216\n",
      "[74, 240] loss: 0.218\n",
      "[74, 300] loss: 0.206\n",
      "[74, 360] loss: 0.219\n",
      "Epoch: 74 -> Loss: 0.196225956082\n",
      "Epoch: 74 -> Test Accuracy: 81.98\n",
      "[75, 60] loss: 0.207\n",
      "[75, 120] loss: 0.218\n",
      "[75, 180] loss: 0.222\n",
      "[75, 240] loss: 0.221\n",
      "[75, 300] loss: 0.221\n",
      "[75, 360] loss: 0.208\n",
      "Epoch: 75 -> Loss: 0.254274785519\n",
      "Epoch: 75 -> Test Accuracy: 81.99\n",
      "[76, 60] loss: 0.210\n",
      "[76, 120] loss: 0.214\n",
      "[76, 180] loss: 0.230\n",
      "[76, 240] loss: 0.212\n",
      "[76, 300] loss: 0.219\n",
      "[76, 360] loss: 0.215\n",
      "Epoch: 76 -> Loss: 0.242740154266\n",
      "Epoch: 76 -> Test Accuracy: 81.97\n",
      "[77, 60] loss: 0.209\n",
      "[77, 120] loss: 0.208\n",
      "[77, 180] loss: 0.229\n",
      "[77, 240] loss: 0.212\n",
      "[77, 300] loss: 0.209\n",
      "[77, 360] loss: 0.215\n",
      "Epoch: 77 -> Loss: 0.19202812016\n",
      "Epoch: 77 -> Test Accuracy: 81.91\n",
      "[78, 60] loss: 0.216\n",
      "[78, 120] loss: 0.219\n",
      "[78, 180] loss: 0.218\n",
      "[78, 240] loss: 0.214\n",
      "[78, 300] loss: 0.210\n",
      "[78, 360] loss: 0.212\n",
      "Epoch: 78 -> Loss: 0.25531706214\n",
      "Epoch: 78 -> Test Accuracy: 81.98\n",
      "[79, 60] loss: 0.207\n",
      "[79, 120] loss: 0.218\n",
      "[79, 180] loss: 0.204\n",
      "[79, 240] loss: 0.216\n",
      "[79, 300] loss: 0.207\n",
      "[79, 360] loss: 0.225\n",
      "Epoch: 79 -> Loss: 0.389507710934\n",
      "Epoch: 79 -> Test Accuracy: 81.98\n",
      "[80, 60] loss: 0.211\n",
      "[80, 120] loss: 0.217\n",
      "[80, 180] loss: 0.216\n",
      "[80, 240] loss: 0.216\n",
      "[80, 300] loss: 0.220\n",
      "[80, 360] loss: 0.211\n",
      "Epoch: 80 -> Loss: 0.197521001101\n",
      "Epoch: 80 -> Test Accuracy: 81.95\n",
      "[81, 60] loss: 0.208\n",
      "[81, 120] loss: 0.214\n",
      "[81, 180] loss: 0.199\n",
      "[81, 240] loss: 0.217\n",
      "[81, 300] loss: 0.216\n",
      "[81, 360] loss: 0.212\n",
      "Epoch: 81 -> Loss: 0.172801971436\n",
      "Epoch: 81 -> Test Accuracy: 82.03\n",
      "[82, 60] loss: 0.207\n",
      "[82, 120] loss: 0.212\n",
      "[82, 180] loss: 0.202\n",
      "[82, 240] loss: 0.210\n",
      "[82, 300] loss: 0.221\n",
      "[82, 360] loss: 0.215\n",
      "Epoch: 82 -> Loss: 0.219598963857\n",
      "Epoch: 82 -> Test Accuracy: 81.9\n",
      "[83, 60] loss: 0.218\n",
      "[83, 120] loss: 0.205\n",
      "[83, 180] loss: 0.208\n",
      "[83, 240] loss: 0.207\n",
      "[83, 300] loss: 0.218\n",
      "[83, 360] loss: 0.219\n",
      "Epoch: 83 -> Loss: 0.264281511307\n",
      "Epoch: 83 -> Test Accuracy: 81.95\n",
      "[84, 60] loss: 0.197\n",
      "[84, 120] loss: 0.208\n",
      "[84, 180] loss: 0.209\n",
      "[84, 240] loss: 0.206\n",
      "[84, 300] loss: 0.205\n",
      "[84, 360] loss: 0.205\n",
      "Epoch: 84 -> Loss: 0.291994303465\n",
      "Epoch: 84 -> Test Accuracy: 81.83\n",
      "[85, 60] loss: 0.209\n",
      "[85, 120] loss: 0.214\n",
      "[85, 180] loss: 0.209\n",
      "[85, 240] loss: 0.206\n",
      "[85, 300] loss: 0.204\n",
      "[85, 360] loss: 0.199\n",
      "Epoch: 85 -> Loss: 0.266495049\n",
      "Epoch: 85 -> Test Accuracy: 81.86\n",
      "[86, 60] loss: 0.207\n",
      "[86, 120] loss: 0.207\n",
      "[86, 180] loss: 0.207\n",
      "[86, 240] loss: 0.214\n",
      "[86, 300] loss: 0.194\n",
      "[86, 360] loss: 0.207\n",
      "Epoch: 86 -> Loss: 0.193253651261\n",
      "Epoch: 86 -> Test Accuracy: 81.87\n",
      "[87, 60] loss: 0.195\n",
      "[87, 120] loss: 0.204\n",
      "[87, 180] loss: 0.211\n",
      "[87, 240] loss: 0.200\n",
      "[87, 300] loss: 0.202\n",
      "[87, 360] loss: 0.205\n",
      "Epoch: 87 -> Loss: 0.193643882871\n",
      "Epoch: 87 -> Test Accuracy: 81.69\n",
      "[88, 60] loss: 0.203\n",
      "[88, 120] loss: 0.210\n",
      "[88, 180] loss: 0.206\n",
      "[88, 240] loss: 0.202\n",
      "[88, 300] loss: 0.199\n",
      "[88, 360] loss: 0.209\n",
      "Epoch: 88 -> Loss: 0.117545232177\n",
      "Epoch: 88 -> Test Accuracy: 81.76\n",
      "[89, 60] loss: 0.191\n",
      "[89, 120] loss: 0.207\n",
      "[89, 180] loss: 0.193\n",
      "[89, 240] loss: 0.220\n",
      "[89, 300] loss: 0.208\n",
      "[89, 360] loss: 0.213\n",
      "Epoch: 89 -> Loss: 0.271049439907\n",
      "Epoch: 89 -> Test Accuracy: 81.7\n",
      "[90, 60] loss: 0.197\n",
      "[90, 120] loss: 0.202\n",
      "[90, 180] loss: 0.199\n",
      "[90, 240] loss: 0.207\n",
      "[90, 300] loss: 0.215\n",
      "[90, 360] loss: 0.213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 -> Loss: 0.144330009818\n",
      "Epoch: 90 -> Test Accuracy: 81.82\n",
      "[91, 60] loss: 0.194\n",
      "[91, 120] loss: 0.201\n",
      "[91, 180] loss: 0.208\n",
      "[91, 240] loss: 0.195\n",
      "[91, 300] loss: 0.202\n",
      "[91, 360] loss: 0.200\n",
      "Epoch: 91 -> Loss: 0.301908165216\n",
      "Epoch: 91 -> Test Accuracy: 81.86\n",
      "[92, 60] loss: 0.207\n",
      "[92, 120] loss: 0.204\n",
      "[92, 180] loss: 0.196\n",
      "[92, 240] loss: 0.213\n",
      "[92, 300] loss: 0.203\n",
      "[92, 360] loss: 0.203\n",
      "Epoch: 92 -> Loss: 0.244701221585\n",
      "Epoch: 92 -> Test Accuracy: 81.84\n",
      "[93, 60] loss: 0.207\n",
      "[93, 120] loss: 0.194\n",
      "[93, 180] loss: 0.196\n",
      "[93, 240] loss: 0.193\n",
      "[93, 300] loss: 0.198\n",
      "[93, 360] loss: 0.202\n",
      "Epoch: 93 -> Loss: 0.266982376575\n",
      "Epoch: 93 -> Test Accuracy: 81.71\n",
      "[94, 60] loss: 0.190\n",
      "[94, 120] loss: 0.199\n",
      "[94, 180] loss: 0.210\n",
      "[94, 240] loss: 0.197\n",
      "[94, 300] loss: 0.211\n",
      "[94, 360] loss: 0.200\n",
      "Epoch: 94 -> Loss: 0.319970875978\n",
      "Epoch: 94 -> Test Accuracy: 81.74\n",
      "[95, 60] loss: 0.193\n",
      "[95, 120] loss: 0.192\n",
      "[95, 180] loss: 0.190\n",
      "[95, 240] loss: 0.201\n",
      "[95, 300] loss: 0.199\n",
      "[95, 360] loss: 0.208\n",
      "Epoch: 95 -> Loss: 0.20193310082\n",
      "Epoch: 95 -> Test Accuracy: 81.88\n",
      "[96, 60] loss: 0.196\n",
      "[96, 120] loss: 0.197\n",
      "[96, 180] loss: 0.194\n",
      "[96, 240] loss: 0.203\n",
      "[96, 300] loss: 0.200\n",
      "[96, 360] loss: 0.193\n",
      "Epoch: 96 -> Loss: 0.140904709697\n",
      "Epoch: 96 -> Test Accuracy: 81.89\n",
      "[97, 60] loss: 0.199\n",
      "[97, 120] loss: 0.190\n",
      "[97, 180] loss: 0.202\n",
      "[97, 240] loss: 0.189\n",
      "[97, 300] loss: 0.196\n",
      "[97, 360] loss: 0.203\n",
      "Epoch: 97 -> Loss: 0.191393226385\n",
      "Epoch: 97 -> Test Accuracy: 81.79\n",
      "[98, 60] loss: 0.197\n",
      "[98, 120] loss: 0.195\n",
      "[98, 180] loss: 0.201\n",
      "[98, 240] loss: 0.208\n",
      "[98, 300] loss: 0.199\n",
      "[98, 360] loss: 0.199\n",
      "Epoch: 98 -> Loss: 0.112066909671\n",
      "Epoch: 98 -> Test Accuracy: 81.8\n",
      "[99, 60] loss: 0.197\n",
      "[99, 120] loss: 0.186\n",
      "[99, 180] loss: 0.192\n",
      "[99, 240] loss: 0.195\n",
      "[99, 300] loss: 0.191\n",
      "[99, 360] loss: 0.186\n",
      "Epoch: 99 -> Loss: 0.16277654469\n",
      "Epoch: 99 -> Test Accuracy: 81.79\n",
      "[100, 60] loss: 0.203\n",
      "[100, 120] loss: 0.194\n",
      "[100, 180] loss: 0.191\n",
      "[100, 240] loss: 0.202\n",
      "[100, 300] loss: 0.195\n",
      "[100, 360] loss: 0.206\n",
      "Epoch: 100 -> Loss: 0.231629371643\n",
      "Epoch: 100 -> Test Accuracy: 82.06\n",
      "Finished Training\n",
      "[1, 60] loss: 2.877\n",
      "[1, 120] loss: 2.039\n",
      "[1, 180] loss: 1.973\n",
      "[1, 240] loss: 1.928\n",
      "[1, 300] loss: 1.903\n",
      "[1, 360] loss: 1.888\n",
      "Epoch: 1 -> Loss: 1.81571519375\n",
      "Epoch: 1 -> Test Accuracy: 32.06\n",
      "[2, 60] loss: 1.841\n",
      "[2, 120] loss: 1.822\n",
      "[2, 180] loss: 1.813\n",
      "[2, 240] loss: 1.800\n",
      "[2, 300] loss: 1.807\n",
      "[2, 360] loss: 1.803\n",
      "Epoch: 2 -> Loss: 1.75125980377\n",
      "Epoch: 2 -> Test Accuracy: 35.16\n",
      "[3, 60] loss: 1.775\n",
      "[3, 120] loss: 1.782\n",
      "[3, 180] loss: 1.766\n",
      "[3, 240] loss: 1.759\n",
      "[3, 300] loss: 1.738\n",
      "[3, 360] loss: 1.731\n",
      "Epoch: 3 -> Loss: 1.89970052242\n",
      "Epoch: 3 -> Test Accuracy: 36.56\n",
      "[4, 60] loss: 1.744\n",
      "[4, 120] loss: 1.725\n",
      "[4, 180] loss: 1.726\n",
      "[4, 240] loss: 1.734\n",
      "[4, 300] loss: 1.716\n",
      "[4, 360] loss: 1.728\n",
      "Epoch: 4 -> Loss: 1.52281928062\n",
      "Epoch: 4 -> Test Accuracy: 37.08\n",
      "[5, 60] loss: 1.715\n",
      "[5, 120] loss: 1.727\n",
      "[5, 180] loss: 1.702\n",
      "[5, 240] loss: 1.713\n",
      "[5, 300] loss: 1.720\n",
      "[5, 360] loss: 1.716\n",
      "Epoch: 5 -> Loss: 1.56071448326\n",
      "Epoch: 5 -> Test Accuracy: 36.88\n",
      "[6, 60] loss: 1.693\n",
      "[6, 120] loss: 1.705\n",
      "[6, 180] loss: 1.704\n",
      "[6, 240] loss: 1.710\n",
      "[6, 300] loss: 1.695\n",
      "[6, 360] loss: 1.700\n",
      "Epoch: 6 -> Loss: 1.90132164955\n",
      "Epoch: 6 -> Test Accuracy: 37.69\n",
      "[7, 60] loss: 1.689\n",
      "[7, 120] loss: 1.689\n",
      "[7, 180] loss: 1.680\n",
      "[7, 240] loss: 1.700\n",
      "[7, 300] loss: 1.689\n",
      "[7, 360] loss: 1.696\n",
      "Epoch: 7 -> Loss: 1.63427519798\n",
      "Epoch: 7 -> Test Accuracy: 36.85\n",
      "[8, 60] loss: 1.680\n",
      "[8, 120] loss: 1.683\n",
      "[8, 180] loss: 1.680\n",
      "[8, 240] loss: 1.687\n",
      "[8, 300] loss: 1.683\n",
      "[8, 360] loss: 1.678\n",
      "Epoch: 8 -> Loss: 1.70267128944\n",
      "Epoch: 8 -> Test Accuracy: 38.25\n",
      "[9, 60] loss: 1.695\n",
      "[9, 120] loss: 1.667\n",
      "[9, 180] loss: 1.685\n",
      "[9, 240] loss: 1.684\n",
      "[9, 300] loss: 1.668\n",
      "[9, 360] loss: 1.666\n",
      "Epoch: 9 -> Loss: 1.82479071617\n",
      "Epoch: 9 -> Test Accuracy: 37.91\n",
      "[10, 60] loss: 1.675\n",
      "[10, 120] loss: 1.682\n",
      "[10, 180] loss: 1.693\n",
      "[10, 240] loss: 1.671\n",
      "[10, 300] loss: 1.677\n",
      "[10, 360] loss: 1.682\n",
      "Epoch: 10 -> Loss: 1.55050444603\n",
      "Epoch: 10 -> Test Accuracy: 38.51\n",
      "[11, 60] loss: 1.668\n",
      "[11, 120] loss: 1.659\n",
      "[11, 180] loss: 1.675\n",
      "[11, 240] loss: 1.680\n",
      "[11, 300] loss: 1.666\n",
      "[11, 360] loss: 1.667\n",
      "Epoch: 11 -> Loss: 1.66984677315\n",
      "Epoch: 11 -> Test Accuracy: 37.74\n",
      "[12, 60] loss: 1.664\n",
      "[12, 120] loss: 1.669\n",
      "[12, 180] loss: 1.675\n",
      "[12, 240] loss: 1.669\n",
      "[12, 300] loss: 1.658\n",
      "[12, 360] loss: 1.666\n",
      "Epoch: 12 -> Loss: 1.63751924038\n",
      "Epoch: 12 -> Test Accuracy: 37.52\n",
      "[13, 60] loss: 1.664\n",
      "[13, 120] loss: 1.657\n",
      "[13, 180] loss: 1.678\n",
      "[13, 240] loss: 1.661\n",
      "[13, 300] loss: 1.659\n",
      "[13, 360] loss: 1.658\n",
      "Epoch: 13 -> Loss: 1.74240720272\n",
      "Epoch: 13 -> Test Accuracy: 38.47\n",
      "[14, 60] loss: 1.650\n",
      "[14, 120] loss: 1.651\n",
      "[14, 180] loss: 1.660\n",
      "[14, 240] loss: 1.664\n",
      "[14, 300] loss: 1.656\n",
      "[14, 360] loss: 1.676\n",
      "Epoch: 14 -> Loss: 1.69313311577\n",
      "Epoch: 14 -> Test Accuracy: 38.57\n",
      "[15, 60] loss: 1.663\n",
      "[15, 120] loss: 1.649\n",
      "[15, 180] loss: 1.646\n",
      "[15, 240] loss: 1.640\n",
      "[15, 300] loss: 1.667\n",
      "[15, 360] loss: 1.648\n",
      "Epoch: 15 -> Loss: 1.71031975746\n",
      "Epoch: 15 -> Test Accuracy: 38.34\n",
      "[16, 60] loss: 1.645\n",
      "[16, 120] loss: 1.674\n",
      "[16, 180] loss: 1.650\n",
      "[16, 240] loss: 1.669\n",
      "[16, 300] loss: 1.662\n",
      "[16, 360] loss: 1.656\n",
      "Epoch: 16 -> Loss: 1.6715862751\n",
      "Epoch: 16 -> Test Accuracy: 38.27\n",
      "[17, 60] loss: 1.657\n",
      "[17, 120] loss: 1.643\n",
      "[17, 180] loss: 1.657\n",
      "[17, 240] loss: 1.648\n",
      "[17, 300] loss: 1.661\n",
      "[17, 360] loss: 1.655\n",
      "Epoch: 17 -> Loss: 1.83244681358\n",
      "Epoch: 17 -> Test Accuracy: 38.08\n",
      "[18, 60] loss: 1.649\n",
      "[18, 120] loss: 1.667\n",
      "[18, 180] loss: 1.651\n",
      "[18, 240] loss: 1.644\n",
      "[18, 300] loss: 1.647\n",
      "[18, 360] loss: 1.665\n",
      "Epoch: 18 -> Loss: 1.75106453896\n",
      "Epoch: 18 -> Test Accuracy: 38.12\n",
      "[19, 60] loss: 1.666\n",
      "[19, 120] loss: 1.643\n",
      "[19, 180] loss: 1.650\n",
      "[19, 240] loss: 1.646\n",
      "[19, 300] loss: 1.649\n",
      "[19, 360] loss: 1.655\n",
      "Epoch: 19 -> Loss: 1.5983145237\n",
      "Epoch: 19 -> Test Accuracy: 37.96\n",
      "[20, 60] loss: 1.660\n",
      "[20, 120] loss: 1.652\n",
      "[20, 180] loss: 1.665\n",
      "[20, 240] loss: 1.643\n",
      "[20, 300] loss: 1.654\n",
      "[20, 360] loss: 1.661\n",
      "Epoch: 20 -> Loss: 1.56157708168\n",
      "Epoch: 20 -> Test Accuracy: 37.96\n",
      "[21, 60] loss: 1.614\n",
      "[21, 120] loss: 1.583\n",
      "[21, 180] loss: 1.578\n",
      "[21, 240] loss: 1.556\n",
      "[21, 300] loss: 1.566\n",
      "[21, 360] loss: 1.553\n",
      "Epoch: 21 -> Loss: 1.46912753582\n",
      "Epoch: 21 -> Test Accuracy: 40.85\n",
      "[22, 60] loss: 1.551\n",
      "[22, 120] loss: 1.538\n",
      "[22, 180] loss: 1.534\n",
      "[22, 240] loss: 1.551\n",
      "[22, 300] loss: 1.547\n",
      "[22, 360] loss: 1.540\n",
      "Epoch: 22 -> Loss: 1.59301686287\n",
      "Epoch: 22 -> Test Accuracy: 41.35\n",
      "[23, 60] loss: 1.526\n",
      "[23, 120] loss: 1.532\n",
      "[23, 180] loss: 1.526\n",
      "[23, 240] loss: 1.523\n",
      "[23, 300] loss: 1.543\n",
      "[23, 360] loss: 1.536\n",
      "Epoch: 23 -> Loss: 1.50347018242\n",
      "Epoch: 23 -> Test Accuracy: 41.65\n",
      "[24, 60] loss: 1.513\n",
      "[24, 120] loss: 1.526\n",
      "[24, 180] loss: 1.529\n",
      "[24, 240] loss: 1.543\n",
      "[24, 300] loss: 1.547\n",
      "[24, 360] loss: 1.522\n",
      "Epoch: 24 -> Loss: 1.47770857811\n",
      "Epoch: 24 -> Test Accuracy: 41.88\n",
      "[25, 60] loss: 1.539\n",
      "[25, 120] loss: 1.520\n",
      "[25, 180] loss: 1.528\n",
      "[25, 240] loss: 1.523\n",
      "[25, 300] loss: 1.521\n",
      "[25, 360] loss: 1.515\n",
      "Epoch: 25 -> Loss: 1.50405704975\n",
      "Epoch: 25 -> Test Accuracy: 42.6\n",
      "[26, 60] loss: 1.524\n",
      "[26, 120] loss: 1.509\n",
      "[26, 180] loss: 1.520\n",
      "[26, 240] loss: 1.534\n",
      "[26, 300] loss: 1.515\n",
      "[26, 360] loss: 1.528\n",
      "Epoch: 26 -> Loss: 1.70724523067\n",
      "Epoch: 26 -> Test Accuracy: 41.57\n",
      "[27, 60] loss: 1.508\n",
      "[27, 120] loss: 1.521\n",
      "[27, 180] loss: 1.514\n",
      "[27, 240] loss: 1.512\n",
      "[27, 300] loss: 1.520\n",
      "[27, 360] loss: 1.524\n",
      "Epoch: 27 -> Loss: 1.5794852972\n",
      "Epoch: 27 -> Test Accuracy: 41.74\n",
      "[28, 60] loss: 1.525\n",
      "[28, 120] loss: 1.523\n",
      "[28, 180] loss: 1.528\n",
      "[28, 240] loss: 1.501\n",
      "[28, 300] loss: 1.515\n",
      "[28, 360] loss: 1.504\n",
      "Epoch: 28 -> Loss: 1.40003836155\n",
      "Epoch: 28 -> Test Accuracy: 42.71\n",
      "[29, 60] loss: 1.516\n",
      "[29, 120] loss: 1.519\n",
      "[29, 180] loss: 1.512\n",
      "[29, 240] loss: 1.515\n",
      "[29, 300] loss: 1.516\n",
      "[29, 360] loss: 1.514\n",
      "Epoch: 29 -> Loss: 1.39775621891\n",
      "Epoch: 29 -> Test Accuracy: 41.6\n",
      "[30, 60] loss: 1.520\n",
      "[30, 120] loss: 1.516\n",
      "[30, 180] loss: 1.520\n",
      "[30, 240] loss: 1.515\n",
      "[30, 300] loss: 1.506\n",
      "[30, 360] loss: 1.518\n",
      "Epoch: 30 -> Loss: 1.54206264019\n",
      "Epoch: 30 -> Test Accuracy: 41.6\n",
      "[31, 60] loss: 1.510\n",
      "[31, 120] loss: 1.512\n",
      "[31, 180] loss: 1.524\n",
      "[31, 240] loss: 1.507\n",
      "[31, 300] loss: 1.516\n",
      "[31, 360] loss: 1.525\n",
      "Epoch: 31 -> Loss: 1.44410598278\n",
      "Epoch: 31 -> Test Accuracy: 42.39\n",
      "[32, 60] loss: 1.530\n",
      "[32, 120] loss: 1.494\n",
      "[32, 180] loss: 1.499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 240] loss: 1.520\n",
      "[32, 300] loss: 1.506\n",
      "[32, 360] loss: 1.502\n",
      "Epoch: 32 -> Loss: 1.53307819366\n",
      "Epoch: 32 -> Test Accuracy: 42.22\n",
      "[33, 60] loss: 1.515\n",
      "[33, 120] loss: 1.508\n",
      "[33, 180] loss: 1.515\n",
      "[33, 240] loss: 1.510\n",
      "[33, 300] loss: 1.508\n",
      "[33, 360] loss: 1.502\n",
      "Epoch: 33 -> Loss: 1.44775021076\n",
      "Epoch: 33 -> Test Accuracy: 42.15\n",
      "[34, 60] loss: 1.496\n",
      "[34, 120] loss: 1.500\n",
      "[34, 180] loss: 1.521\n",
      "[34, 240] loss: 1.503\n",
      "[34, 300] loss: 1.510\n",
      "[34, 360] loss: 1.515\n",
      "Epoch: 34 -> Loss: 1.60223293304\n",
      "Epoch: 34 -> Test Accuracy: 42.08\n",
      "[35, 60] loss: 1.506\n",
      "[35, 120] loss: 1.505\n",
      "[35, 180] loss: 1.512\n",
      "[35, 240] loss: 1.512\n",
      "[35, 300] loss: 1.524\n",
      "[35, 360] loss: 1.496\n",
      "Epoch: 35 -> Loss: 1.43342030048\n",
      "Epoch: 35 -> Test Accuracy: 41.82\n",
      "[36, 60] loss: 1.526\n",
      "[36, 120] loss: 1.499\n",
      "[36, 180] loss: 1.506\n",
      "[36, 240] loss: 1.496\n",
      "[36, 300] loss: 1.515\n",
      "[36, 360] loss: 1.517\n",
      "Epoch: 36 -> Loss: 1.35133290291\n",
      "Epoch: 36 -> Test Accuracy: 41.7\n",
      "[37, 60] loss: 1.502\n",
      "[37, 120] loss: 1.508\n",
      "[37, 180] loss: 1.498\n",
      "[37, 240] loss: 1.503\n",
      "[37, 300] loss: 1.510\n",
      "[37, 360] loss: 1.508\n",
      "Epoch: 37 -> Loss: 1.39469695091\n",
      "Epoch: 37 -> Test Accuracy: 42.05\n",
      "[38, 60] loss: 1.479\n",
      "[38, 120] loss: 1.529\n",
      "[38, 180] loss: 1.499\n",
      "[38, 240] loss: 1.506\n",
      "[38, 300] loss: 1.503\n",
      "[38, 360] loss: 1.511\n",
      "Epoch: 38 -> Loss: 1.49214673042\n",
      "Epoch: 38 -> Test Accuracy: 42.36\n",
      "[39, 60] loss: 1.503\n",
      "[39, 120] loss: 1.495\n",
      "[39, 180] loss: 1.511\n",
      "[39, 240] loss: 1.511\n",
      "[39, 300] loss: 1.507\n",
      "[39, 360] loss: 1.507\n",
      "Epoch: 39 -> Loss: 1.42209076881\n",
      "Epoch: 39 -> Test Accuracy: 41.69\n",
      "[40, 60] loss: 1.505\n",
      "[40, 120] loss: 1.502\n",
      "[40, 180] loss: 1.509\n",
      "[40, 240] loss: 1.487\n",
      "[40, 300] loss: 1.502\n",
      "[40, 360] loss: 1.497\n",
      "Epoch: 40 -> Loss: 1.62140917778\n",
      "Epoch: 40 -> Test Accuracy: 42.32\n",
      "[41, 60] loss: 1.491\n",
      "[41, 120] loss: 1.475\n",
      "[41, 180] loss: 1.459\n",
      "[41, 240] loss: 1.456\n",
      "[41, 300] loss: 1.474\n",
      "[41, 360] loss: 1.456\n",
      "Epoch: 41 -> Loss: 1.25656497478\n",
      "Epoch: 41 -> Test Accuracy: 44.0\n",
      "[42, 60] loss: 1.436\n",
      "[42, 120] loss: 1.440\n",
      "[42, 180] loss: 1.426\n",
      "[42, 240] loss: 1.434\n",
      "[42, 300] loss: 1.453\n",
      "[42, 360] loss: 1.435\n",
      "Epoch: 42 -> Loss: 1.507802248\n",
      "Epoch: 42 -> Test Accuracy: 43.96\n",
      "[43, 60] loss: 1.426\n",
      "[43, 120] loss: 1.438\n",
      "[43, 180] loss: 1.436\n",
      "[43, 240] loss: 1.428\n",
      "[43, 300] loss: 1.432\n",
      "[43, 360] loss: 1.456\n",
      "Epoch: 43 -> Loss: 1.48420977592\n",
      "Epoch: 43 -> Test Accuracy: 44.15\n",
      "[44, 60] loss: 1.435\n",
      "[44, 120] loss: 1.423\n",
      "[44, 180] loss: 1.423\n",
      "[44, 240] loss: 1.449\n",
      "[44, 300] loss: 1.430\n",
      "[44, 360] loss: 1.434\n",
      "Epoch: 44 -> Loss: 1.418430686\n",
      "Epoch: 44 -> Test Accuracy: 43.99\n",
      "[45, 60] loss: 1.444\n",
      "[45, 120] loss: 1.419\n",
      "[45, 180] loss: 1.422\n",
      "[45, 240] loss: 1.416\n",
      "[45, 300] loss: 1.437\n",
      "[45, 360] loss: 1.422\n",
      "Epoch: 45 -> Loss: 1.45715975761\n",
      "Epoch: 45 -> Test Accuracy: 44.36\n",
      "[46, 60] loss: 1.417\n",
      "[46, 120] loss: 1.407\n",
      "[46, 180] loss: 1.421\n",
      "[46, 240] loss: 1.418\n",
      "[46, 300] loss: 1.417\n",
      "[46, 360] loss: 1.433\n",
      "Epoch: 46 -> Loss: 1.35691094398\n",
      "Epoch: 46 -> Test Accuracy: 44.82\n",
      "[47, 60] loss: 1.399\n",
      "[47, 120] loss: 1.407\n",
      "[47, 180] loss: 1.411\n",
      "[47, 240] loss: 1.410\n",
      "[47, 300] loss: 1.399\n",
      "[47, 360] loss: 1.408\n",
      "Epoch: 47 -> Loss: 1.46051299572\n",
      "Epoch: 47 -> Test Accuracy: 44.33\n",
      "[48, 60] loss: 1.400\n",
      "[48, 120] loss: 1.417\n",
      "[48, 180] loss: 1.399\n",
      "[48, 240] loss: 1.392\n",
      "[48, 300] loss: 1.420\n",
      "[48, 360] loss: 1.404\n",
      "Epoch: 48 -> Loss: 1.66138195992\n",
      "Epoch: 48 -> Test Accuracy: 44.61\n",
      "[49, 60] loss: 1.394\n",
      "[49, 120] loss: 1.403\n",
      "[49, 180] loss: 1.412\n",
      "[49, 240] loss: 1.412\n",
      "[49, 300] loss: 1.392\n",
      "[49, 360] loss: 1.408\n",
      "Epoch: 49 -> Loss: 1.34307515621\n",
      "Epoch: 49 -> Test Accuracy: 44.48\n",
      "[50, 60] loss: 1.413\n",
      "[50, 120] loss: 1.407\n",
      "[50, 180] loss: 1.428\n",
      "[50, 240] loss: 1.402\n",
      "[50, 300] loss: 1.398\n",
      "[50, 360] loss: 1.395\n",
      "Epoch: 50 -> Loss: 1.36244440079\n",
      "Epoch: 50 -> Test Accuracy: 44.58\n",
      "[51, 60] loss: 1.404\n",
      "[51, 120] loss: 1.392\n",
      "[51, 180] loss: 1.404\n",
      "[51, 240] loss: 1.406\n",
      "[51, 300] loss: 1.405\n",
      "[51, 360] loss: 1.381\n",
      "Epoch: 51 -> Loss: 1.59294843674\n",
      "Epoch: 51 -> Test Accuracy: 44.9\n",
      "[52, 60] loss: 1.407\n",
      "[52, 120] loss: 1.407\n",
      "[52, 180] loss: 1.383\n",
      "[52, 240] loss: 1.394\n",
      "[52, 300] loss: 1.410\n",
      "[52, 360] loss: 1.401\n",
      "Epoch: 52 -> Loss: 1.33531808853\n",
      "Epoch: 52 -> Test Accuracy: 44.9\n",
      "[53, 60] loss: 1.403\n",
      "[53, 120] loss: 1.409\n",
      "[53, 180] loss: 1.406\n",
      "[53, 240] loss: 1.390\n",
      "[53, 300] loss: 1.371\n",
      "[53, 360] loss: 1.387\n",
      "Epoch: 53 -> Loss: 1.28905797005\n",
      "Epoch: 53 -> Test Accuracy: 44.68\n",
      "[54, 60] loss: 1.391\n",
      "[54, 120] loss: 1.394\n",
      "[54, 180] loss: 1.394\n",
      "[54, 240] loss: 1.416\n",
      "[54, 300] loss: 1.383\n",
      "[54, 360] loss: 1.405\n",
      "Epoch: 54 -> Loss: 1.35212302208\n",
      "Epoch: 54 -> Test Accuracy: 44.56\n",
      "[55, 60] loss: 1.392\n",
      "[55, 120] loss: 1.390\n",
      "[55, 180] loss: 1.403\n",
      "[55, 240] loss: 1.398\n",
      "[55, 300] loss: 1.390\n",
      "[55, 360] loss: 1.398\n",
      "Epoch: 55 -> Loss: 1.51299035549\n",
      "Epoch: 55 -> Test Accuracy: 44.81\n",
      "[56, 60] loss: 1.391\n",
      "[56, 120] loss: 1.415\n",
      "[56, 180] loss: 1.403\n",
      "[56, 240] loss: 1.399\n",
      "[56, 300] loss: 1.397\n",
      "[56, 360] loss: 1.384\n",
      "Epoch: 56 -> Loss: 1.39515209198\n",
      "Epoch: 56 -> Test Accuracy: 44.72\n",
      "[57, 60] loss: 1.387\n",
      "[57, 120] loss: 1.394\n",
      "[57, 180] loss: 1.405\n",
      "[57, 240] loss: 1.404\n",
      "[57, 300] loss: 1.395\n",
      "[57, 360] loss: 1.395\n",
      "Epoch: 57 -> Loss: 1.33136403561\n",
      "Epoch: 57 -> Test Accuracy: 44.99\n",
      "[58, 60] loss: 1.387\n",
      "[58, 120] loss: 1.384\n",
      "[58, 180] loss: 1.425\n",
      "[58, 240] loss: 1.384\n",
      "[58, 300] loss: 1.403\n",
      "[58, 360] loss: 1.380\n",
      "Epoch: 58 -> Loss: 1.47898650169\n",
      "Epoch: 58 -> Test Accuracy: 45.03\n",
      "[59, 60] loss: 1.389\n",
      "[59, 120] loss: 1.373\n",
      "[59, 180] loss: 1.409\n",
      "[59, 240] loss: 1.382\n",
      "[59, 300] loss: 1.393\n",
      "[59, 360] loss: 1.386\n",
      "Epoch: 59 -> Loss: 1.33589243889\n",
      "Epoch: 59 -> Test Accuracy: 44.86\n",
      "[60, 60] loss: 1.399\n",
      "[60, 120] loss: 1.389\n",
      "[60, 180] loss: 1.401\n",
      "[60, 240] loss: 1.395\n",
      "[60, 300] loss: 1.385\n",
      "[60, 360] loss: 1.373\n",
      "Epoch: 60 -> Loss: 1.43451404572\n",
      "Epoch: 60 -> Test Accuracy: 45.14\n",
      "[61, 60] loss: 1.413\n",
      "[61, 120] loss: 1.396\n",
      "[61, 180] loss: 1.378\n",
      "[61, 240] loss: 1.381\n",
      "[61, 300] loss: 1.396\n",
      "[61, 360] loss: 1.401\n",
      "Epoch: 61 -> Loss: 1.51603615284\n",
      "Epoch: 61 -> Test Accuracy: 45.14\n",
      "[62, 60] loss: 1.396\n",
      "[62, 120] loss: 1.392\n",
      "[62, 180] loss: 1.380\n",
      "[62, 240] loss: 1.386\n",
      "[62, 300] loss: 1.409\n",
      "[62, 360] loss: 1.403\n",
      "Epoch: 62 -> Loss: 1.39555227757\n",
      "Epoch: 62 -> Test Accuracy: 45.26\n",
      "[63, 60] loss: 1.399\n",
      "[63, 120] loss: 1.382\n",
      "[63, 180] loss: 1.377\n",
      "[63, 240] loss: 1.397\n",
      "[63, 300] loss: 1.370\n",
      "[63, 360] loss: 1.402\n",
      "Epoch: 63 -> Loss: 1.45749080181\n",
      "Epoch: 63 -> Test Accuracy: 45.12\n",
      "[64, 60] loss: 1.380\n",
      "[64, 120] loss: 1.396\n",
      "[64, 180] loss: 1.386\n",
      "[64, 240] loss: 1.393\n",
      "[64, 300] loss: 1.392\n",
      "[64, 360] loss: 1.379\n",
      "Epoch: 64 -> Loss: 1.51662755013\n",
      "Epoch: 64 -> Test Accuracy: 45.08\n",
      "[65, 60] loss: 1.385\n",
      "[65, 120] loss: 1.388\n",
      "[65, 180] loss: 1.394\n",
      "[65, 240] loss: 1.388\n",
      "[65, 300] loss: 1.403\n",
      "[65, 360] loss: 1.381\n",
      "Epoch: 65 -> Loss: 1.27753889561\n",
      "Epoch: 65 -> Test Accuracy: 45.27\n",
      "[66, 60] loss: 1.393\n",
      "[66, 120] loss: 1.379\n",
      "[66, 180] loss: 1.377\n",
      "[66, 240] loss: 1.390\n",
      "[66, 300] loss: 1.393\n",
      "[66, 360] loss: 1.391\n",
      "Epoch: 66 -> Loss: 1.2980556488\n",
      "Epoch: 66 -> Test Accuracy: 45.34\n",
      "[67, 60] loss: 1.381\n",
      "[67, 120] loss: 1.383\n",
      "[67, 180] loss: 1.367\n",
      "[67, 240] loss: 1.390\n",
      "[67, 300] loss: 1.378\n",
      "[67, 360] loss: 1.420\n",
      "Epoch: 67 -> Loss: 1.63029253483\n",
      "Epoch: 67 -> Test Accuracy: 45.13\n",
      "[68, 60] loss: 1.382\n",
      "[68, 120] loss: 1.404\n",
      "[68, 180] loss: 1.401\n",
      "[68, 240] loss: 1.383\n",
      "[68, 300] loss: 1.376\n",
      "[68, 360] loss: 1.382\n",
      "Epoch: 68 -> Loss: 1.36562812328\n",
      "Epoch: 68 -> Test Accuracy: 45.17\n",
      "[69, 60] loss: 1.384\n",
      "[69, 120] loss: 1.394\n",
      "[69, 180] loss: 1.390\n",
      "[69, 240] loss: 1.380\n",
      "[69, 300] loss: 1.370\n",
      "[69, 360] loss: 1.374\n",
      "Epoch: 69 -> Loss: 1.32027161121\n",
      "Epoch: 69 -> Test Accuracy: 45.02\n",
      "[70, 60] loss: 1.382\n",
      "[70, 120] loss: 1.385\n",
      "[70, 180] loss: 1.380\n",
      "[70, 240] loss: 1.396\n",
      "[70, 300] loss: 1.385\n",
      "[70, 360] loss: 1.398\n",
      "Epoch: 70 -> Loss: 1.3162728548\n",
      "Epoch: 70 -> Test Accuracy: 45.3\n",
      "[71, 60] loss: 1.383\n",
      "[71, 120] loss: 1.382\n",
      "[71, 180] loss: 1.359\n",
      "[71, 240] loss: 1.402\n",
      "[71, 300] loss: 1.389\n",
      "[71, 360] loss: 1.385\n",
      "Epoch: 71 -> Loss: 1.51615691185\n",
      "Epoch: 71 -> Test Accuracy: 45.02\n",
      "[72, 60] loss: 1.379\n",
      "[72, 120] loss: 1.377\n",
      "[72, 180] loss: 1.389\n",
      "[72, 240] loss: 1.381\n",
      "[72, 300] loss: 1.381\n",
      "[72, 360] loss: 1.384\n",
      "Epoch: 72 -> Loss: 1.4912135601\n",
      "Epoch: 72 -> Test Accuracy: 45.42\n",
      "[73, 60] loss: 1.387\n",
      "[73, 120] loss: 1.372\n",
      "[73, 180] loss: 1.381\n",
      "[73, 240] loss: 1.382\n",
      "[73, 300] loss: 1.396\n",
      "[73, 360] loss: 1.374\n",
      "Epoch: 73 -> Loss: 1.32607913017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 -> Test Accuracy: 45.46\n",
      "[74, 60] loss: 1.361\n",
      "[74, 120] loss: 1.369\n",
      "[74, 180] loss: 1.387\n",
      "[74, 240] loss: 1.389\n",
      "[74, 300] loss: 1.368\n",
      "[74, 360] loss: 1.396\n",
      "Epoch: 74 -> Loss: 1.49426150322\n",
      "Epoch: 74 -> Test Accuracy: 45.52\n",
      "[75, 60] loss: 1.368\n",
      "[75, 120] loss: 1.376\n",
      "[75, 180] loss: 1.402\n",
      "[75, 240] loss: 1.377\n",
      "[75, 300] loss: 1.360\n",
      "[75, 360] loss: 1.375\n",
      "Epoch: 75 -> Loss: 1.41872096062\n",
      "Epoch: 75 -> Test Accuracy: 45.42\n",
      "[76, 60] loss: 1.366\n",
      "[76, 120] loss: 1.365\n",
      "[76, 180] loss: 1.396\n",
      "[76, 240] loss: 1.369\n",
      "[76, 300] loss: 1.405\n",
      "[76, 360] loss: 1.373\n",
      "Epoch: 76 -> Loss: 1.43177592754\n",
      "Epoch: 76 -> Test Accuracy: 45.23\n",
      "[77, 60] loss: 1.392\n",
      "[77, 120] loss: 1.369\n",
      "[77, 180] loss: 1.388\n",
      "[77, 240] loss: 1.388\n",
      "[77, 300] loss: 1.371\n",
      "[77, 360] loss: 1.376\n",
      "Epoch: 77 -> Loss: 1.51616621017\n",
      "Epoch: 77 -> Test Accuracy: 45.09\n",
      "[78, 60] loss: 1.349\n",
      "[78, 120] loss: 1.394\n",
      "[78, 180] loss: 1.362\n",
      "[78, 240] loss: 1.388\n",
      "[78, 300] loss: 1.389\n",
      "[78, 360] loss: 1.381\n",
      "Epoch: 78 -> Loss: 1.46561729908\n",
      "Epoch: 78 -> Test Accuracy: 45.22\n",
      "[79, 60] loss: 1.366\n",
      "[79, 120] loss: 1.385\n",
      "[79, 180] loss: 1.397\n",
      "[79, 240] loss: 1.375\n",
      "[79, 300] loss: 1.369\n",
      "[79, 360] loss: 1.388\n",
      "Epoch: 79 -> Loss: 1.38409495354\n",
      "Epoch: 79 -> Test Accuracy: 45.31\n",
      "[80, 60] loss: 1.378\n",
      "[80, 120] loss: 1.383\n",
      "[80, 180] loss: 1.381\n",
      "[80, 240] loss: 1.397\n",
      "[80, 300] loss: 1.378\n",
      "[80, 360] loss: 1.378\n",
      "Epoch: 80 -> Loss: 1.39296364784\n",
      "Epoch: 80 -> Test Accuracy: 45.48\n",
      "[81, 60] loss: 1.369\n",
      "[81, 120] loss: 1.367\n",
      "[81, 180] loss: 1.358\n",
      "[81, 240] loss: 1.374\n",
      "[81, 300] loss: 1.395\n",
      "[81, 360] loss: 1.398\n",
      "Epoch: 81 -> Loss: 1.27806544304\n",
      "Epoch: 81 -> Test Accuracy: 45.27\n",
      "[82, 60] loss: 1.401\n",
      "[82, 120] loss: 1.392\n",
      "[82, 180] loss: 1.379\n",
      "[82, 240] loss: 1.357\n",
      "[82, 300] loss: 1.363\n",
      "[82, 360] loss: 1.381\n",
      "Epoch: 82 -> Loss: 1.42363452911\n",
      "Epoch: 82 -> Test Accuracy: 45.15\n",
      "[83, 60] loss: 1.388\n",
      "[83, 120] loss: 1.385\n",
      "[83, 180] loss: 1.376\n",
      "[83, 240] loss: 1.364\n",
      "[83, 300] loss: 1.381\n",
      "[83, 360] loss: 1.375\n",
      "Epoch: 83 -> Loss: 1.3788523674\n",
      "Epoch: 83 -> Test Accuracy: 45.46\n",
      "[84, 60] loss: 1.397\n",
      "[84, 120] loss: 1.374\n",
      "[84, 180] loss: 1.375\n",
      "[84, 240] loss: 1.371\n",
      "[84, 300] loss: 1.392\n",
      "[84, 360] loss: 1.351\n",
      "Epoch: 84 -> Loss: 1.40906453133\n",
      "Epoch: 84 -> Test Accuracy: 45.71\n",
      "[85, 60] loss: 1.363\n",
      "[85, 120] loss: 1.394\n",
      "[85, 180] loss: 1.366\n",
      "[85, 240] loss: 1.370\n",
      "[85, 300] loss: 1.385\n",
      "[85, 360] loss: 1.354\n",
      "Epoch: 85 -> Loss: 1.35587918758\n",
      "Epoch: 85 -> Test Accuracy: 45.69\n",
      "[86, 60] loss: 1.367\n",
      "[86, 120] loss: 1.384\n",
      "[86, 180] loss: 1.382\n",
      "[86, 240] loss: 1.389\n",
      "[86, 300] loss: 1.372\n",
      "[86, 360] loss: 1.354\n",
      "Epoch: 86 -> Loss: 1.32844090462\n",
      "Epoch: 86 -> Test Accuracy: 45.41\n",
      "[87, 60] loss: 1.368\n",
      "[87, 120] loss: 1.364\n",
      "[87, 180] loss: 1.373\n",
      "[87, 240] loss: 1.386\n",
      "[87, 300] loss: 1.385\n",
      "[87, 360] loss: 1.371\n",
      "Epoch: 87 -> Loss: 1.46197712421\n",
      "Epoch: 87 -> Test Accuracy: 45.16\n",
      "[88, 60] loss: 1.394\n",
      "[88, 120] loss: 1.367\n",
      "[88, 180] loss: 1.360\n",
      "[88, 240] loss: 1.378\n",
      "[88, 300] loss: 1.400\n",
      "[88, 360] loss: 1.354\n",
      "Epoch: 88 -> Loss: 1.41291630268\n",
      "Epoch: 88 -> Test Accuracy: 45.45\n",
      "[89, 60] loss: 1.360\n",
      "[89, 120] loss: 1.378\n",
      "[89, 180] loss: 1.364\n",
      "[89, 240] loss: 1.403\n",
      "[89, 300] loss: 1.373\n",
      "[89, 360] loss: 1.360\n",
      "Epoch: 89 -> Loss: 1.24320936203\n",
      "Epoch: 89 -> Test Accuracy: 45.55\n",
      "[90, 60] loss: 1.370\n",
      "[90, 120] loss: 1.359\n",
      "[90, 180] loss: 1.353\n",
      "[90, 240] loss: 1.384\n",
      "[90, 300] loss: 1.364\n",
      "[90, 360] loss: 1.387\n",
      "Epoch: 90 -> Loss: 1.40198373795\n",
      "Epoch: 90 -> Test Accuracy: 45.5\n",
      "[91, 60] loss: 1.385\n",
      "[91, 120] loss: 1.387\n",
      "[91, 180] loss: 1.369\n",
      "[91, 240] loss: 1.367\n",
      "[91, 300] loss: 1.366\n",
      "[91, 360] loss: 1.362\n",
      "Epoch: 91 -> Loss: 1.60843157768\n",
      "Epoch: 91 -> Test Accuracy: 45.53\n",
      "[92, 60] loss: 1.374\n",
      "[92, 120] loss: 1.388\n",
      "[92, 180] loss: 1.359\n",
      "[92, 240] loss: 1.395\n",
      "[92, 300] loss: 1.362\n",
      "[92, 360] loss: 1.364\n",
      "Epoch: 92 -> Loss: 1.53172373772\n",
      "Epoch: 92 -> Test Accuracy: 45.41\n",
      "[93, 60] loss: 1.366\n",
      "[93, 120] loss: 1.366\n",
      "[93, 180] loss: 1.354\n",
      "[93, 240] loss: 1.366\n",
      "[93, 300] loss: 1.366\n",
      "[93, 360] loss: 1.386\n",
      "Epoch: 93 -> Loss: 1.41054189205\n",
      "Epoch: 93 -> Test Accuracy: 45.51\n",
      "[94, 60] loss: 1.350\n",
      "[94, 120] loss: 1.363\n",
      "[94, 180] loss: 1.364\n",
      "[94, 240] loss: 1.383\n",
      "[94, 300] loss: 1.375\n",
      "[94, 360] loss: 1.399\n",
      "Epoch: 94 -> Loss: 1.47588825226\n",
      "Epoch: 94 -> Test Accuracy: 45.46\n",
      "[95, 60] loss: 1.392\n",
      "[95, 120] loss: 1.368\n",
      "[95, 180] loss: 1.369\n",
      "[95, 240] loss: 1.352\n",
      "[95, 300] loss: 1.358\n",
      "[95, 360] loss: 1.390\n",
      "Epoch: 95 -> Loss: 1.39417099953\n",
      "Epoch: 95 -> Test Accuracy: 45.29\n",
      "[96, 60] loss: 1.362\n",
      "[96, 120] loss: 1.374\n",
      "[96, 180] loss: 1.373\n",
      "[96, 240] loss: 1.375\n",
      "[96, 300] loss: 1.359\n",
      "[96, 360] loss: 1.369\n",
      "Epoch: 96 -> Loss: 1.36585736275\n",
      "Epoch: 96 -> Test Accuracy: 45.17\n",
      "[97, 60] loss: 1.370\n",
      "[97, 120] loss: 1.378\n",
      "[97, 180] loss: 1.383\n",
      "[97, 240] loss: 1.360\n",
      "[97, 300] loss: 1.370\n",
      "[97, 360] loss: 1.356\n",
      "Epoch: 97 -> Loss: 1.37288987637\n",
      "Epoch: 97 -> Test Accuracy: 45.44\n",
      "[98, 60] loss: 1.374\n",
      "[98, 120] loss: 1.358\n",
      "[98, 180] loss: 1.366\n",
      "[98, 240] loss: 1.357\n",
      "[98, 300] loss: 1.369\n",
      "[98, 360] loss: 1.373\n",
      "Epoch: 98 -> Loss: 1.41155862808\n",
      "Epoch: 98 -> Test Accuracy: 45.48\n",
      "[99, 60] loss: 1.384\n",
      "[99, 120] loss: 1.377\n",
      "[99, 180] loss: 1.372\n",
      "[99, 240] loss: 1.382\n",
      "[99, 300] loss: 1.381\n",
      "[99, 360] loss: 1.333\n",
      "Epoch: 99 -> Loss: 1.3632401228\n",
      "Epoch: 99 -> Test Accuracy: 45.25\n",
      "[100, 60] loss: 1.355\n",
      "[100, 120] loss: 1.386\n",
      "[100, 180] loss: 1.390\n",
      "[100, 240] loss: 1.370\n",
      "[100, 300] loss: 1.359\n",
      "[100, 360] loss: 1.345\n",
      "Epoch: 100 -> Loss: 1.39532744884\n",
      "Epoch: 100 -> Test Accuracy: 45.45\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train NonLinearClassifiers on feature map of net_3block\n",
    "block4_loss_log, _, block4_test_accuracy_log, _, _ = tr.train_all_blocks(4, 10, [0.1, 0.02, 0.004, 0.0008], \n",
    "    [20, 40, 45, 100], 0.9, 5e-4, net_block4, criterion, trainloader, None, testloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.366\n",
      "[1, 120] loss: 1.033\n",
      "[1, 180] loss: 0.964\n",
      "[1, 240] loss: 0.875\n",
      "[1, 300] loss: 0.869\n",
      "[1, 360] loss: 0.829\n",
      "Epoch: 1 -> Loss: 0.770958185196\n",
      "Epoch: 1 -> Test Accuracy: 69.65\n",
      "[2, 60] loss: 0.766\n",
      "[2, 120] loss: 0.757\n",
      "[2, 180] loss: 0.720\n",
      "[2, 240] loss: 0.713\n",
      "[2, 300] loss: 0.695\n",
      "[2, 360] loss: 0.684\n",
      "Epoch: 2 -> Loss: 0.731605708599\n",
      "Epoch: 2 -> Test Accuracy: 73.18\n",
      "[3, 60] loss: 0.655\n",
      "[3, 120] loss: 0.654\n",
      "[3, 180] loss: 0.642\n",
      "[3, 240] loss: 0.651\n",
      "[3, 300] loss: 0.637\n",
      "[3, 360] loss: 0.638\n",
      "Epoch: 3 -> Loss: 0.696549057961\n",
      "Epoch: 3 -> Test Accuracy: 76.14\n",
      "[4, 60] loss: 0.592\n",
      "[4, 120] loss: 0.583\n",
      "[4, 180] loss: 0.593\n",
      "[4, 240] loss: 0.599\n",
      "[4, 300] loss: 0.595\n",
      "[4, 360] loss: 0.566\n",
      "Epoch: 4 -> Loss: 0.517301440239\n",
      "Epoch: 4 -> Test Accuracy: 75.34\n",
      "[5, 60] loss: 0.552\n",
      "[5, 120] loss: 0.543\n",
      "[5, 180] loss: 0.565\n",
      "[5, 240] loss: 0.569\n",
      "[5, 300] loss: 0.581\n",
      "[5, 360] loss: 0.544\n",
      "Epoch: 5 -> Loss: 0.716678977013\n",
      "Epoch: 5 -> Test Accuracy: 78.01\n",
      "[6, 60] loss: 0.510\n",
      "[6, 120] loss: 0.545\n",
      "[6, 180] loss: 0.534\n",
      "[6, 240] loss: 0.536\n",
      "[6, 300] loss: 0.546\n",
      "[6, 360] loss: 0.541\n",
      "Epoch: 6 -> Loss: 0.574008882046\n",
      "Epoch: 6 -> Test Accuracy: 78.91\n",
      "[7, 60] loss: 0.508\n",
      "[7, 120] loss: 0.521\n",
      "[7, 180] loss: 0.516\n",
      "[7, 240] loss: 0.533\n",
      "[7, 300] loss: 0.539\n",
      "[7, 360] loss: 0.520\n",
      "Epoch: 7 -> Loss: 0.437037080526\n",
      "Epoch: 7 -> Test Accuracy: 78.67\n",
      "[8, 60] loss: 0.476\n",
      "[8, 120] loss: 0.504\n",
      "[8, 180] loss: 0.535\n",
      "[8, 240] loss: 0.506\n",
      "[8, 300] loss: 0.503\n",
      "[8, 360] loss: 0.499\n",
      "Epoch: 8 -> Loss: 0.468064635992\n",
      "Epoch: 8 -> Test Accuracy: 79.92\n",
      "[9, 60] loss: 0.483\n",
      "[9, 120] loss: 0.491\n",
      "[9, 180] loss: 0.501\n",
      "[9, 240] loss: 0.507\n",
      "[9, 300] loss: 0.505\n",
      "[9, 360] loss: 0.487\n",
      "Epoch: 9 -> Loss: 0.617081046104\n",
      "Epoch: 9 -> Test Accuracy: 79.81\n",
      "[10, 60] loss: 0.463\n",
      "[10, 120] loss: 0.484\n",
      "[10, 180] loss: 0.484\n",
      "[10, 240] loss: 0.493\n",
      "[10, 300] loss: 0.497\n",
      "[10, 360] loss: 0.507\n",
      "Epoch: 10 -> Loss: 0.58091211319\n",
      "Epoch: 10 -> Test Accuracy: 79.98\n",
      "[11, 60] loss: 0.469\n",
      "[11, 120] loss: 0.478\n",
      "[11, 180] loss: 0.468\n",
      "[11, 240] loss: 0.470\n",
      "[11, 300] loss: 0.483\n",
      "[11, 360] loss: 0.484\n",
      "Epoch: 11 -> Loss: 0.616281509399\n",
      "Epoch: 11 -> Test Accuracy: 80.03\n",
      "[12, 60] loss: 0.457\n",
      "[12, 120] loss: 0.475\n",
      "[12, 180] loss: 0.440\n",
      "[12, 240] loss: 0.485\n",
      "[12, 300] loss: 0.498\n",
      "[12, 360] loss: 0.487\n",
      "Epoch: 12 -> Loss: 0.598754405975\n",
      "Epoch: 12 -> Test Accuracy: 80.64\n",
      "[13, 60] loss: 0.445\n",
      "[13, 120] loss: 0.460\n",
      "[13, 180] loss: 0.476\n",
      "[13, 240] loss: 0.480\n",
      "[13, 300] loss: 0.463\n",
      "[13, 360] loss: 0.487\n",
      "Epoch: 13 -> Loss: 0.473371118307\n",
      "Epoch: 13 -> Test Accuracy: 80.92\n",
      "[14, 60] loss: 0.454\n",
      "[14, 120] loss: 0.456\n",
      "[14, 180] loss: 0.448\n",
      "[14, 240] loss: 0.490\n",
      "[14, 300] loss: 0.458\n",
      "[14, 360] loss: 0.454\n",
      "Epoch: 14 -> Loss: 0.551057934761\n",
      "Epoch: 14 -> Test Accuracy: 80.9\n",
      "[15, 60] loss: 0.459\n",
      "[15, 120] loss: 0.468\n",
      "[15, 180] loss: 0.452\n",
      "[15, 240] loss: 0.458\n",
      "[15, 300] loss: 0.477\n",
      "[15, 360] loss: 0.464\n",
      "Epoch: 15 -> Loss: 0.492679417133\n",
      "Epoch: 15 -> Test Accuracy: 80.35\n",
      "[16, 60] loss: 0.431\n",
      "[16, 120] loss: 0.438\n",
      "[16, 180] loss: 0.450\n",
      "[16, 240] loss: 0.438\n",
      "[16, 300] loss: 0.477\n",
      "[16, 360] loss: 0.475\n",
      "Epoch: 16 -> Loss: 0.317068636417\n",
      "Epoch: 16 -> Test Accuracy: 80.69\n",
      "[17, 60] loss: 0.439\n",
      "[17, 120] loss: 0.435\n",
      "[17, 180] loss: 0.455\n",
      "[17, 240] loss: 0.448\n",
      "[17, 300] loss: 0.464\n",
      "[17, 360] loss: 0.453\n",
      "Epoch: 17 -> Loss: 0.625002563\n",
      "Epoch: 17 -> Test Accuracy: 80.49\n",
      "[18, 60] loss: 0.441\n",
      "[18, 120] loss: 0.422\n",
      "[18, 180] loss: 0.443\n",
      "[18, 240] loss: 0.448\n",
      "[18, 300] loss: 0.453\n",
      "[18, 360] loss: 0.471\n",
      "Epoch: 18 -> Loss: 0.436507314444\n",
      "Epoch: 18 -> Test Accuracy: 81.2\n",
      "[19, 60] loss: 0.433\n",
      "[19, 120] loss: 0.447\n",
      "[19, 180] loss: 0.431\n",
      "[19, 240] loss: 0.451\n",
      "[19, 300] loss: 0.441\n",
      "[19, 360] loss: 0.456\n",
      "Epoch: 19 -> Loss: 0.325430423021\n",
      "Epoch: 19 -> Test Accuracy: 80.66\n",
      "[20, 60] loss: 0.425\n",
      "[20, 120] loss: 0.425\n",
      "[20, 180] loss: 0.438\n",
      "[20, 240] loss: 0.452\n",
      "[20, 300] loss: 0.456\n",
      "[20, 360] loss: 0.437\n",
      "Epoch: 20 -> Loss: 0.395677268505\n",
      "Epoch: 20 -> Test Accuracy: 79.84\n",
      "[21, 60] loss: 0.441\n",
      "[21, 120] loss: 0.424\n",
      "[21, 180] loss: 0.442\n",
      "[21, 240] loss: 0.433\n",
      "[21, 300] loss: 0.463\n",
      "[21, 360] loss: 0.444\n",
      "Epoch: 21 -> Loss: 0.324453264475\n",
      "Epoch: 21 -> Test Accuracy: 79.87\n",
      "[22, 60] loss: 0.405\n",
      "[22, 120] loss: 0.428\n",
      "[22, 180] loss: 0.443\n",
      "[22, 240] loss: 0.434\n",
      "[22, 300] loss: 0.457\n",
      "[22, 360] loss: 0.461\n",
      "Epoch: 22 -> Loss: 0.418870598078\n",
      "Epoch: 22 -> Test Accuracy: 81.06\n",
      "[23, 60] loss: 0.414\n",
      "[23, 120] loss: 0.420\n",
      "[23, 180] loss: 0.435\n",
      "[23, 240] loss: 0.451\n",
      "[23, 300] loss: 0.427\n",
      "[23, 360] loss: 0.465\n",
      "Epoch: 23 -> Loss: 0.605429768562\n",
      "Epoch: 23 -> Test Accuracy: 80.71\n",
      "[24, 60] loss: 0.435\n",
      "[24, 120] loss: 0.423\n",
      "[24, 180] loss: 0.429\n",
      "[24, 240] loss: 0.432\n",
      "[24, 300] loss: 0.452\n",
      "[24, 360] loss: 0.442\n",
      "Epoch: 24 -> Loss: 0.345892578363\n",
      "Epoch: 24 -> Test Accuracy: 80.87\n",
      "[25, 60] loss: 0.422\n",
      "[25, 120] loss: 0.423\n",
      "[25, 180] loss: 0.425\n",
      "[25, 240] loss: 0.437\n",
      "[25, 300] loss: 0.444\n",
      "[25, 360] loss: 0.438\n",
      "Epoch: 25 -> Loss: 0.65160381794\n",
      "Epoch: 25 -> Test Accuracy: 80.35\n",
      "[26, 60] loss: 0.419\n",
      "[26, 120] loss: 0.428\n",
      "[26, 180] loss: 0.407\n",
      "[26, 240] loss: 0.440\n",
      "[26, 300] loss: 0.429\n",
      "[26, 360] loss: 0.433\n",
      "Epoch: 26 -> Loss: 0.457416683435\n",
      "Epoch: 26 -> Test Accuracy: 81.12\n",
      "[27, 60] loss: 0.406\n",
      "[27, 120] loss: 0.424\n",
      "[27, 180] loss: 0.434\n",
      "[27, 240] loss: 0.404\n",
      "[27, 300] loss: 0.448\n",
      "[27, 360] loss: 0.442\n",
      "Epoch: 27 -> Loss: 0.440534442663\n",
      "Epoch: 27 -> Test Accuracy: 79.45\n",
      "[28, 60] loss: 0.413\n",
      "[28, 120] loss: 0.424\n",
      "[28, 180] loss: 0.399\n",
      "[28, 240] loss: 0.440\n",
      "[28, 300] loss: 0.443\n",
      "[28, 360] loss: 0.457\n",
      "Epoch: 28 -> Loss: 0.562983393669\n",
      "Epoch: 28 -> Test Accuracy: 80.35\n",
      "[29, 60] loss: 0.415\n",
      "[29, 120] loss: 0.418\n",
      "[29, 180] loss: 0.415\n",
      "[29, 240] loss: 0.445\n",
      "[29, 300] loss: 0.439\n",
      "[29, 360] loss: 0.437\n",
      "Epoch: 29 -> Loss: 0.510769128799\n",
      "Epoch: 29 -> Test Accuracy: 81.81\n",
      "[30, 60] loss: 0.409\n",
      "[30, 120] loss: 0.409\n",
      "[30, 180] loss: 0.427\n",
      "[30, 240] loss: 0.432\n",
      "[30, 300] loss: 0.432\n",
      "[30, 360] loss: 0.439\n",
      "Epoch: 30 -> Loss: 0.361189991236\n",
      "Epoch: 30 -> Test Accuracy: 82.21\n",
      "[31, 60] loss: 0.418\n",
      "[31, 120] loss: 0.409\n",
      "[31, 180] loss: 0.400\n",
      "[31, 240] loss: 0.426\n",
      "[31, 300] loss: 0.429\n",
      "[31, 360] loss: 0.462\n",
      "Epoch: 31 -> Loss: 0.436680734158\n",
      "Epoch: 31 -> Test Accuracy: 81.06\n",
      "[32, 60] loss: 0.402\n",
      "[32, 120] loss: 0.397\n",
      "[32, 180] loss: 0.426\n",
      "[32, 240] loss: 0.434\n",
      "[32, 300] loss: 0.432\n",
      "[32, 360] loss: 0.437\n",
      "Epoch: 32 -> Loss: 0.424393028021\n",
      "Epoch: 32 -> Test Accuracy: 81.59\n",
      "[33, 60] loss: 0.417\n",
      "[33, 120] loss: 0.412\n",
      "[33, 180] loss: 0.414\n",
      "[33, 240] loss: 0.433\n",
      "[33, 300] loss: 0.447\n",
      "[33, 360] loss: 0.412\n",
      "Epoch: 33 -> Loss: 0.521845698357\n",
      "Epoch: 33 -> Test Accuracy: 81.48\n",
      "[34, 60] loss: 0.418\n",
      "[34, 120] loss: 0.415\n",
      "[34, 180] loss: 0.399\n",
      "[34, 240] loss: 0.406\n",
      "[34, 300] loss: 0.428\n",
      "[34, 360] loss: 0.454\n",
      "Epoch: 34 -> Loss: 0.357910454273\n",
      "Epoch: 34 -> Test Accuracy: 80.69\n",
      "[35, 60] loss: 0.396\n",
      "[35, 120] loss: 0.412\n",
      "[35, 180] loss: 0.429\n",
      "[35, 240] loss: 0.430\n",
      "[35, 300] loss: 0.428\n",
      "[35, 360] loss: 0.426\n",
      "Epoch: 35 -> Loss: 0.506079375744\n",
      "Epoch: 35 -> Test Accuracy: 81.65\n",
      "[36, 60] loss: 0.344\n",
      "[36, 120] loss: 0.305\n",
      "[36, 180] loss: 0.292\n",
      "[36, 240] loss: 0.293\n",
      "[36, 300] loss: 0.289\n",
      "[36, 360] loss: 0.272\n",
      "Epoch: 36 -> Loss: 0.331483125687\n",
      "Epoch: 36 -> Test Accuracy: 85.52\n",
      "[37, 60] loss: 0.263\n",
      "[37, 120] loss: 0.270\n",
      "[37, 180] loss: 0.265\n",
      "[37, 240] loss: 0.267\n",
      "[37, 300] loss: 0.268\n",
      "[37, 360] loss: 0.267\n",
      "Epoch: 37 -> Loss: 0.263730794191\n",
      "Epoch: 37 -> Test Accuracy: 85.91\n",
      "[38, 60] loss: 0.249\n",
      "[38, 120] loss: 0.250\n",
      "[38, 180] loss: 0.249\n",
      "[38, 240] loss: 0.247\n",
      "[38, 300] loss: 0.259\n",
      "[38, 360] loss: 0.261\n",
      "Epoch: 38 -> Loss: 0.328485637903\n",
      "Epoch: 38 -> Test Accuracy: 85.83\n",
      "[39, 60] loss: 0.221\n",
      "[39, 120] loss: 0.242\n",
      "[39, 180] loss: 0.247\n",
      "[39, 240] loss: 0.249\n",
      "[39, 300] loss: 0.250\n",
      "[39, 360] loss: 0.254\n",
      "Epoch: 39 -> Loss: 0.217844337225\n",
      "Epoch: 39 -> Test Accuracy: 86.01\n",
      "[40, 60] loss: 0.219\n",
      "[40, 120] loss: 0.231\n",
      "[40, 180] loss: 0.233\n",
      "[40, 240] loss: 0.241\n",
      "[40, 300] loss: 0.244\n",
      "[40, 360] loss: 0.253\n",
      "Epoch: 40 -> Loss: 0.195134952664\n",
      "Epoch: 40 -> Test Accuracy: 85.66\n",
      "[41, 60] loss: 0.227\n",
      "[41, 120] loss: 0.239\n",
      "[41, 180] loss: 0.239\n",
      "[41, 240] loss: 0.237\n",
      "[41, 300] loss: 0.236\n",
      "[41, 360] loss: 0.243\n",
      "Epoch: 41 -> Loss: 0.227319449186\n",
      "Epoch: 41 -> Test Accuracy: 85.34\n",
      "[42, 60] loss: 0.216\n",
      "[42, 120] loss: 0.221\n",
      "[42, 180] loss: 0.240\n",
      "[42, 240] loss: 0.237\n",
      "[42, 300] loss: 0.232\n",
      "[42, 360] loss: 0.240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.268489658833\n",
      "Epoch: 42 -> Test Accuracy: 85.36\n",
      "[43, 60] loss: 0.216\n",
      "[43, 120] loss: 0.234\n",
      "[43, 180] loss: 0.236\n",
      "[43, 240] loss: 0.241\n",
      "[43, 300] loss: 0.226\n",
      "[43, 360] loss: 0.233\n",
      "Epoch: 43 -> Loss: 0.270304620266\n",
      "Epoch: 43 -> Test Accuracy: 84.06\n",
      "[44, 60] loss: 0.222\n",
      "[44, 120] loss: 0.221\n",
      "[44, 180] loss: 0.242\n",
      "[44, 240] loss: 0.235\n",
      "[44, 300] loss: 0.239\n",
      "[44, 360] loss: 0.232\n",
      "Epoch: 44 -> Loss: 0.221127554774\n",
      "Epoch: 44 -> Test Accuracy: 84.92\n",
      "[45, 60] loss: 0.221\n",
      "[45, 120] loss: 0.218\n",
      "[45, 180] loss: 0.222\n",
      "[45, 240] loss: 0.231\n",
      "[45, 300] loss: 0.244\n",
      "[45, 360] loss: 0.244\n",
      "Epoch: 45 -> Loss: 0.241934448481\n",
      "Epoch: 45 -> Test Accuracy: 85.02\n",
      "[46, 60] loss: 0.222\n",
      "[46, 120] loss: 0.224\n",
      "[46, 180] loss: 0.224\n",
      "[46, 240] loss: 0.242\n",
      "[46, 300] loss: 0.227\n",
      "[46, 360] loss: 0.236\n",
      "Epoch: 46 -> Loss: 0.179915875196\n",
      "Epoch: 46 -> Test Accuracy: 85.26\n",
      "[47, 60] loss: 0.215\n",
      "[47, 120] loss: 0.232\n",
      "[47, 180] loss: 0.233\n",
      "[47, 240] loss: 0.229\n",
      "[47, 300] loss: 0.223\n",
      "[47, 360] loss: 0.240\n",
      "Epoch: 47 -> Loss: 0.299593359232\n",
      "Epoch: 47 -> Test Accuracy: 85.08\n",
      "[48, 60] loss: 0.213\n",
      "[48, 120] loss: 0.218\n",
      "[48, 180] loss: 0.229\n",
      "[48, 240] loss: 0.240\n",
      "[48, 300] loss: 0.242\n",
      "[48, 360] loss: 0.239\n",
      "Epoch: 48 -> Loss: 0.370880097151\n",
      "Epoch: 48 -> Test Accuracy: 84.56\n",
      "[49, 60] loss: 0.218\n",
      "[49, 120] loss: 0.236\n",
      "[49, 180] loss: 0.228\n",
      "[49, 240] loss: 0.232\n",
      "[49, 300] loss: 0.238\n",
      "[49, 360] loss: 0.235\n",
      "Epoch: 49 -> Loss: 0.381273090839\n",
      "Epoch: 49 -> Test Accuracy: 84.63\n",
      "[50, 60] loss: 0.212\n",
      "[50, 120] loss: 0.220\n",
      "[50, 180] loss: 0.234\n",
      "[50, 240] loss: 0.245\n",
      "[50, 300] loss: 0.236\n",
      "[50, 360] loss: 0.234\n",
      "Epoch: 50 -> Loss: 0.295511901379\n",
      "Epoch: 50 -> Test Accuracy: 84.77\n",
      "[51, 60] loss: 0.214\n",
      "[51, 120] loss: 0.219\n",
      "[51, 180] loss: 0.230\n",
      "[51, 240] loss: 0.239\n",
      "[51, 300] loss: 0.231\n",
      "[51, 360] loss: 0.243\n",
      "Epoch: 51 -> Loss: 0.418012320995\n",
      "Epoch: 51 -> Test Accuracy: 85.4\n",
      "[52, 60] loss: 0.226\n",
      "[52, 120] loss: 0.227\n",
      "[52, 180] loss: 0.223\n",
      "[52, 240] loss: 0.225\n",
      "[52, 300] loss: 0.238\n",
      "[52, 360] loss: 0.239\n",
      "Epoch: 52 -> Loss: 0.159740358591\n",
      "Epoch: 52 -> Test Accuracy: 84.64\n",
      "[53, 60] loss: 0.219\n",
      "[53, 120] loss: 0.229\n",
      "[53, 180] loss: 0.225\n",
      "[53, 240] loss: 0.217\n",
      "[53, 300] loss: 0.229\n",
      "[53, 360] loss: 0.239\n",
      "Epoch: 53 -> Loss: 0.301912486553\n",
      "Epoch: 53 -> Test Accuracy: 84.83\n",
      "[54, 60] loss: 0.220\n",
      "[54, 120] loss: 0.229\n",
      "[54, 180] loss: 0.219\n",
      "[54, 240] loss: 0.225\n",
      "[54, 300] loss: 0.225\n",
      "[54, 360] loss: 0.244\n",
      "Epoch: 54 -> Loss: 0.281379461288\n",
      "Epoch: 54 -> Test Accuracy: 85.36\n",
      "[55, 60] loss: 0.209\n",
      "[55, 120] loss: 0.220\n",
      "[55, 180] loss: 0.223\n",
      "[55, 240] loss: 0.231\n",
      "[55, 300] loss: 0.233\n",
      "[55, 360] loss: 0.256\n",
      "Epoch: 55 -> Loss: 0.211631208658\n",
      "Epoch: 55 -> Test Accuracy: 84.99\n",
      "[56, 60] loss: 0.222\n",
      "[56, 120] loss: 0.207\n",
      "[56, 180] loss: 0.239\n",
      "[56, 240] loss: 0.232\n",
      "[56, 300] loss: 0.233\n",
      "[56, 360] loss: 0.245\n",
      "Epoch: 56 -> Loss: 0.212259814143\n",
      "Epoch: 56 -> Test Accuracy: 84.69\n",
      "[57, 60] loss: 0.228\n",
      "[57, 120] loss: 0.226\n",
      "[57, 180] loss: 0.226\n",
      "[57, 240] loss: 0.232\n",
      "[57, 300] loss: 0.231\n",
      "[57, 360] loss: 0.238\n",
      "Epoch: 57 -> Loss: 0.246907562017\n",
      "Epoch: 57 -> Test Accuracy: 84.86\n",
      "[58, 60] loss: 0.206\n",
      "[58, 120] loss: 0.211\n",
      "[58, 180] loss: 0.224\n",
      "[58, 240] loss: 0.227\n",
      "[58, 300] loss: 0.238\n",
      "[58, 360] loss: 0.235\n",
      "Epoch: 58 -> Loss: 0.215773969889\n",
      "Epoch: 58 -> Test Accuracy: 84.48\n",
      "[59, 60] loss: 0.213\n",
      "[59, 120] loss: 0.227\n",
      "[59, 180] loss: 0.241\n",
      "[59, 240] loss: 0.234\n",
      "[59, 300] loss: 0.231\n",
      "[59, 360] loss: 0.228\n",
      "Epoch: 59 -> Loss: 0.26949185133\n",
      "Epoch: 59 -> Test Accuracy: 84.73\n",
      "[60, 60] loss: 0.212\n",
      "[60, 120] loss: 0.213\n",
      "[60, 180] loss: 0.228\n",
      "[60, 240] loss: 0.228\n",
      "[60, 300] loss: 0.239\n",
      "[60, 360] loss: 0.240\n",
      "Epoch: 60 -> Loss: 0.200605556369\n",
      "Epoch: 60 -> Test Accuracy: 84.73\n",
      "[61, 60] loss: 0.203\n",
      "[61, 120] loss: 0.218\n",
      "[61, 180] loss: 0.232\n",
      "[61, 240] loss: 0.222\n",
      "[61, 300] loss: 0.227\n",
      "[61, 360] loss: 0.234\n",
      "Epoch: 61 -> Loss: 0.271961301565\n",
      "Epoch: 61 -> Test Accuracy: 84.05\n",
      "[62, 60] loss: 0.210\n",
      "[62, 120] loss: 0.219\n",
      "[62, 180] loss: 0.220\n",
      "[62, 240] loss: 0.230\n",
      "[62, 300] loss: 0.244\n",
      "[62, 360] loss: 0.239\n",
      "Epoch: 62 -> Loss: 0.218460276723\n",
      "Epoch: 62 -> Test Accuracy: 84.67\n",
      "[63, 60] loss: 0.207\n",
      "[63, 120] loss: 0.227\n",
      "[63, 180] loss: 0.211\n",
      "[63, 240] loss: 0.230\n",
      "[63, 300] loss: 0.231\n",
      "[63, 360] loss: 0.238\n",
      "Epoch: 63 -> Loss: 0.376750648022\n",
      "Epoch: 63 -> Test Accuracy: 84.36\n",
      "[64, 60] loss: 0.211\n",
      "[64, 120] loss: 0.214\n",
      "[64, 180] loss: 0.222\n",
      "[64, 240] loss: 0.217\n",
      "[64, 300] loss: 0.229\n",
      "[64, 360] loss: 0.240\n",
      "Epoch: 64 -> Loss: 0.233668774366\n",
      "Epoch: 64 -> Test Accuracy: 85.36\n",
      "[65, 60] loss: 0.210\n",
      "[65, 120] loss: 0.214\n",
      "[65, 180] loss: 0.222\n",
      "[65, 240] loss: 0.222\n",
      "[65, 300] loss: 0.231\n",
      "[65, 360] loss: 0.239\n",
      "Epoch: 65 -> Loss: 0.262175381184\n",
      "Epoch: 65 -> Test Accuracy: 84.98\n",
      "[66, 60] loss: 0.204\n",
      "[66, 120] loss: 0.209\n",
      "[66, 180] loss: 0.225\n",
      "[66, 240] loss: 0.222\n",
      "[66, 300] loss: 0.230\n",
      "[66, 360] loss: 0.242\n",
      "Epoch: 66 -> Loss: 0.240499928594\n",
      "Epoch: 66 -> Test Accuracy: 84.58\n",
      "[67, 60] loss: 0.208\n",
      "[67, 120] loss: 0.219\n",
      "[67, 180] loss: 0.220\n",
      "[67, 240] loss: 0.220\n",
      "[67, 300] loss: 0.223\n",
      "[67, 360] loss: 0.231\n",
      "Epoch: 67 -> Loss: 0.249106362462\n",
      "Epoch: 67 -> Test Accuracy: 84.56\n",
      "[68, 60] loss: 0.210\n",
      "[68, 120] loss: 0.206\n",
      "[68, 180] loss: 0.211\n",
      "[68, 240] loss: 0.229\n",
      "[68, 300] loss: 0.242\n",
      "[68, 360] loss: 0.235\n",
      "Epoch: 68 -> Loss: 0.309001713991\n",
      "Epoch: 68 -> Test Accuracy: 84.7\n",
      "[69, 60] loss: 0.205\n",
      "[69, 120] loss: 0.216\n",
      "[69, 180] loss: 0.213\n",
      "[69, 240] loss: 0.212\n",
      "[69, 300] loss: 0.234\n",
      "[69, 360] loss: 0.223\n",
      "Epoch: 69 -> Loss: 0.27531594038\n",
      "Epoch: 69 -> Test Accuracy: 84.53\n",
      "[70, 60] loss: 0.205\n",
      "[70, 120] loss: 0.210\n",
      "[70, 180] loss: 0.210\n",
      "[70, 240] loss: 0.225\n",
      "[70, 300] loss: 0.223\n",
      "[70, 360] loss: 0.239\n",
      "Epoch: 70 -> Loss: 0.209898501635\n",
      "Epoch: 70 -> Test Accuracy: 84.42\n",
      "[71, 60] loss: 0.183\n",
      "[71, 120] loss: 0.150\n",
      "[71, 180] loss: 0.158\n",
      "[71, 240] loss: 0.147\n",
      "[71, 300] loss: 0.148\n",
      "[71, 360] loss: 0.149\n",
      "Epoch: 71 -> Loss: 0.113101556897\n",
      "Epoch: 71 -> Test Accuracy: 86.66\n",
      "[72, 60] loss: 0.135\n",
      "[72, 120] loss: 0.139\n",
      "[72, 180] loss: 0.135\n",
      "[72, 240] loss: 0.131\n",
      "[72, 300] loss: 0.134\n",
      "[72, 360] loss: 0.134\n",
      "Epoch: 72 -> Loss: 0.161292716861\n",
      "Epoch: 72 -> Test Accuracy: 86.6\n",
      "[73, 60] loss: 0.127\n",
      "[73, 120] loss: 0.128\n",
      "[73, 180] loss: 0.128\n",
      "[73, 240] loss: 0.128\n",
      "[73, 300] loss: 0.133\n",
      "[73, 360] loss: 0.141\n",
      "Epoch: 73 -> Loss: 0.0991555899382\n",
      "Epoch: 73 -> Test Accuracy: 86.56\n",
      "[74, 60] loss: 0.127\n",
      "[74, 120] loss: 0.123\n",
      "[74, 180] loss: 0.123\n",
      "[74, 240] loss: 0.127\n",
      "[74, 300] loss: 0.123\n",
      "[74, 360] loss: 0.127\n",
      "Epoch: 74 -> Loss: 0.0962848812342\n",
      "Epoch: 74 -> Test Accuracy: 86.63\n",
      "[75, 60] loss: 0.116\n",
      "[75, 120] loss: 0.118\n",
      "[75, 180] loss: 0.126\n",
      "[75, 240] loss: 0.123\n",
      "[75, 300] loss: 0.121\n",
      "[75, 360] loss: 0.124\n",
      "Epoch: 75 -> Loss: 0.134795382619\n",
      "Epoch: 75 -> Test Accuracy: 86.87\n",
      "[76, 60] loss: 0.117\n",
      "[76, 120] loss: 0.116\n",
      "[76, 180] loss: 0.118\n",
      "[76, 240] loss: 0.122\n",
      "[76, 300] loss: 0.120\n",
      "[76, 360] loss: 0.119\n",
      "Epoch: 76 -> Loss: 0.0995289757848\n",
      "Epoch: 76 -> Test Accuracy: 86.84\n",
      "[77, 60] loss: 0.121\n",
      "[77, 120] loss: 0.110\n",
      "[77, 180] loss: 0.117\n",
      "[77, 240] loss: 0.112\n",
      "[77, 300] loss: 0.118\n",
      "[77, 360] loss: 0.119\n",
      "Epoch: 77 -> Loss: 0.117598555982\n",
      "Epoch: 77 -> Test Accuracy: 86.53\n",
      "[78, 60] loss: 0.117\n",
      "[78, 120] loss: 0.113\n",
      "[78, 180] loss: 0.116\n",
      "[78, 240] loss: 0.117\n",
      "[78, 300] loss: 0.119\n",
      "[78, 360] loss: 0.113\n",
      "Epoch: 78 -> Loss: 0.119907736778\n",
      "Epoch: 78 -> Test Accuracy: 86.62\n",
      "[79, 60] loss: 0.106\n",
      "[79, 120] loss: 0.112\n",
      "[79, 180] loss: 0.115\n",
      "[79, 240] loss: 0.114\n",
      "[79, 300] loss: 0.116\n",
      "[79, 360] loss: 0.112\n",
      "Epoch: 79 -> Loss: 0.140373855829\n",
      "Epoch: 79 -> Test Accuracy: 86.62\n",
      "[80, 60] loss: 0.106\n",
      "[80, 120] loss: 0.105\n",
      "[80, 180] loss: 0.110\n",
      "[80, 240] loss: 0.114\n",
      "[80, 300] loss: 0.109\n",
      "[80, 360] loss: 0.118\n",
      "Epoch: 80 -> Loss: 0.0977410376072\n",
      "Epoch: 80 -> Test Accuracy: 86.5\n",
      "[81, 60] loss: 0.103\n",
      "[81, 120] loss: 0.109\n",
      "[81, 180] loss: 0.107\n",
      "[81, 240] loss: 0.109\n",
      "[81, 300] loss: 0.112\n",
      "[81, 360] loss: 0.114\n",
      "Epoch: 81 -> Loss: 0.114344596863\n",
      "Epoch: 81 -> Test Accuracy: 86.41\n",
      "[82, 60] loss: 0.101\n",
      "[82, 120] loss: 0.109\n",
      "[82, 180] loss: 0.108\n",
      "[82, 240] loss: 0.104\n",
      "[82, 300] loss: 0.110\n",
      "[82, 360] loss: 0.110\n",
      "Epoch: 82 -> Loss: 0.0741960555315\n",
      "Epoch: 82 -> Test Accuracy: 86.7\n",
      "[83, 60] loss: 0.097\n",
      "[83, 120] loss: 0.109\n",
      "[83, 180] loss: 0.111\n",
      "[83, 240] loss: 0.105\n",
      "[83, 300] loss: 0.103\n",
      "[83, 360] loss: 0.105\n",
      "Epoch: 83 -> Loss: 0.157271578908\n",
      "Epoch: 83 -> Test Accuracy: 86.64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.097\n",
      "[84, 120] loss: 0.104\n",
      "[84, 180] loss: 0.102\n",
      "[84, 240] loss: 0.103\n",
      "[84, 300] loss: 0.103\n",
      "[84, 360] loss: 0.112\n",
      "Epoch: 84 -> Loss: 0.122205749154\n",
      "Epoch: 84 -> Test Accuracy: 86.15\n",
      "[85, 60] loss: 0.102\n",
      "[85, 120] loss: 0.101\n",
      "[85, 180] loss: 0.105\n",
      "[85, 240] loss: 0.101\n",
      "[85, 300] loss: 0.104\n",
      "[85, 360] loss: 0.103\n",
      "Epoch: 85 -> Loss: 0.143395036459\n",
      "Epoch: 85 -> Test Accuracy: 86.7\n",
      "[86, 60] loss: 0.101\n",
      "[86, 120] loss: 0.096\n",
      "[86, 180] loss: 0.088\n",
      "[86, 240] loss: 0.086\n",
      "[86, 300] loss: 0.087\n",
      "[86, 360] loss: 0.096\n",
      "Epoch: 86 -> Loss: 0.119076631963\n",
      "Epoch: 86 -> Test Accuracy: 86.76\n",
      "[87, 60] loss: 0.084\n",
      "[87, 120] loss: 0.087\n",
      "[87, 180] loss: 0.084\n",
      "[87, 240] loss: 0.087\n",
      "[87, 300] loss: 0.090\n",
      "[87, 360] loss: 0.090\n",
      "Epoch: 87 -> Loss: 0.0653090029955\n",
      "Epoch: 87 -> Test Accuracy: 86.87\n",
      "[88, 60] loss: 0.081\n",
      "[88, 120] loss: 0.090\n",
      "[88, 180] loss: 0.084\n",
      "[88, 240] loss: 0.088\n",
      "[88, 300] loss: 0.086\n",
      "[88, 360] loss: 0.099\n",
      "Epoch: 88 -> Loss: 0.0823090821505\n",
      "Epoch: 88 -> Test Accuracy: 86.93\n",
      "[89, 60] loss: 0.091\n",
      "[89, 120] loss: 0.089\n",
      "[89, 180] loss: 0.084\n",
      "[89, 240] loss: 0.085\n",
      "[89, 300] loss: 0.085\n",
      "[89, 360] loss: 0.087\n",
      "Epoch: 89 -> Loss: 0.10627862066\n",
      "Epoch: 89 -> Test Accuracy: 87.08\n",
      "[90, 60] loss: 0.084\n",
      "[90, 120] loss: 0.088\n",
      "[90, 180] loss: 0.087\n",
      "[90, 240] loss: 0.086\n",
      "[90, 300] loss: 0.087\n",
      "[90, 360] loss: 0.088\n",
      "Epoch: 90 -> Loss: 0.0950036197901\n",
      "Epoch: 90 -> Test Accuracy: 87.0\n",
      "[91, 60] loss: 0.082\n",
      "[91, 120] loss: 0.085\n",
      "[91, 180] loss: 0.089\n",
      "[91, 240] loss: 0.094\n",
      "[91, 300] loss: 0.087\n",
      "[91, 360] loss: 0.084\n",
      "Epoch: 91 -> Loss: 0.109464623034\n",
      "Epoch: 91 -> Test Accuracy: 86.94\n",
      "[92, 60] loss: 0.084\n",
      "[92, 120] loss: 0.086\n",
      "[92, 180] loss: 0.086\n",
      "[92, 240] loss: 0.085\n",
      "[92, 300] loss: 0.082\n",
      "[92, 360] loss: 0.087\n",
      "Epoch: 92 -> Loss: 0.110300384462\n",
      "Epoch: 92 -> Test Accuracy: 86.87\n",
      "[93, 60] loss: 0.083\n",
      "[93, 120] loss: 0.084\n",
      "[93, 180] loss: 0.085\n",
      "[93, 240] loss: 0.084\n",
      "[93, 300] loss: 0.083\n",
      "[93, 360] loss: 0.082\n",
      "Epoch: 93 -> Loss: 0.0784741714597\n",
      "Epoch: 93 -> Test Accuracy: 86.87\n",
      "[94, 60] loss: 0.085\n",
      "[94, 120] loss: 0.086\n",
      "[94, 180] loss: 0.084\n",
      "[94, 240] loss: 0.084\n",
      "[94, 300] loss: 0.084\n",
      "[94, 360] loss: 0.086\n",
      "Epoch: 94 -> Loss: 0.114614471793\n",
      "Epoch: 94 -> Test Accuracy: 86.77\n",
      "[95, 60] loss: 0.086\n",
      "[95, 120] loss: 0.083\n",
      "[95, 180] loss: 0.081\n",
      "[95, 240] loss: 0.085\n",
      "[95, 300] loss: 0.084\n",
      "[95, 360] loss: 0.089\n",
      "Epoch: 95 -> Loss: 0.0496258996427\n",
      "Epoch: 95 -> Test Accuracy: 86.96\n",
      "[96, 60] loss: 0.082\n",
      "[96, 120] loss: 0.080\n",
      "[96, 180] loss: 0.081\n",
      "[96, 240] loss: 0.085\n",
      "[96, 300] loss: 0.084\n",
      "[96, 360] loss: 0.087\n",
      "Epoch: 96 -> Loss: 0.0384640172124\n",
      "Epoch: 96 -> Test Accuracy: 86.72\n",
      "[97, 60] loss: 0.076\n",
      "[97, 120] loss: 0.086\n",
      "[97, 180] loss: 0.088\n",
      "[97, 240] loss: 0.087\n",
      "[97, 300] loss: 0.086\n",
      "[97, 360] loss: 0.084\n",
      "Epoch: 97 -> Loss: 0.0970738977194\n",
      "Epoch: 97 -> Test Accuracy: 86.68\n",
      "[98, 60] loss: 0.081\n",
      "[98, 120] loss: 0.084\n",
      "[98, 180] loss: 0.079\n",
      "[98, 240] loss: 0.085\n",
      "[98, 300] loss: 0.082\n",
      "[98, 360] loss: 0.083\n",
      "Epoch: 98 -> Loss: 0.126682475209\n",
      "Epoch: 98 -> Test Accuracy: 86.73\n",
      "[99, 60] loss: 0.079\n",
      "[99, 120] loss: 0.083\n",
      "[99, 180] loss: 0.080\n",
      "[99, 240] loss: 0.082\n",
      "[99, 300] loss: 0.085\n",
      "[99, 360] loss: 0.084\n",
      "Epoch: 99 -> Loss: 0.090732216835\n",
      "Epoch: 99 -> Test Accuracy: 86.6\n",
      "[100, 60] loss: 0.080\n",
      "[100, 120] loss: 0.086\n",
      "[100, 180] loss: 0.081\n",
      "[100, 240] loss: 0.083\n",
      "[100, 300] loss: 0.081\n",
      "[100, 360] loss: 0.082\n",
      "Epoch: 100 -> Loss: 0.0622853152454\n",
      "Epoch: 100 -> Test Accuracy: 86.59\n",
      "Finished Training\n",
      "[1, 60] loss: 0.957\n",
      "[1, 120] loss: 0.657\n",
      "[1, 180] loss: 0.581\n",
      "[1, 240] loss: 0.550\n",
      "[1, 300] loss: 0.519\n",
      "[1, 360] loss: 0.509\n",
      "Epoch: 1 -> Loss: 0.621480822563\n",
      "Epoch: 1 -> Test Accuracy: 80.88\n",
      "[2, 60] loss: 0.461\n",
      "[2, 120] loss: 0.444\n",
      "[2, 180] loss: 0.439\n",
      "[2, 240] loss: 0.444\n",
      "[2, 300] loss: 0.458\n",
      "[2, 360] loss: 0.420\n",
      "Epoch: 2 -> Loss: 0.661199510098\n",
      "Epoch: 2 -> Test Accuracy: 83.34\n",
      "[3, 60] loss: 0.390\n",
      "[3, 120] loss: 0.405\n",
      "[3, 180] loss: 0.401\n",
      "[3, 240] loss: 0.397\n",
      "[3, 300] loss: 0.395\n",
      "[3, 360] loss: 0.378\n",
      "Epoch: 3 -> Loss: 0.369901001453\n",
      "Epoch: 3 -> Test Accuracy: 83.28\n",
      "[4, 60] loss: 0.358\n",
      "[4, 120] loss: 0.359\n",
      "[4, 180] loss: 0.373\n",
      "[4, 240] loss: 0.378\n",
      "[4, 300] loss: 0.381\n",
      "[4, 360] loss: 0.366\n",
      "Epoch: 4 -> Loss: 0.31889256835\n",
      "Epoch: 4 -> Test Accuracy: 84.78\n",
      "[5, 60] loss: 0.328\n",
      "[5, 120] loss: 0.347\n",
      "[5, 180] loss: 0.344\n",
      "[5, 240] loss: 0.351\n",
      "[5, 300] loss: 0.367\n",
      "[5, 360] loss: 0.349\n",
      "Epoch: 5 -> Loss: 0.372667312622\n",
      "Epoch: 5 -> Test Accuracy: 83.98\n",
      "[6, 60] loss: 0.319\n",
      "[6, 120] loss: 0.327\n",
      "[6, 180] loss: 0.333\n",
      "[6, 240] loss: 0.341\n",
      "[6, 300] loss: 0.334\n",
      "[6, 360] loss: 0.349\n",
      "Epoch: 6 -> Loss: 0.326589941978\n",
      "Epoch: 6 -> Test Accuracy: 84.81\n",
      "[7, 60] loss: 0.303\n",
      "[7, 120] loss: 0.311\n",
      "[7, 180] loss: 0.311\n",
      "[7, 240] loss: 0.328\n",
      "[7, 300] loss: 0.318\n",
      "[7, 360] loss: 0.338\n",
      "Epoch: 7 -> Loss: 0.559491038322\n",
      "Epoch: 7 -> Test Accuracy: 84.24\n",
      "[8, 60] loss: 0.301\n",
      "[8, 120] loss: 0.300\n",
      "[8, 180] loss: 0.326\n",
      "[8, 240] loss: 0.336\n",
      "[8, 300] loss: 0.313\n",
      "[8, 360] loss: 0.318\n",
      "Epoch: 8 -> Loss: 0.242688328028\n",
      "Epoch: 8 -> Test Accuracy: 83.66\n",
      "[9, 60] loss: 0.288\n",
      "[9, 120] loss: 0.290\n",
      "[9, 180] loss: 0.321\n",
      "[9, 240] loss: 0.326\n",
      "[9, 300] loss: 0.314\n",
      "[9, 360] loss: 0.309\n",
      "Epoch: 9 -> Loss: 0.255054622889\n",
      "Epoch: 9 -> Test Accuracy: 85.01\n",
      "[10, 60] loss: 0.277\n",
      "[10, 120] loss: 0.292\n",
      "[10, 180] loss: 0.288\n",
      "[10, 240] loss: 0.304\n",
      "[10, 300] loss: 0.311\n",
      "[10, 360] loss: 0.317\n",
      "Epoch: 10 -> Loss: 0.220045566559\n",
      "Epoch: 10 -> Test Accuracy: 85.73\n",
      "[11, 60] loss: 0.289\n",
      "[11, 120] loss: 0.295\n",
      "[11, 180] loss: 0.287\n",
      "[11, 240] loss: 0.314\n",
      "[11, 300] loss: 0.303\n",
      "[11, 360] loss: 0.311\n",
      "Epoch: 11 -> Loss: 0.245121240616\n",
      "Epoch: 11 -> Test Accuracy: 84.71\n",
      "[12, 60] loss: 0.265\n",
      "[12, 120] loss: 0.283\n",
      "[12, 180] loss: 0.290\n",
      "[12, 240] loss: 0.298\n",
      "[12, 300] loss: 0.303\n",
      "[12, 360] loss: 0.316\n",
      "Epoch: 12 -> Loss: 0.205279439688\n",
      "Epoch: 12 -> Test Accuracy: 85.87\n",
      "[13, 60] loss: 0.265\n",
      "[13, 120] loss: 0.279\n",
      "[13, 180] loss: 0.298\n",
      "[13, 240] loss: 0.280\n",
      "[13, 300] loss: 0.309\n",
      "[13, 360] loss: 0.290\n",
      "Epoch: 13 -> Loss: 0.315471708775\n",
      "Epoch: 13 -> Test Accuracy: 85.46\n",
      "[14, 60] loss: 0.267\n",
      "[14, 120] loss: 0.272\n",
      "[14, 180] loss: 0.298\n",
      "[14, 240] loss: 0.283\n",
      "[14, 300] loss: 0.276\n",
      "[14, 360] loss: 0.303\n",
      "Epoch: 14 -> Loss: 0.291509449482\n",
      "Epoch: 14 -> Test Accuracy: 85.08\n",
      "[15, 60] loss: 0.254\n",
      "[15, 120] loss: 0.275\n",
      "[15, 180] loss: 0.258\n",
      "[15, 240] loss: 0.303\n",
      "[15, 300] loss: 0.292\n",
      "[15, 360] loss: 0.300\n",
      "Epoch: 15 -> Loss: 0.350124746561\n",
      "Epoch: 15 -> Test Accuracy: 84.9\n",
      "[16, 60] loss: 0.264\n",
      "[16, 120] loss: 0.274\n",
      "[16, 180] loss: 0.264\n",
      "[16, 240] loss: 0.271\n",
      "[16, 300] loss: 0.291\n",
      "[16, 360] loss: 0.308\n",
      "Epoch: 16 -> Loss: 0.270698219538\n",
      "Epoch: 16 -> Test Accuracy: 84.98\n",
      "[17, 60] loss: 0.262\n",
      "[17, 120] loss: 0.277\n",
      "[17, 180] loss: 0.284\n",
      "[17, 240] loss: 0.279\n",
      "[17, 300] loss: 0.294\n",
      "[17, 360] loss: 0.295\n",
      "Epoch: 17 -> Loss: 0.346682012081\n",
      "Epoch: 17 -> Test Accuracy: 86.0\n",
      "[18, 60] loss: 0.262\n",
      "[18, 120] loss: 0.277\n",
      "[18, 180] loss: 0.279\n",
      "[18, 240] loss: 0.288\n",
      "[18, 300] loss: 0.282\n",
      "[18, 360] loss: 0.284\n",
      "Epoch: 18 -> Loss: 0.262564986944\n",
      "Epoch: 18 -> Test Accuracy: 86.12\n",
      "[19, 60] loss: 0.244\n",
      "[19, 120] loss: 0.267\n",
      "[19, 180] loss: 0.269\n",
      "[19, 240] loss: 0.298\n",
      "[19, 300] loss: 0.301\n",
      "[19, 360] loss: 0.290\n",
      "Epoch: 19 -> Loss: 0.338002324104\n",
      "Epoch: 19 -> Test Accuracy: 84.57\n",
      "[20, 60] loss: 0.247\n",
      "[20, 120] loss: 0.261\n",
      "[20, 180] loss: 0.278\n",
      "[20, 240] loss: 0.287\n",
      "[20, 300] loss: 0.279\n",
      "[20, 360] loss: 0.280\n",
      "Epoch: 20 -> Loss: 0.218984082341\n",
      "Epoch: 20 -> Test Accuracy: 85.74\n",
      "[21, 60] loss: 0.256\n",
      "[21, 120] loss: 0.259\n",
      "[21, 180] loss: 0.258\n",
      "[21, 240] loss: 0.272\n",
      "[21, 300] loss: 0.281\n",
      "[21, 360] loss: 0.290\n",
      "Epoch: 21 -> Loss: 0.162334114313\n",
      "Epoch: 21 -> Test Accuracy: 85.61\n",
      "[22, 60] loss: 0.250\n",
      "[22, 120] loss: 0.258\n",
      "[22, 180] loss: 0.264\n",
      "[22, 240] loss: 0.276\n",
      "[22, 300] loss: 0.280\n",
      "[22, 360] loss: 0.287\n",
      "Epoch: 22 -> Loss: 0.261073768139\n",
      "Epoch: 22 -> Test Accuracy: 85.47\n",
      "[23, 60] loss: 0.243\n",
      "[23, 120] loss: 0.263\n",
      "[23, 180] loss: 0.277\n",
      "[23, 240] loss: 0.273\n",
      "[23, 300] loss: 0.286\n",
      "[23, 360] loss: 0.282\n",
      "Epoch: 23 -> Loss: 0.243987590075\n",
      "Epoch: 23 -> Test Accuracy: 85.38\n",
      "[24, 60] loss: 0.244\n",
      "[24, 120] loss: 0.249\n",
      "[24, 180] loss: 0.269\n",
      "[24, 240] loss: 0.269\n",
      "[24, 300] loss: 0.284\n",
      "[24, 360] loss: 0.288\n",
      "Epoch: 24 -> Loss: 0.530919194221\n",
      "Epoch: 24 -> Test Accuracy: 86.3\n",
      "[25, 60] loss: 0.239\n",
      "[25, 120] loss: 0.254\n",
      "[25, 180] loss: 0.262\n",
      "[25, 240] loss: 0.268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 300] loss: 0.277\n",
      "[25, 360] loss: 0.279\n",
      "Epoch: 25 -> Loss: 0.154956161976\n",
      "Epoch: 25 -> Test Accuracy: 85.93\n",
      "[26, 60] loss: 0.236\n",
      "[26, 120] loss: 0.252\n",
      "[26, 180] loss: 0.263\n",
      "[26, 240] loss: 0.279\n",
      "[26, 300] loss: 0.275\n",
      "[26, 360] loss: 0.271\n",
      "Epoch: 26 -> Loss: 0.398384422064\n",
      "Epoch: 26 -> Test Accuracy: 85.32\n",
      "[27, 60] loss: 0.250\n",
      "[27, 120] loss: 0.248\n",
      "[27, 180] loss: 0.267\n",
      "[27, 240] loss: 0.275\n",
      "[27, 300] loss: 0.287\n",
      "[27, 360] loss: 0.280\n",
      "Epoch: 27 -> Loss: 0.305144429207\n",
      "Epoch: 27 -> Test Accuracy: 85.33\n",
      "[28, 60] loss: 0.243\n",
      "[28, 120] loss: 0.249\n",
      "[28, 180] loss: 0.263\n",
      "[28, 240] loss: 0.281\n",
      "[28, 300] loss: 0.270\n",
      "[28, 360] loss: 0.274\n",
      "Epoch: 28 -> Loss: 0.189732342958\n",
      "Epoch: 28 -> Test Accuracy: 84.76\n",
      "[29, 60] loss: 0.246\n",
      "[29, 120] loss: 0.253\n",
      "[29, 180] loss: 0.267\n",
      "[29, 240] loss: 0.254\n",
      "[29, 300] loss: 0.278\n",
      "[29, 360] loss: 0.285\n",
      "Epoch: 29 -> Loss: 0.327595174313\n",
      "Epoch: 29 -> Test Accuracy: 85.22\n",
      "[30, 60] loss: 0.256\n",
      "[30, 120] loss: 0.253\n",
      "[30, 180] loss: 0.261\n",
      "[30, 240] loss: 0.277\n",
      "[30, 300] loss: 0.267\n",
      "[30, 360] loss: 0.271\n",
      "Epoch: 30 -> Loss: 0.245927721262\n",
      "Epoch: 30 -> Test Accuracy: 86.01\n",
      "[31, 60] loss: 0.234\n",
      "[31, 120] loss: 0.261\n",
      "[31, 180] loss: 0.260\n",
      "[31, 240] loss: 0.251\n",
      "[31, 300] loss: 0.270\n",
      "[31, 360] loss: 0.293\n",
      "Epoch: 31 -> Loss: 0.252451330423\n",
      "Epoch: 31 -> Test Accuracy: 85.61\n",
      "[32, 60] loss: 0.231\n",
      "[32, 120] loss: 0.258\n",
      "[32, 180] loss: 0.251\n",
      "[32, 240] loss: 0.265\n",
      "[32, 300] loss: 0.268\n",
      "[32, 360] loss: 0.289\n",
      "Epoch: 32 -> Loss: 0.32339912653\n",
      "Epoch: 32 -> Test Accuracy: 85.9\n",
      "[33, 60] loss: 0.246\n",
      "[33, 120] loss: 0.248\n",
      "[33, 180] loss: 0.258\n",
      "[33, 240] loss: 0.257\n",
      "[33, 300] loss: 0.262\n",
      "[33, 360] loss: 0.276\n",
      "Epoch: 33 -> Loss: 0.258812040091\n",
      "Epoch: 33 -> Test Accuracy: 86.04\n",
      "[34, 60] loss: 0.232\n",
      "[34, 120] loss: 0.243\n",
      "[34, 180] loss: 0.260\n",
      "[34, 240] loss: 0.258\n",
      "[34, 300] loss: 0.279\n",
      "[34, 360] loss: 0.282\n",
      "Epoch: 34 -> Loss: 0.320092827082\n",
      "Epoch: 34 -> Test Accuracy: 85.95\n",
      "[35, 60] loss: 0.244\n",
      "[35, 120] loss: 0.254\n",
      "[35, 180] loss: 0.258\n",
      "[35, 240] loss: 0.272\n",
      "[35, 300] loss: 0.259\n",
      "[35, 360] loss: 0.285\n",
      "Epoch: 35 -> Loss: 0.184209421277\n",
      "Epoch: 35 -> Test Accuracy: 86.1\n",
      "[36, 60] loss: 0.209\n",
      "[36, 120] loss: 0.185\n",
      "[36, 180] loss: 0.160\n",
      "[36, 240] loss: 0.169\n",
      "[36, 300] loss: 0.177\n",
      "[36, 360] loss: 0.166\n",
      "Epoch: 36 -> Loss: 0.179385975003\n",
      "Epoch: 36 -> Test Accuracy: 88.7\n",
      "[37, 60] loss: 0.138\n",
      "[37, 120] loss: 0.143\n",
      "[37, 180] loss: 0.147\n",
      "[37, 240] loss: 0.143\n",
      "[37, 300] loss: 0.140\n",
      "[37, 360] loss: 0.146\n",
      "Epoch: 37 -> Loss: 0.144654557109\n",
      "Epoch: 37 -> Test Accuracy: 88.8\n",
      "[38, 60] loss: 0.126\n",
      "[38, 120] loss: 0.128\n",
      "[38, 180] loss: 0.130\n",
      "[38, 240] loss: 0.127\n",
      "[38, 300] loss: 0.125\n",
      "[38, 360] loss: 0.131\n",
      "Epoch: 38 -> Loss: 0.0868843719363\n",
      "Epoch: 38 -> Test Accuracy: 88.79\n",
      "[39, 60] loss: 0.113\n",
      "[39, 120] loss: 0.120\n",
      "[39, 180] loss: 0.123\n",
      "[39, 240] loss: 0.128\n",
      "[39, 300] loss: 0.124\n",
      "[39, 360] loss: 0.122\n",
      "Epoch: 39 -> Loss: 0.223237320781\n",
      "Epoch: 39 -> Test Accuracy: 88.68\n",
      "[40, 60] loss: 0.105\n",
      "[40, 120] loss: 0.110\n",
      "[40, 180] loss: 0.118\n",
      "[40, 240] loss: 0.122\n",
      "[40, 300] loss: 0.116\n",
      "[40, 360] loss: 0.112\n",
      "Epoch: 40 -> Loss: 0.119444236159\n",
      "Epoch: 40 -> Test Accuracy: 88.45\n",
      "[41, 60] loss: 0.109\n",
      "[41, 120] loss: 0.107\n",
      "[41, 180] loss: 0.111\n",
      "[41, 240] loss: 0.109\n",
      "[41, 300] loss: 0.120\n",
      "[41, 360] loss: 0.123\n",
      "Epoch: 41 -> Loss: 0.135621592402\n",
      "Epoch: 41 -> Test Accuracy: 88.17\n",
      "[42, 60] loss: 0.101\n",
      "[42, 120] loss: 0.108\n",
      "[42, 180] loss: 0.098\n",
      "[42, 240] loss: 0.109\n",
      "[42, 300] loss: 0.110\n",
      "[42, 360] loss: 0.118\n",
      "Epoch: 42 -> Loss: 0.115049898624\n",
      "Epoch: 42 -> Test Accuracy: 88.27\n",
      "[43, 60] loss: 0.099\n",
      "[43, 120] loss: 0.100\n",
      "[43, 180] loss: 0.096\n",
      "[43, 240] loss: 0.112\n",
      "[43, 300] loss: 0.105\n",
      "[43, 360] loss: 0.103\n",
      "Epoch: 43 -> Loss: 0.0651640743017\n",
      "Epoch: 43 -> Test Accuracy: 87.53\n",
      "[44, 60] loss: 0.103\n",
      "[44, 120] loss: 0.101\n",
      "[44, 180] loss: 0.097\n",
      "[44, 240] loss: 0.105\n",
      "[44, 300] loss: 0.113\n",
      "[44, 360] loss: 0.114\n",
      "Epoch: 44 -> Loss: 0.146915048361\n",
      "Epoch: 44 -> Test Accuracy: 87.65\n",
      "[45, 60] loss: 0.103\n",
      "[45, 120] loss: 0.093\n",
      "[45, 180] loss: 0.103\n",
      "[45, 240] loss: 0.109\n",
      "[45, 300] loss: 0.117\n",
      "[45, 360] loss: 0.114\n",
      "Epoch: 45 -> Loss: 0.136743158102\n",
      "Epoch: 45 -> Test Accuracy: 87.64\n",
      "[46, 60] loss: 0.097\n",
      "[46, 120] loss: 0.107\n",
      "[46, 180] loss: 0.102\n",
      "[46, 240] loss: 0.094\n",
      "[46, 300] loss: 0.115\n",
      "[46, 360] loss: 0.117\n",
      "Epoch: 46 -> Loss: 0.22321292758\n",
      "Epoch: 46 -> Test Accuracy: 87.61\n",
      "[47, 60] loss: 0.109\n",
      "[47, 120] loss: 0.104\n",
      "[47, 180] loss: 0.107\n",
      "[47, 240] loss: 0.106\n",
      "[47, 300] loss: 0.117\n",
      "[47, 360] loss: 0.110\n",
      "Epoch: 47 -> Loss: 0.129744082689\n",
      "Epoch: 47 -> Test Accuracy: 87.66\n",
      "[48, 60] loss: 0.094\n",
      "[48, 120] loss: 0.098\n",
      "[48, 180] loss: 0.099\n",
      "[48, 240] loss: 0.105\n",
      "[48, 300] loss: 0.110\n",
      "[48, 360] loss: 0.105\n",
      "Epoch: 48 -> Loss: 0.0825979337096\n",
      "Epoch: 48 -> Test Accuracy: 87.5\n",
      "[49, 60] loss: 0.088\n",
      "[49, 120] loss: 0.100\n",
      "[49, 180] loss: 0.104\n",
      "[49, 240] loss: 0.109\n",
      "[49, 300] loss: 0.115\n",
      "[49, 360] loss: 0.114\n",
      "Epoch: 49 -> Loss: 0.0801225453615\n",
      "Epoch: 49 -> Test Accuracy: 87.22\n",
      "[50, 60] loss: 0.098\n",
      "[50, 120] loss: 0.109\n",
      "[50, 180] loss: 0.106\n",
      "[50, 240] loss: 0.106\n",
      "[50, 300] loss: 0.113\n",
      "[50, 360] loss: 0.110\n",
      "Epoch: 50 -> Loss: 0.0398025363684\n",
      "Epoch: 50 -> Test Accuracy: 87.19\n",
      "[51, 60] loss: 0.100\n",
      "[51, 120] loss: 0.099\n",
      "[51, 180] loss: 0.101\n",
      "[51, 240] loss: 0.110\n",
      "[51, 300] loss: 0.115\n",
      "[51, 360] loss: 0.111\n",
      "Epoch: 51 -> Loss: 0.179039627314\n",
      "Epoch: 51 -> Test Accuracy: 86.96\n",
      "[52, 60] loss: 0.094\n",
      "[52, 120] loss: 0.098\n",
      "[52, 180] loss: 0.105\n",
      "[52, 240] loss: 0.105\n",
      "[52, 300] loss: 0.112\n",
      "[52, 360] loss: 0.117\n",
      "Epoch: 52 -> Loss: 0.128962054849\n",
      "Epoch: 52 -> Test Accuracy: 87.15\n",
      "[53, 60] loss: 0.097\n",
      "[53, 120] loss: 0.110\n",
      "[53, 180] loss: 0.104\n",
      "[53, 240] loss: 0.112\n",
      "[53, 300] loss: 0.110\n",
      "[53, 360] loss: 0.117\n",
      "Epoch: 53 -> Loss: 0.116254448891\n",
      "Epoch: 53 -> Test Accuracy: 87.55\n",
      "[54, 60] loss: 0.099\n",
      "[54, 120] loss: 0.089\n",
      "[54, 180] loss: 0.097\n",
      "[54, 240] loss: 0.113\n",
      "[54, 300] loss: 0.114\n",
      "[54, 360] loss: 0.112\n",
      "Epoch: 54 -> Loss: 0.0980487018824\n",
      "Epoch: 54 -> Test Accuracy: 86.96\n",
      "[55, 60] loss: 0.084\n",
      "[55, 120] loss: 0.099\n",
      "[55, 180] loss: 0.111\n",
      "[55, 240] loss: 0.108\n",
      "[55, 300] loss: 0.110\n",
      "[55, 360] loss: 0.119\n",
      "Epoch: 55 -> Loss: 0.11435803026\n",
      "Epoch: 55 -> Test Accuracy: 86.97\n",
      "[56, 60] loss: 0.099\n",
      "[56, 120] loss: 0.100\n",
      "[56, 180] loss: 0.103\n",
      "[56, 240] loss: 0.109\n",
      "[56, 300] loss: 0.109\n",
      "[56, 360] loss: 0.112\n",
      "Epoch: 56 -> Loss: 0.108088694513\n",
      "Epoch: 56 -> Test Accuracy: 87.48\n",
      "[57, 60] loss: 0.098\n",
      "[57, 120] loss: 0.104\n",
      "[57, 180] loss: 0.103\n",
      "[57, 240] loss: 0.109\n",
      "[57, 300] loss: 0.102\n",
      "[57, 360] loss: 0.102\n",
      "Epoch: 57 -> Loss: 0.116165742278\n",
      "Epoch: 57 -> Test Accuracy: 87.26\n",
      "[58, 60] loss: 0.094\n",
      "[58, 120] loss: 0.099\n",
      "[58, 180] loss: 0.111\n",
      "[58, 240] loss: 0.110\n",
      "[58, 300] loss: 0.113\n",
      "[58, 360] loss: 0.122\n",
      "Epoch: 58 -> Loss: 0.241356372833\n",
      "Epoch: 58 -> Test Accuracy: 87.23\n",
      "[59, 60] loss: 0.102\n",
      "[59, 120] loss: 0.098\n",
      "[59, 180] loss: 0.105\n",
      "[59, 240] loss: 0.112\n",
      "[59, 300] loss: 0.104\n",
      "[59, 360] loss: 0.113\n",
      "Epoch: 59 -> Loss: 0.0942915230989\n",
      "Epoch: 59 -> Test Accuracy: 87.41\n",
      "[60, 60] loss: 0.109\n",
      "[60, 120] loss: 0.101\n",
      "[60, 180] loss: 0.104\n",
      "[60, 240] loss: 0.110\n",
      "[60, 300] loss: 0.105\n",
      "[60, 360] loss: 0.113\n",
      "Epoch: 60 -> Loss: 0.123474262655\n",
      "Epoch: 60 -> Test Accuracy: 87.17\n",
      "[61, 60] loss: 0.091\n",
      "[61, 120] loss: 0.092\n",
      "[61, 180] loss: 0.095\n",
      "[61, 240] loss: 0.101\n",
      "[61, 300] loss: 0.110\n",
      "[61, 360] loss: 0.111\n",
      "Epoch: 61 -> Loss: 0.150077745318\n",
      "Epoch: 61 -> Test Accuracy: 87.52\n",
      "[62, 60] loss: 0.091\n",
      "[62, 120] loss: 0.103\n",
      "[62, 180] loss: 0.100\n",
      "[62, 240] loss: 0.101\n",
      "[62, 300] loss: 0.108\n",
      "[62, 360] loss: 0.112\n",
      "Epoch: 62 -> Loss: 0.0992865115404\n",
      "Epoch: 62 -> Test Accuracy: 87.52\n",
      "[63, 60] loss: 0.093\n",
      "[63, 120] loss: 0.097\n",
      "[63, 180] loss: 0.100\n",
      "[63, 240] loss: 0.100\n",
      "[63, 300] loss: 0.109\n",
      "[63, 360] loss: 0.121\n",
      "Epoch: 63 -> Loss: 0.172370001674\n",
      "Epoch: 63 -> Test Accuracy: 86.98\n",
      "[64, 60] loss: 0.099\n",
      "[64, 120] loss: 0.097\n",
      "[64, 180] loss: 0.099\n",
      "[64, 240] loss: 0.105\n",
      "[64, 300] loss: 0.120\n",
      "[64, 360] loss: 0.114\n",
      "Epoch: 64 -> Loss: 0.157233327627\n",
      "Epoch: 64 -> Test Accuracy: 86.84\n",
      "[65, 60] loss: 0.089\n",
      "[65, 120] loss: 0.098\n",
      "[65, 180] loss: 0.099\n",
      "[65, 240] loss: 0.109\n",
      "[65, 300] loss: 0.109\n",
      "[65, 360] loss: 0.109\n",
      "Epoch: 65 -> Loss: 0.119529724121\n",
      "Epoch: 65 -> Test Accuracy: 87.23\n",
      "[66, 60] loss: 0.094\n",
      "[66, 120] loss: 0.092\n",
      "[66, 180] loss: 0.109\n",
      "[66, 240] loss: 0.105\n",
      "[66, 300] loss: 0.108\n",
      "[66, 360] loss: 0.110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Loss: 0.138274505734\n",
      "Epoch: 66 -> Test Accuracy: 87.46\n",
      "[67, 60] loss: 0.091\n",
      "[67, 120] loss: 0.096\n",
      "[67, 180] loss: 0.098\n",
      "[67, 240] loss: 0.103\n",
      "[67, 300] loss: 0.111\n",
      "[67, 360] loss: 0.114\n",
      "Epoch: 67 -> Loss: 0.11690954864\n",
      "Epoch: 67 -> Test Accuracy: 86.92\n",
      "[68, 60] loss: 0.092\n",
      "[68, 120] loss: 0.101\n",
      "[68, 180] loss: 0.108\n",
      "[68, 240] loss: 0.113\n",
      "[68, 300] loss: 0.107\n",
      "[68, 360] loss: 0.108\n",
      "Epoch: 68 -> Loss: 0.109473228455\n",
      "Epoch: 68 -> Test Accuracy: 86.63\n",
      "[69, 60] loss: 0.097\n",
      "[69, 120] loss: 0.093\n",
      "[69, 180] loss: 0.095\n",
      "[69, 240] loss: 0.102\n",
      "[69, 300] loss: 0.114\n",
      "[69, 360] loss: 0.105\n",
      "Epoch: 69 -> Loss: 0.0828288123012\n",
      "Epoch: 69 -> Test Accuracy: 87.23\n",
      "[70, 60] loss: 0.094\n",
      "[70, 120] loss: 0.095\n",
      "[70, 180] loss: 0.103\n",
      "[70, 240] loss: 0.095\n",
      "[70, 300] loss: 0.109\n",
      "[70, 360] loss: 0.106\n",
      "Epoch: 70 -> Loss: 0.12513551116\n",
      "Epoch: 70 -> Test Accuracy: 87.42\n",
      "[71, 60] loss: 0.073\n",
      "[71, 120] loss: 0.072\n",
      "[71, 180] loss: 0.063\n",
      "[71, 240] loss: 0.063\n",
      "[71, 300] loss: 0.055\n",
      "[71, 360] loss: 0.061\n",
      "Epoch: 71 -> Loss: 0.0678733959794\n",
      "Epoch: 71 -> Test Accuracy: 88.48\n",
      "[72, 60] loss: 0.047\n",
      "[72, 120] loss: 0.052\n",
      "[72, 180] loss: 0.049\n",
      "[72, 240] loss: 0.048\n",
      "[72, 300] loss: 0.052\n",
      "[72, 360] loss: 0.053\n",
      "Epoch: 72 -> Loss: 0.0246820803732\n",
      "Epoch: 72 -> Test Accuracy: 88.49\n",
      "[73, 60] loss: 0.046\n",
      "[73, 120] loss: 0.047\n",
      "[73, 180] loss: 0.047\n",
      "[73, 240] loss: 0.047\n",
      "[73, 300] loss: 0.045\n",
      "[73, 360] loss: 0.048\n",
      "Epoch: 73 -> Loss: 0.0414846241474\n",
      "Epoch: 73 -> Test Accuracy: 88.63\n",
      "[74, 60] loss: 0.047\n",
      "[74, 120] loss: 0.042\n",
      "[74, 180] loss: 0.046\n",
      "[74, 240] loss: 0.045\n",
      "[74, 300] loss: 0.042\n",
      "[74, 360] loss: 0.044\n",
      "Epoch: 74 -> Loss: 0.0251543112099\n",
      "Epoch: 74 -> Test Accuracy: 88.7\n",
      "[75, 60] loss: 0.039\n",
      "[75, 120] loss: 0.043\n",
      "[75, 180] loss: 0.045\n",
      "[75, 240] loss: 0.042\n",
      "[75, 300] loss: 0.036\n",
      "[75, 360] loss: 0.044\n",
      "Epoch: 75 -> Loss: 0.0298782531172\n",
      "Epoch: 75 -> Test Accuracy: 88.65\n",
      "[76, 60] loss: 0.037\n",
      "[76, 120] loss: 0.037\n",
      "[76, 180] loss: 0.042\n",
      "[76, 240] loss: 0.040\n",
      "[76, 300] loss: 0.040\n",
      "[76, 360] loss: 0.041\n",
      "Epoch: 76 -> Loss: 0.0689159184694\n",
      "Epoch: 76 -> Test Accuracy: 88.47\n",
      "[77, 60] loss: 0.036\n",
      "[77, 120] loss: 0.036\n",
      "[77, 180] loss: 0.038\n",
      "[77, 240] loss: 0.037\n",
      "[77, 300] loss: 0.034\n",
      "[77, 360] loss: 0.039\n",
      "Epoch: 77 -> Loss: 0.0238733831793\n",
      "Epoch: 77 -> Test Accuracy: 88.66\n",
      "[78, 60] loss: 0.036\n",
      "[78, 120] loss: 0.036\n",
      "[78, 180] loss: 0.039\n",
      "[78, 240] loss: 0.033\n",
      "[78, 300] loss: 0.034\n",
      "[78, 360] loss: 0.039\n",
      "Epoch: 78 -> Loss: 0.0377734452486\n",
      "Epoch: 78 -> Test Accuracy: 88.51\n",
      "[79, 60] loss: 0.034\n",
      "[79, 120] loss: 0.036\n",
      "[79, 180] loss: 0.037\n",
      "[79, 240] loss: 0.040\n",
      "[79, 300] loss: 0.034\n",
      "[79, 360] loss: 0.035\n",
      "Epoch: 79 -> Loss: 0.0226610060781\n",
      "Epoch: 79 -> Test Accuracy: 88.72\n",
      "[80, 60] loss: 0.031\n",
      "[80, 120] loss: 0.033\n",
      "[80, 180] loss: 0.033\n",
      "[80, 240] loss: 0.033\n",
      "[80, 300] loss: 0.037\n",
      "[80, 360] loss: 0.034\n",
      "Epoch: 80 -> Loss: 0.0449096150696\n",
      "Epoch: 80 -> Test Accuracy: 88.68\n",
      "[81, 60] loss: 0.032\n",
      "[81, 120] loss: 0.036\n",
      "[81, 180] loss: 0.034\n",
      "[81, 240] loss: 0.033\n",
      "[81, 300] loss: 0.034\n",
      "[81, 360] loss: 0.037\n",
      "Epoch: 81 -> Loss: 0.0544035844505\n",
      "Epoch: 81 -> Test Accuracy: 88.53\n",
      "[82, 60] loss: 0.031\n",
      "[82, 120] loss: 0.033\n",
      "[82, 180] loss: 0.035\n",
      "[82, 240] loss: 0.033\n",
      "[82, 300] loss: 0.036\n",
      "[82, 360] loss: 0.034\n",
      "Epoch: 82 -> Loss: 0.0424543134868\n",
      "Epoch: 82 -> Test Accuracy: 88.74\n",
      "[83, 60] loss: 0.031\n",
      "[83, 120] loss: 0.032\n",
      "[83, 180] loss: 0.031\n",
      "[83, 240] loss: 0.034\n",
      "[83, 300] loss: 0.032\n",
      "[83, 360] loss: 0.030\n",
      "Epoch: 83 -> Loss: 0.0749002322555\n",
      "Epoch: 83 -> Test Accuracy: 88.62\n",
      "[84, 60] loss: 0.030\n",
      "[84, 120] loss: 0.033\n",
      "[84, 180] loss: 0.032\n",
      "[84, 240] loss: 0.031\n",
      "[84, 300] loss: 0.033\n",
      "[84, 360] loss: 0.034\n",
      "Epoch: 84 -> Loss: 0.034797899425\n",
      "Epoch: 84 -> Test Accuracy: 88.55\n",
      "[85, 60] loss: 0.033\n",
      "[85, 120] loss: 0.028\n",
      "[85, 180] loss: 0.030\n",
      "[85, 240] loss: 0.031\n",
      "[85, 300] loss: 0.034\n",
      "[85, 360] loss: 0.031\n",
      "Epoch: 85 -> Loss: 0.0247629918158\n",
      "Epoch: 85 -> Test Accuracy: 88.59\n",
      "[86, 60] loss: 0.029\n",
      "[86, 120] loss: 0.028\n",
      "[86, 180] loss: 0.029\n",
      "[86, 240] loss: 0.027\n",
      "[86, 300] loss: 0.027\n",
      "[86, 360] loss: 0.030\n",
      "Epoch: 86 -> Loss: 0.0106290634722\n",
      "Epoch: 86 -> Test Accuracy: 88.84\n",
      "[87, 60] loss: 0.026\n",
      "[87, 120] loss: 0.026\n",
      "[87, 180] loss: 0.029\n",
      "[87, 240] loss: 0.029\n",
      "[87, 300] loss: 0.030\n",
      "[87, 360] loss: 0.026\n",
      "Epoch: 87 -> Loss: 0.0210833158344\n",
      "Epoch: 87 -> Test Accuracy: 88.77\n",
      "[88, 60] loss: 0.024\n",
      "[88, 120] loss: 0.026\n",
      "[88, 180] loss: 0.027\n",
      "[88, 240] loss: 0.026\n",
      "[88, 300] loss: 0.031\n",
      "[88, 360] loss: 0.029\n",
      "Epoch: 88 -> Loss: 0.0203830115497\n",
      "Epoch: 88 -> Test Accuracy: 88.92\n",
      "[89, 60] loss: 0.027\n",
      "[89, 120] loss: 0.030\n",
      "[89, 180] loss: 0.027\n",
      "[89, 240] loss: 0.027\n",
      "[89, 300] loss: 0.028\n",
      "[89, 360] loss: 0.027\n",
      "Epoch: 89 -> Loss: 0.0354160666466\n",
      "Epoch: 89 -> Test Accuracy: 88.91\n",
      "[90, 60] loss: 0.025\n",
      "[90, 120] loss: 0.029\n",
      "[90, 180] loss: 0.026\n",
      "[90, 240] loss: 0.026\n",
      "[90, 300] loss: 0.026\n",
      "[90, 360] loss: 0.025\n",
      "Epoch: 90 -> Loss: 0.0443608425558\n",
      "Epoch: 90 -> Test Accuracy: 88.77\n",
      "[91, 60] loss: 0.026\n",
      "[91, 120] loss: 0.027\n",
      "[91, 180] loss: 0.025\n",
      "[91, 240] loss: 0.028\n",
      "[91, 300] loss: 0.025\n",
      "[91, 360] loss: 0.024\n",
      "Epoch: 91 -> Loss: 0.0334783867002\n",
      "Epoch: 91 -> Test Accuracy: 88.89\n",
      "[92, 60] loss: 0.025\n",
      "[92, 120] loss: 0.027\n",
      "[92, 180] loss: 0.025\n",
      "[92, 240] loss: 0.027\n",
      "[92, 300] loss: 0.025\n",
      "[92, 360] loss: 0.026\n",
      "Epoch: 92 -> Loss: 0.0200509317219\n",
      "Epoch: 92 -> Test Accuracy: 88.95\n",
      "[93, 60] loss: 0.027\n",
      "[93, 120] loss: 0.025\n",
      "[93, 180] loss: 0.026\n",
      "[93, 240] loss: 0.025\n",
      "[93, 300] loss: 0.024\n",
      "[93, 360] loss: 0.025\n",
      "Epoch: 93 -> Loss: 0.0316858701408\n",
      "Epoch: 93 -> Test Accuracy: 88.88\n",
      "[94, 60] loss: 0.025\n",
      "[94, 120] loss: 0.028\n",
      "[94, 180] loss: 0.028\n",
      "[94, 240] loss: 0.027\n",
      "[94, 300] loss: 0.024\n",
      "[94, 360] loss: 0.026\n",
      "Epoch: 94 -> Loss: 0.0148616908118\n",
      "Epoch: 94 -> Test Accuracy: 88.79\n",
      "[95, 60] loss: 0.023\n",
      "[95, 120] loss: 0.024\n",
      "[95, 180] loss: 0.024\n",
      "[95, 240] loss: 0.026\n",
      "[95, 300] loss: 0.025\n",
      "[95, 360] loss: 0.024\n",
      "Epoch: 95 -> Loss: 0.0219969265163\n",
      "Epoch: 95 -> Test Accuracy: 88.84\n",
      "[96, 60] loss: 0.024\n",
      "[96, 120] loss: 0.027\n",
      "[96, 180] loss: 0.024\n",
      "[96, 240] loss: 0.026\n",
      "[96, 300] loss: 0.023\n",
      "[96, 360] loss: 0.026\n",
      "Epoch: 96 -> Loss: 0.0454033985734\n",
      "Epoch: 96 -> Test Accuracy: 88.75\n",
      "[97, 60] loss: 0.026\n",
      "[97, 120] loss: 0.025\n",
      "[97, 180] loss: 0.025\n",
      "[97, 240] loss: 0.023\n",
      "[97, 300] loss: 0.024\n",
      "[97, 360] loss: 0.025\n",
      "Epoch: 97 -> Loss: 0.0300606526434\n",
      "Epoch: 97 -> Test Accuracy: 88.7\n",
      "[98, 60] loss: 0.026\n",
      "[98, 120] loss: 0.027\n",
      "[98, 180] loss: 0.023\n",
      "[98, 240] loss: 0.024\n",
      "[98, 300] loss: 0.026\n",
      "[98, 360] loss: 0.022\n",
      "Epoch: 98 -> Loss: 0.00799255352467\n",
      "Epoch: 98 -> Test Accuracy: 88.78\n",
      "[99, 60] loss: 0.024\n",
      "[99, 120] loss: 0.025\n",
      "[99, 180] loss: 0.025\n",
      "[99, 240] loss: 0.026\n",
      "[99, 300] loss: 0.025\n",
      "[99, 360] loss: 0.025\n",
      "Epoch: 99 -> Loss: 0.0292485393584\n",
      "Epoch: 99 -> Test Accuracy: 88.85\n",
      "[100, 60] loss: 0.023\n",
      "[100, 120] loss: 0.026\n",
      "[100, 180] loss: 0.024\n",
      "[100, 240] loss: 0.025\n",
      "[100, 300] loss: 0.024\n",
      "[100, 360] loss: 0.025\n",
      "Epoch: 100 -> Loss: 0.0400872789323\n",
      "Epoch: 100 -> Test Accuracy: 88.77\n",
      "Finished Training\n",
      "[1, 60] loss: 0.944\n",
      "[1, 120] loss: 0.708\n",
      "[1, 180] loss: 0.640\n",
      "[1, 240] loss: 0.608\n",
      "[1, 300] loss: 0.613\n",
      "[1, 360] loss: 0.581\n",
      "Epoch: 1 -> Loss: 0.525946676731\n",
      "Epoch: 1 -> Test Accuracy: 76.18\n",
      "[2, 60] loss: 0.562\n",
      "[2, 120] loss: 0.556\n",
      "[2, 180] loss: 0.542\n",
      "[2, 240] loss: 0.540\n",
      "[2, 300] loss: 0.548\n",
      "[2, 360] loss: 0.530\n",
      "Epoch: 2 -> Loss: 0.491305530071\n",
      "Epoch: 2 -> Test Accuracy: 76.8\n",
      "[3, 60] loss: 0.509\n",
      "[3, 120] loss: 0.502\n",
      "[3, 180] loss: 0.498\n",
      "[3, 240] loss: 0.512\n",
      "[3, 300] loss: 0.511\n",
      "[3, 360] loss: 0.518\n",
      "Epoch: 3 -> Loss: 0.51089656353\n",
      "Epoch: 3 -> Test Accuracy: 78.81\n",
      "[4, 60] loss: 0.468\n",
      "[4, 120] loss: 0.489\n",
      "[4, 180] loss: 0.492\n",
      "[4, 240] loss: 0.487\n",
      "[4, 300] loss: 0.493\n",
      "[4, 360] loss: 0.472\n",
      "Epoch: 4 -> Loss: 0.418497949839\n",
      "Epoch: 4 -> Test Accuracy: 78.08\n",
      "[5, 60] loss: 0.477\n",
      "[5, 120] loss: 0.490\n",
      "[5, 180] loss: 0.469\n",
      "[5, 240] loss: 0.454\n",
      "[5, 300] loss: 0.481\n",
      "[5, 360] loss: 0.477\n",
      "Epoch: 5 -> Loss: 0.44750675559\n",
      "Epoch: 5 -> Test Accuracy: 79.31\n",
      "[6, 60] loss: 0.451\n",
      "[6, 120] loss: 0.467\n",
      "[6, 180] loss: 0.466\n",
      "[6, 240] loss: 0.481\n",
      "[6, 300] loss: 0.456\n",
      "[6, 360] loss: 0.469\n",
      "Epoch: 6 -> Loss: 0.442129194736\n",
      "Epoch: 6 -> Test Accuracy: 79.24\n",
      "[7, 60] loss: 0.453\n",
      "[7, 120] loss: 0.442\n",
      "[7, 180] loss: 0.450\n",
      "[7, 240] loss: 0.474\n",
      "[7, 300] loss: 0.471\n",
      "[7, 360] loss: 0.473\n",
      "Epoch: 7 -> Loss: 0.49910902977\n",
      "Epoch: 7 -> Test Accuracy: 80.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 60] loss: 0.449\n",
      "[8, 120] loss: 0.446\n",
      "[8, 180] loss: 0.448\n",
      "[8, 240] loss: 0.452\n",
      "[8, 300] loss: 0.464\n",
      "[8, 360] loss: 0.459\n",
      "Epoch: 8 -> Loss: 0.343017667532\n",
      "Epoch: 8 -> Test Accuracy: 79.88\n",
      "[9, 60] loss: 0.421\n",
      "[9, 120] loss: 0.433\n",
      "[9, 180] loss: 0.461\n",
      "[9, 240] loss: 0.454\n",
      "[9, 300] loss: 0.450\n",
      "[9, 360] loss: 0.461\n",
      "Epoch: 9 -> Loss: 0.394865095615\n",
      "Epoch: 9 -> Test Accuracy: 80.02\n",
      "[10, 60] loss: 0.428\n",
      "[10, 120] loss: 0.441\n",
      "[10, 180] loss: 0.452\n",
      "[10, 240] loss: 0.449\n",
      "[10, 300] loss: 0.444\n",
      "[10, 360] loss: 0.434\n",
      "Epoch: 10 -> Loss: 0.570749163628\n",
      "Epoch: 10 -> Test Accuracy: 80.07\n",
      "[11, 60] loss: 0.414\n",
      "[11, 120] loss: 0.437\n",
      "[11, 180] loss: 0.440\n",
      "[11, 240] loss: 0.454\n",
      "[11, 300] loss: 0.430\n",
      "[11, 360] loss: 0.444\n",
      "Epoch: 11 -> Loss: 0.420474380255\n",
      "Epoch: 11 -> Test Accuracy: 79.96\n",
      "[12, 60] loss: 0.426\n",
      "[12, 120] loss: 0.445\n",
      "[12, 180] loss: 0.430\n",
      "[12, 240] loss: 0.457\n",
      "[12, 300] loss: 0.429\n",
      "[12, 360] loss: 0.433\n",
      "Epoch: 12 -> Loss: 0.437109082937\n",
      "Epoch: 12 -> Test Accuracy: 79.66\n",
      "[13, 60] loss: 0.410\n",
      "[13, 120] loss: 0.429\n",
      "[13, 180] loss: 0.429\n",
      "[13, 240] loss: 0.458\n",
      "[13, 300] loss: 0.432\n",
      "[13, 360] loss: 0.443\n",
      "Epoch: 13 -> Loss: 0.521059632301\n",
      "Epoch: 13 -> Test Accuracy: 79.67\n",
      "[14, 60] loss: 0.423\n",
      "[14, 120] loss: 0.419\n",
      "[14, 180] loss: 0.432\n",
      "[14, 240] loss: 0.434\n",
      "[14, 300] loss: 0.442\n",
      "[14, 360] loss: 0.431\n",
      "Epoch: 14 -> Loss: 0.438052266836\n",
      "Epoch: 14 -> Test Accuracy: 79.42\n",
      "[15, 60] loss: 0.410\n",
      "[15, 120] loss: 0.433\n",
      "[15, 180] loss: 0.431\n",
      "[15, 240] loss: 0.421\n",
      "[15, 300] loss: 0.432\n",
      "[15, 360] loss: 0.430\n",
      "Epoch: 15 -> Loss: 0.344011634588\n",
      "Epoch: 15 -> Test Accuracy: 80.78\n",
      "[16, 60] loss: 0.405\n",
      "[16, 120] loss: 0.427\n",
      "[16, 180] loss: 0.423\n",
      "[16, 240] loss: 0.444\n",
      "[16, 300] loss: 0.439\n",
      "[16, 360] loss: 0.434\n",
      "Epoch: 16 -> Loss: 0.522401928902\n",
      "Epoch: 16 -> Test Accuracy: 80.96\n",
      "[17, 60] loss: 0.427\n",
      "[17, 120] loss: 0.421\n",
      "[17, 180] loss: 0.431\n",
      "[17, 240] loss: 0.430\n",
      "[17, 300] loss: 0.432\n",
      "[17, 360] loss: 0.429\n",
      "Epoch: 17 -> Loss: 0.454163491726\n",
      "Epoch: 17 -> Test Accuracy: 80.18\n",
      "[18, 60] loss: 0.412\n",
      "[18, 120] loss: 0.405\n",
      "[18, 180] loss: 0.424\n",
      "[18, 240] loss: 0.429\n",
      "[18, 300] loss: 0.430\n",
      "[18, 360] loss: 0.434\n",
      "Epoch: 18 -> Loss: 0.418575674295\n",
      "Epoch: 18 -> Test Accuracy: 81.03\n",
      "[19, 60] loss: 0.398\n",
      "[19, 120] loss: 0.393\n",
      "[19, 180] loss: 0.425\n",
      "[19, 240] loss: 0.419\n",
      "[19, 300] loss: 0.433\n",
      "[19, 360] loss: 0.434\n",
      "Epoch: 19 -> Loss: 0.510185241699\n",
      "Epoch: 19 -> Test Accuracy: 80.54\n",
      "[20, 60] loss: 0.418\n",
      "[20, 120] loss: 0.406\n",
      "[20, 180] loss: 0.422\n",
      "[20, 240] loss: 0.421\n",
      "[20, 300] loss: 0.430\n",
      "[20, 360] loss: 0.430\n",
      "Epoch: 20 -> Loss: 0.288747131824\n",
      "Epoch: 20 -> Test Accuracy: 80.38\n",
      "[21, 60] loss: 0.413\n",
      "[21, 120] loss: 0.416\n",
      "[21, 180] loss: 0.399\n",
      "[21, 240] loss: 0.426\n",
      "[21, 300] loss: 0.415\n",
      "[21, 360] loss: 0.445\n",
      "Epoch: 21 -> Loss: 0.441168308258\n",
      "Epoch: 21 -> Test Accuracy: 81.21\n",
      "[22, 60] loss: 0.398\n",
      "[22, 120] loss: 0.408\n",
      "[22, 180] loss: 0.425\n",
      "[22, 240] loss: 0.432\n",
      "[22, 300] loss: 0.417\n",
      "[22, 360] loss: 0.422\n",
      "Epoch: 22 -> Loss: 0.354813665152\n",
      "Epoch: 22 -> Test Accuracy: 80.41\n",
      "[23, 60] loss: 0.401\n",
      "[23, 120] loss: 0.412\n",
      "[23, 180] loss: 0.413\n",
      "[23, 240] loss: 0.418\n",
      "[23, 300] loss: 0.418\n",
      "[23, 360] loss: 0.421\n",
      "Epoch: 23 -> Loss: 0.314420044422\n",
      "Epoch: 23 -> Test Accuracy: 80.68\n",
      "[24, 60] loss: 0.396\n",
      "[24, 120] loss: 0.421\n",
      "[24, 180] loss: 0.397\n",
      "[24, 240] loss: 0.420\n",
      "[24, 300] loss: 0.410\n",
      "[24, 360] loss: 0.420\n",
      "Epoch: 24 -> Loss: 0.431682735682\n",
      "Epoch: 24 -> Test Accuracy: 81.12\n",
      "[25, 60] loss: 0.404\n",
      "[25, 120] loss: 0.409\n",
      "[25, 180] loss: 0.430\n",
      "[25, 240] loss: 0.423\n",
      "[25, 300] loss: 0.434\n",
      "[25, 360] loss: 0.404\n",
      "Epoch: 25 -> Loss: 0.351793915033\n",
      "Epoch: 25 -> Test Accuracy: 80.94\n",
      "[26, 60] loss: 0.397\n",
      "[26, 120] loss: 0.403\n",
      "[26, 180] loss: 0.408\n",
      "[26, 240] loss: 0.416\n",
      "[26, 300] loss: 0.423\n",
      "[26, 360] loss: 0.436\n",
      "Epoch: 26 -> Loss: 0.399212688208\n",
      "Epoch: 26 -> Test Accuracy: 80.89\n",
      "[27, 60] loss: 0.393\n",
      "[27, 120] loss: 0.394\n",
      "[27, 180] loss: 0.397\n",
      "[27, 240] loss: 0.430\n",
      "[27, 300] loss: 0.442\n",
      "[27, 360] loss: 0.412\n",
      "Epoch: 27 -> Loss: 0.326309084892\n",
      "Epoch: 27 -> Test Accuracy: 81.02\n",
      "[28, 60] loss: 0.399\n",
      "[28, 120] loss: 0.407\n",
      "[28, 180] loss: 0.393\n",
      "[28, 240] loss: 0.414\n",
      "[28, 300] loss: 0.431\n",
      "[28, 360] loss: 0.395\n",
      "Epoch: 28 -> Loss: 0.394883275032\n",
      "Epoch: 28 -> Test Accuracy: 80.32\n",
      "[29, 60] loss: 0.380\n",
      "[29, 120] loss: 0.396\n",
      "[29, 180] loss: 0.408\n",
      "[29, 240] loss: 0.415\n",
      "[29, 300] loss: 0.428\n",
      "[29, 360] loss: 0.421\n",
      "Epoch: 29 -> Loss: 0.271279335022\n",
      "Epoch: 29 -> Test Accuracy: 80.38\n",
      "[30, 60] loss: 0.399\n",
      "[30, 120] loss: 0.392\n",
      "[30, 180] loss: 0.392\n",
      "[30, 240] loss: 0.417\n",
      "[30, 300] loss: 0.442\n",
      "[30, 360] loss: 0.428\n",
      "Epoch: 30 -> Loss: 0.396146029234\n",
      "Epoch: 30 -> Test Accuracy: 80.48\n",
      "[31, 60] loss: 0.406\n",
      "[31, 120] loss: 0.412\n",
      "[31, 180] loss: 0.400\n",
      "[31, 240] loss: 0.422\n",
      "[31, 300] loss: 0.422\n",
      "[31, 360] loss: 0.417\n",
      "Epoch: 31 -> Loss: 0.338467150927\n",
      "Epoch: 31 -> Test Accuracy: 80.72\n",
      "[32, 60] loss: 0.397\n",
      "[32, 120] loss: 0.407\n",
      "[32, 180] loss: 0.406\n",
      "[32, 240] loss: 0.426\n",
      "[32, 300] loss: 0.403\n",
      "[32, 360] loss: 0.424\n",
      "Epoch: 32 -> Loss: 0.461687743664\n",
      "Epoch: 32 -> Test Accuracy: 80.95\n",
      "[33, 60] loss: 0.400\n",
      "[33, 120] loss: 0.408\n",
      "[33, 180] loss: 0.398\n",
      "[33, 240] loss: 0.395\n",
      "[33, 300] loss: 0.425\n",
      "[33, 360] loss: 0.431\n",
      "Epoch: 33 -> Loss: 0.391520261765\n",
      "Epoch: 33 -> Test Accuracy: 80.98\n",
      "[34, 60] loss: 0.390\n",
      "[34, 120] loss: 0.390\n",
      "[34, 180] loss: 0.419\n",
      "[34, 240] loss: 0.423\n",
      "[34, 300] loss: 0.414\n",
      "[34, 360] loss: 0.419\n",
      "Epoch: 34 -> Loss: 0.551268935204\n",
      "Epoch: 34 -> Test Accuracy: 81.56\n",
      "[35, 60] loss: 0.379\n",
      "[35, 120] loss: 0.419\n",
      "[35, 180] loss: 0.419\n",
      "[35, 240] loss: 0.400\n",
      "[35, 300] loss: 0.404\n",
      "[35, 360] loss: 0.412\n",
      "Epoch: 35 -> Loss: 0.411093890667\n",
      "Epoch: 35 -> Test Accuracy: 80.92\n",
      "[36, 60] loss: 0.344\n",
      "[36, 120] loss: 0.339\n",
      "[36, 180] loss: 0.325\n",
      "[36, 240] loss: 0.333\n",
      "[36, 300] loss: 0.329\n",
      "[36, 360] loss: 0.321\n",
      "Epoch: 36 -> Loss: 0.199990302324\n",
      "Epoch: 36 -> Test Accuracy: 82.71\n",
      "[37, 60] loss: 0.314\n",
      "[37, 120] loss: 0.297\n",
      "[37, 180] loss: 0.319\n",
      "[37, 240] loss: 0.305\n",
      "[37, 300] loss: 0.304\n",
      "[37, 360] loss: 0.300\n",
      "Epoch: 37 -> Loss: 0.292003005743\n",
      "Epoch: 37 -> Test Accuracy: 83.26\n",
      "[38, 60] loss: 0.294\n",
      "[38, 120] loss: 0.288\n",
      "[38, 180] loss: 0.296\n",
      "[38, 240] loss: 0.294\n",
      "[38, 300] loss: 0.296\n",
      "[38, 360] loss: 0.300\n",
      "Epoch: 38 -> Loss: 0.324092179537\n",
      "Epoch: 38 -> Test Accuracy: 83.39\n",
      "[39, 60] loss: 0.286\n",
      "[39, 120] loss: 0.288\n",
      "[39, 180] loss: 0.284\n",
      "[39, 240] loss: 0.298\n",
      "[39, 300] loss: 0.305\n",
      "[39, 360] loss: 0.291\n",
      "Epoch: 39 -> Loss: 0.235009759665\n",
      "Epoch: 39 -> Test Accuracy: 83.76\n",
      "[40, 60] loss: 0.288\n",
      "[40, 120] loss: 0.287\n",
      "[40, 180] loss: 0.287\n",
      "[40, 240] loss: 0.289\n",
      "[40, 300] loss: 0.281\n",
      "[40, 360] loss: 0.282\n",
      "Epoch: 40 -> Loss: 0.266657024622\n",
      "Epoch: 40 -> Test Accuracy: 83.04\n",
      "[41, 60] loss: 0.288\n",
      "[41, 120] loss: 0.279\n",
      "[41, 180] loss: 0.285\n",
      "[41, 240] loss: 0.268\n",
      "[41, 300] loss: 0.292\n",
      "[41, 360] loss: 0.278\n",
      "Epoch: 41 -> Loss: 0.216303259134\n",
      "Epoch: 41 -> Test Accuracy: 82.97\n",
      "[42, 60] loss: 0.266\n",
      "[42, 120] loss: 0.269\n",
      "[42, 180] loss: 0.268\n",
      "[42, 240] loss: 0.276\n",
      "[42, 300] loss: 0.289\n",
      "[42, 360] loss: 0.295\n",
      "Epoch: 42 -> Loss: 0.206177949905\n",
      "Epoch: 42 -> Test Accuracy: 83.22\n",
      "[43, 60] loss: 0.269\n",
      "[43, 120] loss: 0.267\n",
      "[43, 180] loss: 0.275\n",
      "[43, 240] loss: 0.286\n",
      "[43, 300] loss: 0.281\n",
      "[43, 360] loss: 0.289\n",
      "Epoch: 43 -> Loss: 0.315302550793\n",
      "Epoch: 43 -> Test Accuracy: 83.0\n",
      "[44, 60] loss: 0.265\n",
      "[44, 120] loss: 0.272\n",
      "[44, 180] loss: 0.263\n",
      "[44, 240] loss: 0.286\n",
      "[44, 300] loss: 0.282\n",
      "[44, 360] loss: 0.288\n",
      "Epoch: 44 -> Loss: 0.239088147879\n",
      "Epoch: 44 -> Test Accuracy: 83.47\n",
      "[45, 60] loss: 0.260\n",
      "[45, 120] loss: 0.264\n",
      "[45, 180] loss: 0.276\n",
      "[45, 240] loss: 0.272\n",
      "[45, 300] loss: 0.280\n",
      "[45, 360] loss: 0.278\n",
      "Epoch: 45 -> Loss: 0.517499685287\n",
      "Epoch: 45 -> Test Accuracy: 82.97\n",
      "[46, 60] loss: 0.261\n",
      "[46, 120] loss: 0.270\n",
      "[46, 180] loss: 0.276\n",
      "[46, 240] loss: 0.278\n",
      "[46, 300] loss: 0.285\n",
      "[46, 360] loss: 0.286\n",
      "Epoch: 46 -> Loss: 0.298107385635\n",
      "Epoch: 46 -> Test Accuracy: 82.66\n",
      "[47, 60] loss: 0.255\n",
      "[47, 120] loss: 0.268\n",
      "[47, 180] loss: 0.273\n",
      "[47, 240] loss: 0.271\n",
      "[47, 300] loss: 0.283\n",
      "[47, 360] loss: 0.292\n",
      "Epoch: 47 -> Loss: 0.31003138423\n",
      "Epoch: 47 -> Test Accuracy: 82.72\n",
      "[48, 60] loss: 0.270\n",
      "[48, 120] loss: 0.263\n",
      "[48, 180] loss: 0.265\n",
      "[48, 240] loss: 0.274\n",
      "[48, 300] loss: 0.277\n",
      "[48, 360] loss: 0.280\n",
      "Epoch: 48 -> Loss: 0.257547706366\n",
      "Epoch: 48 -> Test Accuracy: 83.35\n",
      "[49, 60] loss: 0.256\n",
      "[49, 120] loss: 0.275\n",
      "[49, 180] loss: 0.251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 240] loss: 0.271\n",
      "[49, 300] loss: 0.288\n",
      "[49, 360] loss: 0.292\n",
      "Epoch: 49 -> Loss: 0.36791652441\n",
      "Epoch: 49 -> Test Accuracy: 83.56\n",
      "[50, 60] loss: 0.261\n",
      "[50, 120] loss: 0.266\n",
      "[50, 180] loss: 0.251\n",
      "[50, 240] loss: 0.281\n",
      "[50, 300] loss: 0.267\n",
      "[50, 360] loss: 0.279\n",
      "Epoch: 50 -> Loss: 0.366372019053\n",
      "Epoch: 50 -> Test Accuracy: 82.4\n",
      "[51, 60] loss: 0.261\n",
      "[51, 120] loss: 0.259\n",
      "[51, 180] loss: 0.271\n",
      "[51, 240] loss: 0.284\n",
      "[51, 300] loss: 0.282\n",
      "[51, 360] loss: 0.283\n",
      "Epoch: 51 -> Loss: 0.37327042222\n",
      "Epoch: 51 -> Test Accuracy: 82.4\n",
      "[52, 60] loss: 0.247\n",
      "[52, 120] loss: 0.271\n",
      "[52, 180] loss: 0.268\n",
      "[52, 240] loss: 0.263\n",
      "[52, 300] loss: 0.268\n",
      "[52, 360] loss: 0.292\n",
      "Epoch: 52 -> Loss: 0.266908824444\n",
      "Epoch: 52 -> Test Accuracy: 83.23\n",
      "[53, 60] loss: 0.261\n",
      "[53, 120] loss: 0.270\n",
      "[53, 180] loss: 0.262\n",
      "[53, 240] loss: 0.277\n",
      "[53, 300] loss: 0.277\n",
      "[53, 360] loss: 0.275\n",
      "Epoch: 53 -> Loss: 0.290431320667\n",
      "Epoch: 53 -> Test Accuracy: 82.63\n",
      "[54, 60] loss: 0.253\n",
      "[54, 120] loss: 0.271\n",
      "[54, 180] loss: 0.261\n",
      "[54, 240] loss: 0.271\n",
      "[54, 300] loss: 0.268\n",
      "[54, 360] loss: 0.275\n",
      "Epoch: 54 -> Loss: 0.38958722353\n",
      "Epoch: 54 -> Test Accuracy: 82.95\n",
      "[55, 60] loss: 0.264\n",
      "[55, 120] loss: 0.259\n",
      "[55, 180] loss: 0.270\n",
      "[55, 240] loss: 0.261\n",
      "[55, 300] loss: 0.267\n",
      "[55, 360] loss: 0.285\n",
      "Epoch: 55 -> Loss: 0.279244035482\n",
      "Epoch: 55 -> Test Accuracy: 82.95\n",
      "[56, 60] loss: 0.243\n",
      "[56, 120] loss: 0.257\n",
      "[56, 180] loss: 0.282\n",
      "[56, 240] loss: 0.271\n",
      "[56, 300] loss: 0.259\n",
      "[56, 360] loss: 0.278\n",
      "Epoch: 56 -> Loss: 0.191879481077\n",
      "Epoch: 56 -> Test Accuracy: 83.16\n",
      "[57, 60] loss: 0.248\n",
      "[57, 120] loss: 0.253\n",
      "[57, 180] loss: 0.264\n",
      "[57, 240] loss: 0.285\n",
      "[57, 300] loss: 0.274\n",
      "[57, 360] loss: 0.282\n",
      "Epoch: 57 -> Loss: 0.134701803327\n",
      "Epoch: 57 -> Test Accuracy: 83.39\n",
      "[58, 60] loss: 0.244\n",
      "[58, 120] loss: 0.249\n",
      "[58, 180] loss: 0.275\n",
      "[58, 240] loss: 0.284\n",
      "[58, 300] loss: 0.266\n",
      "[58, 360] loss: 0.277\n",
      "Epoch: 58 -> Loss: 0.241709664464\n",
      "Epoch: 58 -> Test Accuracy: 83.0\n",
      "[59, 60] loss: 0.238\n",
      "[59, 120] loss: 0.251\n",
      "[59, 180] loss: 0.262\n",
      "[59, 240] loss: 0.258\n",
      "[59, 300] loss: 0.272\n",
      "[59, 360] loss: 0.265\n",
      "Epoch: 59 -> Loss: 0.285673558712\n",
      "Epoch: 59 -> Test Accuracy: 82.96\n",
      "[60, 60] loss: 0.242\n",
      "[60, 120] loss: 0.260\n",
      "[60, 180] loss: 0.260\n",
      "[60, 240] loss: 0.257\n",
      "[60, 300] loss: 0.264\n",
      "[60, 360] loss: 0.288\n",
      "Epoch: 60 -> Loss: 0.319700807333\n",
      "Epoch: 60 -> Test Accuracy: 83.01\n",
      "[61, 60] loss: 0.251\n",
      "[61, 120] loss: 0.258\n",
      "[61, 180] loss: 0.271\n",
      "[61, 240] loss: 0.260\n",
      "[61, 300] loss: 0.264\n",
      "[61, 360] loss: 0.267\n",
      "Epoch: 61 -> Loss: 0.230489015579\n",
      "Epoch: 61 -> Test Accuracy: 82.53\n",
      "[62, 60] loss: 0.250\n",
      "[62, 120] loss: 0.241\n",
      "[62, 180] loss: 0.268\n",
      "[62, 240] loss: 0.268\n",
      "[62, 300] loss: 0.264\n",
      "[62, 360] loss: 0.263\n",
      "Epoch: 62 -> Loss: 0.350054740906\n",
      "Epoch: 62 -> Test Accuracy: 82.59\n",
      "[63, 60] loss: 0.244\n",
      "[63, 120] loss: 0.250\n",
      "[63, 180] loss: 0.260\n",
      "[63, 240] loss: 0.276\n",
      "[63, 300] loss: 0.261\n",
      "[63, 360] loss: 0.289\n",
      "Epoch: 63 -> Loss: 0.318574994802\n",
      "Epoch: 63 -> Test Accuracy: 82.14\n",
      "[64, 60] loss: 0.248\n",
      "[64, 120] loss: 0.252\n",
      "[64, 180] loss: 0.256\n",
      "[64, 240] loss: 0.275\n",
      "[64, 300] loss: 0.273\n",
      "[64, 360] loss: 0.267\n",
      "Epoch: 64 -> Loss: 0.17504312098\n",
      "Epoch: 64 -> Test Accuracy: 82.34\n",
      "[65, 60] loss: 0.250\n",
      "[65, 120] loss: 0.239\n",
      "[65, 180] loss: 0.262\n",
      "[65, 240] loss: 0.271\n",
      "[65, 300] loss: 0.262\n",
      "[65, 360] loss: 0.263\n",
      "Epoch: 65 -> Loss: 0.183694884181\n",
      "Epoch: 65 -> Test Accuracy: 82.81\n",
      "[66, 60] loss: 0.245\n",
      "[66, 120] loss: 0.239\n",
      "[66, 180] loss: 0.254\n",
      "[66, 240] loss: 0.272\n",
      "[66, 300] loss: 0.275\n",
      "[66, 360] loss: 0.260\n",
      "Epoch: 66 -> Loss: 0.221641629934\n",
      "Epoch: 66 -> Test Accuracy: 82.82\n",
      "[67, 60] loss: 0.230\n",
      "[67, 120] loss: 0.240\n",
      "[67, 180] loss: 0.260\n",
      "[67, 240] loss: 0.273\n",
      "[67, 300] loss: 0.253\n",
      "[67, 360] loss: 0.276\n",
      "Epoch: 67 -> Loss: 0.341778069735\n",
      "Epoch: 67 -> Test Accuracy: 82.36\n",
      "[68, 60] loss: 0.238\n",
      "[68, 120] loss: 0.252\n",
      "[68, 180] loss: 0.252\n",
      "[68, 240] loss: 0.264\n",
      "[68, 300] loss: 0.265\n",
      "[68, 360] loss: 0.260\n",
      "Epoch: 68 -> Loss: 0.371775776148\n",
      "Epoch: 68 -> Test Accuracy: 82.32\n",
      "[69, 60] loss: 0.238\n",
      "[69, 120] loss: 0.246\n",
      "[69, 180] loss: 0.255\n",
      "[69, 240] loss: 0.266\n",
      "[69, 300] loss: 0.257\n",
      "[69, 360] loss: 0.250\n",
      "Epoch: 69 -> Loss: 0.220050901175\n",
      "Epoch: 69 -> Test Accuracy: 83.31\n",
      "[70, 60] loss: 0.252\n",
      "[70, 120] loss: 0.251\n",
      "[70, 180] loss: 0.253\n",
      "[70, 240] loss: 0.259\n",
      "[70, 300] loss: 0.246\n",
      "[70, 360] loss: 0.251\n",
      "Epoch: 70 -> Loss: 0.354209899902\n",
      "Epoch: 70 -> Test Accuracy: 82.48\n",
      "[71, 60] loss: 0.225\n",
      "[71, 120] loss: 0.207\n",
      "[71, 180] loss: 0.198\n",
      "[71, 240] loss: 0.196\n",
      "[71, 300] loss: 0.193\n",
      "[71, 360] loss: 0.193\n",
      "Epoch: 71 -> Loss: 0.35501947999\n",
      "Epoch: 71 -> Test Accuracy: 84.23\n",
      "[72, 60] loss: 0.181\n",
      "[72, 120] loss: 0.198\n",
      "[72, 180] loss: 0.189\n",
      "[72, 240] loss: 0.179\n",
      "[72, 300] loss: 0.192\n",
      "[72, 360] loss: 0.179\n",
      "Epoch: 72 -> Loss: 0.136572152376\n",
      "Epoch: 72 -> Test Accuracy: 84.24\n",
      "[73, 60] loss: 0.178\n",
      "[73, 120] loss: 0.175\n",
      "[73, 180] loss: 0.189\n",
      "[73, 240] loss: 0.184\n",
      "[73, 300] loss: 0.183\n",
      "[73, 360] loss: 0.172\n",
      "Epoch: 73 -> Loss: 0.191420942545\n",
      "Epoch: 73 -> Test Accuracy: 84.09\n",
      "[74, 60] loss: 0.176\n",
      "[74, 120] loss: 0.175\n",
      "[74, 180] loss: 0.174\n",
      "[74, 240] loss: 0.174\n",
      "[74, 300] loss: 0.165\n",
      "[74, 360] loss: 0.178\n",
      "Epoch: 74 -> Loss: 0.121811911464\n",
      "Epoch: 74 -> Test Accuracy: 84.32\n",
      "[75, 60] loss: 0.162\n",
      "[75, 120] loss: 0.164\n",
      "[75, 180] loss: 0.166\n",
      "[75, 240] loss: 0.172\n",
      "[75, 300] loss: 0.172\n",
      "[75, 360] loss: 0.176\n",
      "Epoch: 75 -> Loss: 0.152078703046\n",
      "Epoch: 75 -> Test Accuracy: 83.99\n",
      "[76, 60] loss: 0.163\n",
      "[76, 120] loss: 0.162\n",
      "[76, 180] loss: 0.166\n",
      "[76, 240] loss: 0.161\n",
      "[76, 300] loss: 0.163\n",
      "[76, 360] loss: 0.176\n",
      "Epoch: 76 -> Loss: 0.123698808253\n",
      "Epoch: 76 -> Test Accuracy: 84.26\n",
      "[77, 60] loss: 0.161\n",
      "[77, 120] loss: 0.167\n",
      "[77, 180] loss: 0.167\n",
      "[77, 240] loss: 0.169\n",
      "[77, 300] loss: 0.163\n",
      "[77, 360] loss: 0.161\n",
      "Epoch: 77 -> Loss: 0.217108935118\n",
      "Epoch: 77 -> Test Accuracy: 84.13\n",
      "[78, 60] loss: 0.156\n",
      "[78, 120] loss: 0.160\n",
      "[78, 180] loss: 0.165\n",
      "[78, 240] loss: 0.162\n",
      "[78, 300] loss: 0.167\n",
      "[78, 360] loss: 0.163\n",
      "Epoch: 78 -> Loss: 0.179110690951\n",
      "Epoch: 78 -> Test Accuracy: 84.18\n",
      "[79, 60] loss: 0.149\n",
      "[79, 120] loss: 0.164\n",
      "[79, 180] loss: 0.155\n",
      "[79, 240] loss: 0.160\n",
      "[79, 300] loss: 0.161\n",
      "[79, 360] loss: 0.168\n",
      "Epoch: 79 -> Loss: 0.279852449894\n",
      "Epoch: 79 -> Test Accuracy: 83.8\n",
      "[80, 60] loss: 0.152\n",
      "[80, 120] loss: 0.159\n",
      "[80, 180] loss: 0.150\n",
      "[80, 240] loss: 0.158\n",
      "[80, 300] loss: 0.153\n",
      "[80, 360] loss: 0.157\n",
      "Epoch: 80 -> Loss: 0.169274643064\n",
      "Epoch: 80 -> Test Accuracy: 83.88\n",
      "[81, 60] loss: 0.152\n",
      "[81, 120] loss: 0.148\n",
      "[81, 180] loss: 0.156\n",
      "[81, 240] loss: 0.154\n",
      "[81, 300] loss: 0.158\n",
      "[81, 360] loss: 0.144\n",
      "Epoch: 81 -> Loss: 0.283686578274\n",
      "Epoch: 81 -> Test Accuracy: 84.1\n",
      "[82, 60] loss: 0.157\n",
      "[82, 120] loss: 0.156\n",
      "[82, 180] loss: 0.149\n",
      "[82, 240] loss: 0.155\n",
      "[82, 300] loss: 0.149\n",
      "[82, 360] loss: 0.165\n",
      "Epoch: 82 -> Loss: 0.316122621298\n",
      "Epoch: 82 -> Test Accuracy: 84.22\n",
      "[83, 60] loss: 0.154\n",
      "[83, 120] loss: 0.146\n",
      "[83, 180] loss: 0.153\n",
      "[83, 240] loss: 0.147\n",
      "[83, 300] loss: 0.154\n",
      "[83, 360] loss: 0.152\n",
      "Epoch: 83 -> Loss: 0.319652169943\n",
      "Epoch: 83 -> Test Accuracy: 84.16\n",
      "[84, 60] loss: 0.142\n",
      "[84, 120] loss: 0.158\n",
      "[84, 180] loss: 0.146\n",
      "[84, 240] loss: 0.160\n",
      "[84, 300] loss: 0.147\n",
      "[84, 360] loss: 0.152\n",
      "Epoch: 84 -> Loss: 0.169294089079\n",
      "Epoch: 84 -> Test Accuracy: 83.92\n",
      "[85, 60] loss: 0.146\n",
      "[85, 120] loss: 0.148\n",
      "[85, 180] loss: 0.148\n",
      "[85, 240] loss: 0.149\n",
      "[85, 300] loss: 0.153\n",
      "[85, 360] loss: 0.151\n",
      "Epoch: 85 -> Loss: 0.164970889688\n",
      "Epoch: 85 -> Test Accuracy: 84.25\n",
      "[86, 60] loss: 0.137\n",
      "[86, 120] loss: 0.148\n",
      "[86, 180] loss: 0.139\n",
      "[86, 240] loss: 0.128\n",
      "[86, 300] loss: 0.132\n",
      "[86, 360] loss: 0.134\n",
      "Epoch: 86 -> Loss: 0.172084063292\n",
      "Epoch: 86 -> Test Accuracy: 84.56\n",
      "[87, 60] loss: 0.136\n",
      "[87, 120] loss: 0.133\n",
      "[87, 180] loss: 0.131\n",
      "[87, 240] loss: 0.127\n",
      "[87, 300] loss: 0.132\n",
      "[87, 360] loss: 0.128\n",
      "Epoch: 87 -> Loss: 0.154645428061\n",
      "Epoch: 87 -> Test Accuracy: 84.62\n",
      "[88, 60] loss: 0.132\n",
      "[88, 120] loss: 0.121\n",
      "[88, 180] loss: 0.130\n",
      "[88, 240] loss: 0.134\n",
      "[88, 300] loss: 0.129\n",
      "[88, 360] loss: 0.130\n",
      "Epoch: 88 -> Loss: 0.118209004402\n",
      "Epoch: 88 -> Test Accuracy: 84.68\n",
      "[89, 60] loss: 0.125\n",
      "[89, 120] loss: 0.130\n",
      "[89, 180] loss: 0.133\n",
      "[89, 240] loss: 0.126\n",
      "[89, 300] loss: 0.130\n",
      "[89, 360] loss: 0.133\n",
      "Epoch: 89 -> Loss: 0.119861885905\n",
      "Epoch: 89 -> Test Accuracy: 84.61\n",
      "[90, 60] loss: 0.127\n",
      "[90, 120] loss: 0.125\n",
      "[90, 180] loss: 0.123\n",
      "[90, 240] loss: 0.142\n",
      "[90, 300] loss: 0.120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90, 360] loss: 0.131\n",
      "Epoch: 90 -> Loss: 0.148670464754\n",
      "Epoch: 90 -> Test Accuracy: 84.64\n",
      "[91, 60] loss: 0.125\n",
      "[91, 120] loss: 0.124\n",
      "[91, 180] loss: 0.127\n",
      "[91, 240] loss: 0.127\n",
      "[91, 300] loss: 0.129\n",
      "[91, 360] loss: 0.134\n",
      "Epoch: 91 -> Loss: 0.229154825211\n",
      "Epoch: 91 -> Test Accuracy: 84.54\n",
      "[92, 60] loss: 0.133\n",
      "[92, 120] loss: 0.126\n",
      "[92, 180] loss: 0.131\n",
      "[92, 240] loss: 0.125\n",
      "[92, 300] loss: 0.130\n",
      "[92, 360] loss: 0.122\n",
      "Epoch: 92 -> Loss: 0.132621482015\n",
      "Epoch: 92 -> Test Accuracy: 84.62\n",
      "[93, 60] loss: 0.131\n",
      "[93, 120] loss: 0.122\n",
      "[93, 180] loss: 0.124\n",
      "[93, 240] loss: 0.126\n",
      "[93, 300] loss: 0.131\n",
      "[93, 360] loss: 0.122\n",
      "Epoch: 93 -> Loss: 0.124566137791\n",
      "Epoch: 93 -> Test Accuracy: 84.54\n",
      "[94, 60] loss: 0.116\n",
      "[94, 120] loss: 0.123\n",
      "[94, 180] loss: 0.120\n",
      "[94, 240] loss: 0.125\n",
      "[94, 300] loss: 0.126\n",
      "[94, 360] loss: 0.125\n",
      "Epoch: 94 -> Loss: 0.141932845116\n",
      "Epoch: 94 -> Test Accuracy: 84.5\n",
      "[95, 60] loss: 0.120\n",
      "[95, 120] loss: 0.124\n",
      "[95, 180] loss: 0.128\n",
      "[95, 240] loss: 0.125\n",
      "[95, 300] loss: 0.119\n",
      "[95, 360] loss: 0.128\n",
      "Epoch: 95 -> Loss: 0.0786533430219\n",
      "Epoch: 95 -> Test Accuracy: 84.53\n",
      "[96, 60] loss: 0.118\n",
      "[96, 120] loss: 0.126\n",
      "[96, 180] loss: 0.124\n",
      "[96, 240] loss: 0.132\n",
      "[96, 300] loss: 0.129\n",
      "[96, 360] loss: 0.122\n",
      "Epoch: 96 -> Loss: 0.123966321349\n",
      "Epoch: 96 -> Test Accuracy: 84.65\n",
      "[97, 60] loss: 0.122\n",
      "[97, 120] loss: 0.125\n",
      "[97, 180] loss: 0.127\n",
      "[97, 240] loss: 0.118\n",
      "[97, 300] loss: 0.122\n",
      "[97, 360] loss: 0.122\n",
      "Epoch: 97 -> Loss: 0.163268581033\n",
      "Epoch: 97 -> Test Accuracy: 84.55\n",
      "[98, 60] loss: 0.123\n",
      "[98, 120] loss: 0.114\n",
      "[98, 180] loss: 0.116\n",
      "[98, 240] loss: 0.126\n",
      "[98, 300] loss: 0.124\n",
      "[98, 360] loss: 0.119\n",
      "Epoch: 98 -> Loss: 0.106427945197\n",
      "Epoch: 98 -> Test Accuracy: 84.52\n",
      "[99, 60] loss: 0.115\n",
      "[99, 120] loss: 0.125\n",
      "[99, 180] loss: 0.121\n",
      "[99, 240] loss: 0.121\n",
      "[99, 300] loss: 0.131\n",
      "[99, 360] loss: 0.120\n",
      "Epoch: 99 -> Loss: 0.0963425189257\n",
      "Epoch: 99 -> Test Accuracy: 84.64\n",
      "[100, 60] loss: 0.129\n",
      "[100, 120] loss: 0.121\n",
      "[100, 180] loss: 0.122\n",
      "[100, 240] loss: 0.122\n",
      "[100, 300] loss: 0.132\n",
      "[100, 360] loss: 0.118\n",
      "Epoch: 100 -> Loss: 0.139837950468\n",
      "Epoch: 100 -> Test Accuracy: 84.46\n",
      "Finished Training\n",
      "[1, 60] loss: 2.082\n",
      "[1, 120] loss: 1.929\n",
      "[1, 180] loss: 1.863\n",
      "[1, 240] loss: 1.818\n",
      "[1, 300] loss: 1.798\n",
      "[1, 360] loss: 1.779\n",
      "Epoch: 1 -> Loss: 1.67026424408\n",
      "Epoch: 1 -> Test Accuracy: 33.82\n",
      "[2, 60] loss: 1.739\n",
      "[2, 120] loss: 1.718\n",
      "[2, 180] loss: 1.710\n",
      "[2, 240] loss: 1.707\n",
      "[2, 300] loss: 1.690\n",
      "[2, 360] loss: 1.669\n",
      "Epoch: 2 -> Loss: 1.66855454445\n",
      "Epoch: 2 -> Test Accuracy: 37.59\n",
      "[3, 60] loss: 1.653\n",
      "[3, 120] loss: 1.664\n",
      "[3, 180] loss: 1.635\n",
      "[3, 240] loss: 1.621\n",
      "[3, 300] loss: 1.631\n",
      "[3, 360] loss: 1.612\n",
      "Epoch: 3 -> Loss: 1.67479801178\n",
      "Epoch: 3 -> Test Accuracy: 38.59\n",
      "[4, 60] loss: 1.598\n",
      "[4, 120] loss: 1.592\n",
      "[4, 180] loss: 1.607\n",
      "[4, 240] loss: 1.595\n",
      "[4, 300] loss: 1.579\n",
      "[4, 360] loss: 1.601\n",
      "Epoch: 4 -> Loss: 1.4861536026\n",
      "Epoch: 4 -> Test Accuracy: 39.27\n",
      "[5, 60] loss: 1.583\n",
      "[5, 120] loss: 1.569\n",
      "[5, 180] loss: 1.587\n",
      "[5, 240] loss: 1.547\n",
      "[5, 300] loss: 1.562\n",
      "[5, 360] loss: 1.580\n",
      "Epoch: 5 -> Loss: 1.55298984051\n",
      "Epoch: 5 -> Test Accuracy: 39.22\n",
      "[6, 60] loss: 1.554\n",
      "[6, 120] loss: 1.564\n",
      "[6, 180] loss: 1.535\n",
      "[6, 240] loss: 1.535\n",
      "[6, 300] loss: 1.554\n",
      "[6, 360] loss: 1.539\n",
      "Epoch: 6 -> Loss: 1.57438361645\n",
      "Epoch: 6 -> Test Accuracy: 41.42\n",
      "[7, 60] loss: 1.554\n",
      "[7, 120] loss: 1.531\n",
      "[7, 180] loss: 1.534\n",
      "[7, 240] loss: 1.546\n",
      "[7, 300] loss: 1.547\n",
      "[7, 360] loss: 1.530\n",
      "Epoch: 7 -> Loss: 1.52843642235\n",
      "Epoch: 7 -> Test Accuracy: 41.09\n",
      "[8, 60] loss: 1.538\n",
      "[8, 120] loss: 1.530\n",
      "[8, 180] loss: 1.516\n",
      "[8, 240] loss: 1.512\n",
      "[8, 300] loss: 1.529\n",
      "[8, 360] loss: 1.535\n",
      "Epoch: 8 -> Loss: 1.46779620647\n",
      "Epoch: 8 -> Test Accuracy: 42.11\n",
      "[9, 60] loss: 1.517\n",
      "[9, 120] loss: 1.531\n",
      "[9, 180] loss: 1.516\n",
      "[9, 240] loss: 1.517\n",
      "[9, 300] loss: 1.526\n",
      "[9, 360] loss: 1.516\n",
      "Epoch: 9 -> Loss: 1.5450040102\n",
      "Epoch: 9 -> Test Accuracy: 41.21\n",
      "[10, 60] loss: 1.494\n",
      "[10, 120] loss: 1.507\n",
      "[10, 180] loss: 1.544\n",
      "[10, 240] loss: 1.517\n",
      "[10, 300] loss: 1.533\n",
      "[10, 360] loss: 1.513\n",
      "Epoch: 10 -> Loss: 1.5149333477\n",
      "Epoch: 10 -> Test Accuracy: 41.39\n",
      "[11, 60] loss: 1.495\n",
      "[11, 120] loss: 1.511\n",
      "[11, 180] loss: 1.496\n",
      "[11, 240] loss: 1.497\n",
      "[11, 300] loss: 1.500\n",
      "[11, 360] loss: 1.499\n",
      "Epoch: 11 -> Loss: 1.58857131004\n",
      "Epoch: 11 -> Test Accuracy: 42.07\n",
      "[12, 60] loss: 1.515\n",
      "[12, 120] loss: 1.529\n",
      "[12, 180] loss: 1.484\n",
      "[12, 240] loss: 1.492\n",
      "[12, 300] loss: 1.512\n",
      "[12, 360] loss: 1.495\n",
      "Epoch: 12 -> Loss: 1.41128790379\n",
      "Epoch: 12 -> Test Accuracy: 42.26\n",
      "[13, 60] loss: 1.489\n",
      "[13, 120] loss: 1.505\n",
      "[13, 180] loss: 1.495\n",
      "[13, 240] loss: 1.510\n",
      "[13, 300] loss: 1.512\n",
      "[13, 360] loss: 1.513\n",
      "Epoch: 13 -> Loss: 1.62382388115\n",
      "Epoch: 13 -> Test Accuracy: 41.98\n",
      "[14, 60] loss: 1.497\n",
      "[14, 120] loss: 1.497\n",
      "[14, 180] loss: 1.496\n",
      "[14, 240] loss: 1.501\n",
      "[14, 300] loss: 1.498\n",
      "[14, 360] loss: 1.492\n",
      "Epoch: 14 -> Loss: 1.65614771843\n",
      "Epoch: 14 -> Test Accuracy: 43.55\n",
      "[15, 60] loss: 1.503\n",
      "[15, 120] loss: 1.487\n",
      "[15, 180] loss: 1.512\n",
      "[15, 240] loss: 1.497\n",
      "[15, 300] loss: 1.490\n",
      "[15, 360] loss: 1.491\n",
      "Epoch: 15 -> Loss: 1.56285095215\n",
      "Epoch: 15 -> Test Accuracy: 42.86\n",
      "[16, 60] loss: 1.496\n",
      "[16, 120] loss: 1.501\n",
      "[16, 180] loss: 1.483\n",
      "[16, 240] loss: 1.479\n",
      "[16, 300] loss: 1.485\n",
      "[16, 360] loss: 1.496\n",
      "Epoch: 16 -> Loss: 1.2336192131\n",
      "Epoch: 16 -> Test Accuracy: 42.88\n",
      "[17, 60] loss: 1.495\n",
      "[17, 120] loss: 1.491\n",
      "[17, 180] loss: 1.512\n",
      "[17, 240] loss: 1.484\n",
      "[17, 300] loss: 1.474\n",
      "[17, 360] loss: 1.495\n",
      "Epoch: 17 -> Loss: 1.44860482216\n",
      "Epoch: 17 -> Test Accuracy: 43.61\n",
      "[18, 60] loss: 1.515\n",
      "[18, 120] loss: 1.479\n",
      "[18, 180] loss: 1.499\n",
      "[18, 240] loss: 1.476\n",
      "[18, 300] loss: 1.483\n",
      "[18, 360] loss: 1.478\n",
      "Epoch: 18 -> Loss: 1.55413246155\n",
      "Epoch: 18 -> Test Accuracy: 42.59\n",
      "[19, 60] loss: 1.474\n",
      "[19, 120] loss: 1.488\n",
      "[19, 180] loss: 1.473\n",
      "[19, 240] loss: 1.491\n",
      "[19, 300] loss: 1.507\n",
      "[19, 360] loss: 1.508\n",
      "Epoch: 19 -> Loss: 1.46486830711\n",
      "Epoch: 19 -> Test Accuracy: 42.61\n",
      "[20, 60] loss: 1.471\n",
      "[20, 120] loss: 1.493\n",
      "[20, 180] loss: 1.495\n",
      "[20, 240] loss: 1.475\n",
      "[20, 300] loss: 1.478\n",
      "[20, 360] loss: 1.477\n",
      "Epoch: 20 -> Loss: 1.37101054192\n",
      "Epoch: 20 -> Test Accuracy: 41.12\n",
      "[21, 60] loss: 1.474\n",
      "[21, 120] loss: 1.493\n",
      "[21, 180] loss: 1.502\n",
      "[21, 240] loss: 1.503\n",
      "[21, 300] loss: 1.478\n",
      "[21, 360] loss: 1.473\n",
      "Epoch: 21 -> Loss: 1.58278739452\n",
      "Epoch: 21 -> Test Accuracy: 41.43\n",
      "[22, 60] loss: 1.485\n",
      "[22, 120] loss: 1.478\n",
      "[22, 180] loss: 1.496\n",
      "[22, 240] loss: 1.502\n",
      "[22, 300] loss: 1.471\n",
      "[22, 360] loss: 1.480\n",
      "Epoch: 22 -> Loss: 1.48059153557\n",
      "Epoch: 22 -> Test Accuracy: 41.49\n",
      "[23, 60] loss: 1.494\n",
      "[23, 120] loss: 1.478\n",
      "[23, 180] loss: 1.486\n",
      "[23, 240] loss: 1.450\n",
      "[23, 300] loss: 1.482\n",
      "[23, 360] loss: 1.468\n",
      "Epoch: 23 -> Loss: 1.47697758675\n",
      "Epoch: 23 -> Test Accuracy: 42.27\n",
      "[24, 60] loss: 1.466\n",
      "[24, 120] loss: 1.463\n",
      "[24, 180] loss: 1.479\n",
      "[24, 240] loss: 1.483\n",
      "[24, 300] loss: 1.483\n",
      "[24, 360] loss: 1.482\n",
      "Epoch: 24 -> Loss: 1.48587536812\n",
      "Epoch: 24 -> Test Accuracy: 44.05\n",
      "[25, 60] loss: 1.464\n",
      "[25, 120] loss: 1.487\n",
      "[25, 180] loss: 1.485\n",
      "[25, 240] loss: 1.467\n",
      "[25, 300] loss: 1.478\n",
      "[25, 360] loss: 1.486\n",
      "Epoch: 25 -> Loss: 1.45291233063\n",
      "Epoch: 25 -> Test Accuracy: 43.09\n",
      "[26, 60] loss: 1.471\n",
      "[26, 120] loss: 1.487\n",
      "[26, 180] loss: 1.487\n",
      "[26, 240] loss: 1.490\n",
      "[26, 300] loss: 1.457\n",
      "[26, 360] loss: 1.474\n",
      "Epoch: 26 -> Loss: 1.68505513668\n",
      "Epoch: 26 -> Test Accuracy: 42.74\n",
      "[27, 60] loss: 1.496\n",
      "[27, 120] loss: 1.489\n",
      "[27, 180] loss: 1.478\n",
      "[27, 240] loss: 1.499\n",
      "[27, 300] loss: 1.473\n",
      "[27, 360] loss: 1.470\n",
      "Epoch: 27 -> Loss: 1.42580330372\n",
      "Epoch: 27 -> Test Accuracy: 42.58\n",
      "[28, 60] loss: 1.470\n",
      "[28, 120] loss: 1.485\n",
      "[28, 180] loss: 1.456\n",
      "[28, 240] loss: 1.484\n",
      "[28, 300] loss: 1.479\n",
      "[28, 360] loss: 1.487\n",
      "Epoch: 28 -> Loss: 1.69204771519\n",
      "Epoch: 28 -> Test Accuracy: 42.11\n",
      "[29, 60] loss: 1.476\n",
      "[29, 120] loss: 1.481\n",
      "[29, 180] loss: 1.467\n",
      "[29, 240] loss: 1.472\n",
      "[29, 300] loss: 1.487\n",
      "[29, 360] loss: 1.485\n",
      "Epoch: 29 -> Loss: 1.5329515934\n",
      "Epoch: 29 -> Test Accuracy: 42.57\n",
      "[30, 60] loss: 1.497\n",
      "[30, 120] loss: 1.494\n",
      "[30, 180] loss: 1.466\n",
      "[30, 240] loss: 1.485\n",
      "[30, 300] loss: 1.471\n",
      "[30, 360] loss: 1.488\n",
      "Epoch: 30 -> Loss: 1.42151224613\n",
      "Epoch: 30 -> Test Accuracy: 42.73\n",
      "[31, 60] loss: 1.487\n",
      "[31, 120] loss: 1.496\n",
      "[31, 180] loss: 1.459\n",
      "[31, 240] loss: 1.482\n",
      "[31, 300] loss: 1.472\n",
      "[31, 360] loss: 1.474\n",
      "Epoch: 31 -> Loss: 1.5895062685\n",
      "Epoch: 31 -> Test Accuracy: 42.92\n",
      "[32, 60] loss: 1.485\n",
      "[32, 120] loss: 1.472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 180] loss: 1.480\n",
      "[32, 240] loss: 1.479\n",
      "[32, 300] loss: 1.470\n",
      "[32, 360] loss: 1.467\n",
      "Epoch: 32 -> Loss: 1.3478000164\n",
      "Epoch: 32 -> Test Accuracy: 43.13\n",
      "[33, 60] loss: 1.440\n",
      "[33, 120] loss: 1.489\n",
      "[33, 180] loss: 1.464\n",
      "[33, 240] loss: 1.482\n",
      "[33, 300] loss: 1.483\n",
      "[33, 360] loss: 1.474\n",
      "Epoch: 33 -> Loss: 1.63054466248\n",
      "Epoch: 33 -> Test Accuracy: 42.0\n",
      "[34, 60] loss: 1.479\n",
      "[34, 120] loss: 1.476\n",
      "[34, 180] loss: 1.466\n",
      "[34, 240] loss: 1.478\n",
      "[34, 300] loss: 1.470\n",
      "[34, 360] loss: 1.480\n",
      "Epoch: 34 -> Loss: 1.49120390415\n",
      "Epoch: 34 -> Test Accuracy: 42.52\n",
      "[35, 60] loss: 1.463\n",
      "[35, 120] loss: 1.474\n",
      "[35, 180] loss: 1.472\n",
      "[35, 240] loss: 1.459\n",
      "[35, 300] loss: 1.474\n",
      "[35, 360] loss: 1.460\n",
      "Epoch: 35 -> Loss: 1.38645970821\n",
      "Epoch: 35 -> Test Accuracy: 43.84\n",
      "[36, 60] loss: 1.431\n",
      "[36, 120] loss: 1.350\n",
      "[36, 180] loss: 1.358\n",
      "[36, 240] loss: 1.355\n",
      "[36, 300] loss: 1.347\n",
      "[36, 360] loss: 1.360\n",
      "Epoch: 36 -> Loss: 1.42236995697\n",
      "Epoch: 36 -> Test Accuracy: 47.24\n",
      "[37, 60] loss: 1.358\n",
      "[37, 120] loss: 1.341\n",
      "[37, 180] loss: 1.344\n",
      "[37, 240] loss: 1.354\n",
      "[37, 300] loss: 1.344\n",
      "[37, 360] loss: 1.350\n",
      "Epoch: 37 -> Loss: 1.45163607597\n",
      "Epoch: 37 -> Test Accuracy: 47.27\n",
      "[38, 60] loss: 1.358\n",
      "[38, 120] loss: 1.329\n",
      "[38, 180] loss: 1.337\n",
      "[38, 240] loss: 1.351\n",
      "[38, 300] loss: 1.331\n",
      "[38, 360] loss: 1.368\n",
      "Epoch: 38 -> Loss: 1.31294512749\n",
      "Epoch: 38 -> Test Accuracy: 47.5\n",
      "[39, 60] loss: 1.323\n",
      "[39, 120] loss: 1.337\n",
      "[39, 180] loss: 1.312\n",
      "[39, 240] loss: 1.337\n",
      "[39, 300] loss: 1.330\n",
      "[39, 360] loss: 1.322\n",
      "Epoch: 39 -> Loss: 1.37419354916\n",
      "Epoch: 39 -> Test Accuracy: 46.95\n",
      "[40, 60] loss: 1.339\n",
      "[40, 120] loss: 1.324\n",
      "[40, 180] loss: 1.316\n",
      "[40, 240] loss: 1.317\n",
      "[40, 300] loss: 1.365\n",
      "[40, 360] loss: 1.355\n",
      "Epoch: 40 -> Loss: 1.31384384632\n",
      "Epoch: 40 -> Test Accuracy: 47.25\n",
      "[41, 60] loss: 1.317\n",
      "[41, 120] loss: 1.360\n",
      "[41, 180] loss: 1.316\n",
      "[41, 240] loss: 1.337\n",
      "[41, 300] loss: 1.330\n",
      "[41, 360] loss: 1.334\n",
      "Epoch: 41 -> Loss: 1.3942220211\n",
      "Epoch: 41 -> Test Accuracy: 47.42\n",
      "[42, 60] loss: 1.318\n",
      "[42, 120] loss: 1.322\n",
      "[42, 180] loss: 1.331\n",
      "[42, 240] loss: 1.349\n",
      "[42, 300] loss: 1.351\n",
      "[42, 360] loss: 1.327\n",
      "Epoch: 42 -> Loss: 1.57675790787\n",
      "Epoch: 42 -> Test Accuracy: 47.18\n",
      "[43, 60] loss: 1.336\n",
      "[43, 120] loss: 1.339\n",
      "[43, 180] loss: 1.331\n",
      "[43, 240] loss: 1.324\n",
      "[43, 300] loss: 1.338\n",
      "[43, 360] loss: 1.324\n",
      "Epoch: 43 -> Loss: 1.18786370754\n",
      "Epoch: 43 -> Test Accuracy: 47.93\n",
      "[44, 60] loss: 1.319\n",
      "[44, 120] loss: 1.328\n",
      "[44, 180] loss: 1.324\n",
      "[44, 240] loss: 1.325\n",
      "[44, 300] loss: 1.327\n",
      "[44, 360] loss: 1.339\n",
      "Epoch: 44 -> Loss: 1.18589484692\n",
      "Epoch: 44 -> Test Accuracy: 47.39\n",
      "[45, 60] loss: 1.321\n",
      "[45, 120] loss: 1.316\n",
      "[45, 180] loss: 1.338\n",
      "[45, 240] loss: 1.361\n",
      "[45, 300] loss: 1.323\n",
      "[45, 360] loss: 1.340\n",
      "Epoch: 45 -> Loss: 1.30830657482\n",
      "Epoch: 45 -> Test Accuracy: 46.82\n",
      "[46, 60] loss: 1.317\n",
      "[46, 120] loss: 1.345\n",
      "[46, 180] loss: 1.341\n",
      "[46, 240] loss: 1.337\n",
      "[46, 300] loss: 1.326\n",
      "[46, 360] loss: 1.328\n",
      "Epoch: 46 -> Loss: 1.26463007927\n",
      "Epoch: 46 -> Test Accuracy: 47.44\n",
      "[47, 60] loss: 1.316\n",
      "[47, 120] loss: 1.318\n",
      "[47, 180] loss: 1.350\n",
      "[47, 240] loss: 1.343\n",
      "[47, 300] loss: 1.333\n",
      "[47, 360] loss: 1.329\n",
      "Epoch: 47 -> Loss: 1.46890377998\n",
      "Epoch: 47 -> Test Accuracy: 47.68\n",
      "[48, 60] loss: 1.339\n",
      "[48, 120] loss: 1.326\n",
      "[48, 180] loss: 1.328\n",
      "[48, 240] loss: 1.309\n",
      "[48, 300] loss: 1.312\n",
      "[48, 360] loss: 1.333\n",
      "Epoch: 48 -> Loss: 1.11550474167\n",
      "Epoch: 48 -> Test Accuracy: 47.13\n",
      "[49, 60] loss: 1.327\n",
      "[49, 120] loss: 1.342\n",
      "[49, 180] loss: 1.336\n",
      "[49, 240] loss: 1.317\n",
      "[49, 300] loss: 1.341\n",
      "[49, 360] loss: 1.351\n",
      "Epoch: 49 -> Loss: 1.44853794575\n",
      "Epoch: 49 -> Test Accuracy: 47.77\n",
      "[50, 60] loss: 1.324\n",
      "[50, 120] loss: 1.333\n",
      "[50, 180] loss: 1.337\n",
      "[50, 240] loss: 1.322\n",
      "[50, 300] loss: 1.331\n",
      "[50, 360] loss: 1.336\n",
      "Epoch: 50 -> Loss: 1.41614806652\n",
      "Epoch: 50 -> Test Accuracy: 48.01\n",
      "[51, 60] loss: 1.312\n",
      "[51, 120] loss: 1.308\n",
      "[51, 180] loss: 1.327\n",
      "[51, 240] loss: 1.324\n",
      "[51, 300] loss: 1.321\n",
      "[51, 360] loss: 1.318\n",
      "Epoch: 51 -> Loss: 1.45832550526\n",
      "Epoch: 51 -> Test Accuracy: 45.98\n",
      "[52, 60] loss: 1.342\n",
      "[52, 120] loss: 1.347\n",
      "[52, 180] loss: 1.317\n",
      "[52, 240] loss: 1.320\n",
      "[52, 300] loss: 1.326\n",
      "[52, 360] loss: 1.314\n",
      "Epoch: 52 -> Loss: 1.28989124298\n",
      "Epoch: 52 -> Test Accuracy: 47.89\n",
      "[53, 60] loss: 1.324\n",
      "[53, 120] loss: 1.342\n",
      "[53, 180] loss: 1.348\n",
      "[53, 240] loss: 1.333\n",
      "[53, 300] loss: 1.321\n",
      "[53, 360] loss: 1.325\n",
      "Epoch: 53 -> Loss: 1.34531009197\n",
      "Epoch: 53 -> Test Accuracy: 46.63\n",
      "[54, 60] loss: 1.324\n",
      "[54, 120] loss: 1.337\n",
      "[54, 180] loss: 1.323\n",
      "[54, 240] loss: 1.326\n",
      "[54, 300] loss: 1.323\n",
      "[54, 360] loss: 1.319\n",
      "Epoch: 54 -> Loss: 1.27353096008\n",
      "Epoch: 54 -> Test Accuracy: 47.94\n",
      "[55, 60] loss: 1.330\n",
      "[55, 120] loss: 1.334\n",
      "[55, 180] loss: 1.328\n",
      "[55, 240] loss: 1.313\n",
      "[55, 300] loss: 1.337\n",
      "[55, 360] loss: 1.318\n",
      "Epoch: 55 -> Loss: 1.21172463894\n",
      "Epoch: 55 -> Test Accuracy: 47.3\n",
      "[56, 60] loss: 1.323\n",
      "[56, 120] loss: 1.331\n",
      "[56, 180] loss: 1.343\n",
      "[56, 240] loss: 1.342\n",
      "[56, 300] loss: 1.331\n",
      "[56, 360] loss: 1.338\n",
      "Epoch: 56 -> Loss: 1.41725242138\n",
      "Epoch: 56 -> Test Accuracy: 47.55\n",
      "[57, 60] loss: 1.323\n",
      "[57, 120] loss: 1.306\n",
      "[57, 180] loss: 1.350\n",
      "[57, 240] loss: 1.336\n",
      "[57, 300] loss: 1.317\n",
      "[57, 360] loss: 1.332\n",
      "Epoch: 57 -> Loss: 1.29977726936\n",
      "Epoch: 57 -> Test Accuracy: 48.56\n",
      "[58, 60] loss: 1.306\n",
      "[58, 120] loss: 1.310\n",
      "[58, 180] loss: 1.343\n",
      "[58, 240] loss: 1.329\n",
      "[58, 300] loss: 1.337\n",
      "[58, 360] loss: 1.314\n",
      "Epoch: 58 -> Loss: 1.50542747974\n",
      "Epoch: 58 -> Test Accuracy: 47.6\n",
      "[59, 60] loss: 1.308\n",
      "[59, 120] loss: 1.328\n",
      "[59, 180] loss: 1.317\n",
      "[59, 240] loss: 1.334\n",
      "[59, 300] loss: 1.329\n",
      "[59, 360] loss: 1.333\n",
      "Epoch: 59 -> Loss: 1.36060893536\n",
      "Epoch: 59 -> Test Accuracy: 46.73\n",
      "[60, 60] loss: 1.349\n",
      "[60, 120] loss: 1.315\n",
      "[60, 180] loss: 1.319\n",
      "[60, 240] loss: 1.325\n",
      "[60, 300] loss: 1.334\n",
      "[60, 360] loss: 1.323\n",
      "Epoch: 60 -> Loss: 1.36124646664\n",
      "Epoch: 60 -> Test Accuracy: 47.87\n",
      "[61, 60] loss: 1.299\n",
      "[61, 120] loss: 1.322\n",
      "[61, 180] loss: 1.314\n",
      "[61, 240] loss: 1.353\n",
      "[61, 300] loss: 1.318\n",
      "[61, 360] loss: 1.335\n",
      "Epoch: 61 -> Loss: 1.2412750721\n",
      "Epoch: 61 -> Test Accuracy: 47.0\n",
      "[62, 60] loss: 1.317\n",
      "[62, 120] loss: 1.330\n",
      "[62, 180] loss: 1.319\n",
      "[62, 240] loss: 1.313\n",
      "[62, 300] loss: 1.315\n",
      "[62, 360] loss: 1.321\n",
      "Epoch: 62 -> Loss: 1.51092064381\n",
      "Epoch: 62 -> Test Accuracy: 47.28\n",
      "[63, 60] loss: 1.341\n",
      "[63, 120] loss: 1.327\n",
      "[63, 180] loss: 1.339\n",
      "[63, 240] loss: 1.331\n",
      "[63, 300] loss: 1.301\n",
      "[63, 360] loss: 1.328\n",
      "Epoch: 63 -> Loss: 1.24285578728\n",
      "Epoch: 63 -> Test Accuracy: 47.8\n",
      "[64, 60] loss: 1.316\n",
      "[64, 120] loss: 1.335\n",
      "[64, 180] loss: 1.304\n",
      "[64, 240] loss: 1.330\n",
      "[64, 300] loss: 1.323\n",
      "[64, 360] loss: 1.321\n",
      "Epoch: 64 -> Loss: 1.22501552105\n",
      "Epoch: 64 -> Test Accuracy: 47.36\n",
      "[65, 60] loss: 1.331\n",
      "[65, 120] loss: 1.332\n",
      "[65, 180] loss: 1.325\n",
      "[65, 240] loss: 1.313\n",
      "[65, 300] loss: 1.299\n",
      "[65, 360] loss: 1.300\n",
      "Epoch: 65 -> Loss: 1.45706570148\n",
      "Epoch: 65 -> Test Accuracy: 47.77\n",
      "[66, 60] loss: 1.311\n",
      "[66, 120] loss: 1.325\n",
      "[66, 180] loss: 1.297\n",
      "[66, 240] loss: 1.317\n",
      "[66, 300] loss: 1.307\n",
      "[66, 360] loss: 1.318\n",
      "Epoch: 66 -> Loss: 1.51663088799\n",
      "Epoch: 66 -> Test Accuracy: 47.03\n",
      "[67, 60] loss: 1.322\n",
      "[67, 120] loss: 1.342\n",
      "[67, 180] loss: 1.324\n",
      "[67, 240] loss: 1.312\n",
      "[67, 300] loss: 1.324\n",
      "[67, 360] loss: 1.303\n",
      "Epoch: 67 -> Loss: 1.24173378944\n",
      "Epoch: 67 -> Test Accuracy: 47.69\n",
      "[68, 60] loss: 1.307\n",
      "[68, 120] loss: 1.302\n",
      "[68, 180] loss: 1.310\n",
      "[68, 240] loss: 1.312\n",
      "[68, 300] loss: 1.324\n",
      "[68, 360] loss: 1.317\n",
      "Epoch: 68 -> Loss: 1.27451491356\n",
      "Epoch: 68 -> Test Accuracy: 48.02\n",
      "[69, 60] loss: 1.311\n",
      "[69, 120] loss: 1.332\n",
      "[69, 180] loss: 1.330\n",
      "[69, 240] loss: 1.308\n",
      "[69, 300] loss: 1.336\n",
      "[69, 360] loss: 1.313\n",
      "Epoch: 69 -> Loss: 1.35714459419\n",
      "Epoch: 69 -> Test Accuracy: 47.11\n",
      "[70, 60] loss: 1.309\n",
      "[70, 120] loss: 1.325\n",
      "[70, 180] loss: 1.324\n",
      "[70, 240] loss: 1.314\n",
      "[70, 300] loss: 1.318\n",
      "[70, 360] loss: 1.324\n",
      "Epoch: 70 -> Loss: 1.31095576286\n",
      "Epoch: 70 -> Test Accuracy: 47.22\n",
      "[71, 60] loss: 1.301\n",
      "[71, 120] loss: 1.246\n",
      "[71, 180] loss: 1.240\n",
      "[71, 240] loss: 1.232\n",
      "[71, 300] loss: 1.249\n",
      "[71, 360] loss: 1.260\n",
      "Epoch: 71 -> Loss: 1.19359338284\n",
      "Epoch: 71 -> Test Accuracy: 50.76\n",
      "[72, 60] loss: 1.248\n",
      "[72, 120] loss: 1.232\n",
      "[72, 180] loss: 1.241\n",
      "[72, 240] loss: 1.229\n",
      "[72, 300] loss: 1.251\n",
      "[72, 360] loss: 1.213\n",
      "Epoch: 72 -> Loss: 1.47404062748\n",
      "Epoch: 72 -> Test Accuracy: 50.51\n",
      "[73, 60] loss: 1.232\n",
      "[73, 120] loss: 1.235\n",
      "[73, 180] loss: 1.256\n",
      "[73, 240] loss: 1.221\n",
      "[73, 300] loss: 1.219\n",
      "[73, 360] loss: 1.241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73 -> Loss: 1.06943678856\n",
      "Epoch: 73 -> Test Accuracy: 50.63\n",
      "[74, 60] loss: 1.241\n",
      "[74, 120] loss: 1.238\n",
      "[74, 180] loss: 1.209\n",
      "[74, 240] loss: 1.211\n",
      "[74, 300] loss: 1.223\n",
      "[74, 360] loss: 1.230\n",
      "Epoch: 74 -> Loss: 1.23911035061\n",
      "Epoch: 74 -> Test Accuracy: 50.69\n",
      "[75, 60] loss: 1.214\n",
      "[75, 120] loss: 1.231\n",
      "[75, 180] loss: 1.221\n",
      "[75, 240] loss: 1.207\n",
      "[75, 300] loss: 1.211\n",
      "[75, 360] loss: 1.213\n",
      "Epoch: 75 -> Loss: 1.00642776489\n",
      "Epoch: 75 -> Test Accuracy: 51.05\n",
      "[76, 60] loss: 1.240\n",
      "[76, 120] loss: 1.221\n",
      "[76, 180] loss: 1.196\n",
      "[76, 240] loss: 1.214\n",
      "[76, 300] loss: 1.222\n",
      "[76, 360] loss: 1.227\n",
      "Epoch: 76 -> Loss: 1.14471018314\n",
      "Epoch: 76 -> Test Accuracy: 51.04\n",
      "[77, 60] loss: 1.221\n",
      "[77, 120] loss: 1.230\n",
      "[77, 180] loss: 1.205\n",
      "[77, 240] loss: 1.224\n",
      "[77, 300] loss: 1.219\n",
      "[77, 360] loss: 1.219\n",
      "Epoch: 77 -> Loss: 0.967162132263\n",
      "Epoch: 77 -> Test Accuracy: 50.96\n",
      "[78, 60] loss: 1.198\n",
      "[78, 120] loss: 1.195\n",
      "[78, 180] loss: 1.219\n",
      "[78, 240] loss: 1.232\n",
      "[78, 300] loss: 1.197\n",
      "[78, 360] loss: 1.216\n",
      "Epoch: 78 -> Loss: 1.27107739449\n",
      "Epoch: 78 -> Test Accuracy: 50.99\n",
      "[79, 60] loss: 1.213\n",
      "[79, 120] loss: 1.211\n",
      "[79, 180] loss: 1.211\n",
      "[79, 240] loss: 1.231\n",
      "[79, 300] loss: 1.215\n",
      "[79, 360] loss: 1.216\n",
      "Epoch: 79 -> Loss: 1.3117839098\n",
      "Epoch: 79 -> Test Accuracy: 51.14\n",
      "[80, 60] loss: 1.211\n",
      "[80, 120] loss: 1.211\n",
      "[80, 180] loss: 1.213\n",
      "[80, 240] loss: 1.217\n",
      "[80, 300] loss: 1.209\n",
      "[80, 360] loss: 1.200\n",
      "Epoch: 80 -> Loss: 1.4038220644\n",
      "Epoch: 80 -> Test Accuracy: 50.25\n",
      "[81, 60] loss: 1.203\n",
      "[81, 120] loss: 1.215\n",
      "[81, 180] loss: 1.189\n",
      "[81, 240] loss: 1.219\n",
      "[81, 300] loss: 1.223\n",
      "[81, 360] loss: 1.230\n",
      "Epoch: 81 -> Loss: 1.27979850769\n",
      "Epoch: 81 -> Test Accuracy: 51.36\n",
      "[82, 60] loss: 1.194\n",
      "[82, 120] loss: 1.209\n",
      "[82, 180] loss: 1.230\n",
      "[82, 240] loss: 1.202\n",
      "[82, 300] loss: 1.202\n",
      "[82, 360] loss: 1.226\n",
      "Epoch: 82 -> Loss: 1.46458494663\n",
      "Epoch: 82 -> Test Accuracy: 51.31\n",
      "[83, 60] loss: 1.197\n",
      "[83, 120] loss: 1.209\n",
      "[83, 180] loss: 1.218\n",
      "[83, 240] loss: 1.211\n",
      "[83, 300] loss: 1.214\n",
      "[83, 360] loss: 1.217\n",
      "Epoch: 83 -> Loss: 1.23092675209\n",
      "Epoch: 83 -> Test Accuracy: 51.16\n",
      "[84, 60] loss: 1.202\n",
      "[84, 120] loss: 1.211\n",
      "[84, 180] loss: 1.206\n",
      "[84, 240] loss: 1.196\n",
      "[84, 300] loss: 1.221\n",
      "[84, 360] loss: 1.211\n",
      "Epoch: 84 -> Loss: 1.28723967075\n",
      "Epoch: 84 -> Test Accuracy: 51.36\n",
      "[85, 60] loss: 1.211\n",
      "[85, 120] loss: 1.208\n",
      "[85, 180] loss: 1.224\n",
      "[85, 240] loss: 1.194\n",
      "[85, 300] loss: 1.211\n",
      "[85, 360] loss: 1.223\n",
      "Epoch: 85 -> Loss: 1.26623129845\n",
      "Epoch: 85 -> Test Accuracy: 51.08\n",
      "[86, 60] loss: 1.183\n",
      "[86, 120] loss: 1.178\n",
      "[86, 180] loss: 1.182\n",
      "[86, 240] loss: 1.179\n",
      "[86, 300] loss: 1.179\n",
      "[86, 360] loss: 1.173\n",
      "Epoch: 86 -> Loss: 1.21830964088\n",
      "Epoch: 86 -> Test Accuracy: 52.0\n",
      "[87, 60] loss: 1.167\n",
      "[87, 120] loss: 1.187\n",
      "[87, 180] loss: 1.163\n",
      "[87, 240] loss: 1.169\n",
      "[87, 300] loss: 1.158\n",
      "[87, 360] loss: 1.198\n",
      "Epoch: 87 -> Loss: 1.14631295204\n",
      "Epoch: 87 -> Test Accuracy: 52.35\n",
      "[88, 60] loss: 1.164\n",
      "[88, 120] loss: 1.167\n",
      "[88, 180] loss: 1.182\n",
      "[88, 240] loss: 1.188\n",
      "[88, 300] loss: 1.164\n",
      "[88, 360] loss: 1.157\n",
      "Epoch: 88 -> Loss: 1.20009255409\n",
      "Epoch: 88 -> Test Accuracy: 52.18\n",
      "[89, 60] loss: 1.163\n",
      "[89, 120] loss: 1.161\n",
      "[89, 180] loss: 1.178\n",
      "[89, 240] loss: 1.179\n",
      "[89, 300] loss: 1.173\n",
      "[89, 360] loss: 1.169\n",
      "Epoch: 89 -> Loss: 1.15107369423\n",
      "Epoch: 89 -> Test Accuracy: 52.55\n",
      "[90, 60] loss: 1.164\n",
      "[90, 120] loss: 1.167\n",
      "[90, 180] loss: 1.180\n",
      "[90, 240] loss: 1.157\n",
      "[90, 300] loss: 1.160\n",
      "[90, 360] loss: 1.164\n",
      "Epoch: 90 -> Loss: 1.10894274712\n",
      "Epoch: 90 -> Test Accuracy: 52.52\n",
      "[91, 60] loss: 1.169\n",
      "[91, 120] loss: 1.163\n",
      "[91, 180] loss: 1.164\n",
      "[91, 240] loss: 1.181\n",
      "[91, 300] loss: 1.153\n",
      "[91, 360] loss: 1.164\n",
      "Epoch: 91 -> Loss: 1.09214377403\n",
      "Epoch: 91 -> Test Accuracy: 52.95\n",
      "[92, 60] loss: 1.180\n",
      "[92, 120] loss: 1.182\n",
      "[92, 180] loss: 1.167\n",
      "[92, 240] loss: 1.157\n",
      "[92, 300] loss: 1.160\n",
      "[92, 360] loss: 1.151\n",
      "Epoch: 92 -> Loss: 1.31798136234\n",
      "Epoch: 92 -> Test Accuracy: 52.59\n",
      "[93, 60] loss: 1.179\n",
      "[93, 120] loss: 1.162\n",
      "[93, 180] loss: 1.149\n",
      "[93, 240] loss: 1.158\n",
      "[93, 300] loss: 1.176\n",
      "[93, 360] loss: 1.171\n",
      "Epoch: 93 -> Loss: 1.1227196455\n",
      "Epoch: 93 -> Test Accuracy: 52.45\n",
      "[94, 60] loss: 1.174\n",
      "[94, 120] loss: 1.165\n",
      "[94, 180] loss: 1.170\n",
      "[94, 240] loss: 1.157\n",
      "[94, 300] loss: 1.163\n",
      "[94, 360] loss: 1.182\n",
      "Epoch: 94 -> Loss: 1.24051332474\n",
      "Epoch: 94 -> Test Accuracy: 52.5\n",
      "[95, 60] loss: 1.139\n",
      "[95, 120] loss: 1.149\n",
      "[95, 180] loss: 1.165\n",
      "[95, 240] loss: 1.155\n",
      "[95, 300] loss: 1.168\n",
      "[95, 360] loss: 1.186\n",
      "Epoch: 95 -> Loss: 1.17861127853\n",
      "Epoch: 95 -> Test Accuracy: 52.6\n",
      "[96, 60] loss: 1.160\n",
      "[96, 120] loss: 1.151\n",
      "[96, 180] loss: 1.162\n",
      "[96, 240] loss: 1.185\n",
      "[96, 300] loss: 1.159\n",
      "[96, 360] loss: 1.144\n",
      "Epoch: 96 -> Loss: 1.30046868324\n",
      "Epoch: 96 -> Test Accuracy: 52.61\n",
      "[97, 60] loss: 1.166\n",
      "[97, 120] loss: 1.142\n",
      "[97, 180] loss: 1.155\n",
      "[97, 240] loss: 1.161\n",
      "[97, 300] loss: 1.154\n",
      "[97, 360] loss: 1.180\n",
      "Epoch: 97 -> Loss: 1.06159305573\n",
      "Epoch: 97 -> Test Accuracy: 52.75\n",
      "[98, 60] loss: 1.160\n",
      "[98, 120] loss: 1.161\n",
      "[98, 180] loss: 1.153\n",
      "[98, 240] loss: 1.164\n",
      "[98, 300] loss: 1.166\n",
      "[98, 360] loss: 1.165\n",
      "Epoch: 98 -> Loss: 1.11536085606\n",
      "Epoch: 98 -> Test Accuracy: 52.74\n",
      "[99, 60] loss: 1.146\n",
      "[99, 120] loss: 1.155\n",
      "[99, 180] loss: 1.159\n",
      "[99, 240] loss: 1.147\n",
      "[99, 300] loss: 1.160\n",
      "[99, 360] loss: 1.179\n",
      "Epoch: 99 -> Loss: 1.04047560692\n",
      "Epoch: 99 -> Test Accuracy: 52.38\n",
      "[100, 60] loss: 1.152\n",
      "[100, 120] loss: 1.166\n",
      "[100, 180] loss: 1.161\n",
      "[100, 240] loss: 1.141\n",
      "[100, 300] loss: 1.167\n",
      "[100, 360] loss: 1.163\n",
      "Epoch: 100 -> Loss: 1.10527777672\n",
      "Epoch: 100 -> Test Accuracy: 52.84\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train ConvClassifiers on feature map of net_3block\n",
    "conv_block4_loss_log, _, conv_block4_test_accuracy_log, _, _ = tr.train_all_blocks(4, 10, [0.1, 0.02, 0.004, 0.0008], \n",
    "    [35, 70, 85, 100], 0.9, 5e-4, net_block4, criterion, trainloader, None, testloader, use_ConvClassifier=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save variables\n",
    "fm.save_variable([rot_block4_loss_log, rot_block4_test_accuracy_log, \n",
    "                  block4_loss_log, block4_test_accuracy_log, \n",
    "                  conv_block4_loss_log, conv_block4_test_accuracy_log], \"4_block_net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename files\n",
    "fm.add_block_to_name(4, [100, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Block RotNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize network\n",
    "net_block5 = RN.RotNet(num_classes=4, num_conv_block=5, add_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.150\n",
      "[1, 120] loss: 1.009\n",
      "[1, 180] loss: 0.937\n",
      "[1, 240] loss: 0.881\n",
      "[1, 300] loss: 0.840\n",
      "[1, 360] loss: 0.809\n",
      "Epoch: 1 -> Loss: 0.706528186798\n",
      "Epoch: 1 -> Test Accuracy: 67.8\n",
      "[2, 60] loss: 0.750\n",
      "[2, 120] loss: 0.738\n",
      "[2, 180] loss: 0.719\n",
      "[2, 240] loss: 0.699\n",
      "[2, 300] loss: 0.701\n",
      "[2, 360] loss: 0.661\n",
      "Epoch: 2 -> Loss: 0.674540877342\n",
      "Epoch: 2 -> Test Accuracy: 74.25\n",
      "[3, 60] loss: 0.648\n",
      "[3, 120] loss: 0.628\n",
      "[3, 180] loss: 0.622\n",
      "[3, 240] loss: 0.613\n",
      "[3, 300] loss: 0.601\n",
      "[3, 360] loss: 0.599\n",
      "Epoch: 3 -> Loss: 0.547346711159\n",
      "Epoch: 3 -> Test Accuracy: 76.78\n",
      "[4, 60] loss: 0.570\n",
      "[4, 120] loss: 0.575\n",
      "[4, 180] loss: 0.556\n",
      "[4, 240] loss: 0.559\n",
      "[4, 300] loss: 0.540\n",
      "[4, 360] loss: 0.556\n",
      "Epoch: 4 -> Loss: 0.583145558834\n",
      "Epoch: 4 -> Test Accuracy: 78.97\n",
      "[5, 60] loss: 0.542\n",
      "[5, 120] loss: 0.530\n",
      "[5, 180] loss: 0.518\n",
      "[5, 240] loss: 0.520\n",
      "[5, 300] loss: 0.500\n",
      "[5, 360] loss: 0.493\n",
      "Epoch: 5 -> Loss: 0.451287358999\n",
      "Epoch: 5 -> Test Accuracy: 79.9525\n",
      "[6, 60] loss: 0.485\n",
      "[6, 120] loss: 0.493\n",
      "[6, 180] loss: 0.491\n",
      "[6, 240] loss: 0.497\n",
      "[6, 300] loss: 0.484\n",
      "[6, 360] loss: 0.473\n",
      "Epoch: 6 -> Loss: 0.326938331127\n",
      "Epoch: 6 -> Test Accuracy: 80.2925\n",
      "[7, 60] loss: 0.461\n",
      "[7, 120] loss: 0.467\n",
      "[7, 180] loss: 0.475\n",
      "[7, 240] loss: 0.450\n",
      "[7, 300] loss: 0.454\n",
      "[7, 360] loss: 0.462\n",
      "Epoch: 7 -> Loss: 0.44445079565\n",
      "Epoch: 7 -> Test Accuracy: 80.715\n",
      "[8, 60] loss: 0.440\n",
      "[8, 120] loss: 0.441\n",
      "[8, 180] loss: 0.447\n",
      "[8, 240] loss: 0.465\n",
      "[8, 300] loss: 0.446\n",
      "[8, 360] loss: 0.447\n",
      "Epoch: 8 -> Loss: 0.326623409986\n",
      "Epoch: 8 -> Test Accuracy: 82.415\n",
      "[9, 60] loss: 0.426\n",
      "[9, 120] loss: 0.431\n",
      "[9, 180] loss: 0.425\n",
      "[9, 240] loss: 0.430\n",
      "[9, 300] loss: 0.429\n",
      "[9, 360] loss: 0.447\n",
      "Epoch: 9 -> Loss: 0.430388301611\n",
      "Epoch: 9 -> Test Accuracy: 82.5525\n",
      "[10, 60] loss: 0.406\n",
      "[10, 120] loss: 0.428\n",
      "[10, 180] loss: 0.410\n",
      "[10, 240] loss: 0.423\n",
      "[10, 300] loss: 0.430\n",
      "[10, 360] loss: 0.419\n",
      "Epoch: 10 -> Loss: 0.21101538837\n",
      "Epoch: 10 -> Test Accuracy: 83.4\n",
      "[11, 60] loss: 0.404\n",
      "[11, 120] loss: 0.418\n",
      "[11, 180] loss: 0.421\n",
      "[11, 240] loss: 0.402\n",
      "[11, 300] loss: 0.418\n",
      "[11, 360] loss: 0.411\n",
      "Epoch: 11 -> Loss: 0.470157146454\n",
      "Epoch: 11 -> Test Accuracy: 82.695\n",
      "[12, 60] loss: 0.404\n",
      "[12, 120] loss: 0.399\n",
      "[12, 180] loss: 0.406\n",
      "[12, 240] loss: 0.399\n",
      "[12, 300] loss: 0.394\n",
      "[12, 360] loss: 0.390\n",
      "Epoch: 12 -> Loss: 0.350586920977\n",
      "Epoch: 12 -> Test Accuracy: 84.105\n",
      "[13, 60] loss: 0.387\n",
      "[13, 120] loss: 0.394\n",
      "[13, 180] loss: 0.394\n",
      "[13, 240] loss: 0.393\n",
      "[13, 300] loss: 0.400\n",
      "[13, 360] loss: 0.386\n",
      "Epoch: 13 -> Loss: 0.476928651333\n",
      "Epoch: 13 -> Test Accuracy: 84.475\n",
      "[14, 60] loss: 0.385\n",
      "[14, 120] loss: 0.383\n",
      "[14, 180] loss: 0.398\n",
      "[14, 240] loss: 0.378\n",
      "[14, 300] loss: 0.389\n",
      "[14, 360] loss: 0.375\n",
      "Epoch: 14 -> Loss: 0.443620860577\n",
      "Epoch: 14 -> Test Accuracy: 84.0225\n",
      "[15, 60] loss: 0.377\n",
      "[15, 120] loss: 0.381\n",
      "[15, 180] loss: 0.372\n",
      "[15, 240] loss: 0.366\n",
      "[15, 300] loss: 0.389\n",
      "[15, 360] loss: 0.366\n",
      "Epoch: 15 -> Loss: 0.502232015133\n",
      "Epoch: 15 -> Test Accuracy: 85.22\n",
      "[16, 60] loss: 0.369\n",
      "[16, 120] loss: 0.379\n",
      "[16, 180] loss: 0.372\n",
      "[16, 240] loss: 0.362\n",
      "[16, 300] loss: 0.363\n",
      "[16, 360] loss: 0.368\n",
      "Epoch: 16 -> Loss: 0.322080373764\n",
      "Epoch: 16 -> Test Accuracy: 83.9175\n",
      "[17, 60] loss: 0.364\n",
      "[17, 120] loss: 0.373\n",
      "[17, 180] loss: 0.367\n",
      "[17, 240] loss: 0.354\n",
      "[17, 300] loss: 0.377\n",
      "[17, 360] loss: 0.369\n",
      "Epoch: 17 -> Loss: 0.38893738389\n",
      "Epoch: 17 -> Test Accuracy: 84.6775\n",
      "[18, 60] loss: 0.360\n",
      "[18, 120] loss: 0.346\n",
      "[18, 180] loss: 0.374\n",
      "[18, 240] loss: 0.364\n",
      "[18, 300] loss: 0.361\n",
      "[18, 360] loss: 0.370\n",
      "Epoch: 18 -> Loss: 0.341686397791\n",
      "Epoch: 18 -> Test Accuracy: 84.5\n",
      "[19, 60] loss: 0.359\n",
      "[19, 120] loss: 0.354\n",
      "[19, 180] loss: 0.370\n",
      "[19, 240] loss: 0.356\n",
      "[19, 300] loss: 0.365\n",
      "[19, 360] loss: 0.356\n",
      "Epoch: 19 -> Loss: 0.334328770638\n",
      "Epoch: 19 -> Test Accuracy: 85.195\n",
      "[20, 60] loss: 0.345\n",
      "[20, 120] loss: 0.349\n",
      "[20, 180] loss: 0.351\n",
      "[20, 240] loss: 0.373\n",
      "[20, 300] loss: 0.354\n",
      "[20, 360] loss: 0.354\n",
      "Epoch: 20 -> Loss: 0.353271633387\n",
      "Epoch: 20 -> Test Accuracy: 85.7875\n",
      "[21, 60] loss: 0.347\n",
      "[21, 120] loss: 0.358\n",
      "[21, 180] loss: 0.347\n",
      "[21, 240] loss: 0.331\n",
      "[21, 300] loss: 0.346\n",
      "[21, 360] loss: 0.354\n",
      "Epoch: 21 -> Loss: 0.440704971552\n",
      "Epoch: 21 -> Test Accuracy: 84.835\n",
      "[22, 60] loss: 0.329\n",
      "[22, 120] loss: 0.346\n",
      "[22, 180] loss: 0.356\n",
      "[22, 240] loss: 0.348\n",
      "[22, 300] loss: 0.346\n",
      "[22, 360] loss: 0.347\n",
      "Epoch: 22 -> Loss: 0.414895355701\n",
      "Epoch: 22 -> Test Accuracy: 84.1625\n",
      "[23, 60] loss: 0.353\n",
      "[23, 120] loss: 0.332\n",
      "[23, 180] loss: 0.344\n",
      "[23, 240] loss: 0.326\n",
      "[23, 300] loss: 0.357\n",
      "[23, 360] loss: 0.344\n",
      "Epoch: 23 -> Loss: 0.337291687727\n",
      "Epoch: 23 -> Test Accuracy: 85.4975\n",
      "[24, 60] loss: 0.332\n",
      "[24, 120] loss: 0.357\n",
      "[24, 180] loss: 0.336\n",
      "[24, 240] loss: 0.342\n",
      "[24, 300] loss: 0.340\n",
      "[24, 360] loss: 0.352\n",
      "Epoch: 24 -> Loss: 0.34106746316\n",
      "Epoch: 24 -> Test Accuracy: 85.39\n",
      "[25, 60] loss: 0.338\n",
      "[25, 120] loss: 0.342\n",
      "[25, 180] loss: 0.331\n",
      "[25, 240] loss: 0.330\n",
      "[25, 300] loss: 0.343\n",
      "[25, 360] loss: 0.342\n",
      "Epoch: 25 -> Loss: 0.291838079691\n",
      "Epoch: 25 -> Test Accuracy: 85.4475\n",
      "[26, 60] loss: 0.337\n",
      "[26, 120] loss: 0.333\n",
      "[26, 180] loss: 0.333\n",
      "[26, 240] loss: 0.333\n",
      "[26, 300] loss: 0.355\n",
      "[26, 360] loss: 0.345\n",
      "Epoch: 26 -> Loss: 0.250146746635\n",
      "Epoch: 26 -> Test Accuracy: 85.66\n",
      "[27, 60] loss: 0.322\n",
      "[27, 120] loss: 0.332\n",
      "[27, 180] loss: 0.329\n",
      "[27, 240] loss: 0.342\n",
      "[27, 300] loss: 0.327\n",
      "[27, 360] loss: 0.358\n",
      "Epoch: 27 -> Loss: 0.34985512495\n",
      "Epoch: 27 -> Test Accuracy: 86.1825\n",
      "[28, 60] loss: 0.320\n",
      "[28, 120] loss: 0.341\n",
      "[28, 180] loss: 0.334\n",
      "[28, 240] loss: 0.334\n",
      "[28, 300] loss: 0.334\n",
      "[28, 360] loss: 0.335\n",
      "Epoch: 28 -> Loss: 0.324654519558\n",
      "Epoch: 28 -> Test Accuracy: 85.815\n",
      "[29, 60] loss: 0.329\n",
      "[29, 120] loss: 0.323\n",
      "[29, 180] loss: 0.332\n",
      "[29, 240] loss: 0.331\n",
      "[29, 300] loss: 0.340\n",
      "[29, 360] loss: 0.332\n",
      "Epoch: 29 -> Loss: 0.280507802963\n",
      "Epoch: 29 -> Test Accuracy: 86.43\n",
      "[30, 60] loss: 0.311\n",
      "[30, 120] loss: 0.325\n",
      "[30, 180] loss: 0.324\n",
      "[30, 240] loss: 0.327\n",
      "[30, 300] loss: 0.341\n",
      "[30, 360] loss: 0.336\n",
      "Epoch: 30 -> Loss: 0.284505456686\n",
      "Epoch: 30 -> Test Accuracy: 85.885\n",
      "[31, 60] loss: 0.316\n",
      "[31, 120] loss: 0.330\n",
      "[31, 180] loss: 0.332\n",
      "[31, 240] loss: 0.319\n",
      "[31, 300] loss: 0.326\n",
      "[31, 360] loss: 0.339\n",
      "Epoch: 31 -> Loss: 0.405428081751\n",
      "Epoch: 31 -> Test Accuracy: 85.62\n",
      "[32, 60] loss: 0.308\n",
      "[32, 120] loss: 0.322\n",
      "[32, 180] loss: 0.321\n",
      "[32, 240] loss: 0.338\n",
      "[32, 300] loss: 0.347\n",
      "[32, 360] loss: 0.321\n",
      "Epoch: 32 -> Loss: 0.404097735882\n",
      "Epoch: 32 -> Test Accuracy: 85.925\n",
      "[33, 60] loss: 0.326\n",
      "[33, 120] loss: 0.334\n",
      "[33, 180] loss: 0.313\n",
      "[33, 240] loss: 0.318\n",
      "[33, 300] loss: 0.323\n",
      "[33, 360] loss: 0.334\n",
      "Epoch: 33 -> Loss: 0.454325735569\n",
      "Epoch: 33 -> Test Accuracy: 86.655\n",
      "[34, 60] loss: 0.310\n",
      "[34, 120] loss: 0.317\n",
      "[34, 180] loss: 0.330\n",
      "[34, 240] loss: 0.335\n",
      "[34, 300] loss: 0.334\n",
      "[34, 360] loss: 0.318\n",
      "Epoch: 34 -> Loss: 0.314757913351\n",
      "Epoch: 34 -> Test Accuracy: 85.375\n",
      "[35, 60] loss: 0.302\n",
      "[35, 120] loss: 0.316\n",
      "[35, 180] loss: 0.324\n",
      "[35, 240] loss: 0.325\n",
      "[35, 300] loss: 0.322\n",
      "[35, 360] loss: 0.330\n",
      "Epoch: 35 -> Loss: 0.355924636126\n",
      "Epoch: 35 -> Test Accuracy: 86.6175\n",
      "[36, 60] loss: 0.309\n",
      "[36, 120] loss: 0.304\n",
      "[36, 180] loss: 0.321\n",
      "[36, 240] loss: 0.326\n",
      "[36, 300] loss: 0.314\n",
      "[36, 360] loss: 0.330\n",
      "Epoch: 36 -> Loss: 0.31842559576\n",
      "Epoch: 36 -> Test Accuracy: 86.76\n",
      "[37, 60] loss: 0.307\n",
      "[37, 120] loss: 0.328\n",
      "[37, 180] loss: 0.328\n",
      "[37, 240] loss: 0.312\n",
      "[37, 300] loss: 0.323\n",
      "[37, 360] loss: 0.308\n",
      "Epoch: 37 -> Loss: 0.349977552891\n",
      "Epoch: 37 -> Test Accuracy: 86.355\n",
      "[38, 60] loss: 0.309\n",
      "[38, 120] loss: 0.319\n",
      "[38, 180] loss: 0.307\n",
      "[38, 240] loss: 0.323\n",
      "[38, 300] loss: 0.318\n",
      "[38, 360] loss: 0.329\n",
      "Epoch: 38 -> Loss: 0.250458776951\n",
      "Epoch: 38 -> Test Accuracy: 86.5525\n",
      "[39, 60] loss: 0.313\n",
      "[39, 120] loss: 0.303\n",
      "[39, 180] loss: 0.328\n",
      "[39, 240] loss: 0.320\n",
      "[39, 300] loss: 0.314\n",
      "[39, 360] loss: 0.319\n",
      "Epoch: 39 -> Loss: 0.373709797859\n",
      "Epoch: 39 -> Test Accuracy: 86.9125\n",
      "[40, 60] loss: 0.294\n",
      "[40, 120] loss: 0.322\n",
      "[40, 180] loss: 0.316\n",
      "[40, 240] loss: 0.319\n",
      "[40, 300] loss: 0.313\n",
      "[40, 360] loss: 0.327\n",
      "Epoch: 40 -> Loss: 0.311906725168\n",
      "Epoch: 40 -> Test Accuracy: 86.2075\n",
      "[41, 60] loss: 0.312\n",
      "[41, 120] loss: 0.313\n",
      "[41, 180] loss: 0.315\n",
      "[41, 240] loss: 0.318\n",
      "[41, 300] loss: 0.324\n",
      "[41, 360] loss: 0.320\n",
      "Epoch: 41 -> Loss: 0.455862760544\n",
      "Epoch: 41 -> Test Accuracy: 85.7925\n",
      "[42, 60] loss: 0.320\n",
      "[42, 120] loss: 0.311\n",
      "[42, 180] loss: 0.319\n",
      "[42, 240] loss: 0.308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, 300] loss: 0.326\n",
      "[42, 360] loss: 0.311\n",
      "Epoch: 42 -> Loss: 0.202413871884\n",
      "Epoch: 42 -> Test Accuracy: 86.4575\n",
      "[43, 60] loss: 0.303\n",
      "[43, 120] loss: 0.312\n",
      "[43, 180] loss: 0.308\n",
      "[43, 240] loss: 0.320\n",
      "[43, 300] loss: 0.327\n",
      "[43, 360] loss: 0.316\n",
      "Epoch: 43 -> Loss: 0.38969796896\n",
      "Epoch: 43 -> Test Accuracy: 86.6225\n",
      "[44, 60] loss: 0.299\n",
      "[44, 120] loss: 0.314\n",
      "[44, 180] loss: 0.314\n",
      "[44, 240] loss: 0.318\n",
      "[44, 300] loss: 0.305\n",
      "[44, 360] loss: 0.313\n",
      "Epoch: 44 -> Loss: 0.24058906734\n",
      "Epoch: 44 -> Test Accuracy: 86.245\n",
      "[45, 60] loss: 0.301\n",
      "[45, 120] loss: 0.309\n",
      "[45, 180] loss: 0.306\n",
      "[45, 240] loss: 0.313\n",
      "[45, 300] loss: 0.322\n",
      "[45, 360] loss: 0.315\n",
      "Epoch: 45 -> Loss: 0.296419978142\n",
      "Epoch: 45 -> Test Accuracy: 86.9975\n",
      "[46, 60] loss: 0.295\n",
      "[46, 120] loss: 0.309\n",
      "[46, 180] loss: 0.327\n",
      "[46, 240] loss: 0.329\n",
      "[46, 300] loss: 0.302\n",
      "[46, 360] loss: 0.310\n",
      "Epoch: 46 -> Loss: 0.329180210829\n",
      "Epoch: 46 -> Test Accuracy: 86.6975\n",
      "[47, 60] loss: 0.301\n",
      "[47, 120] loss: 0.314\n",
      "[47, 180] loss: 0.310\n",
      "[47, 240] loss: 0.308\n",
      "[47, 300] loss: 0.317\n",
      "[47, 360] loss: 0.319\n",
      "Epoch: 47 -> Loss: 0.256463855505\n",
      "Epoch: 47 -> Test Accuracy: 86.515\n",
      "[48, 60] loss: 0.315\n",
      "[48, 120] loss: 0.312\n",
      "[48, 180] loss: 0.310\n",
      "[48, 240] loss: 0.311\n",
      "[48, 300] loss: 0.310\n",
      "[48, 360] loss: 0.318\n",
      "Epoch: 48 -> Loss: 0.377172231674\n",
      "Epoch: 48 -> Test Accuracy: 86.65\n",
      "[49, 60] loss: 0.306\n",
      "[49, 120] loss: 0.312\n",
      "[49, 180] loss: 0.314\n",
      "[49, 240] loss: 0.302\n",
      "[49, 300] loss: 0.313\n",
      "[49, 360] loss: 0.305\n",
      "Epoch: 49 -> Loss: 0.240230247378\n",
      "Epoch: 49 -> Test Accuracy: 86.275\n",
      "[50, 60] loss: 0.291\n",
      "[50, 120] loss: 0.307\n",
      "[50, 180] loss: 0.309\n",
      "[50, 240] loss: 0.318\n",
      "[50, 300] loss: 0.301\n",
      "[50, 360] loss: 0.326\n",
      "Epoch: 50 -> Loss: 0.526159405708\n",
      "Epoch: 50 -> Test Accuracy: 86.0925\n",
      "[51, 60] loss: 0.302\n",
      "[51, 120] loss: 0.310\n",
      "[51, 180] loss: 0.313\n",
      "[51, 240] loss: 0.308\n",
      "[51, 300] loss: 0.303\n",
      "[51, 360] loss: 0.308\n",
      "Epoch: 51 -> Loss: 0.253426998854\n",
      "Epoch: 51 -> Test Accuracy: 86.8975\n",
      "[52, 60] loss: 0.311\n",
      "[52, 120] loss: 0.301\n",
      "[52, 180] loss: 0.301\n",
      "[52, 240] loss: 0.319\n",
      "[52, 300] loss: 0.307\n",
      "[52, 360] loss: 0.322\n",
      "Epoch: 52 -> Loss: 0.3774343431\n",
      "Epoch: 52 -> Test Accuracy: 86.1625\n",
      "[53, 60] loss: 0.293\n",
      "[53, 120] loss: 0.308\n",
      "[53, 180] loss: 0.305\n",
      "[53, 240] loss: 0.315\n",
      "[53, 300] loss: 0.312\n",
      "[53, 360] loss: 0.310\n",
      "Epoch: 53 -> Loss: 0.408788919449\n",
      "Epoch: 53 -> Test Accuracy: 86.3125\n",
      "[54, 60] loss: 0.299\n",
      "[54, 120] loss: 0.304\n",
      "[54, 180] loss: 0.317\n",
      "[54, 240] loss: 0.306\n",
      "[54, 300] loss: 0.302\n",
      "[54, 360] loss: 0.330\n",
      "Epoch: 54 -> Loss: 0.276946365833\n",
      "Epoch: 54 -> Test Accuracy: 86.8375\n",
      "[55, 60] loss: 0.310\n",
      "[55, 120] loss: 0.302\n",
      "[55, 180] loss: 0.296\n",
      "[55, 240] loss: 0.299\n",
      "[55, 300] loss: 0.303\n",
      "[55, 360] loss: 0.311\n",
      "Epoch: 55 -> Loss: 0.408140271902\n",
      "Epoch: 55 -> Test Accuracy: 86.62\n",
      "[56, 60] loss: 0.296\n",
      "[56, 120] loss: 0.313\n",
      "[56, 180] loss: 0.303\n",
      "[56, 240] loss: 0.312\n",
      "[56, 300] loss: 0.301\n",
      "[56, 360] loss: 0.318\n",
      "Epoch: 56 -> Loss: 0.246590062976\n",
      "Epoch: 56 -> Test Accuracy: 86.1175\n",
      "[57, 60] loss: 0.294\n",
      "[57, 120] loss: 0.316\n",
      "[57, 180] loss: 0.302\n",
      "[57, 240] loss: 0.303\n",
      "[57, 300] loss: 0.301\n",
      "[57, 360] loss: 0.301\n",
      "Epoch: 57 -> Loss: 0.484372198582\n",
      "Epoch: 57 -> Test Accuracy: 85.905\n",
      "[58, 60] loss: 0.292\n",
      "[58, 120] loss: 0.298\n",
      "[58, 180] loss: 0.306\n",
      "[58, 240] loss: 0.304\n",
      "[58, 300] loss: 0.315\n",
      "[58, 360] loss: 0.325\n",
      "Epoch: 58 -> Loss: 0.267398267984\n",
      "Epoch: 58 -> Test Accuracy: 86.2375\n",
      "[59, 60] loss: 0.284\n",
      "[59, 120] loss: 0.309\n",
      "[59, 180] loss: 0.302\n",
      "[59, 240] loss: 0.306\n",
      "[59, 300] loss: 0.311\n",
      "[59, 360] loss: 0.305\n",
      "Epoch: 59 -> Loss: 0.263384789228\n",
      "Epoch: 59 -> Test Accuracy: 87.3225\n",
      "[60, 60] loss: 0.302\n",
      "[60, 120] loss: 0.318\n",
      "[60, 180] loss: 0.300\n",
      "[60, 240] loss: 0.297\n",
      "[60, 300] loss: 0.313\n",
      "[60, 360] loss: 0.306\n",
      "Epoch: 60 -> Loss: 0.405421555042\n",
      "Epoch: 60 -> Test Accuracy: 86.445\n",
      "[61, 60] loss: 0.234\n",
      "[61, 120] loss: 0.198\n",
      "[61, 180] loss: 0.189\n",
      "[61, 240] loss: 0.180\n",
      "[61, 300] loss: 0.199\n",
      "[61, 360] loss: 0.183\n",
      "Epoch: 61 -> Loss: 0.269334971905\n",
      "Epoch: 61 -> Test Accuracy: 90.815\n",
      "[62, 60] loss: 0.162\n",
      "[62, 120] loss: 0.168\n",
      "[62, 180] loss: 0.170\n",
      "[62, 240] loss: 0.168\n",
      "[62, 300] loss: 0.167\n",
      "[62, 360] loss: 0.184\n",
      "Epoch: 62 -> Loss: 0.151763692498\n",
      "Epoch: 62 -> Test Accuracy: 91.1125\n",
      "[63, 60] loss: 0.154\n",
      "[63, 120] loss: 0.157\n",
      "[63, 180] loss: 0.156\n",
      "[63, 240] loss: 0.172\n",
      "[63, 300] loss: 0.162\n",
      "[63, 360] loss: 0.159\n",
      "Epoch: 63 -> Loss: 0.115095891058\n",
      "Epoch: 63 -> Test Accuracy: 90.7425\n",
      "[64, 60] loss: 0.152\n",
      "[64, 120] loss: 0.155\n",
      "[64, 180] loss: 0.156\n",
      "[64, 240] loss: 0.156\n",
      "[64, 300] loss: 0.161\n",
      "[64, 360] loss: 0.154\n",
      "Epoch: 64 -> Loss: 0.188539505005\n",
      "Epoch: 64 -> Test Accuracy: 90.9775\n",
      "[65, 60] loss: 0.144\n",
      "[65, 120] loss: 0.154\n",
      "[65, 180] loss: 0.146\n",
      "[65, 240] loss: 0.141\n",
      "[65, 300] loss: 0.157\n",
      "[65, 360] loss: 0.162\n",
      "Epoch: 65 -> Loss: 0.125533401966\n",
      "Epoch: 65 -> Test Accuracy: 90.5925\n",
      "[66, 60] loss: 0.142\n",
      "[66, 120] loss: 0.149\n",
      "[66, 180] loss: 0.143\n",
      "[66, 240] loss: 0.158\n",
      "[66, 300] loss: 0.153\n",
      "[66, 360] loss: 0.158\n",
      "Epoch: 66 -> Loss: 0.0975689962506\n",
      "Epoch: 66 -> Test Accuracy: 90.375\n",
      "[67, 60] loss: 0.135\n",
      "[67, 120] loss: 0.143\n",
      "[67, 180] loss: 0.147\n",
      "[67, 240] loss: 0.158\n",
      "[67, 300] loss: 0.153\n",
      "[67, 360] loss: 0.147\n",
      "Epoch: 67 -> Loss: 0.227123767138\n",
      "Epoch: 67 -> Test Accuracy: 90.525\n",
      "[68, 60] loss: 0.139\n",
      "[68, 120] loss: 0.148\n",
      "[68, 180] loss: 0.149\n",
      "[68, 240] loss: 0.153\n",
      "[68, 300] loss: 0.154\n",
      "[68, 360] loss: 0.158\n",
      "Epoch: 68 -> Loss: 0.166642338037\n",
      "Epoch: 68 -> Test Accuracy: 90.6075\n",
      "[69, 60] loss: 0.140\n",
      "[69, 120] loss: 0.153\n",
      "[69, 180] loss: 0.144\n",
      "[69, 240] loss: 0.148\n",
      "[69, 300] loss: 0.146\n",
      "[69, 360] loss: 0.159\n",
      "Epoch: 69 -> Loss: 0.127617761493\n",
      "Epoch: 69 -> Test Accuracy: 90.01\n",
      "[70, 60] loss: 0.130\n",
      "[70, 120] loss: 0.138\n",
      "[70, 180] loss: 0.154\n",
      "[70, 240] loss: 0.156\n",
      "[70, 300] loss: 0.152\n",
      "[70, 360] loss: 0.164\n",
      "Epoch: 70 -> Loss: 0.192519873381\n",
      "Epoch: 70 -> Test Accuracy: 89.8975\n",
      "[71, 60] loss: 0.137\n",
      "[71, 120] loss: 0.145\n",
      "[71, 180] loss: 0.148\n",
      "[71, 240] loss: 0.150\n",
      "[71, 300] loss: 0.158\n",
      "[71, 360] loss: 0.149\n",
      "Epoch: 71 -> Loss: 0.181957289577\n",
      "Epoch: 71 -> Test Accuracy: 90.05\n",
      "[72, 60] loss: 0.147\n",
      "[72, 120] loss: 0.146\n",
      "[72, 180] loss: 0.148\n",
      "[72, 240] loss: 0.153\n",
      "[72, 300] loss: 0.146\n",
      "[72, 360] loss: 0.162\n",
      "Epoch: 72 -> Loss: 0.151845604181\n",
      "Epoch: 72 -> Test Accuracy: 90.1675\n",
      "[73, 60] loss: 0.141\n",
      "[73, 120] loss: 0.142\n",
      "[73, 180] loss: 0.145\n",
      "[73, 240] loss: 0.156\n",
      "[73, 300] loss: 0.146\n",
      "[73, 360] loss: 0.151\n",
      "Epoch: 73 -> Loss: 0.0884171649814\n",
      "Epoch: 73 -> Test Accuracy: 89.92\n",
      "[74, 60] loss: 0.132\n",
      "[74, 120] loss: 0.153\n",
      "[74, 180] loss: 0.150\n",
      "[74, 240] loss: 0.147\n",
      "[74, 300] loss: 0.156\n",
      "[74, 360] loss: 0.154\n",
      "Epoch: 74 -> Loss: 0.198935106397\n",
      "Epoch: 74 -> Test Accuracy: 90.1075\n",
      "[75, 60] loss: 0.135\n",
      "[75, 120] loss: 0.145\n",
      "[75, 180] loss: 0.146\n",
      "[75, 240] loss: 0.160\n",
      "[75, 300] loss: 0.154\n",
      "[75, 360] loss: 0.163\n",
      "Epoch: 75 -> Loss: 0.121698699892\n",
      "Epoch: 75 -> Test Accuracy: 90.0275\n",
      "[76, 60] loss: 0.143\n",
      "[76, 120] loss: 0.144\n",
      "[76, 180] loss: 0.145\n",
      "[76, 240] loss: 0.152\n",
      "[76, 300] loss: 0.159\n",
      "[76, 360] loss: 0.160\n",
      "Epoch: 76 -> Loss: 0.201559111476\n",
      "Epoch: 76 -> Test Accuracy: 89.92\n",
      "[77, 60] loss: 0.145\n",
      "[77, 120] loss: 0.151\n",
      "[77, 180] loss: 0.148\n",
      "[77, 240] loss: 0.151\n",
      "[77, 300] loss: 0.148\n",
      "[77, 360] loss: 0.154\n",
      "Epoch: 77 -> Loss: 0.0550473332405\n",
      "Epoch: 77 -> Test Accuracy: 89.98\n",
      "[78, 60] loss: 0.135\n",
      "[78, 120] loss: 0.146\n",
      "[78, 180] loss: 0.148\n",
      "[78, 240] loss: 0.153\n",
      "[78, 300] loss: 0.157\n",
      "[78, 360] loss: 0.149\n",
      "Epoch: 78 -> Loss: 0.150269240141\n",
      "Epoch: 78 -> Test Accuracy: 89.405\n",
      "[79, 60] loss: 0.150\n",
      "[79, 120] loss: 0.142\n",
      "[79, 180] loss: 0.146\n",
      "[79, 240] loss: 0.153\n",
      "[79, 300] loss: 0.148\n",
      "[79, 360] loss: 0.160\n",
      "Epoch: 79 -> Loss: 0.184640914202\n",
      "Epoch: 79 -> Test Accuracy: 89.6675\n",
      "[80, 60] loss: 0.145\n",
      "[80, 120] loss: 0.148\n",
      "[80, 180] loss: 0.149\n",
      "[80, 240] loss: 0.149\n",
      "[80, 300] loss: 0.154\n",
      "[80, 360] loss: 0.155\n",
      "Epoch: 80 -> Loss: 0.0886156708002\n",
      "Epoch: 80 -> Test Accuracy: 89.5725\n",
      "[81, 60] loss: 0.143\n",
      "[81, 120] loss: 0.138\n",
      "[81, 180] loss: 0.155\n",
      "[81, 240] loss: 0.147\n",
      "[81, 300] loss: 0.158\n",
      "[81, 360] loss: 0.160\n",
      "Epoch: 81 -> Loss: 0.107396677136\n",
      "Epoch: 81 -> Test Accuracy: 90.1075\n",
      "[82, 60] loss: 0.142\n",
      "[82, 120] loss: 0.145\n",
      "[82, 180] loss: 0.151\n",
      "[82, 240] loss: 0.153\n",
      "[82, 300] loss: 0.145\n",
      "[82, 360] loss: 0.153\n",
      "Epoch: 82 -> Loss: 0.146289512515\n",
      "Epoch: 82 -> Test Accuracy: 89.905\n",
      "[83, 60] loss: 0.137\n",
      "[83, 120] loss: 0.142\n",
      "[83, 180] loss: 0.143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83, 240] loss: 0.155\n",
      "[83, 300] loss: 0.159\n",
      "[83, 360] loss: 0.149\n",
      "Epoch: 83 -> Loss: 0.133886381984\n",
      "Epoch: 83 -> Test Accuracy: 90.1575\n",
      "[84, 60] loss: 0.129\n",
      "[84, 120] loss: 0.146\n",
      "[84, 180] loss: 0.148\n",
      "[84, 240] loss: 0.151\n",
      "[84, 300] loss: 0.156\n",
      "[84, 360] loss: 0.160\n",
      "Epoch: 84 -> Loss: 0.134064465761\n",
      "Epoch: 84 -> Test Accuracy: 89.715\n",
      "[85, 60] loss: 0.141\n",
      "[85, 120] loss: 0.146\n",
      "[85, 180] loss: 0.140\n",
      "[85, 240] loss: 0.145\n",
      "[85, 300] loss: 0.151\n",
      "[85, 360] loss: 0.156\n",
      "Epoch: 85 -> Loss: 0.112060904503\n",
      "Epoch: 85 -> Test Accuracy: 89.6125\n",
      "[86, 60] loss: 0.133\n",
      "[86, 120] loss: 0.148\n",
      "[86, 180] loss: 0.149\n",
      "[86, 240] loss: 0.147\n",
      "[86, 300] loss: 0.150\n",
      "[86, 360] loss: 0.153\n",
      "Epoch: 86 -> Loss: 0.161302492023\n",
      "Epoch: 86 -> Test Accuracy: 90.4925\n",
      "[87, 60] loss: 0.142\n",
      "[87, 120] loss: 0.143\n",
      "[87, 180] loss: 0.141\n",
      "[87, 240] loss: 0.153\n",
      "[87, 300] loss: 0.149\n",
      "[87, 360] loss: 0.148\n",
      "Epoch: 87 -> Loss: 0.139245599508\n",
      "Epoch: 87 -> Test Accuracy: 89.745\n",
      "[88, 60] loss: 0.138\n",
      "[88, 120] loss: 0.139\n",
      "[88, 180] loss: 0.159\n",
      "[88, 240] loss: 0.155\n",
      "[88, 300] loss: 0.138\n",
      "[88, 360] loss: 0.151\n",
      "Epoch: 88 -> Loss: 0.138681665063\n",
      "Epoch: 88 -> Test Accuracy: 89.555\n",
      "[89, 60] loss: 0.129\n",
      "[89, 120] loss: 0.141\n",
      "[89, 180] loss: 0.143\n",
      "[89, 240] loss: 0.147\n",
      "[89, 300] loss: 0.149\n",
      "[89, 360] loss: 0.150\n",
      "Epoch: 89 -> Loss: 0.158570468426\n",
      "Epoch: 89 -> Test Accuracy: 89.9075\n",
      "[90, 60] loss: 0.139\n",
      "[90, 120] loss: 0.134\n",
      "[90, 180] loss: 0.152\n",
      "[90, 240] loss: 0.144\n",
      "[90, 300] loss: 0.150\n",
      "[90, 360] loss: 0.151\n",
      "Epoch: 90 -> Loss: 0.148902788758\n",
      "Epoch: 90 -> Test Accuracy: 90.1975\n",
      "[91, 60] loss: 0.133\n",
      "[91, 120] loss: 0.141\n",
      "[91, 180] loss: 0.144\n",
      "[91, 240] loss: 0.142\n",
      "[91, 300] loss: 0.144\n",
      "[91, 360] loss: 0.152\n",
      "Epoch: 91 -> Loss: 0.134662672877\n",
      "Epoch: 91 -> Test Accuracy: 90.0325\n",
      "[92, 60] loss: 0.133\n",
      "[92, 120] loss: 0.135\n",
      "[92, 180] loss: 0.156\n",
      "[92, 240] loss: 0.141\n",
      "[92, 300] loss: 0.145\n",
      "[92, 360] loss: 0.160\n",
      "Epoch: 92 -> Loss: 0.110449299216\n",
      "Epoch: 92 -> Test Accuracy: 89.805\n",
      "[93, 60] loss: 0.137\n",
      "[93, 120] loss: 0.138\n",
      "[93, 180] loss: 0.144\n",
      "[93, 240] loss: 0.145\n",
      "[93, 300] loss: 0.150\n",
      "[93, 360] loss: 0.144\n",
      "Epoch: 93 -> Loss: 0.139570310712\n",
      "Epoch: 93 -> Test Accuracy: 90.0625\n",
      "[94, 60] loss: 0.138\n",
      "[94, 120] loss: 0.133\n",
      "[94, 180] loss: 0.135\n",
      "[94, 240] loss: 0.147\n",
      "[94, 300] loss: 0.144\n",
      "[94, 360] loss: 0.156\n",
      "Epoch: 94 -> Loss: 0.106828942895\n",
      "Epoch: 94 -> Test Accuracy: 89.755\n",
      "[95, 60] loss: 0.138\n",
      "[95, 120] loss: 0.135\n",
      "[95, 180] loss: 0.145\n",
      "[95, 240] loss: 0.150\n",
      "[95, 300] loss: 0.141\n",
      "[95, 360] loss: 0.147\n",
      "Epoch: 95 -> Loss: 0.15689766407\n",
      "Epoch: 95 -> Test Accuracy: 89.9975\n",
      "[96, 60] loss: 0.132\n",
      "[96, 120] loss: 0.139\n",
      "[96, 180] loss: 0.142\n",
      "[96, 240] loss: 0.151\n",
      "[96, 300] loss: 0.153\n",
      "[96, 360] loss: 0.139\n",
      "Epoch: 96 -> Loss: 0.0980915501714\n",
      "Epoch: 96 -> Test Accuracy: 89.5775\n",
      "[97, 60] loss: 0.133\n",
      "[97, 120] loss: 0.136\n",
      "[97, 180] loss: 0.138\n",
      "[97, 240] loss: 0.151\n",
      "[97, 300] loss: 0.138\n",
      "[97, 360] loss: 0.152\n",
      "Epoch: 97 -> Loss: 0.134076282382\n",
      "Epoch: 97 -> Test Accuracy: 90.3\n",
      "[98, 60] loss: 0.132\n",
      "[98, 120] loss: 0.140\n",
      "[98, 180] loss: 0.140\n",
      "[98, 240] loss: 0.143\n",
      "[98, 300] loss: 0.148\n",
      "[98, 360] loss: 0.151\n",
      "Epoch: 98 -> Loss: 0.186950236559\n",
      "Epoch: 98 -> Test Accuracy: 90.2425\n",
      "[99, 60] loss: 0.133\n",
      "[99, 120] loss: 0.136\n",
      "[99, 180] loss: 0.146\n",
      "[99, 240] loss: 0.134\n",
      "[99, 300] loss: 0.141\n",
      "[99, 360] loss: 0.154\n",
      "Epoch: 99 -> Loss: 0.258063197136\n",
      "Epoch: 99 -> Test Accuracy: 89.7225\n",
      "[100, 60] loss: 0.132\n",
      "[100, 120] loss: 0.136\n",
      "[100, 180] loss: 0.149\n",
      "[100, 240] loss: 0.142\n",
      "[100, 300] loss: 0.143\n",
      "[100, 360] loss: 0.145\n",
      "Epoch: 100 -> Loss: 0.119396291673\n",
      "Epoch: 100 -> Test Accuracy: 89.2125\n",
      "[101, 60] loss: 0.134\n",
      "[101, 120] loss: 0.130\n",
      "[101, 180] loss: 0.141\n",
      "[101, 240] loss: 0.143\n",
      "[101, 300] loss: 0.143\n",
      "[101, 360] loss: 0.142\n",
      "Epoch: 101 -> Loss: 0.154390692711\n",
      "Epoch: 101 -> Test Accuracy: 89.83\n",
      "[102, 60] loss: 0.124\n",
      "[102, 120] loss: 0.140\n",
      "[102, 180] loss: 0.133\n",
      "[102, 240] loss: 0.143\n",
      "[102, 300] loss: 0.139\n",
      "[102, 360] loss: 0.146\n",
      "Epoch: 102 -> Loss: 0.0957317203283\n",
      "Epoch: 102 -> Test Accuracy: 89.97\n",
      "[103, 60] loss: 0.125\n",
      "[103, 120] loss: 0.133\n",
      "[103, 180] loss: 0.139\n",
      "[103, 240] loss: 0.137\n",
      "[103, 300] loss: 0.147\n",
      "[103, 360] loss: 0.146\n",
      "Epoch: 103 -> Loss: 0.14086151123\n",
      "Epoch: 103 -> Test Accuracy: 89.6825\n",
      "[104, 60] loss: 0.134\n",
      "[104, 120] loss: 0.134\n",
      "[104, 180] loss: 0.136\n",
      "[104, 240] loss: 0.134\n",
      "[104, 300] loss: 0.143\n",
      "[104, 360] loss: 0.151\n",
      "Epoch: 104 -> Loss: 0.121187232435\n",
      "Epoch: 104 -> Test Accuracy: 89.9575\n",
      "[105, 60] loss: 0.132\n",
      "[105, 120] loss: 0.130\n",
      "[105, 180] loss: 0.139\n",
      "[105, 240] loss: 0.143\n",
      "[105, 300] loss: 0.146\n",
      "[105, 360] loss: 0.145\n",
      "Epoch: 105 -> Loss: 0.12362767756\n",
      "Epoch: 105 -> Test Accuracy: 90.38\n",
      "[106, 60] loss: 0.132\n",
      "[106, 120] loss: 0.137\n",
      "[106, 180] loss: 0.141\n",
      "[106, 240] loss: 0.134\n",
      "[106, 300] loss: 0.132\n",
      "[106, 360] loss: 0.141\n",
      "Epoch: 106 -> Loss: 0.156450837851\n",
      "Epoch: 106 -> Test Accuracy: 90.3625\n",
      "[107, 60] loss: 0.129\n",
      "[107, 120] loss: 0.144\n",
      "[107, 180] loss: 0.143\n",
      "[107, 240] loss: 0.144\n",
      "[107, 300] loss: 0.135\n",
      "[107, 360] loss: 0.144\n",
      "Epoch: 107 -> Loss: 0.208046510816\n",
      "Epoch: 107 -> Test Accuracy: 90.405\n",
      "[108, 60] loss: 0.130\n",
      "[108, 120] loss: 0.131\n",
      "[108, 180] loss: 0.138\n",
      "[108, 240] loss: 0.141\n",
      "[108, 300] loss: 0.147\n",
      "[108, 360] loss: 0.142\n",
      "Epoch: 108 -> Loss: 0.144947558641\n",
      "Epoch: 108 -> Test Accuracy: 90.0775\n",
      "[109, 60] loss: 0.130\n",
      "[109, 120] loss: 0.123\n",
      "[109, 180] loss: 0.134\n",
      "[109, 240] loss: 0.145\n",
      "[109, 300] loss: 0.145\n",
      "[109, 360] loss: 0.144\n",
      "Epoch: 109 -> Loss: 0.160101026297\n",
      "Epoch: 109 -> Test Accuracy: 90.155\n",
      "[110, 60] loss: 0.122\n",
      "[110, 120] loss: 0.134\n",
      "[110, 180] loss: 0.136\n",
      "[110, 240] loss: 0.143\n",
      "[110, 300] loss: 0.137\n",
      "[110, 360] loss: 0.131\n",
      "Epoch: 110 -> Loss: 0.113789439201\n",
      "Epoch: 110 -> Test Accuracy: 89.2725\n",
      "[111, 60] loss: 0.127\n",
      "[111, 120] loss: 0.133\n",
      "[111, 180] loss: 0.139\n",
      "[111, 240] loss: 0.140\n",
      "[111, 300] loss: 0.139\n",
      "[111, 360] loss: 0.138\n",
      "Epoch: 111 -> Loss: 0.19155305624\n",
      "Epoch: 111 -> Test Accuracy: 89.6975\n",
      "[112, 60] loss: 0.127\n",
      "[112, 120] loss: 0.124\n",
      "[112, 180] loss: 0.134\n",
      "[112, 240] loss: 0.137\n",
      "[112, 300] loss: 0.141\n",
      "[112, 360] loss: 0.137\n",
      "Epoch: 112 -> Loss: 0.132862269878\n",
      "Epoch: 112 -> Test Accuracy: 90.025\n",
      "[113, 60] loss: 0.137\n",
      "[113, 120] loss: 0.130\n",
      "[113, 180] loss: 0.134\n",
      "[113, 240] loss: 0.129\n",
      "[113, 300] loss: 0.141\n",
      "[113, 360] loss: 0.147\n",
      "Epoch: 113 -> Loss: 0.175592765212\n",
      "Epoch: 113 -> Test Accuracy: 89.9475\n",
      "[114, 60] loss: 0.127\n",
      "[114, 120] loss: 0.129\n",
      "[114, 180] loss: 0.121\n",
      "[114, 240] loss: 0.143\n",
      "[114, 300] loss: 0.138\n",
      "[114, 360] loss: 0.145\n",
      "Epoch: 114 -> Loss: 0.106483839452\n",
      "Epoch: 114 -> Test Accuracy: 89.8825\n",
      "[115, 60] loss: 0.124\n",
      "[115, 120] loss: 0.126\n",
      "[115, 180] loss: 0.134\n",
      "[115, 240] loss: 0.133\n",
      "[115, 300] loss: 0.151\n",
      "[115, 360] loss: 0.133\n",
      "Epoch: 115 -> Loss: 0.19576767087\n",
      "Epoch: 115 -> Test Accuracy: 90.325\n",
      "[116, 60] loss: 0.134\n",
      "[116, 120] loss: 0.125\n",
      "[116, 180] loss: 0.128\n",
      "[116, 240] loss: 0.141\n",
      "[116, 300] loss: 0.143\n",
      "[116, 360] loss: 0.144\n",
      "Epoch: 116 -> Loss: 0.0712580010295\n",
      "Epoch: 116 -> Test Accuracy: 90.2175\n",
      "[117, 60] loss: 0.125\n",
      "[117, 120] loss: 0.131\n",
      "[117, 180] loss: 0.136\n",
      "[117, 240] loss: 0.142\n",
      "[117, 300] loss: 0.133\n",
      "[117, 360] loss: 0.132\n",
      "Epoch: 117 -> Loss: 0.133187353611\n",
      "Epoch: 117 -> Test Accuracy: 90.115\n",
      "[118, 60] loss: 0.124\n",
      "[118, 120] loss: 0.129\n",
      "[118, 180] loss: 0.139\n",
      "[118, 240] loss: 0.132\n",
      "[118, 300] loss: 0.139\n",
      "[118, 360] loss: 0.145\n",
      "Epoch: 118 -> Loss: 0.15876236558\n",
      "Epoch: 118 -> Test Accuracy: 89.8475\n",
      "[119, 60] loss: 0.121\n",
      "[119, 120] loss: 0.139\n",
      "[119, 180] loss: 0.125\n",
      "[119, 240] loss: 0.130\n",
      "[119, 300] loss: 0.138\n",
      "[119, 360] loss: 0.135\n",
      "Epoch: 119 -> Loss: 0.120277479291\n",
      "Epoch: 119 -> Test Accuracy: 90.0175\n",
      "[120, 60] loss: 0.127\n",
      "[120, 120] loss: 0.129\n",
      "[120, 180] loss: 0.131\n",
      "[120, 240] loss: 0.132\n",
      "[120, 300] loss: 0.138\n",
      "[120, 360] loss: 0.143\n",
      "Epoch: 120 -> Loss: 0.0898219570518\n",
      "Epoch: 120 -> Test Accuracy: 90.8225\n",
      "[121, 60] loss: 0.097\n",
      "[121, 120] loss: 0.075\n",
      "[121, 180] loss: 0.079\n",
      "[121, 240] loss: 0.072\n",
      "[121, 300] loss: 0.069\n",
      "[121, 360] loss: 0.064\n",
      "Epoch: 121 -> Loss: 0.137890338898\n",
      "Epoch: 121 -> Test Accuracy: 91.965\n",
      "[122, 60] loss: 0.057\n",
      "[122, 120] loss: 0.050\n",
      "[122, 180] loss: 0.055\n",
      "[122, 240] loss: 0.056\n",
      "[122, 300] loss: 0.059\n",
      "[122, 360] loss: 0.054\n",
      "Epoch: 122 -> Loss: 0.0699537247419\n",
      "Epoch: 122 -> Test Accuracy: 92.095\n",
      "[123, 60] loss: 0.047\n",
      "[123, 120] loss: 0.050\n",
      "[123, 180] loss: 0.049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123, 240] loss: 0.048\n",
      "[123, 300] loss: 0.052\n",
      "[123, 360] loss: 0.051\n",
      "Epoch: 123 -> Loss: 0.0242857132107\n",
      "Epoch: 123 -> Test Accuracy: 91.915\n",
      "[124, 60] loss: 0.046\n",
      "[124, 120] loss: 0.040\n",
      "[124, 180] loss: 0.042\n",
      "[124, 240] loss: 0.044\n",
      "[124, 300] loss: 0.046\n",
      "[124, 360] loss: 0.049\n",
      "Epoch: 124 -> Loss: 0.0347153320909\n",
      "Epoch: 124 -> Test Accuracy: 92.225\n",
      "[125, 60] loss: 0.040\n",
      "[125, 120] loss: 0.038\n",
      "[125, 180] loss: 0.040\n",
      "[125, 240] loss: 0.042\n",
      "[125, 300] loss: 0.042\n",
      "[125, 360] loss: 0.042\n",
      "Epoch: 125 -> Loss: 0.0650164335966\n",
      "Epoch: 125 -> Test Accuracy: 91.995\n",
      "[126, 60] loss: 0.040\n",
      "[126, 120] loss: 0.039\n",
      "[126, 180] loss: 0.040\n",
      "[126, 240] loss: 0.037\n",
      "[126, 300] loss: 0.041\n",
      "[126, 360] loss: 0.041\n",
      "Epoch: 126 -> Loss: 0.0732892155647\n",
      "Epoch: 126 -> Test Accuracy: 91.9675\n",
      "[127, 60] loss: 0.038\n",
      "[127, 120] loss: 0.039\n",
      "[127, 180] loss: 0.039\n",
      "[127, 240] loss: 0.036\n",
      "[127, 300] loss: 0.037\n",
      "[127, 360] loss: 0.037\n",
      "Epoch: 127 -> Loss: 0.016385499388\n",
      "Epoch: 127 -> Test Accuracy: 91.865\n",
      "[128, 60] loss: 0.032\n",
      "[128, 120] loss: 0.035\n",
      "[128, 180] loss: 0.036\n",
      "[128, 240] loss: 0.041\n",
      "[128, 300] loss: 0.031\n",
      "[128, 360] loss: 0.038\n",
      "Epoch: 128 -> Loss: 0.0109456349164\n",
      "Epoch: 128 -> Test Accuracy: 91.8875\n",
      "[129, 60] loss: 0.032\n",
      "[129, 120] loss: 0.033\n",
      "[129, 180] loss: 0.032\n",
      "[129, 240] loss: 0.033\n",
      "[129, 300] loss: 0.039\n",
      "[129, 360] loss: 0.035\n",
      "Epoch: 129 -> Loss: 0.0138136940077\n",
      "Epoch: 129 -> Test Accuracy: 91.7825\n",
      "[130, 60] loss: 0.031\n",
      "[130, 120] loss: 0.037\n",
      "[130, 180] loss: 0.033\n",
      "[130, 240] loss: 0.032\n",
      "[130, 300] loss: 0.030\n",
      "[130, 360] loss: 0.038\n",
      "Epoch: 130 -> Loss: 0.03566005826\n",
      "Epoch: 130 -> Test Accuracy: 91.89\n",
      "[131, 60] loss: 0.031\n",
      "[131, 120] loss: 0.029\n",
      "[131, 180] loss: 0.033\n",
      "[131, 240] loss: 0.032\n",
      "[131, 300] loss: 0.032\n",
      "[131, 360] loss: 0.035\n",
      "Epoch: 131 -> Loss: 0.0390828475356\n",
      "Epoch: 131 -> Test Accuracy: 91.745\n",
      "[132, 60] loss: 0.029\n",
      "[132, 120] loss: 0.032\n",
      "[132, 180] loss: 0.030\n",
      "[132, 240] loss: 0.031\n",
      "[132, 300] loss: 0.032\n",
      "[132, 360] loss: 0.038\n",
      "Epoch: 132 -> Loss: 0.0180100388825\n",
      "Epoch: 132 -> Test Accuracy: 91.675\n",
      "[133, 60] loss: 0.028\n",
      "[133, 120] loss: 0.032\n",
      "[133, 180] loss: 0.034\n",
      "[133, 240] loss: 0.031\n",
      "[133, 300] loss: 0.033\n",
      "[133, 360] loss: 0.032\n",
      "Epoch: 133 -> Loss: 0.0118077909574\n",
      "Epoch: 133 -> Test Accuracy: 91.6975\n",
      "[134, 60] loss: 0.026\n",
      "[134, 120] loss: 0.030\n",
      "[134, 180] loss: 0.030\n",
      "[134, 240] loss: 0.030\n",
      "[134, 300] loss: 0.033\n",
      "[134, 360] loss: 0.032\n",
      "Epoch: 134 -> Loss: 0.0555007942021\n",
      "Epoch: 134 -> Test Accuracy: 91.8875\n",
      "[135, 60] loss: 0.027\n",
      "[135, 120] loss: 0.029\n",
      "[135, 180] loss: 0.027\n",
      "[135, 240] loss: 0.028\n",
      "[135, 300] loss: 0.032\n",
      "[135, 360] loss: 0.032\n",
      "Epoch: 135 -> Loss: 0.0338557437062\n",
      "Epoch: 135 -> Test Accuracy: 91.4825\n",
      "[136, 60] loss: 0.029\n",
      "[136, 120] loss: 0.030\n",
      "[136, 180] loss: 0.028\n",
      "[136, 240] loss: 0.030\n",
      "[136, 300] loss: 0.029\n",
      "[136, 360] loss: 0.025\n",
      "Epoch: 136 -> Loss: 0.0350014865398\n",
      "Epoch: 136 -> Test Accuracy: 91.6075\n",
      "[137, 60] loss: 0.033\n",
      "[137, 120] loss: 0.027\n",
      "[137, 180] loss: 0.027\n",
      "[137, 240] loss: 0.030\n",
      "[137, 300] loss: 0.030\n",
      "[137, 360] loss: 0.031\n",
      "Epoch: 137 -> Loss: 0.0486399829388\n",
      "Epoch: 137 -> Test Accuracy: 91.33\n",
      "[138, 60] loss: 0.029\n",
      "[138, 120] loss: 0.028\n",
      "[138, 180] loss: 0.027\n",
      "[138, 240] loss: 0.028\n",
      "[138, 300] loss: 0.029\n",
      "[138, 360] loss: 0.031\n",
      "Epoch: 138 -> Loss: 0.0349916443229\n",
      "Epoch: 138 -> Test Accuracy: 91.4875\n",
      "[139, 60] loss: 0.031\n",
      "[139, 120] loss: 0.029\n",
      "[139, 180] loss: 0.030\n",
      "[139, 240] loss: 0.033\n",
      "[139, 300] loss: 0.034\n",
      "[139, 360] loss: 0.033\n",
      "Epoch: 139 -> Loss: 0.0244318507612\n",
      "Epoch: 139 -> Test Accuracy: 91.4525\n",
      "[140, 60] loss: 0.028\n",
      "[140, 120] loss: 0.027\n",
      "[140, 180] loss: 0.029\n",
      "[140, 240] loss: 0.028\n",
      "[140, 300] loss: 0.030\n",
      "[140, 360] loss: 0.032\n",
      "Epoch: 140 -> Loss: 0.0124510182068\n",
      "Epoch: 140 -> Test Accuracy: 91.63\n",
      "[141, 60] loss: 0.028\n",
      "[141, 120] loss: 0.026\n",
      "[141, 180] loss: 0.026\n",
      "[141, 240] loss: 0.028\n",
      "[141, 300] loss: 0.031\n",
      "[141, 360] loss: 0.035\n",
      "Epoch: 141 -> Loss: 0.00667686620727\n",
      "Epoch: 141 -> Test Accuracy: 91.445\n",
      "[142, 60] loss: 0.025\n",
      "[142, 120] loss: 0.027\n",
      "[142, 180] loss: 0.025\n",
      "[142, 240] loss: 0.029\n",
      "[142, 300] loss: 0.031\n",
      "[142, 360] loss: 0.032\n",
      "Epoch: 142 -> Loss: 0.00895163975656\n",
      "Epoch: 142 -> Test Accuracy: 91.1975\n",
      "[143, 60] loss: 0.029\n",
      "[143, 120] loss: 0.028\n",
      "[143, 180] loss: 0.027\n",
      "[143, 240] loss: 0.031\n",
      "[143, 300] loss: 0.028\n",
      "[143, 360] loss: 0.031\n",
      "Epoch: 143 -> Loss: 0.0238042995334\n",
      "Epoch: 143 -> Test Accuracy: 91.4925\n",
      "[144, 60] loss: 0.028\n",
      "[144, 120] loss: 0.028\n",
      "[144, 180] loss: 0.028\n",
      "[144, 240] loss: 0.030\n",
      "[144, 300] loss: 0.030\n",
      "[144, 360] loss: 0.030\n",
      "Epoch: 144 -> Loss: 0.0261526163667\n",
      "Epoch: 144 -> Test Accuracy: 91.4575\n",
      "[145, 60] loss: 0.028\n",
      "[145, 120] loss: 0.027\n",
      "[145, 180] loss: 0.031\n",
      "[145, 240] loss: 0.030\n",
      "[145, 300] loss: 0.027\n",
      "[145, 360] loss: 0.029\n",
      "Epoch: 145 -> Loss: 0.024902138859\n",
      "Epoch: 145 -> Test Accuracy: 91.755\n",
      "[146, 60] loss: 0.027\n",
      "[146, 120] loss: 0.027\n",
      "[146, 180] loss: 0.027\n",
      "[146, 240] loss: 0.027\n",
      "[146, 300] loss: 0.029\n",
      "[146, 360] loss: 0.031\n",
      "Epoch: 146 -> Loss: 0.0543857738376\n",
      "Epoch: 146 -> Test Accuracy: 91.4025\n",
      "[147, 60] loss: 0.029\n",
      "[147, 120] loss: 0.028\n",
      "[147, 180] loss: 0.029\n",
      "[147, 240] loss: 0.029\n",
      "[147, 300] loss: 0.029\n",
      "[147, 360] loss: 0.030\n",
      "Epoch: 147 -> Loss: 0.0182418562472\n",
      "Epoch: 147 -> Test Accuracy: 91.3775\n",
      "[148, 60] loss: 0.028\n",
      "[148, 120] loss: 0.029\n",
      "[148, 180] loss: 0.030\n",
      "[148, 240] loss: 0.028\n",
      "[148, 300] loss: 0.029\n",
      "[148, 360] loss: 0.030\n",
      "Epoch: 148 -> Loss: 0.0240513570607\n",
      "Epoch: 148 -> Test Accuracy: 91.48\n",
      "[149, 60] loss: 0.027\n",
      "[149, 120] loss: 0.029\n",
      "[149, 180] loss: 0.031\n",
      "[149, 240] loss: 0.028\n",
      "[149, 300] loss: 0.029\n",
      "[149, 360] loss: 0.032\n",
      "Epoch: 149 -> Loss: 0.0344547815621\n",
      "Epoch: 149 -> Test Accuracy: 91.485\n",
      "[150, 60] loss: 0.028\n",
      "[150, 120] loss: 0.028\n",
      "[150, 180] loss: 0.027\n",
      "[150, 240] loss: 0.030\n",
      "[150, 300] loss: 0.028\n",
      "[150, 360] loss: 0.031\n",
      "Epoch: 150 -> Loss: 0.0225305464119\n",
      "Epoch: 150 -> Test Accuracy: 91.56\n",
      "[151, 60] loss: 0.026\n",
      "[151, 120] loss: 0.026\n",
      "[151, 180] loss: 0.030\n",
      "[151, 240] loss: 0.030\n",
      "[151, 300] loss: 0.030\n",
      "[151, 360] loss: 0.033\n",
      "Epoch: 151 -> Loss: 0.0140234604478\n",
      "Epoch: 151 -> Test Accuracy: 91.505\n",
      "[152, 60] loss: 0.023\n",
      "[152, 120] loss: 0.024\n",
      "[152, 180] loss: 0.029\n",
      "[152, 240] loss: 0.030\n",
      "[152, 300] loss: 0.030\n",
      "[152, 360] loss: 0.030\n",
      "Epoch: 152 -> Loss: 0.055515229702\n",
      "Epoch: 152 -> Test Accuracy: 91.5575\n",
      "[153, 60] loss: 0.031\n",
      "[153, 120] loss: 0.027\n",
      "[153, 180] loss: 0.031\n",
      "[153, 240] loss: 0.030\n",
      "[153, 300] loss: 0.031\n",
      "[153, 360] loss: 0.032\n",
      "Epoch: 153 -> Loss: 0.0273314658552\n",
      "Epoch: 153 -> Test Accuracy: 91.655\n",
      "[154, 60] loss: 0.028\n",
      "[154, 120] loss: 0.029\n",
      "[154, 180] loss: 0.029\n",
      "[154, 240] loss: 0.030\n",
      "[154, 300] loss: 0.032\n",
      "[154, 360] loss: 0.033\n",
      "Epoch: 154 -> Loss: 0.0313385315239\n",
      "Epoch: 154 -> Test Accuracy: 91.4175\n",
      "[155, 60] loss: 0.031\n",
      "[155, 120] loss: 0.031\n",
      "[155, 180] loss: 0.029\n",
      "[155, 240] loss: 0.030\n",
      "[155, 300] loss: 0.032\n",
      "[155, 360] loss: 0.029\n",
      "Epoch: 155 -> Loss: 0.00862885452807\n",
      "Epoch: 155 -> Test Accuracy: 91.625\n",
      "[156, 60] loss: 0.028\n",
      "[156, 120] loss: 0.026\n",
      "[156, 180] loss: 0.030\n",
      "[156, 240] loss: 0.034\n",
      "[156, 300] loss: 0.031\n",
      "[156, 360] loss: 0.032\n",
      "Epoch: 156 -> Loss: 0.041626188904\n",
      "Epoch: 156 -> Test Accuracy: 91.4075\n",
      "[157, 60] loss: 0.025\n",
      "[157, 120] loss: 0.028\n",
      "[157, 180] loss: 0.025\n",
      "[157, 240] loss: 0.030\n",
      "[157, 300] loss: 0.032\n",
      "[157, 360] loss: 0.035\n",
      "Epoch: 157 -> Loss: 0.0414715781808\n",
      "Epoch: 157 -> Test Accuracy: 91.3925\n",
      "[158, 60] loss: 0.028\n",
      "[158, 120] loss: 0.027\n",
      "[158, 180] loss: 0.029\n",
      "[158, 240] loss: 0.034\n",
      "[158, 300] loss: 0.032\n",
      "[158, 360] loss: 0.032\n",
      "Epoch: 158 -> Loss: 0.0340915843844\n",
      "Epoch: 158 -> Test Accuracy: 91.225\n",
      "[159, 60] loss: 0.030\n",
      "[159, 120] loss: 0.028\n",
      "[159, 180] loss: 0.030\n",
      "[159, 240] loss: 0.031\n",
      "[159, 300] loss: 0.030\n",
      "[159, 360] loss: 0.033\n",
      "Epoch: 159 -> Loss: 0.0253469347954\n",
      "Epoch: 159 -> Test Accuracy: 91.2075\n",
      "[160, 60] loss: 0.032\n",
      "[160, 120] loss: 0.029\n",
      "[160, 180] loss: 0.026\n",
      "[160, 240] loss: 0.031\n",
      "[160, 300] loss: 0.028\n",
      "[160, 360] loss: 0.031\n",
      "Epoch: 160 -> Loss: 0.0207560416311\n",
      "Epoch: 160 -> Test Accuracy: 91.26\n",
      "[161, 60] loss: 0.021\n",
      "[161, 120] loss: 0.018\n",
      "[161, 180] loss: 0.016\n",
      "[161, 240] loss: 0.014\n",
      "[161, 300] loss: 0.016\n",
      "[161, 360] loss: 0.014\n",
      "Epoch: 161 -> Loss: 0.0250822007656\n",
      "Epoch: 161 -> Test Accuracy: 91.93\n",
      "[162, 60] loss: 0.013\n",
      "[162, 120] loss: 0.014\n",
      "[162, 180] loss: 0.013\n",
      "[162, 240] loss: 0.012\n",
      "[162, 300] loss: 0.013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[162, 360] loss: 0.013\n",
      "Epoch: 162 -> Loss: 0.00761998165399\n",
      "Epoch: 162 -> Test Accuracy: 91.89\n",
      "[163, 60] loss: 0.013\n",
      "[163, 120] loss: 0.011\n",
      "[163, 180] loss: 0.011\n",
      "[163, 240] loss: 0.011\n",
      "[163, 300] loss: 0.011\n",
      "[163, 360] loss: 0.011\n",
      "Epoch: 163 -> Loss: 0.0119529506192\n",
      "Epoch: 163 -> Test Accuracy: 91.945\n",
      "[164, 60] loss: 0.010\n",
      "[164, 120] loss: 0.009\n",
      "[164, 180] loss: 0.011\n",
      "[164, 240] loss: 0.009\n",
      "[164, 300] loss: 0.011\n",
      "[164, 360] loss: 0.011\n",
      "Epoch: 164 -> Loss: 0.00904276128858\n",
      "Epoch: 164 -> Test Accuracy: 91.955\n",
      "[165, 60] loss: 0.010\n",
      "[165, 120] loss: 0.009\n",
      "[165, 180] loss: 0.009\n",
      "[165, 240] loss: 0.010\n",
      "[165, 300] loss: 0.009\n",
      "[165, 360] loss: 0.010\n",
      "Epoch: 165 -> Loss: 0.0153510095552\n",
      "Epoch: 165 -> Test Accuracy: 91.985\n",
      "[166, 60] loss: 0.009\n",
      "[166, 120] loss: 0.010\n",
      "[166, 180] loss: 0.009\n",
      "[166, 240] loss: 0.009\n",
      "[166, 300] loss: 0.008\n",
      "[166, 360] loss: 0.009\n",
      "Epoch: 166 -> Loss: 0.00571954529732\n",
      "Epoch: 166 -> Test Accuracy: 91.94\n",
      "[167, 60] loss: 0.009\n",
      "[167, 120] loss: 0.007\n",
      "[167, 180] loss: 0.009\n",
      "[167, 240] loss: 0.009\n",
      "[167, 300] loss: 0.009\n",
      "[167, 360] loss: 0.009\n",
      "Epoch: 167 -> Loss: 0.0145969940349\n",
      "Epoch: 167 -> Test Accuracy: 91.945\n",
      "[168, 60] loss: 0.008\n",
      "[168, 120] loss: 0.009\n",
      "[168, 180] loss: 0.007\n",
      "[168, 240] loss: 0.008\n",
      "[168, 300] loss: 0.008\n",
      "[168, 360] loss: 0.008\n",
      "Epoch: 168 -> Loss: 0.00758798420429\n",
      "Epoch: 168 -> Test Accuracy: 91.9575\n",
      "[169, 60] loss: 0.008\n",
      "[169, 120] loss: 0.007\n",
      "[169, 180] loss: 0.008\n",
      "[169, 240] loss: 0.008\n",
      "[169, 300] loss: 0.008\n",
      "[169, 360] loss: 0.006\n",
      "Epoch: 169 -> Loss: 0.0149642946199\n",
      "Epoch: 169 -> Test Accuracy: 91.955\n",
      "[170, 60] loss: 0.007\n",
      "[170, 120] loss: 0.007\n",
      "[170, 180] loss: 0.007\n",
      "[170, 240] loss: 0.007\n",
      "[170, 300] loss: 0.007\n",
      "[170, 360] loss: 0.008\n",
      "Epoch: 170 -> Loss: 0.00702686328441\n",
      "Epoch: 170 -> Test Accuracy: 91.9875\n",
      "[171, 60] loss: 0.008\n",
      "[171, 120] loss: 0.008\n",
      "[171, 180] loss: 0.007\n",
      "[171, 240] loss: 0.007\n",
      "[171, 300] loss: 0.007\n",
      "[171, 360] loss: 0.007\n",
      "Epoch: 171 -> Loss: 0.0111516946927\n",
      "Epoch: 171 -> Test Accuracy: 91.9125\n",
      "[172, 60] loss: 0.008\n",
      "[172, 120] loss: 0.007\n",
      "[172, 180] loss: 0.007\n",
      "[172, 240] loss: 0.007\n",
      "[172, 300] loss: 0.007\n",
      "[172, 360] loss: 0.007\n",
      "Epoch: 172 -> Loss: 0.0082681607455\n",
      "Epoch: 172 -> Test Accuracy: 91.97\n",
      "[173, 60] loss: 0.006\n",
      "[173, 120] loss: 0.007\n",
      "[173, 180] loss: 0.006\n",
      "[173, 240] loss: 0.007\n",
      "[173, 300] loss: 0.007\n",
      "[173, 360] loss: 0.007\n",
      "Epoch: 173 -> Loss: 0.011242216453\n",
      "Epoch: 173 -> Test Accuracy: 92.11\n",
      "[174, 60] loss: 0.007\n",
      "[174, 120] loss: 0.006\n",
      "[174, 180] loss: 0.007\n",
      "[174, 240] loss: 0.005\n",
      "[174, 300] loss: 0.006\n",
      "[174, 360] loss: 0.007\n",
      "Epoch: 174 -> Loss: 0.00417691608891\n",
      "Epoch: 174 -> Test Accuracy: 92.03\n",
      "[175, 60] loss: 0.007\n",
      "[175, 120] loss: 0.007\n",
      "[175, 180] loss: 0.006\n",
      "[175, 240] loss: 0.006\n",
      "[175, 300] loss: 0.006\n",
      "[175, 360] loss: 0.006\n",
      "Epoch: 175 -> Loss: 0.00198864634149\n",
      "Epoch: 175 -> Test Accuracy: 92.0775\n",
      "[176, 60] loss: 0.005\n",
      "[176, 120] loss: 0.006\n",
      "[176, 180] loss: 0.007\n",
      "[176, 240] loss: 0.006\n",
      "[176, 300] loss: 0.006\n",
      "[176, 360] loss: 0.007\n",
      "Epoch: 176 -> Loss: 0.00446497509256\n",
      "Epoch: 176 -> Test Accuracy: 92.1375\n",
      "[177, 60] loss: 0.007\n",
      "[177, 120] loss: 0.005\n",
      "[177, 180] loss: 0.006\n",
      "[177, 240] loss: 0.006\n",
      "[177, 300] loss: 0.006\n",
      "[177, 360] loss: 0.006\n",
      "Epoch: 177 -> Loss: 0.00158619659487\n",
      "Epoch: 177 -> Test Accuracy: 91.9\n",
      "[178, 60] loss: 0.005\n",
      "[178, 120] loss: 0.006\n",
      "[178, 180] loss: 0.006\n",
      "[178, 240] loss: 0.005\n",
      "[178, 300] loss: 0.006\n",
      "[178, 360] loss: 0.006\n",
      "Epoch: 178 -> Loss: 0.00748038198799\n",
      "Epoch: 178 -> Test Accuracy: 91.9175\n",
      "[179, 60] loss: 0.006\n",
      "[179, 120] loss: 0.005\n",
      "[179, 180] loss: 0.005\n",
      "[179, 240] loss: 0.005\n",
      "[179, 300] loss: 0.006\n",
      "[179, 360] loss: 0.006\n",
      "Epoch: 179 -> Loss: 0.00894325785339\n",
      "Epoch: 179 -> Test Accuracy: 92.005\n",
      "[180, 60] loss: 0.005\n",
      "[180, 120] loss: 0.006\n",
      "[180, 180] loss: 0.005\n",
      "[180, 240] loss: 0.006\n",
      "[180, 300] loss: 0.005\n",
      "[180, 360] loss: 0.006\n",
      "Epoch: 180 -> Loss: 0.00214598770253\n",
      "Epoch: 180 -> Test Accuracy: 92.0475\n",
      "[181, 60] loss: 0.006\n",
      "[181, 120] loss: 0.006\n",
      "[181, 180] loss: 0.005\n",
      "[181, 240] loss: 0.006\n",
      "[181, 300] loss: 0.005\n",
      "[181, 360] loss: 0.006\n",
      "Epoch: 181 -> Loss: 0.00514571601525\n",
      "Epoch: 181 -> Test Accuracy: 92.0\n",
      "[182, 60] loss: 0.006\n",
      "[182, 120] loss: 0.006\n",
      "[182, 180] loss: 0.006\n",
      "[182, 240] loss: 0.005\n",
      "[182, 300] loss: 0.005\n",
      "[182, 360] loss: 0.005\n",
      "Epoch: 182 -> Loss: 0.00484857847914\n",
      "Epoch: 182 -> Test Accuracy: 92.0225\n",
      "[183, 60] loss: 0.005\n",
      "[183, 120] loss: 0.005\n",
      "[183, 180] loss: 0.005\n",
      "[183, 240] loss: 0.006\n",
      "[183, 300] loss: 0.006\n",
      "[183, 360] loss: 0.005\n",
      "Epoch: 183 -> Loss: 0.00231927330606\n",
      "Epoch: 183 -> Test Accuracy: 91.9375\n",
      "[184, 60] loss: 0.006\n",
      "[184, 120] loss: 0.005\n",
      "[184, 180] loss: 0.005\n",
      "[184, 240] loss: 0.004\n",
      "[184, 300] loss: 0.005\n",
      "[184, 360] loss: 0.005\n",
      "Epoch: 184 -> Loss: 0.00450408924371\n",
      "Epoch: 184 -> Test Accuracy: 91.8825\n",
      "[185, 60] loss: 0.005\n",
      "[185, 120] loss: 0.006\n",
      "[185, 180] loss: 0.005\n",
      "[185, 240] loss: 0.005\n",
      "[185, 300] loss: 0.005\n",
      "[185, 360] loss: 0.005\n",
      "Epoch: 185 -> Loss: 0.00241574202664\n",
      "Epoch: 185 -> Test Accuracy: 91.8875\n",
      "[186, 60] loss: 0.005\n",
      "[186, 120] loss: 0.005\n",
      "[186, 180] loss: 0.005\n",
      "[186, 240] loss: 0.005\n",
      "[186, 300] loss: 0.004\n",
      "[186, 360] loss: 0.005\n",
      "Epoch: 186 -> Loss: 0.00366910477169\n",
      "Epoch: 186 -> Test Accuracy: 91.9175\n",
      "[187, 60] loss: 0.005\n",
      "[187, 120] loss: 0.005\n",
      "[187, 180] loss: 0.005\n",
      "[187, 240] loss: 0.006\n",
      "[187, 300] loss: 0.005\n",
      "[187, 360] loss: 0.005\n",
      "Epoch: 187 -> Loss: 0.00315701821819\n",
      "Epoch: 187 -> Test Accuracy: 91.86\n",
      "[188, 60] loss: 0.004\n",
      "[188, 120] loss: 0.005\n",
      "[188, 180] loss: 0.005\n",
      "[188, 240] loss: 0.004\n",
      "[188, 300] loss: 0.006\n",
      "[188, 360] loss: 0.005\n",
      "Epoch: 188 -> Loss: 0.00221917266026\n",
      "Epoch: 188 -> Test Accuracy: 91.935\n",
      "[189, 60] loss: 0.004\n",
      "[189, 120] loss: 0.005\n",
      "[189, 180] loss: 0.005\n",
      "[189, 240] loss: 0.004\n",
      "[189, 300] loss: 0.004\n",
      "[189, 360] loss: 0.005\n",
      "Epoch: 189 -> Loss: 0.0021352537442\n",
      "Epoch: 189 -> Test Accuracy: 91.9125\n",
      "[190, 60] loss: 0.005\n",
      "[190, 120] loss: 0.005\n",
      "[190, 180] loss: 0.005\n",
      "[190, 240] loss: 0.005\n",
      "[190, 300] loss: 0.005\n",
      "[190, 360] loss: 0.005\n",
      "Epoch: 190 -> Loss: 0.00291916285641\n",
      "Epoch: 190 -> Test Accuracy: 91.94\n",
      "[191, 60] loss: 0.005\n",
      "[191, 120] loss: 0.006\n",
      "[191, 180] loss: 0.005\n",
      "[191, 240] loss: 0.006\n",
      "[191, 300] loss: 0.005\n",
      "[191, 360] loss: 0.005\n",
      "Epoch: 191 -> Loss: 0.0117914248258\n",
      "Epoch: 191 -> Test Accuracy: 91.92\n",
      "[192, 60] loss: 0.004\n",
      "[192, 120] loss: 0.005\n",
      "[192, 180] loss: 0.005\n",
      "[192, 240] loss: 0.004\n",
      "[192, 300] loss: 0.005\n",
      "[192, 360] loss: 0.005\n",
      "Epoch: 192 -> Loss: 0.00584613298997\n",
      "Epoch: 192 -> Test Accuracy: 91.9475\n",
      "[193, 60] loss: 0.004\n",
      "[193, 120] loss: 0.004\n",
      "[193, 180] loss: 0.005\n",
      "[193, 240] loss: 0.005\n",
      "[193, 300] loss: 0.005\n",
      "[193, 360] loss: 0.005\n",
      "Epoch: 193 -> Loss: 0.00364509155042\n",
      "Epoch: 193 -> Test Accuracy: 91.905\n",
      "[194, 60] loss: 0.004\n",
      "[194, 120] loss: 0.004\n",
      "[194, 180] loss: 0.004\n",
      "[194, 240] loss: 0.004\n",
      "[194, 300] loss: 0.004\n",
      "[194, 360] loss: 0.004\n",
      "Epoch: 194 -> Loss: 0.00441462546587\n",
      "Epoch: 194 -> Test Accuracy: 91.9725\n",
      "[195, 60] loss: 0.004\n",
      "[195, 120] loss: 0.005\n",
      "[195, 180] loss: 0.004\n",
      "[195, 240] loss: 0.004\n",
      "[195, 300] loss: 0.004\n",
      "[195, 360] loss: 0.005\n",
      "Epoch: 195 -> Loss: 0.00887906830758\n",
      "Epoch: 195 -> Test Accuracy: 91.9875\n",
      "[196, 60] loss: 0.005\n",
      "[196, 120] loss: 0.005\n",
      "[196, 180] loss: 0.005\n",
      "[196, 240] loss: 0.005\n",
      "[196, 300] loss: 0.004\n",
      "[196, 360] loss: 0.004\n",
      "Epoch: 196 -> Loss: 0.00815657712519\n",
      "Epoch: 196 -> Test Accuracy: 91.885\n",
      "[197, 60] loss: 0.005\n",
      "[197, 120] loss: 0.005\n",
      "[197, 180] loss: 0.005\n",
      "[197, 240] loss: 0.004\n",
      "[197, 300] loss: 0.005\n",
      "[197, 360] loss: 0.005\n",
      "Epoch: 197 -> Loss: 0.00630168104544\n",
      "Epoch: 197 -> Test Accuracy: 91.8575\n",
      "[198, 60] loss: 0.005\n",
      "[198, 120] loss: 0.004\n",
      "[198, 180] loss: 0.003\n",
      "[198, 240] loss: 0.005\n",
      "[198, 300] loss: 0.005\n",
      "[198, 360] loss: 0.004\n",
      "Epoch: 198 -> Loss: 0.0158441178501\n",
      "Epoch: 198 -> Test Accuracy: 91.9125\n",
      "[199, 60] loss: 0.004\n",
      "[199, 120] loss: 0.005\n",
      "[199, 180] loss: 0.005\n",
      "[199, 240] loss: 0.004\n",
      "[199, 300] loss: 0.004\n",
      "[199, 360] loss: 0.005\n",
      "Epoch: 199 -> Loss: 0.00965034030378\n",
      "Epoch: 199 -> Test Accuracy: 91.8375\n",
      "[200, 60] loss: 0.005\n",
      "[200, 120] loss: 0.004\n",
      "[200, 180] loss: 0.004\n",
      "[200, 240] loss: 0.004\n",
      "[200, 300] loss: 0.004\n",
      "[200, 360] loss: 0.005\n",
      "Epoch: 200 -> Loss: 0.00338997831568\n",
      "Epoch: 200 -> Test Accuracy: 91.83\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "rot_block5_loss_log, _, rot_block5_test_accuracy_log, _, _ = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], \n",
    "    [60, 120, 160, 200], 0.9, 5e-4, net_block5, criterion, trainloader, None, testloader, rot=['90', '180', '270'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 2.182\n",
      "[1, 120] loss: 1.240\n",
      "[1, 180] loss: 1.122\n",
      "[1, 240] loss: 1.080\n",
      "[1, 300] loss: 1.037\n",
      "[1, 360] loss: 0.998\n",
      "Epoch: 1 -> Loss: 0.888221740723\n",
      "Epoch: 1 -> Test Accuracy: 67.78\n",
      "[2, 60] loss: 0.941\n",
      "[2, 120] loss: 0.915\n",
      "[2, 180] loss: 0.901\n",
      "[2, 240] loss: 0.874\n",
      "[2, 300] loss: 0.886\n",
      "[2, 360] loss: 0.867\n",
      "Epoch: 2 -> Loss: 0.951764404774\n",
      "Epoch: 2 -> Test Accuracy: 71.28\n",
      "[3, 60] loss: 0.853\n",
      "[3, 120] loss: 0.810\n",
      "[3, 180] loss: 0.791\n",
      "[3, 240] loss: 0.808\n",
      "[3, 300] loss: 0.787\n",
      "[3, 360] loss: 0.766\n",
      "Epoch: 3 -> Loss: 0.725242853165\n",
      "Epoch: 3 -> Test Accuracy: 72.86\n",
      "[4, 60] loss: 0.763\n",
      "[4, 120] loss: 0.781\n",
      "[4, 180] loss: 0.775\n",
      "[4, 240] loss: 0.751\n",
      "[4, 300] loss: 0.736\n",
      "[4, 360] loss: 0.771\n",
      "Epoch: 4 -> Loss: 0.7917958498\n",
      "Epoch: 4 -> Test Accuracy: 74.22\n",
      "[5, 60] loss: 0.721\n",
      "[5, 120] loss: 0.716\n",
      "[5, 180] loss: 0.733\n",
      "[5, 240] loss: 0.741\n",
      "[5, 300] loss: 0.711\n",
      "[5, 360] loss: 0.730\n",
      "Epoch: 5 -> Loss: 0.757658779621\n",
      "Epoch: 5 -> Test Accuracy: 75.18\n",
      "[6, 60] loss: 0.704\n",
      "[6, 120] loss: 0.698\n",
      "[6, 180] loss: 0.696\n",
      "[6, 240] loss: 0.704\n",
      "[6, 300] loss: 0.702\n",
      "[6, 360] loss: 0.685\n",
      "Epoch: 6 -> Loss: 0.650731563568\n",
      "Epoch: 6 -> Test Accuracy: 75.94\n",
      "[7, 60] loss: 0.677\n",
      "[7, 120] loss: 0.692\n",
      "[7, 180] loss: 0.693\n",
      "[7, 240] loss: 0.693\n",
      "[7, 300] loss: 0.684\n",
      "[7, 360] loss: 0.686\n",
      "Epoch: 7 -> Loss: 0.9145154953\n",
      "Epoch: 7 -> Test Accuracy: 76.22\n",
      "[8, 60] loss: 0.662\n",
      "[8, 120] loss: 0.673\n",
      "[8, 180] loss: 0.676\n",
      "[8, 240] loss: 0.663\n",
      "[8, 300] loss: 0.692\n",
      "[8, 360] loss: 0.674\n",
      "Epoch: 8 -> Loss: 0.676441252232\n",
      "Epoch: 8 -> Test Accuracy: 76.57\n",
      "[9, 60] loss: 0.664\n",
      "[9, 120] loss: 0.649\n",
      "[9, 180] loss: 0.657\n",
      "[9, 240] loss: 0.668\n",
      "[9, 300] loss: 0.655\n",
      "[9, 360] loss: 0.658\n",
      "Epoch: 9 -> Loss: 0.946856200695\n",
      "Epoch: 9 -> Test Accuracy: 76.38\n",
      "[10, 60] loss: 0.637\n",
      "[10, 120] loss: 0.642\n",
      "[10, 180] loss: 0.641\n",
      "[10, 240] loss: 0.668\n",
      "[10, 300] loss: 0.646\n",
      "[10, 360] loss: 0.652\n",
      "Epoch: 10 -> Loss: 0.572565674782\n",
      "Epoch: 10 -> Test Accuracy: 76.97\n",
      "[11, 60] loss: 0.626\n",
      "[11, 120] loss: 0.646\n",
      "[11, 180] loss: 0.638\n",
      "[11, 240] loss: 0.644\n",
      "[11, 300] loss: 0.662\n",
      "[11, 360] loss: 0.652\n",
      "Epoch: 11 -> Loss: 0.64015185833\n",
      "Epoch: 11 -> Test Accuracy: 77.38\n",
      "[12, 60] loss: 0.636\n",
      "[12, 120] loss: 0.621\n",
      "[12, 180] loss: 0.635\n",
      "[12, 240] loss: 0.624\n",
      "[12, 300] loss: 0.630\n",
      "[12, 360] loss: 0.656\n",
      "Epoch: 12 -> Loss: 0.759081065655\n",
      "Epoch: 12 -> Test Accuracy: 77.66\n",
      "[13, 60] loss: 0.624\n",
      "[13, 120] loss: 0.618\n",
      "[13, 180] loss: 0.635\n",
      "[13, 240] loss: 0.619\n",
      "[13, 300] loss: 0.658\n",
      "[13, 360] loss: 0.645\n",
      "Epoch: 13 -> Loss: 0.489219278097\n",
      "Epoch: 13 -> Test Accuracy: 77.78\n",
      "[14, 60] loss: 0.627\n",
      "[14, 120] loss: 0.612\n",
      "[14, 180] loss: 0.619\n",
      "[14, 240] loss: 0.620\n",
      "[14, 300] loss: 0.637\n",
      "[14, 360] loss: 0.634\n",
      "Epoch: 14 -> Loss: 0.728446006775\n",
      "Epoch: 14 -> Test Accuracy: 77.73\n",
      "[15, 60] loss: 0.613\n",
      "[15, 120] loss: 0.610\n",
      "[15, 180] loss: 0.630\n",
      "[15, 240] loss: 0.612\n",
      "[15, 300] loss: 0.606\n",
      "[15, 360] loss: 0.635\n",
      "Epoch: 15 -> Loss: 0.97629326582\n",
      "Epoch: 15 -> Test Accuracy: 77.98\n",
      "[16, 60] loss: 0.608\n",
      "[16, 120] loss: 0.593\n",
      "[16, 180] loss: 0.612\n",
      "[16, 240] loss: 0.637\n",
      "[16, 300] loss: 0.622\n",
      "[16, 360] loss: 0.621\n",
      "Epoch: 16 -> Loss: 0.731149435043\n",
      "Epoch: 16 -> Test Accuracy: 77.62\n",
      "[17, 60] loss: 0.584\n",
      "[17, 120] loss: 0.631\n",
      "[17, 180] loss: 0.604\n",
      "[17, 240] loss: 0.613\n",
      "[17, 300] loss: 0.634\n",
      "[17, 360] loss: 0.622\n",
      "Epoch: 17 -> Loss: 0.509759187698\n",
      "Epoch: 17 -> Test Accuracy: 78.71\n",
      "[18, 60] loss: 0.594\n",
      "[18, 120] loss: 0.619\n",
      "[18, 180] loss: 0.601\n",
      "[18, 240] loss: 0.610\n",
      "[18, 300] loss: 0.609\n",
      "[18, 360] loss: 0.645\n",
      "Epoch: 18 -> Loss: 0.579723715782\n",
      "Epoch: 18 -> Test Accuracy: 78.46\n",
      "[19, 60] loss: 0.590\n",
      "[19, 120] loss: 0.621\n",
      "[19, 180] loss: 0.607\n",
      "[19, 240] loss: 0.616\n",
      "[19, 300] loss: 0.617\n",
      "[19, 360] loss: 0.600\n",
      "Epoch: 19 -> Loss: 0.57422709465\n",
      "Epoch: 19 -> Test Accuracy: 78.98\n",
      "[20, 60] loss: 0.586\n",
      "[20, 120] loss: 0.597\n",
      "[20, 180] loss: 0.612\n",
      "[20, 240] loss: 0.616\n",
      "[20, 300] loss: 0.594\n",
      "[20, 360] loss: 0.623\n",
      "Epoch: 20 -> Loss: 0.560020744801\n",
      "Epoch: 20 -> Test Accuracy: 78.83\n",
      "[21, 60] loss: 0.550\n",
      "[21, 120] loss: 0.530\n",
      "[21, 180] loss: 0.504\n",
      "[21, 240] loss: 0.517\n",
      "[21, 300] loss: 0.497\n",
      "[21, 360] loss: 0.486\n",
      "Epoch: 21 -> Loss: 0.528198897839\n",
      "Epoch: 21 -> Test Accuracy: 80.82\n",
      "[22, 60] loss: 0.489\n",
      "[22, 120] loss: 0.471\n",
      "[22, 180] loss: 0.478\n",
      "[22, 240] loss: 0.462\n",
      "[22, 300] loss: 0.473\n",
      "[22, 360] loss: 0.484\n",
      "Epoch: 22 -> Loss: 0.483328729868\n",
      "Epoch: 22 -> Test Accuracy: 81.43\n",
      "[23, 60] loss: 0.453\n",
      "[23, 120] loss: 0.462\n",
      "[23, 180] loss: 0.460\n",
      "[23, 240] loss: 0.457\n",
      "[23, 300] loss: 0.459\n",
      "[23, 360] loss: 0.461\n",
      "Epoch: 23 -> Loss: 0.547541558743\n",
      "Epoch: 23 -> Test Accuracy: 81.25\n",
      "[24, 60] loss: 0.454\n",
      "[24, 120] loss: 0.450\n",
      "[24, 180] loss: 0.447\n",
      "[24, 240] loss: 0.434\n",
      "[24, 300] loss: 0.447\n",
      "[24, 360] loss: 0.444\n",
      "Epoch: 24 -> Loss: 0.388503313065\n",
      "Epoch: 24 -> Test Accuracy: 81.35\n",
      "[25, 60] loss: 0.426\n",
      "[25, 120] loss: 0.448\n",
      "[25, 180] loss: 0.442\n",
      "[25, 240] loss: 0.431\n",
      "[25, 300] loss: 0.439\n",
      "[25, 360] loss: 0.431\n",
      "Epoch: 25 -> Loss: 0.355383694172\n",
      "Epoch: 25 -> Test Accuracy: 82.08\n",
      "[26, 60] loss: 0.414\n",
      "[26, 120] loss: 0.410\n",
      "[26, 180] loss: 0.435\n",
      "[26, 240] loss: 0.428\n",
      "[26, 300] loss: 0.442\n",
      "[26, 360] loss: 0.431\n",
      "Epoch: 26 -> Loss: 0.3030179739\n",
      "Epoch: 26 -> Test Accuracy: 81.75\n",
      "[27, 60] loss: 0.436\n",
      "[27, 120] loss: 0.409\n",
      "[27, 180] loss: 0.428\n",
      "[27, 240] loss: 0.417\n",
      "[27, 300] loss: 0.431\n",
      "[27, 360] loss: 0.437\n",
      "Epoch: 27 -> Loss: 0.379159212112\n",
      "Epoch: 27 -> Test Accuracy: 81.67\n",
      "[28, 60] loss: 0.404\n",
      "[28, 120] loss: 0.407\n",
      "[28, 180] loss: 0.415\n",
      "[28, 240] loss: 0.428\n",
      "[28, 300] loss: 0.407\n",
      "[28, 360] loss: 0.426\n",
      "Epoch: 28 -> Loss: 0.338245630264\n",
      "Epoch: 28 -> Test Accuracy: 81.71\n",
      "[29, 60] loss: 0.410\n",
      "[29, 120] loss: 0.423\n",
      "[29, 180] loss: 0.420\n",
      "[29, 240] loss: 0.409\n",
      "[29, 300] loss: 0.407\n",
      "[29, 360] loss: 0.421\n",
      "Epoch: 29 -> Loss: 0.380491733551\n",
      "Epoch: 29 -> Test Accuracy: 81.48\n",
      "[30, 60] loss: 0.397\n",
      "[30, 120] loss: 0.415\n",
      "[30, 180] loss: 0.410\n",
      "[30, 240] loss: 0.409\n",
      "[30, 300] loss: 0.428\n",
      "[30, 360] loss: 0.410\n",
      "Epoch: 30 -> Loss: 0.255045413971\n",
      "Epoch: 30 -> Test Accuracy: 81.16\n",
      "[31, 60] loss: 0.385\n",
      "[31, 120] loss: 0.415\n",
      "[31, 180] loss: 0.403\n",
      "[31, 240] loss: 0.415\n",
      "[31, 300] loss: 0.405\n",
      "[31, 360] loss: 0.413\n",
      "Epoch: 31 -> Loss: 0.422018766403\n",
      "Epoch: 31 -> Test Accuracy: 81.22\n",
      "[32, 60] loss: 0.406\n",
      "[32, 120] loss: 0.393\n",
      "[32, 180] loss: 0.404\n",
      "[32, 240] loss: 0.403\n",
      "[32, 300] loss: 0.414\n",
      "[32, 360] loss: 0.414\n",
      "Epoch: 32 -> Loss: 0.637579381466\n",
      "Epoch: 32 -> Test Accuracy: 81.67\n",
      "[33, 60] loss: 0.391\n",
      "[33, 120] loss: 0.399\n",
      "[33, 180] loss: 0.414\n",
      "[33, 240] loss: 0.400\n",
      "[33, 300] loss: 0.400\n",
      "[33, 360] loss: 0.414\n",
      "Epoch: 33 -> Loss: 0.507943511009\n",
      "Epoch: 33 -> Test Accuracy: 81.59\n",
      "[34, 60] loss: 0.401\n",
      "[34, 120] loss: 0.399\n",
      "[34, 180] loss: 0.411\n",
      "[34, 240] loss: 0.408\n",
      "[34, 300] loss: 0.420\n",
      "[34, 360] loss: 0.407\n",
      "Epoch: 34 -> Loss: 0.352932840586\n",
      "Epoch: 34 -> Test Accuracy: 81.24\n",
      "[35, 60] loss: 0.374\n",
      "[35, 120] loss: 0.399\n",
      "[35, 180] loss: 0.407\n",
      "[35, 240] loss: 0.412\n",
      "[35, 300] loss: 0.410\n",
      "[35, 360] loss: 0.413\n",
      "Epoch: 35 -> Loss: 0.625798881054\n",
      "Epoch: 35 -> Test Accuracy: 81.09\n",
      "[36, 60] loss: 0.393\n",
      "[36, 120] loss: 0.408\n",
      "[36, 180] loss: 0.404\n",
      "[36, 240] loss: 0.404\n",
      "[36, 300] loss: 0.400\n",
      "[36, 360] loss: 0.395\n",
      "Epoch: 36 -> Loss: 0.529586851597\n",
      "Epoch: 36 -> Test Accuracy: 80.75\n",
      "[37, 60] loss: 0.395\n",
      "[37, 120] loss: 0.388\n",
      "[37, 180] loss: 0.410\n",
      "[37, 240] loss: 0.401\n",
      "[37, 300] loss: 0.406\n",
      "[37, 360] loss: 0.406\n",
      "Epoch: 37 -> Loss: 0.684429526329\n",
      "Epoch: 37 -> Test Accuracy: 81.49\n",
      "[38, 60] loss: 0.396\n",
      "[38, 120] loss: 0.404\n",
      "[38, 180] loss: 0.398\n",
      "[38, 240] loss: 0.415\n",
      "[38, 300] loss: 0.397\n",
      "[38, 360] loss: 0.398\n",
      "Epoch: 38 -> Loss: 0.505430817604\n",
      "Epoch: 38 -> Test Accuracy: 81.25\n",
      "[39, 60] loss: 0.406\n",
      "[39, 120] loss: 0.390\n",
      "[39, 180] loss: 0.394\n",
      "[39, 240] loss: 0.389\n",
      "[39, 300] loss: 0.414\n",
      "[39, 360] loss: 0.406\n",
      "Epoch: 39 -> Loss: 0.26519086957\n",
      "Epoch: 39 -> Test Accuracy: 81.44\n",
      "[40, 60] loss: 0.373\n",
      "[40, 120] loss: 0.384\n",
      "[40, 180] loss: 0.379\n",
      "[40, 240] loss: 0.403\n",
      "[40, 300] loss: 0.396\n",
      "[40, 360] loss: 0.410\n",
      "Epoch: 40 -> Loss: 0.548456788063\n",
      "Epoch: 40 -> Test Accuracy: 80.87\n",
      "[41, 60] loss: 0.375\n",
      "[41, 120] loss: 0.347\n",
      "[41, 180] loss: 0.362\n",
      "[41, 240] loss: 0.359\n",
      "[41, 300] loss: 0.362\n",
      "[41, 360] loss: 0.336\n",
      "Epoch: 41 -> Loss: 0.320163697004\n",
      "Epoch: 41 -> Test Accuracy: 81.95\n",
      "[42, 60] loss: 0.332\n",
      "[42, 120] loss: 0.327\n",
      "[42, 180] loss: 0.330\n",
      "[42, 240] loss: 0.326\n",
      "[42, 300] loss: 0.325\n",
      "[42, 360] loss: 0.345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.420903027058\n",
      "Epoch: 42 -> Test Accuracy: 82.26\n",
      "[43, 60] loss: 0.333\n",
      "[43, 120] loss: 0.322\n",
      "[43, 180] loss: 0.316\n",
      "[43, 240] loss: 0.327\n",
      "[43, 300] loss: 0.317\n",
      "[43, 360] loss: 0.324\n",
      "Epoch: 43 -> Loss: 0.316190809011\n",
      "Epoch: 43 -> Test Accuracy: 82.23\n",
      "[44, 60] loss: 0.308\n",
      "[44, 120] loss: 0.309\n",
      "[44, 180] loss: 0.305\n",
      "[44, 240] loss: 0.312\n",
      "[44, 300] loss: 0.319\n",
      "[44, 360] loss: 0.322\n",
      "Epoch: 44 -> Loss: 0.290711343288\n",
      "Epoch: 44 -> Test Accuracy: 82.25\n",
      "[45, 60] loss: 0.288\n",
      "[45, 120] loss: 0.321\n",
      "[45, 180] loss: 0.316\n",
      "[45, 240] loss: 0.304\n",
      "[45, 300] loss: 0.299\n",
      "[45, 360] loss: 0.307\n",
      "Epoch: 45 -> Loss: 0.32226151228\n",
      "Epoch: 45 -> Test Accuracy: 82.22\n",
      "[46, 60] loss: 0.305\n",
      "[46, 120] loss: 0.306\n",
      "[46, 180] loss: 0.308\n",
      "[46, 240] loss: 0.286\n",
      "[46, 300] loss: 0.291\n",
      "[46, 360] loss: 0.297\n",
      "Epoch: 46 -> Loss: 0.279633402824\n",
      "Epoch: 46 -> Test Accuracy: 82.46\n",
      "[47, 60] loss: 0.291\n",
      "[47, 120] loss: 0.294\n",
      "[47, 180] loss: 0.299\n",
      "[47, 240] loss: 0.291\n",
      "[47, 300] loss: 0.274\n",
      "[47, 360] loss: 0.303\n",
      "Epoch: 47 -> Loss: 0.310583174229\n",
      "Epoch: 47 -> Test Accuracy: 82.52\n",
      "[48, 60] loss: 0.282\n",
      "[48, 120] loss: 0.296\n",
      "[48, 180] loss: 0.289\n",
      "[48, 240] loss: 0.291\n",
      "[48, 300] loss: 0.289\n",
      "[48, 360] loss: 0.285\n",
      "Epoch: 48 -> Loss: 0.233705490828\n",
      "Epoch: 48 -> Test Accuracy: 82.55\n",
      "[49, 60] loss: 0.281\n",
      "[49, 120] loss: 0.285\n",
      "[49, 180] loss: 0.287\n",
      "[49, 240] loss: 0.300\n",
      "[49, 300] loss: 0.299\n",
      "[49, 360] loss: 0.282\n",
      "Epoch: 49 -> Loss: 0.334133535624\n",
      "Epoch: 49 -> Test Accuracy: 82.43\n",
      "[50, 60] loss: 0.282\n",
      "[50, 120] loss: 0.291\n",
      "[50, 180] loss: 0.282\n",
      "[50, 240] loss: 0.291\n",
      "[50, 300] loss: 0.299\n",
      "[50, 360] loss: 0.291\n",
      "Epoch: 50 -> Loss: 0.254858881235\n",
      "Epoch: 50 -> Test Accuracy: 82.49\n",
      "[51, 60] loss: 0.284\n",
      "[51, 120] loss: 0.290\n",
      "[51, 180] loss: 0.291\n",
      "[51, 240] loss: 0.273\n",
      "[51, 300] loss: 0.276\n",
      "[51, 360] loss: 0.295\n",
      "Epoch: 51 -> Loss: 0.40483006835\n",
      "Epoch: 51 -> Test Accuracy: 82.57\n",
      "[52, 60] loss: 0.272\n",
      "[52, 120] loss: 0.271\n",
      "[52, 180] loss: 0.281\n",
      "[52, 240] loss: 0.283\n",
      "[52, 300] loss: 0.292\n",
      "[52, 360] loss: 0.287\n",
      "Epoch: 52 -> Loss: 0.306162297726\n",
      "Epoch: 52 -> Test Accuracy: 82.64\n",
      "[53, 60] loss: 0.274\n",
      "[53, 120] loss: 0.269\n",
      "[53, 180] loss: 0.278\n",
      "[53, 240] loss: 0.286\n",
      "[53, 300] loss: 0.291\n",
      "[53, 360] loss: 0.282\n",
      "Epoch: 53 -> Loss: 0.376108080149\n",
      "Epoch: 53 -> Test Accuracy: 82.46\n",
      "[54, 60] loss: 0.270\n",
      "[54, 120] loss: 0.278\n",
      "[54, 180] loss: 0.288\n",
      "[54, 240] loss: 0.282\n",
      "[54, 300] loss: 0.290\n",
      "[54, 360] loss: 0.276\n",
      "Epoch: 54 -> Loss: 0.455203920603\n",
      "Epoch: 54 -> Test Accuracy: 82.51\n",
      "[55, 60] loss: 0.281\n",
      "[55, 120] loss: 0.274\n",
      "[55, 180] loss: 0.286\n",
      "[55, 240] loss: 0.267\n",
      "[55, 300] loss: 0.278\n",
      "[55, 360] loss: 0.282\n",
      "Epoch: 55 -> Loss: 0.262966483831\n",
      "Epoch: 55 -> Test Accuracy: 82.58\n",
      "[56, 60] loss: 0.280\n",
      "[56, 120] loss: 0.280\n",
      "[56, 180] loss: 0.292\n",
      "[56, 240] loss: 0.275\n",
      "[56, 300] loss: 0.276\n",
      "[56, 360] loss: 0.272\n",
      "Epoch: 56 -> Loss: 0.309959501028\n",
      "Epoch: 56 -> Test Accuracy: 82.68\n",
      "[57, 60] loss: 0.278\n",
      "[57, 120] loss: 0.282\n",
      "[57, 180] loss: 0.266\n",
      "[57, 240] loss: 0.269\n",
      "[57, 300] loss: 0.280\n",
      "[57, 360] loss: 0.277\n",
      "Epoch: 57 -> Loss: 0.340485423803\n",
      "Epoch: 57 -> Test Accuracy: 82.5\n",
      "[58, 60] loss: 0.277\n",
      "[58, 120] loss: 0.275\n",
      "[58, 180] loss: 0.273\n",
      "[58, 240] loss: 0.278\n",
      "[58, 300] loss: 0.280\n",
      "[58, 360] loss: 0.268\n",
      "Epoch: 58 -> Loss: 0.276349842548\n",
      "Epoch: 58 -> Test Accuracy: 82.61\n",
      "[59, 60] loss: 0.286\n",
      "[59, 120] loss: 0.274\n",
      "[59, 180] loss: 0.279\n",
      "[59, 240] loss: 0.272\n",
      "[59, 300] loss: 0.264\n",
      "[59, 360] loss: 0.278\n",
      "Epoch: 59 -> Loss: 0.170421242714\n",
      "Epoch: 59 -> Test Accuracy: 82.41\n",
      "[60, 60] loss: 0.271\n",
      "[60, 120] loss: 0.291\n",
      "[60, 180] loss: 0.261\n",
      "[60, 240] loss: 0.273\n",
      "[60, 300] loss: 0.267\n",
      "[60, 360] loss: 0.275\n",
      "Epoch: 60 -> Loss: 0.370997101068\n",
      "Epoch: 60 -> Test Accuracy: 82.52\n",
      "[61, 60] loss: 0.265\n",
      "[61, 120] loss: 0.273\n",
      "[61, 180] loss: 0.273\n",
      "[61, 240] loss: 0.278\n",
      "[61, 300] loss: 0.264\n",
      "[61, 360] loss: 0.270\n",
      "Epoch: 61 -> Loss: 0.469749301672\n",
      "Epoch: 61 -> Test Accuracy: 82.51\n",
      "[62, 60] loss: 0.270\n",
      "[62, 120] loss: 0.258\n",
      "[62, 180] loss: 0.271\n",
      "[62, 240] loss: 0.269\n",
      "[62, 300] loss: 0.276\n",
      "[62, 360] loss: 0.277\n",
      "Epoch: 62 -> Loss: 0.486546337605\n",
      "Epoch: 62 -> Test Accuracy: 82.49\n",
      "[63, 60] loss: 0.276\n",
      "[63, 120] loss: 0.258\n",
      "[63, 180] loss: 0.271\n",
      "[63, 240] loss: 0.271\n",
      "[63, 300] loss: 0.263\n",
      "[63, 360] loss: 0.263\n",
      "Epoch: 63 -> Loss: 0.31947273016\n",
      "Epoch: 63 -> Test Accuracy: 82.53\n",
      "[64, 60] loss: 0.260\n",
      "[64, 120] loss: 0.280\n",
      "[64, 180] loss: 0.274\n",
      "[64, 240] loss: 0.261\n",
      "[64, 300] loss: 0.259\n",
      "[64, 360] loss: 0.265\n",
      "Epoch: 64 -> Loss: 0.204063534737\n",
      "Epoch: 64 -> Test Accuracy: 82.4\n",
      "[65, 60] loss: 0.258\n",
      "[65, 120] loss: 0.265\n",
      "[65, 180] loss: 0.277\n",
      "[65, 240] loss: 0.267\n",
      "[65, 300] loss: 0.265\n",
      "[65, 360] loss: 0.269\n",
      "Epoch: 65 -> Loss: 0.342465162277\n",
      "Epoch: 65 -> Test Accuracy: 82.44\n",
      "[66, 60] loss: 0.253\n",
      "[66, 120] loss: 0.274\n",
      "[66, 180] loss: 0.279\n",
      "[66, 240] loss: 0.261\n",
      "[66, 300] loss: 0.271\n",
      "[66, 360] loss: 0.258\n",
      "Epoch: 66 -> Loss: 0.162976890802\n",
      "Epoch: 66 -> Test Accuracy: 82.55\n",
      "[67, 60] loss: 0.254\n",
      "[67, 120] loss: 0.269\n",
      "[67, 180] loss: 0.286\n",
      "[67, 240] loss: 0.275\n",
      "[67, 300] loss: 0.281\n",
      "[67, 360] loss: 0.254\n",
      "Epoch: 67 -> Loss: 0.346048027277\n",
      "Epoch: 67 -> Test Accuracy: 82.59\n",
      "[68, 60] loss: 0.265\n",
      "[68, 120] loss: 0.260\n",
      "[68, 180] loss: 0.265\n",
      "[68, 240] loss: 0.263\n",
      "[68, 300] loss: 0.265\n",
      "[68, 360] loss: 0.258\n",
      "Epoch: 68 -> Loss: 0.150452688336\n",
      "Epoch: 68 -> Test Accuracy: 82.63\n",
      "[69, 60] loss: 0.259\n",
      "[69, 120] loss: 0.259\n",
      "[69, 180] loss: 0.266\n",
      "[69, 240] loss: 0.266\n",
      "[69, 300] loss: 0.262\n",
      "[69, 360] loss: 0.266\n",
      "Epoch: 69 -> Loss: 0.239269331098\n",
      "Epoch: 69 -> Test Accuracy: 82.49\n",
      "[70, 60] loss: 0.244\n",
      "[70, 120] loss: 0.257\n",
      "[70, 180] loss: 0.264\n",
      "[70, 240] loss: 0.269\n",
      "[70, 300] loss: 0.267\n",
      "[70, 360] loss: 0.259\n",
      "Epoch: 70 -> Loss: 0.21597366035\n",
      "Epoch: 70 -> Test Accuracy: 82.55\n",
      "[71, 60] loss: 0.267\n",
      "[71, 120] loss: 0.263\n",
      "[71, 180] loss: 0.264\n",
      "[71, 240] loss: 0.266\n",
      "[71, 300] loss: 0.256\n",
      "[71, 360] loss: 0.256\n",
      "Epoch: 71 -> Loss: 0.240311190486\n",
      "Epoch: 71 -> Test Accuracy: 82.36\n",
      "[72, 60] loss: 0.268\n",
      "[72, 120] loss: 0.264\n",
      "[72, 180] loss: 0.250\n",
      "[72, 240] loss: 0.257\n",
      "[72, 300] loss: 0.265\n",
      "[72, 360] loss: 0.261\n",
      "Epoch: 72 -> Loss: 0.376833379269\n",
      "Epoch: 72 -> Test Accuracy: 82.34\n",
      "[73, 60] loss: 0.241\n",
      "[73, 120] loss: 0.263\n",
      "[73, 180] loss: 0.265\n",
      "[73, 240] loss: 0.262\n",
      "[73, 300] loss: 0.259\n",
      "[73, 360] loss: 0.265\n",
      "Epoch: 73 -> Loss: 0.265670657158\n",
      "Epoch: 73 -> Test Accuracy: 82.35\n",
      "[74, 60] loss: 0.250\n",
      "[74, 120] loss: 0.258\n",
      "[74, 180] loss: 0.256\n",
      "[74, 240] loss: 0.266\n",
      "[74, 300] loss: 0.256\n",
      "[74, 360] loss: 0.254\n",
      "Epoch: 74 -> Loss: 0.200331881642\n",
      "Epoch: 74 -> Test Accuracy: 82.37\n",
      "[75, 60] loss: 0.252\n",
      "[75, 120] loss: 0.256\n",
      "[75, 180] loss: 0.260\n",
      "[75, 240] loss: 0.260\n",
      "[75, 300] loss: 0.266\n",
      "[75, 360] loss: 0.263\n",
      "Epoch: 75 -> Loss: 0.266535133123\n",
      "Epoch: 75 -> Test Accuracy: 82.38\n",
      "[76, 60] loss: 0.273\n",
      "[76, 120] loss: 0.257\n",
      "[76, 180] loss: 0.257\n",
      "[76, 240] loss: 0.265\n",
      "[76, 300] loss: 0.247\n",
      "[76, 360] loss: 0.256\n",
      "Epoch: 76 -> Loss: 0.238486096263\n",
      "Epoch: 76 -> Test Accuracy: 82.47\n",
      "[77, 60] loss: 0.259\n",
      "[77, 120] loss: 0.259\n",
      "[77, 180] loss: 0.252\n",
      "[77, 240] loss: 0.259\n",
      "[77, 300] loss: 0.247\n",
      "[77, 360] loss: 0.261\n",
      "Epoch: 77 -> Loss: 0.195395946503\n",
      "Epoch: 77 -> Test Accuracy: 82.57\n",
      "[78, 60] loss: 0.254\n",
      "[78, 120] loss: 0.243\n",
      "[78, 180] loss: 0.246\n",
      "[78, 240] loss: 0.261\n",
      "[78, 300] loss: 0.253\n",
      "[78, 360] loss: 0.256\n",
      "Epoch: 78 -> Loss: 0.374813079834\n",
      "Epoch: 78 -> Test Accuracy: 82.61\n",
      "[79, 60] loss: 0.250\n",
      "[79, 120] loss: 0.252\n",
      "[79, 180] loss: 0.255\n",
      "[79, 240] loss: 0.246\n",
      "[79, 300] loss: 0.252\n",
      "[79, 360] loss: 0.255\n",
      "Epoch: 79 -> Loss: 0.158499777317\n",
      "Epoch: 79 -> Test Accuracy: 82.4\n",
      "[80, 60] loss: 0.259\n",
      "[80, 120] loss: 0.252\n",
      "[80, 180] loss: 0.249\n",
      "[80, 240] loss: 0.245\n",
      "[80, 300] loss: 0.252\n",
      "[80, 360] loss: 0.246\n",
      "Epoch: 80 -> Loss: 0.284727603197\n",
      "Epoch: 80 -> Test Accuracy: 82.6\n",
      "[81, 60] loss: 0.239\n",
      "[81, 120] loss: 0.246\n",
      "[81, 180] loss: 0.260\n",
      "[81, 240] loss: 0.246\n",
      "[81, 300] loss: 0.256\n",
      "[81, 360] loss: 0.261\n",
      "Epoch: 81 -> Loss: 0.323564469814\n",
      "Epoch: 81 -> Test Accuracy: 82.49\n",
      "[82, 60] loss: 0.234\n",
      "[82, 120] loss: 0.258\n",
      "[82, 180] loss: 0.256\n",
      "[82, 240] loss: 0.248\n",
      "[82, 300] loss: 0.253\n",
      "[82, 360] loss: 0.262\n",
      "Epoch: 82 -> Loss: 0.299566805363\n",
      "Epoch: 82 -> Test Accuracy: 82.45\n",
      "[83, 60] loss: 0.251\n",
      "[83, 120] loss: 0.251\n",
      "[83, 180] loss: 0.253\n",
      "[83, 240] loss: 0.247\n",
      "[83, 300] loss: 0.246\n",
      "[83, 360] loss: 0.247\n",
      "Epoch: 83 -> Loss: 0.21166190505\n",
      "Epoch: 83 -> Test Accuracy: 82.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.243\n",
      "[84, 120] loss: 0.253\n",
      "[84, 180] loss: 0.248\n",
      "[84, 240] loss: 0.245\n",
      "[84, 300] loss: 0.247\n",
      "[84, 360] loss: 0.250\n",
      "Epoch: 84 -> Loss: 0.153328850865\n",
      "Epoch: 84 -> Test Accuracy: 82.64\n",
      "[85, 60] loss: 0.248\n",
      "[85, 120] loss: 0.244\n",
      "[85, 180] loss: 0.248\n",
      "[85, 240] loss: 0.241\n",
      "[85, 300] loss: 0.252\n",
      "[85, 360] loss: 0.242\n",
      "Epoch: 85 -> Loss: 0.178085491061\n",
      "Epoch: 85 -> Test Accuracy: 82.3\n",
      "[86, 60] loss: 0.239\n",
      "[86, 120] loss: 0.258\n",
      "[86, 180] loss: 0.238\n",
      "[86, 240] loss: 0.244\n",
      "[86, 300] loss: 0.235\n",
      "[86, 360] loss: 0.246\n",
      "Epoch: 86 -> Loss: 0.247001975775\n",
      "Epoch: 86 -> Test Accuracy: 82.52\n",
      "[87, 60] loss: 0.252\n",
      "[87, 120] loss: 0.246\n",
      "[87, 180] loss: 0.241\n",
      "[87, 240] loss: 0.246\n",
      "[87, 300] loss: 0.249\n",
      "[87, 360] loss: 0.249\n",
      "Epoch: 87 -> Loss: 0.407880365849\n",
      "Epoch: 87 -> Test Accuracy: 82.44\n",
      "[88, 60] loss: 0.250\n",
      "[88, 120] loss: 0.242\n",
      "[88, 180] loss: 0.242\n",
      "[88, 240] loss: 0.246\n",
      "[88, 300] loss: 0.240\n",
      "[88, 360] loss: 0.244\n",
      "Epoch: 88 -> Loss: 0.29486811161\n",
      "Epoch: 88 -> Test Accuracy: 82.51\n",
      "[89, 60] loss: 0.249\n",
      "[89, 120] loss: 0.238\n",
      "[89, 180] loss: 0.241\n",
      "[89, 240] loss: 0.247\n",
      "[89, 300] loss: 0.245\n",
      "[89, 360] loss: 0.250\n",
      "Epoch: 89 -> Loss: 0.176816880703\n",
      "Epoch: 89 -> Test Accuracy: 82.41\n",
      "[90, 60] loss: 0.250\n",
      "[90, 120] loss: 0.243\n",
      "[90, 180] loss: 0.250\n",
      "[90, 240] loss: 0.239\n",
      "[90, 300] loss: 0.230\n",
      "[90, 360] loss: 0.241\n",
      "Epoch: 90 -> Loss: 0.208742573857\n",
      "Epoch: 90 -> Test Accuracy: 82.48\n",
      "[91, 60] loss: 0.246\n",
      "[91, 120] loss: 0.238\n",
      "[91, 180] loss: 0.253\n",
      "[91, 240] loss: 0.242\n",
      "[91, 300] loss: 0.236\n",
      "[91, 360] loss: 0.248\n",
      "Epoch: 91 -> Loss: 0.133582308888\n",
      "Epoch: 91 -> Test Accuracy: 82.54\n",
      "[92, 60] loss: 0.241\n",
      "[92, 120] loss: 0.237\n",
      "[92, 180] loss: 0.252\n",
      "[92, 240] loss: 0.243\n",
      "[92, 300] loss: 0.237\n",
      "[92, 360] loss: 0.238\n",
      "Epoch: 92 -> Loss: 0.236907571554\n",
      "Epoch: 92 -> Test Accuracy: 82.42\n",
      "[93, 60] loss: 0.248\n",
      "[93, 120] loss: 0.231\n",
      "[93, 180] loss: 0.244\n",
      "[93, 240] loss: 0.245\n",
      "[93, 300] loss: 0.236\n",
      "[93, 360] loss: 0.241\n",
      "Epoch: 93 -> Loss: 0.18715877831\n",
      "Epoch: 93 -> Test Accuracy: 82.38\n",
      "[94, 60] loss: 0.231\n",
      "[94, 120] loss: 0.247\n",
      "[94, 180] loss: 0.255\n",
      "[94, 240] loss: 0.232\n",
      "[94, 300] loss: 0.236\n",
      "[94, 360] loss: 0.234\n",
      "Epoch: 94 -> Loss: 0.278233587742\n",
      "Epoch: 94 -> Test Accuracy: 82.26\n",
      "[95, 60] loss: 0.240\n",
      "[95, 120] loss: 0.242\n",
      "[95, 180] loss: 0.236\n",
      "[95, 240] loss: 0.235\n",
      "[95, 300] loss: 0.243\n",
      "[95, 360] loss: 0.247\n",
      "Epoch: 95 -> Loss: 0.259756922722\n",
      "Epoch: 95 -> Test Accuracy: 82.47\n",
      "[96, 60] loss: 0.247\n",
      "[96, 120] loss: 0.234\n",
      "[96, 180] loss: 0.240\n",
      "[96, 240] loss: 0.243\n",
      "[96, 300] loss: 0.239\n",
      "[96, 360] loss: 0.248\n",
      "Epoch: 96 -> Loss: 0.293178081512\n",
      "Epoch: 96 -> Test Accuracy: 82.34\n",
      "[97, 60] loss: 0.236\n",
      "[97, 120] loss: 0.228\n",
      "[97, 180] loss: 0.236\n",
      "[97, 240] loss: 0.244\n",
      "[97, 300] loss: 0.246\n",
      "[97, 360] loss: 0.240\n",
      "Epoch: 97 -> Loss: 0.224813386798\n",
      "Epoch: 97 -> Test Accuracy: 82.4\n",
      "[98, 60] loss: 0.251\n",
      "[98, 120] loss: 0.244\n",
      "[98, 180] loss: 0.239\n",
      "[98, 240] loss: 0.222\n",
      "[98, 300] loss: 0.234\n",
      "[98, 360] loss: 0.235\n",
      "Epoch: 98 -> Loss: 0.226194471121\n",
      "Epoch: 98 -> Test Accuracy: 82.47\n",
      "[99, 60] loss: 0.228\n",
      "[99, 120] loss: 0.231\n",
      "[99, 180] loss: 0.234\n",
      "[99, 240] loss: 0.234\n",
      "[99, 300] loss: 0.240\n",
      "[99, 360] loss: 0.245\n",
      "Epoch: 99 -> Loss: 0.143506005406\n",
      "Epoch: 99 -> Test Accuracy: 82.33\n",
      "[100, 60] loss: 0.245\n",
      "[100, 120] loss: 0.233\n",
      "[100, 180] loss: 0.232\n",
      "[100, 240] loss: 0.243\n",
      "[100, 300] loss: 0.244\n",
      "[100, 360] loss: 0.231\n",
      "Epoch: 100 -> Loss: 0.215303584933\n",
      "Epoch: 100 -> Test Accuracy: 82.38\n",
      "Finished Training\n",
      "[1, 60] loss: 1.661\n",
      "[1, 120] loss: 0.836\n",
      "[1, 180] loss: 0.790\n",
      "[1, 240] loss: 0.736\n",
      "[1, 300] loss: 0.702\n",
      "[1, 360] loss: 0.657\n",
      "Epoch: 1 -> Loss: 0.662912428379\n",
      "Epoch: 1 -> Test Accuracy: 77.21\n",
      "[2, 60] loss: 0.601\n",
      "[2, 120] loss: 0.591\n",
      "[2, 180] loss: 0.605\n",
      "[2, 240] loss: 0.584\n",
      "[2, 300] loss: 0.547\n",
      "[2, 360] loss: 0.571\n",
      "Epoch: 2 -> Loss: 0.475015640259\n",
      "Epoch: 2 -> Test Accuracy: 79.71\n",
      "[3, 60] loss: 0.523\n",
      "[3, 120] loss: 0.505\n",
      "[3, 180] loss: 0.526\n",
      "[3, 240] loss: 0.544\n",
      "[3, 300] loss: 0.515\n",
      "[3, 360] loss: 0.522\n",
      "Epoch: 3 -> Loss: 0.61695933342\n",
      "Epoch: 3 -> Test Accuracy: 81.56\n",
      "[4, 60] loss: 0.476\n",
      "[4, 120] loss: 0.482\n",
      "[4, 180] loss: 0.488\n",
      "[4, 240] loss: 0.503\n",
      "[4, 300] loss: 0.496\n",
      "[4, 360] loss: 0.492\n",
      "Epoch: 4 -> Loss: 0.431643635035\n",
      "Epoch: 4 -> Test Accuracy: 81.96\n",
      "[5, 60] loss: 0.474\n",
      "[5, 120] loss: 0.452\n",
      "[5, 180] loss: 0.449\n",
      "[5, 240] loss: 0.460\n",
      "[5, 300] loss: 0.468\n",
      "[5, 360] loss: 0.465\n",
      "Epoch: 5 -> Loss: 0.389506667852\n",
      "Epoch: 5 -> Test Accuracy: 82.29\n",
      "[6, 60] loss: 0.446\n",
      "[6, 120] loss: 0.437\n",
      "[6, 180] loss: 0.443\n",
      "[6, 240] loss: 0.456\n",
      "[6, 300] loss: 0.451\n",
      "[6, 360] loss: 0.444\n",
      "Epoch: 6 -> Loss: 0.610335230827\n",
      "Epoch: 6 -> Test Accuracy: 82.89\n",
      "[7, 60] loss: 0.417\n",
      "[7, 120] loss: 0.425\n",
      "[7, 180] loss: 0.444\n",
      "[7, 240] loss: 0.443\n",
      "[7, 300] loss: 0.440\n",
      "[7, 360] loss: 0.439\n",
      "Epoch: 7 -> Loss: 0.396539568901\n",
      "Epoch: 7 -> Test Accuracy: 83.34\n",
      "[8, 60] loss: 0.402\n",
      "[8, 120] loss: 0.404\n",
      "[8, 180] loss: 0.430\n",
      "[8, 240] loss: 0.446\n",
      "[8, 300] loss: 0.424\n",
      "[8, 360] loss: 0.433\n",
      "Epoch: 8 -> Loss: 0.314007163048\n",
      "Epoch: 8 -> Test Accuracy: 83.49\n",
      "[9, 60] loss: 0.411\n",
      "[9, 120] loss: 0.423\n",
      "[9, 180] loss: 0.405\n",
      "[9, 240] loss: 0.428\n",
      "[9, 300] loss: 0.414\n",
      "[9, 360] loss: 0.421\n",
      "Epoch: 9 -> Loss: 0.441345781088\n",
      "Epoch: 9 -> Test Accuracy: 83.0\n",
      "[10, 60] loss: 0.393\n",
      "[10, 120] loss: 0.407\n",
      "[10, 180] loss: 0.401\n",
      "[10, 240] loss: 0.408\n",
      "[10, 300] loss: 0.399\n",
      "[10, 360] loss: 0.413\n",
      "Epoch: 10 -> Loss: 0.480906963348\n",
      "Epoch: 10 -> Test Accuracy: 83.01\n",
      "[11, 60] loss: 0.394\n",
      "[11, 120] loss: 0.404\n",
      "[11, 180] loss: 0.390\n",
      "[11, 240] loss: 0.416\n",
      "[11, 300] loss: 0.406\n",
      "[11, 360] loss: 0.419\n",
      "Epoch: 11 -> Loss: 0.474487006664\n",
      "Epoch: 11 -> Test Accuracy: 83.1\n",
      "[12, 60] loss: 0.374\n",
      "[12, 120] loss: 0.396\n",
      "[12, 180] loss: 0.386\n",
      "[12, 240] loss: 0.390\n",
      "[12, 300] loss: 0.411\n",
      "[12, 360] loss: 0.416\n",
      "Epoch: 12 -> Loss: 0.514926850796\n",
      "Epoch: 12 -> Test Accuracy: 83.13\n",
      "[13, 60] loss: 0.380\n",
      "[13, 120] loss: 0.389\n",
      "[13, 180] loss: 0.379\n",
      "[13, 240] loss: 0.397\n",
      "[13, 300] loss: 0.402\n",
      "[13, 360] loss: 0.407\n",
      "Epoch: 13 -> Loss: 0.53812456131\n",
      "Epoch: 13 -> Test Accuracy: 83.73\n",
      "[14, 60] loss: 0.367\n",
      "[14, 120] loss: 0.367\n",
      "[14, 180] loss: 0.381\n",
      "[14, 240] loss: 0.399\n",
      "[14, 300] loss: 0.405\n",
      "[14, 360] loss: 0.404\n",
      "Epoch: 14 -> Loss: 0.385162442923\n",
      "Epoch: 14 -> Test Accuracy: 83.65\n",
      "[15, 60] loss: 0.371\n",
      "[15, 120] loss: 0.385\n",
      "[15, 180] loss: 0.372\n",
      "[15, 240] loss: 0.369\n",
      "[15, 300] loss: 0.393\n",
      "[15, 360] loss: 0.386\n",
      "Epoch: 15 -> Loss: 0.316706269979\n",
      "Epoch: 15 -> Test Accuracy: 83.93\n",
      "[16, 60] loss: 0.368\n",
      "[16, 120] loss: 0.358\n",
      "[16, 180] loss: 0.377\n",
      "[16, 240] loss: 0.386\n",
      "[16, 300] loss: 0.379\n",
      "[16, 360] loss: 0.411\n",
      "Epoch: 16 -> Loss: 0.328259915113\n",
      "Epoch: 16 -> Test Accuracy: 83.35\n",
      "[17, 60] loss: 0.363\n",
      "[17, 120] loss: 0.368\n",
      "[17, 180] loss: 0.389\n",
      "[17, 240] loss: 0.389\n",
      "[17, 300] loss: 0.393\n",
      "[17, 360] loss: 0.385\n",
      "Epoch: 17 -> Loss: 0.265327006578\n",
      "Epoch: 17 -> Test Accuracy: 83.58\n",
      "[18, 60] loss: 0.350\n",
      "[18, 120] loss: 0.358\n",
      "[18, 180] loss: 0.375\n",
      "[18, 240] loss: 0.369\n",
      "[18, 300] loss: 0.378\n",
      "[18, 360] loss: 0.399\n",
      "Epoch: 18 -> Loss: 0.403873622417\n",
      "Epoch: 18 -> Test Accuracy: 83.41\n",
      "[19, 60] loss: 0.356\n",
      "[19, 120] loss: 0.370\n",
      "[19, 180] loss: 0.367\n",
      "[19, 240] loss: 0.377\n",
      "[19, 300] loss: 0.389\n",
      "[19, 360] loss: 0.379\n",
      "Epoch: 19 -> Loss: 0.275705337524\n",
      "Epoch: 19 -> Test Accuracy: 84.02\n",
      "[20, 60] loss: 0.357\n",
      "[20, 120] loss: 0.371\n",
      "[20, 180] loss: 0.363\n",
      "[20, 240] loss: 0.372\n",
      "[20, 300] loss: 0.374\n",
      "[20, 360] loss: 0.386\n",
      "Epoch: 20 -> Loss: 0.22891266644\n",
      "Epoch: 20 -> Test Accuracy: 83.67\n",
      "[21, 60] loss: 0.324\n",
      "[21, 120] loss: 0.296\n",
      "[21, 180] loss: 0.311\n",
      "[21, 240] loss: 0.291\n",
      "[21, 300] loss: 0.282\n",
      "[21, 360] loss: 0.296\n",
      "Epoch: 21 -> Loss: 0.255854070187\n",
      "Epoch: 21 -> Test Accuracy: 85.82\n",
      "[22, 60] loss: 0.273\n",
      "[22, 120] loss: 0.255\n",
      "[22, 180] loss: 0.264\n",
      "[22, 240] loss: 0.266\n",
      "[22, 300] loss: 0.262\n",
      "[22, 360] loss: 0.277\n",
      "Epoch: 22 -> Loss: 0.247487828135\n",
      "Epoch: 22 -> Test Accuracy: 86.02\n",
      "[23, 60] loss: 0.257\n",
      "[23, 120] loss: 0.240\n",
      "[23, 180] loss: 0.257\n",
      "[23, 240] loss: 0.248\n",
      "[23, 300] loss: 0.266\n",
      "[23, 360] loss: 0.242\n",
      "Epoch: 23 -> Loss: 0.160983771086\n",
      "Epoch: 23 -> Test Accuracy: 86.01\n",
      "[24, 60] loss: 0.237\n",
      "[24, 120] loss: 0.227\n",
      "[24, 180] loss: 0.230\n",
      "[24, 240] loss: 0.238\n",
      "[24, 300] loss: 0.232\n",
      "[24, 360] loss: 0.231\n",
      "Epoch: 24 -> Loss: 0.303112655878\n",
      "Epoch: 24 -> Test Accuracy: 85.82\n",
      "[25, 60] loss: 0.225\n",
      "[25, 120] loss: 0.231\n",
      "[25, 180] loss: 0.218\n",
      "[25, 240] loss: 0.241\n",
      "[25, 300] loss: 0.236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 360] loss: 0.226\n",
      "Epoch: 25 -> Loss: 0.182897120714\n",
      "Epoch: 25 -> Test Accuracy: 86.35\n",
      "[26, 60] loss: 0.204\n",
      "[26, 120] loss: 0.220\n",
      "[26, 180] loss: 0.206\n",
      "[26, 240] loss: 0.238\n",
      "[26, 300] loss: 0.235\n",
      "[26, 360] loss: 0.225\n",
      "Epoch: 26 -> Loss: 0.191764861345\n",
      "Epoch: 26 -> Test Accuracy: 86.36\n",
      "[27, 60] loss: 0.212\n",
      "[27, 120] loss: 0.200\n",
      "[27, 180] loss: 0.220\n",
      "[27, 240] loss: 0.213\n",
      "[27, 300] loss: 0.234\n",
      "[27, 360] loss: 0.222\n",
      "Epoch: 27 -> Loss: 0.384246259928\n",
      "Epoch: 27 -> Test Accuracy: 86.11\n",
      "[28, 60] loss: 0.202\n",
      "[28, 120] loss: 0.211\n",
      "[28, 180] loss: 0.222\n",
      "[28, 240] loss: 0.216\n",
      "[28, 300] loss: 0.207\n",
      "[28, 360] loss: 0.216\n",
      "Epoch: 28 -> Loss: 0.213461995125\n",
      "Epoch: 28 -> Test Accuracy: 86.16\n",
      "[29, 60] loss: 0.197\n",
      "[29, 120] loss: 0.203\n",
      "[29, 180] loss: 0.207\n",
      "[29, 240] loss: 0.209\n",
      "[29, 300] loss: 0.221\n",
      "[29, 360] loss: 0.211\n",
      "Epoch: 29 -> Loss: 0.197112932801\n",
      "Epoch: 29 -> Test Accuracy: 85.57\n",
      "[30, 60] loss: 0.199\n",
      "[30, 120] loss: 0.182\n",
      "[30, 180] loss: 0.210\n",
      "[30, 240] loss: 0.209\n",
      "[30, 300] loss: 0.211\n",
      "[30, 360] loss: 0.200\n",
      "Epoch: 30 -> Loss: 0.160024106503\n",
      "Epoch: 30 -> Test Accuracy: 85.47\n",
      "[31, 60] loss: 0.200\n",
      "[31, 120] loss: 0.191\n",
      "[31, 180] loss: 0.210\n",
      "[31, 240] loss: 0.194\n",
      "[31, 300] loss: 0.196\n",
      "[31, 360] loss: 0.212\n",
      "Epoch: 31 -> Loss: 0.324800670147\n",
      "Epoch: 31 -> Test Accuracy: 86.23\n",
      "[32, 60] loss: 0.187\n",
      "[32, 120] loss: 0.198\n",
      "[32, 180] loss: 0.201\n",
      "[32, 240] loss: 0.197\n",
      "[32, 300] loss: 0.212\n",
      "[32, 360] loss: 0.212\n",
      "Epoch: 32 -> Loss: 0.214083716273\n",
      "Epoch: 32 -> Test Accuracy: 85.47\n",
      "[33, 60] loss: 0.189\n",
      "[33, 120] loss: 0.213\n",
      "[33, 180] loss: 0.195\n",
      "[33, 240] loss: 0.203\n",
      "[33, 300] loss: 0.216\n",
      "[33, 360] loss: 0.211\n",
      "Epoch: 33 -> Loss: 0.264400303364\n",
      "Epoch: 33 -> Test Accuracy: 84.89\n",
      "[34, 60] loss: 0.200\n",
      "[34, 120] loss: 0.206\n",
      "[34, 180] loss: 0.189\n",
      "[34, 240] loss: 0.196\n",
      "[34, 300] loss: 0.208\n",
      "[34, 360] loss: 0.209\n",
      "Epoch: 34 -> Loss: 0.255374193192\n",
      "Epoch: 34 -> Test Accuracy: 85.63\n",
      "[35, 60] loss: 0.189\n",
      "[35, 120] loss: 0.195\n",
      "[35, 180] loss: 0.198\n",
      "[35, 240] loss: 0.201\n",
      "[35, 300] loss: 0.196\n",
      "[35, 360] loss: 0.212\n",
      "Epoch: 35 -> Loss: 0.246921777725\n",
      "Epoch: 35 -> Test Accuracy: 85.04\n",
      "[36, 60] loss: 0.188\n",
      "[36, 120] loss: 0.192\n",
      "[36, 180] loss: 0.201\n",
      "[36, 240] loss: 0.212\n",
      "[36, 300] loss: 0.192\n",
      "[36, 360] loss: 0.208\n",
      "Epoch: 36 -> Loss: 0.180636763573\n",
      "Epoch: 36 -> Test Accuracy: 85.41\n",
      "[37, 60] loss: 0.180\n",
      "[37, 120] loss: 0.174\n",
      "[37, 180] loss: 0.191\n",
      "[37, 240] loss: 0.199\n",
      "[37, 300] loss: 0.208\n",
      "[37, 360] loss: 0.212\n",
      "Epoch: 37 -> Loss: 0.182334691286\n",
      "Epoch: 37 -> Test Accuracy: 85.2\n",
      "[38, 60] loss: 0.185\n",
      "[38, 120] loss: 0.187\n",
      "[38, 180] loss: 0.205\n",
      "[38, 240] loss: 0.209\n",
      "[38, 300] loss: 0.195\n",
      "[38, 360] loss: 0.216\n",
      "Epoch: 38 -> Loss: 0.238036587834\n",
      "Epoch: 38 -> Test Accuracy: 85.39\n",
      "[39, 60] loss: 0.185\n",
      "[39, 120] loss: 0.185\n",
      "[39, 180] loss: 0.202\n",
      "[39, 240] loss: 0.194\n",
      "[39, 300] loss: 0.204\n",
      "[39, 360] loss: 0.206\n",
      "Epoch: 39 -> Loss: 0.160474777222\n",
      "Epoch: 39 -> Test Accuracy: 85.67\n",
      "[40, 60] loss: 0.199\n",
      "[40, 120] loss: 0.191\n",
      "[40, 180] loss: 0.193\n",
      "[40, 240] loss: 0.197\n",
      "[40, 300] loss: 0.204\n",
      "[40, 360] loss: 0.201\n",
      "Epoch: 40 -> Loss: 0.187443897128\n",
      "Epoch: 40 -> Test Accuracy: 85.39\n",
      "[41, 60] loss: 0.173\n",
      "[41, 120] loss: 0.167\n",
      "[41, 180] loss: 0.163\n",
      "[41, 240] loss: 0.167\n",
      "[41, 300] loss: 0.157\n",
      "[41, 360] loss: 0.165\n",
      "Epoch: 41 -> Loss: 0.168841943145\n",
      "Epoch: 41 -> Test Accuracy: 86.09\n",
      "[42, 60] loss: 0.141\n",
      "[42, 120] loss: 0.154\n",
      "[42, 180] loss: 0.145\n",
      "[42, 240] loss: 0.146\n",
      "[42, 300] loss: 0.143\n",
      "[42, 360] loss: 0.147\n",
      "Epoch: 42 -> Loss: 0.230678990483\n",
      "Epoch: 42 -> Test Accuracy: 85.84\n",
      "[43, 60] loss: 0.139\n",
      "[43, 120] loss: 0.140\n",
      "[43, 180] loss: 0.137\n",
      "[43, 240] loss: 0.143\n",
      "[43, 300] loss: 0.126\n",
      "[43, 360] loss: 0.136\n",
      "Epoch: 43 -> Loss: 0.225089401007\n",
      "Epoch: 43 -> Test Accuracy: 86.21\n",
      "[44, 60] loss: 0.122\n",
      "[44, 120] loss: 0.136\n",
      "[44, 180] loss: 0.132\n",
      "[44, 240] loss: 0.131\n",
      "[44, 300] loss: 0.139\n",
      "[44, 360] loss: 0.128\n",
      "Epoch: 44 -> Loss: 0.200444370508\n",
      "Epoch: 44 -> Test Accuracy: 86.37\n",
      "[45, 60] loss: 0.133\n",
      "[45, 120] loss: 0.130\n",
      "[45, 180] loss: 0.130\n",
      "[45, 240] loss: 0.138\n",
      "[45, 300] loss: 0.122\n",
      "[45, 360] loss: 0.132\n",
      "Epoch: 45 -> Loss: 0.0834670290351\n",
      "Epoch: 45 -> Test Accuracy: 86.25\n",
      "[46, 60] loss: 0.126\n",
      "[46, 120] loss: 0.128\n",
      "[46, 180] loss: 0.120\n",
      "[46, 240] loss: 0.126\n",
      "[46, 300] loss: 0.119\n",
      "[46, 360] loss: 0.107\n",
      "Epoch: 46 -> Loss: 0.0536660328507\n",
      "Epoch: 46 -> Test Accuracy: 86.29\n",
      "[47, 60] loss: 0.122\n",
      "[47, 120] loss: 0.114\n",
      "[47, 180] loss: 0.116\n",
      "[47, 240] loss: 0.116\n",
      "[47, 300] loss: 0.113\n",
      "[47, 360] loss: 0.123\n",
      "Epoch: 47 -> Loss: 0.184636071324\n",
      "Epoch: 47 -> Test Accuracy: 86.3\n",
      "[48, 60] loss: 0.110\n",
      "[48, 120] loss: 0.108\n",
      "[48, 180] loss: 0.111\n",
      "[48, 240] loss: 0.119\n",
      "[48, 300] loss: 0.126\n",
      "[48, 360] loss: 0.120\n",
      "Epoch: 48 -> Loss: 0.054202824831\n",
      "Epoch: 48 -> Test Accuracy: 86.34\n",
      "[49, 60] loss: 0.120\n",
      "[49, 120] loss: 0.110\n",
      "[49, 180] loss: 0.115\n",
      "[49, 240] loss: 0.118\n",
      "[49, 300] loss: 0.111\n",
      "[49, 360] loss: 0.110\n",
      "Epoch: 49 -> Loss: 0.122256204486\n",
      "Epoch: 49 -> Test Accuracy: 86.31\n",
      "[50, 60] loss: 0.115\n",
      "[50, 120] loss: 0.125\n",
      "[50, 180] loss: 0.109\n",
      "[50, 240] loss: 0.112\n",
      "[50, 300] loss: 0.118\n",
      "[50, 360] loss: 0.108\n",
      "Epoch: 50 -> Loss: 0.117869153619\n",
      "Epoch: 50 -> Test Accuracy: 86.31\n",
      "[51, 60] loss: 0.114\n",
      "[51, 120] loss: 0.120\n",
      "[51, 180] loss: 0.109\n",
      "[51, 240] loss: 0.116\n",
      "[51, 300] loss: 0.116\n",
      "[51, 360] loss: 0.109\n",
      "Epoch: 51 -> Loss: 0.113590955734\n",
      "Epoch: 51 -> Test Accuracy: 86.33\n",
      "[52, 60] loss: 0.112\n",
      "[52, 120] loss: 0.104\n",
      "[52, 180] loss: 0.114\n",
      "[52, 240] loss: 0.108\n",
      "[52, 300] loss: 0.110\n",
      "[52, 360] loss: 0.116\n",
      "Epoch: 52 -> Loss: 0.165630787611\n",
      "Epoch: 52 -> Test Accuracy: 86.32\n",
      "[53, 60] loss: 0.106\n",
      "[53, 120] loss: 0.111\n",
      "[53, 180] loss: 0.110\n",
      "[53, 240] loss: 0.116\n",
      "[53, 300] loss: 0.118\n",
      "[53, 360] loss: 0.101\n",
      "Epoch: 53 -> Loss: 0.107637666166\n",
      "Epoch: 53 -> Test Accuracy: 86.3\n",
      "[54, 60] loss: 0.108\n",
      "[54, 120] loss: 0.114\n",
      "[54, 180] loss: 0.116\n",
      "[54, 240] loss: 0.111\n",
      "[54, 300] loss: 0.099\n",
      "[54, 360] loss: 0.112\n",
      "Epoch: 54 -> Loss: 0.121674194932\n",
      "Epoch: 54 -> Test Accuracy: 86.29\n",
      "[55, 60] loss: 0.105\n",
      "[55, 120] loss: 0.107\n",
      "[55, 180] loss: 0.109\n",
      "[55, 240] loss: 0.114\n",
      "[55, 300] loss: 0.108\n",
      "[55, 360] loss: 0.104\n",
      "Epoch: 55 -> Loss: 0.167022451758\n",
      "Epoch: 55 -> Test Accuracy: 86.37\n",
      "[56, 60] loss: 0.110\n",
      "[56, 120] loss: 0.104\n",
      "[56, 180] loss: 0.106\n",
      "[56, 240] loss: 0.111\n",
      "[56, 300] loss: 0.100\n",
      "[56, 360] loss: 0.120\n",
      "Epoch: 56 -> Loss: 0.0955591648817\n",
      "Epoch: 56 -> Test Accuracy: 86.37\n",
      "[57, 60] loss: 0.109\n",
      "[57, 120] loss: 0.106\n",
      "[57, 180] loss: 0.095\n",
      "[57, 240] loss: 0.107\n",
      "[57, 300] loss: 0.104\n",
      "[57, 360] loss: 0.103\n",
      "Epoch: 57 -> Loss: 0.165836632252\n",
      "Epoch: 57 -> Test Accuracy: 86.32\n",
      "[58, 60] loss: 0.099\n",
      "[58, 120] loss: 0.100\n",
      "[58, 180] loss: 0.101\n",
      "[58, 240] loss: 0.101\n",
      "[58, 300] loss: 0.104\n",
      "[58, 360] loss: 0.100\n",
      "Epoch: 58 -> Loss: 0.0825623422861\n",
      "Epoch: 58 -> Test Accuracy: 86.33\n",
      "[59, 60] loss: 0.104\n",
      "[59, 120] loss: 0.107\n",
      "[59, 180] loss: 0.100\n",
      "[59, 240] loss: 0.104\n",
      "[59, 300] loss: 0.097\n",
      "[59, 360] loss: 0.101\n",
      "Epoch: 59 -> Loss: 0.102952122688\n",
      "Epoch: 59 -> Test Accuracy: 86.31\n",
      "[60, 60] loss: 0.102\n",
      "[60, 120] loss: 0.104\n",
      "[60, 180] loss: 0.107\n",
      "[60, 240] loss: 0.103\n",
      "[60, 300] loss: 0.100\n",
      "[60, 360] loss: 0.104\n",
      "Epoch: 60 -> Loss: 0.163744688034\n",
      "Epoch: 60 -> Test Accuracy: 86.27\n",
      "[61, 60] loss: 0.098\n",
      "[61, 120] loss: 0.108\n",
      "[61, 180] loss: 0.103\n",
      "[61, 240] loss: 0.109\n",
      "[61, 300] loss: 0.109\n",
      "[61, 360] loss: 0.098\n",
      "Epoch: 61 -> Loss: 0.175240173936\n",
      "Epoch: 61 -> Test Accuracy: 86.26\n",
      "[62, 60] loss: 0.100\n",
      "[62, 120] loss: 0.096\n",
      "[62, 180] loss: 0.111\n",
      "[62, 240] loss: 0.092\n",
      "[62, 300] loss: 0.101\n",
      "[62, 360] loss: 0.093\n",
      "Epoch: 62 -> Loss: 0.148496717215\n",
      "Epoch: 62 -> Test Accuracy: 86.41\n",
      "[63, 60] loss: 0.098\n",
      "[63, 120] loss: 0.096\n",
      "[63, 180] loss: 0.107\n",
      "[63, 240] loss: 0.099\n",
      "[63, 300] loss: 0.104\n",
      "[63, 360] loss: 0.096\n",
      "Epoch: 63 -> Loss: 0.125284746289\n",
      "Epoch: 63 -> Test Accuracy: 86.32\n",
      "[64, 60] loss: 0.097\n",
      "[64, 120] loss: 0.097\n",
      "[64, 180] loss: 0.099\n",
      "[64, 240] loss: 0.096\n",
      "[64, 300] loss: 0.095\n",
      "[64, 360] loss: 0.099\n",
      "Epoch: 64 -> Loss: 0.144953861833\n",
      "Epoch: 64 -> Test Accuracy: 86.34\n",
      "[65, 60] loss: 0.102\n",
      "[65, 120] loss: 0.099\n",
      "[65, 180] loss: 0.102\n",
      "[65, 240] loss: 0.106\n",
      "[65, 300] loss: 0.100\n",
      "[65, 360] loss: 0.105\n",
      "Epoch: 65 -> Loss: 0.0787519961596\n",
      "Epoch: 65 -> Test Accuracy: 86.36\n",
      "[66, 60] loss: 0.091\n",
      "[66, 120] loss: 0.106\n",
      "[66, 180] loss: 0.097\n",
      "[66, 240] loss: 0.097\n",
      "[66, 300] loss: 0.103\n",
      "[66, 360] loss: 0.088\n",
      "Epoch: 66 -> Loss: 0.07210727036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Test Accuracy: 86.26\n",
      "[67, 60] loss: 0.103\n",
      "[67, 120] loss: 0.095\n",
      "[67, 180] loss: 0.096\n",
      "[67, 240] loss: 0.091\n",
      "[67, 300] loss: 0.100\n",
      "[67, 360] loss: 0.096\n",
      "Epoch: 67 -> Loss: 0.0488171167672\n",
      "Epoch: 67 -> Test Accuracy: 86.39\n",
      "[68, 60] loss: 0.096\n",
      "[68, 120] loss: 0.097\n",
      "[68, 180] loss: 0.103\n",
      "[68, 240] loss: 0.098\n",
      "[68, 300] loss: 0.101\n",
      "[68, 360] loss: 0.098\n",
      "Epoch: 68 -> Loss: 0.115463376045\n",
      "Epoch: 68 -> Test Accuracy: 86.36\n",
      "[69, 60] loss: 0.093\n",
      "[69, 120] loss: 0.102\n",
      "[69, 180] loss: 0.098\n",
      "[69, 240] loss: 0.096\n",
      "[69, 300] loss: 0.094\n",
      "[69, 360] loss: 0.102\n",
      "Epoch: 69 -> Loss: 0.0813453048468\n",
      "Epoch: 69 -> Test Accuracy: 86.32\n",
      "[70, 60] loss: 0.089\n",
      "[70, 120] loss: 0.089\n",
      "[70, 180] loss: 0.090\n",
      "[70, 240] loss: 0.097\n",
      "[70, 300] loss: 0.094\n",
      "[70, 360] loss: 0.102\n",
      "Epoch: 70 -> Loss: 0.0443096607924\n",
      "Epoch: 70 -> Test Accuracy: 86.38\n",
      "[71, 60] loss: 0.096\n",
      "[71, 120] loss: 0.094\n",
      "[71, 180] loss: 0.090\n",
      "[71, 240] loss: 0.096\n",
      "[71, 300] loss: 0.090\n",
      "[71, 360] loss: 0.093\n",
      "Epoch: 71 -> Loss: 0.0764009803534\n",
      "Epoch: 71 -> Test Accuracy: 86.36\n",
      "[72, 60] loss: 0.084\n",
      "[72, 120] loss: 0.090\n",
      "[72, 180] loss: 0.090\n",
      "[72, 240] loss: 0.088\n",
      "[72, 300] loss: 0.100\n",
      "[72, 360] loss: 0.102\n",
      "Epoch: 72 -> Loss: 0.0384293906391\n",
      "Epoch: 72 -> Test Accuracy: 86.23\n",
      "[73, 60] loss: 0.097\n",
      "[73, 120] loss: 0.090\n",
      "[73, 180] loss: 0.094\n",
      "[73, 240] loss: 0.085\n",
      "[73, 300] loss: 0.089\n",
      "[73, 360] loss: 0.101\n",
      "Epoch: 73 -> Loss: 0.115447118878\n",
      "Epoch: 73 -> Test Accuracy: 86.35\n",
      "[74, 60] loss: 0.091\n",
      "[74, 120] loss: 0.090\n",
      "[74, 180] loss: 0.090\n",
      "[74, 240] loss: 0.098\n",
      "[74, 300] loss: 0.098\n",
      "[74, 360] loss: 0.094\n",
      "Epoch: 74 -> Loss: 0.0749593526125\n",
      "Epoch: 74 -> Test Accuracy: 86.28\n",
      "[75, 60] loss: 0.090\n",
      "[75, 120] loss: 0.088\n",
      "[75, 180] loss: 0.092\n",
      "[75, 240] loss: 0.087\n",
      "[75, 300] loss: 0.086\n",
      "[75, 360] loss: 0.093\n",
      "Epoch: 75 -> Loss: 0.0644688084722\n",
      "Epoch: 75 -> Test Accuracy: 86.28\n",
      "[76, 60] loss: 0.096\n",
      "[76, 120] loss: 0.087\n",
      "[76, 180] loss: 0.087\n",
      "[76, 240] loss: 0.088\n",
      "[76, 300] loss: 0.086\n",
      "[76, 360] loss: 0.092\n",
      "Epoch: 76 -> Loss: 0.147222578526\n",
      "Epoch: 76 -> Test Accuracy: 86.35\n",
      "[77, 60] loss: 0.089\n",
      "[77, 120] loss: 0.086\n",
      "[77, 180] loss: 0.092\n",
      "[77, 240] loss: 0.092\n",
      "[77, 300] loss: 0.094\n",
      "[77, 360] loss: 0.089\n",
      "Epoch: 77 -> Loss: 0.0586154684424\n",
      "Epoch: 77 -> Test Accuracy: 86.45\n",
      "[78, 60] loss: 0.094\n",
      "[78, 120] loss: 0.090\n",
      "[78, 180] loss: 0.092\n",
      "[78, 240] loss: 0.084\n",
      "[78, 300] loss: 0.092\n",
      "[78, 360] loss: 0.088\n",
      "Epoch: 78 -> Loss: 0.0227459724993\n",
      "Epoch: 78 -> Test Accuracy: 86.34\n",
      "[79, 60] loss: 0.089\n",
      "[79, 120] loss: 0.085\n",
      "[79, 180] loss: 0.086\n",
      "[79, 240] loss: 0.086\n",
      "[79, 300] loss: 0.084\n",
      "[79, 360] loss: 0.085\n",
      "Epoch: 79 -> Loss: 0.0575455650687\n",
      "Epoch: 79 -> Test Accuracy: 86.41\n",
      "[80, 60] loss: 0.087\n",
      "[80, 120] loss: 0.088\n",
      "[80, 180] loss: 0.088\n",
      "[80, 240] loss: 0.086\n",
      "[80, 300] loss: 0.085\n",
      "[80, 360] loss: 0.086\n",
      "Epoch: 80 -> Loss: 0.108354747295\n",
      "Epoch: 80 -> Test Accuracy: 86.38\n",
      "[81, 60] loss: 0.086\n",
      "[81, 120] loss: 0.094\n",
      "[81, 180] loss: 0.086\n",
      "[81, 240] loss: 0.086\n",
      "[81, 300] loss: 0.082\n",
      "[81, 360] loss: 0.086\n",
      "Epoch: 81 -> Loss: 0.08481515944\n",
      "Epoch: 81 -> Test Accuracy: 86.3\n",
      "[82, 60] loss: 0.090\n",
      "[82, 120] loss: 0.085\n",
      "[82, 180] loss: 0.089\n",
      "[82, 240] loss: 0.084\n",
      "[82, 300] loss: 0.089\n",
      "[82, 360] loss: 0.090\n",
      "Epoch: 82 -> Loss: 0.0632436499\n",
      "Epoch: 82 -> Test Accuracy: 86.27\n",
      "[83, 60] loss: 0.092\n",
      "[83, 120] loss: 0.086\n",
      "[83, 180] loss: 0.083\n",
      "[83, 240] loss: 0.080\n",
      "[83, 300] loss: 0.081\n",
      "[83, 360] loss: 0.080\n",
      "Epoch: 83 -> Loss: 0.0581690147519\n",
      "Epoch: 83 -> Test Accuracy: 86.29\n",
      "[84, 60] loss: 0.081\n",
      "[84, 120] loss: 0.085\n",
      "[84, 180] loss: 0.089\n",
      "[84, 240] loss: 0.084\n",
      "[84, 300] loss: 0.092\n",
      "[84, 360] loss: 0.084\n",
      "Epoch: 84 -> Loss: 0.11943795532\n",
      "Epoch: 84 -> Test Accuracy: 86.25\n",
      "[85, 60] loss: 0.085\n",
      "[85, 120] loss: 0.084\n",
      "[85, 180] loss: 0.084\n",
      "[85, 240] loss: 0.088\n",
      "[85, 300] loss: 0.077\n",
      "[85, 360] loss: 0.085\n",
      "Epoch: 85 -> Loss: 0.166458413005\n",
      "Epoch: 85 -> Test Accuracy: 86.23\n",
      "[86, 60] loss: 0.082\n",
      "[86, 120] loss: 0.088\n",
      "[86, 180] loss: 0.079\n",
      "[86, 240] loss: 0.085\n",
      "[86, 300] loss: 0.082\n",
      "[86, 360] loss: 0.085\n",
      "Epoch: 86 -> Loss: 0.0553410947323\n",
      "Epoch: 86 -> Test Accuracy: 86.09\n",
      "[87, 60] loss: 0.081\n",
      "[87, 120] loss: 0.083\n",
      "[87, 180] loss: 0.078\n",
      "[87, 240] loss: 0.082\n",
      "[87, 300] loss: 0.080\n",
      "[87, 360] loss: 0.081\n",
      "Epoch: 87 -> Loss: 0.125213846564\n",
      "Epoch: 87 -> Test Accuracy: 86.22\n",
      "[88, 60] loss: 0.081\n",
      "[88, 120] loss: 0.082\n",
      "[88, 180] loss: 0.089\n",
      "[88, 240] loss: 0.081\n",
      "[88, 300] loss: 0.079\n",
      "[88, 360] loss: 0.077\n",
      "Epoch: 88 -> Loss: 0.0753725767136\n",
      "Epoch: 88 -> Test Accuracy: 86.17\n",
      "[89, 60] loss: 0.080\n",
      "[89, 120] loss: 0.084\n",
      "[89, 180] loss: 0.080\n",
      "[89, 240] loss: 0.075\n",
      "[89, 300] loss: 0.084\n",
      "[89, 360] loss: 0.081\n",
      "Epoch: 89 -> Loss: 0.105984352529\n",
      "Epoch: 89 -> Test Accuracy: 86.27\n",
      "[90, 60] loss: 0.079\n",
      "[90, 120] loss: 0.080\n",
      "[90, 180] loss: 0.087\n",
      "[90, 240] loss: 0.082\n",
      "[90, 300] loss: 0.087\n",
      "[90, 360] loss: 0.081\n",
      "Epoch: 90 -> Loss: 0.0807774960995\n",
      "Epoch: 90 -> Test Accuracy: 86.25\n",
      "[91, 60] loss: 0.083\n",
      "[91, 120] loss: 0.085\n",
      "[91, 180] loss: 0.080\n",
      "[91, 240] loss: 0.078\n",
      "[91, 300] loss: 0.079\n",
      "[91, 360] loss: 0.088\n",
      "Epoch: 91 -> Loss: 0.172451466322\n",
      "Epoch: 91 -> Test Accuracy: 86.28\n",
      "[92, 60] loss: 0.084\n",
      "[92, 120] loss: 0.078\n",
      "[92, 180] loss: 0.083\n",
      "[92, 240] loss: 0.075\n",
      "[92, 300] loss: 0.084\n",
      "[92, 360] loss: 0.082\n",
      "Epoch: 92 -> Loss: 0.103992663324\n",
      "Epoch: 92 -> Test Accuracy: 86.27\n",
      "[93, 60] loss: 0.082\n",
      "[93, 120] loss: 0.081\n",
      "[93, 180] loss: 0.090\n",
      "[93, 240] loss: 0.071\n",
      "[93, 300] loss: 0.079\n",
      "[93, 360] loss: 0.078\n",
      "Epoch: 93 -> Loss: 0.140131860971\n",
      "Epoch: 93 -> Test Accuracy: 86.19\n",
      "[94, 60] loss: 0.080\n",
      "[94, 120] loss: 0.078\n",
      "[94, 180] loss: 0.083\n",
      "[94, 240] loss: 0.080\n",
      "[94, 300] loss: 0.078\n",
      "[94, 360] loss: 0.078\n",
      "Epoch: 94 -> Loss: 0.0842392742634\n",
      "Epoch: 94 -> Test Accuracy: 86.18\n",
      "[95, 60] loss: 0.080\n",
      "[95, 120] loss: 0.072\n",
      "[95, 180] loss: 0.081\n",
      "[95, 240] loss: 0.072\n",
      "[95, 300] loss: 0.079\n",
      "[95, 360] loss: 0.072\n",
      "Epoch: 95 -> Loss: 0.0902614146471\n",
      "Epoch: 95 -> Test Accuracy: 86.06\n",
      "[96, 60] loss: 0.077\n",
      "[96, 120] loss: 0.074\n",
      "[96, 180] loss: 0.081\n",
      "[96, 240] loss: 0.081\n",
      "[96, 300] loss: 0.080\n",
      "[96, 360] loss: 0.080\n",
      "Epoch: 96 -> Loss: 0.087632521987\n",
      "Epoch: 96 -> Test Accuracy: 86.17\n",
      "[97, 60] loss: 0.071\n",
      "[97, 120] loss: 0.077\n",
      "[97, 180] loss: 0.077\n",
      "[97, 240] loss: 0.080\n",
      "[97, 300] loss: 0.080\n",
      "[97, 360] loss: 0.074\n",
      "Epoch: 97 -> Loss: 0.102625146508\n",
      "Epoch: 97 -> Test Accuracy: 86.14\n",
      "[98, 60] loss: 0.074\n",
      "[98, 120] loss: 0.077\n",
      "[98, 180] loss: 0.080\n",
      "[98, 240] loss: 0.078\n",
      "[98, 300] loss: 0.084\n",
      "[98, 360] loss: 0.076\n",
      "Epoch: 98 -> Loss: 0.0721199885011\n",
      "Epoch: 98 -> Test Accuracy: 86.12\n",
      "[99, 60] loss: 0.080\n",
      "[99, 120] loss: 0.078\n",
      "[99, 180] loss: 0.075\n",
      "[99, 240] loss: 0.076\n",
      "[99, 300] loss: 0.080\n",
      "[99, 360] loss: 0.070\n",
      "Epoch: 99 -> Loss: 0.0851885676384\n",
      "Epoch: 99 -> Test Accuracy: 86.03\n",
      "[100, 60] loss: 0.076\n",
      "[100, 120] loss: 0.079\n",
      "[100, 180] loss: 0.070\n",
      "[100, 240] loss: 0.079\n",
      "[100, 300] loss: 0.070\n",
      "[100, 360] loss: 0.074\n",
      "Epoch: 100 -> Loss: 0.0908648818731\n",
      "Epoch: 100 -> Test Accuracy: 86.04\n",
      "Finished Training\n",
      "[1, 60] loss: 1.688\n",
      "[1, 120] loss: 0.896\n",
      "[1, 180] loss: 0.823\n",
      "[1, 240] loss: 0.769\n",
      "[1, 300] loss: 0.747\n",
      "[1, 360] loss: 0.706\n",
      "Epoch: 1 -> Loss: 0.753571867943\n",
      "Epoch: 1 -> Test Accuracy: 74.01\n",
      "[2, 60] loss: 0.688\n",
      "[2, 120] loss: 0.669\n",
      "[2, 180] loss: 0.671\n",
      "[2, 240] loss: 0.660\n",
      "[2, 300] loss: 0.651\n",
      "[2, 360] loss: 0.644\n",
      "Epoch: 2 -> Loss: 0.822703838348\n",
      "Epoch: 2 -> Test Accuracy: 76.23\n",
      "[3, 60] loss: 0.623\n",
      "[3, 120] loss: 0.617\n",
      "[3, 180] loss: 0.622\n",
      "[3, 240] loss: 0.610\n",
      "[3, 300] loss: 0.595\n",
      "[3, 360] loss: 0.607\n",
      "Epoch: 3 -> Loss: 0.553404450417\n",
      "Epoch: 3 -> Test Accuracy: 76.96\n",
      "[4, 60] loss: 0.570\n",
      "[4, 120] loss: 0.569\n",
      "[4, 180] loss: 0.595\n",
      "[4, 240] loss: 0.579\n",
      "[4, 300] loss: 0.584\n",
      "[4, 360] loss: 0.580\n",
      "Epoch: 4 -> Loss: 0.427854776382\n",
      "Epoch: 4 -> Test Accuracy: 77.91\n",
      "[5, 60] loss: 0.567\n",
      "[5, 120] loss: 0.543\n",
      "[5, 180] loss: 0.562\n",
      "[5, 240] loss: 0.566\n",
      "[5, 300] loss: 0.557\n",
      "[5, 360] loss: 0.552\n",
      "Epoch: 5 -> Loss: 0.702017247677\n",
      "Epoch: 5 -> Test Accuracy: 78.17\n",
      "[6, 60] loss: 0.541\n",
      "[6, 120] loss: 0.544\n",
      "[6, 180] loss: 0.568\n",
      "[6, 240] loss: 0.542\n",
      "[6, 300] loss: 0.558\n",
      "[6, 360] loss: 0.534\n",
      "Epoch: 6 -> Loss: 0.460871130228\n",
      "Epoch: 6 -> Test Accuracy: 77.67\n",
      "[7, 60] loss: 0.535\n",
      "[7, 120] loss: 0.541\n",
      "[7, 180] loss: 0.521\n",
      "[7, 240] loss: 0.537\n",
      "[7, 300] loss: 0.525\n",
      "[7, 360] loss: 0.538\n",
      "Epoch: 7 -> Loss: 0.6728733778\n",
      "Epoch: 7 -> Test Accuracy: 78.27\n",
      "[8, 60] loss: 0.521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 120] loss: 0.517\n",
      "[8, 180] loss: 0.514\n",
      "[8, 240] loss: 0.545\n",
      "[8, 300] loss: 0.514\n",
      "[8, 360] loss: 0.532\n",
      "Epoch: 8 -> Loss: 0.636314809322\n",
      "Epoch: 8 -> Test Accuracy: 78.07\n",
      "[9, 60] loss: 0.521\n",
      "[9, 120] loss: 0.510\n",
      "[9, 180] loss: 0.509\n",
      "[9, 240] loss: 0.536\n",
      "[9, 300] loss: 0.516\n",
      "[9, 360] loss: 0.512\n",
      "Epoch: 9 -> Loss: 0.390735328197\n",
      "Epoch: 9 -> Test Accuracy: 79.32\n",
      "[10, 60] loss: 0.492\n",
      "[10, 120] loss: 0.504\n",
      "[10, 180] loss: 0.500\n",
      "[10, 240] loss: 0.501\n",
      "[10, 300] loss: 0.517\n",
      "[10, 360] loss: 0.523\n",
      "Epoch: 10 -> Loss: 0.573737859726\n",
      "Epoch: 10 -> Test Accuracy: 78.61\n",
      "[11, 60] loss: 0.493\n",
      "[11, 120] loss: 0.517\n",
      "[11, 180] loss: 0.505\n",
      "[11, 240] loss: 0.495\n",
      "[11, 300] loss: 0.516\n",
      "[11, 360] loss: 0.518\n",
      "Epoch: 11 -> Loss: 0.59681814909\n",
      "Epoch: 11 -> Test Accuracy: 79.27\n",
      "[12, 60] loss: 0.494\n",
      "[12, 120] loss: 0.496\n",
      "[12, 180] loss: 0.505\n",
      "[12, 240] loss: 0.501\n",
      "[12, 300] loss: 0.511\n",
      "[12, 360] loss: 0.504\n",
      "Epoch: 12 -> Loss: 0.481519162655\n",
      "Epoch: 12 -> Test Accuracy: 79.55\n",
      "[13, 60] loss: 0.464\n",
      "[13, 120] loss: 0.483\n",
      "[13, 180] loss: 0.495\n",
      "[13, 240] loss: 0.514\n",
      "[13, 300] loss: 0.517\n",
      "[13, 360] loss: 0.501\n",
      "Epoch: 13 -> Loss: 0.37342235446\n",
      "Epoch: 13 -> Test Accuracy: 78.23\n",
      "[14, 60] loss: 0.474\n",
      "[14, 120] loss: 0.493\n",
      "[14, 180] loss: 0.483\n",
      "[14, 240] loss: 0.519\n",
      "[14, 300] loss: 0.499\n",
      "[14, 360] loss: 0.487\n",
      "Epoch: 14 -> Loss: 0.378597974777\n",
      "Epoch: 14 -> Test Accuracy: 79.43\n",
      "[15, 60] loss: 0.478\n",
      "[15, 120] loss: 0.495\n",
      "[15, 180] loss: 0.499\n",
      "[15, 240] loss: 0.499\n",
      "[15, 300] loss: 0.499\n",
      "[15, 360] loss: 0.504\n",
      "Epoch: 15 -> Loss: 0.563316047192\n",
      "Epoch: 15 -> Test Accuracy: 79.28\n",
      "[16, 60] loss: 0.482\n",
      "[16, 120] loss: 0.494\n",
      "[16, 180] loss: 0.490\n",
      "[16, 240] loss: 0.493\n",
      "[16, 300] loss: 0.498\n",
      "[16, 360] loss: 0.491\n",
      "Epoch: 16 -> Loss: 0.564153194427\n",
      "Epoch: 16 -> Test Accuracy: 78.98\n",
      "[17, 60] loss: 0.464\n",
      "[17, 120] loss: 0.492\n",
      "[17, 180] loss: 0.477\n",
      "[17, 240] loss: 0.508\n",
      "[17, 300] loss: 0.490\n",
      "[17, 360] loss: 0.492\n",
      "Epoch: 17 -> Loss: 0.463874965906\n",
      "Epoch: 17 -> Test Accuracy: 79.69\n",
      "[18, 60] loss: 0.483\n",
      "[18, 120] loss: 0.471\n",
      "[18, 180] loss: 0.478\n",
      "[18, 240] loss: 0.494\n",
      "[18, 300] loss: 0.473\n",
      "[18, 360] loss: 0.494\n",
      "Epoch: 18 -> Loss: 0.632206916809\n",
      "Epoch: 18 -> Test Accuracy: 79.55\n",
      "[19, 60] loss: 0.472\n",
      "[19, 120] loss: 0.481\n",
      "[19, 180] loss: 0.491\n",
      "[19, 240] loss: 0.481\n",
      "[19, 300] loss: 0.491\n",
      "[19, 360] loss: 0.499\n",
      "Epoch: 19 -> Loss: 0.603734076023\n",
      "Epoch: 19 -> Test Accuracy: 80.06\n",
      "[20, 60] loss: 0.457\n",
      "[20, 120] loss: 0.462\n",
      "[20, 180] loss: 0.487\n",
      "[20, 240] loss: 0.487\n",
      "[20, 300] loss: 0.490\n",
      "[20, 360] loss: 0.495\n",
      "Epoch: 20 -> Loss: 0.37822380662\n",
      "Epoch: 20 -> Test Accuracy: 79.26\n",
      "[21, 60] loss: 0.438\n",
      "[21, 120] loss: 0.424\n",
      "[21, 180] loss: 0.401\n",
      "[21, 240] loss: 0.396\n",
      "[21, 300] loss: 0.419\n",
      "[21, 360] loss: 0.409\n",
      "Epoch: 21 -> Loss: 0.266086220741\n",
      "Epoch: 21 -> Test Accuracy: 80.97\n",
      "[22, 60] loss: 0.387\n",
      "[22, 120] loss: 0.391\n",
      "[22, 180] loss: 0.384\n",
      "[22, 240] loss: 0.386\n",
      "[22, 300] loss: 0.403\n",
      "[22, 360] loss: 0.373\n",
      "Epoch: 22 -> Loss: 0.342135578394\n",
      "Epoch: 22 -> Test Accuracy: 81.31\n",
      "[23, 60] loss: 0.356\n",
      "[23, 120] loss: 0.361\n",
      "[23, 180] loss: 0.363\n",
      "[23, 240] loss: 0.373\n",
      "[23, 300] loss: 0.354\n",
      "[23, 360] loss: 0.373\n",
      "Epoch: 23 -> Loss: 0.302548974752\n",
      "Epoch: 23 -> Test Accuracy: 81.48\n",
      "[24, 60] loss: 0.366\n",
      "[24, 120] loss: 0.370\n",
      "[24, 180] loss: 0.356\n",
      "[24, 240] loss: 0.363\n",
      "[24, 300] loss: 0.362\n",
      "[24, 360] loss: 0.362\n",
      "Epoch: 24 -> Loss: 0.331136524677\n",
      "Epoch: 24 -> Test Accuracy: 81.64\n",
      "[25, 60] loss: 0.359\n",
      "[25, 120] loss: 0.345\n",
      "[25, 180] loss: 0.341\n",
      "[25, 240] loss: 0.353\n",
      "[25, 300] loss: 0.363\n",
      "[25, 360] loss: 0.365\n",
      "Epoch: 25 -> Loss: 0.299855589867\n",
      "Epoch: 25 -> Test Accuracy: 81.49\n",
      "[26, 60] loss: 0.328\n",
      "[26, 120] loss: 0.352\n",
      "[26, 180] loss: 0.346\n",
      "[26, 240] loss: 0.346\n",
      "[26, 300] loss: 0.354\n",
      "[26, 360] loss: 0.340\n",
      "Epoch: 26 -> Loss: 0.352993965149\n",
      "Epoch: 26 -> Test Accuracy: 81.57\n",
      "[27, 60] loss: 0.340\n",
      "[27, 120] loss: 0.337\n",
      "[27, 180] loss: 0.347\n",
      "[27, 240] loss: 0.333\n",
      "[27, 300] loss: 0.345\n",
      "[27, 360] loss: 0.336\n",
      "Epoch: 27 -> Loss: 0.325632810593\n",
      "Epoch: 27 -> Test Accuracy: 81.3\n",
      "[28, 60] loss: 0.321\n",
      "[28, 120] loss: 0.358\n",
      "[28, 180] loss: 0.315\n",
      "[28, 240] loss: 0.336\n",
      "[28, 300] loss: 0.351\n",
      "[28, 360] loss: 0.351\n",
      "Epoch: 28 -> Loss: 0.274193495512\n",
      "Epoch: 28 -> Test Accuracy: 81.08\n",
      "[29, 60] loss: 0.336\n",
      "[29, 120] loss: 0.350\n",
      "[29, 180] loss: 0.334\n",
      "[29, 240] loss: 0.341\n",
      "[29, 300] loss: 0.340\n",
      "[29, 360] loss: 0.348\n",
      "Epoch: 29 -> Loss: 0.48037570715\n",
      "Epoch: 29 -> Test Accuracy: 81.01\n",
      "[30, 60] loss: 0.336\n",
      "[30, 120] loss: 0.344\n",
      "[30, 180] loss: 0.315\n",
      "[30, 240] loss: 0.335\n",
      "[30, 300] loss: 0.328\n",
      "[30, 360] loss: 0.336\n",
      "Epoch: 30 -> Loss: 0.143726050854\n",
      "Epoch: 30 -> Test Accuracy: 81.25\n",
      "[31, 60] loss: 0.311\n",
      "[31, 120] loss: 0.323\n",
      "[31, 180] loss: 0.324\n",
      "[31, 240] loss: 0.335\n",
      "[31, 300] loss: 0.339\n",
      "[31, 360] loss: 0.340\n",
      "Epoch: 31 -> Loss: 0.332631111145\n",
      "Epoch: 31 -> Test Accuracy: 81.21\n",
      "[32, 60] loss: 0.315\n",
      "[32, 120] loss: 0.322\n",
      "[32, 180] loss: 0.334\n",
      "[32, 240] loss: 0.313\n",
      "[32, 300] loss: 0.331\n",
      "[32, 360] loss: 0.335\n",
      "Epoch: 32 -> Loss: 0.357261836529\n",
      "Epoch: 32 -> Test Accuracy: 80.77\n",
      "[33, 60] loss: 0.327\n",
      "[33, 120] loss: 0.311\n",
      "[33, 180] loss: 0.326\n",
      "[33, 240] loss: 0.328\n",
      "[33, 300] loss: 0.335\n",
      "[33, 360] loss: 0.347\n",
      "Epoch: 33 -> Loss: 0.356532514095\n",
      "Epoch: 33 -> Test Accuracy: 81.41\n",
      "[34, 60] loss: 0.319\n",
      "[34, 120] loss: 0.325\n",
      "[34, 180] loss: 0.337\n",
      "[34, 240] loss: 0.330\n",
      "[34, 300] loss: 0.333\n",
      "[34, 360] loss: 0.341\n",
      "Epoch: 34 -> Loss: 0.397627025843\n",
      "Epoch: 34 -> Test Accuracy: 81.13\n",
      "[35, 60] loss: 0.320\n",
      "[35, 120] loss: 0.312\n",
      "[35, 180] loss: 0.323\n",
      "[35, 240] loss: 0.324\n",
      "[35, 300] loss: 0.326\n",
      "[35, 360] loss: 0.329\n",
      "Epoch: 35 -> Loss: 0.35084053874\n",
      "Epoch: 35 -> Test Accuracy: 80.81\n",
      "[36, 60] loss: 0.319\n",
      "[36, 120] loss: 0.318\n",
      "[36, 180] loss: 0.320\n",
      "[36, 240] loss: 0.327\n",
      "[36, 300] loss: 0.328\n",
      "[36, 360] loss: 0.326\n",
      "Epoch: 36 -> Loss: 0.413269847631\n",
      "Epoch: 36 -> Test Accuracy: 81.31\n",
      "[37, 60] loss: 0.324\n",
      "[37, 120] loss: 0.321\n",
      "[37, 180] loss: 0.328\n",
      "[37, 240] loss: 0.313\n",
      "[37, 300] loss: 0.339\n",
      "[37, 360] loss: 0.344\n",
      "Epoch: 37 -> Loss: 0.505464315414\n",
      "Epoch: 37 -> Test Accuracy: 80.82\n",
      "[38, 60] loss: 0.306\n",
      "[38, 120] loss: 0.313\n",
      "[38, 180] loss: 0.314\n",
      "[38, 240] loss: 0.341\n",
      "[38, 300] loss: 0.324\n",
      "[38, 360] loss: 0.339\n",
      "Epoch: 38 -> Loss: 0.368182003498\n",
      "Epoch: 38 -> Test Accuracy: 81.14\n",
      "[39, 60] loss: 0.315\n",
      "[39, 120] loss: 0.308\n",
      "[39, 180] loss: 0.319\n",
      "[39, 240] loss: 0.317\n",
      "[39, 300] loss: 0.337\n",
      "[39, 360] loss: 0.335\n",
      "Epoch: 39 -> Loss: 0.344587415457\n",
      "Epoch: 39 -> Test Accuracy: 80.94\n",
      "[40, 60] loss: 0.316\n",
      "[40, 120] loss: 0.308\n",
      "[40, 180] loss: 0.329\n",
      "[40, 240] loss: 0.324\n",
      "[40, 300] loss: 0.326\n",
      "[40, 360] loss: 0.330\n",
      "Epoch: 40 -> Loss: 0.410146802664\n",
      "Epoch: 40 -> Test Accuracy: 81.01\n",
      "[41, 60] loss: 0.299\n",
      "[41, 120] loss: 0.288\n",
      "[41, 180] loss: 0.276\n",
      "[41, 240] loss: 0.290\n",
      "[41, 300] loss: 0.282\n",
      "[41, 360] loss: 0.277\n",
      "Epoch: 41 -> Loss: 0.345135480165\n",
      "Epoch: 41 -> Test Accuracy: 81.95\n",
      "[42, 60] loss: 0.277\n",
      "[42, 120] loss: 0.269\n",
      "[42, 180] loss: 0.262\n",
      "[42, 240] loss: 0.280\n",
      "[42, 300] loss: 0.268\n",
      "[42, 360] loss: 0.258\n",
      "Epoch: 42 -> Loss: 0.350058048964\n",
      "Epoch: 42 -> Test Accuracy: 81.93\n",
      "[43, 60] loss: 0.254\n",
      "[43, 120] loss: 0.266\n",
      "[43, 180] loss: 0.266\n",
      "[43, 240] loss: 0.260\n",
      "[43, 300] loss: 0.264\n",
      "[43, 360] loss: 0.257\n",
      "Epoch: 43 -> Loss: 0.36568158865\n",
      "Epoch: 43 -> Test Accuracy: 82.08\n",
      "[44, 60] loss: 0.258\n",
      "[44, 120] loss: 0.255\n",
      "[44, 180] loss: 0.238\n",
      "[44, 240] loss: 0.250\n",
      "[44, 300] loss: 0.254\n",
      "[44, 360] loss: 0.254\n",
      "Epoch: 44 -> Loss: 0.280406206846\n",
      "Epoch: 44 -> Test Accuracy: 82.0\n",
      "[45, 60] loss: 0.244\n",
      "[45, 120] loss: 0.241\n",
      "[45, 180] loss: 0.257\n",
      "[45, 240] loss: 0.256\n",
      "[45, 300] loss: 0.264\n",
      "[45, 360] loss: 0.250\n",
      "Epoch: 45 -> Loss: 0.312685310841\n",
      "Epoch: 45 -> Test Accuracy: 82.23\n",
      "[46, 60] loss: 0.239\n",
      "[46, 120] loss: 0.226\n",
      "[46, 180] loss: 0.269\n",
      "[46, 240] loss: 0.237\n",
      "[46, 300] loss: 0.237\n",
      "[46, 360] loss: 0.223\n",
      "Epoch: 46 -> Loss: 0.258587002754\n",
      "Epoch: 46 -> Test Accuracy: 82.09\n",
      "[47, 60] loss: 0.233\n",
      "[47, 120] loss: 0.246\n",
      "[47, 180] loss: 0.235\n",
      "[47, 240] loss: 0.223\n",
      "[47, 300] loss: 0.232\n",
      "[47, 360] loss: 0.233\n",
      "Epoch: 47 -> Loss: 0.293756008148\n",
      "Epoch: 47 -> Test Accuracy: 82.16\n",
      "[48, 60] loss: 0.223\n",
      "[48, 120] loss: 0.245\n",
      "[48, 180] loss: 0.232\n",
      "[48, 240] loss: 0.226\n",
      "[48, 300] loss: 0.237\n",
      "[48, 360] loss: 0.233\n",
      "Epoch: 48 -> Loss: 0.428586661816\n",
      "Epoch: 48 -> Test Accuracy: 82.06\n",
      "[49, 60] loss: 0.235\n",
      "[49, 120] loss: 0.218\n",
      "[49, 180] loss: 0.238\n",
      "[49, 240] loss: 0.220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 300] loss: 0.228\n",
      "[49, 360] loss: 0.238\n",
      "Epoch: 49 -> Loss: 0.295928359032\n",
      "Epoch: 49 -> Test Accuracy: 82.28\n",
      "[50, 60] loss: 0.234\n",
      "[50, 120] loss: 0.225\n",
      "[50, 180] loss: 0.222\n",
      "[50, 240] loss: 0.231\n",
      "[50, 300] loss: 0.225\n",
      "[50, 360] loss: 0.228\n",
      "Epoch: 50 -> Loss: 0.312008082867\n",
      "Epoch: 50 -> Test Accuracy: 82.42\n",
      "[51, 60] loss: 0.220\n",
      "[51, 120] loss: 0.226\n",
      "[51, 180] loss: 0.221\n",
      "[51, 240] loss: 0.235\n",
      "[51, 300] loss: 0.226\n",
      "[51, 360] loss: 0.221\n",
      "Epoch: 51 -> Loss: 0.318003326654\n",
      "Epoch: 51 -> Test Accuracy: 82.52\n",
      "[52, 60] loss: 0.241\n",
      "[52, 120] loss: 0.216\n",
      "[52, 180] loss: 0.231\n",
      "[52, 240] loss: 0.216\n",
      "[52, 300] loss: 0.218\n",
      "[52, 360] loss: 0.229\n",
      "Epoch: 52 -> Loss: 0.330271154642\n",
      "Epoch: 52 -> Test Accuracy: 82.47\n",
      "[53, 60] loss: 0.230\n",
      "[53, 120] loss: 0.235\n",
      "[53, 180] loss: 0.226\n",
      "[53, 240] loss: 0.226\n",
      "[53, 300] loss: 0.226\n",
      "[53, 360] loss: 0.215\n",
      "Epoch: 53 -> Loss: 0.280066460371\n",
      "Epoch: 53 -> Test Accuracy: 82.51\n",
      "[54, 60] loss: 0.226\n",
      "[54, 120] loss: 0.235\n",
      "[54, 180] loss: 0.222\n",
      "[54, 240] loss: 0.218\n",
      "[54, 300] loss: 0.221\n",
      "[54, 360] loss: 0.221\n",
      "Epoch: 54 -> Loss: 0.20117919147\n",
      "Epoch: 54 -> Test Accuracy: 82.43\n",
      "[55, 60] loss: 0.219\n",
      "[55, 120] loss: 0.217\n",
      "[55, 180] loss: 0.225\n",
      "[55, 240] loss: 0.214\n",
      "[55, 300] loss: 0.221\n",
      "[55, 360] loss: 0.229\n",
      "Epoch: 55 -> Loss: 0.170571014285\n",
      "Epoch: 55 -> Test Accuracy: 82.44\n",
      "[56, 60] loss: 0.210\n",
      "[56, 120] loss: 0.223\n",
      "[56, 180] loss: 0.228\n",
      "[56, 240] loss: 0.220\n",
      "[56, 300] loss: 0.216\n",
      "[56, 360] loss: 0.218\n",
      "Epoch: 56 -> Loss: 0.255950778723\n",
      "Epoch: 56 -> Test Accuracy: 82.64\n",
      "[57, 60] loss: 0.223\n",
      "[57, 120] loss: 0.218\n",
      "[57, 180] loss: 0.219\n",
      "[57, 240] loss: 0.220\n",
      "[57, 300] loss: 0.221\n",
      "[57, 360] loss: 0.219\n",
      "Epoch: 57 -> Loss: 0.180883422494\n",
      "Epoch: 57 -> Test Accuracy: 82.48\n",
      "[58, 60] loss: 0.219\n",
      "[58, 120] loss: 0.209\n",
      "[58, 180] loss: 0.225\n",
      "[58, 240] loss: 0.217\n",
      "[58, 300] loss: 0.207\n",
      "[58, 360] loss: 0.228\n",
      "Epoch: 58 -> Loss: 0.358042031527\n",
      "Epoch: 58 -> Test Accuracy: 82.56\n",
      "[59, 60] loss: 0.220\n",
      "[59, 120] loss: 0.217\n",
      "[59, 180] loss: 0.217\n",
      "[59, 240] loss: 0.217\n",
      "[59, 300] loss: 0.228\n",
      "[59, 360] loss: 0.216\n",
      "Epoch: 59 -> Loss: 0.216255813837\n",
      "Epoch: 59 -> Test Accuracy: 82.58\n",
      "[60, 60] loss: 0.206\n",
      "[60, 120] loss: 0.205\n",
      "[60, 180] loss: 0.216\n",
      "[60, 240] loss: 0.219\n",
      "[60, 300] loss: 0.215\n",
      "[60, 360] loss: 0.227\n",
      "Epoch: 60 -> Loss: 0.257909744978\n",
      "Epoch: 60 -> Test Accuracy: 82.55\n",
      "[61, 60] loss: 0.218\n",
      "[61, 120] loss: 0.220\n",
      "[61, 180] loss: 0.223\n",
      "[61, 240] loss: 0.222\n",
      "[61, 300] loss: 0.210\n",
      "[61, 360] loss: 0.216\n",
      "Epoch: 61 -> Loss: 0.355645000935\n",
      "Epoch: 61 -> Test Accuracy: 82.47\n",
      "[62, 60] loss: 0.216\n",
      "[62, 120] loss: 0.212\n",
      "[62, 180] loss: 0.215\n",
      "[62, 240] loss: 0.223\n",
      "[62, 300] loss: 0.216\n",
      "[62, 360] loss: 0.211\n",
      "Epoch: 62 -> Loss: 0.167954653502\n",
      "Epoch: 62 -> Test Accuracy: 82.41\n",
      "[63, 60] loss: 0.209\n",
      "[63, 120] loss: 0.209\n",
      "[63, 180] loss: 0.205\n",
      "[63, 240] loss: 0.212\n",
      "[63, 300] loss: 0.231\n",
      "[63, 360] loss: 0.219\n",
      "Epoch: 63 -> Loss: 0.272805690765\n",
      "Epoch: 63 -> Test Accuracy: 82.35\n",
      "[64, 60] loss: 0.199\n",
      "[64, 120] loss: 0.211\n",
      "[64, 180] loss: 0.231\n",
      "[64, 240] loss: 0.207\n",
      "[64, 300] loss: 0.216\n",
      "[64, 360] loss: 0.203\n",
      "Epoch: 64 -> Loss: 0.19437456131\n",
      "Epoch: 64 -> Test Accuracy: 82.34\n",
      "[65, 60] loss: 0.207\n",
      "[65, 120] loss: 0.209\n",
      "[65, 180] loss: 0.221\n",
      "[65, 240] loss: 0.224\n",
      "[65, 300] loss: 0.214\n",
      "[65, 360] loss: 0.207\n",
      "Epoch: 65 -> Loss: 0.291274487972\n",
      "Epoch: 65 -> Test Accuracy: 82.32\n",
      "[66, 60] loss: 0.208\n",
      "[66, 120] loss: 0.214\n",
      "[66, 180] loss: 0.205\n",
      "[66, 240] loss: 0.215\n",
      "[66, 300] loss: 0.204\n",
      "[66, 360] loss: 0.210\n",
      "Epoch: 66 -> Loss: 0.235957056284\n",
      "Epoch: 66 -> Test Accuracy: 82.54\n",
      "[67, 60] loss: 0.207\n",
      "[67, 120] loss: 0.209\n",
      "[67, 180] loss: 0.207\n",
      "[67, 240] loss: 0.213\n",
      "[67, 300] loss: 0.202\n",
      "[67, 360] loss: 0.217\n",
      "Epoch: 67 -> Loss: 0.340725958347\n",
      "Epoch: 67 -> Test Accuracy: 82.55\n",
      "[68, 60] loss: 0.202\n",
      "[68, 120] loss: 0.220\n",
      "[68, 180] loss: 0.209\n",
      "[68, 240] loss: 0.213\n",
      "[68, 300] loss: 0.215\n",
      "[68, 360] loss: 0.206\n",
      "Epoch: 68 -> Loss: 0.186259046197\n",
      "Epoch: 68 -> Test Accuracy: 82.52\n",
      "[69, 60] loss: 0.198\n",
      "[69, 120] loss: 0.207\n",
      "[69, 180] loss: 0.213\n",
      "[69, 240] loss: 0.202\n",
      "[69, 300] loss: 0.208\n",
      "[69, 360] loss: 0.213\n",
      "Epoch: 69 -> Loss: 0.141333624721\n",
      "Epoch: 69 -> Test Accuracy: 82.45\n",
      "[70, 60] loss: 0.212\n",
      "[70, 120] loss: 0.213\n",
      "[70, 180] loss: 0.192\n",
      "[70, 240] loss: 0.194\n",
      "[70, 300] loss: 0.209\n",
      "[70, 360] loss: 0.209\n",
      "Epoch: 70 -> Loss: 0.223462969065\n",
      "Epoch: 70 -> Test Accuracy: 82.5\n",
      "[71, 60] loss: 0.212\n",
      "[71, 120] loss: 0.202\n",
      "[71, 180] loss: 0.208\n",
      "[71, 240] loss: 0.211\n",
      "[71, 300] loss: 0.196\n",
      "[71, 360] loss: 0.206\n",
      "Epoch: 71 -> Loss: 0.261893451214\n",
      "Epoch: 71 -> Test Accuracy: 82.48\n",
      "[72, 60] loss: 0.205\n",
      "[72, 120] loss: 0.203\n",
      "[72, 180] loss: 0.203\n",
      "[72, 240] loss: 0.205\n",
      "[72, 300] loss: 0.204\n",
      "[72, 360] loss: 0.198\n",
      "Epoch: 72 -> Loss: 0.317385435104\n",
      "Epoch: 72 -> Test Accuracy: 82.45\n",
      "[73, 60] loss: 0.217\n",
      "[73, 120] loss: 0.194\n",
      "[73, 180] loss: 0.205\n",
      "[73, 240] loss: 0.204\n",
      "[73, 300] loss: 0.206\n",
      "[73, 360] loss: 0.200\n",
      "Epoch: 73 -> Loss: 0.32893255353\n",
      "Epoch: 73 -> Test Accuracy: 82.43\n",
      "[74, 60] loss: 0.207\n",
      "[74, 120] loss: 0.205\n",
      "[74, 180] loss: 0.198\n",
      "[74, 240] loss: 0.208\n",
      "[74, 300] loss: 0.206\n",
      "[74, 360] loss: 0.198\n",
      "Epoch: 74 -> Loss: 0.428860187531\n",
      "Epoch: 74 -> Test Accuracy: 82.57\n",
      "[75, 60] loss: 0.208\n",
      "[75, 120] loss: 0.198\n",
      "[75, 180] loss: 0.210\n",
      "[75, 240] loss: 0.203\n",
      "[75, 300] loss: 0.208\n",
      "[75, 360] loss: 0.200\n",
      "Epoch: 75 -> Loss: 0.238104894757\n",
      "Epoch: 75 -> Test Accuracy: 82.51\n",
      "[76, 60] loss: 0.194\n",
      "[76, 120] loss: 0.191\n",
      "[76, 180] loss: 0.207\n",
      "[76, 240] loss: 0.198\n",
      "[76, 300] loss: 0.206\n",
      "[76, 360] loss: 0.196\n",
      "Epoch: 76 -> Loss: 0.213916614652\n",
      "Epoch: 76 -> Test Accuracy: 82.61\n",
      "[77, 60] loss: 0.197\n",
      "[77, 120] loss: 0.199\n",
      "[77, 180] loss: 0.194\n",
      "[77, 240] loss: 0.197\n",
      "[77, 300] loss: 0.195\n",
      "[77, 360] loss: 0.208\n",
      "Epoch: 77 -> Loss: 0.377571284771\n",
      "Epoch: 77 -> Test Accuracy: 82.54\n",
      "[78, 60] loss: 0.208\n",
      "[78, 120] loss: 0.198\n",
      "[78, 180] loss: 0.185\n",
      "[78, 240] loss: 0.194\n",
      "[78, 300] loss: 0.214\n",
      "[78, 360] loss: 0.201\n",
      "Epoch: 78 -> Loss: 0.351211607456\n",
      "Epoch: 78 -> Test Accuracy: 82.59\n",
      "[79, 60] loss: 0.195\n",
      "[79, 120] loss: 0.191\n",
      "[79, 180] loss: 0.192\n",
      "[79, 240] loss: 0.199\n",
      "[79, 300] loss: 0.201\n",
      "[79, 360] loss: 0.198\n",
      "Epoch: 79 -> Loss: 0.19017675519\n",
      "Epoch: 79 -> Test Accuracy: 82.51\n",
      "[80, 60] loss: 0.198\n",
      "[80, 120] loss: 0.196\n",
      "[80, 180] loss: 0.203\n",
      "[80, 240] loss: 0.190\n",
      "[80, 300] loss: 0.188\n",
      "[80, 360] loss: 0.202\n",
      "Epoch: 80 -> Loss: 0.248954683542\n",
      "Epoch: 80 -> Test Accuracy: 82.46\n",
      "[81, 60] loss: 0.196\n",
      "[81, 120] loss: 0.203\n",
      "[81, 180] loss: 0.178\n",
      "[81, 240] loss: 0.200\n",
      "[81, 300] loss: 0.198\n",
      "[81, 360] loss: 0.198\n",
      "Epoch: 81 -> Loss: 0.112916469574\n",
      "Epoch: 81 -> Test Accuracy: 82.49\n",
      "[82, 60] loss: 0.197\n",
      "[82, 120] loss: 0.181\n",
      "[82, 180] loss: 0.191\n",
      "[82, 240] loss: 0.199\n",
      "[82, 300] loss: 0.195\n",
      "[82, 360] loss: 0.197\n",
      "Epoch: 82 -> Loss: 0.406295239925\n",
      "Epoch: 82 -> Test Accuracy: 82.63\n",
      "[83, 60] loss: 0.197\n",
      "[83, 120] loss: 0.190\n",
      "[83, 180] loss: 0.197\n",
      "[83, 240] loss: 0.188\n",
      "[83, 300] loss: 0.183\n",
      "[83, 360] loss: 0.188\n",
      "Epoch: 83 -> Loss: 0.252580970526\n",
      "Epoch: 83 -> Test Accuracy: 82.64\n",
      "[84, 60] loss: 0.189\n",
      "[84, 120] loss: 0.200\n",
      "[84, 180] loss: 0.184\n",
      "[84, 240] loss: 0.184\n",
      "[84, 300] loss: 0.201\n",
      "[84, 360] loss: 0.197\n",
      "Epoch: 84 -> Loss: 0.154452964664\n",
      "Epoch: 84 -> Test Accuracy: 82.6\n",
      "[85, 60] loss: 0.194\n",
      "[85, 120] loss: 0.198\n",
      "[85, 180] loss: 0.182\n",
      "[85, 240] loss: 0.185\n",
      "[85, 300] loss: 0.198\n",
      "[85, 360] loss: 0.193\n",
      "Epoch: 85 -> Loss: 0.182782500982\n",
      "Epoch: 85 -> Test Accuracy: 82.48\n",
      "[86, 60] loss: 0.189\n",
      "[86, 120] loss: 0.188\n",
      "[86, 180] loss: 0.194\n",
      "[86, 240] loss: 0.188\n",
      "[86, 300] loss: 0.184\n",
      "[86, 360] loss: 0.197\n",
      "Epoch: 86 -> Loss: 0.358865559101\n",
      "Epoch: 86 -> Test Accuracy: 82.68\n",
      "[87, 60] loss: 0.193\n",
      "[87, 120] loss: 0.192\n",
      "[87, 180] loss: 0.189\n",
      "[87, 240] loss: 0.197\n",
      "[87, 300] loss: 0.200\n",
      "[87, 360] loss: 0.196\n",
      "Epoch: 87 -> Loss: 0.115446545184\n",
      "Epoch: 87 -> Test Accuracy: 82.61\n",
      "[88, 60] loss: 0.199\n",
      "[88, 120] loss: 0.182\n",
      "[88, 180] loss: 0.194\n",
      "[88, 240] loss: 0.195\n",
      "[88, 300] loss: 0.182\n",
      "[88, 360] loss: 0.195\n",
      "Epoch: 88 -> Loss: 0.271364539862\n",
      "Epoch: 88 -> Test Accuracy: 82.76\n",
      "[89, 60] loss: 0.190\n",
      "[89, 120] loss: 0.188\n",
      "[89, 180] loss: 0.185\n",
      "[89, 240] loss: 0.191\n",
      "[89, 300] loss: 0.187\n",
      "[89, 360] loss: 0.202\n",
      "Epoch: 89 -> Loss: 0.170622125268\n",
      "Epoch: 89 -> Test Accuracy: 82.51\n",
      "[90, 60] loss: 0.194\n",
      "[90, 120] loss: 0.181\n",
      "[90, 180] loss: 0.192\n",
      "[90, 240] loss: 0.193\n",
      "[90, 300] loss: 0.184\n",
      "[90, 360] loss: 0.192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90 -> Loss: 0.356305599213\n",
      "Epoch: 90 -> Test Accuracy: 82.57\n",
      "[91, 60] loss: 0.183\n",
      "[91, 120] loss: 0.181\n",
      "[91, 180] loss: 0.174\n",
      "[91, 240] loss: 0.183\n",
      "[91, 300] loss: 0.186\n",
      "[91, 360] loss: 0.189\n",
      "Epoch: 91 -> Loss: 0.158716037869\n",
      "Epoch: 91 -> Test Accuracy: 82.67\n",
      "[92, 60] loss: 0.168\n",
      "[92, 120] loss: 0.184\n",
      "[92, 180] loss: 0.188\n",
      "[92, 240] loss: 0.188\n",
      "[92, 300] loss: 0.185\n",
      "[92, 360] loss: 0.173\n",
      "Epoch: 92 -> Loss: 0.173720553517\n",
      "Epoch: 92 -> Test Accuracy: 82.69\n",
      "[93, 60] loss: 0.181\n",
      "[93, 120] loss: 0.181\n",
      "[93, 180] loss: 0.196\n",
      "[93, 240] loss: 0.187\n",
      "[93, 300] loss: 0.183\n",
      "[93, 360] loss: 0.186\n",
      "Epoch: 93 -> Loss: 0.18745046854\n",
      "Epoch: 93 -> Test Accuracy: 82.68\n",
      "[94, 60] loss: 0.180\n",
      "[94, 120] loss: 0.189\n",
      "[94, 180] loss: 0.181\n",
      "[94, 240] loss: 0.189\n",
      "[94, 300] loss: 0.186\n",
      "[94, 360] loss: 0.182\n",
      "Epoch: 94 -> Loss: 0.137159302831\n",
      "Epoch: 94 -> Test Accuracy: 82.75\n",
      "[95, 60] loss: 0.177\n",
      "[95, 120] loss: 0.176\n",
      "[95, 180] loss: 0.177\n",
      "[95, 240] loss: 0.190\n",
      "[95, 300] loss: 0.190\n",
      "[95, 360] loss: 0.193\n",
      "Epoch: 95 -> Loss: 0.168620109558\n",
      "Epoch: 95 -> Test Accuracy: 82.6\n",
      "[96, 60] loss: 0.176\n",
      "[96, 120] loss: 0.193\n",
      "[96, 180] loss: 0.177\n",
      "[96, 240] loss: 0.186\n",
      "[96, 300] loss: 0.184\n",
      "[96, 360] loss: 0.188\n",
      "Epoch: 96 -> Loss: 0.188229054213\n",
      "Epoch: 96 -> Test Accuracy: 82.73\n",
      "[97, 60] loss: 0.179\n",
      "[97, 120] loss: 0.194\n",
      "[97, 180] loss: 0.186\n",
      "[97, 240] loss: 0.177\n",
      "[97, 300] loss: 0.176\n",
      "[97, 360] loss: 0.185\n",
      "Epoch: 97 -> Loss: 0.137030690908\n",
      "Epoch: 97 -> Test Accuracy: 82.76\n",
      "[98, 60] loss: 0.182\n",
      "[98, 120] loss: 0.177\n",
      "[98, 180] loss: 0.179\n",
      "[98, 240] loss: 0.179\n",
      "[98, 300] loss: 0.183\n",
      "[98, 360] loss: 0.176\n",
      "Epoch: 98 -> Loss: 0.210213810205\n",
      "Epoch: 98 -> Test Accuracy: 82.59\n",
      "[99, 60] loss: 0.182\n",
      "[99, 120] loss: 0.176\n",
      "[99, 180] loss: 0.185\n",
      "[99, 240] loss: 0.183\n",
      "[99, 300] loss: 0.186\n",
      "[99, 360] loss: 0.183\n",
      "Epoch: 99 -> Loss: 0.0859719365835\n",
      "Epoch: 99 -> Test Accuracy: 82.62\n",
      "[100, 60] loss: 0.173\n",
      "[100, 120] loss: 0.174\n",
      "[100, 180] loss: 0.175\n",
      "[100, 240] loss: 0.189\n",
      "[100, 300] loss: 0.180\n",
      "[100, 360] loss: 0.184\n",
      "Epoch: 100 -> Loss: 0.154658585787\n",
      "Epoch: 100 -> Test Accuracy: 82.61\n",
      "Finished Training\n",
      "[1, 60] loss: 2.276\n",
      "[1, 120] loss: 1.432\n",
      "[1, 180] loss: 1.306\n",
      "[1, 240] loss: 1.280\n",
      "[1, 300] loss: 1.195\n",
      "[1, 360] loss: 1.185\n",
      "Epoch: 1 -> Loss: 0.958452045918\n",
      "Epoch: 1 -> Test Accuracy: 54.57\n",
      "[2, 60] loss: 1.115\n",
      "[2, 120] loss: 1.112\n",
      "[2, 180] loss: 1.116\n",
      "[2, 240] loss: 1.091\n",
      "[2, 300] loss: 1.094\n",
      "[2, 360] loss: 1.097\n",
      "Epoch: 2 -> Loss: 0.966240048409\n",
      "Epoch: 2 -> Test Accuracy: 58.31\n",
      "[3, 60] loss: 1.070\n",
      "[3, 120] loss: 1.052\n",
      "[3, 180] loss: 1.047\n",
      "[3, 240] loss: 1.051\n",
      "[3, 300] loss: 1.048\n",
      "[3, 360] loss: 1.030\n",
      "Epoch: 3 -> Loss: 1.05617487431\n",
      "Epoch: 3 -> Test Accuracy: 58.93\n",
      "[4, 60] loss: 1.013\n",
      "[4, 120] loss: 1.026\n",
      "[4, 180] loss: 1.027\n",
      "[4, 240] loss: 1.012\n",
      "[4, 300] loss: 1.018\n",
      "[4, 360] loss: 1.020\n",
      "Epoch: 4 -> Loss: 1.0764772892\n",
      "Epoch: 4 -> Test Accuracy: 59.48\n",
      "[5, 60] loss: 1.006\n",
      "[5, 120] loss: 1.003\n",
      "[5, 180] loss: 0.998\n",
      "[5, 240] loss: 1.011\n",
      "[5, 300] loss: 1.001\n",
      "[5, 360] loss: 0.987\n",
      "Epoch: 5 -> Loss: 0.837233841419\n",
      "Epoch: 5 -> Test Accuracy: 58.98\n",
      "[6, 60] loss: 0.987\n",
      "[6, 120] loss: 0.988\n",
      "[6, 180] loss: 0.983\n",
      "[6, 240] loss: 0.981\n",
      "[6, 300] loss: 0.997\n",
      "[6, 360] loss: 1.006\n",
      "Epoch: 6 -> Loss: 1.10666155815\n",
      "Epoch: 6 -> Test Accuracy: 60.5\n",
      "[7, 60] loss: 0.968\n",
      "[7, 120] loss: 0.967\n",
      "[7, 180] loss: 0.992\n",
      "[7, 240] loss: 0.991\n",
      "[7, 300] loss: 0.990\n",
      "[7, 360] loss: 0.991\n",
      "Epoch: 7 -> Loss: 0.994351089001\n",
      "Epoch: 7 -> Test Accuracy: 60.66\n",
      "[8, 60] loss: 0.979\n",
      "[8, 120] loss: 0.986\n",
      "[8, 180] loss: 0.976\n",
      "[8, 240] loss: 0.974\n",
      "[8, 300] loss: 0.981\n",
      "[8, 360] loss: 0.973\n",
      "Epoch: 8 -> Loss: 0.904663085938\n",
      "Epoch: 8 -> Test Accuracy: 60.59\n",
      "[9, 60] loss: 0.972\n",
      "[9, 120] loss: 0.989\n",
      "[9, 180] loss: 0.973\n",
      "[9, 240] loss: 0.964\n",
      "[9, 300] loss: 0.994\n",
      "[9, 360] loss: 0.960\n",
      "Epoch: 9 -> Loss: 0.970480322838\n",
      "Epoch: 9 -> Test Accuracy: 60.87\n",
      "[10, 60] loss: 0.958\n",
      "[10, 120] loss: 0.985\n",
      "[10, 180] loss: 0.976\n",
      "[10, 240] loss: 0.989\n",
      "[10, 300] loss: 0.971\n",
      "[10, 360] loss: 0.962\n",
      "Epoch: 10 -> Loss: 1.09110665321\n",
      "Epoch: 10 -> Test Accuracy: 62.1\n",
      "[11, 60] loss: 0.976\n",
      "[11, 120] loss: 0.964\n",
      "[11, 180] loss: 0.959\n",
      "[11, 240] loss: 0.979\n",
      "[11, 300] loss: 0.961\n",
      "[11, 360] loss: 0.959\n",
      "Epoch: 11 -> Loss: 0.830842792988\n",
      "Epoch: 11 -> Test Accuracy: 61.74\n",
      "[12, 60] loss: 0.973\n",
      "[12, 120] loss: 0.955\n",
      "[12, 180] loss: 0.985\n",
      "[12, 240] loss: 0.993\n",
      "[12, 300] loss: 0.934\n",
      "[12, 360] loss: 0.952\n",
      "Epoch: 12 -> Loss: 0.894786715508\n",
      "Epoch: 12 -> Test Accuracy: 61.4\n",
      "[13, 60] loss: 0.949\n",
      "[13, 120] loss: 0.955\n",
      "[13, 180] loss: 0.975\n",
      "[13, 240] loss: 0.980\n",
      "[13, 300] loss: 0.963\n",
      "[13, 360] loss: 0.972\n",
      "Epoch: 13 -> Loss: 1.00711083412\n",
      "Epoch: 13 -> Test Accuracy: 61.21\n",
      "[14, 60] loss: 0.957\n",
      "[14, 120] loss: 0.956\n",
      "[14, 180] loss: 0.984\n",
      "[14, 240] loss: 0.953\n",
      "[14, 300] loss: 0.948\n",
      "[14, 360] loss: 0.968\n",
      "Epoch: 14 -> Loss: 1.01872062683\n",
      "Epoch: 14 -> Test Accuracy: 61.85\n",
      "[15, 60] loss: 0.931\n",
      "[15, 120] loss: 0.956\n",
      "[15, 180] loss: 0.958\n",
      "[15, 240] loss: 0.958\n",
      "[15, 300] loss: 0.983\n",
      "[15, 360] loss: 0.970\n",
      "Epoch: 15 -> Loss: 0.77279740572\n",
      "Epoch: 15 -> Test Accuracy: 61.68\n",
      "[16, 60] loss: 0.955\n",
      "[16, 120] loss: 0.964\n",
      "[16, 180] loss: 0.956\n",
      "[16, 240] loss: 0.947\n",
      "[16, 300] loss: 0.957\n",
      "[16, 360] loss: 0.975\n",
      "Epoch: 16 -> Loss: 1.07396054268\n",
      "Epoch: 16 -> Test Accuracy: 61.62\n",
      "[17, 60] loss: 0.913\n",
      "[17, 120] loss: 0.948\n",
      "[17, 180] loss: 0.957\n",
      "[17, 240] loss: 0.970\n",
      "[17, 300] loss: 0.963\n",
      "[17, 360] loss: 0.962\n",
      "Epoch: 17 -> Loss: 0.968614280224\n",
      "Epoch: 17 -> Test Accuracy: 61.91\n",
      "[18, 60] loss: 0.955\n",
      "[18, 120] loss: 0.945\n",
      "[18, 180] loss: 0.972\n",
      "[18, 240] loss: 0.953\n",
      "[18, 300] loss: 0.960\n",
      "[18, 360] loss: 0.967\n",
      "Epoch: 18 -> Loss: 0.939059376717\n",
      "Epoch: 18 -> Test Accuracy: 61.55\n",
      "[19, 60] loss: 0.969\n",
      "[19, 120] loss: 0.948\n",
      "[19, 180] loss: 0.950\n",
      "[19, 240] loss: 0.960\n",
      "[19, 300] loss: 0.968\n",
      "[19, 360] loss: 0.951\n",
      "Epoch: 19 -> Loss: 0.919539570808\n",
      "Epoch: 19 -> Test Accuracy: 62.32\n",
      "[20, 60] loss: 0.941\n",
      "[20, 120] loss: 0.960\n",
      "[20, 180] loss: 0.939\n",
      "[20, 240] loss: 0.949\n",
      "[20, 300] loss: 0.971\n",
      "[20, 360] loss: 0.942\n",
      "Epoch: 20 -> Loss: 0.919953942299\n",
      "Epoch: 20 -> Test Accuracy: 62.08\n",
      "[21, 60] loss: 0.911\n",
      "[21, 120] loss: 0.878\n",
      "[21, 180] loss: 0.884\n",
      "[21, 240] loss: 0.863\n",
      "[21, 300] loss: 0.863\n",
      "[21, 360] loss: 0.836\n",
      "Epoch: 21 -> Loss: 0.916615307331\n",
      "Epoch: 21 -> Test Accuracy: 64.96\n",
      "[22, 60] loss: 0.840\n",
      "[22, 120] loss: 0.846\n",
      "[22, 180] loss: 0.803\n",
      "[22, 240] loss: 0.857\n",
      "[22, 300] loss: 0.855\n",
      "[22, 360] loss: 0.830\n",
      "Epoch: 22 -> Loss: 0.704418480396\n",
      "Epoch: 22 -> Test Accuracy: 65.26\n",
      "[23, 60] loss: 0.836\n",
      "[23, 120] loss: 0.832\n",
      "[23, 180] loss: 0.849\n",
      "[23, 240] loss: 0.815\n",
      "[23, 300] loss: 0.811\n",
      "[23, 360] loss: 0.825\n",
      "Epoch: 23 -> Loss: 0.71877682209\n",
      "Epoch: 23 -> Test Accuracy: 65.3\n",
      "[24, 60] loss: 0.822\n",
      "[24, 120] loss: 0.813\n",
      "[24, 180] loss: 0.811\n",
      "[24, 240] loss: 0.833\n",
      "[24, 300] loss: 0.799\n",
      "[24, 360] loss: 0.845\n",
      "Epoch: 24 -> Loss: 0.957919120789\n",
      "Epoch: 24 -> Test Accuracy: 64.87\n",
      "[25, 60] loss: 0.808\n",
      "[25, 120] loss: 0.813\n",
      "[25, 180] loss: 0.818\n",
      "[25, 240] loss: 0.830\n",
      "[25, 300] loss: 0.840\n",
      "[25, 360] loss: 0.796\n",
      "Epoch: 25 -> Loss: 0.810170173645\n",
      "Epoch: 25 -> Test Accuracy: 66.1\n",
      "[26, 60] loss: 0.810\n",
      "[26, 120] loss: 0.807\n",
      "[26, 180] loss: 0.817\n",
      "[26, 240] loss: 0.808\n",
      "[26, 300] loss: 0.832\n",
      "[26, 360] loss: 0.808\n",
      "Epoch: 26 -> Loss: 0.810378670692\n",
      "Epoch: 26 -> Test Accuracy: 65.35\n",
      "[27, 60] loss: 0.833\n",
      "[27, 120] loss: 0.810\n",
      "[27, 180] loss: 0.796\n",
      "[27, 240] loss: 0.824\n",
      "[27, 300] loss: 0.809\n",
      "[27, 360] loss: 0.821\n",
      "Epoch: 27 -> Loss: 0.660692870617\n",
      "Epoch: 27 -> Test Accuracy: 66.02\n",
      "[28, 60] loss: 0.806\n",
      "[28, 120] loss: 0.809\n",
      "[28, 180] loss: 0.822\n",
      "[28, 240] loss: 0.814\n",
      "[28, 300] loss: 0.812\n",
      "[28, 360] loss: 0.825\n",
      "Epoch: 28 -> Loss: 0.769402980804\n",
      "Epoch: 28 -> Test Accuracy: 66.21\n",
      "[29, 60] loss: 0.788\n",
      "[29, 120] loss: 0.824\n",
      "[29, 180] loss: 0.817\n",
      "[29, 240] loss: 0.818\n",
      "[29, 300] loss: 0.825\n",
      "[29, 360] loss: 0.804\n",
      "Epoch: 29 -> Loss: 0.839892983437\n",
      "Epoch: 29 -> Test Accuracy: 65.93\n",
      "[30, 60] loss: 0.795\n",
      "[30, 120] loss: 0.803\n",
      "[30, 180] loss: 0.804\n",
      "[30, 240] loss: 0.792\n",
      "[30, 300] loss: 0.823\n",
      "[30, 360] loss: 0.809\n",
      "Epoch: 30 -> Loss: 0.756263554096\n",
      "Epoch: 30 -> Test Accuracy: 66.14\n",
      "[31, 60] loss: 0.800\n",
      "[31, 120] loss: 0.806\n",
      "[31, 180] loss: 0.801\n",
      "[31, 240] loss: 0.810\n",
      "[31, 300] loss: 0.812\n",
      "[31, 360] loss: 0.817\n",
      "Epoch: 31 -> Loss: 0.969227194786\n",
      "Epoch: 31 -> Test Accuracy: 65.22\n",
      "[32, 60] loss: 0.798\n",
      "[32, 120] loss: 0.802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 180] loss: 0.812\n",
      "[32, 240] loss: 0.788\n",
      "[32, 300] loss: 0.808\n",
      "[32, 360] loss: 0.806\n",
      "Epoch: 32 -> Loss: 0.81226092577\n",
      "Epoch: 32 -> Test Accuracy: 65.13\n",
      "[33, 60] loss: 0.811\n",
      "[33, 120] loss: 0.803\n",
      "[33, 180] loss: 0.788\n",
      "[33, 240] loss: 0.799\n",
      "[33, 300] loss: 0.815\n",
      "[33, 360] loss: 0.805\n",
      "Epoch: 33 -> Loss: 0.799949228764\n",
      "Epoch: 33 -> Test Accuracy: 65.58\n",
      "[34, 60] loss: 0.790\n",
      "[34, 120] loss: 0.816\n",
      "[34, 180] loss: 0.801\n",
      "[34, 240] loss: 0.804\n",
      "[34, 300] loss: 0.789\n",
      "[34, 360] loss: 0.814\n",
      "Epoch: 34 -> Loss: 0.731688082218\n",
      "Epoch: 34 -> Test Accuracy: 65.77\n",
      "[35, 60] loss: 0.802\n",
      "[35, 120] loss: 0.801\n",
      "[35, 180] loss: 0.807\n",
      "[35, 240] loss: 0.818\n",
      "[35, 300] loss: 0.800\n",
      "[35, 360] loss: 0.814\n",
      "Epoch: 35 -> Loss: 0.876521885395\n",
      "Epoch: 35 -> Test Accuracy: 65.95\n",
      "[36, 60] loss: 0.779\n",
      "[36, 120] loss: 0.815\n",
      "[36, 180] loss: 0.803\n",
      "[36, 240] loss: 0.812\n",
      "[36, 300] loss: 0.807\n",
      "[36, 360] loss: 0.831\n",
      "Epoch: 36 -> Loss: 0.79645717144\n",
      "Epoch: 36 -> Test Accuracy: 65.72\n",
      "[37, 60] loss: 0.774\n",
      "[37, 120] loss: 0.784\n",
      "[37, 180] loss: 0.819\n",
      "[37, 240] loss: 0.802\n",
      "[37, 300] loss: 0.797\n",
      "[37, 360] loss: 0.808\n",
      "Epoch: 37 -> Loss: 0.75992590189\n",
      "Epoch: 37 -> Test Accuracy: 66.19\n",
      "[38, 60] loss: 0.806\n",
      "[38, 120] loss: 0.815\n",
      "[38, 180] loss: 0.796\n",
      "[38, 240] loss: 0.778\n",
      "[38, 300] loss: 0.799\n",
      "[38, 360] loss: 0.804\n",
      "Epoch: 38 -> Loss: 0.79209536314\n",
      "Epoch: 38 -> Test Accuracy: 65.73\n",
      "[39, 60] loss: 0.805\n",
      "[39, 120] loss: 0.804\n",
      "[39, 180] loss: 0.801\n",
      "[39, 240] loss: 0.803\n",
      "[39, 300] loss: 0.801\n",
      "[39, 360] loss: 0.795\n",
      "Epoch: 39 -> Loss: 0.752439022064\n",
      "Epoch: 39 -> Test Accuracy: 65.74\n",
      "[40, 60] loss: 0.813\n",
      "[40, 120] loss: 0.826\n",
      "[40, 180] loss: 0.811\n",
      "[40, 240] loss: 0.809\n",
      "[40, 300] loss: 0.803\n",
      "[40, 360] loss: 0.803\n",
      "Epoch: 40 -> Loss: 0.633458673954\n",
      "Epoch: 40 -> Test Accuracy: 65.98\n",
      "[41, 60] loss: 0.789\n",
      "[41, 120] loss: 0.767\n",
      "[41, 180] loss: 0.780\n",
      "[41, 240] loss: 0.738\n",
      "[41, 300] loss: 0.748\n",
      "[41, 360] loss: 0.752\n",
      "Epoch: 41 -> Loss: 0.80747282505\n",
      "Epoch: 41 -> Test Accuracy: 67.68\n",
      "[42, 60] loss: 0.750\n",
      "[42, 120] loss: 0.719\n",
      "[42, 180] loss: 0.745\n",
      "[42, 240] loss: 0.759\n",
      "[42, 300] loss: 0.738\n",
      "[42, 360] loss: 0.724\n",
      "Epoch: 42 -> Loss: 0.776615262032\n",
      "Epoch: 42 -> Test Accuracy: 67.9\n",
      "[43, 60] loss: 0.723\n",
      "[43, 120] loss: 0.724\n",
      "[43, 180] loss: 0.731\n",
      "[43, 240] loss: 0.728\n",
      "[43, 300] loss: 0.722\n",
      "[43, 360] loss: 0.726\n",
      "Epoch: 43 -> Loss: 0.775137722492\n",
      "Epoch: 43 -> Test Accuracy: 68.01\n",
      "[44, 60] loss: 0.727\n",
      "[44, 120] loss: 0.722\n",
      "[44, 180] loss: 0.736\n",
      "[44, 240] loss: 0.724\n",
      "[44, 300] loss: 0.723\n",
      "[44, 360] loss: 0.733\n",
      "Epoch: 44 -> Loss: 0.871845364571\n",
      "Epoch: 44 -> Test Accuracy: 67.82\n",
      "[45, 60] loss: 0.729\n",
      "[45, 120] loss: 0.723\n",
      "[45, 180] loss: 0.708\n",
      "[45, 240] loss: 0.736\n",
      "[45, 300] loss: 0.736\n",
      "[45, 360] loss: 0.725\n",
      "Epoch: 45 -> Loss: 0.739436209202\n",
      "Epoch: 45 -> Test Accuracy: 68.08\n",
      "[46, 60] loss: 0.707\n",
      "[46, 120] loss: 0.711\n",
      "[46, 180] loss: 0.725\n",
      "[46, 240] loss: 0.690\n",
      "[46, 300] loss: 0.709\n",
      "[46, 360] loss: 0.704\n",
      "Epoch: 46 -> Loss: 0.681515097618\n",
      "Epoch: 46 -> Test Accuracy: 68.08\n",
      "[47, 60] loss: 0.721\n",
      "[47, 120] loss: 0.713\n",
      "[47, 180] loss: 0.709\n",
      "[47, 240] loss: 0.705\n",
      "[47, 300] loss: 0.711\n",
      "[47, 360] loss: 0.685\n",
      "Epoch: 47 -> Loss: 0.768082618713\n",
      "Epoch: 47 -> Test Accuracy: 68.26\n",
      "[48, 60] loss: 0.704\n",
      "[48, 120] loss: 0.687\n",
      "[48, 180] loss: 0.716\n",
      "[48, 240] loss: 0.706\n",
      "[48, 300] loss: 0.709\n",
      "[48, 360] loss: 0.710\n",
      "Epoch: 48 -> Loss: 0.686768889427\n",
      "Epoch: 48 -> Test Accuracy: 68.55\n",
      "[49, 60] loss: 0.702\n",
      "[49, 120] loss: 0.695\n",
      "[49, 180] loss: 0.704\n",
      "[49, 240] loss: 0.720\n",
      "[49, 300] loss: 0.724\n",
      "[49, 360] loss: 0.693\n",
      "Epoch: 49 -> Loss: 0.745475172997\n",
      "Epoch: 49 -> Test Accuracy: 68.47\n",
      "[50, 60] loss: 0.708\n",
      "[50, 120] loss: 0.673\n",
      "[50, 180] loss: 0.710\n",
      "[50, 240] loss: 0.699\n",
      "[50, 300] loss: 0.713\n",
      "[50, 360] loss: 0.698\n",
      "Epoch: 50 -> Loss: 0.541679382324\n",
      "Epoch: 50 -> Test Accuracy: 68.34\n",
      "[51, 60] loss: 0.709\n",
      "[51, 120] loss: 0.690\n",
      "[51, 180] loss: 0.696\n",
      "[51, 240] loss: 0.695\n",
      "[51, 300] loss: 0.712\n",
      "[51, 360] loss: 0.706\n",
      "Epoch: 51 -> Loss: 0.670947909355\n",
      "Epoch: 51 -> Test Accuracy: 68.43\n",
      "[52, 60] loss: 0.697\n",
      "[52, 120] loss: 0.698\n",
      "[52, 180] loss: 0.699\n",
      "[52, 240] loss: 0.693\n",
      "[52, 300] loss: 0.706\n",
      "[52, 360] loss: 0.705\n",
      "Epoch: 52 -> Loss: 0.694115757942\n",
      "Epoch: 52 -> Test Accuracy: 68.74\n",
      "[53, 60] loss: 0.702\n",
      "[53, 120] loss: 0.695\n",
      "[53, 180] loss: 0.701\n",
      "[53, 240] loss: 0.701\n",
      "[53, 300] loss: 0.705\n",
      "[53, 360] loss: 0.707\n",
      "Epoch: 53 -> Loss: 0.728747546673\n",
      "Epoch: 53 -> Test Accuracy: 68.52\n",
      "[54, 60] loss: 0.689\n",
      "[54, 120] loss: 0.698\n",
      "[54, 180] loss: 0.693\n",
      "[54, 240] loss: 0.703\n",
      "[54, 300] loss: 0.690\n",
      "[54, 360] loss: 0.682\n",
      "Epoch: 54 -> Loss: 0.889345347881\n",
      "Epoch: 54 -> Test Accuracy: 68.51\n",
      "[55, 60] loss: 0.705\n",
      "[55, 120] loss: 0.686\n",
      "[55, 180] loss: 0.688\n",
      "[55, 240] loss: 0.705\n",
      "[55, 300] loss: 0.693\n",
      "[55, 360] loss: 0.702\n",
      "Epoch: 55 -> Loss: 0.486169964075\n",
      "Epoch: 55 -> Test Accuracy: 68.63\n",
      "[56, 60] loss: 0.710\n",
      "[56, 120] loss: 0.683\n",
      "[56, 180] loss: 0.689\n",
      "[56, 240] loss: 0.703\n",
      "[56, 300] loss: 0.691\n",
      "[56, 360] loss: 0.704\n",
      "Epoch: 56 -> Loss: 0.703004360199\n",
      "Epoch: 56 -> Test Accuracy: 68.71\n",
      "[57, 60] loss: 0.687\n",
      "[57, 120] loss: 0.695\n",
      "[57, 180] loss: 0.685\n",
      "[57, 240] loss: 0.681\n",
      "[57, 300] loss: 0.687\n",
      "[57, 360] loss: 0.713\n",
      "Epoch: 57 -> Loss: 0.707298576832\n",
      "Epoch: 57 -> Test Accuracy: 68.82\n",
      "[58, 60] loss: 0.698\n",
      "[58, 120] loss: 0.685\n",
      "[58, 180] loss: 0.702\n",
      "[58, 240] loss: 0.680\n",
      "[58, 300] loss: 0.686\n",
      "[58, 360] loss: 0.684\n",
      "Epoch: 58 -> Loss: 0.695422589779\n",
      "Epoch: 58 -> Test Accuracy: 68.83\n",
      "[59, 60] loss: 0.682\n",
      "[59, 120] loss: 0.680\n",
      "[59, 180] loss: 0.699\n",
      "[59, 240] loss: 0.688\n",
      "[59, 300] loss: 0.696\n",
      "[59, 360] loss: 0.699\n",
      "Epoch: 59 -> Loss: 0.65285551548\n",
      "Epoch: 59 -> Test Accuracy: 68.94\n",
      "[60, 60] loss: 0.699\n",
      "[60, 120] loss: 0.690\n",
      "[60, 180] loss: 0.682\n",
      "[60, 240] loss: 0.693\n",
      "[60, 300] loss: 0.689\n",
      "[60, 360] loss: 0.673\n",
      "Epoch: 60 -> Loss: 0.781907916069\n",
      "Epoch: 60 -> Test Accuracy: 68.7\n",
      "[61, 60] loss: 0.699\n",
      "[61, 120] loss: 0.690\n",
      "[61, 180] loss: 0.686\n",
      "[61, 240] loss: 0.690\n",
      "[61, 300] loss: 0.692\n",
      "[61, 360] loss: 0.672\n",
      "Epoch: 61 -> Loss: 0.705371558666\n",
      "Epoch: 61 -> Test Accuracy: 68.76\n",
      "[62, 60] loss: 0.680\n",
      "[62, 120] loss: 0.680\n",
      "[62, 180] loss: 0.689\n",
      "[62, 240] loss: 0.705\n",
      "[62, 300] loss: 0.692\n",
      "[62, 360] loss: 0.685\n",
      "Epoch: 62 -> Loss: 0.777101278305\n",
      "Epoch: 62 -> Test Accuracy: 68.77\n",
      "[63, 60] loss: 0.684\n",
      "[63, 120] loss: 0.685\n",
      "[63, 180] loss: 0.689\n",
      "[63, 240] loss: 0.705\n",
      "[63, 300] loss: 0.694\n",
      "[63, 360] loss: 0.697\n",
      "Epoch: 63 -> Loss: 0.781316876411\n",
      "Epoch: 63 -> Test Accuracy: 68.79\n",
      "[64, 60] loss: 0.700\n",
      "[64, 120] loss: 0.663\n",
      "[64, 180] loss: 0.681\n",
      "[64, 240] loss: 0.700\n",
      "[64, 300] loss: 0.689\n",
      "[64, 360] loss: 0.693\n",
      "Epoch: 64 -> Loss: 0.624698281288\n",
      "Epoch: 64 -> Test Accuracy: 68.87\n",
      "[65, 60] loss: 0.679\n",
      "[65, 120] loss: 0.672\n",
      "[65, 180] loss: 0.687\n",
      "[65, 240] loss: 0.686\n",
      "[65, 300] loss: 0.677\n",
      "[65, 360] loss: 0.694\n",
      "Epoch: 65 -> Loss: 0.762767195702\n",
      "Epoch: 65 -> Test Accuracy: 68.83\n",
      "[66, 60] loss: 0.687\n",
      "[66, 120] loss: 0.670\n",
      "[66, 180] loss: 0.676\n",
      "[66, 240] loss: 0.698\n",
      "[66, 300] loss: 0.681\n",
      "[66, 360] loss: 0.685\n",
      "Epoch: 66 -> Loss: 0.657383739948\n",
      "Epoch: 66 -> Test Accuracy: 68.72\n",
      "[67, 60] loss: 0.679\n",
      "[67, 120] loss: 0.694\n",
      "[67, 180] loss: 0.695\n",
      "[67, 240] loss: 0.690\n",
      "[67, 300] loss: 0.676\n",
      "[67, 360] loss: 0.683\n",
      "Epoch: 67 -> Loss: 0.822233974934\n",
      "Epoch: 67 -> Test Accuracy: 68.89\n",
      "[68, 60] loss: 0.676\n",
      "[68, 120] loss: 0.677\n",
      "[68, 180] loss: 0.680\n",
      "[68, 240] loss: 0.670\n",
      "[68, 300] loss: 0.690\n",
      "[68, 360] loss: 0.689\n",
      "Epoch: 68 -> Loss: 0.670591235161\n",
      "Epoch: 68 -> Test Accuracy: 69.0\n",
      "[69, 60] loss: 0.690\n",
      "[69, 120] loss: 0.677\n",
      "[69, 180] loss: 0.672\n",
      "[69, 240] loss: 0.688\n",
      "[69, 300] loss: 0.690\n",
      "[69, 360] loss: 0.679\n",
      "Epoch: 69 -> Loss: 0.680150151253\n",
      "Epoch: 69 -> Test Accuracy: 69.0\n",
      "[70, 60] loss: 0.694\n",
      "[70, 120] loss: 0.660\n",
      "[70, 180] loss: 0.682\n",
      "[70, 240] loss: 0.681\n",
      "[70, 300] loss: 0.672\n",
      "[70, 360] loss: 0.684\n",
      "Epoch: 70 -> Loss: 0.664799690247\n",
      "Epoch: 70 -> Test Accuracy: 68.83\n",
      "[71, 60] loss: 0.667\n",
      "[71, 120] loss: 0.682\n",
      "[71, 180] loss: 0.668\n",
      "[71, 240] loss: 0.679\n",
      "[71, 300] loss: 0.695\n",
      "[71, 360] loss: 0.688\n",
      "Epoch: 71 -> Loss: 0.7527795434\n",
      "Epoch: 71 -> Test Accuracy: 68.86\n",
      "[72, 60] loss: 0.680\n",
      "[72, 120] loss: 0.688\n",
      "[72, 180] loss: 0.676\n",
      "[72, 240] loss: 0.676\n",
      "[72, 300] loss: 0.676\n",
      "[72, 360] loss: 0.675\n",
      "Epoch: 72 -> Loss: 0.667218804359\n",
      "Epoch: 72 -> Test Accuracy: 68.94\n",
      "[73, 60] loss: 0.679\n",
      "[73, 120] loss: 0.677\n",
      "[73, 180] loss: 0.657\n",
      "[73, 240] loss: 0.676\n",
      "[73, 300] loss: 0.700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73, 360] loss: 0.685\n",
      "Epoch: 73 -> Loss: 0.884572684765\n",
      "Epoch: 73 -> Test Accuracy: 68.8\n",
      "[74, 60] loss: 0.679\n",
      "[74, 120] loss: 0.667\n",
      "[74, 180] loss: 0.677\n",
      "[74, 240] loss: 0.678\n",
      "[74, 300] loss: 0.673\n",
      "[74, 360] loss: 0.683\n",
      "Epoch: 74 -> Loss: 0.975633323193\n",
      "Epoch: 74 -> Test Accuracy: 68.98\n",
      "[75, 60] loss: 0.693\n",
      "[75, 120] loss: 0.692\n",
      "[75, 180] loss: 0.665\n",
      "[75, 240] loss: 0.682\n",
      "[75, 300] loss: 0.674\n",
      "[75, 360] loss: 0.675\n",
      "Epoch: 75 -> Loss: 0.729549348354\n",
      "Epoch: 75 -> Test Accuracy: 69.18\n",
      "[76, 60] loss: 0.678\n",
      "[76, 120] loss: 0.663\n",
      "[76, 180] loss: 0.688\n",
      "[76, 240] loss: 0.678\n",
      "[76, 300] loss: 0.682\n",
      "[76, 360] loss: 0.684\n",
      "Epoch: 76 -> Loss: 0.819790840149\n",
      "Epoch: 76 -> Test Accuracy: 68.87\n",
      "[77, 60] loss: 0.669\n",
      "[77, 120] loss: 0.659\n",
      "[77, 180] loss: 0.666\n",
      "[77, 240] loss: 0.701\n",
      "[77, 300] loss: 0.664\n",
      "[77, 360] loss: 0.676\n",
      "Epoch: 77 -> Loss: 0.771557331085\n",
      "Epoch: 77 -> Test Accuracy: 68.89\n",
      "[78, 60] loss: 0.656\n",
      "[78, 120] loss: 0.689\n",
      "[78, 180] loss: 0.674\n",
      "[78, 240] loss: 0.687\n",
      "[78, 300] loss: 0.661\n",
      "[78, 360] loss: 0.655\n",
      "Epoch: 78 -> Loss: 0.739880740643\n",
      "Epoch: 78 -> Test Accuracy: 68.81\n",
      "[79, 60] loss: 0.687\n",
      "[79, 120] loss: 0.658\n",
      "[79, 180] loss: 0.672\n",
      "[79, 240] loss: 0.678\n",
      "[79, 300] loss: 0.676\n",
      "[79, 360] loss: 0.655\n",
      "Epoch: 79 -> Loss: 0.694181799889\n",
      "Epoch: 79 -> Test Accuracy: 68.98\n",
      "[80, 60] loss: 0.691\n",
      "[80, 120] loss: 0.666\n",
      "[80, 180] loss: 0.669\n",
      "[80, 240] loss: 0.689\n",
      "[80, 300] loss: 0.677\n",
      "[80, 360] loss: 0.681\n",
      "Epoch: 80 -> Loss: 0.616692304611\n",
      "Epoch: 80 -> Test Accuracy: 68.98\n",
      "[81, 60] loss: 0.652\n",
      "[81, 120] loss: 0.684\n",
      "[81, 180] loss: 0.678\n",
      "[81, 240] loss: 0.670\n",
      "[81, 300] loss: 0.673\n",
      "[81, 360] loss: 0.668\n",
      "Epoch: 81 -> Loss: 0.736333727837\n",
      "Epoch: 81 -> Test Accuracy: 69.0\n",
      "[82, 60] loss: 0.660\n",
      "[82, 120] loss: 0.680\n",
      "[82, 180] loss: 0.667\n",
      "[82, 240] loss: 0.676\n",
      "[82, 300] loss: 0.674\n",
      "[82, 360] loss: 0.678\n",
      "Epoch: 82 -> Loss: 0.665478348732\n",
      "Epoch: 82 -> Test Accuracy: 68.99\n",
      "[83, 60] loss: 0.680\n",
      "[83, 120] loss: 0.666\n",
      "[83, 180] loss: 0.670\n",
      "[83, 240] loss: 0.659\n",
      "[83, 300] loss: 0.663\n",
      "[83, 360] loss: 0.665\n",
      "Epoch: 83 -> Loss: 0.75566470623\n",
      "Epoch: 83 -> Test Accuracy: 69.16\n",
      "[84, 60] loss: 0.666\n",
      "[84, 120] loss: 0.671\n",
      "[84, 180] loss: 0.689\n",
      "[84, 240] loss: 0.670\n",
      "[84, 300] loss: 0.689\n",
      "[84, 360] loss: 0.683\n",
      "Epoch: 84 -> Loss: 0.668639063835\n",
      "Epoch: 84 -> Test Accuracy: 69.13\n",
      "[85, 60] loss: 0.665\n",
      "[85, 120] loss: 0.671\n",
      "[85, 180] loss: 0.664\n",
      "[85, 240] loss: 0.663\n",
      "[85, 300] loss: 0.677\n",
      "[85, 360] loss: 0.675\n",
      "Epoch: 85 -> Loss: 0.790746808052\n",
      "Epoch: 85 -> Test Accuracy: 69.07\n",
      "[86, 60] loss: 0.676\n",
      "[86, 120] loss: 0.669\n",
      "[86, 180] loss: 0.677\n",
      "[86, 240] loss: 0.674\n",
      "[86, 300] loss: 0.663\n",
      "[86, 360] loss: 0.660\n",
      "Epoch: 86 -> Loss: 0.550673425198\n",
      "Epoch: 86 -> Test Accuracy: 69.02\n",
      "[87, 60] loss: 0.676\n",
      "[87, 120] loss: 0.662\n",
      "[87, 180] loss: 0.677\n",
      "[87, 240] loss: 0.673\n",
      "[87, 300] loss: 0.667\n",
      "[87, 360] loss: 0.692\n",
      "Epoch: 87 -> Loss: 0.652423858643\n",
      "Epoch: 87 -> Test Accuracy: 69.2\n",
      "[88, 60] loss: 0.658\n",
      "[88, 120] loss: 0.678\n",
      "[88, 180] loss: 0.670\n",
      "[88, 240] loss: 0.659\n",
      "[88, 300] loss: 0.671\n",
      "[88, 360] loss: 0.666\n",
      "Epoch: 88 -> Loss: 0.57431948185\n",
      "Epoch: 88 -> Test Accuracy: 68.85\n",
      "[89, 60] loss: 0.648\n",
      "[89, 120] loss: 0.675\n",
      "[89, 180] loss: 0.665\n",
      "[89, 240] loss: 0.690\n",
      "[89, 300] loss: 0.654\n",
      "[89, 360] loss: 0.674\n",
      "Epoch: 89 -> Loss: 0.652404785156\n",
      "Epoch: 89 -> Test Accuracy: 68.82\n",
      "[90, 60] loss: 0.679\n",
      "[90, 120] loss: 0.660\n",
      "[90, 180] loss: 0.671\n",
      "[90, 240] loss: 0.662\n",
      "[90, 300] loss: 0.675\n",
      "[90, 360] loss: 0.661\n",
      "Epoch: 90 -> Loss: 0.658668398857\n",
      "Epoch: 90 -> Test Accuracy: 69.02\n",
      "[91, 60] loss: 0.662\n",
      "[91, 120] loss: 0.676\n",
      "[91, 180] loss: 0.686\n",
      "[91, 240] loss: 0.675\n",
      "[91, 300] loss: 0.668\n",
      "[91, 360] loss: 0.671\n",
      "Epoch: 91 -> Loss: 0.696956455708\n",
      "Epoch: 91 -> Test Accuracy: 69.24\n",
      "[92, 60] loss: 0.671\n",
      "[92, 120] loss: 0.664\n",
      "[92, 180] loss: 0.664\n",
      "[92, 240] loss: 0.673\n",
      "[92, 300] loss: 0.658\n",
      "[92, 360] loss: 0.682\n",
      "Epoch: 92 -> Loss: 0.69937479496\n",
      "Epoch: 92 -> Test Accuracy: 69.08\n",
      "[93, 60] loss: 0.669\n",
      "[93, 120] loss: 0.659\n",
      "[93, 180] loss: 0.681\n",
      "[93, 240] loss: 0.668\n",
      "[93, 300] loss: 0.685\n",
      "[93, 360] loss: 0.668\n",
      "Epoch: 93 -> Loss: 0.730400443077\n",
      "Epoch: 93 -> Test Accuracy: 68.84\n",
      "[94, 60] loss: 0.664\n",
      "[94, 120] loss: 0.658\n",
      "[94, 180] loss: 0.669\n",
      "[94, 240] loss: 0.686\n",
      "[94, 300] loss: 0.669\n",
      "[94, 360] loss: 0.670\n",
      "Epoch: 94 -> Loss: 0.659617066383\n",
      "Epoch: 94 -> Test Accuracy: 68.96\n",
      "[95, 60] loss: 0.664\n",
      "[95, 120] loss: 0.673\n",
      "[95, 180] loss: 0.645\n",
      "[95, 240] loss: 0.667\n",
      "[95, 300] loss: 0.646\n",
      "[95, 360] loss: 0.668\n",
      "Epoch: 95 -> Loss: 0.871490001678\n",
      "Epoch: 95 -> Test Accuracy: 68.92\n",
      "[96, 60] loss: 0.660\n",
      "[96, 120] loss: 0.653\n",
      "[96, 180] loss: 0.667\n",
      "[96, 240] loss: 0.669\n",
      "[96, 300] loss: 0.664\n",
      "[96, 360] loss: 0.653\n",
      "Epoch: 96 -> Loss: 0.720087707043\n",
      "Epoch: 96 -> Test Accuracy: 69.2\n",
      "[97, 60] loss: 0.665\n",
      "[97, 120] loss: 0.651\n",
      "[97, 180] loss: 0.667\n",
      "[97, 240] loss: 0.664\n",
      "[97, 300] loss: 0.664\n",
      "[97, 360] loss: 0.685\n",
      "Epoch: 97 -> Loss: 0.703871011734\n",
      "Epoch: 97 -> Test Accuracy: 69.29\n",
      "[98, 60] loss: 0.653\n",
      "[98, 120] loss: 0.658\n",
      "[98, 180] loss: 0.661\n",
      "[98, 240] loss: 0.678\n",
      "[98, 300] loss: 0.669\n",
      "[98, 360] loss: 0.658\n",
      "Epoch: 98 -> Loss: 0.711778044701\n",
      "Epoch: 98 -> Test Accuracy: 69.15\n",
      "[99, 60] loss: 0.670\n",
      "[99, 120] loss: 0.653\n",
      "[99, 180] loss: 0.658\n",
      "[99, 240] loss: 0.665\n",
      "[99, 300] loss: 0.657\n",
      "[99, 360] loss: 0.668\n",
      "Epoch: 99 -> Loss: 0.734291732311\n",
      "Epoch: 99 -> Test Accuracy: 69.29\n",
      "[100, 60] loss: 0.662\n",
      "[100, 120] loss: 0.661\n",
      "[100, 180] loss: 0.672\n",
      "[100, 240] loss: 0.670\n",
      "[100, 300] loss: 0.676\n",
      "[100, 360] loss: 0.640\n",
      "Epoch: 100 -> Loss: 0.711661815643\n",
      "Epoch: 100 -> Test Accuracy: 69.25\n",
      "Finished Training\n",
      "[1, 60] loss: 2.931\n",
      "[1, 120] loss: 2.165\n",
      "[1, 180] loss: 2.119\n",
      "[1, 240] loss: 2.074\n",
      "[1, 300] loss: 2.056\n",
      "[1, 360] loss: 2.040\n",
      "Epoch: 1 -> Loss: 2.11470651627\n",
      "Epoch: 1 -> Test Accuracy: 25.98\n",
      "[2, 60] loss: 2.009\n",
      "[2, 120] loss: 1.995\n",
      "[2, 180] loss: 2.003\n",
      "[2, 240] loss: 1.973\n",
      "[2, 300] loss: 1.973\n",
      "[2, 360] loss: 1.961\n",
      "Epoch: 2 -> Loss: 2.02872395515\n",
      "Epoch: 2 -> Test Accuracy: 27.72\n",
      "[3, 60] loss: 1.947\n",
      "[3, 120] loss: 1.954\n",
      "[3, 180] loss: 1.940\n",
      "[3, 240] loss: 1.923\n",
      "[3, 300] loss: 1.926\n",
      "[3, 360] loss: 1.939\n",
      "Epoch: 3 -> Loss: 1.97604501247\n",
      "Epoch: 3 -> Test Accuracy: 29.13\n",
      "[4, 60] loss: 1.917\n",
      "[4, 120] loss: 1.906\n",
      "[4, 180] loss: 1.903\n",
      "[4, 240] loss: 1.914\n",
      "[4, 300] loss: 1.913\n",
      "[4, 360] loss: 1.910\n",
      "Epoch: 4 -> Loss: 1.72013437748\n",
      "Epoch: 4 -> Test Accuracy: 29.7\n",
      "[5, 60] loss: 1.889\n",
      "[5, 120] loss: 1.904\n",
      "[5, 180] loss: 1.886\n",
      "[5, 240] loss: 1.901\n",
      "[5, 300] loss: 1.891\n",
      "[5, 360] loss: 1.876\n",
      "Epoch: 5 -> Loss: 1.89976274967\n",
      "Epoch: 5 -> Test Accuracy: 29.67\n",
      "[6, 60] loss: 1.892\n",
      "[6, 120] loss: 1.875\n",
      "[6, 180] loss: 1.881\n",
      "[6, 240] loss: 1.878\n",
      "[6, 300] loss: 1.882\n",
      "[6, 360] loss: 1.883\n",
      "Epoch: 6 -> Loss: 1.86010873318\n",
      "Epoch: 6 -> Test Accuracy: 30.42\n",
      "[7, 60] loss: 1.881\n",
      "[7, 120] loss: 1.876\n",
      "[7, 180] loss: 1.872\n",
      "[7, 240] loss: 1.884\n",
      "[7, 300] loss: 1.872\n",
      "[7, 360] loss: 1.864\n",
      "Epoch: 7 -> Loss: 1.8686811924\n",
      "Epoch: 7 -> Test Accuracy: 30.48\n",
      "[8, 60] loss: 1.871\n",
      "[8, 120] loss: 1.859\n",
      "[8, 180] loss: 1.872\n",
      "[8, 240] loss: 1.879\n",
      "[8, 300] loss: 1.857\n",
      "[8, 360] loss: 1.859\n",
      "Epoch: 8 -> Loss: 1.92451035976\n",
      "Epoch: 8 -> Test Accuracy: 30.21\n",
      "[9, 60] loss: 1.871\n",
      "[9, 120] loss: 1.865\n",
      "[9, 180] loss: 1.855\n",
      "[9, 240] loss: 1.870\n",
      "[9, 300] loss: 1.865\n",
      "[9, 360] loss: 1.869\n",
      "Epoch: 9 -> Loss: 1.90211796761\n",
      "Epoch: 9 -> Test Accuracy: 31.01\n",
      "[10, 60] loss: 1.869\n",
      "[10, 120] loss: 1.859\n",
      "[10, 180] loss: 1.847\n",
      "[10, 240] loss: 1.849\n",
      "[10, 300] loss: 1.872\n",
      "[10, 360] loss: 1.856\n",
      "Epoch: 10 -> Loss: 1.9148209095\n",
      "Epoch: 10 -> Test Accuracy: 30.58\n",
      "[11, 60] loss: 1.853\n",
      "[11, 120] loss: 1.852\n",
      "[11, 180] loss: 1.861\n",
      "[11, 240] loss: 1.865\n",
      "[11, 300] loss: 1.855\n",
      "[11, 360] loss: 1.858\n",
      "Epoch: 11 -> Loss: 1.84607315063\n",
      "Epoch: 11 -> Test Accuracy: 30.17\n",
      "[12, 60] loss: 1.867\n",
      "[12, 120] loss: 1.848\n",
      "[12, 180] loss: 1.855\n",
      "[12, 240] loss: 1.860\n",
      "[12, 300] loss: 1.863\n",
      "[12, 360] loss: 1.837\n",
      "Epoch: 12 -> Loss: 1.91767191887\n",
      "Epoch: 12 -> Test Accuracy: 30.27\n",
      "[13, 60] loss: 1.851\n",
      "[13, 120] loss: 1.846\n",
      "[13, 180] loss: 1.852\n",
      "[13, 240] loss: 1.858\n",
      "[13, 300] loss: 1.841\n",
      "[13, 360] loss: 1.830\n",
      "Epoch: 13 -> Loss: 1.8212941885\n",
      "Epoch: 13 -> Test Accuracy: 30.8\n",
      "[14, 60] loss: 1.861\n",
      "[14, 120] loss: 1.853\n",
      "[14, 180] loss: 1.843\n",
      "[14, 240] loss: 1.853\n",
      "[14, 300] loss: 1.862\n",
      "[14, 360] loss: 1.832\n",
      "Epoch: 14 -> Loss: 1.85173642635\n",
      "Epoch: 14 -> Test Accuracy: 31.09\n",
      "[15, 60] loss: 1.867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 120] loss: 1.847\n",
      "[15, 180] loss: 1.840\n",
      "[15, 240] loss: 1.851\n",
      "[15, 300] loss: 1.845\n",
      "[15, 360] loss: 1.844\n",
      "Epoch: 15 -> Loss: 1.82569944859\n",
      "Epoch: 15 -> Test Accuracy: 30.87\n",
      "[16, 60] loss: 1.836\n",
      "[16, 120] loss: 1.849\n",
      "[16, 180] loss: 1.851\n",
      "[16, 240] loss: 1.836\n",
      "[16, 300] loss: 1.842\n",
      "[16, 360] loss: 1.833\n",
      "Epoch: 16 -> Loss: 1.79934942722\n",
      "Epoch: 16 -> Test Accuracy: 31.33\n",
      "[17, 60] loss: 1.833\n",
      "[17, 120] loss: 1.865\n",
      "[17, 180] loss: 1.839\n",
      "[17, 240] loss: 1.828\n",
      "[17, 300] loss: 1.834\n",
      "[17, 360] loss: 1.855\n",
      "Epoch: 17 -> Loss: 1.99478721619\n",
      "Epoch: 17 -> Test Accuracy: 30.63\n",
      "[18, 60] loss: 1.843\n",
      "[18, 120] loss: 1.844\n",
      "[18, 180] loss: 1.830\n",
      "[18, 240] loss: 1.836\n",
      "[18, 300] loss: 1.843\n",
      "[18, 360] loss: 1.840\n",
      "Epoch: 18 -> Loss: 2.09351754189\n",
      "Epoch: 18 -> Test Accuracy: 30.32\n",
      "[19, 60] loss: 1.849\n",
      "[19, 120] loss: 1.832\n",
      "[19, 180] loss: 1.847\n",
      "[19, 240] loss: 1.842\n",
      "[19, 300] loss: 1.837\n",
      "[19, 360] loss: 1.838\n",
      "Epoch: 19 -> Loss: 1.78403949738\n",
      "Epoch: 19 -> Test Accuracy: 31.38\n",
      "[20, 60] loss: 1.852\n",
      "[20, 120] loss: 1.851\n",
      "[20, 180] loss: 1.850\n",
      "[20, 240] loss: 1.817\n",
      "[20, 300] loss: 1.834\n",
      "[20, 360] loss: 1.850\n",
      "Epoch: 20 -> Loss: 1.81015133858\n",
      "Epoch: 20 -> Test Accuracy: 31.63\n",
      "[21, 60] loss: 1.806\n",
      "[21, 120] loss: 1.783\n",
      "[21, 180] loss: 1.775\n",
      "[21, 240] loss: 1.763\n",
      "[21, 300] loss: 1.757\n",
      "[21, 360] loss: 1.753\n",
      "Epoch: 21 -> Loss: 1.6613740921\n",
      "Epoch: 21 -> Test Accuracy: 34.33\n",
      "[22, 60] loss: 1.761\n",
      "[22, 120] loss: 1.752\n",
      "[22, 180] loss: 1.749\n",
      "[22, 240] loss: 1.745\n",
      "[22, 300] loss: 1.746\n",
      "[22, 360] loss: 1.746\n",
      "Epoch: 22 -> Loss: 1.83144021034\n",
      "Epoch: 22 -> Test Accuracy: 34.1\n",
      "[23, 60] loss: 1.723\n",
      "[23, 120] loss: 1.738\n",
      "[23, 180] loss: 1.745\n",
      "[23, 240] loss: 1.739\n",
      "[23, 300] loss: 1.744\n",
      "[23, 360] loss: 1.748\n",
      "Epoch: 23 -> Loss: 1.74424338341\n",
      "Epoch: 23 -> Test Accuracy: 33.88\n",
      "[24, 60] loss: 1.738\n",
      "[24, 120] loss: 1.745\n",
      "[24, 180] loss: 1.737\n",
      "[24, 240] loss: 1.754\n",
      "[24, 300] loss: 1.749\n",
      "[24, 360] loss: 1.735\n",
      "Epoch: 24 -> Loss: 1.65283930302\n",
      "Epoch: 24 -> Test Accuracy: 34.8\n",
      "[25, 60] loss: 1.733\n",
      "[25, 120] loss: 1.747\n",
      "[25, 180] loss: 1.728\n",
      "[25, 240] loss: 1.742\n",
      "[25, 300] loss: 1.736\n",
      "[25, 360] loss: 1.741\n",
      "Epoch: 25 -> Loss: 1.88935351372\n",
      "Epoch: 25 -> Test Accuracy: 34.58\n",
      "[26, 60] loss: 1.724\n",
      "[26, 120] loss: 1.721\n",
      "[26, 180] loss: 1.746\n",
      "[26, 240] loss: 1.728\n",
      "[26, 300] loss: 1.738\n",
      "[26, 360] loss: 1.712\n",
      "Epoch: 26 -> Loss: 1.74550795555\n",
      "Epoch: 26 -> Test Accuracy: 34.37\n",
      "[27, 60] loss: 1.735\n",
      "[27, 120] loss: 1.730\n",
      "[27, 180] loss: 1.731\n",
      "[27, 240] loss: 1.736\n",
      "[27, 300] loss: 1.719\n",
      "[27, 360] loss: 1.722\n",
      "Epoch: 27 -> Loss: 1.61271476746\n",
      "Epoch: 27 -> Test Accuracy: 34.79\n",
      "[28, 60] loss: 1.705\n",
      "[28, 120] loss: 1.712\n",
      "[28, 180] loss: 1.727\n",
      "[28, 240] loss: 1.750\n",
      "[28, 300] loss: 1.720\n",
      "[28, 360] loss: 1.745\n",
      "Epoch: 28 -> Loss: 1.6578963995\n",
      "Epoch: 28 -> Test Accuracy: 34.62\n",
      "[29, 60] loss: 1.718\n",
      "[29, 120] loss: 1.735\n",
      "[29, 180] loss: 1.714\n",
      "[29, 240] loss: 1.722\n",
      "[29, 300] loss: 1.726\n",
      "[29, 360] loss: 1.742\n",
      "Epoch: 29 -> Loss: 1.58735466003\n",
      "Epoch: 29 -> Test Accuracy: 35.12\n",
      "[30, 60] loss: 1.728\n",
      "[30, 120] loss: 1.733\n",
      "[30, 180] loss: 1.732\n",
      "[30, 240] loss: 1.728\n",
      "[30, 300] loss: 1.712\n",
      "[30, 360] loss: 1.712\n",
      "Epoch: 30 -> Loss: 1.8189239502\n",
      "Epoch: 30 -> Test Accuracy: 34.25\n",
      "[31, 60] loss: 1.733\n",
      "[31, 120] loss: 1.729\n",
      "[31, 180] loss: 1.728\n",
      "[31, 240] loss: 1.740\n",
      "[31, 300] loss: 1.722\n",
      "[31, 360] loss: 1.720\n",
      "Epoch: 31 -> Loss: 1.60332274437\n",
      "Epoch: 31 -> Test Accuracy: 34.62\n",
      "[32, 60] loss: 1.722\n",
      "[32, 120] loss: 1.715\n",
      "[32, 180] loss: 1.725\n",
      "[32, 240] loss: 1.718\n",
      "[32, 300] loss: 1.725\n",
      "[32, 360] loss: 1.731\n",
      "Epoch: 32 -> Loss: 1.72777080536\n",
      "Epoch: 32 -> Test Accuracy: 34.85\n",
      "[33, 60] loss: 1.727\n",
      "[33, 120] loss: 1.718\n",
      "[33, 180] loss: 1.698\n",
      "[33, 240] loss: 1.731\n",
      "[33, 300] loss: 1.720\n",
      "[33, 360] loss: 1.721\n",
      "Epoch: 33 -> Loss: 1.91199421883\n",
      "Epoch: 33 -> Test Accuracy: 35.0\n",
      "[34, 60] loss: 1.712\n",
      "[34, 120] loss: 1.715\n",
      "[34, 180] loss: 1.722\n",
      "[34, 240] loss: 1.730\n",
      "[34, 300] loss: 1.725\n",
      "[34, 360] loss: 1.711\n",
      "Epoch: 34 -> Loss: 1.61569440365\n",
      "Epoch: 34 -> Test Accuracy: 33.85\n",
      "[35, 60] loss: 1.719\n",
      "[35, 120] loss: 1.712\n",
      "[35, 180] loss: 1.703\n",
      "[35, 240] loss: 1.709\n",
      "[35, 300] loss: 1.715\n",
      "[35, 360] loss: 1.718\n",
      "Epoch: 35 -> Loss: 1.6523090601\n",
      "Epoch: 35 -> Test Accuracy: 34.34\n",
      "[36, 60] loss: 1.719\n",
      "[36, 120] loss: 1.735\n",
      "[36, 180] loss: 1.718\n",
      "[36, 240] loss: 1.716\n",
      "[36, 300] loss: 1.717\n",
      "[36, 360] loss: 1.702\n",
      "Epoch: 36 -> Loss: 1.76068782806\n",
      "Epoch: 36 -> Test Accuracy: 34.35\n",
      "[37, 60] loss: 1.710\n",
      "[37, 120] loss: 1.713\n",
      "[37, 180] loss: 1.730\n",
      "[37, 240] loss: 1.720\n",
      "[37, 300] loss: 1.715\n",
      "[37, 360] loss: 1.708\n",
      "Epoch: 37 -> Loss: 1.66690611839\n",
      "Epoch: 37 -> Test Accuracy: 35.68\n",
      "[38, 60] loss: 1.710\n",
      "[38, 120] loss: 1.699\n",
      "[38, 180] loss: 1.708\n",
      "[38, 240] loss: 1.730\n",
      "[38, 300] loss: 1.716\n",
      "[38, 360] loss: 1.714\n",
      "Epoch: 38 -> Loss: 1.82064652443\n",
      "Epoch: 38 -> Test Accuracy: 34.45\n",
      "[39, 60] loss: 1.728\n",
      "[39, 120] loss: 1.715\n",
      "[39, 180] loss: 1.725\n",
      "[39, 240] loss: 1.710\n",
      "[39, 300] loss: 1.718\n",
      "[39, 360] loss: 1.724\n",
      "Epoch: 39 -> Loss: 1.73448312283\n",
      "Epoch: 39 -> Test Accuracy: 34.16\n",
      "[40, 60] loss: 1.725\n",
      "[40, 120] loss: 1.706\n",
      "[40, 180] loss: 1.700\n",
      "[40, 240] loss: 1.723\n",
      "[40, 300] loss: 1.706\n",
      "[40, 360] loss: 1.698\n",
      "Epoch: 40 -> Loss: 1.68348753452\n",
      "Epoch: 40 -> Test Accuracy: 34.46\n",
      "[41, 60] loss: 1.696\n",
      "[41, 120] loss: 1.689\n",
      "[41, 180] loss: 1.685\n",
      "[41, 240] loss: 1.676\n",
      "[41, 300] loss: 1.685\n",
      "[41, 360] loss: 1.668\n",
      "Epoch: 41 -> Loss: 1.52834236622\n",
      "Epoch: 41 -> Test Accuracy: 35.84\n",
      "[42, 60] loss: 1.663\n",
      "[42, 120] loss: 1.671\n",
      "[42, 180] loss: 1.656\n",
      "[42, 240] loss: 1.668\n",
      "[42, 300] loss: 1.672\n",
      "[42, 360] loss: 1.654\n",
      "Epoch: 42 -> Loss: 1.70603752136\n",
      "Epoch: 42 -> Test Accuracy: 36.29\n",
      "[43, 60] loss: 1.665\n",
      "[43, 120] loss: 1.647\n",
      "[43, 180] loss: 1.651\n",
      "[43, 240] loss: 1.640\n",
      "[43, 300] loss: 1.673\n",
      "[43, 360] loss: 1.656\n",
      "Epoch: 43 -> Loss: 1.57988286018\n",
      "Epoch: 43 -> Test Accuracy: 36.31\n",
      "[44, 60] loss: 1.646\n",
      "[44, 120] loss: 1.659\n",
      "[44, 180] loss: 1.654\n",
      "[44, 240] loss: 1.664\n",
      "[44, 300] loss: 1.653\n",
      "[44, 360] loss: 1.659\n",
      "Epoch: 44 -> Loss: 1.67558634281\n",
      "Epoch: 44 -> Test Accuracy: 36.22\n",
      "[45, 60] loss: 1.649\n",
      "[45, 120] loss: 1.652\n",
      "[45, 180] loss: 1.657\n",
      "[45, 240] loss: 1.646\n",
      "[45, 300] loss: 1.659\n",
      "[45, 360] loss: 1.642\n",
      "Epoch: 45 -> Loss: 1.60718667507\n",
      "Epoch: 45 -> Test Accuracy: 36.44\n",
      "[46, 60] loss: 1.632\n",
      "[46, 120] loss: 1.672\n",
      "[46, 180] loss: 1.635\n",
      "[46, 240] loss: 1.634\n",
      "[46, 300] loss: 1.644\n",
      "[46, 360] loss: 1.641\n",
      "Epoch: 46 -> Loss: 1.74687170982\n",
      "Epoch: 46 -> Test Accuracy: 36.8\n",
      "[47, 60] loss: 1.640\n",
      "[47, 120] loss: 1.630\n",
      "[47, 180] loss: 1.640\n",
      "[47, 240] loss: 1.640\n",
      "[47, 300] loss: 1.641\n",
      "[47, 360] loss: 1.629\n",
      "Epoch: 47 -> Loss: 1.64698827267\n",
      "Epoch: 47 -> Test Accuracy: 36.91\n",
      "[48, 60] loss: 1.633\n",
      "[48, 120] loss: 1.629\n",
      "[48, 180] loss: 1.621\n",
      "[48, 240] loss: 1.631\n",
      "[48, 300] loss: 1.647\n",
      "[48, 360] loss: 1.632\n",
      "Epoch: 48 -> Loss: 1.51803803444\n",
      "Epoch: 48 -> Test Accuracy: 36.86\n",
      "[49, 60] loss: 1.623\n",
      "[49, 120] loss: 1.642\n",
      "[49, 180] loss: 1.633\n",
      "[49, 240] loss: 1.656\n",
      "[49, 300] loss: 1.626\n",
      "[49, 360] loss: 1.634\n",
      "Epoch: 49 -> Loss: 1.72642457485\n",
      "Epoch: 49 -> Test Accuracy: 36.64\n",
      "[50, 60] loss: 1.638\n",
      "[50, 120] loss: 1.632\n",
      "[50, 180] loss: 1.628\n",
      "[50, 240] loss: 1.625\n",
      "[50, 300] loss: 1.636\n",
      "[50, 360] loss: 1.625\n",
      "Epoch: 50 -> Loss: 1.73197650909\n",
      "Epoch: 50 -> Test Accuracy: 36.81\n",
      "[51, 60] loss: 1.636\n",
      "[51, 120] loss: 1.642\n",
      "[51, 180] loss: 1.610\n",
      "[51, 240] loss: 1.650\n",
      "[51, 300] loss: 1.620\n",
      "[51, 360] loss: 1.615\n",
      "Epoch: 51 -> Loss: 1.52561450005\n",
      "Epoch: 51 -> Test Accuracy: 36.71\n",
      "[52, 60] loss: 1.629\n",
      "[52, 120] loss: 1.643\n",
      "[52, 180] loss: 1.633\n",
      "[52, 240] loss: 1.643\n",
      "[52, 300] loss: 1.621\n",
      "[52, 360] loss: 1.625\n",
      "Epoch: 52 -> Loss: 1.57939207554\n",
      "Epoch: 52 -> Test Accuracy: 37.06\n",
      "[53, 60] loss: 1.624\n",
      "[53, 120] loss: 1.628\n",
      "[53, 180] loss: 1.622\n",
      "[53, 240] loss: 1.642\n",
      "[53, 300] loss: 1.626\n",
      "[53, 360] loss: 1.639\n",
      "Epoch: 53 -> Loss: 1.49854695797\n",
      "Epoch: 53 -> Test Accuracy: 36.67\n",
      "[54, 60] loss: 1.619\n",
      "[54, 120] loss: 1.635\n",
      "[54, 180] loss: 1.639\n",
      "[54, 240] loss: 1.628\n",
      "[54, 300] loss: 1.625\n",
      "[54, 360] loss: 1.632\n",
      "Epoch: 54 -> Loss: 1.65057373047\n",
      "Epoch: 54 -> Test Accuracy: 36.46\n",
      "[55, 60] loss: 1.639\n",
      "[55, 120] loss: 1.638\n",
      "[55, 180] loss: 1.636\n",
      "[55, 240] loss: 1.632\n",
      "[55, 300] loss: 1.624\n",
      "[55, 360] loss: 1.608\n",
      "Epoch: 55 -> Loss: 1.59399473667\n",
      "Epoch: 55 -> Test Accuracy: 36.81\n",
      "[56, 60] loss: 1.628\n",
      "[56, 120] loss: 1.626\n",
      "[56, 180] loss: 1.624\n",
      "[56, 240] loss: 1.631\n",
      "[56, 300] loss: 1.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56, 360] loss: 1.620\n",
      "Epoch: 56 -> Loss: 1.5257871151\n",
      "Epoch: 56 -> Test Accuracy: 36.75\n",
      "[57, 60] loss: 1.607\n",
      "[57, 120] loss: 1.629\n",
      "[57, 180] loss: 1.641\n",
      "[57, 240] loss: 1.615\n",
      "[57, 300] loss: 1.633\n",
      "[57, 360] loss: 1.628\n",
      "Epoch: 57 -> Loss: 1.52280402184\n",
      "Epoch: 57 -> Test Accuracy: 36.99\n",
      "[58, 60] loss: 1.623\n",
      "[58, 120] loss: 1.614\n",
      "[58, 180] loss: 1.637\n",
      "[58, 240] loss: 1.604\n",
      "[58, 300] loss: 1.633\n",
      "[58, 360] loss: 1.636\n",
      "Epoch: 58 -> Loss: 1.6641600132\n",
      "Epoch: 58 -> Test Accuracy: 36.92\n",
      "[59, 60] loss: 1.625\n",
      "[59, 120] loss: 1.627\n",
      "[59, 180] loss: 1.618\n",
      "[59, 240] loss: 1.613\n",
      "[59, 300] loss: 1.621\n",
      "[59, 360] loss: 1.617\n",
      "Epoch: 59 -> Loss: 1.66690540314\n",
      "Epoch: 59 -> Test Accuracy: 36.56\n",
      "[60, 60] loss: 1.622\n",
      "[60, 120] loss: 1.618\n",
      "[60, 180] loss: 1.635\n",
      "[60, 240] loss: 1.594\n",
      "[60, 300] loss: 1.623\n",
      "[60, 360] loss: 1.636\n",
      "Epoch: 60 -> Loss: 1.82768595219\n",
      "Epoch: 60 -> Test Accuracy: 37.0\n",
      "[61, 60] loss: 1.631\n",
      "[61, 120] loss: 1.603\n",
      "[61, 180] loss: 1.641\n",
      "[61, 240] loss: 1.622\n",
      "[61, 300] loss: 1.631\n",
      "[61, 360] loss: 1.629\n",
      "Epoch: 61 -> Loss: 1.67841947079\n",
      "Epoch: 61 -> Test Accuracy: 36.98\n",
      "[62, 60] loss: 1.612\n",
      "[62, 120] loss: 1.618\n",
      "[62, 180] loss: 1.602\n",
      "[62, 240] loss: 1.629\n",
      "[62, 300] loss: 1.631\n",
      "[62, 360] loss: 1.628\n",
      "Epoch: 62 -> Loss: 1.84376084805\n",
      "Epoch: 62 -> Test Accuracy: 37.0\n",
      "[63, 60] loss: 1.609\n",
      "[63, 120] loss: 1.618\n",
      "[63, 180] loss: 1.619\n",
      "[63, 240] loss: 1.632\n",
      "[63, 300] loss: 1.634\n",
      "[63, 360] loss: 1.627\n",
      "Epoch: 63 -> Loss: 1.6444413662\n",
      "Epoch: 63 -> Test Accuracy: 37.0\n",
      "[64, 60] loss: 1.618\n",
      "[64, 120] loss: 1.630\n",
      "[64, 180] loss: 1.629\n",
      "[64, 240] loss: 1.627\n",
      "[64, 300] loss: 1.617\n",
      "[64, 360] loss: 1.605\n",
      "Epoch: 64 -> Loss: 1.56653404236\n",
      "Epoch: 64 -> Test Accuracy: 36.97\n",
      "[65, 60] loss: 1.637\n",
      "[65, 120] loss: 1.619\n",
      "[65, 180] loss: 1.630\n",
      "[65, 240] loss: 1.641\n",
      "[65, 300] loss: 1.598\n",
      "[65, 360] loss: 1.625\n",
      "Epoch: 65 -> Loss: 1.43001961708\n",
      "Epoch: 65 -> Test Accuracy: 36.97\n",
      "[66, 60] loss: 1.629\n",
      "[66, 120] loss: 1.612\n",
      "[66, 180] loss: 1.629\n",
      "[66, 240] loss: 1.616\n",
      "[66, 300] loss: 1.629\n",
      "[66, 360] loss: 1.628\n",
      "Epoch: 66 -> Loss: 1.51320910454\n",
      "Epoch: 66 -> Test Accuracy: 36.87\n",
      "[67, 60] loss: 1.607\n",
      "[67, 120] loss: 1.628\n",
      "[67, 180] loss: 1.615\n",
      "[67, 240] loss: 1.613\n",
      "[67, 300] loss: 1.601\n",
      "[67, 360] loss: 1.646\n",
      "Epoch: 67 -> Loss: 1.56546723843\n",
      "Epoch: 67 -> Test Accuracy: 37.12\n",
      "[68, 60] loss: 1.603\n",
      "[68, 120] loss: 1.633\n",
      "[68, 180] loss: 1.616\n",
      "[68, 240] loss: 1.617\n",
      "[68, 300] loss: 1.618\n",
      "[68, 360] loss: 1.618\n",
      "Epoch: 68 -> Loss: 1.67814826965\n",
      "Epoch: 68 -> Test Accuracy: 37.21\n",
      "[69, 60] loss: 1.631\n",
      "[69, 120] loss: 1.617\n",
      "[69, 180] loss: 1.617\n",
      "[69, 240] loss: 1.624\n",
      "[69, 300] loss: 1.622\n",
      "[69, 360] loss: 1.629\n",
      "Epoch: 69 -> Loss: 1.45329415798\n",
      "Epoch: 69 -> Test Accuracy: 37.18\n",
      "[70, 60] loss: 1.618\n",
      "[70, 120] loss: 1.633\n",
      "[70, 180] loss: 1.615\n",
      "[70, 240] loss: 1.618\n",
      "[70, 300] loss: 1.609\n",
      "[70, 360] loss: 1.607\n",
      "Epoch: 70 -> Loss: 1.69169104099\n",
      "Epoch: 70 -> Test Accuracy: 37.02\n",
      "[71, 60] loss: 1.624\n",
      "[71, 120] loss: 1.608\n",
      "[71, 180] loss: 1.615\n",
      "[71, 240] loss: 1.619\n",
      "[71, 300] loss: 1.624\n",
      "[71, 360] loss: 1.613\n",
      "Epoch: 71 -> Loss: 1.6613509655\n",
      "Epoch: 71 -> Test Accuracy: 37.0\n",
      "[72, 60] loss: 1.629\n",
      "[72, 120] loss: 1.625\n",
      "[72, 180] loss: 1.614\n",
      "[72, 240] loss: 1.613\n",
      "[72, 300] loss: 1.617\n",
      "[72, 360] loss: 1.618\n",
      "Epoch: 72 -> Loss: 1.54609954357\n",
      "Epoch: 72 -> Test Accuracy: 37.17\n",
      "[73, 60] loss: 1.612\n",
      "[73, 120] loss: 1.624\n",
      "[73, 180] loss: 1.619\n",
      "[73, 240] loss: 1.610\n",
      "[73, 300] loss: 1.621\n",
      "[73, 360] loss: 1.626\n",
      "Epoch: 73 -> Loss: 1.73334145546\n",
      "Epoch: 73 -> Test Accuracy: 37.09\n",
      "[74, 60] loss: 1.607\n",
      "[74, 120] loss: 1.629\n",
      "[74, 180] loss: 1.613\n",
      "[74, 240] loss: 1.614\n",
      "[74, 300] loss: 1.615\n",
      "[74, 360] loss: 1.630\n",
      "Epoch: 74 -> Loss: 1.57009804249\n",
      "Epoch: 74 -> Test Accuracy: 36.96\n",
      "[75, 60] loss: 1.615\n",
      "[75, 120] loss: 1.607\n",
      "[75, 180] loss: 1.610\n",
      "[75, 240] loss: 1.622\n",
      "[75, 300] loss: 1.610\n",
      "[75, 360] loss: 1.630\n",
      "Epoch: 75 -> Loss: 1.52341198921\n",
      "Epoch: 75 -> Test Accuracy: 37.03\n",
      "[76, 60] loss: 1.629\n",
      "[76, 120] loss: 1.614\n",
      "[76, 180] loss: 1.600\n",
      "[76, 240] loss: 1.623\n",
      "[76, 300] loss: 1.621\n",
      "[76, 360] loss: 1.617\n",
      "Epoch: 76 -> Loss: 1.68703043461\n",
      "Epoch: 76 -> Test Accuracy: 37.19\n",
      "[77, 60] loss: 1.616\n",
      "[77, 120] loss: 1.622\n",
      "[77, 180] loss: 1.618\n",
      "[77, 240] loss: 1.609\n",
      "[77, 300] loss: 1.616\n",
      "[77, 360] loss: 1.599\n",
      "Epoch: 77 -> Loss: 1.63975214958\n",
      "Epoch: 77 -> Test Accuracy: 36.96\n",
      "[78, 60] loss: 1.606\n",
      "[78, 120] loss: 1.602\n",
      "[78, 180] loss: 1.619\n",
      "[78, 240] loss: 1.623\n",
      "[78, 300] loss: 1.596\n",
      "[78, 360] loss: 1.617\n",
      "Epoch: 78 -> Loss: 1.6670563221\n",
      "Epoch: 78 -> Test Accuracy: 37.06\n",
      "[79, 60] loss: 1.607\n",
      "[79, 120] loss: 1.617\n",
      "[79, 180] loss: 1.608\n",
      "[79, 240] loss: 1.603\n",
      "[79, 300] loss: 1.611\n",
      "[79, 360] loss: 1.609\n",
      "Epoch: 79 -> Loss: 1.66875171661\n",
      "Epoch: 79 -> Test Accuracy: 36.95\n",
      "[80, 60] loss: 1.612\n",
      "[80, 120] loss: 1.620\n",
      "[80, 180] loss: 1.618\n",
      "[80, 240] loss: 1.624\n",
      "[80, 300] loss: 1.609\n",
      "[80, 360] loss: 1.633\n",
      "Epoch: 80 -> Loss: 1.60641980171\n",
      "Epoch: 80 -> Test Accuracy: 36.99\n",
      "[81, 60] loss: 1.611\n",
      "[81, 120] loss: 1.606\n",
      "[81, 180] loss: 1.600\n",
      "[81, 240] loss: 1.613\n",
      "[81, 300] loss: 1.621\n",
      "[81, 360] loss: 1.608\n",
      "Epoch: 81 -> Loss: 1.58378899097\n",
      "Epoch: 81 -> Test Accuracy: 37.13\n",
      "[82, 60] loss: 1.613\n",
      "[82, 120] loss: 1.623\n",
      "[82, 180] loss: 1.605\n",
      "[82, 240] loss: 1.582\n",
      "[82, 300] loss: 1.610\n",
      "[82, 360] loss: 1.633\n",
      "Epoch: 82 -> Loss: 1.48321247101\n",
      "Epoch: 82 -> Test Accuracy: 37.37\n",
      "[83, 60] loss: 1.626\n",
      "[83, 120] loss: 1.587\n",
      "[83, 180] loss: 1.632\n",
      "[83, 240] loss: 1.600\n",
      "[83, 300] loss: 1.630\n",
      "[83, 360] loss: 1.616\n",
      "Epoch: 83 -> Loss: 1.63629472256\n",
      "Epoch: 83 -> Test Accuracy: 37.14\n",
      "[84, 60] loss: 1.603\n",
      "[84, 120] loss: 1.605\n",
      "[84, 180] loss: 1.611\n",
      "[84, 240] loss: 1.617\n",
      "[84, 300] loss: 1.620\n",
      "[84, 360] loss: 1.609\n",
      "Epoch: 84 -> Loss: 1.55503547192\n",
      "Epoch: 84 -> Test Accuracy: 37.23\n",
      "[85, 60] loss: 1.601\n",
      "[85, 120] loss: 1.611\n",
      "[85, 180] loss: 1.602\n",
      "[85, 240] loss: 1.604\n",
      "[85, 300] loss: 1.606\n",
      "[85, 360] loss: 1.607\n",
      "Epoch: 85 -> Loss: 1.59662652016\n",
      "Epoch: 85 -> Test Accuracy: 37.21\n",
      "[86, 60] loss: 1.597\n",
      "[86, 120] loss: 1.613\n",
      "[86, 180] loss: 1.622\n",
      "[86, 240] loss: 1.622\n",
      "[86, 300] loss: 1.606\n",
      "[86, 360] loss: 1.610\n",
      "Epoch: 86 -> Loss: 1.67283177376\n",
      "Epoch: 86 -> Test Accuracy: 37.62\n",
      "[87, 60] loss: 1.606\n",
      "[87, 120] loss: 1.615\n",
      "[87, 180] loss: 1.602\n",
      "[87, 240] loss: 1.600\n",
      "[87, 300] loss: 1.591\n",
      "[87, 360] loss: 1.625\n",
      "Epoch: 87 -> Loss: 1.53986525536\n",
      "Epoch: 87 -> Test Accuracy: 37.08\n",
      "[88, 60] loss: 1.585\n",
      "[88, 120] loss: 1.610\n",
      "[88, 180] loss: 1.624\n",
      "[88, 240] loss: 1.619\n",
      "[88, 300] loss: 1.632\n",
      "[88, 360] loss: 1.602\n",
      "Epoch: 88 -> Loss: 1.66432738304\n",
      "Epoch: 88 -> Test Accuracy: 37.33\n",
      "[89, 60] loss: 1.597\n",
      "[89, 120] loss: 1.598\n",
      "[89, 180] loss: 1.616\n",
      "[89, 240] loss: 1.595\n",
      "[89, 300] loss: 1.614\n",
      "[89, 360] loss: 1.618\n",
      "Epoch: 89 -> Loss: 1.63545799255\n",
      "Epoch: 89 -> Test Accuracy: 37.0\n",
      "[90, 60] loss: 1.610\n",
      "[90, 120] loss: 1.608\n",
      "[90, 180] loss: 1.600\n",
      "[90, 240] loss: 1.602\n",
      "[90, 300] loss: 1.609\n",
      "[90, 360] loss: 1.619\n",
      "Epoch: 90 -> Loss: 1.61653113365\n",
      "Epoch: 90 -> Test Accuracy: 37.51\n",
      "[91, 60] loss: 1.608\n",
      "[91, 120] loss: 1.595\n",
      "[91, 180] loss: 1.615\n",
      "[91, 240] loss: 1.597\n",
      "[91, 300] loss: 1.631\n",
      "[91, 360] loss: 1.606\n",
      "Epoch: 91 -> Loss: 1.63300669193\n",
      "Epoch: 91 -> Test Accuracy: 37.37\n",
      "[92, 60] loss: 1.608\n",
      "[92, 120] loss: 1.623\n",
      "[92, 180] loss: 1.604\n",
      "[92, 240] loss: 1.608\n",
      "[92, 300] loss: 1.592\n",
      "[92, 360] loss: 1.618\n",
      "Epoch: 92 -> Loss: 1.56604969501\n",
      "Epoch: 92 -> Test Accuracy: 37.2\n",
      "[93, 60] loss: 1.617\n",
      "[93, 120] loss: 1.598\n",
      "[93, 180] loss: 1.594\n",
      "[93, 240] loss: 1.622\n",
      "[93, 300] loss: 1.609\n",
      "[93, 360] loss: 1.603\n",
      "Epoch: 93 -> Loss: 1.69902586937\n",
      "Epoch: 93 -> Test Accuracy: 37.02\n",
      "[94, 60] loss: 1.599\n",
      "[94, 120] loss: 1.610\n",
      "[94, 180] loss: 1.605\n",
      "[94, 240] loss: 1.626\n",
      "[94, 300] loss: 1.609\n",
      "[94, 360] loss: 1.612\n",
      "Epoch: 94 -> Loss: 1.39743483067\n",
      "Epoch: 94 -> Test Accuracy: 37.35\n",
      "[95, 60] loss: 1.602\n",
      "[95, 120] loss: 1.605\n",
      "[95, 180] loss: 1.586\n",
      "[95, 240] loss: 1.604\n",
      "[95, 300] loss: 1.610\n",
      "[95, 360] loss: 1.632\n",
      "Epoch: 95 -> Loss: 1.84993839264\n",
      "Epoch: 95 -> Test Accuracy: 37.36\n",
      "[96, 60] loss: 1.618\n",
      "[96, 120] loss: 1.593\n",
      "[96, 180] loss: 1.616\n",
      "[96, 240] loss: 1.621\n",
      "[96, 300] loss: 1.607\n",
      "[96, 360] loss: 1.600\n",
      "Epoch: 96 -> Loss: 1.64696502686\n",
      "Epoch: 96 -> Test Accuracy: 37.25\n",
      "[97, 60] loss: 1.595\n",
      "[97, 120] loss: 1.596\n",
      "[97, 180] loss: 1.612\n",
      "[97, 240] loss: 1.606\n",
      "[97, 300] loss: 1.611\n",
      "[97, 360] loss: 1.614\n",
      "Epoch: 97 -> Loss: 1.5730561018\n",
      "Epoch: 97 -> Test Accuracy: 37.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98, 60] loss: 1.598\n",
      "[98, 120] loss: 1.605\n",
      "[98, 180] loss: 1.598\n",
      "[98, 240] loss: 1.599\n",
      "[98, 300] loss: 1.607\n",
      "[98, 360] loss: 1.594\n",
      "Epoch: 98 -> Loss: 1.79247283936\n",
      "Epoch: 98 -> Test Accuracy: 37.28\n",
      "[99, 60] loss: 1.604\n",
      "[99, 120] loss: 1.584\n",
      "[99, 180] loss: 1.607\n",
      "[99, 240] loss: 1.632\n",
      "[99, 300] loss: 1.594\n",
      "[99, 360] loss: 1.608\n",
      "Epoch: 99 -> Loss: 1.5799267292\n",
      "Epoch: 99 -> Test Accuracy: 37.3\n",
      "[100, 60] loss: 1.604\n",
      "[100, 120] loss: 1.598\n",
      "[100, 180] loss: 1.597\n",
      "[100, 240] loss: 1.588\n",
      "[100, 300] loss: 1.589\n",
      "[100, 360] loss: 1.606\n",
      "Epoch: 100 -> Loss: 1.52403187752\n",
      "Epoch: 100 -> Test Accuracy: 37.43\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train NonLinearClassifiers on feature map of net_3block\n",
    "block5_loss_log, _, block5_test_accuracy_log, _, _ = tr.train_all_blocks(5, 10, [0.1, 0.02, 0.004, 0.0008], \n",
    "    [20, 40, 45, 100], 0.9, 5e-4, net_block5, criterion, trainloader, None, testloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.373\n",
      "[1, 120] loss: 1.059\n",
      "[1, 180] loss: 0.948\n",
      "[1, 240] loss: 0.896\n",
      "[1, 300] loss: 0.835\n",
      "[1, 360] loss: 0.837\n",
      "Epoch: 1 -> Loss: 0.960916340351\n",
      "Epoch: 1 -> Test Accuracy: 68.22\n",
      "[2, 60] loss: 0.763\n",
      "[2, 120] loss: 0.753\n",
      "[2, 180] loss: 0.723\n",
      "[2, 240] loss: 0.691\n",
      "[2, 300] loss: 0.693\n",
      "[2, 360] loss: 0.680\n",
      "Epoch: 2 -> Loss: 0.862775802612\n",
      "Epoch: 2 -> Test Accuracy: 72.5\n",
      "[3, 60] loss: 0.628\n",
      "[3, 120] loss: 0.648\n",
      "[3, 180] loss: 0.645\n",
      "[3, 240] loss: 0.635\n",
      "[3, 300] loss: 0.625\n",
      "[3, 360] loss: 0.623\n",
      "Epoch: 3 -> Loss: 0.528761863708\n",
      "Epoch: 3 -> Test Accuracy: 75.04\n",
      "[4, 60] loss: 0.602\n",
      "[4, 120] loss: 0.596\n",
      "[4, 180] loss: 0.581\n",
      "[4, 240] loss: 0.588\n",
      "[4, 300] loss: 0.591\n",
      "[4, 360] loss: 0.607\n",
      "Epoch: 4 -> Loss: 0.514687359333\n",
      "Epoch: 4 -> Test Accuracy: 76.2\n",
      "[5, 60] loss: 0.587\n",
      "[5, 120] loss: 0.546\n",
      "[5, 180] loss: 0.534\n",
      "[5, 240] loss: 0.562\n",
      "[5, 300] loss: 0.568\n",
      "[5, 360] loss: 0.564\n",
      "Epoch: 5 -> Loss: 0.500259041786\n",
      "Epoch: 5 -> Test Accuracy: 77.02\n",
      "[6, 60] loss: 0.535\n",
      "[6, 120] loss: 0.544\n",
      "[6, 180] loss: 0.540\n",
      "[6, 240] loss: 0.531\n",
      "[6, 300] loss: 0.541\n",
      "[6, 360] loss: 0.524\n",
      "Epoch: 6 -> Loss: 0.674674272537\n",
      "Epoch: 6 -> Test Accuracy: 76.97\n",
      "[7, 60] loss: 0.526\n",
      "[7, 120] loss: 0.519\n",
      "[7, 180] loss: 0.512\n",
      "[7, 240] loss: 0.523\n",
      "[7, 300] loss: 0.512\n",
      "[7, 360] loss: 0.543\n",
      "Epoch: 7 -> Loss: 0.486287593842\n",
      "Epoch: 7 -> Test Accuracy: 79.82\n",
      "[8, 60] loss: 0.495\n",
      "[8, 120] loss: 0.498\n",
      "[8, 180] loss: 0.504\n",
      "[8, 240] loss: 0.523\n",
      "[8, 300] loss: 0.512\n",
      "[8, 360] loss: 0.502\n",
      "Epoch: 8 -> Loss: 0.519704699516\n",
      "Epoch: 8 -> Test Accuracy: 79.02\n",
      "[9, 60] loss: 0.490\n",
      "[9, 120] loss: 0.489\n",
      "[9, 180] loss: 0.493\n",
      "[9, 240] loss: 0.490\n",
      "[9, 300] loss: 0.479\n",
      "[9, 360] loss: 0.514\n",
      "Epoch: 9 -> Loss: 0.382690727711\n",
      "Epoch: 9 -> Test Accuracy: 79.76\n",
      "[10, 60] loss: 0.450\n",
      "[10, 120] loss: 0.508\n",
      "[10, 180] loss: 0.484\n",
      "[10, 240] loss: 0.473\n",
      "[10, 300] loss: 0.497\n",
      "[10, 360] loss: 0.503\n",
      "Epoch: 10 -> Loss: 0.501696527004\n",
      "Epoch: 10 -> Test Accuracy: 80.32\n",
      "[11, 60] loss: 0.471\n",
      "[11, 120] loss: 0.482\n",
      "[11, 180] loss: 0.475\n",
      "[11, 240] loss: 0.488\n",
      "[11, 300] loss: 0.486\n",
      "[11, 360] loss: 0.483\n",
      "Epoch: 11 -> Loss: 0.515934348106\n",
      "Epoch: 11 -> Test Accuracy: 79.22\n",
      "[12, 60] loss: 0.460\n",
      "[12, 120] loss: 0.472\n",
      "[12, 180] loss: 0.467\n",
      "[12, 240] loss: 0.468\n",
      "[12, 300] loss: 0.508\n",
      "[12, 360] loss: 0.473\n",
      "Epoch: 12 -> Loss: 0.659128010273\n",
      "Epoch: 12 -> Test Accuracy: 79.56\n",
      "[13, 60] loss: 0.468\n",
      "[13, 120] loss: 0.453\n",
      "[13, 180] loss: 0.469\n",
      "[13, 240] loss: 0.469\n",
      "[13, 300] loss: 0.473\n",
      "[13, 360] loss: 0.454\n",
      "Epoch: 13 -> Loss: 0.4894143641\n",
      "Epoch: 13 -> Test Accuracy: 80.5\n",
      "[14, 60] loss: 0.448\n",
      "[14, 120] loss: 0.444\n",
      "[14, 180] loss: 0.474\n",
      "[14, 240] loss: 0.469\n",
      "[14, 300] loss: 0.487\n",
      "[14, 360] loss: 0.457\n",
      "Epoch: 14 -> Loss: 0.367695182562\n",
      "Epoch: 14 -> Test Accuracy: 77.79\n",
      "[15, 60] loss: 0.430\n",
      "[15, 120] loss: 0.447\n",
      "[15, 180] loss: 0.461\n",
      "[15, 240] loss: 0.459\n",
      "[15, 300] loss: 0.486\n",
      "[15, 360] loss: 0.469\n",
      "Epoch: 15 -> Loss: 0.322522461414\n",
      "Epoch: 15 -> Test Accuracy: 80.01\n",
      "[16, 60] loss: 0.438\n",
      "[16, 120] loss: 0.454\n",
      "[16, 180] loss: 0.443\n",
      "[16, 240] loss: 0.462\n",
      "[16, 300] loss: 0.448\n",
      "[16, 360] loss: 0.470\n",
      "Epoch: 16 -> Loss: 0.526678264141\n",
      "Epoch: 16 -> Test Accuracy: 80.28\n",
      "[17, 60] loss: 0.419\n",
      "[17, 120] loss: 0.447\n",
      "[17, 180] loss: 0.452\n",
      "[17, 240] loss: 0.460\n",
      "[17, 300] loss: 0.467\n",
      "[17, 360] loss: 0.450\n",
      "Epoch: 17 -> Loss: 0.298011481762\n",
      "Epoch: 17 -> Test Accuracy: 80.83\n",
      "[18, 60] loss: 0.424\n",
      "[18, 120] loss: 0.447\n",
      "[18, 180] loss: 0.443\n",
      "[18, 240] loss: 0.452\n",
      "[18, 300] loss: 0.467\n",
      "[18, 360] loss: 0.454\n",
      "Epoch: 18 -> Loss: 0.493466198444\n",
      "Epoch: 18 -> Test Accuracy: 79.99\n",
      "[19, 60] loss: 0.422\n",
      "[19, 120] loss: 0.445\n",
      "[19, 180] loss: 0.452\n",
      "[19, 240] loss: 0.453\n",
      "[19, 300] loss: 0.435\n",
      "[19, 360] loss: 0.476\n",
      "Epoch: 19 -> Loss: 0.546299874783\n",
      "Epoch: 19 -> Test Accuracy: 80.49\n",
      "[20, 60] loss: 0.423\n",
      "[20, 120] loss: 0.445\n",
      "[20, 180] loss: 0.422\n",
      "[20, 240] loss: 0.452\n",
      "[20, 300] loss: 0.447\n",
      "[20, 360] loss: 0.453\n",
      "Epoch: 20 -> Loss: 0.344104737043\n",
      "Epoch: 20 -> Test Accuracy: 80.25\n",
      "[21, 60] loss: 0.414\n",
      "[21, 120] loss: 0.440\n",
      "[21, 180] loss: 0.441\n",
      "[21, 240] loss: 0.452\n",
      "[21, 300] loss: 0.451\n",
      "[21, 360] loss: 0.464\n",
      "Epoch: 21 -> Loss: 0.533436775208\n",
      "Epoch: 21 -> Test Accuracy: 80.61\n",
      "[22, 60] loss: 0.413\n",
      "[22, 120] loss: 0.410\n",
      "[22, 180] loss: 0.440\n",
      "[22, 240] loss: 0.423\n",
      "[22, 300] loss: 0.460\n",
      "[22, 360] loss: 0.456\n",
      "Epoch: 22 -> Loss: 0.637050151825\n",
      "Epoch: 22 -> Test Accuracy: 80.41\n",
      "[23, 60] loss: 0.407\n",
      "[23, 120] loss: 0.418\n",
      "[23, 180] loss: 0.428\n",
      "[23, 240] loss: 0.449\n",
      "[23, 300] loss: 0.443\n",
      "[23, 360] loss: 0.451\n",
      "Epoch: 23 -> Loss: 0.574285268784\n",
      "Epoch: 23 -> Test Accuracy: 80.34\n",
      "[24, 60] loss: 0.417\n",
      "[24, 120] loss: 0.400\n",
      "[24, 180] loss: 0.425\n",
      "[24, 240] loss: 0.433\n",
      "[24, 300] loss: 0.448\n",
      "[24, 360] loss: 0.449\n",
      "Epoch: 24 -> Loss: 0.467262506485\n",
      "Epoch: 24 -> Test Accuracy: 81.16\n",
      "[25, 60] loss: 0.413\n",
      "[25, 120] loss: 0.426\n",
      "[25, 180] loss: 0.437\n",
      "[25, 240] loss: 0.434\n",
      "[25, 300] loss: 0.441\n",
      "[25, 360] loss: 0.448\n",
      "Epoch: 25 -> Loss: 0.470267683268\n",
      "Epoch: 25 -> Test Accuracy: 80.96\n",
      "[26, 60] loss: 0.412\n",
      "[26, 120] loss: 0.425\n",
      "[26, 180] loss: 0.417\n",
      "[26, 240] loss: 0.426\n",
      "[26, 300] loss: 0.444\n",
      "[26, 360] loss: 0.447\n",
      "Epoch: 26 -> Loss: 0.462284505367\n",
      "Epoch: 26 -> Test Accuracy: 81.35\n",
      "[27, 60] loss: 0.412\n",
      "[27, 120] loss: 0.409\n",
      "[27, 180] loss: 0.435\n",
      "[27, 240] loss: 0.410\n",
      "[27, 300] loss: 0.430\n",
      "[27, 360] loss: 0.455\n",
      "Epoch: 27 -> Loss: 0.656302571297\n",
      "Epoch: 27 -> Test Accuracy: 80.03\n",
      "[28, 60] loss: 0.411\n",
      "[28, 120] loss: 0.401\n",
      "[28, 180] loss: 0.439\n",
      "[28, 240] loss: 0.419\n",
      "[28, 300] loss: 0.434\n",
      "[28, 360] loss: 0.446\n",
      "Epoch: 28 -> Loss: 0.362249195576\n",
      "Epoch: 28 -> Test Accuracy: 80.84\n",
      "[29, 60] loss: 0.407\n",
      "[29, 120] loss: 0.415\n",
      "[29, 180] loss: 0.428\n",
      "[29, 240] loss: 0.421\n",
      "[29, 300] loss: 0.428\n",
      "[29, 360] loss: 0.440\n",
      "Epoch: 29 -> Loss: 0.552367150784\n",
      "Epoch: 29 -> Test Accuracy: 80.74\n",
      "[30, 60] loss: 0.406\n",
      "[30, 120] loss: 0.424\n",
      "[30, 180] loss: 0.433\n",
      "[30, 240] loss: 0.422\n",
      "[30, 300] loss: 0.435\n",
      "[30, 360] loss: 0.430\n",
      "Epoch: 30 -> Loss: 0.457294523716\n",
      "Epoch: 30 -> Test Accuracy: 80.68\n",
      "[31, 60] loss: 0.416\n",
      "[31, 120] loss: 0.406\n",
      "[31, 180] loss: 0.436\n",
      "[31, 240] loss: 0.421\n",
      "[31, 300] loss: 0.429\n",
      "[31, 360] loss: 0.422\n",
      "Epoch: 31 -> Loss: 0.653013348579\n",
      "Epoch: 31 -> Test Accuracy: 81.02\n",
      "[32, 60] loss: 0.419\n",
      "[32, 120] loss: 0.426\n",
      "[32, 180] loss: 0.422\n",
      "[32, 240] loss: 0.420\n",
      "[32, 300] loss: 0.448\n",
      "[32, 360] loss: 0.428\n",
      "Epoch: 32 -> Loss: 0.496709048748\n",
      "Epoch: 32 -> Test Accuracy: 80.01\n",
      "[33, 60] loss: 0.410\n",
      "[33, 120] loss: 0.419\n",
      "[33, 180] loss: 0.423\n",
      "[33, 240] loss: 0.412\n",
      "[33, 300] loss: 0.431\n",
      "[33, 360] loss: 0.418\n",
      "Epoch: 33 -> Loss: 0.289911717176\n",
      "Epoch: 33 -> Test Accuracy: 80.66\n",
      "[34, 60] loss: 0.408\n",
      "[34, 120] loss: 0.401\n",
      "[34, 180] loss: 0.429\n",
      "[34, 240] loss: 0.408\n",
      "[34, 300] loss: 0.439\n",
      "[34, 360] loss: 0.431\n",
      "Epoch: 34 -> Loss: 0.388946920633\n",
      "Epoch: 34 -> Test Accuracy: 81.37\n",
      "[35, 60] loss: 0.412\n",
      "[35, 120] loss: 0.406\n",
      "[35, 180] loss: 0.418\n",
      "[35, 240] loss: 0.426\n",
      "[35, 300] loss: 0.431\n",
      "[35, 360] loss: 0.426\n",
      "Epoch: 35 -> Loss: 0.306434482336\n",
      "Epoch: 35 -> Test Accuracy: 80.1\n",
      "[36, 60] loss: 0.334\n",
      "[36, 120] loss: 0.302\n",
      "[36, 180] loss: 0.304\n",
      "[36, 240] loss: 0.297\n",
      "[36, 300] loss: 0.289\n",
      "[36, 360] loss: 0.287\n",
      "Epoch: 36 -> Loss: 0.170680955052\n",
      "Epoch: 36 -> Test Accuracy: 85.32\n",
      "[37, 60] loss: 0.267\n",
      "[37, 120] loss: 0.270\n",
      "[37, 180] loss: 0.262\n",
      "[37, 240] loss: 0.259\n",
      "[37, 300] loss: 0.270\n",
      "[37, 360] loss: 0.272\n",
      "Epoch: 37 -> Loss: 0.412941992283\n",
      "Epoch: 37 -> Test Accuracy: 85.01\n",
      "[38, 60] loss: 0.251\n",
      "[38, 120] loss: 0.253\n",
      "[38, 180] loss: 0.265\n",
      "[38, 240] loss: 0.252\n",
      "[38, 300] loss: 0.260\n",
      "[38, 360] loss: 0.255\n",
      "Epoch: 38 -> Loss: 0.257576286793\n",
      "Epoch: 38 -> Test Accuracy: 85.52\n",
      "[39, 60] loss: 0.234\n",
      "[39, 120] loss: 0.246\n",
      "[39, 180] loss: 0.247\n",
      "[39, 240] loss: 0.254\n",
      "[39, 300] loss: 0.262\n",
      "[39, 360] loss: 0.252\n",
      "Epoch: 39 -> Loss: 0.307784974575\n",
      "Epoch: 39 -> Test Accuracy: 85.47\n",
      "[40, 60] loss: 0.233\n",
      "[40, 120] loss: 0.234\n",
      "[40, 180] loss: 0.238\n",
      "[40, 240] loss: 0.242\n",
      "[40, 300] loss: 0.250\n",
      "[40, 360] loss: 0.247\n",
      "Epoch: 40 -> Loss: 0.24477224052\n",
      "Epoch: 40 -> Test Accuracy: 85.6\n",
      "[41, 60] loss: 0.231\n",
      "[41, 120] loss: 0.239\n",
      "[41, 180] loss: 0.231\n",
      "[41, 240] loss: 0.241\n",
      "[41, 300] loss: 0.241\n",
      "[41, 360] loss: 0.240\n",
      "Epoch: 41 -> Loss: 0.284914135933\n",
      "Epoch: 41 -> Test Accuracy: 84.82\n",
      "[42, 60] loss: 0.236\n",
      "[42, 120] loss: 0.235\n",
      "[42, 180] loss: 0.239\n",
      "[42, 240] loss: 0.242\n",
      "[42, 300] loss: 0.243\n",
      "[42, 360] loss: 0.242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.198545902967\n",
      "Epoch: 42 -> Test Accuracy: 85.07\n",
      "[43, 60] loss: 0.221\n",
      "[43, 120] loss: 0.233\n",
      "[43, 180] loss: 0.224\n",
      "[43, 240] loss: 0.248\n",
      "[43, 300] loss: 0.241\n",
      "[43, 360] loss: 0.242\n",
      "Epoch: 43 -> Loss: 0.23557202518\n",
      "Epoch: 43 -> Test Accuracy: 85.29\n",
      "[44, 60] loss: 0.212\n",
      "[44, 120] loss: 0.229\n",
      "[44, 180] loss: 0.239\n",
      "[44, 240] loss: 0.237\n",
      "[44, 300] loss: 0.251\n",
      "[44, 360] loss: 0.234\n",
      "Epoch: 44 -> Loss: 0.309601843357\n",
      "Epoch: 44 -> Test Accuracy: 84.72\n",
      "[45, 60] loss: 0.208\n",
      "[45, 120] loss: 0.228\n",
      "[45, 180] loss: 0.237\n",
      "[45, 240] loss: 0.250\n",
      "[45, 300] loss: 0.248\n",
      "[45, 360] loss: 0.243\n",
      "Epoch: 45 -> Loss: 0.24881669879\n",
      "Epoch: 45 -> Test Accuracy: 84.55\n",
      "[46, 60] loss: 0.228\n",
      "[46, 120] loss: 0.224\n",
      "[46, 180] loss: 0.237\n",
      "[46, 240] loss: 0.221\n",
      "[46, 300] loss: 0.236\n",
      "[46, 360] loss: 0.241\n",
      "Epoch: 46 -> Loss: 0.200550347567\n",
      "Epoch: 46 -> Test Accuracy: 84.48\n",
      "[47, 60] loss: 0.220\n",
      "[47, 120] loss: 0.223\n",
      "[47, 180] loss: 0.239\n",
      "[47, 240] loss: 0.214\n",
      "[47, 300] loss: 0.234\n",
      "[47, 360] loss: 0.238\n",
      "Epoch: 47 -> Loss: 0.189895868301\n",
      "Epoch: 47 -> Test Accuracy: 84.56\n",
      "[48, 60] loss: 0.216\n",
      "[48, 120] loss: 0.224\n",
      "[48, 180] loss: 0.232\n",
      "[48, 240] loss: 0.250\n",
      "[48, 300] loss: 0.250\n",
      "[48, 360] loss: 0.236\n",
      "Epoch: 48 -> Loss: 0.186878398061\n",
      "Epoch: 48 -> Test Accuracy: 84.79\n",
      "[49, 60] loss: 0.215\n",
      "[49, 120] loss: 0.233\n",
      "[49, 180] loss: 0.221\n",
      "[49, 240] loss: 0.247\n",
      "[49, 300] loss: 0.238\n",
      "[49, 360] loss: 0.239\n",
      "Epoch: 49 -> Loss: 0.159892812371\n",
      "Epoch: 49 -> Test Accuracy: 84.38\n",
      "[50, 60] loss: 0.234\n",
      "[50, 120] loss: 0.226\n",
      "[50, 180] loss: 0.229\n",
      "[50, 240] loss: 0.239\n",
      "[50, 300] loss: 0.242\n",
      "[50, 360] loss: 0.253\n",
      "Epoch: 50 -> Loss: 0.257295399904\n",
      "Epoch: 50 -> Test Accuracy: 84.48\n",
      "[51, 60] loss: 0.221\n",
      "[51, 120] loss: 0.221\n",
      "[51, 180] loss: 0.223\n",
      "[51, 240] loss: 0.248\n",
      "[51, 300] loss: 0.242\n",
      "[51, 360] loss: 0.243\n",
      "Epoch: 51 -> Loss: 0.273679077625\n",
      "Epoch: 51 -> Test Accuracy: 84.13\n",
      "[52, 60] loss: 0.213\n",
      "[52, 120] loss: 0.236\n",
      "[52, 180] loss: 0.231\n",
      "[52, 240] loss: 0.238\n",
      "[52, 300] loss: 0.246\n",
      "[52, 360] loss: 0.246\n",
      "Epoch: 52 -> Loss: 0.161654397845\n",
      "Epoch: 52 -> Test Accuracy: 83.71\n",
      "[53, 60] loss: 0.224\n",
      "[53, 120] loss: 0.225\n",
      "[53, 180] loss: 0.224\n",
      "[53, 240] loss: 0.229\n",
      "[53, 300] loss: 0.241\n",
      "[53, 360] loss: 0.251\n",
      "Epoch: 53 -> Loss: 0.258047997952\n",
      "Epoch: 53 -> Test Accuracy: 84.62\n",
      "[54, 60] loss: 0.222\n",
      "[54, 120] loss: 0.233\n",
      "[54, 180] loss: 0.218\n",
      "[54, 240] loss: 0.242\n",
      "[54, 300] loss: 0.246\n",
      "[54, 360] loss: 0.243\n",
      "Epoch: 54 -> Loss: 0.320821195841\n",
      "Epoch: 54 -> Test Accuracy: 84.35\n",
      "[55, 60] loss: 0.216\n",
      "[55, 120] loss: 0.218\n",
      "[55, 180] loss: 0.228\n",
      "[55, 240] loss: 0.239\n",
      "[55, 300] loss: 0.237\n",
      "[55, 360] loss: 0.246\n",
      "Epoch: 55 -> Loss: 0.224856778979\n",
      "Epoch: 55 -> Test Accuracy: 84.39\n",
      "[56, 60] loss: 0.215\n",
      "[56, 120] loss: 0.218\n",
      "[56, 180] loss: 0.235\n",
      "[56, 240] loss: 0.236\n",
      "[56, 300] loss: 0.253\n",
      "[56, 360] loss: 0.243\n",
      "Epoch: 56 -> Loss: 0.234345048666\n",
      "Epoch: 56 -> Test Accuracy: 84.25\n",
      "[57, 60] loss: 0.220\n",
      "[57, 120] loss: 0.219\n",
      "[57, 180] loss: 0.245\n",
      "[57, 240] loss: 0.224\n",
      "[57, 300] loss: 0.229\n",
      "[57, 360] loss: 0.252\n",
      "Epoch: 57 -> Loss: 0.229795888066\n",
      "Epoch: 57 -> Test Accuracy: 84.27\n",
      "[58, 60] loss: 0.222\n",
      "[58, 120] loss: 0.215\n",
      "[58, 180] loss: 0.233\n",
      "[58, 240] loss: 0.232\n",
      "[58, 300] loss: 0.240\n",
      "[58, 360] loss: 0.251\n",
      "Epoch: 58 -> Loss: 0.280469954014\n",
      "Epoch: 58 -> Test Accuracy: 84.27\n",
      "[59, 60] loss: 0.220\n",
      "[59, 120] loss: 0.228\n",
      "[59, 180] loss: 0.237\n",
      "[59, 240] loss: 0.242\n",
      "[59, 300] loss: 0.227\n",
      "[59, 360] loss: 0.236\n",
      "Epoch: 59 -> Loss: 0.284465759993\n",
      "Epoch: 59 -> Test Accuracy: 84.22\n",
      "[60, 60] loss: 0.216\n",
      "[60, 120] loss: 0.218\n",
      "[60, 180] loss: 0.224\n",
      "[60, 240] loss: 0.227\n",
      "[60, 300] loss: 0.244\n",
      "[60, 360] loss: 0.234\n",
      "Epoch: 60 -> Loss: 0.282075792551\n",
      "Epoch: 60 -> Test Accuracy: 83.91\n",
      "[61, 60] loss: 0.213\n",
      "[61, 120] loss: 0.226\n",
      "[61, 180] loss: 0.236\n",
      "[61, 240] loss: 0.232\n",
      "[61, 300] loss: 0.237\n",
      "[61, 360] loss: 0.237\n",
      "Epoch: 61 -> Loss: 0.173961311579\n",
      "Epoch: 61 -> Test Accuracy: 84.6\n",
      "[62, 60] loss: 0.216\n",
      "[62, 120] loss: 0.227\n",
      "[62, 180] loss: 0.212\n",
      "[62, 240] loss: 0.234\n",
      "[62, 300] loss: 0.237\n",
      "[62, 360] loss: 0.242\n",
      "Epoch: 62 -> Loss: 0.251608073711\n",
      "Epoch: 62 -> Test Accuracy: 84.04\n",
      "[63, 60] loss: 0.230\n",
      "[63, 120] loss: 0.224\n",
      "[63, 180] loss: 0.236\n",
      "[63, 240] loss: 0.237\n",
      "[63, 300] loss: 0.224\n",
      "[63, 360] loss: 0.229\n",
      "Epoch: 63 -> Loss: 0.263769477606\n",
      "Epoch: 63 -> Test Accuracy: 84.18\n",
      "[64, 60] loss: 0.208\n",
      "[64, 120] loss: 0.220\n",
      "[64, 180] loss: 0.223\n",
      "[64, 240] loss: 0.237\n",
      "[64, 300] loss: 0.224\n",
      "[64, 360] loss: 0.241\n",
      "Epoch: 64 -> Loss: 0.295814573765\n",
      "Epoch: 64 -> Test Accuracy: 84.15\n",
      "[65, 60] loss: 0.208\n",
      "[65, 120] loss: 0.216\n",
      "[65, 180] loss: 0.225\n",
      "[65, 240] loss: 0.222\n",
      "[65, 300] loss: 0.235\n",
      "[65, 360] loss: 0.238\n",
      "Epoch: 65 -> Loss: 0.381906121969\n",
      "Epoch: 65 -> Test Accuracy: 84.12\n",
      "[66, 60] loss: 0.219\n",
      "[66, 120] loss: 0.207\n",
      "[66, 180] loss: 0.232\n",
      "[66, 240] loss: 0.229\n",
      "[66, 300] loss: 0.228\n",
      "[66, 360] loss: 0.233\n",
      "Epoch: 66 -> Loss: 0.154667407274\n",
      "Epoch: 66 -> Test Accuracy: 83.87\n",
      "[67, 60] loss: 0.206\n",
      "[67, 120] loss: 0.210\n",
      "[67, 180] loss: 0.230\n",
      "[67, 240] loss: 0.236\n",
      "[67, 300] loss: 0.241\n",
      "[67, 360] loss: 0.231\n",
      "Epoch: 67 -> Loss: 0.28984862566\n",
      "Epoch: 67 -> Test Accuracy: 84.06\n",
      "[68, 60] loss: 0.220\n",
      "[68, 120] loss: 0.215\n",
      "[68, 180] loss: 0.214\n",
      "[68, 240] loss: 0.225\n",
      "[68, 300] loss: 0.232\n",
      "[68, 360] loss: 0.236\n",
      "Epoch: 68 -> Loss: 0.213124841452\n",
      "Epoch: 68 -> Test Accuracy: 83.5\n",
      "[69, 60] loss: 0.218\n",
      "[69, 120] loss: 0.202\n",
      "[69, 180] loss: 0.234\n",
      "[69, 240] loss: 0.231\n",
      "[69, 300] loss: 0.221\n",
      "[69, 360] loss: 0.230\n",
      "Epoch: 69 -> Loss: 0.162092328072\n",
      "Epoch: 69 -> Test Accuracy: 84.09\n",
      "[70, 60] loss: 0.210\n",
      "[70, 120] loss: 0.213\n",
      "[70, 180] loss: 0.230\n",
      "[70, 240] loss: 0.221\n",
      "[70, 300] loss: 0.245\n",
      "[70, 360] loss: 0.229\n",
      "Epoch: 70 -> Loss: 0.278773844242\n",
      "Epoch: 70 -> Test Accuracy: 84.25\n",
      "[71, 60] loss: 0.181\n",
      "[71, 120] loss: 0.154\n",
      "[71, 180] loss: 0.163\n",
      "[71, 240] loss: 0.145\n",
      "[71, 300] loss: 0.152\n",
      "[71, 360] loss: 0.148\n",
      "Epoch: 71 -> Loss: 0.211007744074\n",
      "Epoch: 71 -> Test Accuracy: 85.99\n",
      "[72, 60] loss: 0.135\n",
      "[72, 120] loss: 0.141\n",
      "[72, 180] loss: 0.143\n",
      "[72, 240] loss: 0.150\n",
      "[72, 300] loss: 0.135\n",
      "[72, 360] loss: 0.137\n",
      "Epoch: 72 -> Loss: 0.182374864817\n",
      "Epoch: 72 -> Test Accuracy: 86.25\n",
      "[73, 60] loss: 0.130\n",
      "[73, 120] loss: 0.140\n",
      "[73, 180] loss: 0.135\n",
      "[73, 240] loss: 0.133\n",
      "[73, 300] loss: 0.128\n",
      "[73, 360] loss: 0.139\n",
      "Epoch: 73 -> Loss: 0.0930586159229\n",
      "Epoch: 73 -> Test Accuracy: 86.28\n",
      "[74, 60] loss: 0.124\n",
      "[74, 120] loss: 0.133\n",
      "[74, 180] loss: 0.130\n",
      "[74, 240] loss: 0.128\n",
      "[74, 300] loss: 0.129\n",
      "[74, 360] loss: 0.133\n",
      "Epoch: 74 -> Loss: 0.132570952177\n",
      "Epoch: 74 -> Test Accuracy: 86.13\n",
      "[75, 60] loss: 0.124\n",
      "[75, 120] loss: 0.128\n",
      "[75, 180] loss: 0.122\n",
      "[75, 240] loss: 0.127\n",
      "[75, 300] loss: 0.127\n",
      "[75, 360] loss: 0.126\n",
      "Epoch: 75 -> Loss: 0.0926084294915\n",
      "Epoch: 75 -> Test Accuracy: 85.7\n",
      "[76, 60] loss: 0.122\n",
      "[76, 120] loss: 0.122\n",
      "[76, 180] loss: 0.118\n",
      "[76, 240] loss: 0.121\n",
      "[76, 300] loss: 0.122\n",
      "[76, 360] loss: 0.128\n",
      "Epoch: 76 -> Loss: 0.138780191541\n",
      "Epoch: 76 -> Test Accuracy: 86.19\n",
      "[77, 60] loss: 0.113\n",
      "[77, 120] loss: 0.121\n",
      "[77, 180] loss: 0.115\n",
      "[77, 240] loss: 0.120\n",
      "[77, 300] loss: 0.117\n",
      "[77, 360] loss: 0.124\n",
      "Epoch: 77 -> Loss: 0.123311474919\n",
      "Epoch: 77 -> Test Accuracy: 86.35\n",
      "[78, 60] loss: 0.110\n",
      "[78, 120] loss: 0.112\n",
      "[78, 180] loss: 0.117\n",
      "[78, 240] loss: 0.112\n",
      "[78, 300] loss: 0.119\n",
      "[78, 360] loss: 0.123\n",
      "Epoch: 78 -> Loss: 0.175581216812\n",
      "Epoch: 78 -> Test Accuracy: 86.0\n",
      "[79, 60] loss: 0.111\n",
      "[79, 120] loss: 0.109\n",
      "[79, 180] loss: 0.110\n",
      "[79, 240] loss: 0.115\n",
      "[79, 300] loss: 0.115\n",
      "[79, 360] loss: 0.127\n",
      "Epoch: 79 -> Loss: 0.0572595484555\n",
      "Epoch: 79 -> Test Accuracy: 86.06\n",
      "[80, 60] loss: 0.111\n",
      "[80, 120] loss: 0.115\n",
      "[80, 180] loss: 0.110\n",
      "[80, 240] loss: 0.113\n",
      "[80, 300] loss: 0.125\n",
      "[80, 360] loss: 0.114\n",
      "Epoch: 80 -> Loss: 0.1001425758\n",
      "Epoch: 80 -> Test Accuracy: 86.0\n",
      "[81, 60] loss: 0.106\n",
      "[81, 120] loss: 0.111\n",
      "[81, 180] loss: 0.113\n",
      "[81, 240] loss: 0.112\n",
      "[81, 300] loss: 0.118\n",
      "[81, 360] loss: 0.118\n",
      "Epoch: 81 -> Loss: 0.0813755691051\n",
      "Epoch: 81 -> Test Accuracy: 85.59\n",
      "[82, 60] loss: 0.110\n",
      "[82, 120] loss: 0.105\n",
      "[82, 180] loss: 0.112\n",
      "[82, 240] loss: 0.113\n",
      "[82, 300] loss: 0.113\n",
      "[82, 360] loss: 0.111\n",
      "Epoch: 82 -> Loss: 0.105520799756\n",
      "Epoch: 82 -> Test Accuracy: 86.07\n",
      "[83, 60] loss: 0.101\n",
      "[83, 120] loss: 0.102\n",
      "[83, 180] loss: 0.101\n",
      "[83, 240] loss: 0.115\n",
      "[83, 300] loss: 0.112\n",
      "[83, 360] loss: 0.112\n",
      "Epoch: 83 -> Loss: 0.0985261872411\n",
      "Epoch: 83 -> Test Accuracy: 85.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.103\n",
      "[84, 120] loss: 0.106\n",
      "[84, 180] loss: 0.112\n",
      "[84, 240] loss: 0.109\n",
      "[84, 300] loss: 0.107\n",
      "[84, 360] loss: 0.112\n",
      "Epoch: 84 -> Loss: 0.174443304539\n",
      "Epoch: 84 -> Test Accuracy: 85.95\n",
      "[85, 60] loss: 0.101\n",
      "[85, 120] loss: 0.097\n",
      "[85, 180] loss: 0.106\n",
      "[85, 240] loss: 0.108\n",
      "[85, 300] loss: 0.114\n",
      "[85, 360] loss: 0.114\n",
      "Epoch: 85 -> Loss: 0.122100234032\n",
      "Epoch: 85 -> Test Accuracy: 86.1\n",
      "[86, 60] loss: 0.096\n",
      "[86, 120] loss: 0.099\n",
      "[86, 180] loss: 0.094\n",
      "[86, 240] loss: 0.098\n",
      "[86, 300] loss: 0.095\n",
      "[86, 360] loss: 0.092\n",
      "Epoch: 86 -> Loss: 0.0955424308777\n",
      "Epoch: 86 -> Test Accuracy: 86.22\n",
      "[87, 60] loss: 0.091\n",
      "[87, 120] loss: 0.095\n",
      "[87, 180] loss: 0.087\n",
      "[87, 240] loss: 0.090\n",
      "[87, 300] loss: 0.092\n",
      "[87, 360] loss: 0.090\n",
      "Epoch: 87 -> Loss: 0.0658046081662\n",
      "Epoch: 87 -> Test Accuracy: 85.98\n",
      "[88, 60] loss: 0.093\n",
      "[88, 120] loss: 0.089\n",
      "[88, 180] loss: 0.092\n",
      "[88, 240] loss: 0.095\n",
      "[88, 300] loss: 0.088\n",
      "[88, 360] loss: 0.093\n",
      "Epoch: 88 -> Loss: 0.112874865532\n",
      "Epoch: 88 -> Test Accuracy: 86.13\n",
      "[89, 60] loss: 0.087\n",
      "[89, 120] loss: 0.086\n",
      "[89, 180] loss: 0.093\n",
      "[89, 240] loss: 0.091\n",
      "[89, 300] loss: 0.095\n",
      "[89, 360] loss: 0.087\n",
      "Epoch: 89 -> Loss: 0.113641478121\n",
      "Epoch: 89 -> Test Accuracy: 86.2\n",
      "[90, 60] loss: 0.088\n",
      "[90, 120] loss: 0.092\n",
      "[90, 180] loss: 0.087\n",
      "[90, 240] loss: 0.091\n",
      "[90, 300] loss: 0.091\n",
      "[90, 360] loss: 0.087\n",
      "Epoch: 90 -> Loss: 0.0660285055637\n",
      "Epoch: 90 -> Test Accuracy: 86.08\n",
      "[91, 60] loss: 0.090\n",
      "[91, 120] loss: 0.089\n",
      "[91, 180] loss: 0.087\n",
      "[91, 240] loss: 0.088\n",
      "[91, 300] loss: 0.089\n",
      "[91, 360] loss: 0.091\n",
      "Epoch: 91 -> Loss: 0.0747816711664\n",
      "Epoch: 91 -> Test Accuracy: 86.27\n",
      "[92, 60] loss: 0.085\n",
      "[92, 120] loss: 0.084\n",
      "[92, 180] loss: 0.089\n",
      "[92, 240] loss: 0.086\n",
      "[92, 300] loss: 0.093\n",
      "[92, 360] loss: 0.090\n",
      "Epoch: 92 -> Loss: 0.0497073382139\n",
      "Epoch: 92 -> Test Accuracy: 86.31\n",
      "[93, 60] loss: 0.085\n",
      "[93, 120] loss: 0.088\n",
      "[93, 180] loss: 0.083\n",
      "[93, 240] loss: 0.089\n",
      "[93, 300] loss: 0.087\n",
      "[93, 360] loss: 0.091\n",
      "Epoch: 93 -> Loss: 0.0867529883981\n",
      "Epoch: 93 -> Test Accuracy: 86.21\n",
      "[94, 60] loss: 0.089\n",
      "[94, 120] loss: 0.092\n",
      "[94, 180] loss: 0.090\n",
      "[94, 240] loss: 0.083\n",
      "[94, 300] loss: 0.088\n",
      "[94, 360] loss: 0.084\n",
      "Epoch: 94 -> Loss: 0.134603947401\n",
      "Epoch: 94 -> Test Accuracy: 85.83\n",
      "[95, 60] loss: 0.086\n",
      "[95, 120] loss: 0.086\n",
      "[95, 180] loss: 0.085\n",
      "[95, 240] loss: 0.085\n",
      "[95, 300] loss: 0.091\n",
      "[95, 360] loss: 0.088\n",
      "Epoch: 95 -> Loss: 0.0781150460243\n",
      "Epoch: 95 -> Test Accuracy: 86.18\n",
      "[96, 60] loss: 0.087\n",
      "[96, 120] loss: 0.091\n",
      "[96, 180] loss: 0.087\n",
      "[96, 240] loss: 0.088\n",
      "[96, 300] loss: 0.084\n",
      "[96, 360] loss: 0.088\n",
      "Epoch: 96 -> Loss: 0.11617834866\n",
      "Epoch: 96 -> Test Accuracy: 86.19\n",
      "[97, 60] loss: 0.086\n",
      "[97, 120] loss: 0.088\n",
      "[97, 180] loss: 0.087\n",
      "[97, 240] loss: 0.083\n",
      "[97, 300] loss: 0.089\n",
      "[97, 360] loss: 0.084\n",
      "Epoch: 97 -> Loss: 0.0853909999132\n",
      "Epoch: 97 -> Test Accuracy: 86.1\n",
      "[98, 60] loss: 0.084\n",
      "[98, 120] loss: 0.090\n",
      "[98, 180] loss: 0.084\n",
      "[98, 240] loss: 0.086\n",
      "[98, 300] loss: 0.084\n",
      "[98, 360] loss: 0.085\n",
      "Epoch: 98 -> Loss: 0.081921197474\n",
      "Epoch: 98 -> Test Accuracy: 86.01\n",
      "[99, 60] loss: 0.088\n",
      "[99, 120] loss: 0.087\n",
      "[99, 180] loss: 0.082\n",
      "[99, 240] loss: 0.087\n",
      "[99, 300] loss: 0.083\n",
      "[99, 360] loss: 0.091\n",
      "Epoch: 99 -> Loss: 0.0619568116963\n",
      "Epoch: 99 -> Test Accuracy: 86.06\n",
      "[100, 60] loss: 0.085\n",
      "[100, 120] loss: 0.090\n",
      "[100, 180] loss: 0.080\n",
      "[100, 240] loss: 0.082\n",
      "[100, 300] loss: 0.084\n",
      "[100, 360] loss: 0.084\n",
      "Epoch: 100 -> Loss: 0.131929844618\n",
      "Epoch: 100 -> Test Accuracy: 85.93\n",
      "Finished Training\n",
      "[1, 60] loss: 0.971\n",
      "[1, 120] loss: 0.623\n",
      "[1, 180] loss: 0.584\n",
      "[1, 240] loss: 0.538\n",
      "[1, 300] loss: 0.512\n",
      "[1, 360] loss: 0.527\n",
      "Epoch: 1 -> Loss: 0.369437038898\n",
      "Epoch: 1 -> Test Accuracy: 80.65\n",
      "[2, 60] loss: 0.449\n",
      "[2, 120] loss: 0.447\n",
      "[2, 180] loss: 0.460\n",
      "[2, 240] loss: 0.426\n",
      "[2, 300] loss: 0.423\n",
      "[2, 360] loss: 0.432\n",
      "Epoch: 2 -> Loss: 0.47478312254\n",
      "Epoch: 2 -> Test Accuracy: 82.07\n",
      "[3, 60] loss: 0.401\n",
      "[3, 120] loss: 0.380\n",
      "[3, 180] loss: 0.405\n",
      "[3, 240] loss: 0.401\n",
      "[3, 300] loss: 0.402\n",
      "[3, 360] loss: 0.380\n",
      "Epoch: 3 -> Loss: 0.442962884903\n",
      "Epoch: 3 -> Test Accuracy: 83.52\n",
      "[4, 60] loss: 0.338\n",
      "[4, 120] loss: 0.364\n",
      "[4, 180] loss: 0.368\n",
      "[4, 240] loss: 0.373\n",
      "[4, 300] loss: 0.367\n",
      "[4, 360] loss: 0.361\n",
      "Epoch: 4 -> Loss: 0.287872880697\n",
      "Epoch: 4 -> Test Accuracy: 83.8\n",
      "[5, 60] loss: 0.329\n",
      "[5, 120] loss: 0.355\n",
      "[5, 180] loss: 0.325\n",
      "[5, 240] loss: 0.337\n",
      "[5, 300] loss: 0.343\n",
      "[5, 360] loss: 0.346\n",
      "Epoch: 5 -> Loss: 0.410630643368\n",
      "Epoch: 5 -> Test Accuracy: 84.32\n",
      "[6, 60] loss: 0.324\n",
      "[6, 120] loss: 0.312\n",
      "[6, 180] loss: 0.334\n",
      "[6, 240] loss: 0.329\n",
      "[6, 300] loss: 0.343\n",
      "[6, 360] loss: 0.346\n",
      "Epoch: 6 -> Loss: 0.39880245924\n",
      "Epoch: 6 -> Test Accuracy: 84.55\n",
      "[7, 60] loss: 0.306\n",
      "[7, 120] loss: 0.299\n",
      "[7, 180] loss: 0.324\n",
      "[7, 240] loss: 0.327\n",
      "[7, 300] loss: 0.340\n",
      "[7, 360] loss: 0.332\n",
      "Epoch: 7 -> Loss: 0.254173487425\n",
      "Epoch: 7 -> Test Accuracy: 85.72\n",
      "[8, 60] loss: 0.297\n",
      "[8, 120] loss: 0.299\n",
      "[8, 180] loss: 0.303\n",
      "[8, 240] loss: 0.306\n",
      "[8, 300] loss: 0.314\n",
      "[8, 360] loss: 0.330\n",
      "Epoch: 8 -> Loss: 0.274381577969\n",
      "Epoch: 8 -> Test Accuracy: 84.93\n",
      "[9, 60] loss: 0.282\n",
      "[9, 120] loss: 0.298\n",
      "[9, 180] loss: 0.305\n",
      "[9, 240] loss: 0.305\n",
      "[9, 300] loss: 0.319\n",
      "[9, 360] loss: 0.336\n",
      "Epoch: 9 -> Loss: 0.2265855968\n",
      "Epoch: 9 -> Test Accuracy: 85.63\n",
      "[10, 60] loss: 0.264\n",
      "[10, 120] loss: 0.288\n",
      "[10, 180] loss: 0.288\n",
      "[10, 240] loss: 0.312\n",
      "[10, 300] loss: 0.302\n",
      "[10, 360] loss: 0.312\n",
      "Epoch: 10 -> Loss: 0.533296644688\n",
      "Epoch: 10 -> Test Accuracy: 84.96\n",
      "[11, 60] loss: 0.267\n",
      "[11, 120] loss: 0.288\n",
      "[11, 180] loss: 0.283\n",
      "[11, 240] loss: 0.295\n",
      "[11, 300] loss: 0.291\n",
      "[11, 360] loss: 0.299\n",
      "Epoch: 11 -> Loss: 0.244301229715\n",
      "Epoch: 11 -> Test Accuracy: 84.87\n",
      "[12, 60] loss: 0.268\n",
      "[12, 120] loss: 0.264\n",
      "[12, 180] loss: 0.301\n",
      "[12, 240] loss: 0.299\n",
      "[12, 300] loss: 0.294\n",
      "[12, 360] loss: 0.302\n",
      "Epoch: 12 -> Loss: 0.362803518772\n",
      "Epoch: 12 -> Test Accuracy: 85.09\n",
      "[13, 60] loss: 0.269\n",
      "[13, 120] loss: 0.279\n",
      "[13, 180] loss: 0.289\n",
      "[13, 240] loss: 0.286\n",
      "[13, 300] loss: 0.273\n",
      "[13, 360] loss: 0.298\n",
      "Epoch: 13 -> Loss: 0.255686223507\n",
      "Epoch: 13 -> Test Accuracy: 84.93\n",
      "[14, 60] loss: 0.262\n",
      "[14, 120] loss: 0.283\n",
      "[14, 180] loss: 0.295\n",
      "[14, 240] loss: 0.276\n",
      "[14, 300] loss: 0.288\n",
      "[14, 360] loss: 0.309\n",
      "Epoch: 14 -> Loss: 0.470247030258\n",
      "Epoch: 14 -> Test Accuracy: 85.43\n",
      "[15, 60] loss: 0.263\n",
      "[15, 120] loss: 0.270\n",
      "[15, 180] loss: 0.279\n",
      "[15, 240] loss: 0.282\n",
      "[15, 300] loss: 0.288\n",
      "[15, 360] loss: 0.286\n",
      "Epoch: 15 -> Loss: 0.311127126217\n",
      "Epoch: 15 -> Test Accuracy: 85.17\n",
      "[16, 60] loss: 0.259\n",
      "[16, 120] loss: 0.258\n",
      "[16, 180] loss: 0.281\n",
      "[16, 240] loss: 0.287\n",
      "[16, 300] loss: 0.280\n",
      "[16, 360] loss: 0.283\n",
      "Epoch: 16 -> Loss: 0.310997903347\n",
      "Epoch: 16 -> Test Accuracy: 84.87\n",
      "[17, 60] loss: 0.259\n",
      "[17, 120] loss: 0.281\n",
      "[17, 180] loss: 0.263\n",
      "[17, 240] loss: 0.273\n",
      "[17, 300] loss: 0.274\n",
      "[17, 360] loss: 0.285\n",
      "Epoch: 17 -> Loss: 0.375820666552\n",
      "Epoch: 17 -> Test Accuracy: 85.4\n",
      "[18, 60] loss: 0.238\n",
      "[18, 120] loss: 0.263\n",
      "[18, 180] loss: 0.275\n",
      "[18, 240] loss: 0.284\n",
      "[18, 300] loss: 0.280\n",
      "[18, 360] loss: 0.293\n",
      "Epoch: 18 -> Loss: 0.299901545048\n",
      "Epoch: 18 -> Test Accuracy: 84.27\n",
      "[19, 60] loss: 0.255\n",
      "[19, 120] loss: 0.259\n",
      "[19, 180] loss: 0.267\n",
      "[19, 240] loss: 0.270\n",
      "[19, 300] loss: 0.276\n",
      "[19, 360] loss: 0.276\n",
      "Epoch: 19 -> Loss: 0.210326716304\n",
      "Epoch: 19 -> Test Accuracy: 84.95\n",
      "[20, 60] loss: 0.258\n",
      "[20, 120] loss: 0.271\n",
      "[20, 180] loss: 0.265\n",
      "[20, 240] loss: 0.280\n",
      "[20, 300] loss: 0.275\n",
      "[20, 360] loss: 0.269\n",
      "Epoch: 20 -> Loss: 0.373623788357\n",
      "Epoch: 20 -> Test Accuracy: 85.41\n",
      "[21, 60] loss: 0.253\n",
      "[21, 120] loss: 0.261\n",
      "[21, 180] loss: 0.284\n",
      "[21, 240] loss: 0.270\n",
      "[21, 300] loss: 0.270\n",
      "[21, 360] loss: 0.274\n",
      "Epoch: 21 -> Loss: 0.30542448163\n",
      "Epoch: 21 -> Test Accuracy: 85.63\n",
      "[22, 60] loss: 0.257\n",
      "[22, 120] loss: 0.259\n",
      "[22, 180] loss: 0.257\n",
      "[22, 240] loss: 0.290\n",
      "[22, 300] loss: 0.270\n",
      "[22, 360] loss: 0.277\n",
      "Epoch: 22 -> Loss: 0.421258151531\n",
      "Epoch: 22 -> Test Accuracy: 85.48\n",
      "[23, 60] loss: 0.236\n",
      "[23, 120] loss: 0.248\n",
      "[23, 180] loss: 0.257\n",
      "[23, 240] loss: 0.264\n",
      "[23, 300] loss: 0.284\n",
      "[23, 360] loss: 0.275\n",
      "Epoch: 23 -> Loss: 0.56354624033\n",
      "Epoch: 23 -> Test Accuracy: 86.2\n",
      "[24, 60] loss: 0.240\n",
      "[24, 120] loss: 0.250\n",
      "[24, 180] loss: 0.264\n",
      "[24, 240] loss: 0.273\n",
      "[24, 300] loss: 0.270\n",
      "[24, 360] loss: 0.282\n",
      "Epoch: 24 -> Loss: 0.308874547482\n",
      "Epoch: 24 -> Test Accuracy: 85.68\n",
      "[25, 60] loss: 0.238\n",
      "[25, 120] loss: 0.256\n",
      "[25, 180] loss: 0.264\n",
      "[25, 240] loss: 0.286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 300] loss: 0.267\n",
      "[25, 360] loss: 0.289\n",
      "Epoch: 25 -> Loss: 0.23557433486\n",
      "Epoch: 25 -> Test Accuracy: 84.91\n",
      "[26, 60] loss: 0.260\n",
      "[26, 120] loss: 0.243\n",
      "[26, 180] loss: 0.269\n",
      "[26, 240] loss: 0.267\n",
      "[26, 300] loss: 0.268\n",
      "[26, 360] loss: 0.279\n",
      "Epoch: 26 -> Loss: 0.32897824049\n",
      "Epoch: 26 -> Test Accuracy: 85.77\n",
      "[27, 60] loss: 0.231\n",
      "[27, 120] loss: 0.246\n",
      "[27, 180] loss: 0.262\n",
      "[27, 240] loss: 0.279\n",
      "[27, 300] loss: 0.271\n",
      "[27, 360] loss: 0.278\n",
      "Epoch: 27 -> Loss: 0.184163317084\n",
      "Epoch: 27 -> Test Accuracy: 85.5\n",
      "[28, 60] loss: 0.244\n",
      "[28, 120] loss: 0.248\n",
      "[28, 180] loss: 0.257\n",
      "[28, 240] loss: 0.272\n",
      "[28, 300] loss: 0.277\n",
      "[28, 360] loss: 0.281\n",
      "Epoch: 28 -> Loss: 0.184274703264\n",
      "Epoch: 28 -> Test Accuracy: 85.56\n",
      "[29, 60] loss: 0.234\n",
      "[29, 120] loss: 0.241\n",
      "[29, 180] loss: 0.253\n",
      "[29, 240] loss: 0.264\n",
      "[29, 300] loss: 0.271\n",
      "[29, 360] loss: 0.284\n",
      "Epoch: 29 -> Loss: 0.172003015876\n",
      "Epoch: 29 -> Test Accuracy: 85.08\n",
      "[30, 60] loss: 0.237\n",
      "[30, 120] loss: 0.248\n",
      "[30, 180] loss: 0.270\n",
      "[30, 240] loss: 0.278\n",
      "[30, 300] loss: 0.264\n",
      "[30, 360] loss: 0.271\n",
      "Epoch: 30 -> Loss: 0.096121840179\n",
      "Epoch: 30 -> Test Accuracy: 85.67\n",
      "[31, 60] loss: 0.243\n",
      "[31, 120] loss: 0.262\n",
      "[31, 180] loss: 0.258\n",
      "[31, 240] loss: 0.268\n",
      "[31, 300] loss: 0.269\n",
      "[31, 360] loss: 0.275\n",
      "Epoch: 31 -> Loss: 0.286776602268\n",
      "Epoch: 31 -> Test Accuracy: 85.91\n",
      "[32, 60] loss: 0.236\n",
      "[32, 120] loss: 0.237\n",
      "[32, 180] loss: 0.258\n",
      "[32, 240] loss: 0.271\n",
      "[32, 300] loss: 0.260\n",
      "[32, 360] loss: 0.286\n",
      "Epoch: 32 -> Loss: 0.274690955877\n",
      "Epoch: 32 -> Test Accuracy: 85.98\n",
      "[33, 60] loss: 0.239\n",
      "[33, 120] loss: 0.249\n",
      "[33, 180] loss: 0.247\n",
      "[33, 240] loss: 0.276\n",
      "[33, 300] loss: 0.269\n",
      "[33, 360] loss: 0.265\n",
      "Epoch: 33 -> Loss: 0.322587043047\n",
      "Epoch: 33 -> Test Accuracy: 85.25\n",
      "[34, 60] loss: 0.228\n",
      "[34, 120] loss: 0.246\n",
      "[34, 180] loss: 0.260\n",
      "[34, 240] loss: 0.284\n",
      "[34, 300] loss: 0.273\n",
      "[34, 360] loss: 0.260\n",
      "Epoch: 34 -> Loss: 0.327111631632\n",
      "Epoch: 34 -> Test Accuracy: 85.52\n",
      "[35, 60] loss: 0.230\n",
      "[35, 120] loss: 0.242\n",
      "[35, 180] loss: 0.254\n",
      "[35, 240] loss: 0.261\n",
      "[35, 300] loss: 0.267\n",
      "[35, 360] loss: 0.265\n",
      "Epoch: 35 -> Loss: 0.190892666578\n",
      "Epoch: 35 -> Test Accuracy: 85.37\n",
      "[36, 60] loss: 0.198\n",
      "[36, 120] loss: 0.186\n",
      "[36, 180] loss: 0.177\n",
      "[36, 240] loss: 0.161\n",
      "[36, 300] loss: 0.154\n",
      "[36, 360] loss: 0.151\n",
      "Epoch: 36 -> Loss: 0.066698089242\n",
      "Epoch: 36 -> Test Accuracy: 87.85\n",
      "[37, 60] loss: 0.145\n",
      "[37, 120] loss: 0.139\n",
      "[37, 180] loss: 0.138\n",
      "[37, 240] loss: 0.137\n",
      "[37, 300] loss: 0.144\n",
      "[37, 360] loss: 0.151\n",
      "Epoch: 37 -> Loss: 0.209699481726\n",
      "Epoch: 37 -> Test Accuracy: 87.95\n",
      "[38, 60] loss: 0.121\n",
      "[38, 120] loss: 0.129\n",
      "[38, 180] loss: 0.132\n",
      "[38, 240] loss: 0.134\n",
      "[38, 300] loss: 0.126\n",
      "[38, 360] loss: 0.130\n",
      "Epoch: 38 -> Loss: 0.0859239697456\n",
      "Epoch: 38 -> Test Accuracy: 88.55\n",
      "[39, 60] loss: 0.112\n",
      "[39, 120] loss: 0.119\n",
      "[39, 180] loss: 0.121\n",
      "[39, 240] loss: 0.117\n",
      "[39, 300] loss: 0.127\n",
      "[39, 360] loss: 0.114\n",
      "Epoch: 39 -> Loss: 0.0728931874037\n",
      "Epoch: 39 -> Test Accuracy: 87.9\n",
      "[40, 60] loss: 0.104\n",
      "[40, 120] loss: 0.111\n",
      "[40, 180] loss: 0.115\n",
      "[40, 240] loss: 0.110\n",
      "[40, 300] loss: 0.119\n",
      "[40, 360] loss: 0.123\n",
      "Epoch: 40 -> Loss: 0.188034817576\n",
      "Epoch: 40 -> Test Accuracy: 87.98\n",
      "[41, 60] loss: 0.106\n",
      "[41, 120] loss: 0.102\n",
      "[41, 180] loss: 0.106\n",
      "[41, 240] loss: 0.111\n",
      "[41, 300] loss: 0.103\n",
      "[41, 360] loss: 0.120\n",
      "Epoch: 41 -> Loss: 0.0998931452632\n",
      "Epoch: 41 -> Test Accuracy: 88.13\n",
      "[42, 60] loss: 0.103\n",
      "[42, 120] loss: 0.097\n",
      "[42, 180] loss: 0.103\n",
      "[42, 240] loss: 0.112\n",
      "[42, 300] loss: 0.105\n",
      "[42, 360] loss: 0.119\n",
      "Epoch: 42 -> Loss: 0.18023404479\n",
      "Epoch: 42 -> Test Accuracy: 87.78\n",
      "[43, 60] loss: 0.100\n",
      "[43, 120] loss: 0.109\n",
      "[43, 180] loss: 0.103\n",
      "[43, 240] loss: 0.105\n",
      "[43, 300] loss: 0.101\n",
      "[43, 360] loss: 0.110\n",
      "Epoch: 43 -> Loss: 0.11309479177\n",
      "Epoch: 43 -> Test Accuracy: 87.54\n",
      "[44, 60] loss: 0.097\n",
      "[44, 120] loss: 0.096\n",
      "[44, 180] loss: 0.101\n",
      "[44, 240] loss: 0.108\n",
      "[44, 300] loss: 0.104\n",
      "[44, 360] loss: 0.105\n",
      "Epoch: 44 -> Loss: 0.277705937624\n",
      "Epoch: 44 -> Test Accuracy: 87.43\n",
      "[45, 60] loss: 0.096\n",
      "[45, 120] loss: 0.091\n",
      "[45, 180] loss: 0.094\n",
      "[45, 240] loss: 0.106\n",
      "[45, 300] loss: 0.104\n",
      "[45, 360] loss: 0.108\n",
      "Epoch: 45 -> Loss: 0.122581794858\n",
      "Epoch: 45 -> Test Accuracy: 87.8\n",
      "[46, 60] loss: 0.091\n",
      "[46, 120] loss: 0.098\n",
      "[46, 180] loss: 0.101\n",
      "[46, 240] loss: 0.109\n",
      "[46, 300] loss: 0.109\n",
      "[46, 360] loss: 0.111\n",
      "Epoch: 46 -> Loss: 0.0961921289563\n",
      "Epoch: 46 -> Test Accuracy: 87.46\n",
      "[47, 60] loss: 0.099\n",
      "[47, 120] loss: 0.095\n",
      "[47, 180] loss: 0.101\n",
      "[47, 240] loss: 0.108\n",
      "[47, 300] loss: 0.110\n",
      "[47, 360] loss: 0.114\n",
      "Epoch: 47 -> Loss: 0.10576428473\n",
      "Epoch: 47 -> Test Accuracy: 87.59\n",
      "[48, 60] loss: 0.090\n",
      "[48, 120] loss: 0.089\n",
      "[48, 180] loss: 0.097\n",
      "[48, 240] loss: 0.110\n",
      "[48, 300] loss: 0.098\n",
      "[48, 360] loss: 0.118\n",
      "Epoch: 48 -> Loss: 0.136466532946\n",
      "Epoch: 48 -> Test Accuracy: 87.42\n",
      "[49, 60] loss: 0.097\n",
      "[49, 120] loss: 0.104\n",
      "[49, 180] loss: 0.099\n",
      "[49, 240] loss: 0.098\n",
      "[49, 300] loss: 0.103\n",
      "[49, 360] loss: 0.116\n",
      "Epoch: 49 -> Loss: 0.168294817209\n",
      "Epoch: 49 -> Test Accuracy: 87.63\n",
      "[50, 60] loss: 0.106\n",
      "[50, 120] loss: 0.096\n",
      "[50, 180] loss: 0.101\n",
      "[50, 240] loss: 0.102\n",
      "[50, 300] loss: 0.112\n",
      "[50, 360] loss: 0.108\n",
      "Epoch: 50 -> Loss: 0.181145042181\n",
      "Epoch: 50 -> Test Accuracy: 87.26\n",
      "[51, 60] loss: 0.095\n",
      "[51, 120] loss: 0.097\n",
      "[51, 180] loss: 0.108\n",
      "[51, 240] loss: 0.105\n",
      "[51, 300] loss: 0.119\n",
      "[51, 360] loss: 0.110\n",
      "Epoch: 51 -> Loss: 0.130636423826\n",
      "Epoch: 51 -> Test Accuracy: 87.51\n",
      "[52, 60] loss: 0.086\n",
      "[52, 120] loss: 0.092\n",
      "[52, 180] loss: 0.103\n",
      "[52, 240] loss: 0.107\n",
      "[52, 300] loss: 0.116\n",
      "[52, 360] loss: 0.107\n",
      "Epoch: 52 -> Loss: 0.0313510075212\n",
      "Epoch: 52 -> Test Accuracy: 87.25\n",
      "[53, 60] loss: 0.092\n",
      "[53, 120] loss: 0.097\n",
      "[53, 180] loss: 0.099\n",
      "[53, 240] loss: 0.107\n",
      "[53, 300] loss: 0.109\n",
      "[53, 360] loss: 0.105\n",
      "Epoch: 53 -> Loss: 0.0995361059904\n",
      "Epoch: 53 -> Test Accuracy: 87.59\n",
      "[54, 60] loss: 0.099\n",
      "[54, 120] loss: 0.096\n",
      "[54, 180] loss: 0.110\n",
      "[54, 240] loss: 0.104\n",
      "[54, 300] loss: 0.108\n",
      "[54, 360] loss: 0.103\n",
      "Epoch: 54 -> Loss: 0.172135040164\n",
      "Epoch: 54 -> Test Accuracy: 87.97\n",
      "[55, 60] loss: 0.097\n",
      "[55, 120] loss: 0.101\n",
      "[55, 180] loss: 0.109\n",
      "[55, 240] loss: 0.111\n",
      "[55, 300] loss: 0.108\n",
      "[55, 360] loss: 0.109\n",
      "Epoch: 55 -> Loss: 0.113258205354\n",
      "Epoch: 55 -> Test Accuracy: 87.76\n",
      "[56, 60] loss: 0.095\n",
      "[56, 120] loss: 0.088\n",
      "[56, 180] loss: 0.099\n",
      "[56, 240] loss: 0.100\n",
      "[56, 300] loss: 0.104\n",
      "[56, 360] loss: 0.113\n",
      "Epoch: 56 -> Loss: 0.0988501533866\n",
      "Epoch: 56 -> Test Accuracy: 86.88\n",
      "[57, 60] loss: 0.096\n",
      "[57, 120] loss: 0.098\n",
      "[57, 180] loss: 0.098\n",
      "[57, 240] loss: 0.118\n",
      "[57, 300] loss: 0.117\n",
      "[57, 360] loss: 0.104\n",
      "Epoch: 57 -> Loss: 0.15631480515\n",
      "Epoch: 57 -> Test Accuracy: 87.04\n",
      "[58, 60] loss: 0.096\n",
      "[58, 120] loss: 0.097\n",
      "[58, 180] loss: 0.103\n",
      "[58, 240] loss: 0.113\n",
      "[58, 300] loss: 0.112\n",
      "[58, 360] loss: 0.116\n",
      "Epoch: 58 -> Loss: 0.0902777388692\n",
      "Epoch: 58 -> Test Accuracy: 87.15\n",
      "[59, 60] loss: 0.097\n",
      "[59, 120] loss: 0.101\n",
      "[59, 180] loss: 0.092\n",
      "[59, 240] loss: 0.104\n",
      "[59, 300] loss: 0.111\n",
      "[59, 360] loss: 0.106\n",
      "Epoch: 59 -> Loss: 0.0914585143328\n",
      "Epoch: 59 -> Test Accuracy: 86.99\n",
      "[60, 60] loss: 0.100\n",
      "[60, 120] loss: 0.089\n",
      "[60, 180] loss: 0.097\n",
      "[60, 240] loss: 0.104\n",
      "[60, 300] loss: 0.106\n",
      "[60, 360] loss: 0.118\n",
      "Epoch: 60 -> Loss: 0.0743315592408\n",
      "Epoch: 60 -> Test Accuracy: 87.1\n",
      "[61, 60] loss: 0.095\n",
      "[61, 120] loss: 0.097\n",
      "[61, 180] loss: 0.098\n",
      "[61, 240] loss: 0.109\n",
      "[61, 300] loss: 0.106\n",
      "[61, 360] loss: 0.108\n",
      "Epoch: 61 -> Loss: 0.121019817889\n",
      "Epoch: 61 -> Test Accuracy: 87.29\n",
      "[62, 60] loss: 0.095\n",
      "[62, 120] loss: 0.094\n",
      "[62, 180] loss: 0.107\n",
      "[62, 240] loss: 0.108\n",
      "[62, 300] loss: 0.111\n",
      "[62, 360] loss: 0.109\n",
      "Epoch: 62 -> Loss: 0.115407928824\n",
      "Epoch: 62 -> Test Accuracy: 86.7\n",
      "[63, 60] loss: 0.096\n",
      "[63, 120] loss: 0.098\n",
      "[63, 180] loss: 0.101\n",
      "[63, 240] loss: 0.093\n",
      "[63, 300] loss: 0.102\n",
      "[63, 360] loss: 0.112\n",
      "Epoch: 63 -> Loss: 0.137736141682\n",
      "Epoch: 63 -> Test Accuracy: 86.94\n",
      "[64, 60] loss: 0.094\n",
      "[64, 120] loss: 0.098\n",
      "[64, 180] loss: 0.090\n",
      "[64, 240] loss: 0.098\n",
      "[64, 300] loss: 0.106\n",
      "[64, 360] loss: 0.114\n",
      "Epoch: 64 -> Loss: 0.17684109509\n",
      "Epoch: 64 -> Test Accuracy: 87.42\n",
      "[65, 60] loss: 0.085\n",
      "[65, 120] loss: 0.096\n",
      "[65, 180] loss: 0.088\n",
      "[65, 240] loss: 0.101\n",
      "[65, 300] loss: 0.103\n",
      "[65, 360] loss: 0.107\n",
      "Epoch: 65 -> Loss: 0.0342645645142\n",
      "Epoch: 65 -> Test Accuracy: 86.89\n",
      "[66, 60] loss: 0.100\n",
      "[66, 120] loss: 0.095\n",
      "[66, 180] loss: 0.097\n",
      "[66, 240] loss: 0.101\n",
      "[66, 300] loss: 0.104\n",
      "[66, 360] loss: 0.110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66 -> Loss: 0.110937856138\n",
      "Epoch: 66 -> Test Accuracy: 86.83\n",
      "[67, 60] loss: 0.096\n",
      "[67, 120] loss: 0.093\n",
      "[67, 180] loss: 0.090\n",
      "[67, 240] loss: 0.102\n",
      "[67, 300] loss: 0.103\n",
      "[67, 360] loss: 0.114\n",
      "Epoch: 67 -> Loss: 0.0884017944336\n",
      "Epoch: 67 -> Test Accuracy: 87.02\n",
      "[68, 60] loss: 0.086\n",
      "[68, 120] loss: 0.087\n",
      "[68, 180] loss: 0.097\n",
      "[68, 240] loss: 0.101\n",
      "[68, 300] loss: 0.107\n",
      "[68, 360] loss: 0.112\n",
      "Epoch: 68 -> Loss: 0.0737691298127\n",
      "Epoch: 68 -> Test Accuracy: 87.4\n",
      "[69, 60] loss: 0.097\n",
      "[69, 120] loss: 0.093\n",
      "[69, 180] loss: 0.105\n",
      "[69, 240] loss: 0.112\n",
      "[69, 300] loss: 0.118\n",
      "[69, 360] loss: 0.111\n",
      "Epoch: 69 -> Loss: 0.145862191916\n",
      "Epoch: 69 -> Test Accuracy: 86.93\n",
      "[70, 60] loss: 0.088\n",
      "[70, 120] loss: 0.087\n",
      "[70, 180] loss: 0.097\n",
      "[70, 240] loss: 0.107\n",
      "[70, 300] loss: 0.103\n",
      "[70, 360] loss: 0.110\n",
      "Epoch: 70 -> Loss: 0.100049495697\n",
      "Epoch: 70 -> Test Accuracy: 86.98\n",
      "[71, 60] loss: 0.084\n",
      "[71, 120] loss: 0.065\n",
      "[71, 180] loss: 0.059\n",
      "[71, 240] loss: 0.064\n",
      "[71, 300] loss: 0.057\n",
      "[71, 360] loss: 0.059\n",
      "Epoch: 71 -> Loss: 0.0582394711673\n",
      "Epoch: 71 -> Test Accuracy: 87.95\n",
      "[72, 60] loss: 0.053\n",
      "[72, 120] loss: 0.053\n",
      "[72, 180] loss: 0.049\n",
      "[72, 240] loss: 0.052\n",
      "[72, 300] loss: 0.050\n",
      "[72, 360] loss: 0.055\n",
      "Epoch: 72 -> Loss: 0.0619064047933\n",
      "Epoch: 72 -> Test Accuracy: 88.61\n",
      "[73, 60] loss: 0.043\n",
      "[73, 120] loss: 0.045\n",
      "[73, 180] loss: 0.045\n",
      "[73, 240] loss: 0.045\n",
      "[73, 300] loss: 0.048\n",
      "[73, 360] loss: 0.046\n",
      "Epoch: 73 -> Loss: 0.0705211013556\n",
      "Epoch: 73 -> Test Accuracy: 88.32\n",
      "[74, 60] loss: 0.040\n",
      "[74, 120] loss: 0.039\n",
      "[74, 180] loss: 0.040\n",
      "[74, 240] loss: 0.042\n",
      "[74, 300] loss: 0.044\n",
      "[74, 360] loss: 0.040\n",
      "Epoch: 74 -> Loss: 0.018563831225\n",
      "Epoch: 74 -> Test Accuracy: 88.47\n",
      "[75, 60] loss: 0.039\n",
      "[75, 120] loss: 0.038\n",
      "[75, 180] loss: 0.039\n",
      "[75, 240] loss: 0.042\n",
      "[75, 300] loss: 0.040\n",
      "[75, 360] loss: 0.040\n",
      "Epoch: 75 -> Loss: 0.0451459474862\n",
      "Epoch: 75 -> Test Accuracy: 88.37\n",
      "[76, 60] loss: 0.034\n",
      "[76, 120] loss: 0.035\n",
      "[76, 180] loss: 0.036\n",
      "[76, 240] loss: 0.038\n",
      "[76, 300] loss: 0.040\n",
      "[76, 360] loss: 0.042\n",
      "Epoch: 76 -> Loss: 0.0630013793707\n",
      "Epoch: 76 -> Test Accuracy: 88.51\n",
      "[77, 60] loss: 0.034\n",
      "[77, 120] loss: 0.034\n",
      "[77, 180] loss: 0.039\n",
      "[77, 240] loss: 0.036\n",
      "[77, 300] loss: 0.040\n",
      "[77, 360] loss: 0.035\n",
      "Epoch: 77 -> Loss: 0.0266649536788\n",
      "Epoch: 77 -> Test Accuracy: 88.5\n",
      "[78, 60] loss: 0.037\n",
      "[78, 120] loss: 0.033\n",
      "[78, 180] loss: 0.035\n",
      "[78, 240] loss: 0.038\n",
      "[78, 300] loss: 0.035\n",
      "[78, 360] loss: 0.037\n",
      "Epoch: 78 -> Loss: 0.137741044164\n",
      "Epoch: 78 -> Test Accuracy: 88.6\n",
      "[79, 60] loss: 0.037\n",
      "[79, 120] loss: 0.034\n",
      "[79, 180] loss: 0.035\n",
      "[79, 240] loss: 0.036\n",
      "[79, 300] loss: 0.035\n",
      "[79, 360] loss: 0.036\n",
      "Epoch: 79 -> Loss: 0.0460104085505\n",
      "Epoch: 79 -> Test Accuracy: 88.68\n",
      "[80, 60] loss: 0.035\n",
      "[80, 120] loss: 0.032\n",
      "[80, 180] loss: 0.033\n",
      "[80, 240] loss: 0.031\n",
      "[80, 300] loss: 0.033\n",
      "[80, 360] loss: 0.032\n",
      "Epoch: 80 -> Loss: 0.0889398008585\n",
      "Epoch: 80 -> Test Accuracy: 88.69\n",
      "[81, 60] loss: 0.033\n",
      "[81, 120] loss: 0.032\n",
      "[81, 180] loss: 0.031\n",
      "[81, 240] loss: 0.033\n",
      "[81, 300] loss: 0.036\n",
      "[81, 360] loss: 0.032\n",
      "Epoch: 81 -> Loss: 0.0478037372231\n",
      "Epoch: 81 -> Test Accuracy: 88.56\n",
      "[82, 60] loss: 0.029\n",
      "[82, 120] loss: 0.031\n",
      "[82, 180] loss: 0.031\n",
      "[82, 240] loss: 0.031\n",
      "[82, 300] loss: 0.034\n",
      "[82, 360] loss: 0.032\n",
      "Epoch: 82 -> Loss: 0.020411318168\n",
      "Epoch: 82 -> Test Accuracy: 88.68\n",
      "[83, 60] loss: 0.031\n",
      "[83, 120] loss: 0.036\n",
      "[83, 180] loss: 0.031\n",
      "[83, 240] loss: 0.031\n",
      "[83, 300] loss: 0.033\n",
      "[83, 360] loss: 0.033\n",
      "Epoch: 83 -> Loss: 0.0189818199724\n",
      "Epoch: 83 -> Test Accuracy: 88.59\n",
      "[84, 60] loss: 0.028\n",
      "[84, 120] loss: 0.030\n",
      "[84, 180] loss: 0.032\n",
      "[84, 240] loss: 0.034\n",
      "[84, 300] loss: 0.032\n",
      "[84, 360] loss: 0.032\n",
      "Epoch: 84 -> Loss: 0.0683481544256\n",
      "Epoch: 84 -> Test Accuracy: 88.5\n",
      "[85, 60] loss: 0.030\n",
      "[85, 120] loss: 0.031\n",
      "[85, 180] loss: 0.031\n",
      "[85, 240] loss: 0.031\n",
      "[85, 300] loss: 0.034\n",
      "[85, 360] loss: 0.033\n",
      "Epoch: 85 -> Loss: 0.0488385632634\n",
      "Epoch: 85 -> Test Accuracy: 88.57\n",
      "[86, 60] loss: 0.027\n",
      "[86, 120] loss: 0.028\n",
      "[86, 180] loss: 0.027\n",
      "[86, 240] loss: 0.026\n",
      "[86, 300] loss: 0.028\n",
      "[86, 360] loss: 0.026\n",
      "Epoch: 86 -> Loss: 0.0182302482426\n",
      "Epoch: 86 -> Test Accuracy: 88.67\n",
      "[87, 60] loss: 0.028\n",
      "[87, 120] loss: 0.028\n",
      "[87, 180] loss: 0.028\n",
      "[87, 240] loss: 0.026\n",
      "[87, 300] loss: 0.026\n",
      "[87, 360] loss: 0.027\n",
      "Epoch: 87 -> Loss: 0.0283513162285\n",
      "Epoch: 87 -> Test Accuracy: 88.79\n",
      "[88, 60] loss: 0.027\n",
      "[88, 120] loss: 0.026\n",
      "[88, 180] loss: 0.028\n",
      "[88, 240] loss: 0.025\n",
      "[88, 300] loss: 0.027\n",
      "[88, 360] loss: 0.027\n",
      "Epoch: 88 -> Loss: 0.0175194647163\n",
      "Epoch: 88 -> Test Accuracy: 88.7\n",
      "[89, 60] loss: 0.026\n",
      "[89, 120] loss: 0.024\n",
      "[89, 180] loss: 0.026\n",
      "[89, 240] loss: 0.026\n",
      "[89, 300] loss: 0.025\n",
      "[89, 360] loss: 0.026\n",
      "Epoch: 89 -> Loss: 0.0622618570924\n",
      "Epoch: 89 -> Test Accuracy: 88.77\n",
      "[90, 60] loss: 0.028\n",
      "[90, 120] loss: 0.025\n",
      "[90, 180] loss: 0.028\n",
      "[90, 240] loss: 0.027\n",
      "[90, 300] loss: 0.023\n",
      "[90, 360] loss: 0.026\n",
      "Epoch: 90 -> Loss: 0.0405211523175\n",
      "Epoch: 90 -> Test Accuracy: 88.78\n",
      "[91, 60] loss: 0.027\n",
      "[91, 120] loss: 0.026\n",
      "[91, 180] loss: 0.024\n",
      "[91, 240] loss: 0.026\n",
      "[91, 300] loss: 0.027\n",
      "[91, 360] loss: 0.023\n",
      "Epoch: 91 -> Loss: 0.0401269458234\n",
      "Epoch: 91 -> Test Accuracy: 88.74\n",
      "[92, 60] loss: 0.026\n",
      "[92, 120] loss: 0.022\n",
      "[92, 180] loss: 0.027\n",
      "[92, 240] loss: 0.026\n",
      "[92, 300] loss: 0.024\n",
      "[92, 360] loss: 0.027\n",
      "Epoch: 92 -> Loss: 0.0252097547054\n",
      "Epoch: 92 -> Test Accuracy: 88.75\n",
      "[93, 60] loss: 0.025\n",
      "[93, 120] loss: 0.025\n",
      "[93, 180] loss: 0.026\n",
      "[93, 240] loss: 0.025\n",
      "[93, 300] loss: 0.024\n",
      "[93, 360] loss: 0.025\n",
      "Epoch: 93 -> Loss: 0.0255874283612\n",
      "Epoch: 93 -> Test Accuracy: 88.82\n",
      "[94, 60] loss: 0.024\n",
      "[94, 120] loss: 0.025\n",
      "[94, 180] loss: 0.026\n",
      "[94, 240] loss: 0.024\n",
      "[94, 300] loss: 0.025\n",
      "[94, 360] loss: 0.023\n",
      "Epoch: 94 -> Loss: 0.0522643849254\n",
      "Epoch: 94 -> Test Accuracy: 88.8\n",
      "[95, 60] loss: 0.025\n",
      "[95, 120] loss: 0.024\n",
      "[95, 180] loss: 0.025\n",
      "[95, 240] loss: 0.026\n",
      "[95, 300] loss: 0.026\n",
      "[95, 360] loss: 0.025\n",
      "Epoch: 95 -> Loss: 0.0158718526363\n",
      "Epoch: 95 -> Test Accuracy: 88.65\n",
      "[96, 60] loss: 0.023\n",
      "[96, 120] loss: 0.023\n",
      "[96, 180] loss: 0.025\n",
      "[96, 240] loss: 0.026\n",
      "[96, 300] loss: 0.024\n",
      "[96, 360] loss: 0.025\n",
      "Epoch: 96 -> Loss: 0.0385310165584\n",
      "Epoch: 96 -> Test Accuracy: 88.86\n",
      "[97, 60] loss: 0.026\n",
      "[97, 120] loss: 0.024\n",
      "[97, 180] loss: 0.026\n",
      "[97, 240] loss: 0.025\n",
      "[97, 300] loss: 0.025\n",
      "[97, 360] loss: 0.022\n",
      "Epoch: 97 -> Loss: 0.0383609123528\n",
      "Epoch: 97 -> Test Accuracy: 88.76\n",
      "[98, 60] loss: 0.024\n",
      "[98, 120] loss: 0.023\n",
      "[98, 180] loss: 0.024\n",
      "[98, 240] loss: 0.025\n",
      "[98, 300] loss: 0.022\n",
      "[98, 360] loss: 0.025\n",
      "Epoch: 98 -> Loss: 0.0454894937575\n",
      "Epoch: 98 -> Test Accuracy: 88.75\n",
      "[99, 60] loss: 0.024\n",
      "[99, 120] loss: 0.024\n",
      "[99, 180] loss: 0.024\n",
      "[99, 240] loss: 0.023\n",
      "[99, 300] loss: 0.026\n",
      "[99, 360] loss: 0.023\n",
      "Epoch: 99 -> Loss: 0.0100147277117\n",
      "Epoch: 99 -> Test Accuracy: 88.68\n",
      "[100, 60] loss: 0.025\n",
      "[100, 120] loss: 0.028\n",
      "[100, 180] loss: 0.023\n",
      "[100, 240] loss: 0.024\n",
      "[100, 300] loss: 0.024\n",
      "[100, 360] loss: 0.025\n",
      "Epoch: 100 -> Loss: 0.0136953350157\n",
      "Epoch: 100 -> Test Accuracy: 88.62\n",
      "Finished Training\n",
      "[1, 60] loss: 0.934\n",
      "[1, 120] loss: 0.673\n",
      "[1, 180] loss: 0.658\n",
      "[1, 240] loss: 0.613\n",
      "[1, 300] loss: 0.564\n",
      "[1, 360] loss: 0.591\n",
      "Epoch: 1 -> Loss: 0.485624551773\n",
      "Epoch: 1 -> Test Accuracy: 77.22\n",
      "[2, 60] loss: 0.545\n",
      "[2, 120] loss: 0.541\n",
      "[2, 180] loss: 0.533\n",
      "[2, 240] loss: 0.522\n",
      "[2, 300] loss: 0.539\n",
      "[2, 360] loss: 0.512\n",
      "Epoch: 2 -> Loss: 0.47289571166\n",
      "Epoch: 2 -> Test Accuracy: 77.92\n",
      "[3, 60] loss: 0.504\n",
      "[3, 120] loss: 0.489\n",
      "[3, 180] loss: 0.487\n",
      "[3, 240] loss: 0.493\n",
      "[3, 300] loss: 0.492\n",
      "[3, 360] loss: 0.512\n",
      "Epoch: 3 -> Loss: 0.650255978107\n",
      "Epoch: 3 -> Test Accuracy: 79.04\n",
      "[4, 60] loss: 0.481\n",
      "[4, 120] loss: 0.485\n",
      "[4, 180] loss: 0.469\n",
      "[4, 240] loss: 0.476\n",
      "[4, 300] loss: 0.468\n",
      "[4, 360] loss: 0.473\n",
      "Epoch: 4 -> Loss: 0.419468075037\n",
      "Epoch: 4 -> Test Accuracy: 79.25\n",
      "[5, 60] loss: 0.469\n",
      "[5, 120] loss: 0.474\n",
      "[5, 180] loss: 0.450\n",
      "[5, 240] loss: 0.460\n",
      "[5, 300] loss: 0.480\n",
      "[5, 360] loss: 0.461\n",
      "Epoch: 5 -> Loss: 0.383632451296\n",
      "Epoch: 5 -> Test Accuracy: 80.17\n",
      "[6, 60] loss: 0.435\n",
      "[6, 120] loss: 0.445\n",
      "[6, 180] loss: 0.458\n",
      "[6, 240] loss: 0.440\n",
      "[6, 300] loss: 0.476\n",
      "[6, 360] loss: 0.459\n",
      "Epoch: 6 -> Loss: 0.426968753338\n",
      "Epoch: 6 -> Test Accuracy: 80.67\n",
      "[7, 60] loss: 0.429\n",
      "[7, 120] loss: 0.430\n",
      "[7, 180] loss: 0.444\n",
      "[7, 240] loss: 0.446\n",
      "[7, 300] loss: 0.457\n",
      "[7, 360] loss: 0.458\n",
      "Epoch: 7 -> Loss: 0.457468181849\n",
      "Epoch: 7 -> Test Accuracy: 80.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 60] loss: 0.422\n",
      "[8, 120] loss: 0.435\n",
      "[8, 180] loss: 0.448\n",
      "[8, 240] loss: 0.434\n",
      "[8, 300] loss: 0.448\n",
      "[8, 360] loss: 0.438\n",
      "Epoch: 8 -> Loss: 0.463697046041\n",
      "Epoch: 8 -> Test Accuracy: 80.55\n",
      "[9, 60] loss: 0.397\n",
      "[9, 120] loss: 0.426\n",
      "[9, 180] loss: 0.421\n",
      "[9, 240] loss: 0.449\n",
      "[9, 300] loss: 0.450\n",
      "[9, 360] loss: 0.439\n",
      "Epoch: 9 -> Loss: 0.445752859116\n",
      "Epoch: 9 -> Test Accuracy: 81.22\n",
      "[10, 60] loss: 0.411\n",
      "[10, 120] loss: 0.426\n",
      "[10, 180] loss: 0.422\n",
      "[10, 240] loss: 0.424\n",
      "[10, 300] loss: 0.431\n",
      "[10, 360] loss: 0.459\n",
      "Epoch: 10 -> Loss: 0.444129943848\n",
      "Epoch: 10 -> Test Accuracy: 81.33\n",
      "[11, 60] loss: 0.423\n",
      "[11, 120] loss: 0.413\n",
      "[11, 180] loss: 0.419\n",
      "[11, 240] loss: 0.431\n",
      "[11, 300] loss: 0.418\n",
      "[11, 360] loss: 0.456\n",
      "Epoch: 11 -> Loss: 0.567027926445\n",
      "Epoch: 11 -> Test Accuracy: 80.39\n",
      "[12, 60] loss: 0.404\n",
      "[12, 120] loss: 0.425\n",
      "[12, 180] loss: 0.430\n",
      "[12, 240] loss: 0.424\n",
      "[12, 300] loss: 0.434\n",
      "[12, 360] loss: 0.431\n",
      "Epoch: 12 -> Loss: 0.356236189604\n",
      "Epoch: 12 -> Test Accuracy: 81.09\n",
      "[13, 60] loss: 0.415\n",
      "[13, 120] loss: 0.416\n",
      "[13, 180] loss: 0.413\n",
      "[13, 240] loss: 0.437\n",
      "[13, 300] loss: 0.426\n",
      "[13, 360] loss: 0.424\n",
      "Epoch: 13 -> Loss: 0.362850636244\n",
      "Epoch: 13 -> Test Accuracy: 80.81\n",
      "[14, 60] loss: 0.407\n",
      "[14, 120] loss: 0.407\n",
      "[14, 180] loss: 0.419\n",
      "[14, 240] loss: 0.428\n",
      "[14, 300] loss: 0.439\n",
      "[14, 360] loss: 0.420\n",
      "Epoch: 14 -> Loss: 0.444517850876\n",
      "Epoch: 14 -> Test Accuracy: 81.43\n",
      "[15, 60] loss: 0.398\n",
      "[15, 120] loss: 0.406\n",
      "[15, 180] loss: 0.414\n",
      "[15, 240] loss: 0.428\n",
      "[15, 300] loss: 0.426\n",
      "[15, 360] loss: 0.424\n",
      "Epoch: 15 -> Loss: 0.359560251236\n",
      "Epoch: 15 -> Test Accuracy: 80.63\n",
      "[16, 60] loss: 0.391\n",
      "[16, 120] loss: 0.401\n",
      "[16, 180] loss: 0.410\n",
      "[16, 240] loss: 0.401\n",
      "[16, 300] loss: 0.406\n",
      "[16, 360] loss: 0.422\n",
      "Epoch: 16 -> Loss: 0.700681507587\n",
      "Epoch: 16 -> Test Accuracy: 81.33\n",
      "[17, 60] loss: 0.388\n",
      "[17, 120] loss: 0.409\n",
      "[17, 180] loss: 0.405\n",
      "[17, 240] loss: 0.422\n",
      "[17, 300] loss: 0.421\n",
      "[17, 360] loss: 0.430\n",
      "Epoch: 17 -> Loss: 0.399750113487\n",
      "Epoch: 17 -> Test Accuracy: 80.88\n",
      "[18, 60] loss: 0.411\n",
      "[18, 120] loss: 0.393\n",
      "[18, 180] loss: 0.411\n",
      "[18, 240] loss: 0.405\n",
      "[18, 300] loss: 0.395\n",
      "[18, 360] loss: 0.430\n",
      "Epoch: 18 -> Loss: 0.314178049564\n",
      "Epoch: 18 -> Test Accuracy: 80.86\n",
      "[19, 60] loss: 0.400\n",
      "[19, 120] loss: 0.403\n",
      "[19, 180] loss: 0.420\n",
      "[19, 240] loss: 0.402\n",
      "[19, 300] loss: 0.427\n",
      "[19, 360] loss: 0.402\n",
      "Epoch: 19 -> Loss: 0.560562729836\n",
      "Epoch: 19 -> Test Accuracy: 80.82\n",
      "[20, 60] loss: 0.384\n",
      "[20, 120] loss: 0.415\n",
      "[20, 180] loss: 0.411\n",
      "[20, 240] loss: 0.404\n",
      "[20, 300] loss: 0.411\n",
      "[20, 360] loss: 0.404\n",
      "Epoch: 20 -> Loss: 0.338573813438\n",
      "Epoch: 20 -> Test Accuracy: 81.15\n",
      "[21, 60] loss: 0.405\n",
      "[21, 120] loss: 0.400\n",
      "[21, 180] loss: 0.416\n",
      "[21, 240] loss: 0.401\n",
      "[21, 300] loss: 0.421\n",
      "[21, 360] loss: 0.425\n",
      "Epoch: 21 -> Loss: 0.588072776794\n",
      "Epoch: 21 -> Test Accuracy: 81.22\n",
      "[22, 60] loss: 0.394\n",
      "[22, 120] loss: 0.391\n",
      "[22, 180] loss: 0.400\n",
      "[22, 240] loss: 0.404\n",
      "[22, 300] loss: 0.419\n",
      "[22, 360] loss: 0.423\n",
      "Epoch: 22 -> Loss: 0.359772145748\n",
      "Epoch: 22 -> Test Accuracy: 81.05\n",
      "[23, 60] loss: 0.385\n",
      "[23, 120] loss: 0.402\n",
      "[23, 180] loss: 0.401\n",
      "[23, 240] loss: 0.409\n",
      "[23, 300] loss: 0.398\n",
      "[23, 360] loss: 0.407\n",
      "Epoch: 23 -> Loss: 0.501700162888\n",
      "Epoch: 23 -> Test Accuracy: 81.54\n",
      "[24, 60] loss: 0.393\n",
      "[24, 120] loss: 0.386\n",
      "[24, 180] loss: 0.391\n",
      "[24, 240] loss: 0.395\n",
      "[24, 300] loss: 0.416\n",
      "[24, 360] loss: 0.413\n",
      "Epoch: 24 -> Loss: 0.33479526639\n",
      "Epoch: 24 -> Test Accuracy: 80.09\n",
      "[25, 60] loss: 0.369\n",
      "[25, 120] loss: 0.396\n",
      "[25, 180] loss: 0.402\n",
      "[25, 240] loss: 0.395\n",
      "[25, 300] loss: 0.415\n",
      "[25, 360] loss: 0.422\n",
      "Epoch: 25 -> Loss: 0.530636131763\n",
      "Epoch: 25 -> Test Accuracy: 81.36\n",
      "[26, 60] loss: 0.385\n",
      "[26, 120] loss: 0.389\n",
      "[26, 180] loss: 0.399\n",
      "[26, 240] loss: 0.410\n",
      "[26, 300] loss: 0.413\n",
      "[26, 360] loss: 0.419\n",
      "Epoch: 26 -> Loss: 0.310536384583\n",
      "Epoch: 26 -> Test Accuracy: 81.5\n",
      "[27, 60] loss: 0.370\n",
      "[27, 120] loss: 0.391\n",
      "[27, 180] loss: 0.403\n",
      "[27, 240] loss: 0.408\n",
      "[27, 300] loss: 0.423\n",
      "[27, 360] loss: 0.402\n",
      "Epoch: 27 -> Loss: 0.455167770386\n",
      "Epoch: 27 -> Test Accuracy: 80.89\n",
      "[28, 60] loss: 0.380\n",
      "[28, 120] loss: 0.389\n",
      "[28, 180] loss: 0.383\n",
      "[28, 240] loss: 0.422\n",
      "[28, 300] loss: 0.417\n",
      "[28, 360] loss: 0.427\n",
      "Epoch: 28 -> Loss: 0.36099499464\n",
      "Epoch: 28 -> Test Accuracy: 81.2\n",
      "[29, 60] loss: 0.396\n",
      "[29, 120] loss: 0.391\n",
      "[29, 180] loss: 0.402\n",
      "[29, 240] loss: 0.391\n",
      "[29, 300] loss: 0.382\n",
      "[29, 360] loss: 0.413\n",
      "Epoch: 29 -> Loss: 0.42956122756\n",
      "Epoch: 29 -> Test Accuracy: 81.41\n",
      "[30, 60] loss: 0.370\n",
      "[30, 120] loss: 0.391\n",
      "[30, 180] loss: 0.392\n",
      "[30, 240] loss: 0.385\n",
      "[30, 300] loss: 0.417\n",
      "[30, 360] loss: 0.406\n",
      "Epoch: 30 -> Loss: 0.420710146427\n",
      "Epoch: 30 -> Test Accuracy: 81.29\n",
      "[31, 60] loss: 0.408\n",
      "[31, 120] loss: 0.390\n",
      "[31, 180] loss: 0.395\n",
      "[31, 240] loss: 0.382\n",
      "[31, 300] loss: 0.399\n",
      "[31, 360] loss: 0.415\n",
      "Epoch: 31 -> Loss: 0.510577440262\n",
      "Epoch: 31 -> Test Accuracy: 81.61\n",
      "[32, 60] loss: 0.377\n",
      "[32, 120] loss: 0.409\n",
      "[32, 180] loss: 0.380\n",
      "[32, 240] loss: 0.406\n",
      "[32, 300] loss: 0.406\n",
      "[32, 360] loss: 0.384\n",
      "Epoch: 32 -> Loss: 0.486554205418\n",
      "Epoch: 32 -> Test Accuracy: 81.56\n",
      "[33, 60] loss: 0.404\n",
      "[33, 120] loss: 0.404\n",
      "[33, 180] loss: 0.387\n",
      "[33, 240] loss: 0.395\n",
      "[33, 300] loss: 0.397\n",
      "[33, 360] loss: 0.404\n",
      "Epoch: 33 -> Loss: 0.473952621222\n",
      "Epoch: 33 -> Test Accuracy: 82.18\n",
      "[34, 60] loss: 0.371\n",
      "[34, 120] loss: 0.393\n",
      "[34, 180] loss: 0.396\n",
      "[34, 240] loss: 0.400\n",
      "[34, 300] loss: 0.412\n",
      "[34, 360] loss: 0.402\n",
      "Epoch: 34 -> Loss: 0.471515804529\n",
      "Epoch: 34 -> Test Accuracy: 81.87\n",
      "[35, 60] loss: 0.371\n",
      "[35, 120] loss: 0.403\n",
      "[35, 180] loss: 0.406\n",
      "[35, 240] loss: 0.385\n",
      "[35, 300] loss: 0.407\n",
      "[35, 360] loss: 0.412\n",
      "Epoch: 35 -> Loss: 0.475963503122\n",
      "Epoch: 35 -> Test Accuracy: 80.28\n",
      "[36, 60] loss: 0.336\n",
      "[36, 120] loss: 0.321\n",
      "[36, 180] loss: 0.332\n",
      "[36, 240] loss: 0.309\n",
      "[36, 300] loss: 0.309\n",
      "[36, 360] loss: 0.304\n",
      "Epoch: 36 -> Loss: 0.287034332752\n",
      "Epoch: 36 -> Test Accuracy: 84.07\n",
      "[37, 60] loss: 0.290\n",
      "[37, 120] loss: 0.298\n",
      "[37, 180] loss: 0.283\n",
      "[37, 240] loss: 0.296\n",
      "[37, 300] loss: 0.286\n",
      "[37, 360] loss: 0.286\n",
      "Epoch: 37 -> Loss: 0.151388823986\n",
      "Epoch: 37 -> Test Accuracy: 84.0\n",
      "[38, 60] loss: 0.275\n",
      "[38, 120] loss: 0.286\n",
      "[38, 180] loss: 0.281\n",
      "[38, 240] loss: 0.277\n",
      "[38, 300] loss: 0.282\n",
      "[38, 360] loss: 0.291\n",
      "Epoch: 38 -> Loss: 0.287036091089\n",
      "Epoch: 38 -> Test Accuracy: 83.74\n",
      "[39, 60] loss: 0.262\n",
      "[39, 120] loss: 0.278\n",
      "[39, 180] loss: 0.265\n",
      "[39, 240] loss: 0.263\n",
      "[39, 300] loss: 0.275\n",
      "[39, 360] loss: 0.294\n",
      "Epoch: 39 -> Loss: 0.295067369938\n",
      "Epoch: 39 -> Test Accuracy: 84.31\n",
      "[40, 60] loss: 0.264\n",
      "[40, 120] loss: 0.271\n",
      "[40, 180] loss: 0.269\n",
      "[40, 240] loss: 0.266\n",
      "[40, 300] loss: 0.283\n",
      "[40, 360] loss: 0.275\n",
      "Epoch: 40 -> Loss: 0.362431436777\n",
      "Epoch: 40 -> Test Accuracy: 83.9\n",
      "[41, 60] loss: 0.264\n",
      "[41, 120] loss: 0.262\n",
      "[41, 180] loss: 0.266\n",
      "[41, 240] loss: 0.285\n",
      "[41, 300] loss: 0.275\n",
      "[41, 360] loss: 0.268\n",
      "Epoch: 41 -> Loss: 0.357991158962\n",
      "Epoch: 41 -> Test Accuracy: 84.11\n",
      "[42, 60] loss: 0.272\n",
      "[42, 120] loss: 0.249\n",
      "[42, 180] loss: 0.266\n",
      "[42, 240] loss: 0.257\n",
      "[42, 300] loss: 0.268\n",
      "[42, 360] loss: 0.276\n",
      "Epoch: 42 -> Loss: 0.369174778461\n",
      "Epoch: 42 -> Test Accuracy: 83.45\n",
      "[43, 60] loss: 0.253\n",
      "[43, 120] loss: 0.255\n",
      "[43, 180] loss: 0.261\n",
      "[43, 240] loss: 0.268\n",
      "[43, 300] loss: 0.281\n",
      "[43, 360] loss: 0.269\n",
      "Epoch: 43 -> Loss: 0.2454187572\n",
      "Epoch: 43 -> Test Accuracy: 83.12\n",
      "[44, 60] loss: 0.250\n",
      "[44, 120] loss: 0.268\n",
      "[44, 180] loss: 0.265\n",
      "[44, 240] loss: 0.258\n",
      "[44, 300] loss: 0.261\n",
      "[44, 360] loss: 0.282\n",
      "Epoch: 44 -> Loss: 0.317929685116\n",
      "Epoch: 44 -> Test Accuracy: 83.48\n",
      "[45, 60] loss: 0.249\n",
      "[45, 120] loss: 0.258\n",
      "[45, 180] loss: 0.258\n",
      "[45, 240] loss: 0.262\n",
      "[45, 300] loss: 0.273\n",
      "[45, 360] loss: 0.269\n",
      "Epoch: 45 -> Loss: 0.261962145567\n",
      "Epoch: 45 -> Test Accuracy: 83.48\n",
      "[46, 60] loss: 0.245\n",
      "[46, 120] loss: 0.249\n",
      "[46, 180] loss: 0.267\n",
      "[46, 240] loss: 0.256\n",
      "[46, 300] loss: 0.258\n",
      "[46, 360] loss: 0.275\n",
      "Epoch: 46 -> Loss: 0.194062009454\n",
      "Epoch: 46 -> Test Accuracy: 83.72\n",
      "[47, 60] loss: 0.250\n",
      "[47, 120] loss: 0.242\n",
      "[47, 180] loss: 0.251\n",
      "[47, 240] loss: 0.281\n",
      "[47, 300] loss: 0.264\n",
      "[47, 360] loss: 0.269\n",
      "Epoch: 47 -> Loss: 0.241105362773\n",
      "Epoch: 47 -> Test Accuracy: 83.36\n",
      "[48, 60] loss: 0.244\n",
      "[48, 120] loss: 0.245\n",
      "[48, 180] loss: 0.252\n",
      "[48, 240] loss: 0.270\n",
      "[48, 300] loss: 0.263\n",
      "[48, 360] loss: 0.269\n",
      "Epoch: 48 -> Loss: 0.294455975294\n",
      "Epoch: 48 -> Test Accuracy: 82.98\n",
      "[49, 60] loss: 0.245\n",
      "[49, 120] loss: 0.256\n",
      "[49, 180] loss: 0.259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49, 240] loss: 0.253\n",
      "[49, 300] loss: 0.272\n",
      "[49, 360] loss: 0.254\n",
      "Epoch: 49 -> Loss: 0.314178645611\n",
      "Epoch: 49 -> Test Accuracy: 83.47\n",
      "[50, 60] loss: 0.238\n",
      "[50, 120] loss: 0.250\n",
      "[50, 180] loss: 0.259\n",
      "[50, 240] loss: 0.256\n",
      "[50, 300] loss: 0.259\n",
      "[50, 360] loss: 0.271\n",
      "Epoch: 50 -> Loss: 0.30451965332\n",
      "Epoch: 50 -> Test Accuracy: 82.96\n",
      "[51, 60] loss: 0.238\n",
      "[51, 120] loss: 0.245\n",
      "[51, 180] loss: 0.248\n",
      "[51, 240] loss: 0.245\n",
      "[51, 300] loss: 0.269\n",
      "[51, 360] loss: 0.271\n",
      "Epoch: 51 -> Loss: 0.257234960794\n",
      "Epoch: 51 -> Test Accuracy: 82.77\n",
      "[52, 60] loss: 0.239\n",
      "[52, 120] loss: 0.244\n",
      "[52, 180] loss: 0.257\n",
      "[52, 240] loss: 0.258\n",
      "[52, 300] loss: 0.261\n",
      "[52, 360] loss: 0.267\n",
      "Epoch: 52 -> Loss: 0.26011878252\n",
      "Epoch: 52 -> Test Accuracy: 82.95\n",
      "[53, 60] loss: 0.236\n",
      "[53, 120] loss: 0.248\n",
      "[53, 180] loss: 0.266\n",
      "[53, 240] loss: 0.274\n",
      "[53, 300] loss: 0.269\n",
      "[53, 360] loss: 0.254\n",
      "Epoch: 53 -> Loss: 0.287103831768\n",
      "Epoch: 53 -> Test Accuracy: 83.44\n",
      "[54, 60] loss: 0.255\n",
      "[54, 120] loss: 0.254\n",
      "[54, 180] loss: 0.241\n",
      "[54, 240] loss: 0.237\n",
      "[54, 300] loss: 0.265\n",
      "[54, 360] loss: 0.245\n",
      "Epoch: 54 -> Loss: 0.233818203211\n",
      "Epoch: 54 -> Test Accuracy: 83.26\n",
      "[55, 60] loss: 0.237\n",
      "[55, 120] loss: 0.250\n",
      "[55, 180] loss: 0.244\n",
      "[55, 240] loss: 0.255\n",
      "[55, 300] loss: 0.270\n",
      "[55, 360] loss: 0.260\n",
      "Epoch: 55 -> Loss: 0.258498042822\n",
      "Epoch: 55 -> Test Accuracy: 83.63\n",
      "[56, 60] loss: 0.249\n",
      "[56, 120] loss: 0.235\n",
      "[56, 180] loss: 0.251\n",
      "[56, 240] loss: 0.269\n",
      "[56, 300] loss: 0.244\n",
      "[56, 360] loss: 0.258\n",
      "Epoch: 56 -> Loss: 0.306626975536\n",
      "Epoch: 56 -> Test Accuracy: 83.15\n",
      "[57, 60] loss: 0.242\n",
      "[57, 120] loss: 0.252\n",
      "[57, 180] loss: 0.244\n",
      "[57, 240] loss: 0.267\n",
      "[57, 300] loss: 0.258\n",
      "[57, 360] loss: 0.279\n",
      "Epoch: 57 -> Loss: 0.353898465633\n",
      "Epoch: 57 -> Test Accuracy: 83.22\n",
      "[58, 60] loss: 0.231\n",
      "[58, 120] loss: 0.258\n",
      "[58, 180] loss: 0.240\n",
      "[58, 240] loss: 0.255\n",
      "[58, 300] loss: 0.258\n",
      "[58, 360] loss: 0.253\n",
      "Epoch: 58 -> Loss: 0.241750210524\n",
      "Epoch: 58 -> Test Accuracy: 82.96\n",
      "[59, 60] loss: 0.239\n",
      "[59, 120] loss: 0.242\n",
      "[59, 180] loss: 0.249\n",
      "[59, 240] loss: 0.238\n",
      "[59, 300] loss: 0.248\n",
      "[59, 360] loss: 0.257\n",
      "Epoch: 59 -> Loss: 0.300862491131\n",
      "Epoch: 59 -> Test Accuracy: 83.02\n",
      "[60, 60] loss: 0.228\n",
      "[60, 120] loss: 0.242\n",
      "[60, 180] loss: 0.249\n",
      "[60, 240] loss: 0.265\n",
      "[60, 300] loss: 0.263\n",
      "[60, 360] loss: 0.244\n",
      "Epoch: 60 -> Loss: 0.234518140554\n",
      "Epoch: 60 -> Test Accuracy: 82.99\n",
      "[61, 60] loss: 0.231\n",
      "[61, 120] loss: 0.240\n",
      "[61, 180] loss: 0.239\n",
      "[61, 240] loss: 0.240\n",
      "[61, 300] loss: 0.262\n",
      "[61, 360] loss: 0.269\n",
      "Epoch: 61 -> Loss: 0.197313845158\n",
      "Epoch: 61 -> Test Accuracy: 83.3\n",
      "[62, 60] loss: 0.239\n",
      "[62, 120] loss: 0.246\n",
      "[62, 180] loss: 0.244\n",
      "[62, 240] loss: 0.259\n",
      "[62, 300] loss: 0.261\n",
      "[62, 360] loss: 0.259\n",
      "Epoch: 62 -> Loss: 0.270871698856\n",
      "Epoch: 62 -> Test Accuracy: 83.12\n",
      "[63, 60] loss: 0.229\n",
      "[63, 120] loss: 0.243\n",
      "[63, 180] loss: 0.236\n",
      "[63, 240] loss: 0.240\n",
      "[63, 300] loss: 0.268\n",
      "[63, 360] loss: 0.260\n",
      "Epoch: 63 -> Loss: 0.23283457756\n",
      "Epoch: 63 -> Test Accuracy: 83.47\n",
      "[64, 60] loss: 0.233\n",
      "[64, 120] loss: 0.226\n",
      "[64, 180] loss: 0.250\n",
      "[64, 240] loss: 0.260\n",
      "[64, 300] loss: 0.239\n",
      "[64, 360] loss: 0.253\n",
      "Epoch: 64 -> Loss: 0.253786504269\n",
      "Epoch: 64 -> Test Accuracy: 82.73\n",
      "[65, 60] loss: 0.233\n",
      "[65, 120] loss: 0.234\n",
      "[65, 180] loss: 0.244\n",
      "[65, 240] loss: 0.241\n",
      "[65, 300] loss: 0.253\n",
      "[65, 360] loss: 0.257\n",
      "Epoch: 65 -> Loss: 0.278762459755\n",
      "Epoch: 65 -> Test Accuracy: 82.67\n",
      "[66, 60] loss: 0.244\n",
      "[66, 120] loss: 0.230\n",
      "[66, 180] loss: 0.239\n",
      "[66, 240] loss: 0.257\n",
      "[66, 300] loss: 0.246\n",
      "[66, 360] loss: 0.253\n",
      "Epoch: 66 -> Loss: 0.318047434092\n",
      "Epoch: 66 -> Test Accuracy: 82.99\n",
      "[67, 60] loss: 0.225\n",
      "[67, 120] loss: 0.253\n",
      "[67, 180] loss: 0.242\n",
      "[67, 240] loss: 0.255\n",
      "[67, 300] loss: 0.242\n",
      "[67, 360] loss: 0.248\n",
      "Epoch: 67 -> Loss: 0.178489789367\n",
      "Epoch: 67 -> Test Accuracy: 82.53\n",
      "[68, 60] loss: 0.229\n",
      "[68, 120] loss: 0.228\n",
      "[68, 180] loss: 0.245\n",
      "[68, 240] loss: 0.245\n",
      "[68, 300] loss: 0.256\n",
      "[68, 360] loss: 0.257\n",
      "Epoch: 68 -> Loss: 0.144168257713\n",
      "Epoch: 68 -> Test Accuracy: 83.16\n",
      "[69, 60] loss: 0.236\n",
      "[69, 120] loss: 0.238\n",
      "[69, 180] loss: 0.230\n",
      "[69, 240] loss: 0.242\n",
      "[69, 300] loss: 0.233\n",
      "[69, 360] loss: 0.251\n",
      "Epoch: 69 -> Loss: 0.189914509654\n",
      "Epoch: 69 -> Test Accuracy: 82.77\n",
      "[70, 60] loss: 0.222\n",
      "[70, 120] loss: 0.237\n",
      "[70, 180] loss: 0.247\n",
      "[70, 240] loss: 0.242\n",
      "[70, 300] loss: 0.265\n",
      "[70, 360] loss: 0.251\n",
      "Epoch: 70 -> Loss: 0.269492030144\n",
      "Epoch: 70 -> Test Accuracy: 83.4\n",
      "[71, 60] loss: 0.211\n",
      "[71, 120] loss: 0.197\n",
      "[71, 180] loss: 0.190\n",
      "[71, 240] loss: 0.179\n",
      "[71, 300] loss: 0.187\n",
      "[71, 360] loss: 0.181\n",
      "Epoch: 71 -> Loss: 0.142958924174\n",
      "Epoch: 71 -> Test Accuracy: 84.67\n",
      "[72, 60] loss: 0.179\n",
      "[72, 120] loss: 0.172\n",
      "[72, 180] loss: 0.177\n",
      "[72, 240] loss: 0.171\n",
      "[72, 300] loss: 0.180\n",
      "[72, 360] loss: 0.181\n",
      "Epoch: 72 -> Loss: 0.0822021961212\n",
      "Epoch: 72 -> Test Accuracy: 84.5\n",
      "[73, 60] loss: 0.167\n",
      "[73, 120] loss: 0.164\n",
      "[73, 180] loss: 0.167\n",
      "[73, 240] loss: 0.160\n",
      "[73, 300] loss: 0.169\n",
      "[73, 360] loss: 0.174\n",
      "Epoch: 73 -> Loss: 0.15674136579\n",
      "Epoch: 73 -> Test Accuracy: 84.51\n",
      "[74, 60] loss: 0.169\n",
      "[74, 120] loss: 0.159\n",
      "[74, 180] loss: 0.161\n",
      "[74, 240] loss: 0.165\n",
      "[74, 300] loss: 0.157\n",
      "[74, 360] loss: 0.166\n",
      "Epoch: 74 -> Loss: 0.179432988167\n",
      "Epoch: 74 -> Test Accuracy: 84.54\n",
      "[75, 60] loss: 0.155\n",
      "[75, 120] loss: 0.162\n",
      "[75, 180] loss: 0.144\n",
      "[75, 240] loss: 0.158\n",
      "[75, 300] loss: 0.167\n",
      "[75, 360] loss: 0.157\n",
      "Epoch: 75 -> Loss: 0.189557507634\n",
      "Epoch: 75 -> Test Accuracy: 84.39\n",
      "[76, 60] loss: 0.151\n",
      "[76, 120] loss: 0.151\n",
      "[76, 180] loss: 0.160\n",
      "[76, 240] loss: 0.160\n",
      "[76, 300] loss: 0.159\n",
      "[76, 360] loss: 0.146\n",
      "Epoch: 76 -> Loss: 0.167920693755\n",
      "Epoch: 76 -> Test Accuracy: 84.5\n",
      "[77, 60] loss: 0.155\n",
      "[77, 120] loss: 0.145\n",
      "[77, 180] loss: 0.149\n",
      "[77, 240] loss: 0.151\n",
      "[77, 300] loss: 0.159\n",
      "[77, 360] loss: 0.147\n",
      "Epoch: 77 -> Loss: 0.119214072824\n",
      "Epoch: 77 -> Test Accuracy: 84.14\n",
      "[78, 60] loss: 0.139\n",
      "[78, 120] loss: 0.149\n",
      "[78, 180] loss: 0.151\n",
      "[78, 240] loss: 0.149\n",
      "[78, 300] loss: 0.155\n",
      "[78, 360] loss: 0.151\n",
      "Epoch: 78 -> Loss: 0.156333789229\n",
      "Epoch: 78 -> Test Accuracy: 84.38\n",
      "[79, 60] loss: 0.151\n",
      "[79, 120] loss: 0.145\n",
      "[79, 180] loss: 0.144\n",
      "[79, 240] loss: 0.138\n",
      "[79, 300] loss: 0.140\n",
      "[79, 360] loss: 0.145\n",
      "Epoch: 79 -> Loss: 0.150622338057\n",
      "Epoch: 79 -> Test Accuracy: 84.34\n",
      "[80, 60] loss: 0.144\n",
      "[80, 120] loss: 0.135\n",
      "[80, 180] loss: 0.137\n",
      "[80, 240] loss: 0.144\n",
      "[80, 300] loss: 0.148\n",
      "[80, 360] loss: 0.144\n",
      "Epoch: 80 -> Loss: 0.21105055511\n",
      "Epoch: 80 -> Test Accuracy: 84.29\n",
      "[81, 60] loss: 0.145\n",
      "[81, 120] loss: 0.141\n",
      "[81, 180] loss: 0.139\n",
      "[81, 240] loss: 0.135\n",
      "[81, 300] loss: 0.144\n",
      "[81, 360] loss: 0.149\n",
      "Epoch: 81 -> Loss: 0.14804688096\n",
      "Epoch: 81 -> Test Accuracy: 84.11\n",
      "[82, 60] loss: 0.136\n",
      "[82, 120] loss: 0.145\n",
      "[82, 180] loss: 0.144\n",
      "[82, 240] loss: 0.144\n",
      "[82, 300] loss: 0.138\n",
      "[82, 360] loss: 0.136\n",
      "Epoch: 82 -> Loss: 0.227236106992\n",
      "Epoch: 82 -> Test Accuracy: 84.38\n",
      "[83, 60] loss: 0.147\n",
      "[83, 120] loss: 0.138\n",
      "[83, 180] loss: 0.136\n",
      "[83, 240] loss: 0.142\n",
      "[83, 300] loss: 0.152\n",
      "[83, 360] loss: 0.142\n",
      "Epoch: 83 -> Loss: 0.0951100513339\n",
      "Epoch: 83 -> Test Accuracy: 84.65\n",
      "[84, 60] loss: 0.141\n",
      "[84, 120] loss: 0.140\n",
      "[84, 180] loss: 0.140\n",
      "[84, 240] loss: 0.140\n",
      "[84, 300] loss: 0.138\n",
      "[84, 360] loss: 0.142\n",
      "Epoch: 84 -> Loss: 0.179926872253\n",
      "Epoch: 84 -> Test Accuracy: 84.31\n",
      "[85, 60] loss: 0.127\n",
      "[85, 120] loss: 0.129\n",
      "[85, 180] loss: 0.135\n",
      "[85, 240] loss: 0.128\n",
      "[85, 300] loss: 0.140\n",
      "[85, 360] loss: 0.138\n",
      "Epoch: 85 -> Loss: 0.165187031031\n",
      "Epoch: 85 -> Test Accuracy: 84.06\n",
      "[86, 60] loss: 0.132\n",
      "[86, 120] loss: 0.128\n",
      "[86, 180] loss: 0.124\n",
      "[86, 240] loss: 0.125\n",
      "[86, 300] loss: 0.121\n",
      "[86, 360] loss: 0.119\n",
      "Epoch: 86 -> Loss: 0.205494791269\n",
      "Epoch: 86 -> Test Accuracy: 84.5\n",
      "[87, 60] loss: 0.123\n",
      "[87, 120] loss: 0.116\n",
      "[87, 180] loss: 0.121\n",
      "[87, 240] loss: 0.118\n",
      "[87, 300] loss: 0.121\n",
      "[87, 360] loss: 0.120\n",
      "Epoch: 87 -> Loss: 0.151883557439\n",
      "Epoch: 87 -> Test Accuracy: 84.48\n",
      "[88, 60] loss: 0.121\n",
      "[88, 120] loss: 0.114\n",
      "[88, 180] loss: 0.124\n",
      "[88, 240] loss: 0.121\n",
      "[88, 300] loss: 0.116\n",
      "[88, 360] loss: 0.117\n",
      "Epoch: 88 -> Loss: 0.103993535042\n",
      "Epoch: 88 -> Test Accuracy: 84.54\n",
      "[89, 60] loss: 0.123\n",
      "[89, 120] loss: 0.117\n",
      "[89, 180] loss: 0.126\n",
      "[89, 240] loss: 0.118\n",
      "[89, 300] loss: 0.113\n",
      "[89, 360] loss: 0.117\n",
      "Epoch: 89 -> Loss: 0.0811484009027\n",
      "Epoch: 89 -> Test Accuracy: 84.52\n",
      "[90, 60] loss: 0.119\n",
      "[90, 120] loss: 0.125\n",
      "[90, 180] loss: 0.117\n",
      "[90, 240] loss: 0.116\n",
      "[90, 300] loss: 0.114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90, 360] loss: 0.120\n",
      "Epoch: 90 -> Loss: 0.157040223479\n",
      "Epoch: 90 -> Test Accuracy: 84.47\n",
      "[91, 60] loss: 0.111\n",
      "[91, 120] loss: 0.122\n",
      "[91, 180] loss: 0.115\n",
      "[91, 240] loss: 0.112\n",
      "[91, 300] loss: 0.117\n",
      "[91, 360] loss: 0.118\n",
      "Epoch: 91 -> Loss: 0.1085222736\n",
      "Epoch: 91 -> Test Accuracy: 84.53\n",
      "[92, 60] loss: 0.112\n",
      "[92, 120] loss: 0.120\n",
      "[92, 180] loss: 0.111\n",
      "[92, 240] loss: 0.119\n",
      "[92, 300] loss: 0.113\n",
      "[92, 360] loss: 0.120\n",
      "Epoch: 92 -> Loss: 0.0777912735939\n",
      "Epoch: 92 -> Test Accuracy: 84.36\n",
      "[93, 60] loss: 0.111\n",
      "[93, 120] loss: 0.117\n",
      "[93, 180] loss: 0.118\n",
      "[93, 240] loss: 0.118\n",
      "[93, 300] loss: 0.115\n",
      "[93, 360] loss: 0.118\n",
      "Epoch: 93 -> Loss: 0.151229128242\n",
      "Epoch: 93 -> Test Accuracy: 84.71\n",
      "[94, 60] loss: 0.118\n",
      "[94, 120] loss: 0.116\n",
      "[94, 180] loss: 0.113\n",
      "[94, 240] loss: 0.117\n",
      "[94, 300] loss: 0.113\n",
      "[94, 360] loss: 0.111\n",
      "Epoch: 94 -> Loss: 0.129433631897\n",
      "Epoch: 94 -> Test Accuracy: 84.66\n",
      "[95, 60] loss: 0.114\n",
      "[95, 120] loss: 0.112\n",
      "[95, 180] loss: 0.111\n",
      "[95, 240] loss: 0.115\n",
      "[95, 300] loss: 0.108\n",
      "[95, 360] loss: 0.122\n",
      "Epoch: 95 -> Loss: 0.09557749331\n",
      "Epoch: 95 -> Test Accuracy: 84.55\n",
      "[96, 60] loss: 0.106\n",
      "[96, 120] loss: 0.117\n",
      "[96, 180] loss: 0.118\n",
      "[96, 240] loss: 0.110\n",
      "[96, 300] loss: 0.108\n",
      "[96, 360] loss: 0.117\n",
      "Epoch: 96 -> Loss: 0.153125151992\n",
      "Epoch: 96 -> Test Accuracy: 84.64\n",
      "[97, 60] loss: 0.110\n",
      "[97, 120] loss: 0.115\n",
      "[97, 180] loss: 0.121\n",
      "[97, 240] loss: 0.113\n",
      "[97, 300] loss: 0.107\n",
      "[97, 360] loss: 0.114\n",
      "Epoch: 97 -> Loss: 0.0744722038507\n",
      "Epoch: 97 -> Test Accuracy: 84.63\n",
      "[98, 60] loss: 0.109\n",
      "[98, 120] loss: 0.111\n",
      "[98, 180] loss: 0.115\n",
      "[98, 240] loss: 0.107\n",
      "[98, 300] loss: 0.109\n",
      "[98, 360] loss: 0.111\n",
      "Epoch: 98 -> Loss: 0.345596015453\n",
      "Epoch: 98 -> Test Accuracy: 84.77\n",
      "[99, 60] loss: 0.109\n",
      "[99, 120] loss: 0.115\n",
      "[99, 180] loss: 0.115\n",
      "[99, 240] loss: 0.112\n",
      "[99, 300] loss: 0.104\n",
      "[99, 360] loss: 0.111\n",
      "Epoch: 99 -> Loss: 0.166036009789\n",
      "Epoch: 99 -> Test Accuracy: 84.57\n",
      "[100, 60] loss: 0.104\n",
      "[100, 120] loss: 0.111\n",
      "[100, 180] loss: 0.107\n",
      "[100, 240] loss: 0.121\n",
      "[100, 300] loss: 0.108\n",
      "[100, 360] loss: 0.110\n",
      "Epoch: 100 -> Loss: 0.110268115997\n",
      "Epoch: 100 -> Test Accuracy: 84.59\n",
      "Finished Training\n",
      "[1, 60] loss: 1.473\n",
      "[1, 120] loss: 1.176\n",
      "[1, 180] loss: 1.104\n",
      "[1, 240] loss: 1.080\n",
      "[1, 300] loss: 1.031\n",
      "[1, 360] loss: 1.027\n",
      "Epoch: 1 -> Loss: 0.921677291393\n",
      "Epoch: 1 -> Test Accuracy: 58.68\n",
      "[2, 60] loss: 0.990\n",
      "[2, 120] loss: 1.002\n",
      "[2, 180] loss: 0.980\n",
      "[2, 240] loss: 0.968\n",
      "[2, 300] loss: 0.970\n",
      "[2, 360] loss: 0.969\n",
      "Epoch: 2 -> Loss: 1.00528764725\n",
      "Epoch: 2 -> Test Accuracy: 61.16\n",
      "[3, 60] loss: 0.949\n",
      "[3, 120] loss: 0.955\n",
      "[3, 180] loss: 0.929\n",
      "[3, 240] loss: 0.926\n",
      "[3, 300] loss: 0.927\n",
      "[3, 360] loss: 0.936\n",
      "Epoch: 3 -> Loss: 1.03852248192\n",
      "Epoch: 3 -> Test Accuracy: 60.82\n",
      "[4, 60] loss: 0.927\n",
      "[4, 120] loss: 0.893\n",
      "[4, 180] loss: 0.929\n",
      "[4, 240] loss: 0.909\n",
      "[4, 300] loss: 0.906\n",
      "[4, 360] loss: 0.912\n",
      "Epoch: 4 -> Loss: 0.965666294098\n",
      "Epoch: 4 -> Test Accuracy: 61.26\n",
      "[5, 60] loss: 0.894\n",
      "[5, 120] loss: 0.902\n",
      "[5, 180] loss: 0.892\n",
      "[5, 240] loss: 0.898\n",
      "[5, 300] loss: 0.908\n",
      "[5, 360] loss: 0.919\n",
      "Epoch: 5 -> Loss: 0.868390858173\n",
      "Epoch: 5 -> Test Accuracy: 60.57\n",
      "[6, 60] loss: 0.894\n",
      "[6, 120] loss: 0.908\n",
      "[6, 180] loss: 0.895\n",
      "[6, 240] loss: 0.889\n",
      "[6, 300] loss: 0.869\n",
      "[6, 360] loss: 0.898\n",
      "Epoch: 6 -> Loss: 0.729511380196\n",
      "Epoch: 6 -> Test Accuracy: 60.95\n",
      "[7, 60] loss: 0.893\n",
      "[7, 120] loss: 0.880\n",
      "[7, 180] loss: 0.905\n",
      "[7, 240] loss: 0.905\n",
      "[7, 300] loss: 0.886\n",
      "[7, 360] loss: 0.864\n",
      "Epoch: 7 -> Loss: 0.820765018463\n",
      "Epoch: 7 -> Test Accuracy: 62.0\n",
      "[8, 60] loss: 0.872\n",
      "[8, 120] loss: 0.888\n",
      "[8, 180] loss: 0.879\n",
      "[8, 240] loss: 0.884\n",
      "[8, 300] loss: 0.879\n",
      "[8, 360] loss: 0.868\n",
      "Epoch: 8 -> Loss: 0.940119624138\n",
      "Epoch: 8 -> Test Accuracy: 62.93\n",
      "[9, 60] loss: 0.889\n",
      "[9, 120] loss: 0.865\n",
      "[9, 180] loss: 0.866\n",
      "[9, 240] loss: 0.855\n",
      "[9, 300] loss: 0.880\n",
      "[9, 360] loss: 0.891\n",
      "Epoch: 9 -> Loss: 0.972784340382\n",
      "Epoch: 9 -> Test Accuracy: 63.02\n",
      "[10, 60] loss: 0.864\n",
      "[10, 120] loss: 0.859\n",
      "[10, 180] loss: 0.858\n",
      "[10, 240] loss: 0.879\n",
      "[10, 300] loss: 0.849\n",
      "[10, 360] loss: 0.883\n",
      "Epoch: 10 -> Loss: 0.817330062389\n",
      "Epoch: 10 -> Test Accuracy: 63.53\n",
      "[11, 60] loss: 0.868\n",
      "[11, 120] loss: 0.866\n",
      "[11, 180] loss: 0.861\n",
      "[11, 240] loss: 0.847\n",
      "[11, 300] loss: 0.865\n",
      "[11, 360] loss: 0.867\n",
      "Epoch: 11 -> Loss: 0.752104640007\n",
      "Epoch: 11 -> Test Accuracy: 62.24\n",
      "[12, 60] loss: 0.842\n",
      "[12, 120] loss: 0.833\n",
      "[12, 180] loss: 0.870\n",
      "[12, 240] loss: 0.856\n",
      "[12, 300] loss: 0.878\n",
      "[12, 360] loss: 0.871\n",
      "Epoch: 12 -> Loss: 0.801067948341\n",
      "Epoch: 12 -> Test Accuracy: 64.44\n",
      "[13, 60] loss: 0.858\n",
      "[13, 120] loss: 0.860\n",
      "[13, 180] loss: 0.873\n",
      "[13, 240] loss: 0.857\n",
      "[13, 300] loss: 0.834\n",
      "[13, 360] loss: 0.846\n",
      "Epoch: 13 -> Loss: 0.660011947155\n",
      "Epoch: 13 -> Test Accuracy: 62.8\n",
      "[14, 60] loss: 0.853\n",
      "[14, 120] loss: 0.848\n",
      "[14, 180] loss: 0.857\n",
      "[14, 240] loss: 0.885\n",
      "[14, 300] loss: 0.846\n",
      "[14, 360] loss: 0.845\n",
      "Epoch: 14 -> Loss: 0.768778204918\n",
      "Epoch: 14 -> Test Accuracy: 63.81\n",
      "[15, 60] loss: 0.847\n",
      "[15, 120] loss: 0.845\n",
      "[15, 180] loss: 0.864\n",
      "[15, 240] loss: 0.859\n",
      "[15, 300] loss: 0.858\n",
      "[15, 360] loss: 0.865\n",
      "Epoch: 15 -> Loss: 0.855344295502\n",
      "Epoch: 15 -> Test Accuracy: 63.23\n",
      "[16, 60] loss: 0.853\n",
      "[16, 120] loss: 0.849\n",
      "[16, 180] loss: 0.860\n",
      "[16, 240] loss: 0.854\n",
      "[16, 300] loss: 0.855\n",
      "[16, 360] loss: 0.809\n",
      "Epoch: 16 -> Loss: 0.79472887516\n",
      "Epoch: 16 -> Test Accuracy: 63.23\n",
      "[17, 60] loss: 0.846\n",
      "[17, 120] loss: 0.839\n",
      "[17, 180] loss: 0.858\n",
      "[17, 240] loss: 0.871\n",
      "[17, 300] loss: 0.862\n",
      "[17, 360] loss: 0.850\n",
      "Epoch: 17 -> Loss: 1.02628350258\n",
      "Epoch: 17 -> Test Accuracy: 64.72\n",
      "[18, 60] loss: 0.846\n",
      "[18, 120] loss: 0.839\n",
      "[18, 180] loss: 0.845\n",
      "[18, 240] loss: 0.822\n",
      "[18, 300] loss: 0.864\n",
      "[18, 360] loss: 0.872\n",
      "Epoch: 18 -> Loss: 0.85580521822\n",
      "Epoch: 18 -> Test Accuracy: 62.53\n",
      "[19, 60] loss: 0.842\n",
      "[19, 120] loss: 0.832\n",
      "[19, 180] loss: 0.840\n",
      "[19, 240] loss: 0.863\n",
      "[19, 300] loss: 0.854\n",
      "[19, 360] loss: 0.827\n",
      "Epoch: 19 -> Loss: 0.862973332405\n",
      "Epoch: 19 -> Test Accuracy: 62.84\n",
      "[20, 60] loss: 0.838\n",
      "[20, 120] loss: 0.864\n",
      "[20, 180] loss: 0.839\n",
      "[20, 240] loss: 0.837\n",
      "[20, 300] loss: 0.848\n",
      "[20, 360] loss: 0.855\n",
      "Epoch: 20 -> Loss: 0.835193157196\n",
      "Epoch: 20 -> Test Accuracy: 63.82\n",
      "[21, 60] loss: 0.836\n",
      "[21, 120] loss: 0.835\n",
      "[21, 180] loss: 0.833\n",
      "[21, 240] loss: 0.844\n",
      "[21, 300] loss: 0.854\n",
      "[21, 360] loss: 0.855\n",
      "Epoch: 21 -> Loss: 0.908996284008\n",
      "Epoch: 21 -> Test Accuracy: 63.08\n",
      "[22, 60] loss: 0.831\n",
      "[22, 120] loss: 0.839\n",
      "[22, 180] loss: 0.854\n",
      "[22, 240] loss: 0.839\n",
      "[22, 300] loss: 0.834\n",
      "[22, 360] loss: 0.852\n",
      "Epoch: 22 -> Loss: 1.10211753845\n",
      "Epoch: 22 -> Test Accuracy: 64.0\n",
      "[23, 60] loss: 0.830\n",
      "[23, 120] loss: 0.846\n",
      "[23, 180] loss: 0.845\n",
      "[23, 240] loss: 0.841\n",
      "[23, 300] loss: 0.837\n",
      "[23, 360] loss: 0.807\n",
      "Epoch: 23 -> Loss: 1.11137163639\n",
      "Epoch: 23 -> Test Accuracy: 63.66\n",
      "[24, 60] loss: 0.827\n",
      "[24, 120] loss: 0.831\n",
      "[24, 180] loss: 0.848\n",
      "[24, 240] loss: 0.864\n",
      "[24, 300] loss: 0.834\n",
      "[24, 360] loss: 0.834\n",
      "Epoch: 24 -> Loss: 0.802790641785\n",
      "Epoch: 24 -> Test Accuracy: 63.15\n",
      "[25, 60] loss: 0.851\n",
      "[25, 120] loss: 0.836\n",
      "[25, 180] loss: 0.813\n",
      "[25, 240] loss: 0.836\n",
      "[25, 300] loss: 0.831\n",
      "[25, 360] loss: 0.837\n",
      "Epoch: 25 -> Loss: 0.778663754463\n",
      "Epoch: 25 -> Test Accuracy: 64.46\n",
      "[26, 60] loss: 0.843\n",
      "[26, 120] loss: 0.836\n",
      "[26, 180] loss: 0.831\n",
      "[26, 240] loss: 0.843\n",
      "[26, 300] loss: 0.860\n",
      "[26, 360] loss: 0.840\n",
      "Epoch: 26 -> Loss: 0.889099776745\n",
      "Epoch: 26 -> Test Accuracy: 64.1\n",
      "[27, 60] loss: 0.823\n",
      "[27, 120] loss: 0.853\n",
      "[27, 180] loss: 0.844\n",
      "[27, 240] loss: 0.836\n",
      "[27, 300] loss: 0.845\n",
      "[27, 360] loss: 0.857\n",
      "Epoch: 27 -> Loss: 0.855278193951\n",
      "Epoch: 27 -> Test Accuracy: 63.6\n",
      "[28, 60] loss: 0.820\n",
      "[28, 120] loss: 0.842\n",
      "[28, 180] loss: 0.846\n",
      "[28, 240] loss: 0.837\n",
      "[28, 300] loss: 0.824\n",
      "[28, 360] loss: 0.850\n",
      "Epoch: 28 -> Loss: 0.986415982246\n",
      "Epoch: 28 -> Test Accuracy: 64.21\n",
      "[29, 60] loss: 0.844\n",
      "[29, 120] loss: 0.821\n",
      "[29, 180] loss: 0.841\n",
      "[29, 240] loss: 0.842\n",
      "[29, 300] loss: 0.844\n",
      "[29, 360] loss: 0.828\n",
      "Epoch: 29 -> Loss: 0.842501938343\n",
      "Epoch: 29 -> Test Accuracy: 64.4\n",
      "[30, 60] loss: 0.841\n",
      "[30, 120] loss: 0.823\n",
      "[30, 180] loss: 0.839\n",
      "[30, 240] loss: 0.833\n",
      "[30, 300] loss: 0.834\n",
      "[30, 360] loss: 0.833\n",
      "Epoch: 30 -> Loss: 1.02365756035\n",
      "Epoch: 30 -> Test Accuracy: 64.39\n",
      "[31, 60] loss: 0.838\n",
      "[31, 120] loss: 0.841\n",
      "[31, 180] loss: 0.836\n",
      "[31, 240] loss: 0.831\n",
      "[31, 300] loss: 0.817\n",
      "[31, 360] loss: 0.851\n",
      "Epoch: 31 -> Loss: 1.0449244976\n",
      "Epoch: 31 -> Test Accuracy: 64.84\n",
      "[32, 60] loss: 0.811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 120] loss: 0.845\n",
      "[32, 180] loss: 0.833\n",
      "[32, 240] loss: 0.840\n",
      "[32, 300] loss: 0.838\n",
      "[32, 360] loss: 0.856\n",
      "Epoch: 32 -> Loss: 0.867956757545\n",
      "Epoch: 32 -> Test Accuracy: 64.03\n",
      "[33, 60] loss: 0.844\n",
      "[33, 120] loss: 0.818\n",
      "[33, 180] loss: 0.856\n",
      "[33, 240] loss: 0.823\n",
      "[33, 300] loss: 0.820\n",
      "[33, 360] loss: 0.848\n",
      "Epoch: 33 -> Loss: 0.693422138691\n",
      "Epoch: 33 -> Test Accuracy: 64.79\n",
      "[34, 60] loss: 0.839\n",
      "[34, 120] loss: 0.846\n",
      "[34, 180] loss: 0.824\n",
      "[34, 240] loss: 0.835\n",
      "[34, 300] loss: 0.849\n",
      "[34, 360] loss: 0.818\n",
      "Epoch: 34 -> Loss: 0.751186430454\n",
      "Epoch: 34 -> Test Accuracy: 64.56\n",
      "[35, 60] loss: 0.836\n",
      "[35, 120] loss: 0.831\n",
      "[35, 180] loss: 0.826\n",
      "[35, 240] loss: 0.836\n",
      "[35, 300] loss: 0.839\n",
      "[35, 360] loss: 0.855\n",
      "Epoch: 35 -> Loss: 1.16005349159\n",
      "Epoch: 35 -> Test Accuracy: 64.56\n",
      "[36, 60] loss: 0.771\n",
      "[36, 120] loss: 0.740\n",
      "[36, 180] loss: 0.759\n",
      "[36, 240] loss: 0.737\n",
      "[36, 300] loss: 0.731\n",
      "[36, 360] loss: 0.754\n",
      "Epoch: 36 -> Loss: 0.740938663483\n",
      "Epoch: 36 -> Test Accuracy: 68.36\n",
      "[37, 60] loss: 0.739\n",
      "[37, 120] loss: 0.705\n",
      "[37, 180] loss: 0.718\n",
      "[37, 240] loss: 0.740\n",
      "[37, 300] loss: 0.732\n",
      "[37, 360] loss: 0.690\n",
      "Epoch: 37 -> Loss: 0.709369897842\n",
      "Epoch: 37 -> Test Accuracy: 67.97\n",
      "[38, 60] loss: 0.712\n",
      "[38, 120] loss: 0.713\n",
      "[38, 180] loss: 0.723\n",
      "[38, 240] loss: 0.715\n",
      "[38, 300] loss: 0.709\n",
      "[38, 360] loss: 0.723\n",
      "Epoch: 38 -> Loss: 0.784338474274\n",
      "Epoch: 38 -> Test Accuracy: 68.46\n",
      "[39, 60] loss: 0.723\n",
      "[39, 120] loss: 0.703\n",
      "[39, 180] loss: 0.703\n",
      "[39, 240] loss: 0.713\n",
      "[39, 300] loss: 0.721\n",
      "[39, 360] loss: 0.710\n",
      "Epoch: 39 -> Loss: 0.664344489574\n",
      "Epoch: 39 -> Test Accuracy: 68.7\n",
      "[40, 60] loss: 0.713\n",
      "[40, 120] loss: 0.724\n",
      "[40, 180] loss: 0.693\n",
      "[40, 240] loss: 0.703\n",
      "[40, 300] loss: 0.728\n",
      "[40, 360] loss: 0.709\n",
      "Epoch: 40 -> Loss: 0.643475711346\n",
      "Epoch: 40 -> Test Accuracy: 68.33\n",
      "[41, 60] loss: 0.710\n",
      "[41, 120] loss: 0.719\n",
      "[41, 180] loss: 0.710\n",
      "[41, 240] loss: 0.711\n",
      "[41, 300] loss: 0.707\n",
      "[41, 360] loss: 0.717\n",
      "Epoch: 41 -> Loss: 0.790218830109\n",
      "Epoch: 41 -> Test Accuracy: 68.12\n",
      "[42, 60] loss: 0.689\n",
      "[42, 120] loss: 0.699\n",
      "[42, 180] loss: 0.696\n",
      "[42, 240] loss: 0.707\n",
      "[42, 300] loss: 0.707\n",
      "[42, 360] loss: 0.710\n",
      "Epoch: 42 -> Loss: 0.640739619732\n",
      "Epoch: 42 -> Test Accuracy: 68.33\n",
      "[43, 60] loss: 0.703\n",
      "[43, 120] loss: 0.713\n",
      "[43, 180] loss: 0.717\n",
      "[43, 240] loss: 0.691\n",
      "[43, 300] loss: 0.697\n",
      "[43, 360] loss: 0.712\n",
      "Epoch: 43 -> Loss: 0.824279427528\n",
      "Epoch: 43 -> Test Accuracy: 68.21\n",
      "[44, 60] loss: 0.688\n",
      "[44, 120] loss: 0.681\n",
      "[44, 180] loss: 0.708\n",
      "[44, 240] loss: 0.712\n",
      "[44, 300] loss: 0.709\n",
      "[44, 360] loss: 0.718\n",
      "Epoch: 44 -> Loss: 0.59397238493\n",
      "Epoch: 44 -> Test Accuracy: 68.39\n",
      "[45, 60] loss: 0.705\n",
      "[45, 120] loss: 0.702\n",
      "[45, 180] loss: 0.711\n",
      "[45, 240] loss: 0.695\n",
      "[45, 300] loss: 0.705\n",
      "[45, 360] loss: 0.706\n",
      "Epoch: 45 -> Loss: 0.864451229572\n",
      "Epoch: 45 -> Test Accuracy: 68.51\n",
      "[46, 60] loss: 0.709\n",
      "[46, 120] loss: 0.709\n",
      "[46, 180] loss: 0.700\n",
      "[46, 240] loss: 0.705\n",
      "[46, 300] loss: 0.709\n",
      "[46, 360] loss: 0.717\n",
      "Epoch: 46 -> Loss: 0.756406128407\n",
      "Epoch: 46 -> Test Accuracy: 67.88\n",
      "[47, 60] loss: 0.675\n",
      "[47, 120] loss: 0.718\n",
      "[47, 180] loss: 0.709\n",
      "[47, 240] loss: 0.726\n",
      "[47, 300] loss: 0.705\n",
      "[47, 360] loss: 0.719\n",
      "Epoch: 47 -> Loss: 0.628019571304\n",
      "Epoch: 47 -> Test Accuracy: 69.1\n",
      "[48, 60] loss: 0.712\n",
      "[48, 120] loss: 0.715\n",
      "[48, 180] loss: 0.713\n",
      "[48, 240] loss: 0.729\n",
      "[48, 300] loss: 0.686\n",
      "[48, 360] loss: 0.691\n",
      "Epoch: 48 -> Loss: 0.606272161007\n",
      "Epoch: 48 -> Test Accuracy: 68.82\n",
      "[49, 60] loss: 0.693\n",
      "[49, 120] loss: 0.702\n",
      "[49, 180] loss: 0.697\n",
      "[49, 240] loss: 0.723\n",
      "[49, 300] loss: 0.704\n",
      "[49, 360] loss: 0.704\n",
      "Epoch: 49 -> Loss: 0.684184849262\n",
      "Epoch: 49 -> Test Accuracy: 68.77\n",
      "[50, 60] loss: 0.704\n",
      "[50, 120] loss: 0.695\n",
      "[50, 180] loss: 0.703\n",
      "[50, 240] loss: 0.714\n",
      "[50, 300] loss: 0.689\n",
      "[50, 360] loss: 0.714\n",
      "Epoch: 50 -> Loss: 0.705642521381\n",
      "Epoch: 50 -> Test Accuracy: 68.98\n",
      "[51, 60] loss: 0.696\n",
      "[51, 120] loss: 0.689\n",
      "[51, 180] loss: 0.699\n",
      "[51, 240] loss: 0.715\n",
      "[51, 300] loss: 0.712\n",
      "[51, 360] loss: 0.723\n",
      "Epoch: 51 -> Loss: 0.65057528019\n",
      "Epoch: 51 -> Test Accuracy: 68.8\n",
      "[52, 60] loss: 0.692\n",
      "[52, 120] loss: 0.708\n",
      "[52, 180] loss: 0.706\n",
      "[52, 240] loss: 0.701\n",
      "[52, 300] loss: 0.708\n",
      "[52, 360] loss: 0.702\n",
      "Epoch: 52 -> Loss: 0.763293862343\n",
      "Epoch: 52 -> Test Accuracy: 69.05\n",
      "[53, 60] loss: 0.696\n",
      "[53, 120] loss: 0.705\n",
      "[53, 180] loss: 0.715\n",
      "[53, 240] loss: 0.722\n",
      "[53, 300] loss: 0.702\n",
      "[53, 360] loss: 0.704\n",
      "Epoch: 53 -> Loss: 0.662967383862\n",
      "Epoch: 53 -> Test Accuracy: 69.07\n",
      "[54, 60] loss: 0.685\n",
      "[54, 120] loss: 0.710\n",
      "[54, 180] loss: 0.711\n",
      "[54, 240] loss: 0.693\n",
      "[54, 300] loss: 0.705\n",
      "[54, 360] loss: 0.694\n",
      "Epoch: 54 -> Loss: 0.614667236805\n",
      "Epoch: 54 -> Test Accuracy: 68.82\n",
      "[55, 60] loss: 0.704\n",
      "[55, 120] loss: 0.688\n",
      "[55, 180] loss: 0.704\n",
      "[55, 240] loss: 0.701\n",
      "[55, 300] loss: 0.712\n",
      "[55, 360] loss: 0.709\n",
      "Epoch: 55 -> Loss: 0.713869333267\n",
      "Epoch: 55 -> Test Accuracy: 68.33\n",
      "[56, 60] loss: 0.700\n",
      "[56, 120] loss: 0.717\n",
      "[56, 180] loss: 0.693\n",
      "[56, 240] loss: 0.698\n",
      "[56, 300] loss: 0.686\n",
      "[56, 360] loss: 0.704\n",
      "Epoch: 56 -> Loss: 0.687046706676\n",
      "Epoch: 56 -> Test Accuracy: 68.84\n",
      "[57, 60] loss: 0.686\n",
      "[57, 120] loss: 0.690\n",
      "[57, 180] loss: 0.692\n",
      "[57, 240] loss: 0.712\n",
      "[57, 300] loss: 0.712\n",
      "[57, 360] loss: 0.697\n",
      "Epoch: 57 -> Loss: 0.713340759277\n",
      "Epoch: 57 -> Test Accuracy: 68.51\n",
      "[58, 60] loss: 0.694\n",
      "[58, 120] loss: 0.706\n",
      "[58, 180] loss: 0.687\n",
      "[58, 240] loss: 0.702\n",
      "[58, 300] loss: 0.714\n",
      "[58, 360] loss: 0.705\n",
      "Epoch: 58 -> Loss: 0.849283576012\n",
      "Epoch: 58 -> Test Accuracy: 68.92\n",
      "[59, 60] loss: 0.704\n",
      "[59, 120] loss: 0.704\n",
      "[59, 180] loss: 0.704\n",
      "[59, 240] loss: 0.685\n",
      "[59, 300] loss: 0.695\n",
      "[59, 360] loss: 0.716\n",
      "Epoch: 59 -> Loss: 0.690793335438\n",
      "Epoch: 59 -> Test Accuracy: 67.99\n",
      "[60, 60] loss: 0.693\n",
      "[60, 120] loss: 0.712\n",
      "[60, 180] loss: 0.686\n",
      "[60, 240] loss: 0.703\n",
      "[60, 300] loss: 0.681\n",
      "[60, 360] loss: 0.704\n",
      "Epoch: 60 -> Loss: 0.802394688129\n",
      "Epoch: 60 -> Test Accuracy: 67.63\n",
      "[61, 60] loss: 0.687\n",
      "[61, 120] loss: 0.688\n",
      "[61, 180] loss: 0.688\n",
      "[61, 240] loss: 0.720\n",
      "[61, 300] loss: 0.717\n",
      "[61, 360] loss: 0.701\n",
      "Epoch: 61 -> Loss: 0.576467096806\n",
      "Epoch: 61 -> Test Accuracy: 68.9\n",
      "[62, 60] loss: 0.685\n",
      "[62, 120] loss: 0.697\n",
      "[62, 180] loss: 0.715\n",
      "[62, 240] loss: 0.710\n",
      "[62, 300] loss: 0.713\n",
      "[62, 360] loss: 0.693\n",
      "Epoch: 62 -> Loss: 0.682661652565\n",
      "Epoch: 62 -> Test Accuracy: 67.98\n",
      "[63, 60] loss: 0.693\n",
      "[63, 120] loss: 0.687\n",
      "[63, 180] loss: 0.704\n",
      "[63, 240] loss: 0.700\n",
      "[63, 300] loss: 0.701\n",
      "[63, 360] loss: 0.699\n",
      "Epoch: 63 -> Loss: 0.655918240547\n",
      "Epoch: 63 -> Test Accuracy: 68.03\n",
      "[64, 60] loss: 0.687\n",
      "[64, 120] loss: 0.695\n",
      "[64, 180] loss: 0.691\n",
      "[64, 240] loss: 0.701\n",
      "[64, 300] loss: 0.705\n",
      "[64, 360] loss: 0.711\n",
      "Epoch: 64 -> Loss: 0.537318468094\n",
      "Epoch: 64 -> Test Accuracy: 68.43\n",
      "[65, 60] loss: 0.696\n",
      "[65, 120] loss: 0.682\n",
      "[65, 180] loss: 0.705\n",
      "[65, 240] loss: 0.702\n",
      "[65, 300] loss: 0.697\n",
      "[65, 360] loss: 0.710\n",
      "Epoch: 65 -> Loss: 0.598965525627\n",
      "Epoch: 65 -> Test Accuracy: 68.1\n",
      "[66, 60] loss: 0.689\n",
      "[66, 120] loss: 0.691\n",
      "[66, 180] loss: 0.709\n",
      "[66, 240] loss: 0.712\n",
      "[66, 300] loss: 0.687\n",
      "[66, 360] loss: 0.708\n",
      "Epoch: 66 -> Loss: 0.699998497963\n",
      "Epoch: 66 -> Test Accuracy: 68.71\n",
      "[67, 60] loss: 0.695\n",
      "[67, 120] loss: 0.696\n",
      "[67, 180] loss: 0.711\n",
      "[67, 240] loss: 0.694\n",
      "[67, 300] loss: 0.682\n",
      "[67, 360] loss: 0.718\n",
      "Epoch: 67 -> Loss: 0.806256592274\n",
      "Epoch: 67 -> Test Accuracy: 67.91\n",
      "[68, 60] loss: 0.702\n",
      "[68, 120] loss: 0.691\n",
      "[68, 180] loss: 0.703\n",
      "[68, 240] loss: 0.686\n",
      "[68, 300] loss: 0.713\n",
      "[68, 360] loss: 0.681\n",
      "Epoch: 68 -> Loss: 0.68614345789\n",
      "Epoch: 68 -> Test Accuracy: 68.55\n",
      "[69, 60] loss: 0.694\n",
      "[69, 120] loss: 0.699\n",
      "[69, 180] loss: 0.676\n",
      "[69, 240] loss: 0.711\n",
      "[69, 300] loss: 0.688\n",
      "[69, 360] loss: 0.716\n",
      "Epoch: 69 -> Loss: 0.706453323364\n",
      "Epoch: 69 -> Test Accuracy: 68.43\n",
      "[70, 60] loss: 0.713\n",
      "[70, 120] loss: 0.700\n",
      "[70, 180] loss: 0.696\n",
      "[70, 240] loss: 0.705\n",
      "[70, 300] loss: 0.704\n",
      "[70, 360] loss: 0.682\n",
      "Epoch: 70 -> Loss: 0.747438788414\n",
      "Epoch: 70 -> Test Accuracy: 68.77\n",
      "[71, 60] loss: 0.676\n",
      "[71, 120] loss: 0.660\n",
      "[71, 180] loss: 0.637\n",
      "[71, 240] loss: 0.630\n",
      "[71, 300] loss: 0.644\n",
      "[71, 360] loss: 0.627\n",
      "Epoch: 71 -> Loss: 0.536457598209\n",
      "Epoch: 71 -> Test Accuracy: 70.59\n",
      "[72, 60] loss: 0.629\n",
      "[72, 120] loss: 0.642\n",
      "[72, 180] loss: 0.629\n",
      "[72, 240] loss: 0.633\n",
      "[72, 300] loss: 0.624\n",
      "[72, 360] loss: 0.612\n",
      "Epoch: 72 -> Loss: 0.562565207481\n",
      "Epoch: 72 -> Test Accuracy: 70.91\n",
      "[73, 60] loss: 0.611\n",
      "[73, 120] loss: 0.621\n",
      "[73, 180] loss: 0.623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73, 240] loss: 0.633\n",
      "[73, 300] loss: 0.631\n",
      "[73, 360] loss: 0.611\n",
      "Epoch: 73 -> Loss: 0.559405624866\n",
      "Epoch: 73 -> Test Accuracy: 70.45\n",
      "[74, 60] loss: 0.626\n",
      "[74, 120] loss: 0.612\n",
      "[74, 180] loss: 0.601\n",
      "[74, 240] loss: 0.608\n",
      "[74, 300] loss: 0.622\n",
      "[74, 360] loss: 0.619\n",
      "Epoch: 74 -> Loss: 0.806261837482\n",
      "Epoch: 74 -> Test Accuracy: 71.1\n",
      "[75, 60] loss: 0.600\n",
      "[75, 120] loss: 0.605\n",
      "[75, 180] loss: 0.628\n",
      "[75, 240] loss: 0.624\n",
      "[75, 300] loss: 0.600\n",
      "[75, 360] loss: 0.616\n",
      "Epoch: 75 -> Loss: 0.652823030949\n",
      "Epoch: 75 -> Test Accuracy: 70.89\n",
      "[76, 60] loss: 0.615\n",
      "[76, 120] loss: 0.622\n",
      "[76, 180] loss: 0.627\n",
      "[76, 240] loss: 0.606\n",
      "[76, 300] loss: 0.628\n",
      "[76, 360] loss: 0.600\n",
      "Epoch: 76 -> Loss: 0.598550617695\n",
      "Epoch: 76 -> Test Accuracy: 71.2\n",
      "[77, 60] loss: 0.602\n",
      "[77, 120] loss: 0.603\n",
      "[77, 180] loss: 0.632\n",
      "[77, 240] loss: 0.611\n",
      "[77, 300] loss: 0.612\n",
      "[77, 360] loss: 0.611\n",
      "Epoch: 77 -> Loss: 0.556010365486\n",
      "Epoch: 77 -> Test Accuracy: 71.33\n",
      "[78, 60] loss: 0.611\n",
      "[78, 120] loss: 0.614\n",
      "[78, 180] loss: 0.631\n",
      "[78, 240] loss: 0.600\n",
      "[78, 300] loss: 0.610\n",
      "[78, 360] loss: 0.623\n",
      "Epoch: 78 -> Loss: 0.522729933262\n",
      "Epoch: 78 -> Test Accuracy: 70.85\n",
      "[79, 60] loss: 0.595\n",
      "[79, 120] loss: 0.617\n",
      "[79, 180] loss: 0.602\n",
      "[79, 240] loss: 0.610\n",
      "[79, 300] loss: 0.609\n",
      "[79, 360] loss: 0.616\n",
      "Epoch: 79 -> Loss: 0.599903225899\n",
      "Epoch: 79 -> Test Accuracy: 71.05\n",
      "[80, 60] loss: 0.594\n",
      "[80, 120] loss: 0.616\n",
      "[80, 180] loss: 0.600\n",
      "[80, 240] loss: 0.601\n",
      "[80, 300] loss: 0.600\n",
      "[80, 360] loss: 0.607\n",
      "Epoch: 80 -> Loss: 0.530991494656\n",
      "Epoch: 80 -> Test Accuracy: 70.92\n",
      "[81, 60] loss: 0.602\n",
      "[81, 120] loss: 0.605\n",
      "[81, 180] loss: 0.604\n",
      "[81, 240] loss: 0.603\n",
      "[81, 300] loss: 0.584\n",
      "[81, 360] loss: 0.605\n",
      "Epoch: 81 -> Loss: 0.616190552711\n",
      "Epoch: 81 -> Test Accuracy: 71.45\n",
      "[82, 60] loss: 0.591\n",
      "[82, 120] loss: 0.585\n",
      "[82, 180] loss: 0.610\n",
      "[82, 240] loss: 0.610\n",
      "[82, 300] loss: 0.602\n",
      "[82, 360] loss: 0.604\n",
      "Epoch: 82 -> Loss: 0.582726240158\n",
      "Epoch: 82 -> Test Accuracy: 71.04\n",
      "[83, 60] loss: 0.594\n",
      "[83, 120] loss: 0.599\n",
      "[83, 180] loss: 0.601\n",
      "[83, 240] loss: 0.600\n",
      "[83, 300] loss: 0.607\n",
      "[83, 360] loss: 0.592\n",
      "Epoch: 83 -> Loss: 0.702142477036\n",
      "Epoch: 83 -> Test Accuracy: 71.19\n",
      "[84, 60] loss: 0.599\n",
      "[84, 120] loss: 0.598\n",
      "[84, 180] loss: 0.604\n",
      "[84, 240] loss: 0.600\n",
      "[84, 300] loss: 0.596\n",
      "[84, 360] loss: 0.609\n",
      "Epoch: 84 -> Loss: 0.626204073429\n",
      "Epoch: 84 -> Test Accuracy: 70.81\n",
      "[85, 60] loss: 0.601\n",
      "[85, 120] loss: 0.591\n",
      "[85, 180] loss: 0.602\n",
      "[85, 240] loss: 0.586\n",
      "[85, 300] loss: 0.597\n",
      "[85, 360] loss: 0.600\n",
      "Epoch: 85 -> Loss: 0.451061099768\n",
      "Epoch: 85 -> Test Accuracy: 71.0\n",
      "[86, 60] loss: 0.593\n",
      "[86, 120] loss: 0.594\n",
      "[86, 180] loss: 0.578\n",
      "[86, 240] loss: 0.572\n",
      "[86, 300] loss: 0.576\n",
      "[86, 360] loss: 0.578\n",
      "Epoch: 86 -> Loss: 0.5542126894\n",
      "Epoch: 86 -> Test Accuracy: 71.42\n",
      "[87, 60] loss: 0.594\n",
      "[87, 120] loss: 0.592\n",
      "[87, 180] loss: 0.561\n",
      "[87, 240] loss: 0.565\n",
      "[87, 300] loss: 0.578\n",
      "[87, 360] loss: 0.576\n",
      "Epoch: 87 -> Loss: 0.720492005348\n",
      "Epoch: 87 -> Test Accuracy: 71.47\n",
      "[88, 60] loss: 0.575\n",
      "[88, 120] loss: 0.585\n",
      "[88, 180] loss: 0.575\n",
      "[88, 240] loss: 0.585\n",
      "[88, 300] loss: 0.553\n",
      "[88, 360] loss: 0.590\n",
      "Epoch: 88 -> Loss: 0.406400501728\n",
      "Epoch: 88 -> Test Accuracy: 71.59\n",
      "[89, 60] loss: 0.562\n",
      "[89, 120] loss: 0.583\n",
      "[89, 180] loss: 0.574\n",
      "[89, 240] loss: 0.578\n",
      "[89, 300] loss: 0.564\n",
      "[89, 360] loss: 0.566\n",
      "Epoch: 89 -> Loss: 0.492288202047\n",
      "Epoch: 89 -> Test Accuracy: 71.53\n",
      "[90, 60] loss: 0.577\n",
      "[90, 120] loss: 0.566\n",
      "[90, 180] loss: 0.576\n",
      "[90, 240] loss: 0.573\n",
      "[90, 300] loss: 0.573\n",
      "[90, 360] loss: 0.575\n",
      "Epoch: 90 -> Loss: 0.635546326637\n",
      "Epoch: 90 -> Test Accuracy: 71.48\n",
      "[91, 60] loss: 0.559\n",
      "[91, 120] loss: 0.572\n",
      "[91, 180] loss: 0.579\n",
      "[91, 240] loss: 0.563\n",
      "[91, 300] loss: 0.566\n",
      "[91, 360] loss: 0.583\n",
      "Epoch: 91 -> Loss: 0.580500006676\n",
      "Epoch: 91 -> Test Accuracy: 71.61\n",
      "[92, 60] loss: 0.560\n",
      "[92, 120] loss: 0.563\n",
      "[92, 180] loss: 0.562\n",
      "[92, 240] loss: 0.574\n",
      "[92, 300] loss: 0.584\n",
      "[92, 360] loss: 0.562\n",
      "Epoch: 92 -> Loss: 0.521413266659\n",
      "Epoch: 92 -> Test Accuracy: 71.9\n",
      "[93, 60] loss: 0.584\n",
      "[93, 120] loss: 0.564\n",
      "[93, 180] loss: 0.553\n",
      "[93, 240] loss: 0.577\n",
      "[93, 300] loss: 0.574\n",
      "[93, 360] loss: 0.574\n",
      "Epoch: 93 -> Loss: 0.495668262243\n",
      "Epoch: 93 -> Test Accuracy: 71.65\n",
      "[94, 60] loss: 0.574\n",
      "[94, 120] loss: 0.555\n",
      "[94, 180] loss: 0.578\n",
      "[94, 240] loss: 0.561\n",
      "[94, 300] loss: 0.574\n",
      "[94, 360] loss: 0.564\n",
      "Epoch: 94 -> Loss: 0.504838943481\n",
      "Epoch: 94 -> Test Accuracy: 71.54\n",
      "[95, 60] loss: 0.571\n",
      "[95, 120] loss: 0.554\n",
      "[95, 180] loss: 0.561\n",
      "[95, 240] loss: 0.580\n",
      "[95, 300] loss: 0.584\n",
      "[95, 360] loss: 0.582\n",
      "Epoch: 95 -> Loss: 0.577372550964\n",
      "Epoch: 95 -> Test Accuracy: 71.72\n",
      "[96, 60] loss: 0.555\n",
      "[96, 120] loss: 0.568\n",
      "[96, 180] loss: 0.551\n",
      "[96, 240] loss: 0.561\n",
      "[96, 300] loss: 0.568\n",
      "[96, 360] loss: 0.575\n",
      "Epoch: 96 -> Loss: 0.770162582397\n",
      "Epoch: 96 -> Test Accuracy: 71.79\n",
      "[97, 60] loss: 0.562\n",
      "[97, 120] loss: 0.564\n",
      "[97, 180] loss: 0.571\n",
      "[97, 240] loss: 0.545\n",
      "[97, 300] loss: 0.551\n",
      "[97, 360] loss: 0.564\n",
      "Epoch: 97 -> Loss: 0.534194171429\n",
      "Epoch: 97 -> Test Accuracy: 71.78\n",
      "[98, 60] loss: 0.559\n",
      "[98, 120] loss: 0.572\n",
      "[98, 180] loss: 0.568\n",
      "[98, 240] loss: 0.564\n",
      "[98, 300] loss: 0.559\n",
      "[98, 360] loss: 0.581\n",
      "Epoch: 98 -> Loss: 0.607220292091\n",
      "Epoch: 98 -> Test Accuracy: 71.82\n",
      "[99, 60] loss: 0.554\n",
      "[99, 120] loss: 0.563\n",
      "[99, 180] loss: 0.563\n",
      "[99, 240] loss: 0.553\n",
      "[99, 300] loss: 0.568\n",
      "[99, 360] loss: 0.571\n",
      "Epoch: 99 -> Loss: 0.5734577775\n",
      "Epoch: 99 -> Test Accuracy: 71.8\n",
      "[100, 60] loss: 0.555\n",
      "[100, 120] loss: 0.553\n",
      "[100, 180] loss: 0.563\n",
      "[100, 240] loss: 0.567\n",
      "[100, 300] loss: 0.558\n",
      "[100, 360] loss: 0.561\n",
      "Epoch: 100 -> Loss: 0.653191387653\n",
      "Epoch: 100 -> Test Accuracy: 71.66\n",
      "Finished Training\n",
      "[1, 60] loss: 2.247\n",
      "[1, 120] loss: 2.069\n",
      "[1, 180] loss: 2.019\n",
      "[1, 240] loss: 1.998\n",
      "[1, 300] loss: 1.967\n",
      "[1, 360] loss: 1.965\n",
      "Epoch: 1 -> Loss: 1.85061228275\n",
      "Epoch: 1 -> Test Accuracy: 25.95\n",
      "[2, 60] loss: 1.937\n",
      "[2, 120] loss: 1.934\n",
      "[2, 180] loss: 1.916\n",
      "[2, 240] loss: 1.906\n",
      "[2, 300] loss: 1.894\n",
      "[2, 360] loss: 1.882\n",
      "Epoch: 2 -> Loss: 1.9198795557\n",
      "Epoch: 2 -> Test Accuracy: 28.54\n",
      "[3, 60] loss: 1.888\n",
      "[3, 120] loss: 1.883\n",
      "[3, 180] loss: 1.865\n",
      "[3, 240] loss: 1.868\n",
      "[3, 300] loss: 1.856\n",
      "[3, 360] loss: 1.860\n",
      "Epoch: 3 -> Loss: 1.79096531868\n",
      "Epoch: 3 -> Test Accuracy: 30.76\n",
      "[4, 60] loss: 1.870\n",
      "[4, 120] loss: 1.829\n",
      "[4, 180] loss: 1.838\n",
      "[4, 240] loss: 1.844\n",
      "[4, 300] loss: 1.839\n",
      "[4, 360] loss: 1.835\n",
      "Epoch: 4 -> Loss: 1.68952536583\n",
      "Epoch: 4 -> Test Accuracy: 30.98\n",
      "[5, 60] loss: 1.839\n",
      "[5, 120] loss: 1.821\n",
      "[5, 180] loss: 1.824\n",
      "[5, 240] loss: 1.832\n",
      "[5, 300] loss: 1.812\n",
      "[5, 360] loss: 1.815\n",
      "Epoch: 5 -> Loss: 1.84151387215\n",
      "Epoch: 5 -> Test Accuracy: 31.63\n",
      "[6, 60] loss: 1.841\n",
      "[6, 120] loss: 1.811\n",
      "[6, 180] loss: 1.816\n",
      "[6, 240] loss: 1.808\n",
      "[6, 300] loss: 1.819\n",
      "[6, 360] loss: 1.800\n",
      "Epoch: 6 -> Loss: 1.69545245171\n",
      "Epoch: 6 -> Test Accuracy: 31.51\n",
      "[7, 60] loss: 1.803\n",
      "[7, 120] loss: 1.805\n",
      "[7, 180] loss: 1.804\n",
      "[7, 240] loss: 1.800\n",
      "[7, 300] loss: 1.798\n",
      "[7, 360] loss: 1.791\n",
      "Epoch: 7 -> Loss: 1.84714865685\n",
      "Epoch: 7 -> Test Accuracy: 32.51\n",
      "[8, 60] loss: 1.803\n",
      "[8, 120] loss: 1.810\n",
      "[8, 180] loss: 1.798\n",
      "[8, 240] loss: 1.786\n",
      "[8, 300] loss: 1.789\n",
      "[8, 360] loss: 1.811\n",
      "Epoch: 8 -> Loss: 1.73032641411\n",
      "Epoch: 8 -> Test Accuracy: 33.6\n",
      "[9, 60] loss: 1.773\n",
      "[9, 120] loss: 1.793\n",
      "[9, 180] loss: 1.790\n",
      "[9, 240] loss: 1.783\n",
      "[9, 300] loss: 1.791\n",
      "[9, 360] loss: 1.788\n",
      "Epoch: 9 -> Loss: 1.80903851986\n",
      "Epoch: 9 -> Test Accuracy: 32.93\n",
      "[10, 60] loss: 1.795\n",
      "[10, 120] loss: 1.801\n",
      "[10, 180] loss: 1.763\n",
      "[10, 240] loss: 1.793\n",
      "[10, 300] loss: 1.775\n",
      "[10, 360] loss: 1.778\n",
      "Epoch: 10 -> Loss: 1.80699157715\n",
      "Epoch: 10 -> Test Accuracy: 32.46\n",
      "[11, 60] loss: 1.771\n",
      "[11, 120] loss: 1.785\n",
      "[11, 180] loss: 1.770\n",
      "[11, 240] loss: 1.777\n",
      "[11, 300] loss: 1.779\n",
      "[11, 360] loss: 1.800\n",
      "Epoch: 11 -> Loss: 1.80518436432\n",
      "Epoch: 11 -> Test Accuracy: 32.28\n",
      "[12, 60] loss: 1.771\n",
      "[12, 120] loss: 1.789\n",
      "[12, 180] loss: 1.758\n",
      "[12, 240] loss: 1.790\n",
      "[12, 300] loss: 1.767\n",
      "[12, 360] loss: 1.776\n",
      "Epoch: 12 -> Loss: 1.93594515324\n",
      "Epoch: 12 -> Test Accuracy: 32.64\n",
      "[13, 60] loss: 1.769\n",
      "[13, 120] loss: 1.783\n",
      "[13, 180] loss: 1.779\n",
      "[13, 240] loss: 1.769\n",
      "[13, 300] loss: 1.780\n",
      "[13, 360] loss: 1.778\n",
      "Epoch: 13 -> Loss: 1.78544068336\n",
      "Epoch: 13 -> Test Accuracy: 33.41\n",
      "[14, 60] loss: 1.777\n",
      "[14, 120] loss: 1.770\n",
      "[14, 180] loss: 1.756\n",
      "[14, 240] loss: 1.772\n",
      "[14, 300] loss: 1.779\n",
      "[14, 360] loss: 1.766\n",
      "Epoch: 14 -> Loss: 1.58979713917\n",
      "Epoch: 14 -> Test Accuracy: 33.12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15, 60] loss: 1.773\n",
      "[15, 120] loss: 1.762\n",
      "[15, 180] loss: 1.766\n",
      "[15, 240] loss: 1.784\n",
      "[15, 300] loss: 1.761\n",
      "[15, 360] loss: 1.757\n",
      "Epoch: 15 -> Loss: 1.85305559635\n",
      "Epoch: 15 -> Test Accuracy: 32.46\n",
      "[16, 60] loss: 1.770\n",
      "[16, 120] loss: 1.756\n",
      "[16, 180] loss: 1.775\n",
      "[16, 240] loss: 1.751\n",
      "[16, 300] loss: 1.769\n",
      "[16, 360] loss: 1.764\n",
      "Epoch: 16 -> Loss: 1.73094022274\n",
      "Epoch: 16 -> Test Accuracy: 33.73\n",
      "[17, 60] loss: 1.774\n",
      "[17, 120] loss: 1.762\n",
      "[17, 180] loss: 1.769\n",
      "[17, 240] loss: 1.743\n",
      "[17, 300] loss: 1.777\n",
      "[17, 360] loss: 1.749\n",
      "Epoch: 17 -> Loss: 1.65575253963\n",
      "Epoch: 17 -> Test Accuracy: 33.26\n",
      "[18, 60] loss: 1.765\n",
      "[18, 120] loss: 1.749\n",
      "[18, 180] loss: 1.760\n",
      "[18, 240] loss: 1.765\n",
      "[18, 300] loss: 1.769\n",
      "[18, 360] loss: 1.764\n",
      "Epoch: 18 -> Loss: 1.99318289757\n",
      "Epoch: 18 -> Test Accuracy: 33.83\n",
      "[19, 60] loss: 1.750\n",
      "[19, 120] loss: 1.753\n",
      "[19, 180] loss: 1.781\n",
      "[19, 240] loss: 1.760\n",
      "[19, 300] loss: 1.766\n",
      "[19, 360] loss: 1.748\n",
      "Epoch: 19 -> Loss: 1.71245706081\n",
      "Epoch: 19 -> Test Accuracy: 33.51\n",
      "[20, 60] loss: 1.752\n",
      "[20, 120] loss: 1.751\n",
      "[20, 180] loss: 1.775\n",
      "[20, 240] loss: 1.753\n",
      "[20, 300] loss: 1.774\n",
      "[20, 360] loss: 1.761\n",
      "Epoch: 20 -> Loss: 1.88972592354\n",
      "Epoch: 20 -> Test Accuracy: 33.08\n",
      "[21, 60] loss: 1.734\n",
      "[21, 120] loss: 1.763\n",
      "[21, 180] loss: 1.746\n",
      "[21, 240] loss: 1.768\n",
      "[21, 300] loss: 1.750\n",
      "[21, 360] loss: 1.754\n",
      "Epoch: 21 -> Loss: 1.85180222988\n",
      "Epoch: 21 -> Test Accuracy: 34.43\n",
      "[22, 60] loss: 1.754\n",
      "[22, 120] loss: 1.768\n",
      "[22, 180] loss: 1.764\n",
      "[22, 240] loss: 1.756\n",
      "[22, 300] loss: 1.757\n",
      "[22, 360] loss: 1.743\n",
      "Epoch: 22 -> Loss: 1.76983380318\n",
      "Epoch: 22 -> Test Accuracy: 34.14\n",
      "[23, 60] loss: 1.737\n",
      "[23, 120] loss: 1.777\n",
      "[23, 180] loss: 1.740\n",
      "[23, 240] loss: 1.763\n",
      "[23, 300] loss: 1.746\n",
      "[23, 360] loss: 1.777\n",
      "Epoch: 23 -> Loss: 1.86060070992\n",
      "Epoch: 23 -> Test Accuracy: 33.63\n",
      "[24, 60] loss: 1.754\n",
      "[24, 120] loss: 1.747\n",
      "[24, 180] loss: 1.761\n",
      "[24, 240] loss: 1.749\n",
      "[24, 300] loss: 1.768\n",
      "[24, 360] loss: 1.749\n",
      "Epoch: 24 -> Loss: 1.65707755089\n",
      "Epoch: 24 -> Test Accuracy: 33.76\n",
      "[25, 60] loss: 1.745\n",
      "[25, 120] loss: 1.764\n",
      "[25, 180] loss: 1.746\n",
      "[25, 240] loss: 1.781\n",
      "[25, 300] loss: 1.757\n",
      "[25, 360] loss: 1.738\n",
      "Epoch: 25 -> Loss: 1.64449858665\n",
      "Epoch: 25 -> Test Accuracy: 34.11\n",
      "[26, 60] loss: 1.754\n",
      "[26, 120] loss: 1.749\n",
      "[26, 180] loss: 1.767\n",
      "[26, 240] loss: 1.757\n",
      "[26, 300] loss: 1.757\n",
      "[26, 360] loss: 1.733\n",
      "Epoch: 26 -> Loss: 1.93188095093\n",
      "Epoch: 26 -> Test Accuracy: 34.9\n",
      "[27, 60] loss: 1.757\n",
      "[27, 120] loss: 1.721\n",
      "[27, 180] loss: 1.746\n",
      "[27, 240] loss: 1.752\n",
      "[27, 300] loss: 1.752\n",
      "[27, 360] loss: 1.753\n",
      "Epoch: 27 -> Loss: 1.83029973507\n",
      "Epoch: 27 -> Test Accuracy: 33.64\n",
      "[28, 60] loss: 1.748\n",
      "[28, 120] loss: 1.750\n",
      "[28, 180] loss: 1.749\n",
      "[28, 240] loss: 1.742\n",
      "[28, 300] loss: 1.749\n",
      "[28, 360] loss: 1.739\n",
      "Epoch: 28 -> Loss: 1.84336543083\n",
      "Epoch: 28 -> Test Accuracy: 32.86\n",
      "[29, 60] loss: 1.733\n",
      "[29, 120] loss: 1.749\n",
      "[29, 180] loss: 1.758\n",
      "[29, 240] loss: 1.770\n",
      "[29, 300] loss: 1.752\n",
      "[29, 360] loss: 1.736\n",
      "Epoch: 29 -> Loss: 1.81621050835\n",
      "Epoch: 29 -> Test Accuracy: 33.07\n",
      "[30, 60] loss: 1.752\n",
      "[30, 120] loss: 1.749\n",
      "[30, 180] loss: 1.759\n",
      "[30, 240] loss: 1.751\n",
      "[30, 300] loss: 1.756\n",
      "[30, 360] loss: 1.747\n",
      "Epoch: 30 -> Loss: 1.70448815823\n",
      "Epoch: 30 -> Test Accuracy: 33.04\n",
      "[31, 60] loss: 1.754\n",
      "[31, 120] loss: 1.744\n",
      "[31, 180] loss: 1.735\n",
      "[31, 240] loss: 1.775\n",
      "[31, 300] loss: 1.733\n",
      "[31, 360] loss: 1.749\n",
      "Epoch: 31 -> Loss: 1.60330867767\n",
      "Epoch: 31 -> Test Accuracy: 34.04\n",
      "[32, 60] loss: 1.755\n",
      "[32, 120] loss: 1.744\n",
      "[32, 180] loss: 1.745\n",
      "[32, 240] loss: 1.740\n",
      "[32, 300] loss: 1.743\n",
      "[32, 360] loss: 1.741\n",
      "Epoch: 32 -> Loss: 1.95406746864\n",
      "Epoch: 32 -> Test Accuracy: 34.11\n",
      "[33, 60] loss: 1.753\n",
      "[33, 120] loss: 1.742\n",
      "[33, 180] loss: 1.748\n",
      "[33, 240] loss: 1.730\n",
      "[33, 300] loss: 1.751\n",
      "[33, 360] loss: 1.758\n",
      "Epoch: 33 -> Loss: 1.63087725639\n",
      "Epoch: 33 -> Test Accuracy: 33.77\n",
      "[34, 60] loss: 1.748\n",
      "[34, 120] loss: 1.758\n",
      "[34, 180] loss: 1.741\n",
      "[34, 240] loss: 1.745\n",
      "[34, 300] loss: 1.743\n",
      "[34, 360] loss: 1.754\n",
      "Epoch: 34 -> Loss: 1.79095494747\n",
      "Epoch: 34 -> Test Accuracy: 33.69\n",
      "[35, 60] loss: 1.730\n",
      "[35, 120] loss: 1.736\n",
      "[35, 180] loss: 1.753\n",
      "[35, 240] loss: 1.756\n",
      "[35, 300] loss: 1.742\n",
      "[35, 360] loss: 1.739\n",
      "Epoch: 35 -> Loss: 1.86127662659\n",
      "Epoch: 35 -> Test Accuracy: 33.23\n",
      "[36, 60] loss: 1.694\n",
      "[36, 120] loss: 1.662\n",
      "[36, 180] loss: 1.680\n",
      "[36, 240] loss: 1.658\n",
      "[36, 300] loss: 1.659\n",
      "[36, 360] loss: 1.648\n",
      "Epoch: 36 -> Loss: 1.67963445187\n",
      "Epoch: 36 -> Test Accuracy: 37.06\n",
      "[37, 60] loss: 1.652\n",
      "[37, 120] loss: 1.663\n",
      "[37, 180] loss: 1.641\n",
      "[37, 240] loss: 1.649\n",
      "[37, 300] loss: 1.640\n",
      "[37, 360] loss: 1.641\n",
      "Epoch: 37 -> Loss: 1.68193221092\n",
      "Epoch: 37 -> Test Accuracy: 37.87\n",
      "[38, 60] loss: 1.632\n",
      "[38, 120] loss: 1.637\n",
      "[38, 180] loss: 1.645\n",
      "[38, 240] loss: 1.638\n",
      "[38, 300] loss: 1.655\n",
      "[38, 360] loss: 1.634\n",
      "Epoch: 38 -> Loss: 1.43856179714\n",
      "Epoch: 38 -> Test Accuracy: 37.33\n",
      "[39, 60] loss: 1.657\n",
      "[39, 120] loss: 1.628\n",
      "[39, 180] loss: 1.624\n",
      "[39, 240] loss: 1.631\n",
      "[39, 300] loss: 1.644\n",
      "[39, 360] loss: 1.647\n",
      "Epoch: 39 -> Loss: 1.53710114956\n",
      "Epoch: 39 -> Test Accuracy: 37.72\n",
      "[40, 60] loss: 1.644\n",
      "[40, 120] loss: 1.642\n",
      "[40, 180] loss: 1.631\n",
      "[40, 240] loss: 1.621\n",
      "[40, 300] loss: 1.635\n",
      "[40, 360] loss: 1.634\n",
      "Epoch: 40 -> Loss: 1.56932795048\n",
      "Epoch: 40 -> Test Accuracy: 37.85\n",
      "[41, 60] loss: 1.630\n",
      "[41, 120] loss: 1.645\n",
      "[41, 180] loss: 1.641\n",
      "[41, 240] loss: 1.637\n",
      "[41, 300] loss: 1.622\n",
      "[41, 360] loss: 1.617\n",
      "Epoch: 41 -> Loss: 1.73145616055\n",
      "Epoch: 41 -> Test Accuracy: 37.61\n",
      "[42, 60] loss: 1.616\n",
      "[42, 120] loss: 1.647\n",
      "[42, 180] loss: 1.614\n",
      "[42, 240] loss: 1.628\n",
      "[42, 300] loss: 1.645\n",
      "[42, 360] loss: 1.646\n",
      "Epoch: 42 -> Loss: 1.56037056446\n",
      "Epoch: 42 -> Test Accuracy: 37.21\n",
      "[43, 60] loss: 1.629\n",
      "[43, 120] loss: 1.614\n",
      "[43, 180] loss: 1.634\n",
      "[43, 240] loss: 1.644\n",
      "[43, 300] loss: 1.628\n",
      "[43, 360] loss: 1.628\n",
      "Epoch: 43 -> Loss: 1.68203616142\n",
      "Epoch: 43 -> Test Accuracy: 37.61\n",
      "[44, 60] loss: 1.640\n",
      "[44, 120] loss: 1.645\n",
      "[44, 180] loss: 1.634\n",
      "[44, 240] loss: 1.624\n",
      "[44, 300] loss: 1.618\n",
      "[44, 360] loss: 1.624\n",
      "Epoch: 44 -> Loss: 1.40001249313\n",
      "Epoch: 44 -> Test Accuracy: 38.14\n",
      "[45, 60] loss: 1.622\n",
      "[45, 120] loss: 1.611\n",
      "[45, 180] loss: 1.624\n",
      "[45, 240] loss: 1.630\n",
      "[45, 300] loss: 1.635\n",
      "[45, 360] loss: 1.640\n",
      "Epoch: 45 -> Loss: 1.61129641533\n",
      "Epoch: 45 -> Test Accuracy: 37.12\n",
      "[46, 60] loss: 1.640\n",
      "[46, 120] loss: 1.637\n",
      "[46, 180] loss: 1.634\n",
      "[46, 240] loss: 1.637\n",
      "[46, 300] loss: 1.638\n",
      "[46, 360] loss: 1.622\n",
      "Epoch: 46 -> Loss: 1.59105432034\n",
      "Epoch: 46 -> Test Accuracy: 37.42\n",
      "[47, 60] loss: 1.622\n",
      "[47, 120] loss: 1.649\n",
      "[47, 180] loss: 1.638\n",
      "[47, 240] loss: 1.625\n",
      "[47, 300] loss: 1.628\n",
      "[47, 360] loss: 1.639\n",
      "Epoch: 47 -> Loss: 1.70384120941\n",
      "Epoch: 47 -> Test Accuracy: 37.69\n",
      "[48, 60] loss: 1.620\n",
      "[48, 120] loss: 1.630\n",
      "[48, 180] loss: 1.643\n",
      "[48, 240] loss: 1.613\n",
      "[48, 300] loss: 1.644\n",
      "[48, 360] loss: 1.638\n",
      "Epoch: 48 -> Loss: 1.56385505199\n",
      "Epoch: 48 -> Test Accuracy: 38.28\n",
      "[49, 60] loss: 1.613\n",
      "[49, 120] loss: 1.629\n",
      "[49, 180] loss: 1.632\n",
      "[49, 240] loss: 1.630\n",
      "[49, 300] loss: 1.631\n",
      "[49, 360] loss: 1.624\n",
      "Epoch: 49 -> Loss: 1.54265570641\n",
      "Epoch: 49 -> Test Accuracy: 36.87\n",
      "[50, 60] loss: 1.627\n",
      "[50, 120] loss: 1.632\n",
      "[50, 180] loss: 1.629\n",
      "[50, 240] loss: 1.631\n",
      "[50, 300] loss: 1.624\n",
      "[50, 360] loss: 1.634\n",
      "Epoch: 50 -> Loss: 1.58279323578\n",
      "Epoch: 50 -> Test Accuracy: 37.86\n",
      "[51, 60] loss: 1.625\n",
      "[51, 120] loss: 1.633\n",
      "[51, 180] loss: 1.642\n",
      "[51, 240] loss: 1.641\n",
      "[51, 300] loss: 1.628\n",
      "[51, 360] loss: 1.619\n",
      "Epoch: 51 -> Loss: 1.57849621773\n",
      "Epoch: 51 -> Test Accuracy: 37.37\n",
      "[52, 60] loss: 1.617\n",
      "[52, 120] loss: 1.622\n",
      "[52, 180] loss: 1.633\n",
      "[52, 240] loss: 1.634\n",
      "[52, 300] loss: 1.644\n",
      "[52, 360] loss: 1.623\n",
      "Epoch: 52 -> Loss: 1.69125652313\n",
      "Epoch: 52 -> Test Accuracy: 37.95\n",
      "[53, 60] loss: 1.631\n",
      "[53, 120] loss: 1.632\n",
      "[53, 180] loss: 1.644\n",
      "[53, 240] loss: 1.637\n",
      "[53, 300] loss: 1.624\n",
      "[53, 360] loss: 1.618\n",
      "Epoch: 53 -> Loss: 1.52246165276\n",
      "Epoch: 53 -> Test Accuracy: 37.02\n",
      "[54, 60] loss: 1.632\n",
      "[54, 120] loss: 1.641\n",
      "[54, 180] loss: 1.628\n",
      "[54, 240] loss: 1.626\n",
      "[54, 300] loss: 1.632\n",
      "[54, 360] loss: 1.624\n",
      "Epoch: 54 -> Loss: 1.62474513054\n",
      "Epoch: 54 -> Test Accuracy: 37.62\n",
      "[55, 60] loss: 1.609\n",
      "[55, 120] loss: 1.619\n",
      "[55, 180] loss: 1.619\n",
      "[55, 240] loss: 1.639\n",
      "[55, 300] loss: 1.643\n",
      "[55, 360] loss: 1.630\n",
      "Epoch: 55 -> Loss: 1.55344796181\n",
      "Epoch: 55 -> Test Accuracy: 37.38\n",
      "[56, 60] loss: 1.619\n",
      "[56, 120] loss: 1.623\n",
      "[56, 180] loss: 1.627\n",
      "[56, 240] loss: 1.637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56, 300] loss: 1.617\n",
      "[56, 360] loss: 1.638\n",
      "Epoch: 56 -> Loss: 1.51970827579\n",
      "Epoch: 56 -> Test Accuracy: 38.12\n",
      "[57, 60] loss: 1.623\n",
      "[57, 120] loss: 1.644\n",
      "[57, 180] loss: 1.633\n",
      "[57, 240] loss: 1.637\n",
      "[57, 300] loss: 1.604\n",
      "[57, 360] loss: 1.633\n",
      "Epoch: 57 -> Loss: 1.48829591274\n",
      "Epoch: 57 -> Test Accuracy: 38.61\n",
      "[58, 60] loss: 1.611\n",
      "[58, 120] loss: 1.633\n",
      "[58, 180] loss: 1.635\n",
      "[58, 240] loss: 1.623\n",
      "[58, 300] loss: 1.636\n",
      "[58, 360] loss: 1.610\n",
      "Epoch: 58 -> Loss: 1.69478416443\n",
      "Epoch: 58 -> Test Accuracy: 39.03\n",
      "[59, 60] loss: 1.610\n",
      "[59, 120] loss: 1.620\n",
      "[59, 180] loss: 1.621\n",
      "[59, 240] loss: 1.623\n",
      "[59, 300] loss: 1.612\n",
      "[59, 360] loss: 1.636\n",
      "Epoch: 59 -> Loss: 1.80027079582\n",
      "Epoch: 59 -> Test Accuracy: 39.03\n",
      "[60, 60] loss: 1.646\n",
      "[60, 120] loss: 1.623\n",
      "[60, 180] loss: 1.617\n",
      "[60, 240] loss: 1.627\n",
      "[60, 300] loss: 1.626\n",
      "[60, 360] loss: 1.630\n",
      "Epoch: 60 -> Loss: 1.6705083847\n",
      "Epoch: 60 -> Test Accuracy: 37.53\n",
      "[61, 60] loss: 1.629\n",
      "[61, 120] loss: 1.631\n",
      "[61, 180] loss: 1.627\n",
      "[61, 240] loss: 1.627\n",
      "[61, 300] loss: 1.619\n",
      "[61, 360] loss: 1.604\n",
      "Epoch: 61 -> Loss: 1.5112811327\n",
      "Epoch: 61 -> Test Accuracy: 37.34\n",
      "[62, 60] loss: 1.630\n",
      "[62, 120] loss: 1.614\n",
      "[62, 180] loss: 1.619\n",
      "[62, 240] loss: 1.614\n",
      "[62, 300] loss: 1.627\n",
      "[62, 360] loss: 1.618\n",
      "Epoch: 62 -> Loss: 1.4861831665\n",
      "Epoch: 62 -> Test Accuracy: 37.69\n",
      "[63, 60] loss: 1.622\n",
      "[63, 120] loss: 1.608\n",
      "[63, 180] loss: 1.630\n",
      "[63, 240] loss: 1.622\n",
      "[63, 300] loss: 1.618\n",
      "[63, 360] loss: 1.622\n",
      "Epoch: 63 -> Loss: 1.58792006969\n",
      "Epoch: 63 -> Test Accuracy: 36.95\n",
      "[64, 60] loss: 1.633\n",
      "[64, 120] loss: 1.605\n",
      "[64, 180] loss: 1.626\n",
      "[64, 240] loss: 1.624\n",
      "[64, 300] loss: 1.612\n",
      "[64, 360] loss: 1.610\n",
      "Epoch: 64 -> Loss: 1.76414704323\n",
      "Epoch: 64 -> Test Accuracy: 38.09\n",
      "[65, 60] loss: 1.620\n",
      "[65, 120] loss: 1.623\n",
      "[65, 180] loss: 1.624\n",
      "[65, 240] loss: 1.614\n",
      "[65, 300] loss: 1.629\n",
      "[65, 360] loss: 1.630\n",
      "Epoch: 65 -> Loss: 1.69710850716\n",
      "Epoch: 65 -> Test Accuracy: 37.85\n",
      "[66, 60] loss: 1.628\n",
      "[66, 120] loss: 1.618\n",
      "[66, 180] loss: 1.619\n",
      "[66, 240] loss: 1.618\n",
      "[66, 300] loss: 1.611\n",
      "[66, 360] loss: 1.631\n",
      "Epoch: 66 -> Loss: 1.54268050194\n",
      "Epoch: 66 -> Test Accuracy: 38.1\n",
      "[67, 60] loss: 1.634\n",
      "[67, 120] loss: 1.608\n",
      "[67, 180] loss: 1.619\n",
      "[67, 240] loss: 1.612\n",
      "[67, 300] loss: 1.617\n",
      "[67, 360] loss: 1.627\n",
      "Epoch: 67 -> Loss: 1.74588394165\n",
      "Epoch: 67 -> Test Accuracy: 37.9\n",
      "[68, 60] loss: 1.622\n",
      "[68, 120] loss: 1.615\n",
      "[68, 180] loss: 1.617\n",
      "[68, 240] loss: 1.630\n",
      "[68, 300] loss: 1.632\n",
      "[68, 360] loss: 1.609\n",
      "Epoch: 68 -> Loss: 1.68218266964\n",
      "Epoch: 68 -> Test Accuracy: 37.96\n",
      "[69, 60] loss: 1.603\n",
      "[69, 120] loss: 1.622\n",
      "[69, 180] loss: 1.642\n",
      "[69, 240] loss: 1.619\n",
      "[69, 300] loss: 1.630\n",
      "[69, 360] loss: 1.600\n",
      "Epoch: 69 -> Loss: 1.62148189545\n",
      "Epoch: 69 -> Test Accuracy: 38.43\n",
      "[70, 60] loss: 1.617\n",
      "[70, 120] loss: 1.629\n",
      "[70, 180] loss: 1.619\n",
      "[70, 240] loss: 1.607\n",
      "[70, 300] loss: 1.611\n",
      "[70, 360] loss: 1.625\n",
      "Epoch: 70 -> Loss: 1.67784571648\n",
      "Epoch: 70 -> Test Accuracy: 38.02\n",
      "[71, 60] loss: 1.598\n",
      "[71, 120] loss: 1.560\n",
      "[71, 180] loss: 1.569\n",
      "[71, 240] loss: 1.571\n",
      "[71, 300] loss: 1.561\n",
      "[71, 360] loss: 1.549\n",
      "Epoch: 71 -> Loss: 1.6180254221\n",
      "Epoch: 71 -> Test Accuracy: 40.32\n",
      "[72, 60] loss: 1.536\n",
      "[72, 120] loss: 1.540\n",
      "[72, 180] loss: 1.571\n",
      "[72, 240] loss: 1.552\n",
      "[72, 300] loss: 1.561\n",
      "[72, 360] loss: 1.540\n",
      "Epoch: 72 -> Loss: 1.3983092308\n",
      "Epoch: 72 -> Test Accuracy: 40.1\n",
      "[73, 60] loss: 1.543\n",
      "[73, 120] loss: 1.573\n",
      "[73, 180] loss: 1.554\n",
      "[73, 240] loss: 1.541\n",
      "[73, 300] loss: 1.535\n",
      "[73, 360] loss: 1.541\n",
      "Epoch: 73 -> Loss: 1.41933226585\n",
      "Epoch: 73 -> Test Accuracy: 40.36\n",
      "[74, 60] loss: 1.528\n",
      "[74, 120] loss: 1.545\n",
      "[74, 180] loss: 1.544\n",
      "[74, 240] loss: 1.545\n",
      "[74, 300] loss: 1.533\n",
      "[74, 360] loss: 1.543\n",
      "Epoch: 74 -> Loss: 1.60810780525\n",
      "Epoch: 74 -> Test Accuracy: 40.17\n",
      "[75, 60] loss: 1.539\n",
      "[75, 120] loss: 1.542\n",
      "[75, 180] loss: 1.537\n",
      "[75, 240] loss: 1.544\n",
      "[75, 300] loss: 1.531\n",
      "[75, 360] loss: 1.542\n",
      "Epoch: 75 -> Loss: 1.56894755363\n",
      "Epoch: 75 -> Test Accuracy: 40.25\n",
      "[76, 60] loss: 1.534\n",
      "[76, 120] loss: 1.521\n",
      "[76, 180] loss: 1.545\n",
      "[76, 240] loss: 1.548\n",
      "[76, 300] loss: 1.539\n",
      "[76, 360] loss: 1.531\n",
      "Epoch: 76 -> Loss: 1.43743157387\n",
      "Epoch: 76 -> Test Accuracy: 40.53\n",
      "[77, 60] loss: 1.533\n",
      "[77, 120] loss: 1.545\n",
      "[77, 180] loss: 1.526\n",
      "[77, 240] loss: 1.557\n",
      "[77, 300] loss: 1.529\n",
      "[77, 360] loss: 1.535\n",
      "Epoch: 77 -> Loss: 1.49821543694\n",
      "Epoch: 77 -> Test Accuracy: 40.57\n",
      "[78, 60] loss: 1.526\n",
      "[78, 120] loss: 1.533\n",
      "[78, 180] loss: 1.538\n",
      "[78, 240] loss: 1.545\n",
      "[78, 300] loss: 1.536\n",
      "[78, 360] loss: 1.533\n",
      "Epoch: 78 -> Loss: 1.41888451576\n",
      "Epoch: 78 -> Test Accuracy: 40.32\n",
      "[79, 60] loss: 1.524\n",
      "[79, 120] loss: 1.530\n",
      "[79, 180] loss: 1.553\n",
      "[79, 240] loss: 1.535\n",
      "[79, 300] loss: 1.519\n",
      "[79, 360] loss: 1.515\n",
      "Epoch: 79 -> Loss: 1.50238275528\n",
      "Epoch: 79 -> Test Accuracy: 40.44\n",
      "[80, 60] loss: 1.534\n",
      "[80, 120] loss: 1.527\n",
      "[80, 180] loss: 1.534\n",
      "[80, 240] loss: 1.531\n",
      "[80, 300] loss: 1.544\n",
      "[80, 360] loss: 1.525\n",
      "Epoch: 80 -> Loss: 1.44730722904\n",
      "Epoch: 80 -> Test Accuracy: 40.65\n",
      "[81, 60] loss: 1.529\n",
      "[81, 120] loss: 1.538\n",
      "[81, 180] loss: 1.528\n",
      "[81, 240] loss: 1.535\n",
      "[81, 300] loss: 1.543\n",
      "[81, 360] loss: 1.527\n",
      "Epoch: 81 -> Loss: 1.75940859318\n",
      "Epoch: 81 -> Test Accuracy: 40.56\n",
      "[82, 60] loss: 1.529\n",
      "[82, 120] loss: 1.523\n",
      "[82, 180] loss: 1.561\n",
      "[82, 240] loss: 1.522\n",
      "[82, 300] loss: 1.543\n",
      "[82, 360] loss: 1.521\n",
      "Epoch: 82 -> Loss: 1.55852007866\n",
      "Epoch: 82 -> Test Accuracy: 41.0\n",
      "[83, 60] loss: 1.520\n",
      "[83, 120] loss: 1.526\n",
      "[83, 180] loss: 1.525\n",
      "[83, 240] loss: 1.533\n",
      "[83, 300] loss: 1.531\n",
      "[83, 360] loss: 1.544\n",
      "Epoch: 83 -> Loss: 1.50728857517\n",
      "Epoch: 83 -> Test Accuracy: 40.58\n",
      "[84, 60] loss: 1.531\n",
      "[84, 120] loss: 1.542\n",
      "[84, 180] loss: 1.535\n",
      "[84, 240] loss: 1.516\n",
      "[84, 300] loss: 1.515\n",
      "[84, 360] loss: 1.547\n",
      "Epoch: 84 -> Loss: 1.57893121243\n",
      "Epoch: 84 -> Test Accuracy: 40.11\n",
      "[85, 60] loss: 1.540\n",
      "[85, 120] loss: 1.531\n",
      "[85, 180] loss: 1.543\n",
      "[85, 240] loss: 1.526\n",
      "[85, 300] loss: 1.553\n",
      "[85, 360] loss: 1.532\n",
      "Epoch: 85 -> Loss: 1.40689349174\n",
      "Epoch: 85 -> Test Accuracy: 40.43\n",
      "[86, 60] loss: 1.506\n",
      "[86, 120] loss: 1.501\n",
      "[86, 180] loss: 1.515\n",
      "[86, 240] loss: 1.505\n",
      "[86, 300] loss: 1.516\n",
      "[86, 360] loss: 1.509\n",
      "Epoch: 86 -> Loss: 1.63904976845\n",
      "Epoch: 86 -> Test Accuracy: 41.18\n",
      "[87, 60] loss: 1.506\n",
      "[87, 120] loss: 1.506\n",
      "[87, 180] loss: 1.499\n",
      "[87, 240] loss: 1.518\n",
      "[87, 300] loss: 1.511\n",
      "[87, 360] loss: 1.503\n",
      "Epoch: 87 -> Loss: 1.3912807703\n",
      "Epoch: 87 -> Test Accuracy: 41.33\n",
      "[88, 60] loss: 1.508\n",
      "[88, 120] loss: 1.492\n",
      "[88, 180] loss: 1.509\n",
      "[88, 240] loss: 1.509\n",
      "[88, 300] loss: 1.495\n",
      "[88, 360] loss: 1.491\n",
      "Epoch: 88 -> Loss: 1.50173687935\n",
      "Epoch: 88 -> Test Accuracy: 41.26\n",
      "[89, 60] loss: 1.475\n",
      "[89, 120] loss: 1.508\n",
      "[89, 180] loss: 1.497\n",
      "[89, 240] loss: 1.508\n",
      "[89, 300] loss: 1.504\n",
      "[89, 360] loss: 1.509\n",
      "Epoch: 89 -> Loss: 1.57605183125\n",
      "Epoch: 89 -> Test Accuracy: 41.42\n",
      "[90, 60] loss: 1.496\n",
      "[90, 120] loss: 1.506\n",
      "[90, 180] loss: 1.485\n",
      "[90, 240] loss: 1.497\n",
      "[90, 300] loss: 1.488\n",
      "[90, 360] loss: 1.501\n",
      "Epoch: 90 -> Loss: 1.3753900528\n",
      "Epoch: 90 -> Test Accuracy: 41.69\n",
      "[91, 60] loss: 1.487\n",
      "[91, 120] loss: 1.473\n",
      "[91, 180] loss: 1.488\n",
      "[91, 240] loss: 1.527\n",
      "[91, 300] loss: 1.515\n",
      "[91, 360] loss: 1.491\n",
      "Epoch: 91 -> Loss: 1.42230582237\n",
      "Epoch: 91 -> Test Accuracy: 41.57\n",
      "[92, 60] loss: 1.492\n",
      "[92, 120] loss: 1.468\n",
      "[92, 180] loss: 1.492\n",
      "[92, 240] loss: 1.493\n",
      "[92, 300] loss: 1.509\n",
      "[92, 360] loss: 1.506\n",
      "Epoch: 92 -> Loss: 1.73960566521\n",
      "Epoch: 92 -> Test Accuracy: 41.3\n",
      "[93, 60] loss: 1.486\n",
      "[93, 120] loss: 1.481\n",
      "[93, 180] loss: 1.490\n",
      "[93, 240] loss: 1.496\n",
      "[93, 300] loss: 1.500\n",
      "[93, 360] loss: 1.497\n",
      "Epoch: 93 -> Loss: 1.54213440418\n",
      "Epoch: 93 -> Test Accuracy: 41.36\n",
      "[94, 60] loss: 1.498\n",
      "[94, 120] loss: 1.489\n",
      "[94, 180] loss: 1.494\n",
      "[94, 240] loss: 1.498\n",
      "[94, 300] loss: 1.508\n",
      "[94, 360] loss: 1.470\n",
      "Epoch: 94 -> Loss: 1.39831924438\n",
      "Epoch: 94 -> Test Accuracy: 41.47\n",
      "[95, 60] loss: 1.501\n",
      "[95, 120] loss: 1.489\n",
      "[95, 180] loss: 1.492\n",
      "[95, 240] loss: 1.512\n",
      "[95, 300] loss: 1.482\n",
      "[95, 360] loss: 1.508\n",
      "Epoch: 95 -> Loss: 1.60073781013\n",
      "Epoch: 95 -> Test Accuracy: 41.47\n",
      "[96, 60] loss: 1.504\n",
      "[96, 120] loss: 1.491\n",
      "[96, 180] loss: 1.493\n",
      "[96, 240] loss: 1.502\n",
      "[96, 300] loss: 1.513\n",
      "[96, 360] loss: 1.500\n",
      "Epoch: 96 -> Loss: 1.5792696476\n",
      "Epoch: 96 -> Test Accuracy: 41.86\n",
      "[97, 60] loss: 1.488\n",
      "[97, 120] loss: 1.502\n",
      "[97, 180] loss: 1.478\n",
      "[97, 240] loss: 1.490\n",
      "[97, 300] loss: 1.490\n",
      "[97, 360] loss: 1.492\n",
      "Epoch: 97 -> Loss: 1.58493340015\n",
      "Epoch: 97 -> Test Accuracy: 41.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98, 60] loss: 1.474\n",
      "[98, 120] loss: 1.485\n",
      "[98, 180] loss: 1.493\n",
      "[98, 240] loss: 1.481\n",
      "[98, 300] loss: 1.515\n",
      "[98, 360] loss: 1.481\n",
      "Epoch: 98 -> Loss: 1.41757082939\n",
      "Epoch: 98 -> Test Accuracy: 41.27\n",
      "[99, 60] loss: 1.490\n",
      "[99, 120] loss: 1.480\n",
      "[99, 180] loss: 1.494\n",
      "[99, 240] loss: 1.503\n",
      "[99, 300] loss: 1.484\n",
      "[99, 360] loss: 1.499\n",
      "Epoch: 99 -> Loss: 1.64877724648\n",
      "Epoch: 99 -> Test Accuracy: 41.31\n",
      "[100, 60] loss: 1.507\n",
      "[100, 120] loss: 1.494\n",
      "[100, 180] loss: 1.490\n",
      "[100, 240] loss: 1.487\n",
      "[100, 300] loss: 1.486\n",
      "[100, 360] loss: 1.488\n",
      "Epoch: 100 -> Loss: 1.58387207985\n",
      "Epoch: 100 -> Test Accuracy: 41.62\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train ConvClassifiers on feature map of net_3block\n",
    "conv_block5_loss_log, _, conv_block5_test_accuracy_log, _, _ = tr.train_all_blocks(5, 10, [0.1, 0.02, 0.004, 0.0008], \n",
    "    [35, 70, 85, 100], 0.9, 5e-4, net_block5, criterion, trainloader, None, testloader, use_ConvClassifier=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save variables\n",
    "fm.save_variable([rot_block5_loss_log, rot_block5_test_accuracy_log, \n",
    "                  block5_loss_log, block5_test_accuracy_log, \n",
    "                  conv_block5_loss_log, conv_block5_test_accuracy_log], \"5_block_net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename files\n",
    "fm.add_block_to_name(5, [100, 200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised NIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In the code of the paper a 3 convolutional block RotNet was used for the classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize networks\n",
    "net_class = RN.RotNet(num_classes=10, num_conv_block=3, add_avg_pool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 60] loss: 1.819\n",
      "[1, 120] loss: 1.489\n",
      "[1, 180] loss: 1.363\n",
      "[1, 240] loss: 1.256\n",
      "[1, 300] loss: 1.179\n",
      "[1, 360] loss: 1.129\n",
      "Epoch: 1 -> Loss: 1.23693716526\n",
      "Epoch: 1 -> Test Accuracy: 58.58\n",
      "[2, 60] loss: 1.034\n",
      "[2, 120] loss: 0.983\n",
      "[2, 180] loss: 0.963\n",
      "[2, 240] loss: 0.905\n",
      "[2, 300] loss: 0.882\n",
      "[2, 360] loss: 0.872\n",
      "Epoch: 2 -> Loss: 0.986335098743\n",
      "Epoch: 2 -> Test Accuracy: 66.94\n",
      "[3, 60] loss: 0.809\n",
      "[3, 120] loss: 0.828\n",
      "[3, 180] loss: 0.776\n",
      "[3, 240] loss: 0.776\n",
      "[3, 300] loss: 0.753\n",
      "[3, 360] loss: 0.761\n",
      "Epoch: 3 -> Loss: 0.888205885887\n",
      "Epoch: 3 -> Test Accuracy: 72.76\n",
      "[4, 60] loss: 0.732\n",
      "[4, 120] loss: 0.715\n",
      "[4, 180] loss: 0.724\n",
      "[4, 240] loss: 0.719\n",
      "[4, 300] loss: 0.702\n",
      "[4, 360] loss: 0.691\n",
      "Epoch: 4 -> Loss: 0.861030876637\n",
      "Epoch: 4 -> Test Accuracy: 73.76\n",
      "[5, 60] loss: 0.649\n",
      "[5, 120] loss: 0.644\n",
      "[5, 180] loss: 0.679\n",
      "[5, 240] loss: 0.675\n",
      "[5, 300] loss: 0.669\n",
      "[5, 360] loss: 0.657\n",
      "Epoch: 5 -> Loss: 0.828762710094\n",
      "Epoch: 5 -> Test Accuracy: 76.76\n",
      "[6, 60] loss: 0.627\n",
      "[6, 120] loss: 0.621\n",
      "[6, 180] loss: 0.636\n",
      "[6, 240] loss: 0.626\n",
      "[6, 300] loss: 0.630\n",
      "[6, 360] loss: 0.639\n",
      "Epoch: 6 -> Loss: 0.622988700867\n",
      "Epoch: 6 -> Test Accuracy: 76.56\n",
      "[7, 60] loss: 0.587\n",
      "[7, 120] loss: 0.589\n",
      "[7, 180] loss: 0.609\n",
      "[7, 240] loss: 0.584\n",
      "[7, 300] loss: 0.617\n",
      "[7, 360] loss: 0.602\n",
      "Epoch: 7 -> Loss: 0.663072705269\n",
      "Epoch: 7 -> Test Accuracy: 79.12\n",
      "[8, 60] loss: 0.585\n",
      "[8, 120] loss: 0.582\n",
      "[8, 180] loss: 0.579\n",
      "[8, 240] loss: 0.582\n",
      "[8, 300] loss: 0.565\n",
      "[8, 360] loss: 0.563\n",
      "Epoch: 8 -> Loss: 0.536519110203\n",
      "Epoch: 8 -> Test Accuracy: 78.96\n",
      "[9, 60] loss: 0.533\n",
      "[9, 120] loss: 0.560\n",
      "[9, 180] loss: 0.578\n",
      "[9, 240] loss: 0.551\n",
      "[9, 300] loss: 0.555\n",
      "[9, 360] loss: 0.573\n",
      "Epoch: 9 -> Loss: 0.826891720295\n",
      "Epoch: 9 -> Test Accuracy: 78.7\n",
      "[10, 60] loss: 0.540\n",
      "[10, 120] loss: 0.542\n",
      "[10, 180] loss: 0.547\n",
      "[10, 240] loss: 0.522\n",
      "[10, 300] loss: 0.551\n",
      "[10, 360] loss: 0.554\n",
      "Epoch: 10 -> Loss: 0.48559063673\n",
      "Epoch: 10 -> Test Accuracy: 79.32\n",
      "[11, 60] loss: 0.521\n",
      "[11, 120] loss: 0.537\n",
      "[11, 180] loss: 0.538\n",
      "[11, 240] loss: 0.532\n",
      "[11, 300] loss: 0.524\n",
      "[11, 360] loss: 0.529\n",
      "Epoch: 11 -> Loss: 0.569585382938\n",
      "Epoch: 11 -> Test Accuracy: 79.52\n",
      "[12, 60] loss: 0.522\n",
      "[12, 120] loss: 0.516\n",
      "[12, 180] loss: 0.522\n",
      "[12, 240] loss: 0.518\n",
      "[12, 300] loss: 0.520\n",
      "[12, 360] loss: 0.523\n",
      "Epoch: 12 -> Loss: 0.638211607933\n",
      "Epoch: 12 -> Test Accuracy: 80.12\n",
      "[13, 60] loss: 0.494\n",
      "[13, 120] loss: 0.522\n",
      "[13, 180] loss: 0.515\n",
      "[13, 240] loss: 0.499\n",
      "[13, 300] loss: 0.504\n",
      "[13, 360] loss: 0.500\n",
      "Epoch: 13 -> Loss: 0.699341654778\n",
      "Epoch: 13 -> Test Accuracy: 80.57\n",
      "[14, 60] loss: 0.479\n",
      "[14, 120] loss: 0.505\n",
      "[14, 180] loss: 0.487\n",
      "[14, 240] loss: 0.502\n",
      "[14, 300] loss: 0.484\n",
      "[14, 360] loss: 0.524\n",
      "Epoch: 14 -> Loss: 0.424408912659\n",
      "Epoch: 14 -> Test Accuracy: 80.24\n",
      "[15, 60] loss: 0.480\n",
      "[15, 120] loss: 0.479\n",
      "[15, 180] loss: 0.465\n",
      "[15, 240] loss: 0.479\n",
      "[15, 300] loss: 0.492\n",
      "[15, 360] loss: 0.508\n",
      "Epoch: 15 -> Loss: 0.348090112209\n",
      "Epoch: 15 -> Test Accuracy: 80.95\n",
      "[16, 60] loss: 0.470\n",
      "[16, 120] loss: 0.477\n",
      "[16, 180] loss: 0.490\n",
      "[16, 240] loss: 0.498\n",
      "[16, 300] loss: 0.462\n",
      "[16, 360] loss: 0.494\n",
      "Epoch: 16 -> Loss: 0.306843340397\n",
      "Epoch: 16 -> Test Accuracy: 80.72\n",
      "[17, 60] loss: 0.466\n",
      "[17, 120] loss: 0.448\n",
      "[17, 180] loss: 0.462\n",
      "[17, 240] loss: 0.485\n",
      "[17, 300] loss: 0.482\n",
      "[17, 360] loss: 0.491\n",
      "Epoch: 17 -> Loss: 0.318106591702\n",
      "Epoch: 17 -> Test Accuracy: 81.15\n",
      "[18, 60] loss: 0.463\n",
      "[18, 120] loss: 0.449\n",
      "[18, 180] loss: 0.472\n",
      "[18, 240] loss: 0.488\n",
      "[18, 300] loss: 0.476\n",
      "[18, 360] loss: 0.473\n",
      "Epoch: 18 -> Loss: 0.646277546883\n",
      "Epoch: 18 -> Test Accuracy: 80.85\n",
      "[19, 60] loss: 0.446\n",
      "[19, 120] loss: 0.471\n",
      "[19, 180] loss: 0.461\n",
      "[19, 240] loss: 0.457\n",
      "[19, 300] loss: 0.466\n",
      "[19, 360] loss: 0.495\n",
      "Epoch: 19 -> Loss: 0.666882395744\n",
      "Epoch: 19 -> Test Accuracy: 81.38\n",
      "[20, 60] loss: 0.436\n",
      "[20, 120] loss: 0.457\n",
      "[20, 180] loss: 0.454\n",
      "[20, 240] loss: 0.472\n",
      "[20, 300] loss: 0.462\n",
      "[20, 360] loss: 0.460\n",
      "Epoch: 20 -> Loss: 0.48817807436\n",
      "Epoch: 20 -> Test Accuracy: 80.32\n",
      "[21, 60] loss: 0.434\n",
      "[21, 120] loss: 0.449\n",
      "[21, 180] loss: 0.451\n",
      "[21, 240] loss: 0.469\n",
      "[21, 300] loss: 0.461\n",
      "[21, 360] loss: 0.467\n",
      "Epoch: 21 -> Loss: 0.498286396265\n",
      "Epoch: 21 -> Test Accuracy: 82.33\n",
      "[22, 60] loss: 0.422\n",
      "[22, 120] loss: 0.416\n",
      "[22, 180] loss: 0.457\n",
      "[22, 240] loss: 0.447\n",
      "[22, 300] loss: 0.462\n",
      "[22, 360] loss: 0.466\n",
      "Epoch: 22 -> Loss: 0.452228605747\n",
      "Epoch: 22 -> Test Accuracy: 80.98\n",
      "[23, 60] loss: 0.425\n",
      "[23, 120] loss: 0.441\n",
      "[23, 180] loss: 0.455\n",
      "[23, 240] loss: 0.435\n",
      "[23, 300] loss: 0.442\n",
      "[23, 360] loss: 0.456\n",
      "Epoch: 23 -> Loss: 0.455932229757\n",
      "Epoch: 23 -> Test Accuracy: 80.96\n",
      "[24, 60] loss: 0.426\n",
      "[24, 120] loss: 0.424\n",
      "[24, 180] loss: 0.427\n",
      "[24, 240] loss: 0.445\n",
      "[24, 300] loss: 0.459\n",
      "[24, 360] loss: 0.440\n",
      "Epoch: 24 -> Loss: 0.337875306606\n",
      "Epoch: 24 -> Test Accuracy: 80.64\n",
      "[25, 60] loss: 0.412\n",
      "[25, 120] loss: 0.426\n",
      "[25, 180] loss: 0.453\n",
      "[25, 240] loss: 0.430\n",
      "[25, 300] loss: 0.441\n",
      "[25, 360] loss: 0.452\n",
      "Epoch: 25 -> Loss: 0.33400696516\n",
      "Epoch: 25 -> Test Accuracy: 82.23\n",
      "[26, 60] loss: 0.414\n",
      "[26, 120] loss: 0.428\n",
      "[26, 180] loss: 0.467\n",
      "[26, 240] loss: 0.434\n",
      "[26, 300] loss: 0.451\n",
      "[26, 360] loss: 0.435\n",
      "Epoch: 26 -> Loss: 0.518905878067\n",
      "Epoch: 26 -> Test Accuracy: 82.52\n",
      "[27, 60] loss: 0.388\n",
      "[27, 120] loss: 0.424\n",
      "[27, 180] loss: 0.440\n",
      "[27, 240] loss: 0.440\n",
      "[27, 300] loss: 0.419\n",
      "[27, 360] loss: 0.427\n",
      "Epoch: 27 -> Loss: 0.403165996075\n",
      "Epoch: 27 -> Test Accuracy: 83.19\n",
      "[28, 60] loss: 0.409\n",
      "[28, 120] loss: 0.430\n",
      "[28, 180] loss: 0.441\n",
      "[28, 240] loss: 0.418\n",
      "[28, 300] loss: 0.431\n",
      "[28, 360] loss: 0.427\n",
      "Epoch: 28 -> Loss: 0.452795833349\n",
      "Epoch: 28 -> Test Accuracy: 82.4\n",
      "[29, 60] loss: 0.425\n",
      "[29, 120] loss: 0.431\n",
      "[29, 180] loss: 0.418\n",
      "[29, 240] loss: 0.444\n",
      "[29, 300] loss: 0.436\n",
      "[29, 360] loss: 0.441\n",
      "Epoch: 29 -> Loss: 0.445920288563\n",
      "Epoch: 29 -> Test Accuracy: 84.31\n",
      "[30, 60] loss: 0.393\n",
      "[30, 120] loss: 0.418\n",
      "[30, 180] loss: 0.411\n",
      "[30, 240] loss: 0.451\n",
      "[30, 300] loss: 0.439\n",
      "[30, 360] loss: 0.428\n",
      "Epoch: 30 -> Loss: 0.402801692486\n",
      "Epoch: 30 -> Test Accuracy: 80.45\n",
      "[31, 60] loss: 0.415\n",
      "[31, 120] loss: 0.431\n",
      "[31, 180] loss: 0.421\n",
      "[31, 240] loss: 0.416\n",
      "[31, 300] loss: 0.446\n",
      "[31, 360] loss: 0.399\n",
      "Epoch: 31 -> Loss: 0.714214146137\n",
      "Epoch: 31 -> Test Accuracy: 80.95\n",
      "[32, 60] loss: 0.397\n",
      "[32, 120] loss: 0.428\n",
      "[32, 180] loss: 0.436\n",
      "[32, 240] loss: 0.404\n",
      "[32, 300] loss: 0.426\n",
      "[32, 360] loss: 0.424\n",
      "Epoch: 32 -> Loss: 0.617473602295\n",
      "Epoch: 32 -> Test Accuracy: 82.35\n",
      "[33, 60] loss: 0.406\n",
      "[33, 120] loss: 0.403\n",
      "[33, 180] loss: 0.411\n",
      "[33, 240] loss: 0.426\n",
      "[33, 300] loss: 0.434\n",
      "[33, 360] loss: 0.408\n",
      "Epoch: 33 -> Loss: 0.384450346231\n",
      "Epoch: 33 -> Test Accuracy: 82.81\n",
      "[34, 60] loss: 0.396\n",
      "[34, 120] loss: 0.417\n",
      "[34, 180] loss: 0.418\n",
      "[34, 240] loss: 0.405\n",
      "[34, 300] loss: 0.422\n",
      "[34, 360] loss: 0.413\n",
      "Epoch: 34 -> Loss: 0.29638248682\n",
      "Epoch: 34 -> Test Accuracy: 83.37\n",
      "[35, 60] loss: 0.390\n",
      "[35, 120] loss: 0.407\n",
      "[35, 180] loss: 0.415\n",
      "[35, 240] loss: 0.420\n",
      "[35, 300] loss: 0.422\n",
      "[35, 360] loss: 0.416\n",
      "Epoch: 35 -> Loss: 0.462302744389\n",
      "Epoch: 35 -> Test Accuracy: 82.76\n",
      "[36, 60] loss: 0.400\n",
      "[36, 120] loss: 0.413\n",
      "[36, 180] loss: 0.415\n",
      "[36, 240] loss: 0.399\n",
      "[36, 300] loss: 0.423\n",
      "[36, 360] loss: 0.404\n",
      "Epoch: 36 -> Loss: 0.553041994572\n",
      "Epoch: 36 -> Test Accuracy: 81.94\n",
      "[37, 60] loss: 0.383\n",
      "[37, 120] loss: 0.399\n",
      "[37, 180] loss: 0.400\n",
      "[37, 240] loss: 0.420\n",
      "[37, 300] loss: 0.416\n",
      "[37, 360] loss: 0.406\n",
      "Epoch: 37 -> Loss: 0.431072324514\n",
      "Epoch: 37 -> Test Accuracy: 82.01\n",
      "[38, 60] loss: 0.381\n",
      "[38, 120] loss: 0.402\n",
      "[38, 180] loss: 0.424\n",
      "[38, 240] loss: 0.395\n",
      "[38, 300] loss: 0.415\n",
      "[38, 360] loss: 0.426\n",
      "Epoch: 38 -> Loss: 0.43812713027\n",
      "Epoch: 38 -> Test Accuracy: 83.21\n",
      "[39, 60] loss: 0.379\n",
      "[39, 120] loss: 0.398\n",
      "[39, 180] loss: 0.394\n",
      "[39, 240] loss: 0.402\n",
      "[39, 300] loss: 0.412\n",
      "[39, 360] loss: 0.423\n",
      "Epoch: 39 -> Loss: 0.417372047901\n",
      "Epoch: 39 -> Test Accuracy: 83.74\n",
      "[40, 60] loss: 0.375\n",
      "[40, 120] loss: 0.405\n",
      "[40, 180] loss: 0.416\n",
      "[40, 240] loss: 0.409\n",
      "[40, 300] loss: 0.410\n",
      "[40, 360] loss: 0.408\n",
      "Epoch: 40 -> Loss: 0.396571487188\n",
      "Epoch: 40 -> Test Accuracy: 83.15\n",
      "[41, 60] loss: 0.388\n",
      "[41, 120] loss: 0.390\n",
      "[41, 180] loss: 0.397\n",
      "[41, 240] loss: 0.411\n",
      "[41, 300] loss: 0.404\n",
      "[41, 360] loss: 0.423\n",
      "Epoch: 41 -> Loss: 0.517241895199\n",
      "Epoch: 41 -> Test Accuracy: 83.57\n",
      "[42, 60] loss: 0.387\n",
      "[42, 120] loss: 0.385\n",
      "[42, 180] loss: 0.426\n",
      "[42, 240] loss: 0.404\n",
      "[42, 300] loss: 0.416\n",
      "[42, 360] loss: 0.406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 -> Loss: 0.497273266315\n",
      "Epoch: 42 -> Test Accuracy: 82.86\n",
      "[43, 60] loss: 0.383\n",
      "[43, 120] loss: 0.398\n",
      "[43, 180] loss: 0.406\n",
      "[43, 240] loss: 0.396\n",
      "[43, 300] loss: 0.392\n",
      "[43, 360] loss: 0.413\n",
      "Epoch: 43 -> Loss: 0.391762316227\n",
      "Epoch: 43 -> Test Accuracy: 83.12\n",
      "[44, 60] loss: 0.356\n",
      "[44, 120] loss: 0.401\n",
      "[44, 180] loss: 0.408\n",
      "[44, 240] loss: 0.405\n",
      "[44, 300] loss: 0.417\n",
      "[44, 360] loss: 0.393\n",
      "Epoch: 44 -> Loss: 0.49181586504\n",
      "Epoch: 44 -> Test Accuracy: 83.01\n",
      "[45, 60] loss: 0.386\n",
      "[45, 120] loss: 0.394\n",
      "[45, 180] loss: 0.376\n",
      "[45, 240] loss: 0.426\n",
      "[45, 300] loss: 0.380\n",
      "[45, 360] loss: 0.422\n",
      "Epoch: 45 -> Loss: 0.550320327282\n",
      "Epoch: 45 -> Test Accuracy: 83.18\n",
      "[46, 60] loss: 0.376\n",
      "[46, 120] loss: 0.386\n",
      "[46, 180] loss: 0.388\n",
      "[46, 240] loss: 0.410\n",
      "[46, 300] loss: 0.383\n",
      "[46, 360] loss: 0.407\n",
      "Epoch: 46 -> Loss: 0.319671213627\n",
      "Epoch: 46 -> Test Accuracy: 82.69\n",
      "[47, 60] loss: 0.375\n",
      "[47, 120] loss: 0.393\n",
      "[47, 180] loss: 0.391\n",
      "[47, 240] loss: 0.387\n",
      "[47, 300] loss: 0.382\n",
      "[47, 360] loss: 0.406\n",
      "Epoch: 47 -> Loss: 0.361741483212\n",
      "Epoch: 47 -> Test Accuracy: 83.27\n",
      "[48, 60] loss: 0.360\n",
      "[48, 120] loss: 0.370\n",
      "[48, 180] loss: 0.389\n",
      "[48, 240] loss: 0.408\n",
      "[48, 300] loss: 0.399\n",
      "[48, 360] loss: 0.426\n",
      "Epoch: 48 -> Loss: 0.435654789209\n",
      "Epoch: 48 -> Test Accuracy: 84.05\n",
      "[49, 60] loss: 0.347\n",
      "[49, 120] loss: 0.386\n",
      "[49, 180] loss: 0.414\n",
      "[49, 240] loss: 0.398\n",
      "[49, 300] loss: 0.411\n",
      "[49, 360] loss: 0.409\n",
      "Epoch: 49 -> Loss: 0.301557153463\n",
      "Epoch: 49 -> Test Accuracy: 83.07\n",
      "[50, 60] loss: 0.376\n",
      "[50, 120] loss: 0.396\n",
      "[50, 180] loss: 0.381\n",
      "[50, 240] loss: 0.411\n",
      "[50, 300] loss: 0.399\n",
      "[50, 360] loss: 0.403\n",
      "Epoch: 50 -> Loss: 0.340185105801\n",
      "Epoch: 50 -> Test Accuracy: 84.13\n",
      "[51, 60] loss: 0.372\n",
      "[51, 120] loss: 0.381\n",
      "[51, 180] loss: 0.413\n",
      "[51, 240] loss: 0.403\n",
      "[51, 300] loss: 0.391\n",
      "[51, 360] loss: 0.385\n",
      "Epoch: 51 -> Loss: 0.517580151558\n",
      "Epoch: 51 -> Test Accuracy: 83.53\n",
      "[52, 60] loss: 0.382\n",
      "[52, 120] loss: 0.380\n",
      "[52, 180] loss: 0.356\n",
      "[52, 240] loss: 0.388\n",
      "[52, 300] loss: 0.431\n",
      "[52, 360] loss: 0.400\n",
      "Epoch: 52 -> Loss: 0.314218521118\n",
      "Epoch: 52 -> Test Accuracy: 83.02\n",
      "[53, 60] loss: 0.381\n",
      "[53, 120] loss: 0.388\n",
      "[53, 180] loss: 0.373\n",
      "[53, 240] loss: 0.402\n",
      "[53, 300] loss: 0.381\n",
      "[53, 360] loss: 0.412\n",
      "Epoch: 53 -> Loss: 0.428229153156\n",
      "Epoch: 53 -> Test Accuracy: 83.33\n",
      "[54, 60] loss: 0.385\n",
      "[54, 120] loss: 0.348\n",
      "[54, 180] loss: 0.386\n",
      "[54, 240] loss: 0.409\n",
      "[54, 300] loss: 0.407\n",
      "[54, 360] loss: 0.400\n",
      "Epoch: 54 -> Loss: 0.370342135429\n",
      "Epoch: 54 -> Test Accuracy: 84.6\n",
      "[55, 60] loss: 0.373\n",
      "[55, 120] loss: 0.369\n",
      "[55, 180] loss: 0.392\n",
      "[55, 240] loss: 0.380\n",
      "[55, 300] loss: 0.400\n",
      "[55, 360] loss: 0.409\n",
      "Epoch: 55 -> Loss: 0.375511795282\n",
      "Epoch: 55 -> Test Accuracy: 83.42\n",
      "[56, 60] loss: 0.346\n",
      "[56, 120] loss: 0.368\n",
      "[56, 180] loss: 0.384\n",
      "[56, 240] loss: 0.406\n",
      "[56, 300] loss: 0.399\n",
      "[56, 360] loss: 0.391\n",
      "Epoch: 56 -> Loss: 0.358074456453\n",
      "Epoch: 56 -> Test Accuracy: 81.16\n",
      "[57, 60] loss: 0.379\n",
      "[57, 120] loss: 0.382\n",
      "[57, 180] loss: 0.389\n",
      "[57, 240] loss: 0.396\n",
      "[57, 300] loss: 0.391\n",
      "[57, 360] loss: 0.400\n",
      "Epoch: 57 -> Loss: 0.325857818127\n",
      "Epoch: 57 -> Test Accuracy: 84.48\n",
      "[58, 60] loss: 0.378\n",
      "[58, 120] loss: 0.385\n",
      "[58, 180] loss: 0.383\n",
      "[58, 240] loss: 0.387\n",
      "[58, 300] loss: 0.405\n",
      "[58, 360] loss: 0.398\n",
      "Epoch: 58 -> Loss: 0.322288453579\n",
      "Epoch: 58 -> Test Accuracy: 82.88\n",
      "[59, 60] loss: 0.386\n",
      "[59, 120] loss: 0.375\n",
      "[59, 180] loss: 0.371\n",
      "[59, 240] loss: 0.383\n",
      "[59, 300] loss: 0.383\n",
      "[59, 360] loss: 0.385\n",
      "Epoch: 59 -> Loss: 0.29003316164\n",
      "Epoch: 59 -> Test Accuracy: 84.06\n",
      "[60, 60] loss: 0.378\n",
      "[60, 120] loss: 0.357\n",
      "[60, 180] loss: 0.396\n",
      "[60, 240] loss: 0.404\n",
      "[60, 300] loss: 0.371\n",
      "[60, 360] loss: 0.403\n",
      "Epoch: 60 -> Loss: 0.279021978378\n",
      "Epoch: 60 -> Test Accuracy: 84.44\n",
      "[61, 60] loss: 0.280\n",
      "[61, 120] loss: 0.226\n",
      "[61, 180] loss: 0.224\n",
      "[61, 240] loss: 0.208\n",
      "[61, 300] loss: 0.212\n",
      "[61, 360] loss: 0.195\n",
      "Epoch: 61 -> Loss: 0.258277714252\n",
      "Epoch: 61 -> Test Accuracy: 89.11\n",
      "[62, 60] loss: 0.176\n",
      "[62, 120] loss: 0.181\n",
      "[62, 180] loss: 0.182\n",
      "[62, 240] loss: 0.176\n",
      "[62, 300] loss: 0.179\n",
      "[62, 360] loss: 0.181\n",
      "Epoch: 62 -> Loss: 0.189277812839\n",
      "Epoch: 62 -> Test Accuracy: 89.53\n",
      "[63, 60] loss: 0.166\n",
      "[63, 120] loss: 0.149\n",
      "[63, 180] loss: 0.152\n",
      "[63, 240] loss: 0.160\n",
      "[63, 300] loss: 0.164\n",
      "[63, 360] loss: 0.167\n",
      "Epoch: 63 -> Loss: 0.15406434238\n",
      "Epoch: 63 -> Test Accuracy: 89.48\n",
      "[64, 60] loss: 0.141\n",
      "[64, 120] loss: 0.149\n",
      "[64, 180] loss: 0.153\n",
      "[64, 240] loss: 0.156\n",
      "[64, 300] loss: 0.150\n",
      "[64, 360] loss: 0.150\n",
      "Epoch: 64 -> Loss: 0.229251742363\n",
      "Epoch: 64 -> Test Accuracy: 89.53\n",
      "[65, 60] loss: 0.133\n",
      "[65, 120] loss: 0.143\n",
      "[65, 180] loss: 0.138\n",
      "[65, 240] loss: 0.136\n",
      "[65, 300] loss: 0.134\n",
      "[65, 360] loss: 0.153\n",
      "Epoch: 65 -> Loss: 0.0995594412088\n",
      "Epoch: 65 -> Test Accuracy: 89.4\n",
      "[66, 60] loss: 0.122\n",
      "[66, 120] loss: 0.130\n",
      "[66, 180] loss: 0.132\n",
      "[66, 240] loss: 0.144\n",
      "[66, 300] loss: 0.138\n",
      "[66, 360] loss: 0.156\n",
      "Epoch: 66 -> Loss: 0.195820808411\n",
      "Epoch: 66 -> Test Accuracy: 89.47\n",
      "[67, 60] loss: 0.118\n",
      "[67, 120] loss: 0.129\n",
      "[67, 180] loss: 0.145\n",
      "[67, 240] loss: 0.135\n",
      "[67, 300] loss: 0.139\n",
      "[67, 360] loss: 0.135\n",
      "Epoch: 67 -> Loss: 0.0724321082234\n",
      "Epoch: 67 -> Test Accuracy: 89.41\n",
      "[68, 60] loss: 0.119\n",
      "[68, 120] loss: 0.136\n",
      "[68, 180] loss: 0.129\n",
      "[68, 240] loss: 0.130\n",
      "[68, 300] loss: 0.137\n",
      "[68, 360] loss: 0.132\n",
      "Epoch: 68 -> Loss: 0.268745720387\n",
      "Epoch: 68 -> Test Accuracy: 89.26\n",
      "[69, 60] loss: 0.114\n",
      "[69, 120] loss: 0.124\n",
      "[69, 180] loss: 0.118\n",
      "[69, 240] loss: 0.133\n",
      "[69, 300] loss: 0.135\n",
      "[69, 360] loss: 0.138\n",
      "Epoch: 69 -> Loss: 0.105397507548\n",
      "Epoch: 69 -> Test Accuracy: 89.01\n",
      "[70, 60] loss: 0.121\n",
      "[70, 120] loss: 0.131\n",
      "[70, 180] loss: 0.126\n",
      "[70, 240] loss: 0.133\n",
      "[70, 300] loss: 0.127\n",
      "[70, 360] loss: 0.151\n",
      "Epoch: 70 -> Loss: 0.18681243062\n",
      "Epoch: 70 -> Test Accuracy: 88.83\n",
      "[71, 60] loss: 0.125\n",
      "[71, 120] loss: 0.125\n",
      "[71, 180] loss: 0.128\n",
      "[71, 240] loss: 0.142\n",
      "[71, 300] loss: 0.137\n",
      "[71, 360] loss: 0.138\n",
      "Epoch: 71 -> Loss: 0.118388332427\n",
      "Epoch: 71 -> Test Accuracy: 89.03\n",
      "[72, 60] loss: 0.114\n",
      "[72, 120] loss: 0.120\n",
      "[72, 180] loss: 0.123\n",
      "[72, 240] loss: 0.133\n",
      "[72, 300] loss: 0.147\n",
      "[72, 360] loss: 0.140\n",
      "Epoch: 72 -> Loss: 0.103319942951\n",
      "Epoch: 72 -> Test Accuracy: 88.47\n",
      "[73, 60] loss: 0.122\n",
      "[73, 120] loss: 0.122\n",
      "[73, 180] loss: 0.114\n",
      "[73, 240] loss: 0.128\n",
      "[73, 300] loss: 0.142\n",
      "[73, 360] loss: 0.143\n",
      "Epoch: 73 -> Loss: 0.243509531021\n",
      "Epoch: 73 -> Test Accuracy: 89.07\n",
      "[74, 60] loss: 0.123\n",
      "[74, 120] loss: 0.130\n",
      "[74, 180] loss: 0.126\n",
      "[74, 240] loss: 0.139\n",
      "[74, 300] loss: 0.142\n",
      "[74, 360] loss: 0.163\n",
      "Epoch: 74 -> Loss: 0.172263026237\n",
      "Epoch: 74 -> Test Accuracy: 87.82\n",
      "[75, 60] loss: 0.132\n",
      "[75, 120] loss: 0.125\n",
      "[75, 180] loss: 0.128\n",
      "[75, 240] loss: 0.132\n",
      "[75, 300] loss: 0.142\n",
      "[75, 360] loss: 0.139\n",
      "Epoch: 75 -> Loss: 0.184239894152\n",
      "Epoch: 75 -> Test Accuracy: 88.65\n",
      "[76, 60] loss: 0.116\n",
      "[76, 120] loss: 0.137\n",
      "[76, 180] loss: 0.136\n",
      "[76, 240] loss: 0.149\n",
      "[76, 300] loss: 0.128\n",
      "[76, 360] loss: 0.148\n",
      "Epoch: 76 -> Loss: 0.29468908906\n",
      "Epoch: 76 -> Test Accuracy: 88.23\n",
      "[77, 60] loss: 0.125\n",
      "[77, 120] loss: 0.134\n",
      "[77, 180] loss: 0.122\n",
      "[77, 240] loss: 0.132\n",
      "[77, 300] loss: 0.146\n",
      "[77, 360] loss: 0.139\n",
      "Epoch: 77 -> Loss: 0.271967172623\n",
      "Epoch: 77 -> Test Accuracy: 88.47\n",
      "[78, 60] loss: 0.127\n",
      "[78, 120] loss: 0.121\n",
      "[78, 180] loss: 0.124\n",
      "[78, 240] loss: 0.123\n",
      "[78, 300] loss: 0.141\n",
      "[78, 360] loss: 0.147\n",
      "Epoch: 78 -> Loss: 0.0696671381593\n",
      "Epoch: 78 -> Test Accuracy: 88.33\n",
      "[79, 60] loss: 0.127\n",
      "[79, 120] loss: 0.143\n",
      "[79, 180] loss: 0.138\n",
      "[79, 240] loss: 0.144\n",
      "[79, 300] loss: 0.147\n",
      "[79, 360] loss: 0.140\n",
      "Epoch: 79 -> Loss: 0.187681630254\n",
      "Epoch: 79 -> Test Accuracy: 87.74\n",
      "[80, 60] loss: 0.136\n",
      "[80, 120] loss: 0.122\n",
      "[80, 180] loss: 0.131\n",
      "[80, 240] loss: 0.133\n",
      "[80, 300] loss: 0.141\n",
      "[80, 360] loss: 0.156\n",
      "Epoch: 80 -> Loss: 0.19254489243\n",
      "Epoch: 80 -> Test Accuracy: 87.85\n",
      "[81, 60] loss: 0.125\n",
      "[81, 120] loss: 0.134\n",
      "[81, 180] loss: 0.127\n",
      "[81, 240] loss: 0.141\n",
      "[81, 300] loss: 0.150\n",
      "[81, 360] loss: 0.152\n",
      "Epoch: 81 -> Loss: 0.174080893397\n",
      "Epoch: 81 -> Test Accuracy: 87.66\n",
      "[82, 60] loss: 0.129\n",
      "[82, 120] loss: 0.126\n",
      "[82, 180] loss: 0.128\n",
      "[82, 240] loss: 0.133\n",
      "[82, 300] loss: 0.140\n",
      "[82, 360] loss: 0.142\n",
      "Epoch: 82 -> Loss: 0.10569190979\n",
      "Epoch: 82 -> Test Accuracy: 89.17\n",
      "[83, 60] loss: 0.129\n",
      "[83, 120] loss: 0.123\n",
      "[83, 180] loss: 0.130\n",
      "[83, 240] loss: 0.136\n",
      "[83, 300] loss: 0.140\n",
      "[83, 360] loss: 0.152\n",
      "Epoch: 83 -> Loss: 0.0788936316967\n",
      "Epoch: 83 -> Test Accuracy: 88.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 60] loss: 0.110\n",
      "[84, 120] loss: 0.129\n",
      "[84, 180] loss: 0.154\n",
      "[84, 240] loss: 0.145\n",
      "[84, 300] loss: 0.134\n",
      "[84, 360] loss: 0.151\n",
      "Epoch: 84 -> Loss: 0.112958587706\n",
      "Epoch: 84 -> Test Accuracy: 88.0\n",
      "[85, 60] loss: 0.124\n",
      "[85, 120] loss: 0.123\n",
      "[85, 180] loss: 0.136\n",
      "[85, 240] loss: 0.139\n",
      "[85, 300] loss: 0.148\n",
      "[85, 360] loss: 0.132\n",
      "Epoch: 85 -> Loss: 0.230785563588\n",
      "Epoch: 85 -> Test Accuracy: 88.94\n",
      "[86, 60] loss: 0.129\n",
      "[86, 120] loss: 0.125\n",
      "[86, 180] loss: 0.135\n",
      "[86, 240] loss: 0.141\n",
      "[86, 300] loss: 0.143\n",
      "[86, 360] loss: 0.136\n",
      "Epoch: 86 -> Loss: 0.0781771987677\n",
      "Epoch: 86 -> Test Accuracy: 88.91\n",
      "[87, 60] loss: 0.121\n",
      "[87, 120] loss: 0.124\n",
      "[87, 180] loss: 0.125\n",
      "[87, 240] loss: 0.126\n",
      "[87, 300] loss: 0.133\n",
      "[87, 360] loss: 0.141\n",
      "Epoch: 87 -> Loss: 0.148603647947\n",
      "Epoch: 87 -> Test Accuracy: 88.37\n",
      "[88, 60] loss: 0.132\n",
      "[88, 120] loss: 0.125\n",
      "[88, 180] loss: 0.145\n",
      "[88, 240] loss: 0.136\n",
      "[88, 300] loss: 0.132\n",
      "[88, 360] loss: 0.149\n",
      "Epoch: 88 -> Loss: 0.146424606442\n",
      "Epoch: 88 -> Test Accuracy: 88.25\n",
      "[89, 60] loss: 0.118\n",
      "[89, 120] loss: 0.122\n",
      "[89, 180] loss: 0.120\n",
      "[89, 240] loss: 0.125\n",
      "[89, 300] loss: 0.126\n",
      "[89, 360] loss: 0.138\n",
      "Epoch: 89 -> Loss: 0.208356931806\n",
      "Epoch: 89 -> Test Accuracy: 88.08\n",
      "[90, 60] loss: 0.126\n",
      "[90, 120] loss: 0.129\n",
      "[90, 180] loss: 0.134\n",
      "[90, 240] loss: 0.135\n",
      "[90, 300] loss: 0.126\n",
      "[90, 360] loss: 0.150\n",
      "Epoch: 90 -> Loss: 0.180401518941\n",
      "Epoch: 90 -> Test Accuracy: 88.94\n",
      "[91, 60] loss: 0.132\n",
      "[91, 120] loss: 0.124\n",
      "[91, 180] loss: 0.129\n",
      "[91, 240] loss: 0.137\n",
      "[91, 300] loss: 0.141\n",
      "[91, 360] loss: 0.135\n",
      "Epoch: 91 -> Loss: 0.119220353663\n",
      "Epoch: 91 -> Test Accuracy: 87.98\n",
      "[92, 60] loss: 0.112\n",
      "[92, 120] loss: 0.112\n",
      "[92, 180] loss: 0.123\n",
      "[92, 240] loss: 0.116\n",
      "[92, 300] loss: 0.129\n",
      "[92, 360] loss: 0.146\n",
      "Epoch: 92 -> Loss: 0.114839456975\n",
      "Epoch: 92 -> Test Accuracy: 88.4\n",
      "[93, 60] loss: 0.118\n",
      "[93, 120] loss: 0.119\n",
      "[93, 180] loss: 0.136\n",
      "[93, 240] loss: 0.117\n",
      "[93, 300] loss: 0.156\n",
      "[93, 360] loss: 0.154\n",
      "Epoch: 93 -> Loss: 0.176992714405\n",
      "Epoch: 93 -> Test Accuracy: 88.63\n",
      "[94, 60] loss: 0.110\n",
      "[94, 120] loss: 0.117\n",
      "[94, 180] loss: 0.132\n",
      "[94, 240] loss: 0.143\n",
      "[94, 300] loss: 0.150\n",
      "[94, 360] loss: 0.145\n",
      "Epoch: 94 -> Loss: 0.154922962189\n",
      "Epoch: 94 -> Test Accuracy: 88.11\n",
      "[95, 60] loss: 0.115\n",
      "[95, 120] loss: 0.118\n",
      "[95, 180] loss: 0.123\n",
      "[95, 240] loss: 0.141\n",
      "[95, 300] loss: 0.144\n",
      "[95, 360] loss: 0.132\n",
      "Epoch: 95 -> Loss: 0.179609566927\n",
      "Epoch: 95 -> Test Accuracy: 88.3\n",
      "[96, 60] loss: 0.122\n",
      "[96, 120] loss: 0.121\n",
      "[96, 180] loss: 0.117\n",
      "[96, 240] loss: 0.123\n",
      "[96, 300] loss: 0.126\n",
      "[96, 360] loss: 0.140\n",
      "Epoch: 96 -> Loss: 0.16240260005\n",
      "Epoch: 96 -> Test Accuracy: 88.3\n",
      "[97, 60] loss: 0.127\n",
      "[97, 120] loss: 0.115\n",
      "[97, 180] loss: 0.113\n",
      "[97, 240] loss: 0.121\n",
      "[97, 300] loss: 0.124\n",
      "[97, 360] loss: 0.131\n",
      "Epoch: 97 -> Loss: 0.142535731196\n",
      "Epoch: 97 -> Test Accuracy: 89.2\n",
      "[98, 60] loss: 0.103\n",
      "[98, 120] loss: 0.120\n",
      "[98, 180] loss: 0.109\n",
      "[98, 240] loss: 0.125\n",
      "[98, 300] loss: 0.126\n",
      "[98, 360] loss: 0.135\n",
      "Epoch: 98 -> Loss: 0.0447786971927\n",
      "Epoch: 98 -> Test Accuracy: 88.86\n",
      "[99, 60] loss: 0.106\n",
      "[99, 120] loss: 0.098\n",
      "[99, 180] loss: 0.109\n",
      "[99, 240] loss: 0.125\n",
      "[99, 300] loss: 0.142\n",
      "[99, 360] loss: 0.148\n",
      "Epoch: 99 -> Loss: 0.318203628063\n",
      "Epoch: 99 -> Test Accuracy: 88.16\n",
      "[100, 60] loss: 0.112\n",
      "[100, 120] loss: 0.107\n",
      "[100, 180] loss: 0.119\n",
      "[100, 240] loss: 0.121\n",
      "[100, 300] loss: 0.140\n",
      "[100, 360] loss: 0.143\n",
      "Epoch: 100 -> Loss: 0.120280243456\n",
      "Epoch: 100 -> Test Accuracy: 88.03\n",
      "[101, 60] loss: 0.121\n",
      "[101, 120] loss: 0.113\n",
      "[101, 180] loss: 0.128\n",
      "[101, 240] loss: 0.124\n",
      "[101, 300] loss: 0.131\n",
      "[101, 360] loss: 0.116\n",
      "Epoch: 101 -> Loss: 0.156896352768\n",
      "Epoch: 101 -> Test Accuracy: 88.91\n",
      "[102, 60] loss: 0.105\n",
      "[102, 120] loss: 0.116\n",
      "[102, 180] loss: 0.120\n",
      "[102, 240] loss: 0.122\n",
      "[102, 300] loss: 0.124\n",
      "[102, 360] loss: 0.138\n",
      "Epoch: 102 -> Loss: 0.225530534983\n",
      "Epoch: 102 -> Test Accuracy: 88.42\n",
      "[103, 60] loss: 0.114\n",
      "[103, 120] loss: 0.118\n",
      "[103, 180] loss: 0.128\n",
      "[103, 240] loss: 0.116\n",
      "[103, 300] loss: 0.135\n",
      "[103, 360] loss: 0.119\n",
      "Epoch: 103 -> Loss: 0.0943901091814\n",
      "Epoch: 103 -> Test Accuracy: 88.63\n",
      "[104, 60] loss: 0.106\n",
      "[104, 120] loss: 0.112\n",
      "[104, 180] loss: 0.116\n",
      "[104, 240] loss: 0.121\n",
      "[104, 300] loss: 0.121\n",
      "[104, 360] loss: 0.124\n",
      "Epoch: 104 -> Loss: 0.220665544271\n",
      "Epoch: 104 -> Test Accuracy: 88.02\n",
      "[105, 60] loss: 0.115\n",
      "[105, 120] loss: 0.115\n",
      "[105, 180] loss: 0.120\n",
      "[105, 240] loss: 0.127\n",
      "[105, 300] loss: 0.145\n",
      "[105, 360] loss: 0.140\n",
      "Epoch: 105 -> Loss: 0.144761815667\n",
      "Epoch: 105 -> Test Accuracy: 88.21\n",
      "[106, 60] loss: 0.104\n",
      "[106, 120] loss: 0.121\n",
      "[106, 180] loss: 0.119\n",
      "[106, 240] loss: 0.112\n",
      "[106, 300] loss: 0.117\n",
      "[106, 360] loss: 0.140\n",
      "Epoch: 106 -> Loss: 0.059844404459\n",
      "Epoch: 106 -> Test Accuracy: 88.52\n",
      "[107, 60] loss: 0.096\n",
      "[107, 120] loss: 0.110\n",
      "[107, 180] loss: 0.114\n",
      "[107, 240] loss: 0.124\n",
      "[107, 300] loss: 0.127\n",
      "[107, 360] loss: 0.130\n",
      "Epoch: 107 -> Loss: 0.245553344488\n",
      "Epoch: 107 -> Test Accuracy: 88.17\n",
      "[108, 60] loss: 0.108\n",
      "[108, 120] loss: 0.104\n",
      "[108, 180] loss: 0.117\n",
      "[108, 240] loss: 0.121\n",
      "[108, 300] loss: 0.130\n",
      "[108, 360] loss: 0.129\n",
      "Epoch: 108 -> Loss: 0.149532869458\n",
      "Epoch: 108 -> Test Accuracy: 88.29\n",
      "[109, 60] loss: 0.109\n",
      "[109, 120] loss: 0.129\n",
      "[109, 180] loss: 0.119\n",
      "[109, 240] loss: 0.129\n",
      "[109, 300] loss: 0.145\n",
      "[109, 360] loss: 0.139\n",
      "Epoch: 109 -> Loss: 0.105499364436\n",
      "Epoch: 109 -> Test Accuracy: 88.67\n",
      "[110, 60] loss: 0.118\n",
      "[110, 120] loss: 0.103\n",
      "[110, 180] loss: 0.117\n",
      "[110, 240] loss: 0.109\n",
      "[110, 300] loss: 0.122\n",
      "[110, 360] loss: 0.125\n",
      "Epoch: 110 -> Loss: 0.205287486315\n",
      "Epoch: 110 -> Test Accuracy: 88.31\n",
      "[111, 60] loss: 0.105\n",
      "[111, 120] loss: 0.092\n",
      "[111, 180] loss: 0.102\n",
      "[111, 240] loss: 0.116\n",
      "[111, 300] loss: 0.125\n",
      "[111, 360] loss: 0.133\n",
      "Epoch: 111 -> Loss: 0.0697679594159\n",
      "Epoch: 111 -> Test Accuracy: 88.19\n",
      "[112, 60] loss: 0.099\n",
      "[112, 120] loss: 0.104\n",
      "[112, 180] loss: 0.121\n",
      "[112, 240] loss: 0.117\n",
      "[112, 300] loss: 0.132\n",
      "[112, 360] loss: 0.125\n",
      "Epoch: 112 -> Loss: 0.12895847857\n",
      "Epoch: 112 -> Test Accuracy: 87.76\n",
      "[113, 60] loss: 0.118\n",
      "[113, 120] loss: 0.117\n",
      "[113, 180] loss: 0.116\n",
      "[113, 240] loss: 0.127\n",
      "[113, 300] loss: 0.131\n",
      "[113, 360] loss: 0.133\n",
      "Epoch: 113 -> Loss: 0.330876082182\n",
      "Epoch: 113 -> Test Accuracy: 88.17\n",
      "[114, 60] loss: 0.112\n",
      "[114, 120] loss: 0.117\n",
      "[114, 180] loss: 0.107\n",
      "[114, 240] loss: 0.112\n",
      "[114, 300] loss: 0.118\n",
      "[114, 360] loss: 0.126\n",
      "Epoch: 114 -> Loss: 0.129123345017\n",
      "Epoch: 114 -> Test Accuracy: 88.78\n",
      "[115, 60] loss: 0.099\n",
      "[115, 120] loss: 0.109\n",
      "[115, 180] loss: 0.113\n",
      "[115, 240] loss: 0.119\n",
      "[115, 300] loss: 0.119\n",
      "[115, 360] loss: 0.119\n",
      "Epoch: 115 -> Loss: 0.285219728947\n",
      "Epoch: 115 -> Test Accuracy: 87.98\n",
      "[116, 60] loss: 0.116\n",
      "[116, 120] loss: 0.117\n",
      "[116, 180] loss: 0.106\n",
      "[116, 240] loss: 0.109\n",
      "[116, 300] loss: 0.122\n",
      "[116, 360] loss: 0.143\n",
      "Epoch: 116 -> Loss: 0.264785766602\n",
      "Epoch: 116 -> Test Accuracy: 87.86\n",
      "[117, 60] loss: 0.106\n",
      "[117, 120] loss: 0.108\n",
      "[117, 180] loss: 0.108\n",
      "[117, 240] loss: 0.108\n",
      "[117, 300] loss: 0.126\n",
      "[117, 360] loss: 0.143\n",
      "Epoch: 117 -> Loss: 0.0901465266943\n",
      "Epoch: 117 -> Test Accuracy: 87.69\n",
      "[118, 60] loss: 0.107\n",
      "[118, 120] loss: 0.098\n",
      "[118, 180] loss: 0.106\n",
      "[118, 240] loss: 0.114\n",
      "[118, 300] loss: 0.122\n",
      "[118, 360] loss: 0.141\n",
      "Epoch: 118 -> Loss: 0.198692247272\n",
      "Epoch: 118 -> Test Accuracy: 88.13\n",
      "[119, 60] loss: 0.103\n",
      "[119, 120] loss: 0.102\n",
      "[119, 180] loss: 0.111\n",
      "[119, 240] loss: 0.122\n",
      "[119, 300] loss: 0.134\n",
      "[119, 360] loss: 0.121\n",
      "Epoch: 119 -> Loss: 0.0778808370233\n",
      "Epoch: 119 -> Test Accuracy: 88.49\n",
      "[120, 60] loss: 0.118\n",
      "[120, 120] loss: 0.102\n",
      "[120, 180] loss: 0.119\n",
      "[120, 240] loss: 0.107\n",
      "[120, 300] loss: 0.113\n",
      "[120, 360] loss: 0.119\n",
      "Epoch: 120 -> Loss: 0.25483673811\n",
      "Epoch: 120 -> Test Accuracy: 88.68\n",
      "[121, 60] loss: 0.068\n",
      "[121, 120] loss: 0.050\n",
      "[121, 180] loss: 0.045\n",
      "[121, 240] loss: 0.047\n",
      "[121, 300] loss: 0.041\n",
      "[121, 360] loss: 0.037\n",
      "Epoch: 121 -> Loss: 0.0166587438434\n",
      "Epoch: 121 -> Test Accuracy: 90.73\n",
      "[122, 60] loss: 0.030\n",
      "[122, 120] loss: 0.032\n",
      "[122, 180] loss: 0.032\n",
      "[122, 240] loss: 0.034\n",
      "[122, 300] loss: 0.027\n",
      "[122, 360] loss: 0.027\n",
      "Epoch: 122 -> Loss: 0.0449775531888\n",
      "Epoch: 122 -> Test Accuracy: 91.23\n",
      "[123, 60] loss: 0.026\n",
      "[123, 120] loss: 0.024\n",
      "[123, 180] loss: 0.023\n",
      "[123, 240] loss: 0.026\n",
      "[123, 300] loss: 0.025\n",
      "[123, 360] loss: 0.025\n",
      "Epoch: 123 -> Loss: 0.0490025468171\n",
      "Epoch: 123 -> Test Accuracy: 91.31\n",
      "[124, 60] loss: 0.021\n",
      "[124, 120] loss: 0.021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[124, 180] loss: 0.023\n",
      "[124, 240] loss: 0.024\n",
      "[124, 300] loss: 0.022\n",
      "[124, 360] loss: 0.024\n",
      "Epoch: 124 -> Loss: 0.0201849993318\n",
      "Epoch: 124 -> Test Accuracy: 91.13\n",
      "[125, 60] loss: 0.019\n",
      "[125, 120] loss: 0.019\n",
      "[125, 180] loss: 0.020\n",
      "[125, 240] loss: 0.017\n",
      "[125, 300] loss: 0.021\n",
      "[125, 360] loss: 0.019\n",
      "Epoch: 125 -> Loss: 0.0156586822122\n",
      "Epoch: 125 -> Test Accuracy: 91.49\n",
      "[126, 60] loss: 0.019\n",
      "[126, 120] loss: 0.016\n",
      "[126, 180] loss: 0.016\n",
      "[126, 240] loss: 0.015\n",
      "[126, 300] loss: 0.017\n",
      "[126, 360] loss: 0.018\n",
      "Epoch: 126 -> Loss: 0.0122456075624\n",
      "Epoch: 126 -> Test Accuracy: 91.34\n",
      "[127, 60] loss: 0.015\n",
      "[127, 120] loss: 0.017\n",
      "[127, 180] loss: 0.017\n",
      "[127, 240] loss: 0.015\n",
      "[127, 300] loss: 0.016\n",
      "[127, 360] loss: 0.017\n",
      "Epoch: 127 -> Loss: 0.0120175955817\n",
      "Epoch: 127 -> Test Accuracy: 91.11\n",
      "[128, 60] loss: 0.016\n",
      "[128, 120] loss: 0.016\n",
      "[128, 180] loss: 0.016\n",
      "[128, 240] loss: 0.015\n",
      "[128, 300] loss: 0.015\n",
      "[128, 360] loss: 0.015\n",
      "Epoch: 128 -> Loss: 0.0307856090367\n",
      "Epoch: 128 -> Test Accuracy: 91.33\n",
      "[129, 60] loss: 0.013\n",
      "[129, 120] loss: 0.014\n",
      "[129, 180] loss: 0.015\n",
      "[129, 240] loss: 0.015\n",
      "[129, 300] loss: 0.014\n",
      "[129, 360] loss: 0.016\n",
      "Epoch: 129 -> Loss: 0.0555124171078\n",
      "Epoch: 129 -> Test Accuracy: 91.47\n",
      "[130, 60] loss: 0.013\n",
      "[130, 120] loss: 0.014\n",
      "[130, 180] loss: 0.015\n",
      "[130, 240] loss: 0.015\n",
      "[130, 300] loss: 0.013\n",
      "[130, 360] loss: 0.014\n",
      "Epoch: 130 -> Loss: 0.00895470939577\n",
      "Epoch: 130 -> Test Accuracy: 91.47\n",
      "[131, 60] loss: 0.012\n",
      "[131, 120] loss: 0.013\n",
      "[131, 180] loss: 0.013\n",
      "[131, 240] loss: 0.013\n",
      "[131, 300] loss: 0.012\n",
      "[131, 360] loss: 0.012\n",
      "Epoch: 131 -> Loss: 0.00797808729112\n",
      "Epoch: 131 -> Test Accuracy: 91.42\n",
      "[132, 60] loss: 0.012\n",
      "[132, 120] loss: 0.013\n",
      "[132, 180] loss: 0.013\n",
      "[132, 240] loss: 0.013\n",
      "[132, 300] loss: 0.014\n",
      "[132, 360] loss: 0.013\n",
      "Epoch: 132 -> Loss: 0.022483009845\n",
      "Epoch: 132 -> Test Accuracy: 91.34\n",
      "[133, 60] loss: 0.011\n",
      "[133, 120] loss: 0.014\n",
      "[133, 180] loss: 0.013\n",
      "[133, 240] loss: 0.012\n",
      "[133, 300] loss: 0.013\n",
      "[133, 360] loss: 0.012\n",
      "Epoch: 133 -> Loss: 0.00606880802661\n",
      "Epoch: 133 -> Test Accuracy: 91.4\n",
      "[134, 60] loss: 0.012\n",
      "[134, 120] loss: 0.011\n",
      "[134, 180] loss: 0.011\n",
      "[134, 240] loss: 0.012\n",
      "[134, 300] loss: 0.011\n",
      "[134, 360] loss: 0.014\n",
      "Epoch: 134 -> Loss: 0.0155745446682\n",
      "Epoch: 134 -> Test Accuracy: 91.38\n",
      "[135, 60] loss: 0.012\n",
      "[135, 120] loss: 0.012\n",
      "[135, 180] loss: 0.012\n",
      "[135, 240] loss: 0.011\n",
      "[135, 300] loss: 0.013\n",
      "[135, 360] loss: 0.013\n",
      "Epoch: 135 -> Loss: 0.0103165153414\n",
      "Epoch: 135 -> Test Accuracy: 91.5\n",
      "[136, 60] loss: 0.011\n",
      "[136, 120] loss: 0.010\n",
      "[136, 180] loss: 0.010\n",
      "[136, 240] loss: 0.010\n",
      "[136, 300] loss: 0.013\n",
      "[136, 360] loss: 0.012\n",
      "Epoch: 136 -> Loss: 0.00597938895226\n",
      "Epoch: 136 -> Test Accuracy: 91.13\n",
      "[137, 60] loss: 0.011\n",
      "[137, 120] loss: 0.010\n",
      "[137, 180] loss: 0.012\n",
      "[137, 240] loss: 0.010\n",
      "[137, 300] loss: 0.012\n",
      "[137, 360] loss: 0.011\n",
      "Epoch: 137 -> Loss: 0.0547363162041\n",
      "Epoch: 137 -> Test Accuracy: 91.15\n",
      "[138, 60] loss: 0.011\n",
      "[138, 120] loss: 0.011\n",
      "[138, 180] loss: 0.011\n",
      "[138, 240] loss: 0.010\n",
      "[138, 300] loss: 0.012\n",
      "[138, 360] loss: 0.012\n",
      "Epoch: 138 -> Loss: 0.00685435533524\n",
      "Epoch: 138 -> Test Accuracy: 91.36\n",
      "[139, 60] loss: 0.011\n",
      "[139, 120] loss: 0.011\n",
      "[139, 180] loss: 0.011\n",
      "[139, 240] loss: 0.010\n",
      "[139, 300] loss: 0.011\n",
      "[139, 360] loss: 0.011\n",
      "Epoch: 139 -> Loss: 0.0346342995763\n",
      "Epoch: 139 -> Test Accuracy: 91.12\n",
      "[140, 60] loss: 0.009\n",
      "[140, 120] loss: 0.010\n",
      "[140, 180] loss: 0.011\n",
      "[140, 240] loss: 0.011\n",
      "[140, 300] loss: 0.011\n",
      "[140, 360] loss: 0.012\n",
      "Epoch: 140 -> Loss: 0.00554644456133\n",
      "Epoch: 140 -> Test Accuracy: 91.13\n",
      "[141, 60] loss: 0.011\n",
      "[141, 120] loss: 0.011\n",
      "[141, 180] loss: 0.010\n",
      "[141, 240] loss: 0.011\n",
      "[141, 300] loss: 0.011\n",
      "[141, 360] loss: 0.010\n",
      "Epoch: 141 -> Loss: 0.0361941456795\n",
      "Epoch: 141 -> Test Accuracy: 91.22\n",
      "[142, 60] loss: 0.010\n",
      "[142, 120] loss: 0.010\n",
      "[142, 180] loss: 0.009\n",
      "[142, 240] loss: 0.011\n",
      "[142, 300] loss: 0.010\n",
      "[142, 360] loss: 0.011\n",
      "Epoch: 142 -> Loss: 0.0091309491545\n",
      "Epoch: 142 -> Test Accuracy: 91.3\n",
      "[143, 60] loss: 0.009\n",
      "[143, 120] loss: 0.009\n",
      "[143, 180] loss: 0.011\n",
      "[143, 240] loss: 0.011\n",
      "[143, 300] loss: 0.010\n",
      "[143, 360] loss: 0.011\n",
      "Epoch: 143 -> Loss: 0.0110050383955\n",
      "Epoch: 143 -> Test Accuracy: 91.16\n",
      "[144, 60] loss: 0.010\n",
      "[144, 120] loss: 0.009\n",
      "[144, 180] loss: 0.009\n",
      "[144, 240] loss: 0.011\n",
      "[144, 300] loss: 0.009\n",
      "[144, 360] loss: 0.010\n",
      "Epoch: 144 -> Loss: 0.00874240417033\n",
      "Epoch: 144 -> Test Accuracy: 91.29\n",
      "[145, 60] loss: 0.009\n",
      "[145, 120] loss: 0.009\n",
      "[145, 180] loss: 0.009\n",
      "[145, 240] loss: 0.008\n",
      "[145, 300] loss: 0.009\n",
      "[145, 360] loss: 0.011\n",
      "Epoch: 145 -> Loss: 0.016263872385\n",
      "Epoch: 145 -> Test Accuracy: 91.49\n",
      "[146, 60] loss: 0.010\n",
      "[146, 120] loss: 0.010\n",
      "[146, 180] loss: 0.010\n",
      "[146, 240] loss: 0.010\n",
      "[146, 300] loss: 0.011\n",
      "[146, 360] loss: 0.010\n",
      "Epoch: 146 -> Loss: 0.0162814706564\n",
      "Epoch: 146 -> Test Accuracy: 91.18\n",
      "[147, 60] loss: 0.010\n",
      "[147, 120] loss: 0.009\n",
      "[147, 180] loss: 0.008\n",
      "[147, 240] loss: 0.010\n",
      "[147, 300] loss: 0.010\n",
      "[147, 360] loss: 0.011\n",
      "Epoch: 147 -> Loss: 0.0126902610064\n",
      "Epoch: 147 -> Test Accuracy: 91.51\n",
      "[148, 60] loss: 0.008\n",
      "[148, 120] loss: 0.008\n",
      "[148, 180] loss: 0.010\n",
      "[148, 240] loss: 0.009\n",
      "[148, 300] loss: 0.010\n",
      "[148, 360] loss: 0.009\n",
      "Epoch: 148 -> Loss: 0.020275592804\n",
      "Epoch: 148 -> Test Accuracy: 91.25\n",
      "[149, 60] loss: 0.008\n",
      "[149, 120] loss: 0.009\n",
      "[149, 180] loss: 0.009\n",
      "[149, 240] loss: 0.010\n",
      "[149, 300] loss: 0.009\n",
      "[149, 360] loss: 0.009\n",
      "Epoch: 149 -> Loss: 0.0127156255767\n",
      "Epoch: 149 -> Test Accuracy: 91.49\n",
      "[150, 60] loss: 0.009\n",
      "[150, 120] loss: 0.010\n",
      "[150, 180] loss: 0.009\n",
      "[150, 240] loss: 0.008\n",
      "[150, 300] loss: 0.010\n",
      "[150, 360] loss: 0.010\n",
      "Epoch: 150 -> Loss: 0.00300350785255\n",
      "Epoch: 150 -> Test Accuracy: 91.49\n",
      "[151, 60] loss: 0.008\n",
      "[151, 120] loss: 0.009\n",
      "[151, 180] loss: 0.010\n",
      "[151, 240] loss: 0.009\n",
      "[151, 300] loss: 0.009\n",
      "[151, 360] loss: 0.010\n",
      "Epoch: 151 -> Loss: 0.0234811846167\n",
      "Epoch: 151 -> Test Accuracy: 91.29\n",
      "[152, 60] loss: 0.008\n",
      "[152, 120] loss: 0.008\n",
      "[152, 180] loss: 0.009\n",
      "[152, 240] loss: 0.010\n",
      "[152, 300] loss: 0.008\n",
      "[152, 360] loss: 0.009\n",
      "Epoch: 152 -> Loss: 0.0054589509964\n",
      "Epoch: 152 -> Test Accuracy: 91.5\n",
      "[153, 60] loss: 0.009\n",
      "[153, 120] loss: 0.009\n",
      "[153, 180] loss: 0.009\n",
      "[153, 240] loss: 0.009\n",
      "[153, 300] loss: 0.009\n",
      "[153, 360] loss: 0.009\n",
      "Epoch: 153 -> Loss: 0.00614715227857\n",
      "Epoch: 153 -> Test Accuracy: 91.54\n",
      "[154, 60] loss: 0.008\n",
      "[154, 120] loss: 0.009\n",
      "[154, 180] loss: 0.009\n",
      "[154, 240] loss: 0.008\n",
      "[154, 300] loss: 0.009\n",
      "[154, 360] loss: 0.009\n",
      "Epoch: 154 -> Loss: 0.0139436218888\n",
      "Epoch: 154 -> Test Accuracy: 91.22\n",
      "[155, 60] loss: 0.009\n",
      "[155, 120] loss: 0.008\n",
      "[155, 180] loss: 0.009\n",
      "[155, 240] loss: 0.009\n",
      "[155, 300] loss: 0.009\n",
      "[155, 360] loss: 0.010\n",
      "Epoch: 155 -> Loss: 0.00624769926071\n",
      "Epoch: 155 -> Test Accuracy: 91.41\n",
      "[156, 60] loss: 0.008\n",
      "[156, 120] loss: 0.008\n",
      "[156, 180] loss: 0.008\n",
      "[156, 240] loss: 0.009\n",
      "[156, 300] loss: 0.009\n",
      "[156, 360] loss: 0.008\n",
      "Epoch: 156 -> Loss: 0.015930974856\n",
      "Epoch: 156 -> Test Accuracy: 91.3\n",
      "[157, 60] loss: 0.008\n",
      "[157, 120] loss: 0.008\n",
      "[157, 180] loss: 0.008\n",
      "[157, 240] loss: 0.008\n",
      "[157, 300] loss: 0.010\n",
      "[157, 360] loss: 0.010\n",
      "Epoch: 157 -> Loss: 0.0127252433449\n",
      "Epoch: 157 -> Test Accuracy: 91.38\n",
      "[158, 60] loss: 0.009\n",
      "[158, 120] loss: 0.008\n",
      "[158, 180] loss: 0.008\n",
      "[158, 240] loss: 0.008\n",
      "[158, 300] loss: 0.008\n",
      "[158, 360] loss: 0.008\n",
      "Epoch: 158 -> Loss: 0.00696393847466\n",
      "Epoch: 158 -> Test Accuracy: 91.34\n",
      "[159, 60] loss: 0.007\n",
      "[159, 120] loss: 0.008\n",
      "[159, 180] loss: 0.011\n",
      "[159, 240] loss: 0.009\n",
      "[159, 300] loss: 0.009\n",
      "[159, 360] loss: 0.009\n",
      "Epoch: 159 -> Loss: 0.0100853415206\n",
      "Epoch: 159 -> Test Accuracy: 91.11\n",
      "[160, 60] loss: 0.008\n",
      "[160, 120] loss: 0.008\n",
      "[160, 180] loss: 0.008\n",
      "[160, 240] loss: 0.009\n",
      "[160, 300] loss: 0.009\n",
      "[160, 360] loss: 0.009\n",
      "Epoch: 160 -> Loss: 0.0136440750211\n",
      "Epoch: 160 -> Test Accuracy: 91.39\n",
      "[161, 60] loss: 0.008\n",
      "[161, 120] loss: 0.008\n",
      "[161, 180] loss: 0.007\n",
      "[161, 240] loss: 0.008\n",
      "[161, 300] loss: 0.007\n",
      "[161, 360] loss: 0.007\n",
      "Epoch: 161 -> Loss: 0.00373929133639\n",
      "Epoch: 161 -> Test Accuracy: 91.41\n",
      "[162, 60] loss: 0.007\n",
      "[162, 120] loss: 0.007\n",
      "[162, 180] loss: 0.007\n",
      "[162, 240] loss: 0.008\n",
      "[162, 300] loss: 0.007\n",
      "[162, 360] loss: 0.007\n",
      "Epoch: 162 -> Loss: 0.00806639157236\n",
      "Epoch: 162 -> Test Accuracy: 91.3\n",
      "[163, 60] loss: 0.008\n",
      "[163, 120] loss: 0.006\n",
      "[163, 180] loss: 0.007\n",
      "[163, 240] loss: 0.007\n",
      "[163, 300] loss: 0.007\n",
      "[163, 360] loss: 0.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 163 -> Loss: 0.00582162756473\n",
      "Epoch: 163 -> Test Accuracy: 91.28\n",
      "[164, 60] loss: 0.007\n",
      "[164, 120] loss: 0.007\n",
      "[164, 180] loss: 0.007\n",
      "[164, 240] loss: 0.006\n",
      "[164, 300] loss: 0.007\n",
      "[164, 360] loss: 0.007\n",
      "Epoch: 164 -> Loss: 0.00586801767349\n",
      "Epoch: 164 -> Test Accuracy: 91.46\n",
      "[165, 60] loss: 0.006\n",
      "[165, 120] loss: 0.007\n",
      "[165, 180] loss: 0.007\n",
      "[165, 240] loss: 0.007\n",
      "[165, 300] loss: 0.007\n",
      "[165, 360] loss: 0.007\n",
      "Epoch: 165 -> Loss: 0.0117396656424\n",
      "Epoch: 165 -> Test Accuracy: 91.41\n",
      "[166, 60] loss: 0.006\n",
      "[166, 120] loss: 0.006\n",
      "[166, 180] loss: 0.007\n",
      "[166, 240] loss: 0.006\n",
      "[166, 300] loss: 0.006\n",
      "[166, 360] loss: 0.007\n",
      "Epoch: 166 -> Loss: 0.00971355475485\n",
      "Epoch: 166 -> Test Accuracy: 91.47\n",
      "[167, 60] loss: 0.006\n",
      "[167, 120] loss: 0.007\n",
      "[167, 180] loss: 0.006\n",
      "[167, 240] loss: 0.006\n",
      "[167, 300] loss: 0.007\n",
      "[167, 360] loss: 0.007\n",
      "Epoch: 167 -> Loss: 0.0403599776328\n",
      "Epoch: 167 -> Test Accuracy: 91.45\n",
      "[168, 60] loss: 0.006\n",
      "[168, 120] loss: 0.008\n",
      "[168, 180] loss: 0.007\n",
      "[168, 240] loss: 0.006\n",
      "[168, 300] loss: 0.006\n",
      "[168, 360] loss: 0.007\n",
      "Epoch: 168 -> Loss: 0.00487707834691\n",
      "Epoch: 168 -> Test Accuracy: 91.42\n",
      "[169, 60] loss: 0.006\n",
      "[169, 120] loss: 0.006\n",
      "[169, 180] loss: 0.007\n",
      "[169, 240] loss: 0.007\n",
      "[169, 300] loss: 0.007\n",
      "[169, 360] loss: 0.006\n",
      "Epoch: 169 -> Loss: 0.00791093427688\n",
      "Epoch: 169 -> Test Accuracy: 91.47\n",
      "[170, 60] loss: 0.007\n",
      "[170, 120] loss: 0.006\n",
      "[170, 180] loss: 0.006\n",
      "[170, 240] loss: 0.007\n",
      "[170, 300] loss: 0.007\n",
      "[170, 360] loss: 0.007\n",
      "Epoch: 170 -> Loss: 0.00809314846992\n",
      "Epoch: 170 -> Test Accuracy: 91.48\n",
      "[171, 60] loss: 0.007\n",
      "[171, 120] loss: 0.006\n",
      "[171, 180] loss: 0.007\n",
      "[171, 240] loss: 0.007\n",
      "[171, 300] loss: 0.007\n",
      "[171, 360] loss: 0.007\n",
      "Epoch: 171 -> Loss: 0.00212160940282\n",
      "Epoch: 171 -> Test Accuracy: 91.4\n",
      "[172, 60] loss: 0.006\n",
      "[172, 120] loss: 0.006\n",
      "[172, 180] loss: 0.006\n",
      "[172, 240] loss: 0.006\n",
      "[172, 300] loss: 0.007\n",
      "[172, 360] loss: 0.007\n",
      "Epoch: 172 -> Loss: 0.0112671349198\n",
      "Epoch: 172 -> Test Accuracy: 91.4\n",
      "[173, 60] loss: 0.007\n",
      "[173, 120] loss: 0.007\n",
      "[173, 180] loss: 0.006\n",
      "[173, 240] loss: 0.006\n",
      "[173, 300] loss: 0.006\n",
      "[173, 360] loss: 0.006\n",
      "Epoch: 173 -> Loss: 0.0168770290911\n",
      "Epoch: 173 -> Test Accuracy: 91.51\n",
      "[174, 60] loss: 0.007\n",
      "[174, 120] loss: 0.007\n",
      "[174, 180] loss: 0.007\n",
      "[174, 240] loss: 0.007\n",
      "[174, 300] loss: 0.006\n",
      "[174, 360] loss: 0.006\n",
      "Epoch: 174 -> Loss: 0.00415189284831\n",
      "Epoch: 174 -> Test Accuracy: 91.38\n",
      "[175, 60] loss: 0.007\n",
      "[175, 120] loss: 0.006\n",
      "[175, 180] loss: 0.007\n",
      "[175, 240] loss: 0.006\n",
      "[175, 300] loss: 0.007\n",
      "[175, 360] loss: 0.006\n",
      "Epoch: 175 -> Loss: 0.0119191827253\n",
      "Epoch: 175 -> Test Accuracy: 91.45\n",
      "[176, 60] loss: 0.006\n",
      "[176, 120] loss: 0.007\n",
      "[176, 180] loss: 0.007\n",
      "[176, 240] loss: 0.007\n",
      "[176, 300] loss: 0.007\n",
      "[176, 360] loss: 0.006\n",
      "Epoch: 176 -> Loss: 0.00562016386539\n",
      "Epoch: 176 -> Test Accuracy: 91.47\n",
      "[177, 60] loss: 0.006\n",
      "[177, 120] loss: 0.006\n",
      "[177, 180] loss: 0.006\n",
      "[177, 240] loss: 0.006\n",
      "[177, 300] loss: 0.007\n",
      "[177, 360] loss: 0.006\n",
      "Epoch: 177 -> Loss: 0.0143032129854\n",
      "Epoch: 177 -> Test Accuracy: 91.47\n",
      "[178, 60] loss: 0.006\n",
      "[178, 120] loss: 0.006\n",
      "[178, 180] loss: 0.006\n",
      "[178, 240] loss: 0.006\n",
      "[178, 300] loss: 0.007\n",
      "[178, 360] loss: 0.007\n",
      "Epoch: 178 -> Loss: 0.0209115445614\n",
      "Epoch: 178 -> Test Accuracy: 91.47\n",
      "[179, 60] loss: 0.006\n",
      "[179, 120] loss: 0.006\n",
      "[179, 180] loss: 0.007\n",
      "[179, 240] loss: 0.006\n",
      "[179, 300] loss: 0.007\n",
      "[179, 360] loss: 0.007\n",
      "Epoch: 179 -> Loss: 0.0109032988548\n",
      "Epoch: 179 -> Test Accuracy: 91.52\n",
      "[180, 60] loss: 0.006\n",
      "[180, 120] loss: 0.006\n",
      "[180, 180] loss: 0.007\n",
      "[180, 240] loss: 0.006\n",
      "[180, 300] loss: 0.006\n",
      "[180, 360] loss: 0.006\n",
      "Epoch: 180 -> Loss: 0.0105479899794\n",
      "Epoch: 180 -> Test Accuracy: 91.46\n",
      "[181, 60] loss: 0.007\n",
      "[181, 120] loss: 0.006\n",
      "[181, 180] loss: 0.007\n",
      "[181, 240] loss: 0.006\n",
      "[181, 300] loss: 0.007\n",
      "[181, 360] loss: 0.006\n",
      "Epoch: 181 -> Loss: 0.0097231362015\n",
      "Epoch: 181 -> Test Accuracy: 91.61\n",
      "[182, 60] loss: 0.006\n",
      "[182, 120] loss: 0.006\n",
      "[182, 180] loss: 0.007\n",
      "[182, 240] loss: 0.006\n",
      "[182, 300] loss: 0.006\n",
      "[182, 360] loss: 0.007\n",
      "Epoch: 182 -> Loss: 0.00543224811554\n",
      "Epoch: 182 -> Test Accuracy: 91.48\n",
      "[183, 60] loss: 0.006\n",
      "[183, 120] loss: 0.006\n",
      "[183, 180] loss: 0.006\n",
      "[183, 240] loss: 0.006\n",
      "[183, 300] loss: 0.007\n",
      "[183, 360] loss: 0.007\n",
      "Epoch: 183 -> Loss: 0.00244917860255\n",
      "Epoch: 183 -> Test Accuracy: 91.38\n",
      "[184, 60] loss: 0.007\n",
      "[184, 120] loss: 0.006\n",
      "[184, 180] loss: 0.006\n",
      "[184, 240] loss: 0.006\n",
      "[184, 300] loss: 0.007\n",
      "[184, 360] loss: 0.007\n",
      "Epoch: 184 -> Loss: 0.00776959676296\n",
      "Epoch: 184 -> Test Accuracy: 91.4\n",
      "[185, 60] loss: 0.006\n",
      "[185, 120] loss: 0.006\n",
      "[185, 180] loss: 0.006\n",
      "[185, 240] loss: 0.006\n",
      "[185, 300] loss: 0.007\n",
      "[185, 360] loss: 0.006\n",
      "Epoch: 185 -> Loss: 0.00604365486652\n",
      "Epoch: 185 -> Test Accuracy: 91.47\n",
      "[186, 60] loss: 0.006\n",
      "[186, 120] loss: 0.006\n",
      "[186, 180] loss: 0.006\n",
      "[186, 240] loss: 0.006\n",
      "[186, 300] loss: 0.006\n",
      "[186, 360] loss: 0.006\n",
      "Epoch: 186 -> Loss: 0.0104678990319\n",
      "Epoch: 186 -> Test Accuracy: 91.47\n",
      "[187, 60] loss: 0.006\n",
      "[187, 120] loss: 0.006\n",
      "[187, 180] loss: 0.006\n",
      "[187, 240] loss: 0.006\n",
      "[187, 300] loss: 0.007\n",
      "[187, 360] loss: 0.006\n",
      "Epoch: 187 -> Loss: 0.00191040034406\n",
      "Epoch: 187 -> Test Accuracy: 91.48\n",
      "[188, 60] loss: 0.006\n",
      "[188, 120] loss: 0.006\n",
      "[188, 180] loss: 0.006\n",
      "[188, 240] loss: 0.006\n",
      "[188, 300] loss: 0.006\n",
      "[188, 360] loss: 0.006\n",
      "Epoch: 188 -> Loss: 0.00542717566714\n",
      "Epoch: 188 -> Test Accuracy: 91.54\n",
      "[189, 60] loss: 0.006\n",
      "[189, 120] loss: 0.007\n",
      "[189, 180] loss: 0.006\n",
      "[189, 240] loss: 0.006\n",
      "[189, 300] loss: 0.006\n",
      "[189, 360] loss: 0.007\n",
      "Epoch: 189 -> Loss: 0.0230267643929\n",
      "Epoch: 189 -> Test Accuracy: 91.56\n",
      "[190, 60] loss: 0.006\n",
      "[190, 120] loss: 0.006\n",
      "[190, 180] loss: 0.006\n",
      "[190, 240] loss: 0.007\n",
      "[190, 300] loss: 0.006\n",
      "[190, 360] loss: 0.006\n",
      "Epoch: 190 -> Loss: 0.00615693908185\n",
      "Epoch: 190 -> Test Accuracy: 91.48\n",
      "[191, 60] loss: 0.006\n",
      "[191, 120] loss: 0.006\n",
      "[191, 180] loss: 0.007\n",
      "[191, 240] loss: 0.006\n",
      "[191, 300] loss: 0.006\n",
      "[191, 360] loss: 0.006\n",
      "Epoch: 191 -> Loss: 0.00821602903306\n",
      "Epoch: 191 -> Test Accuracy: 91.57\n",
      "[192, 60] loss: 0.007\n",
      "[192, 120] loss: 0.006\n",
      "[192, 180] loss: 0.006\n",
      "[192, 240] loss: 0.006\n",
      "[192, 300] loss: 0.006\n",
      "[192, 360] loss: 0.007\n",
      "Epoch: 192 -> Loss: 0.00445920228958\n",
      "Epoch: 192 -> Test Accuracy: 91.53\n",
      "[193, 60] loss: 0.006\n",
      "[193, 120] loss: 0.006\n",
      "[193, 180] loss: 0.006\n",
      "[193, 240] loss: 0.007\n",
      "[193, 300] loss: 0.006\n",
      "[193, 360] loss: 0.006\n",
      "Epoch: 193 -> Loss: 0.00561681995168\n",
      "Epoch: 193 -> Test Accuracy: 91.47\n",
      "[194, 60] loss: 0.007\n",
      "[194, 120] loss: 0.006\n",
      "[194, 180] loss: 0.006\n",
      "[194, 240] loss: 0.006\n",
      "[194, 300] loss: 0.006\n",
      "[194, 360] loss: 0.006\n",
      "Epoch: 194 -> Loss: 0.00668782601133\n",
      "Epoch: 194 -> Test Accuracy: 91.48\n",
      "[195, 60] loss: 0.006\n",
      "[195, 120] loss: 0.006\n",
      "[195, 180] loss: 0.007\n",
      "[195, 240] loss: 0.007\n",
      "[195, 300] loss: 0.006\n",
      "[195, 360] loss: 0.006\n",
      "Epoch: 195 -> Loss: 0.00895405374467\n",
      "Epoch: 195 -> Test Accuracy: 91.53\n",
      "[196, 60] loss: 0.006\n",
      "[196, 120] loss: 0.007\n",
      "[196, 180] loss: 0.006\n",
      "[196, 240] loss: 0.006\n",
      "[196, 300] loss: 0.007\n",
      "[196, 360] loss: 0.006\n",
      "Epoch: 196 -> Loss: 0.00762928137556\n",
      "Epoch: 196 -> Test Accuracy: 91.36\n",
      "[197, 60] loss: 0.006\n",
      "[197, 120] loss: 0.006\n",
      "[197, 180] loss: 0.006\n",
      "[197, 240] loss: 0.006\n",
      "[197, 300] loss: 0.006\n",
      "[197, 360] loss: 0.006\n",
      "Epoch: 197 -> Loss: 0.00977300386876\n",
      "Epoch: 197 -> Test Accuracy: 91.33\n",
      "[198, 60] loss: 0.006\n",
      "[198, 120] loss: 0.006\n",
      "[198, 180] loss: 0.007\n",
      "[198, 240] loss: 0.006\n",
      "[198, 300] loss: 0.006\n",
      "[198, 360] loss: 0.006\n",
      "Epoch: 198 -> Loss: 0.00871241092682\n",
      "Epoch: 198 -> Test Accuracy: 91.44\n",
      "[199, 60] loss: 0.006\n",
      "[199, 120] loss: 0.007\n",
      "[199, 180] loss: 0.006\n",
      "[199, 240] loss: 0.007\n",
      "[199, 300] loss: 0.007\n",
      "[199, 360] loss: 0.006\n",
      "Epoch: 199 -> Loss: 0.00677056331187\n",
      "Epoch: 199 -> Test Accuracy: 91.56\n",
      "[200, 60] loss: 0.006\n",
      "[200, 120] loss: 0.006\n",
      "[200, 180] loss: 0.006\n",
      "[200, 240] loss: 0.006\n",
      "[200, 300] loss: 0.006\n",
      "[200, 360] loss: 0.007\n",
      "Epoch: 200 -> Loss: 0.0154286148027\n",
      "Epoch: 200 -> Test Accuracy: 91.55\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# train 3 block RotNet on classification task\n",
    "class_NIN_loss_log, _, class_NIN_test_accuracy_log, _, _ = tr.adaptive_learning([0.1, 0.02, 0.004, 0.0008], \n",
    "    [60, 120, 160, 200], 0.9, 5e-4, net_class, criterion, trainloader, None, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save variables\n",
    "fm.save_variable([class_NIN_loss_log, class_NIN_test_accuracy_log], \"supervised_NIN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize networks\n",
    "semi_net = fm.load_net(\"RotNet_rotation_200_4_block_net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 -> Loss: 2.5183327198\n",
      "Epoch: 1 -> Test Accuracy: 34.39\n",
      "Epoch: 2 -> Loss: 1.3776679039\n",
      "Epoch: 2 -> Test Accuracy: 48.19\n",
      "Epoch: 3 -> Loss: 0.986231267452\n",
      "Epoch: 3 -> Test Accuracy: 54.01\n",
      "Epoch: 4 -> Loss: 0.719306468964\n",
      "Epoch: 4 -> Test Accuracy: 57.46\n",
      "Epoch: 5 -> Loss: 0.477100372314\n",
      "Epoch: 5 -> Test Accuracy: 58.43\n",
      "Epoch: 6 -> Loss: 0.42391577363\n",
      "Epoch: 6 -> Test Accuracy: 59.69\n",
      "Epoch: 7 -> Loss: 0.285415709019\n",
      "Epoch: 7 -> Test Accuracy: 60.01\n",
      "Epoch: 8 -> Loss: 0.238389223814\n",
      "Epoch: 8 -> Test Accuracy: 60.15\n",
      "Epoch: 9 -> Loss: 0.202291429043\n",
      "Epoch: 9 -> Test Accuracy: 60.49\n",
      "Epoch: 10 -> Loss: 0.115706339478\n",
      "Epoch: 10 -> Test Accuracy: 61.01\n",
      "Epoch: 11 -> Loss: 0.106966279447\n",
      "Epoch: 11 -> Test Accuracy: 60.95\n",
      "Epoch: 12 -> Loss: 0.100582882762\n",
      "Epoch: 12 -> Test Accuracy: 60.91\n",
      "Epoch: 13 -> Loss: 0.0855379924178\n",
      "Epoch: 13 -> Test Accuracy: 61.07\n",
      "Epoch: 14 -> Loss: 0.0876723229885\n",
      "Epoch: 14 -> Test Accuracy: 61.07\n",
      "Epoch: 15 -> Loss: 0.0521995685995\n",
      "Epoch: 15 -> Test Accuracy: 60.88\n",
      "Epoch: 16 -> Loss: 0.0443979874253\n",
      "Epoch: 16 -> Test Accuracy: 60.92\n",
      "Epoch: 17 -> Loss: 0.0424301698804\n",
      "Epoch: 17 -> Test Accuracy: 61.13\n",
      "Epoch: 18 -> Loss: 0.0302809216082\n",
      "Epoch: 18 -> Test Accuracy: 61.01\n",
      "Epoch: 19 -> Loss: 0.0288190040737\n",
      "Epoch: 19 -> Test Accuracy: 61.04\n",
      "Epoch: 20 -> Loss: 0.0190325584263\n",
      "Epoch: 20 -> Test Accuracy: 61.21\n",
      "Epoch: 21 -> Loss: 0.014446483925\n",
      "Epoch: 21 -> Test Accuracy: 61.42\n",
      "Epoch: 22 -> Loss: 0.0183068048209\n",
      "Epoch: 22 -> Test Accuracy: 61.52\n",
      "Epoch: 23 -> Loss: 0.0116540985182\n",
      "Epoch: 23 -> Test Accuracy: 61.66\n",
      "Epoch: 24 -> Loss: 0.0143347578123\n",
      "Epoch: 24 -> Test Accuracy: 61.8\n",
      "Epoch: 25 -> Loss: 0.00932855717838\n",
      "Epoch: 25 -> Test Accuracy: 61.89\n",
      "Epoch: 26 -> Loss: 0.0118578933179\n",
      "Epoch: 26 -> Test Accuracy: 61.93\n",
      "Epoch: 27 -> Loss: 0.0102749066427\n",
      "Epoch: 27 -> Test Accuracy: 62.01\n",
      "Epoch: 28 -> Loss: 0.00939391087741\n",
      "Epoch: 28 -> Test Accuracy: 62.03\n",
      "Epoch: 29 -> Loss: 0.0174409076571\n",
      "Epoch: 29 -> Test Accuracy: 62.07\n",
      "Epoch: 30 -> Loss: 0.0115684401244\n",
      "Epoch: 30 -> Test Accuracy: 62.17\n",
      "Epoch: 31 -> Loss: 0.0126049052924\n",
      "Epoch: 31 -> Test Accuracy: 62.18\n",
      "Epoch: 32 -> Loss: 0.00643984461203\n",
      "Epoch: 32 -> Test Accuracy: 62.18\n",
      "Epoch: 33 -> Loss: 0.00976192299277\n",
      "Epoch: 33 -> Test Accuracy: 62.11\n",
      "Epoch: 34 -> Loss: 0.011434382759\n",
      "Epoch: 34 -> Test Accuracy: 62.21\n",
      "Epoch: 35 -> Loss: 0.00929268822074\n",
      "Epoch: 35 -> Test Accuracy: 62.15\n",
      "Epoch: 36 -> Loss: 0.0076322555542\n",
      "Epoch: 36 -> Test Accuracy: 62.16\n",
      "Epoch: 37 -> Loss: 0.00719071738422\n",
      "Epoch: 37 -> Test Accuracy: 62.17\n",
      "Epoch: 38 -> Loss: 0.00536433188245\n",
      "Epoch: 38 -> Test Accuracy: 62.15\n",
      "Epoch: 39 -> Loss: 0.00867366790771\n",
      "Epoch: 39 -> Test Accuracy: 62.18\n",
      "Epoch: 40 -> Loss: 0.00551823107526\n",
      "Epoch: 40 -> Test Accuracy: 62.22\n",
      "Epoch: 41 -> Loss: 0.00704732863232\n",
      "Epoch: 41 -> Test Accuracy: 62.23\n",
      "Epoch: 42 -> Loss: 0.00743854045868\n",
      "Epoch: 42 -> Test Accuracy: 62.29\n",
      "Epoch: 43 -> Loss: 0.00874753110111\n",
      "Epoch: 43 -> Test Accuracy: 62.36\n",
      "Epoch: 44 -> Loss: 0.0123824477196\n",
      "Epoch: 44 -> Test Accuracy: 62.39\n",
      "Epoch: 45 -> Loss: 0.00690585374832\n",
      "Epoch: 45 -> Test Accuracy: 62.38\n",
      "Epoch: 46 -> Loss: 0.00658584944904\n",
      "Epoch: 46 -> Test Accuracy: 62.38\n",
      "Epoch: 47 -> Loss: 0.0112991528586\n",
      "Epoch: 47 -> Test Accuracy: 62.37\n",
      "Epoch: 48 -> Loss: 0.00506210979074\n",
      "Epoch: 48 -> Test Accuracy: 62.34\n",
      "Epoch: 49 -> Loss: 0.00747505156323\n",
      "Epoch: 49 -> Test Accuracy: 62.34\n",
      "Epoch: 50 -> Loss: 0.0100234746933\n",
      "Epoch: 50 -> Test Accuracy: 62.36\n",
      "Epoch: 51 -> Loss: 0.0100370384753\n",
      "Epoch: 51 -> Test Accuracy: 62.41\n",
      "Epoch: 52 -> Loss: 0.00774186849594\n",
      "Epoch: 52 -> Test Accuracy: 62.42\n",
      "Epoch: 53 -> Loss: 0.00678187608719\n",
      "Epoch: 53 -> Test Accuracy: 62.46\n",
      "Epoch: 54 -> Loss: 0.00768221728504\n",
      "Epoch: 54 -> Test Accuracy: 62.47\n",
      "Epoch: 55 -> Loss: 0.0116404891014\n",
      "Epoch: 55 -> Test Accuracy: 62.5\n",
      "Epoch: 56 -> Loss: 0.00653253681958\n",
      "Epoch: 56 -> Test Accuracy: 62.47\n",
      "Epoch: 57 -> Loss: 0.00596286868677\n",
      "Epoch: 57 -> Test Accuracy: 62.47\n",
      "Epoch: 58 -> Loss: 0.00611304584891\n",
      "Epoch: 58 -> Test Accuracy: 62.46\n",
      "Epoch: 59 -> Loss: 0.00757322041318\n",
      "Epoch: 59 -> Test Accuracy: 62.46\n",
      "Epoch: 60 -> Loss: 0.0078095132485\n",
      "Epoch: 60 -> Test Accuracy: 62.47\n",
      "Epoch: 61 -> Loss: 0.00710462220013\n",
      "Epoch: 61 -> Test Accuracy: 62.43\n",
      "Epoch: 62 -> Loss: 0.005797366146\n",
      "Epoch: 62 -> Test Accuracy: 62.43\n",
      "Epoch: 63 -> Loss: 0.00538876326755\n",
      "Epoch: 63 -> Test Accuracy: 62.45\n",
      "Epoch: 64 -> Loss: 0.0072604152374\n",
      "Epoch: 64 -> Test Accuracy: 62.42\n",
      "Epoch: 65 -> Loss: 0.00641089025885\n",
      "Epoch: 65 -> Test Accuracy: 62.43\n",
      "Epoch: 66 -> Loss: 0.00712894741446\n",
      "Epoch: 66 -> Test Accuracy: 62.4\n",
      "Epoch: 67 -> Loss: 0.00849246326834\n",
      "Epoch: 67 -> Test Accuracy: 62.39\n",
      "Epoch: 68 -> Loss: 0.00552784092724\n",
      "Epoch: 68 -> Test Accuracy: 62.37\n",
      "Epoch: 69 -> Loss: 0.005284587387\n",
      "Epoch: 69 -> Test Accuracy: 62.35\n",
      "Epoch: 70 -> Loss: 0.0046370360069\n",
      "Epoch: 70 -> Test Accuracy: 62.33\n",
      "Epoch: 71 -> Loss: 0.00387132819742\n",
      "Epoch: 71 -> Test Accuracy: 62.33\n",
      "Epoch: 72 -> Loss: 0.00571637693793\n",
      "Epoch: 72 -> Test Accuracy: 62.35\n",
      "Epoch: 73 -> Loss: 0.00462885713205\n",
      "Epoch: 73 -> Test Accuracy: 62.32\n",
      "Epoch: 74 -> Loss: 0.00520466454327\n",
      "Epoch: 74 -> Test Accuracy: 62.33\n",
      "Epoch: 75 -> Loss: 0.00672825193033\n",
      "Epoch: 75 -> Test Accuracy: 62.33\n",
      "Epoch: 76 -> Loss: 0.00568369356915\n",
      "Epoch: 76 -> Test Accuracy: 62.33\n",
      "Epoch: 77 -> Loss: 0.00685213692486\n",
      "Epoch: 77 -> Test Accuracy: 62.35\n",
      "Epoch: 78 -> Loss: 0.00540745910257\n",
      "Epoch: 78 -> Test Accuracy: 62.36\n",
      "Epoch: 79 -> Loss: 0.0047698286362\n",
      "Epoch: 79 -> Test Accuracy: 62.35\n",
      "Epoch: 80 -> Loss: 0.00732502015308\n",
      "Epoch: 80 -> Test Accuracy: 62.33\n",
      "Epoch: 81 -> Loss: 0.00602610222995\n",
      "Epoch: 81 -> Test Accuracy: 62.32\n",
      "Epoch: 82 -> Loss: 0.00778710190207\n",
      "Epoch: 82 -> Test Accuracy: 62.36\n",
      "Epoch: 83 -> Loss: 0.00774510018528\n",
      "Epoch: 83 -> Test Accuracy: 62.35\n",
      "Epoch: 84 -> Loss: 0.00572581402957\n",
      "Epoch: 84 -> Test Accuracy: 62.36\n",
      "Epoch: 85 -> Loss: 0.00522590335459\n",
      "Epoch: 85 -> Test Accuracy: 62.34\n",
      "Epoch: 86 -> Loss: 0.00448279920965\n",
      "Epoch: 86 -> Test Accuracy: 62.34\n",
      "Epoch: 87 -> Loss: 0.00548755470663\n",
      "Epoch: 87 -> Test Accuracy: 62.34\n",
      "Epoch: 88 -> Loss: 0.00577031914145\n",
      "Epoch: 88 -> Test Accuracy: 62.34\n",
      "Epoch: 89 -> Loss: 0.00458984263241\n",
      "Epoch: 89 -> Test Accuracy: 62.34\n",
      "Epoch: 90 -> Loss: 0.00727615086362\n",
      "Epoch: 90 -> Test Accuracy: 62.34\n",
      "Epoch: 91 -> Loss: 0.00637902133167\n",
      "Epoch: 91 -> Test Accuracy: 62.35\n",
      "Epoch: 92 -> Loss: 0.00646309042349\n",
      "Epoch: 92 -> Test Accuracy: 62.35\n",
      "Epoch: 93 -> Loss: 0.00486344750971\n",
      "Epoch: 93 -> Test Accuracy: 62.35\n",
      "Epoch: 94 -> Loss: 0.00533027760684\n",
      "Epoch: 94 -> Test Accuracy: 62.35\n",
      "Epoch: 95 -> Loss: 0.00744928233325\n",
      "Epoch: 95 -> Test Accuracy: 62.35\n",
      "Epoch: 96 -> Loss: 0.00865851528943\n",
      "Epoch: 96 -> Test Accuracy: 62.35\n",
      "Epoch: 97 -> Loss: 0.00565286492929\n",
      "Epoch: 97 -> Test Accuracy: 62.35\n",
      "Epoch: 98 -> Loss: 0.00445781834424\n",
      "Epoch: 98 -> Test Accuracy: 62.35\n",
      "Epoch: 99 -> Loss: 0.00548502476886\n",
      "Epoch: 99 -> Test Accuracy: 62.35\n",
      "Epoch: 100 -> Loss: 0.00656272983178\n",
      "Epoch: 100 -> Test Accuracy: 62.34\n",
      "Finished Training\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument of type 'bool' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-669c8e0102a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m semi_loss_log, semi_accuracy_log, super_loss_log, super_accuracy_log = tr.train_semi([20, 100, 400, 1000, 5000], 10, \n\u001b[1;32m      2\u001b[0m     \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.004\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0008\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m85\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.004\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0008\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                [60, 120, 160, 200], 0.9, 5e-4, semi_net, criterion)\n\u001b[0m",
      "\u001b[0;32m/home/leo/Dropbox/Bachelorarbeit/Peer Review FeatureLearningRotNet/functionalities/trainer.py\u001b[0m in \u001b[0;36mtrain_semi\u001b[0;34m(img_per_class, num_classes, trainset, testset, batch_size, semi_lr_lst, semi_epoch_change, super_lr_lst, super_epoch_change, momentum, weight_decay, rotnet, criterion, use_paper_metric)\u001b[0m\n\u001b[1;32m    379\u001b[0m         nin_tmp_loss_log, _, nin_tmp_test_accuracy_log, _, _ = adaptive_learning(super_lr_lst, super_epoch_change,\n\u001b[1;32m    380\u001b[0m             \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_paper_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                 num_img)\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0msuper_loss_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnin_tmp_loss_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/Dropbox/Bachelorarbeit/Peer Review FeatureLearningRotNet/functionalities/trainer.py\u001b[0m in \u001b[0;36madaptive_learning\u001b[0;34m(lr_list, epoch_change, momentum, weight_decay, net, criterion, trainloader, validloader, testloader, classifier, conv_block_num, rot, use_paper_metric, use_ConvClassifier, semi)\u001b[0m\n\u001b[1;32m    259\u001b[0m             train(num_epoch, net, criterion, optimizer, trainloader, validloader, testloader, classifier,\n\u001b[1;32m    260\u001b[0m                   \u001b[0mconv_block_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprinting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_paper_metric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m                   use_ConvClassifier, semi)\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mloss_log\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtmp_loss_log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/Dropbox/Bachelorarbeit/Peer Review FeatureLearningRotNet/functionalities/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_epoch, net, criterion, optimizer, trainloader, validloader, testloader, classifier, conv_block_num, epoch_offset, rot, printing, max_accuracy, best_epoch, use_paper_metric, use_ConvClassifier, semi)\u001b[0m\n\u001b[1;32m    109\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mrot_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_rot_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mrot_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrot_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leo/Dropbox/Bachelorarbeit/Peer Review FeatureLearningRotNet/functionalities/rotation.pyc\u001b[0m in \u001b[0;36mcreate_rot_batch\u001b[0;34m(images, labels, rot)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m'90'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mimages_rot90\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrot90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mrot_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrot_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages_rot90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'bool' is not iterable"
     ]
    }
   ],
   "source": [
    "semi_loss_log, semi_accuracy_log, super_loss_log, super_accuracy_log = tr.train_semi([20, 100, 400, 1000, 5000], 10, \n",
    "    trainset, testset, 128, [0.1, 0.02, 0.004, 0.0008], [35, 70, 85, 100], [0.1, 0.02, 0.004, 0.0008],\n",
    "               [60, 120, 160, 200], 0.9, 5e-4, semi_net, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save variables\n",
    "fm.save_variable([semi_loss_log, semi_accuracy_log, super_loss_log, super_accuracy_log], \"semi-supervised\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Test Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RotNet model with 3 Convolutional Blocks:\n",
      "()\n",
      "Evaluating Rotation Task:\n",
      "Test Accuracy:  92.180 %\n",
      "Test Accuracy of original :  92.190 %\n",
      "Test Accuracy of 90 rotation :  92.360 %\n",
      "Test Accuracy of 180 rotation :  92.010 %\n",
      "Test Accuracy of 270 rotation :  92.160 %\n",
      "()\n",
      "--------------------------------------------------------------------------------\n",
      "()\n",
      "Starting to evaluate Non-Linear Classifier:\n",
      "()\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 1:\n",
      "Test Accuracy:  83.110 %\n",
      "Test Accuracy of plane :  85.100 %\n",
      "Test Accuracy of car :  90.400 %\n",
      "Test Accuracy of bird :  74.800 %\n",
      "Test Accuracy of cat :  69.400 %\n",
      "Test Accuracy of deer :  80.200 %\n",
      "Test Accuracy of dog :  73.700 %\n",
      "Test Accuracy of frog :  88.200 %\n",
      "Test Accuracy of horse :  87.900 %\n",
      "Test Accuracy of ship :  90.500 %\n",
      "Test Accuracy of truck :  90.900 %\n",
      "()\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 2:\n",
      "Test Accuracy:  86.540 %\n",
      "Test Accuracy of plane :  88.600 %\n",
      "Test Accuracy of car :  92.500 %\n",
      "Test Accuracy of bird :  81.600 %\n",
      "Test Accuracy of cat :  77.100 %\n",
      "Test Accuracy of deer :  85.500 %\n",
      "Test Accuracy of dog :  78.800 %\n",
      "Test Accuracy of frog :  89.700 %\n",
      "Test Accuracy of horse :  88.300 %\n",
      "Test Accuracy of ship :  92.800 %\n",
      "Test Accuracy of truck :  90.500 %\n",
      "()\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 3:\n",
      "Test Accuracy:  53.600 %\n",
      "Test Accuracy of plane :  63.000 %\n",
      "Test Accuracy of car :  56.100 %\n",
      "Test Accuracy of bird :  42.200 %\n",
      "Test Accuracy of cat :  38.700 %\n",
      "Test Accuracy of deer :  45.100 %\n",
      "Test Accuracy of dog :  52.500 %\n",
      "Test Accuracy of frog :  58.400 %\n",
      "Test Accuracy of horse :  53.500 %\n",
      "Test Accuracy of ship :  60.400 %\n",
      "Test Accuracy of truck :  66.100 %\n",
      "()\n",
      "--------------------------------------------------------------------------------\n",
      "()\n",
      "Starting to evaluate Convolutional Classifier:\n",
      "()\n",
      "Evaluating Convolutional Classifier on Convolutional Block 1\n",
      "Test Accuracy:  86.400 %\n",
      "Test Accuracy of plane :  87.300 %\n",
      "Test Accuracy of car :  93.700 %\n",
      "Test Accuracy of bird :  80.000 %\n",
      "Test Accuracy of cat :  77.500 %\n",
      "Test Accuracy of deer :  84.000 %\n",
      "Test Accuracy of dog :  80.000 %\n",
      "Test Accuracy of frog :  89.600 %\n",
      "Test Accuracy of horse :  88.700 %\n",
      "Test Accuracy of ship :  90.800 %\n",
      "Test Accuracy of truck :  92.400 %\n",
      "()\n",
      "Evaluating Convolutional Classifier on Convolutional Block 2\n",
      "Test Accuracy:  88.710 %\n",
      "Test Accuracy of plane :  89.200 %\n",
      "Test Accuracy of car :  93.900 %\n",
      "Test Accuracy of bird :  83.500 %\n",
      "Test Accuracy of cat :  80.500 %\n",
      "Test Accuracy of deer :  90.600 %\n",
      "Test Accuracy of dog :  82.700 %\n",
      "Test Accuracy of frog :  93.100 %\n",
      "Test Accuracy of horse :  90.200 %\n",
      "Test Accuracy of ship :  92.700 %\n",
      "Test Accuracy of truck :  90.700 %\n",
      "()\n",
      "Evaluating Convolutional Classifier on Convolutional Block 3\n",
      "Test Accuracy:  62.750 %\n",
      "Test Accuracy of plane :  68.400 %\n",
      "Test Accuracy of car :  65.400 %\n",
      "Test Accuracy of bird :  47.000 %\n",
      "Test Accuracy of cat :  49.900 %\n",
      "Test Accuracy of deer :  58.300 %\n",
      "Test Accuracy of dog :  57.200 %\n",
      "Test Accuracy of frog :  74.300 %\n",
      "Test Accuracy of horse :  65.500 %\n",
      "Test Accuracy of ship :  70.500 %\n",
      "Test Accuracy of truck :  71.000 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy ConvClassifier ConvBlock 1': 86.4,\n",
       " 'Accuracy ConvClassifier ConvBlock 2': 88.71,\n",
       " 'Accuracy ConvClassifier ConvBlock 3': 62.75,\n",
       " 'Accuracy Non-Linear ConvBlock 1': 83.11,\n",
       " 'Accuracy Non-Linear ConvBlock 2': 86.54,\n",
       " 'Accuracy Non-Linear ConvBlock 3': 53.6,\n",
       " 'Accuracy Rotation Task': 92.18,\n",
       " 'Class Accuracy ConvClassifier ConvBlock 1': [87.3,\n",
       "  93.7,\n",
       "  80.0,\n",
       "  77.5,\n",
       "  84.0,\n",
       "  80.0,\n",
       "  89.6,\n",
       "  88.7,\n",
       "  90.8,\n",
       "  92.4],\n",
       " 'Class Accuracy ConvClassifier ConvBlock 2': [89.2,\n",
       "  93.9,\n",
       "  83.5,\n",
       "  80.5,\n",
       "  90.6,\n",
       "  82.7,\n",
       "  93.1,\n",
       "  90.2,\n",
       "  92.7,\n",
       "  90.7],\n",
       " 'Class Accuracy ConvClassifier ConvBlock 3': [68.4,\n",
       "  65.4,\n",
       "  47.0,\n",
       "  49.9,\n",
       "  58.3,\n",
       "  57.2,\n",
       "  74.3,\n",
       "  65.5,\n",
       "  70.5,\n",
       "  71.0],\n",
       " 'Class Accuracy Non-Linear ConvBlock 1': [85.1,\n",
       "  90.4,\n",
       "  74.8,\n",
       "  69.4,\n",
       "  80.2,\n",
       "  73.7,\n",
       "  88.2,\n",
       "  87.9,\n",
       "  90.5,\n",
       "  90.9],\n",
       " 'Class Accuracy Non-Linear ConvBlock 2': [88.6,\n",
       "  92.5,\n",
       "  81.6,\n",
       "  77.1,\n",
       "  85.5,\n",
       "  78.8,\n",
       "  89.7,\n",
       "  88.3,\n",
       "  92.8,\n",
       "  90.5],\n",
       " 'Class Accuracy Non-Linear ConvBlock 3': [63.0,\n",
       "  56.1,\n",
       "  42.2,\n",
       "  38.7,\n",
       "  45.1,\n",
       "  52.5,\n",
       "  58.4,\n",
       "  53.5,\n",
       "  60.4,\n",
       "  66.1],\n",
       " 'Class Accuracy Rotation Task': [92.19, 92.36, 92.01, 92.16]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 ConvBlock RotNet model and Classifiers\n",
    "ev.evaluate_all(3, testloader, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RotNet model with 4 Convolutional Blocks:\n",
      "()\n",
      "Evaluating Rotation Task:\n",
      "Test Accuracy:  92.573 %\n",
      "Test Accuracy of original :  93.040 %\n",
      "Test Accuracy of 90 rotation :  92.380 %\n",
      "Test Accuracy of 180 rotation :  92.310 %\n",
      "Test Accuracy of 270 rotation :  92.560 %\n",
      "()\n",
      "--------------------------------------------------------------------------------\n",
      "()\n",
      "Starting to evaluate Non-Linear Classifier:\n",
      "()\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 1:\n",
      "Test Accuracy:  83.140 %\n",
      "Test Accuracy of plane :  85.000 %\n",
      "Test Accuracy of car :  91.600 %\n",
      "Test Accuracy of bird :  75.400 %\n",
      "Test Accuracy of cat :  68.100 %\n",
      "Test Accuracy of deer :  80.400 %\n",
      "Test Accuracy of dog :  73.800 %\n",
      "Test Accuracy of frog :  88.900 %\n",
      "Test Accuracy of horse :  86.900 %\n",
      "Test Accuracy of ship :  91.400 %\n",
      "Test Accuracy of truck :  89.900 %\n",
      "()\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 2:\n",
      "Test Accuracy:  87.050 %\n",
      "Test Accuracy of plane :  89.100 %\n",
      "Test Accuracy of car :  92.600 %\n",
      "Test Accuracy of bird :  82.900 %\n",
      "Test Accuracy of cat :  77.500 %\n",
      "Test Accuracy of deer :  87.100 %\n",
      "Test Accuracy of dog :  76.600 %\n",
      "Test Accuracy of frog :  90.400 %\n",
      "Test Accuracy of horse :  91.400 %\n",
      "Test Accuracy of ship :  91.800 %\n",
      "Test Accuracy of truck :  91.100 %\n",
      "()\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 3:\n",
      "Test Accuracy:  82.060 %\n",
      "Test Accuracy of plane :  82.400 %\n",
      "Test Accuracy of car :  88.000 %\n",
      "Test Accuracy of bird :  78.000 %\n",
      "Test Accuracy of cat :  69.700 %\n",
      "Test Accuracy of deer :  79.500 %\n",
      "Test Accuracy of dog :  74.600 %\n",
      "Test Accuracy of frog :  86.500 %\n",
      "Test Accuracy of horse :  87.700 %\n",
      "Test Accuracy of ship :  88.100 %\n",
      "Test Accuracy of truck :  86.100 %\n",
      "()\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 4:\n",
      "Test Accuracy:  45.450 %\n",
      "Test Accuracy of plane :  52.400 %\n",
      "Test Accuracy of car :  50.900 %\n",
      "Test Accuracy of bird :  37.100 %\n",
      "Test Accuracy of cat :  34.200 %\n",
      "Test Accuracy of deer :  34.300 %\n",
      "Test Accuracy of dog :  37.900 %\n",
      "Test Accuracy of frog :  52.700 %\n",
      "Test Accuracy of horse :  49.900 %\n",
      "Test Accuracy of ship :  53.400 %\n",
      "Test Accuracy of truck :  51.700 %\n",
      "()\n",
      "--------------------------------------------------------------------------------\n",
      "()\n",
      "Starting to evaluate Convolutional Classifier:\n",
      "()\n",
      "Evaluating Convolutional Classifier on Convolutional Block 1\n",
      "Test Accuracy:  86.590 %\n",
      "Test Accuracy of plane :  89.500 %\n",
      "Test Accuracy of car :  92.500 %\n",
      "Test Accuracy of bird :  81.000 %\n",
      "Test Accuracy of cat :  74.800 %\n",
      "Test Accuracy of deer :  84.200 %\n",
      "Test Accuracy of dog :  79.400 %\n",
      "Test Accuracy of frog :  91.600 %\n",
      "Test Accuracy of horse :  89.400 %\n",
      "Test Accuracy of ship :  91.700 %\n",
      "Test Accuracy of truck :  91.800 %\n",
      "()\n",
      "Evaluating Convolutional Classifier on Convolutional Block 2\n",
      "Test Accuracy:  88.770 %\n",
      "Test Accuracy of plane :  90.300 %\n",
      "Test Accuracy of car :  92.900 %\n",
      "Test Accuracy of bird :  84.700 %\n",
      "Test Accuracy of cat :  80.900 %\n",
      "Test Accuracy of deer :  89.700 %\n",
      "Test Accuracy of dog :  81.000 %\n",
      "Test Accuracy of frog :  92.100 %\n",
      "Test Accuracy of horse :  91.300 %\n",
      "Test Accuracy of ship :  92.100 %\n",
      "Test Accuracy of truck :  92.700 %\n",
      "()\n",
      "Evaluating Convolutional Classifier on Convolutional Block 3\n",
      "Test Accuracy:  84.460 %\n",
      "Test Accuracy of plane :  86.700 %\n",
      "Test Accuracy of car :  89.000 %\n",
      "Test Accuracy of bird :  79.600 %\n",
      "Test Accuracy of cat :  75.300 %\n",
      "Test Accuracy of deer :  85.700 %\n",
      "Test Accuracy of dog :  75.300 %\n",
      "Test Accuracy of frog :  87.200 %\n",
      "Test Accuracy of horse :  88.300 %\n",
      "Test Accuracy of ship :  88.000 %\n",
      "Test Accuracy of truck :  89.500 %\n",
      "()\n",
      "Evaluating Convolutional Classifier on Convolutional Block 4\n",
      "Test Accuracy:  52.840 %\n",
      "Test Accuracy of plane :  59.300 %\n",
      "Test Accuracy of car :  57.600 %\n",
      "Test Accuracy of bird :  46.200 %\n",
      "Test Accuracy of cat :  41.100 %\n",
      "Test Accuracy of deer :  43.400 %\n",
      "Test Accuracy of dog :  45.900 %\n",
      "Test Accuracy of frog :  59.300 %\n",
      "Test Accuracy of horse :  56.500 %\n",
      "Test Accuracy of ship :  62.700 %\n",
      "Test Accuracy of truck :  56.400 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy ConvClassifier ConvBlock 1': 86.59,\n",
       " 'Accuracy ConvClassifier ConvBlock 2': 88.77,\n",
       " 'Accuracy ConvClassifier ConvBlock 3': 84.46,\n",
       " 'Accuracy ConvClassifier ConvBlock 4': 52.84,\n",
       " 'Accuracy Non-Linear ConvBlock 1': 83.14,\n",
       " 'Accuracy Non-Linear ConvBlock 2': 87.05,\n",
       " 'Accuracy Non-Linear ConvBlock 3': 82.06,\n",
       " 'Accuracy Non-Linear ConvBlock 4': 45.45,\n",
       " 'Accuracy Rotation Task': 92.5725,\n",
       " 'Class Accuracy ConvClassifier ConvBlock 1': [89.5,\n",
       "  92.5,\n",
       "  81.0,\n",
       "  74.8,\n",
       "  84.2,\n",
       "  79.4,\n",
       "  91.6,\n",
       "  89.4,\n",
       "  91.7,\n",
       "  91.8],\n",
       " 'Class Accuracy ConvClassifier ConvBlock 2': [90.3,\n",
       "  92.9,\n",
       "  84.7,\n",
       "  80.9,\n",
       "  89.7,\n",
       "  81.0,\n",
       "  92.1,\n",
       "  91.3,\n",
       "  92.1,\n",
       "  92.7],\n",
       " 'Class Accuracy ConvClassifier ConvBlock 3': [86.7,\n",
       "  89.0,\n",
       "  79.6,\n",
       "  75.3,\n",
       "  85.7,\n",
       "  75.3,\n",
       "  87.2,\n",
       "  88.3,\n",
       "  88.0,\n",
       "  89.5],\n",
       " 'Class Accuracy ConvClassifier ConvBlock 4': [59.3,\n",
       "  57.6,\n",
       "  46.2,\n",
       "  41.1,\n",
       "  43.4,\n",
       "  45.9,\n",
       "  59.3,\n",
       "  56.5,\n",
       "  62.7,\n",
       "  56.4],\n",
       " 'Class Accuracy Non-Linear ConvBlock 1': [85.0,\n",
       "  91.6,\n",
       "  75.4,\n",
       "  68.1,\n",
       "  80.4,\n",
       "  73.8,\n",
       "  88.9,\n",
       "  86.9,\n",
       "  91.4,\n",
       "  89.9],\n",
       " 'Class Accuracy Non-Linear ConvBlock 2': [89.1,\n",
       "  92.6,\n",
       "  82.9,\n",
       "  77.5,\n",
       "  87.1,\n",
       "  76.6,\n",
       "  90.4,\n",
       "  91.4,\n",
       "  91.8,\n",
       "  91.1],\n",
       " 'Class Accuracy Non-Linear ConvBlock 3': [82.4,\n",
       "  88.0,\n",
       "  78.0,\n",
       "  69.7,\n",
       "  79.5,\n",
       "  74.6,\n",
       "  86.5,\n",
       "  87.7,\n",
       "  88.1,\n",
       "  86.1],\n",
       " 'Class Accuracy Non-Linear ConvBlock 4': [52.4,\n",
       "  50.9,\n",
       "  37.1,\n",
       "  34.2,\n",
       "  34.3,\n",
       "  37.9,\n",
       "  52.7,\n",
       "  49.9,\n",
       "  53.4,\n",
       "  51.7],\n",
       " 'Class Accuracy Rotation Task': [93.04, 92.38, 92.31, 92.56]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4 ConvBlock RotNet model and Classifiers\n",
    "ev.evaluate_all(4, testloader, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RotNet model with 5 Convolutional Blocks:\n",
      "()\n",
      "Evaluating Rotation Task:\n",
      "Test Accuracy:  91.830 %\n",
      "Test Accuracy of original :  91.790 %\n",
      "Test Accuracy of 90 rotation :  91.900 %\n",
      "Test Accuracy of 180 rotation :  92.470 %\n",
      "Test Accuracy of 270 rotation :  91.160 %\n",
      "()\n",
      "--------------------------------------------------------------------------------\n",
      "()\n",
      "Starting to evaluate Non-Linear Classifier:\n",
      "()\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 1:\n",
      "Test Accuracy:  82.380 %\n",
      "Test Accuracy of plane :  83.100 %\n",
      "Test Accuracy of car :  88.700 %\n",
      "Test Accuracy of bird :  76.900 %\n",
      "Test Accuracy of cat :  68.700 %\n",
      "Test Accuracy of deer :  80.400 %\n",
      "Test Accuracy of dog :  72.600 %\n",
      "Test Accuracy of frog :  88.200 %\n",
      "Test Accuracy of horse :  85.500 %\n",
      "Test Accuracy of ship :  92.000 %\n",
      "Test Accuracy of truck :  87.700 %\n",
      "()\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 2:\n",
      "Test Accuracy:  86.040 %\n",
      "Test Accuracy of plane :  87.600 %\n",
      "Test Accuracy of car :  92.600 %\n",
      "Test Accuracy of bird :  80.700 %\n",
      "Test Accuracy of cat :  74.400 %\n",
      "Test Accuracy of deer :  84.700 %\n",
      "Test Accuracy of dog :  79.100 %\n",
      "Test Accuracy of frog :  89.000 %\n",
      "Test Accuracy of horse :  89.400 %\n",
      "Test Accuracy of ship :  90.900 %\n",
      "Test Accuracy of truck :  92.000 %\n",
      "()\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 3:\n",
      "Test Accuracy:  82.610 %\n",
      "Test Accuracy of plane :  84.400 %\n",
      "Test Accuracy of car :  88.100 %\n",
      "Test Accuracy of bird :  78.500 %\n",
      "Test Accuracy of cat :  71.500 %\n",
      "Test Accuracy of deer :  81.300 %\n",
      "Test Accuracy of dog :  71.600 %\n",
      "Test Accuracy of frog :  88.200 %\n",
      "Test Accuracy of horse :  85.600 %\n",
      "Test Accuracy of ship :  88.100 %\n",
      "Test Accuracy of truck :  88.800 %\n",
      "()\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 4:\n",
      "Test Accuracy:  69.250 %\n",
      "Test Accuracy of plane :  77.500 %\n",
      "Test Accuracy of car :  73.700 %\n",
      "Test Accuracy of bird :  59.400 %\n",
      "Test Accuracy of cat :  57.100 %\n",
      "Test Accuracy of deer :  67.700 %\n",
      "Test Accuracy of dog :  57.600 %\n",
      "Test Accuracy of frog :  80.800 %\n",
      "Test Accuracy of horse :  71.800 %\n",
      "Test Accuracy of ship :  73.600 %\n",
      "Test Accuracy of truck :  73.300 %\n",
      "()\n",
      "Evaluating Non-Linear Classifier on Convolutional Block 5:\n",
      "Test Accuracy:  37.430 %\n",
      "Test Accuracy of plane :  45.600 %\n",
      "Test Accuracy of car :  40.900 %\n",
      "Test Accuracy of bird :  29.300 %\n",
      "Test Accuracy of cat :  27.900 %\n",
      "Test Accuracy of deer :  28.600 %\n",
      "Test Accuracy of dog :  32.100 %\n",
      "Test Accuracy of frog :  47.300 %\n",
      "Test Accuracy of horse :  37.700 %\n",
      "Test Accuracy of ship :  40.200 %\n",
      "Test Accuracy of truck :  44.700 %\n",
      "()\n",
      "--------------------------------------------------------------------------------\n",
      "()\n",
      "Starting to evaluate Convolutional Classifier:\n",
      "()\n",
      "Evaluating Convolutional Classifier on Convolutional Block 1\n",
      "Test Accuracy:  85.930 %\n",
      "Test Accuracy of plane :  88.600 %\n",
      "Test Accuracy of car :  92.200 %\n",
      "Test Accuracy of bird :  80.300 %\n",
      "Test Accuracy of cat :  75.300 %\n",
      "Test Accuracy of deer :  83.700 %\n",
      "Test Accuracy of dog :  78.900 %\n",
      "Test Accuracy of frog :  90.800 %\n",
      "Test Accuracy of horse :  88.300 %\n",
      "Test Accuracy of ship :  91.100 %\n",
      "Test Accuracy of truck :  90.100 %\n",
      "()\n",
      "Evaluating Convolutional Classifier on Convolutional Block 2\n",
      "Test Accuracy:  88.620 %\n",
      "Test Accuracy of plane :  88.900 %\n",
      "Test Accuracy of car :  93.900 %\n",
      "Test Accuracy of bird :  84.800 %\n",
      "Test Accuracy of cat :  78.800 %\n",
      "Test Accuracy of deer :  89.400 %\n",
      "Test Accuracy of dog :  83.400 %\n",
      "Test Accuracy of frog :  91.700 %\n",
      "Test Accuracy of horse :  90.800 %\n",
      "Test Accuracy of ship :  92.100 %\n",
      "Test Accuracy of truck :  92.400 %\n",
      "()\n",
      "Evaluating Convolutional Classifier on Convolutional Block 3\n",
      "Test Accuracy:  84.590 %\n",
      "Test Accuracy of plane :  86.400 %\n",
      "Test Accuracy of car :  89.700 %\n",
      "Test Accuracy of bird :  80.000 %\n",
      "Test Accuracy of cat :  72.200 %\n",
      "Test Accuracy of deer :  84.900 %\n",
      "Test Accuracy of dog :  77.600 %\n",
      "Test Accuracy of frog :  89.400 %\n",
      "Test Accuracy of horse :  85.700 %\n",
      "Test Accuracy of ship :  89.200 %\n",
      "Test Accuracy of truck :  90.800 %\n",
      "()\n",
      "Evaluating Convolutional Classifier on Convolutional Block 4\n",
      "Test Accuracy:  71.660 %\n",
      "Test Accuracy of plane :  76.800 %\n",
      "Test Accuracy of car :  78.600 %\n",
      "Test Accuracy of bird :  62.700 %\n",
      "Test Accuracy of cat :  57.700 %\n",
      "Test Accuracy of deer :  69.800 %\n",
      "Test Accuracy of dog :  60.600 %\n",
      "Test Accuracy of frog :  82.500 %\n",
      "Test Accuracy of horse :  76.800 %\n",
      "Test Accuracy of ship :  75.200 %\n",
      "Test Accuracy of truck :  75.900 %\n",
      "()\n",
      "Evaluating Convolutional Classifier on Convolutional Block 5\n",
      "Test Accuracy:  41.620 %\n",
      "Test Accuracy of plane :  53.200 %\n",
      "Test Accuracy of car :  44.500 %\n",
      "Test Accuracy of bird :  35.700 %\n",
      "Test Accuracy of cat :  30.300 %\n",
      "Test Accuracy of deer :  30.200 %\n",
      "Test Accuracy of dog :  33.900 %\n",
      "Test Accuracy of frog :  51.000 %\n",
      "Test Accuracy of horse :  41.400 %\n",
      "Test Accuracy of ship :  50.500 %\n",
      "Test Accuracy of truck :  45.500 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy ConvClassifier ConvBlock 1': 85.93,\n",
       " 'Accuracy ConvClassifier ConvBlock 2': 88.62,\n",
       " 'Accuracy ConvClassifier ConvBlock 3': 84.59,\n",
       " 'Accuracy ConvClassifier ConvBlock 4': 71.66,\n",
       " 'Accuracy ConvClassifier ConvBlock 5': 41.62,\n",
       " 'Accuracy Non-Linear ConvBlock 1': 82.38,\n",
       " 'Accuracy Non-Linear ConvBlock 2': 86.04,\n",
       " 'Accuracy Non-Linear ConvBlock 3': 82.61,\n",
       " 'Accuracy Non-Linear ConvBlock 4': 69.25,\n",
       " 'Accuracy Non-Linear ConvBlock 5': 37.43,\n",
       " 'Accuracy Rotation Task': 91.83,\n",
       " 'Class Accuracy ConvClassifier ConvBlock 1': [88.6,\n",
       "  92.2,\n",
       "  80.3,\n",
       "  75.3,\n",
       "  83.7,\n",
       "  78.9,\n",
       "  90.8,\n",
       "  88.3,\n",
       "  91.1,\n",
       "  90.1],\n",
       " 'Class Accuracy ConvClassifier ConvBlock 2': [88.9,\n",
       "  93.9,\n",
       "  84.8,\n",
       "  78.8,\n",
       "  89.4,\n",
       "  83.4,\n",
       "  91.7,\n",
       "  90.8,\n",
       "  92.1,\n",
       "  92.4],\n",
       " 'Class Accuracy ConvClassifier ConvBlock 3': [86.4,\n",
       "  89.7,\n",
       "  80.0,\n",
       "  72.2,\n",
       "  84.9,\n",
       "  77.6,\n",
       "  89.4,\n",
       "  85.7,\n",
       "  89.2,\n",
       "  90.8],\n",
       " 'Class Accuracy ConvClassifier ConvBlock 4': [76.8,\n",
       "  78.6,\n",
       "  62.7,\n",
       "  57.7,\n",
       "  69.8,\n",
       "  60.6,\n",
       "  82.5,\n",
       "  76.8,\n",
       "  75.2,\n",
       "  75.9],\n",
       " 'Class Accuracy ConvClassifier ConvBlock 5': [53.2,\n",
       "  44.5,\n",
       "  35.7,\n",
       "  30.3,\n",
       "  30.2,\n",
       "  33.9,\n",
       "  51.0,\n",
       "  41.4,\n",
       "  50.5,\n",
       "  45.5],\n",
       " 'Class Accuracy Non-Linear ConvBlock 1': [83.1,\n",
       "  88.7,\n",
       "  76.9,\n",
       "  68.7,\n",
       "  80.4,\n",
       "  72.6,\n",
       "  88.2,\n",
       "  85.5,\n",
       "  92.0,\n",
       "  87.7],\n",
       " 'Class Accuracy Non-Linear ConvBlock 2': [87.6,\n",
       "  92.6,\n",
       "  80.7,\n",
       "  74.4,\n",
       "  84.7,\n",
       "  79.1,\n",
       "  89.0,\n",
       "  89.4,\n",
       "  90.9,\n",
       "  92.0],\n",
       " 'Class Accuracy Non-Linear ConvBlock 3': [84.4,\n",
       "  88.1,\n",
       "  78.5,\n",
       "  71.5,\n",
       "  81.3,\n",
       "  71.6,\n",
       "  88.2,\n",
       "  85.6,\n",
       "  88.1,\n",
       "  88.8],\n",
       " 'Class Accuracy Non-Linear ConvBlock 4': [77.5,\n",
       "  73.7,\n",
       "  59.4,\n",
       "  57.1,\n",
       "  67.7,\n",
       "  57.6,\n",
       "  80.8,\n",
       "  71.8,\n",
       "  73.6,\n",
       "  73.3],\n",
       " 'Class Accuracy Non-Linear ConvBlock 5': [45.6,\n",
       "  40.9,\n",
       "  29.3,\n",
       "  27.9,\n",
       "  28.6,\n",
       "  32.1,\n",
       "  47.3,\n",
       "  37.7,\n",
       "  40.2,\n",
       "  44.7],\n",
       " 'Class Accuracy Rotation Task': [91.79, 91.9, 92.47, 91.16]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 ConvBlock RotNet model and Classifiers\n",
    "ev.evaluate_all(5, testloader, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Supervised NIN Classification Task:\n",
      "Test Accuracy:  91.550 %\n",
      "Test Accuracy of plane :  91.900 %\n",
      "Test Accuracy of car :  96.000 %\n",
      "Test Accuracy of bird :  88.000 %\n",
      "Test Accuracy of cat :  82.100 %\n",
      "Test Accuracy of deer :  92.400 %\n",
      "Test Accuracy of dog :  86.000 %\n",
      "Test Accuracy of frog :  95.100 %\n",
      "Test Accuracy of horse :  93.200 %\n",
      "Test Accuracy of ship :  96.200 %\n",
      "Test Accuracy of truck :  94.600 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy Supervised NIN': 91.55,\n",
       " 'Class Accuracy Supervised NIN': [91.9,\n",
       "  96.0,\n",
       "  88.0,\n",
       "  82.1,\n",
       "  92.4,\n",
       "  86.0,\n",
       "  95.1,\n",
       "  93.2,\n",
       "  96.2,\n",
       "  94.6]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Supervised NIN\n",
    "ev.evaluate_all(0, testloader, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
